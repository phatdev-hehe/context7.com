TITLE: Implementing LLM Invocation in Python
DESCRIPTION: This snippet demonstrates the implementation of the _invoke method for Large Language Models. It supports both streaming and synchronous returns.

LANGUAGE: python
CODE:
def _invoke(self, model: str, credentials: dict,
            prompt_messages: list[PromptMessage], model_parameters: dict,
            tools: Optional[list[PromptMessageTool]] = None, stop: Optional[list[str]] = None,
            stream: bool = True, user: Optional[str] = None) \
        -> Union[LLMResult, Generator]:
    """
    Invoke large language model

    :param model: model name
    :param credentials: model credentials
    :param prompt_messages: prompt messages
    :param model_parameters: model parameters
    :param tools: tools for tool calling
    :param stop: stop words
    :param stream: is stream response
    :param user: unique user id
    :return: full response or stream response chunk generator result
    """

----------------------------------------

TITLE: Implementing Model Credential Validation in Python
DESCRIPTION: This snippet demonstrates the implementation of the validate_credentials method for validating individual model credentials. It's a common interface that all models must implement.

LANGUAGE: python
CODE:
def validate_credentials(self, model: str, credentials: dict) -> None:
    """
    Validate model credentials

    :param model: model name
    :param credentials: model credentials
    :return:
    """

----------------------------------------

TITLE: Defining Dify Plugin Manifest in YAML
DESCRIPTION: This YAML snippet demonstrates the structure of a Dify plugin manifest file. It includes basic plugin information, resource requirements, permissions, and runtime configurations. The manifest is crucial for plugin parsing and packaging processes.

LANGUAGE: yaml
CODE:
version: 0.0.1
type: "plugin"
author: "Yeuoly"
name: "neko"
label:
  en_US: "Neko"
created_at: "2024-07-12T08:03:44.658609186Z"
icon: "icon.svg"
resource:
  memory: 1048576
  permission:
    tool:
      enabled: true
    model:
      enabled: true
      llm: true
    endpoint:
      enabled: true
    app:
      enabled: true
    storage: 
      enabled: true
      size: 1048576
plugins:
  endpoints:
    - "provider/neko.yaml"
meta:
  version: 0.0.1
  arch:
    - "amd64"
    - "arm64"
  runner:
    language: "python"
    version: "3.10"
    entrypoint: "main"
privacy: "./privacy.md"

----------------------------------------

TITLE: Implementing LLM Invocation in Python
DESCRIPTION: Defines the _invoke method for the XinferenceAILargeLanguageModel class, handling both streaming and synchronous responses for LLM invocation.

LANGUAGE: python
CODE:
def _invoke(
    self,
    model: str,
    credentials: dict,
    prompt_messages: list[PromptMessage],
    model_parameters: dict,
    tools: Optional[list[PromptMessageTool]] = None,
    stop: Optional[list[str]] = None,
    stream: bool = True,
    user: Optional[str] = None
) -> Union[LLMResult, Generator]:
    """
    Invoke the large language model.

    :param model: model name
    :param credentials: model credentials
    :param prompt_messages: prompt messages
    :param model_parameters: model parameters
    :param tools: tools for tool calling
    :param stop: stop words
    :param stream: determines if response is streamed
    :param user: unique user id
    :return: full response or a chunk generator
    """
    if stream:
        return self._handle_stream_response(**kwargs)
    return self._handle_sync_response(**kwargs)

def _handle_stream_response(self, **kwargs) -> Generator:
    for chunk in response:
        yield chunk

def _handle_sync_response(self, **kwargs) -> LLMResult:
    return LLMResult(**response)

----------------------------------------

TITLE: Defining Dify Plugin Manifest in YAML
DESCRIPTION: This YAML snippet demonstrates the structure of a Dify plugin manifest file. It includes basic plugin information, resource requirements, permissions, and runtime configurations. The manifest is crucial for plugin parsing and packaging processes.

LANGUAGE: yaml
CODE:
version: 0.0.1
type: "plugin"
author: "Yeuoly"
name: "neko"
label:
  en_US: "Neko"
created_at: "2024-07-12T08:03:44.658609186Z"
icon: "icon.svg"
resource:
  memory: 1048576
  permission:
    tool:
      enabled: true
    model:
      enabled: true
      llm: true
    endpoint:
      enabled: true
    app:
      enabled: true
    storage: 
      enabled: true
      size: 1048576
plugins:
  endpoints:
    - "provider/neko.yaml"
meta:
  version: 0.0.1
  arch:
    - "amd64"
    - "arm64"
  runner:
    language: "python"
    version: "3.10"
    entrypoint: "main"
privacy: "./privacy.md"

----------------------------------------

TITLE: Implementing Rerank Model Invocation in Python
DESCRIPTION: This snippet demonstrates the implementation of the _invoke method for Rerank models. It reranks a list of documents based on a query.

LANGUAGE: python
CODE:
def _invoke(self, model: str, credentials: dict,
            query: str, docs: list[str], score_threshold: Optional[float] = None, top_n: Optional[int] = None,
            user: Optional[str] = None) \
        -> RerankResult:
    """
    Invoke rerank model

    :param model: model name
    :param credentials: model credentials
    :param query: search query
    :param docs: docs for reranking
    :param score_threshold: score threshold
    :param top_n: top n
    :param user: unique user id
    :return: rerank result
    """

----------------------------------------

TITLE: Defining API Request and Response Structures in JSON
DESCRIPTION: Specifies the JSON structure for API requests and responses in Dify's API-based extensions, including headers, request body, and expected response format.

LANGUAGE: JSON
CODE:
{
    "point":  string, // Extension point, different modules may contain multiple extension points
    "params": {
        ...  // Parameters passed to each module's extension point
    }
}

LANGUAGE: JSON
CODE:
{
    ...  // For the content returned by the API, see the specific module's design specifications for different extension points.
}

----------------------------------------

TITLE: Implementing Xinference LLM Class in Python
DESCRIPTION: Defines the XinferenceAILargeLanguageModel class, implementing core methods for LLM invocation, token counting, credential validation, and parameter schema generation.

LANGUAGE: python
CODE:
class XinferenceAILargeLanguageModel(LargeLanguageModel):
    def _invoke(self, model: str, credentials: dict,
                prompt_messages: list[PromptMessage], model_parameters: dict,
                tools: Optional[list[PromptMessageTool]] = None, stop: Optional[List[str]] = None,
                stream: bool = True, user: Optional[str] = None) \
            -> Union[LLMResult, Generator]:
        if stream:
            return self._handle_stream_response(**kwargs)
        return self._handle_sync_response(**kwargs)

    def _handle_stream_response(self, **kwargs) -> Generator:
        for chunk in response:
            yield chunk

    def _handle_sync_response(self, **kwargs) -> LLMResult:
        return LLMResult(**response)

    def get_num_tokens(self, model: str, credentials: dict, prompt_messages: list[PromptMessage],
                       tools: Optional[list[PromptMessageTool]] = None) -> int:
        # Implementation

    def validate_credentials(self, model: str, credentials: dict) -> None:
        # Implementation

    def get_customizable_model_schema(self, model: str, credentials: dict) -> AIModelEntity | None:
        rules = [
            ParameterRule(
                name='temperature', type=ParameterType.FLOAT,
                use_template='temperature',
                label=I18nObject(
                    zh_Hans='温度', en_US='Temperature'
                )
            ),
            # Other rules...
        ]

        entity = AIModelEntity(
            model=model,
            label=I18nObject(
                en_US=model
            ),
            fetch_from=FetchFrom.CUSTOMIZABLE_MODEL,
            model_type=model_type,
            model_properties={ 
                ModelPropertyKey.MODE:  ModelType.LLM,
            },
            parameter_rules=rules
        )

        return entity

    @property
    def _invoke_error_mapping(self) -> dict[type[InvokeError], list[type[Exception]]]:
        # Implementation

----------------------------------------

TITLE: Designing Pre-prompt for iPhone Customer Service in Dify
DESCRIPTION: This code snippet demonstrates how to create a pre-prompt for an iPhone customer service assistant in Dify's Expert Mode. It includes instructions for the AI's behavior and output format.

LANGUAGE: markdown
CODE:
When answer to user:
- If you don't know, just say that you don't know.
- If you don't know when you are not sure, ask for clarification.
Avoid mentioning that you obtained the information from the context.
And answer according to the language of the user's question.

You are a customer service assistant for Apple Inc., and you can provide iPhone consultation services to users.
When answering, you need to list the detailed specifications of the iPhone, and you must output this information in a vertical {{Format}} table. If the list is too long, it should be transposed.
You are allowed to take a long time to think to generate a more reasonable output.
Note: You currently have knowledge of only a subset of iPhone models, not all of them.

----------------------------------------

TITLE: Creating Blob Message in Python for Dify Tool
DESCRIPTION: Method to create a file blob message. It takes raw file data in bytes and optional metadata. Used for returning various file types like images, audio, video, and documents.

LANGUAGE: python
CODE:
def create_blob_message(self, blob: bytes, meta: dict = None) -> ToolInvokeMessage:
    pass

----------------------------------------

TITLE: Defining ProviderConfig Structure for Tool and Endpoint Configurations in Dify
DESCRIPTION: ProviderConfig is a common provider form structure used in both Tool and Endpoint configurations. It specifies various properties including name, label, type, scope, and options for configuring plugin components.

LANGUAGE: yaml
CODE:
ProviderConfig:
  name: "string"
  label: I18nObject
  type: provider_config_type
  scope: provider_config_scope
  required: bool
  default: any
  options: list[provider_config_option]
  helper: object
  url: "string"
  placeholder: object

----------------------------------------

TITLE: Defining Invocation Error Mapping for Models in Python
DESCRIPTION: This snippet shows how to implement the _invoke_error_mapping property to map model invocation errors to unified error types. This is required for all model types.

LANGUAGE: python
CODE:
@property
def _invoke_error_mapping(self) -> dict[type[InvokeError], list[type[Exception]]]:
    """
    Map model invoke error to unified error
    The key is the error type thrown to the caller
    The value is the error type thrown by the model,
    which needs to be converted into a unified error type for the caller.

    :return: Invoke error mapping
    """

----------------------------------------

TITLE: Configuring LLM Node with System Prompt in Dify
DESCRIPTION: This code snippet shows how to set up the system prompt for an LLM node, using context from the knowledge retrieval node to answer user questions.

LANGUAGE: plaintext
CODE:
Based on {{context}}, answer {{user question}}

----------------------------------------

TITLE: Generating Dynamic Model Parameters Schema in Python
DESCRIPTION: Implements the get_customizable_model_schema method to dynamically generate parameter schemas based on model capabilities.

LANGUAGE: python
CODE:
def get_customizable_model_schema(self, model: str, credentials: dict) -> AIModelEntity | None:
    """
        used to define customizable model schema
    """
    rules = [
        ParameterRule(
            name='temperature', type=ParameterType.FLOAT,
            use_template='temperature',
            label=I18nObject(
                zh_Hans='温度', en_US='Temperature'
            )
        ),
        ParameterRule(
            name='top_p', type=ParameterType.FLOAT,
            use_template='top_p',
            label=I18nObject(
                zh_Hans='Top P', en_US='Top P'
            )
        ),
        ParameterRule(
            name='max_tokens', type=ParameterType.INT,
            use_template='max_tokens',
            min=1,
            default=512,
            label=I18nObject(
                zh_Hans='最大生成长度', en_US='Max Tokens'
            )
        )
    ]

    # if model is A, add top_k to rules
    if model == 'A':
        rules.append(
            ParameterRule(
                name='top_k', type=ParameterType.INT,
                use_template='top_k',
                min=1,
                default=50,
                label=I18nObject(
                    zh_Hans='Top K', en_US='Top K'
                )
            )
        )

    """
        some NOT IMPORTANT code here
    """

    entity = AIModelEntity(
        model=model,
        label=I18nObject(
            en_US=model
        ),
        fetch_from=FetchFrom.CUSTOMIZABLE_MODEL,
        model_type=model_type,
        model_properties={ 
            ModelPropertyKey.MODE:  ModelType.LLM,
        },
        parameter_rules=rules
    )

    return entity

----------------------------------------

TITLE: Implementing Credential Validation in Python
DESCRIPTION: Defines the validate_credentials method for validating model-specific credentials.

LANGUAGE: python
CODE:
def validate_credentials(self, model: str, credentials: dict) -> None:
    """
    Validate model credentials.
    """

----------------------------------------

TITLE: Configuring Anthropic Claude-2.1 Model in YAML
DESCRIPTION: This YAML snippet defines the configuration for the Anthropic Claude-2.1 model, including its features, properties, parameter rules, and pricing information.

LANGUAGE: yaml
CODE:
model: claude-2.1
label:
  en_US: claude-2.1
model_type: llm
features:
- agent-thought
model_properties:
  mode: chat
  context_size: 200000
parameter_rules:
- name: temperature
  use_template: temperature
- name: top_p
  use_template: top_p
- name: top_k
  label:
    zh_Hans: 取样数量
    en_US: Top k
  type: int
  help:
    zh_Hans: 仅从每个后续标记的前 K 个选项中采样。
    en_US: Only sample from the top K options for each subsequent token.
  required: false
- name: max_tokens_to_sample
  use_template: max_tokens
  default: 4096
  min: 1
  max: 4096
pricing:
  input: '8.00'
  output: '24.00'
  unit: '0.000001'
  currency: USD

----------------------------------------

TITLE: Implementing Speech-to-Text Model Invocation in Python
DESCRIPTION: This snippet shows the implementation of the _invoke method for Speech-to-Text models. It converts an audio file to text.

LANGUAGE: python
CODE:
def _invoke(self, model: str, credentials: dict,
            file: IO[bytes], user: Optional[str] = None) \
        -> str:
    """
    Invoke large language model

    :param model: model name
    :param credentials: model credentials
    :param file: audio file
    :param user: unique user id
    :return: text for given audio file
    """

----------------------------------------

TITLE: Implementing Text-to-Speech Model Invocation in Python
DESCRIPTION: This snippet demonstrates the implementation of the _invoke method for Text-to-Speech models. It converts text to an audio stream.

LANGUAGE: python
CODE:
def _invoke(self, model: str, credentials: dict, content_text: str, streaming: bool, user: Optional[str] = None):
    """
    Invoke large language model

    :param model: model name
    :param credentials: model credentials
    :param content_text: text content to be translated
    :param streaming: output is streaming
    :param user: unique user id
    :return: translated audio file
    """

----------------------------------------

TITLE: Calling Dify Text Generation API with cURL
DESCRIPTION: This snippet demonstrates how to make a POST request to Dify's completion-messages API for text generation using cURL. It includes setting the authorization header, specifying the content type, and sending the request body with inputs and response mode.

LANGUAGE: cURL
CODE:
curl --location --request POST 'https://api.dify.ai/v1/completion-messages' \
--header 'Authorization: Bearer ENTER-YOUR-SECRET-KEY' \
--header 'Content-Type: application/json' \
--data-raw '{
    "inputs": {},
    "response_mode": "streaming",
    "user": "abc-123"
}'

----------------------------------------

TITLE: Implementing Endpoint Class in Python for Dify Plugin
DESCRIPTION: This Python code demonstrates the implementation of an Endpoint class for a Dify plugin. It includes the _invoke method that handles the request and returns a response.

LANGUAGE: python
CODE:
import json
from typing import Mapping
from werkzeug import Request, Response
from dify_plugin import Endpoint

class Duck(Endpoint):
    def _invoke(self, r: Request, values: Mapping, settings: Mapping) -> Response:
        """
        Invokes the endpoint with the given request.
        """
        app_id = values["app_id"]
        def generator():
            yield f"{app_id} <br>"
        return Response(generator(), status=200, content_type="text/html")

----------------------------------------

TITLE: Defining AI Chatbot Pre-prompt in Dify
DESCRIPTION: This snippet shows an example of a pre-prompt configuration for an AI chatbot named Bob, specializing in answering questions about Dify's products, team, and LLMOps.

LANGUAGE: markdown
CODE:
> Pre prompt：You are Bob, the AI customer service for Dify, specializing in answering questions about Dify's products, team, or LLMOps for users.Please note, refuse to answer when users ask "inappropriate questions", i.e., content beyond the scope of this document.

----------------------------------------

TITLE: Implementing Moderation Model Invocation in Python
DESCRIPTION: This snippet shows the implementation of the _invoke method for Moderation models. It checks if the input text is safe or not.

LANGUAGE: python
CODE:
def _invoke(self, model: str, credentials: dict,
            text: str, user: Optional[str] = None) \
        -> bool:
    """
    Invoke large language model

    :param model: model name
    :param credentials: model credentials
    :param text: text to moderate
    :param user: unique user id
    :return: false if text is safe, true otherwise
    """

----------------------------------------

TITLE: Defining Basic JSON Schema Template
DESCRIPTION: A generic template showing the basic structure and components of a JSON Schema definition, including various field types and validation rules.

LANGUAGE: json
CODE:
{
    "name": "template_schema",
    "description": "A generic template for JSON Schema",
    "strict": true,
    "schema": {
        "type": "object",
        "properties": {
            "field1": {
                "type": "string",
                "description": "Description of field1"
            },
            "field2": {
                "type": "number",
                "description": "Description of field2"
            },
            "field3": {
                "type": "array",
                "description": "Description of field3",
                "items": {
                    "type": "string"
                }
            },
            "field4": {
                "type": "object",
                "description": "Description of field4",
                "properties": {
                    "subfield1": {
                        "type": "string",
                        "description": "Description of subfield1"
                    }
                },
                "required": ["subfield1"],
                "additionalProperties": false
            }
        },
        "required": ["field1", "field2", "field3", "field4"],
        "additionalProperties": false
    }
}

----------------------------------------

TITLE: Project Directory Structure Overview
DESCRIPTION: Detailed file structure showing the organization of the Dify project, including server components, internal packages, and test directories. The structure highlights key components like controllers, middleware, and language-specific executors.

LANGUAGE: plaintext
CODE:
[cmd/]
├── server                // Server startup entry point
├── lib                   // Shared library entry point
└── test                  // Common test scripts
[build/]                  // Build scripts for different architectures and platforms
[internal/]               // Internal packages
├── controller            // HTTP request handlers
├── middleware            // Request processing middleware
├── server                // Server setup and configuration
├── service               // Controller services
├── static                // Configuration files
│   ├── nodejs_syscall    // Node.js system call whitelist
│   └── python_syscall    // Python system call whitelist
├── types                 // Entity definitions
├── core                  // Core isolation and execution logic
│   ├── lib               // Shared libraries
│   ├── runner            // Code execution
│   │   ├── nodejs        // Node.js executor
|   |   └── python        // Python executor
└── tests                 // CI/CD tests

----------------------------------------

TITLE: Calling Dify Chat Messages API with cURL
DESCRIPTION: This cURL command demonstrates how to make a POST request to Dify's chat-messages API for conversational applications. It includes the authorization header, content type, and request body with query, response mode, and conversation ID.

LANGUAGE: cURL
CODE:
curl --location --request POST 'https://api.dify.ai/v1/chat-messages' \
--header 'Authorization: Bearer ENTER-YOUR-SECRET-KEY' \
--header 'Content-Type: application/json' \
--data-raw '{
    "inputs": {},
    "query": "eh",
    "response_mode": "streaming",
    "conversation_id": "1c7e55fb-1ba2-4e10-81b5-30addcea2276",
    "user": "abc-123"
}'

----------------------------------------

TITLE: Defining AIModelEntity Structure in Markdown
DESCRIPTION: Details the structure and properties of the AIModelEntity, including model identifier, display name, type, features, properties, parameter rules, and pricing information.

LANGUAGE: markdown
CODE:
### **AIModelEntity**

* `model` (string): Model identifier, e.g., gpt-3.5-turbo
* `label` (object) \[optional]: Model display name, i18n
  * `zh_Hans` (string) \[optional]: Chinese label
  * `en_US` (string): English label
* `model_type` (\[ModelType]): Model type
* `features` (array\[\[ModelFeature]]) \[optional]: List of supported features
* `model_properties` (object): Model properties
  * `mode` (\[LLMMode]): Mode (available for llm model type)
  * `context_size` (int): Context size (available for llm and text-embedding types)
  * `max_chunks` (int): Maximum number of chunks (available for text-embedding and moderation types)
  * `file_upload_limit` (int): Maximum file upload limit in MB (available for speech2text type)
  * `supported_file_extensions` (string): Supported file extensions, e.g., mp3,mp4 (available for speech2text type)
  * `default_voice` (string): Default voice, must be one of: alloy,echo,fable,onyx,nova,shimmer (available for tts type)
  * `voices` (list): Available voice list
  * `mode` (string): Voice model (available for tts type)
  * `name` (string): Voice model display name (available for tts type)
  * `language` (string): Voice model supported languages (available for tts type)
  * `word_limit` (int): Single conversion word limit, defaults to paragraph division (available for tts type)
  * `audio_type` (string): Supported audio file extensions, e.g., mp3,wav (available for tts type)
  * `max_workers` (int): Maximum concurrent tasks for text-to-audio conversion (available for tts type)
  * `max_characters_per_chunk` (int): Maximum characters per chunk (available for moderation type)
* `parameter_rules` (array\[ParameterRule]) \[optional]: Model call parameter rules
* `pricing` (\[PriceConfig]) \[optional]: Pricing information
* `deprecated` (bool): Whether deprecated. If true, model won't show in list but configured ones can still be used. Default: False

----------------------------------------

TITLE: Managing Knowledge Base Operations
DESCRIPTION: Collection of API endpoints for managing knowledge bases, including creation, listing, deletion, and document management operations.

LANGUAGE: bash
CODE:
curl --location --request POST 'https://api.dify.ai/v1/datasets' \
--header 'Authorization: Bearer {api_key}' \
--header 'Content-Type: application/json' \
--data-raw '{"name": "name", "permission": "only_me"}'

----------------------------------------

TITLE: Cloud Service Moderation Class Template in Python
DESCRIPTION: This Python class template provides a structure for implementing custom cloud service moderation in Dify. It includes methods for config validation, input moderation, and output moderation, with placeholders for custom logic implementation.

LANGUAGE: python
CODE:
from core.moderation.base import Moderation, ModerationAction, ModerationInputsResult, ModerationOutputsResult

class CloudServiceModeration(Moderation):
    """
    The name of custom type must be unique, keep the same with directory and file name.
    """
    name: str = "cloud_service"

    @classmethod
    def validate_config(cls, tenant_id: str, config: dict) -> None:
        """
        schema.json validation. It will be called when user saves the config.
        
        :param tenant_id: the id of workspace
        :param config: the variables of form config
        :return:
        """
        cls._validate_inputs_and_outputs_config(config, True)
        
        # implement your own logic here

    def moderation_for_inputs(self, inputs: dict, query: str = "") -> ModerationInputsResult:
        """
        Moderation for inputs.

        :param inputs: user inputs
        :param query: the query of chat app, there is empty if is completion app
        :return: the moderation result
        """
        flagged = False
        preset_response = ""
        
        # implement your own logic here
        
        # return ModerationInputsResult(flagged=flagged, action=ModerationAction.overridden, inputs=inputs, query=query)
        return ModerationInputsResult(flagged=flagged, action=ModerationAction.DIRECT_OUTPUT, preset_response=preset_response)

    def moderation_for_outputs(self, text: str) -> ModerationOutputsResult:
        """
        Moderation for outputs.

        :param text: the text of LLM response
        :return: the moderation result
        """
        flagged = False
        preset_response = ""
        
        # implement your own logic here

        # return ModerationOutputsResult(flagged=flagged, action=ModerationAction.overridden, text=text)
        return ModerationOutputsResult(flagged=flagged, action=ModerationAction.DIRECT_OUTPUT, preset_response=preset_response)

----------------------------------------

TITLE: Calling Dify Chat Messages API with Python
DESCRIPTION: This Python script shows how to use the requests library to make a POST request to Dify's chat-messages API for conversational applications. It sets up the headers, prepares the request data including the conversation ID, sends the request, and prints the response.

LANGUAGE: Python
CODE:
import requests
import json

url = 'https://api.dify.ai/v1/chat-messages'
headers = {
    'Authorization': 'Bearer ENTER-YOUR-SECRET-KEY',
    'Content-Type': 'application/json',
}
data = {
    "inputs": {},
    "query": "eh",
    "response_mode": "streaming",
    "conversation_id": "1c7e55fb-1ba2-4e10-81b5-30addcea2276",
    "user": "abc-123"
}

response = requests.post(url, headers=headers, data=json.dumps(data))

print(response.text())

----------------------------------------

TITLE: Configuring Endpoint Group Settings in YAML for Dify Plugin
DESCRIPTION: This YAML snippet defines the settings and endpoints for an Endpoint group in a Dify plugin. It includes configuration for an API key input and specifies the location of endpoint interface definitions.

LANGUAGE: yaml
CODE:
settings:
  api_key:
    type: secret-input
    required: true
    label:
      en_US: API key
      zh_Hans: API key
      ja_Jp: API key
      pt_BR: API key
    placeholder:
      en_US: Please input your API key
      zh_Hans: 请输入你的 API key
      ja_Jp: あなたの API key を入れてください
      pt_BR: Por favor, insira sua chave API
endpoints:
  - endpoints/duck.yaml
  - endpoints/neko.yaml

----------------------------------------

TITLE: Model Invocation Implementation
DESCRIPTION: Complete implementation of model invocation including prompt message handling and tool conversion.

LANGUAGE: python
CODE:
from collections.abc import Generator
from typing import Any
from pydantic import BaseModel
from dify_plugin.entities.agent import AgentInvokeMessage
from dify_plugin.entities.model.llm import LLMModelConfig
from dify_plugin.entities.model.message import PromptMessageTool, SystemPromptMessage, UserPromptMessage
from dify_plugin.entities.tool import ToolParameter
from dify_plugin.interfaces.agent import AgentModelConfig, AgentStrategy, ToolEntity

class FunctionCallingParams(BaseModel):
    query: str
    instruction: str | None
    model: AgentModelConfig
    tools: list[ToolEntity] | None
    maximum_iterations: int = 3

class FunctionCallingAgentStrategy(AgentStrategy):
    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:
        fc_params = FunctionCallingParams(**parameters)
        query = fc_params.query
        model = fc_params.model
        stop = fc_params.model.completion_params.get("stop", []) if fc_params.model.completion_params else []
        prompt_messages = [
            SystemPromptMessage(content="your system prompt message"),
            UserPromptMessage(content=query),
        ]
        tools = fc_params.tools
        prompt_messages_tools = self._init_prompt_tools(tools)

        chunks = self.session.model.llm.invoke(
            model_config=LLMModelConfig(**model.model_dump(mode="json")),
            prompt_messages=prompt_messages,
            stream=True,
            stop=stop,
            tools=prompt_messages_tools,
        )

----------------------------------------

TITLE: Implementing Vectorizer.AI Tool in Python for Dify
DESCRIPTION: This code demonstrates the implementation of a Vectorizer.AI tool for Dify. It converts PNG images to vector format, utilizes the variable pool for image retrieval, and includes methods for runtime parameter generation and tool availability checking.

LANGUAGE: python
CODE:
from core.tools.tool.builtin_tool import BuiltinTool
from core.tools.entities.tool_entities import ToolInvokeMessage, ToolParameter
from core.tools.errors import ToolProviderCredentialValidationError

from typing import Any, Dict, List, Union
from httpx import post
from base64 import b64decode

class VectorizerTool(BuiltinTool):
    def _invoke(self, user_id: str, tool_Parameters: Dict[str, Any]) \
        -> Union[ToolInvokeMessage, List[ToolInvokeMessage]]:
        """
            invoke tools
        """
        api_key_name = self.runtime.credentials.get('api_key_name', None)
        api_key_value = self.runtime.credentials.get('api_key_value', None)

        if not api_key_name or not api_key_value:
            raise ToolProviderCredentialValidationError('Please input api key name and value')

        # Get image_id, the definition of image_id can be found in get_runtime_parameters
        image_id = tool_Parameters.get('image_id', '')
        if not image_id:
            return self.create_text_message('Please input image id')

        # Get the image generated by DallE from the variable pool
        image_binary = self.get_variable_file(self.VARIABLE_KEY.IMAGE)
        if not image_binary:
            return self.create_text_message('Image not found, please request user to generate image firstly.')

        # Generate vector image
        response = post(
            'https://vectorizer.ai/api/v1/vectorize',
            files={ 'image': image_binary },
            data={ 'mode': 'test' },
            auth=(api_key_name, api_key_value), 
            timeout=30
        )

        if response.status_code != 200:
            raise Exception(response.text)
        
        return [
            self.create_text_message('the vectorized svg is saved as an image.'),
            self.create_blob_message(blob=response.content,
                                    meta={'mime_type': 'image/svg+xml'})
        ]
    
    def get_runtime_parameters(self) -> List[ToolParameter]:
        """
        override the runtime parameters
        """
        # Here, we override the tool parameter list, define the image_id, and set its option list to all images in the current variable pool. The configuration here is consistent with the configuration in yaml.
        return [
            ToolParameter.get_simple_instance(
                name='image_id',
                llm_description=f'the image id that you want to vectorize, \
                    and the image id should be specified in \
                        {[i.name for i in self.list_default_image_variables()]}',
                type=ToolParameter.ToolParameterType.SELECT,
                required=True,
                options=[i.name for i in self.list_default_image_variables()]
            )
        ]
    
    def is_tool_available(self) -> bool:
        # Only when there are images in the variable pool, the LLM needs to use this tool
        return len(self.list_default_image_variables()) > 0

----------------------------------------

TITLE: Defining Frontend Component Schema for Dify Extensions in JSON
DESCRIPTION: This JSON schema defines the structure for creating frontend components in Dify extensions. It includes specifications for labels, form schemas, and various input types such as select dropdowns, text inputs, and paragraphs.

LANGUAGE: json
CODE:
{
    "label": {
        "en-US": "Cloud Service",
        "zh-Hans": "云服务"
    },
    "form_schema": [
        {
            "type": "select",
            "label": {
                "en-US": "Cloud Provider",
                "zh-Hans": "云厂商"
            },
            "variable": "cloud_provider",
            "required": true,
            "options": [
                {
                    "label": {
                        "en-US": "AWS",
                        "zh-Hans": "亚马逊"
                    },
                    "value": "AWS"
                },
                {
                    "label": {
                        "en-US": "Google Cloud",
                        "zh-Hans": "谷歌云"
                    },
                    "value": "GoogleCloud"
                },
                {
                    "label": {
                        "en-US": "Azure Cloud",
                        "zh-Hans": "微软云"
                    },
                    "value": "Azure"
                }
            ],
            "default": "GoogleCloud",
            "placeholder": ""
        },
        {
            "type": "text-input",
            "label": {
                "en-US": "API Endpoint",
                "zh-Hans": "API Endpoint"
            },
            "variable": "api_endpoint",
            "required": true,
            "max_length": 100,
            "default": "",
            "placeholder": "https://api.example.com"
        },
        {
            "type": "paragraph",
            "label": {
                "en-US": "API Key",
                "zh-Hans": "API Key"
            },
            "variable": "api_keys",
            "required": true,
            "default": "",
            "placeholder": "Paste your API key here"
        }
    ]
}

----------------------------------------

TITLE: LLM Invoke Method Implementation
DESCRIPTION: Core method for handling LLM requests with support for both streaming and synchronous returns, implementing the base LargeLanguageModel class.

LANGUAGE: python
CODE:
def _invoke(self, model: str, credentials: dict,
            prompt_messages: list[PromptMessage], model_parameters: dict,
            tools: Optional[list[PromptMessageTool]] = None, stop: Optional[list[str]] = None,
            stream: bool = True, user: Optional[str] = None) \
        -> Union[LLMResult, Generator]:
    """
    Invoke large language model

    :param model: model name
    :param credentials: model credentials
    :param prompt_messages: prompt messages
    :param model_parameters: model parameters
    :param tools: tools for tool calling
    :param stop: stop words
    :param stream: is stream response
    :param user: unique user id
    :return: full response or stream response chunk generator result
    """

----------------------------------------

TITLE: Weather Search Implementation Class
DESCRIPTION: Python implementation class for the Weather Search tool, including config validation and query functionality.

LANGUAGE: python
CODE:
from typing import Optional

from core.external_data_tool.base import ExternalDataTool


class WeatherSearch(ExternalDataTool):
    """
    The name of custom type must be unique, keep the same with directory and file name.
    """
    name: str = "weather_search"

    @classmethod
    def validate_config(cls, tenant_id: str, config: dict) -> None:
        """
        schema.json validation. It will be called when user save the config.

        Example:
            .. code-block:: python
                config = {
                    "temperature_unit": "centigrade"
                }

        :param tenant_id: the id of workspace
        :param config: the variables of form config
        :return:
        """

        if not config.get('temperature_unit'):
            raise ValueError('temperature unit is required')

    def query(self, inputs: dict, query: Optional[str] = None) -> str:
        """
        Query the external data tool.

        :param inputs: user inputs
        :param query: the query of chat app
        :return: the tool query result
        """
        city = inputs.get('city')
        temperature_unit = self.config.get('temperature_unit')

        if temperature_unit == 'fahrenheit':
            return f'Weather in {city} is 32°F'
        else:
            return f'Weather in {city} is 0°C'

----------------------------------------

TITLE: Web Page Crawling Tool Implementation in Python for Dify
DESCRIPTION: This code snippet demonstrates a shortcut tool for web page crawling in Dify. It takes a URL and an optional user_agent, returning the crawled web page content as a string.

LANGUAGE: python
CODE:
def get_url(self, url: str, user_agent: str = None) -> str:
    """
        get url
    """ the crawled result

----------------------------------------

TITLE: Implementing Text Embedding Invocation in Python
DESCRIPTION: This snippet shows the implementation of the _invoke method for Text Embedding models. It processes a list of texts and returns embedding results.

LANGUAGE: python
CODE:
def _invoke(self, model: str, credentials: dict,
            texts: list[str], user: Optional[str] = None) \
        -> TextEmbeddingResult:
    """
    Invoke large language model

    :param model: model name
    :param credentials: model credentials
    :param texts: texts to embed
    :param user: unique user id
    :return: embeddings result
    """

----------------------------------------

TITLE: Creating JSON Message in Python for Dify Tool
DESCRIPTION: Method to create a JSON message by passing a dictionary. Commonly used for data transfer between workflow nodes and can be understood by large models in agent mode.

LANGUAGE: python
CODE:
def create_json_message(self, json: dict) -> ToolInvokeMessage:
    pass

----------------------------------------

TITLE: Implementing AWS Bedrock Knowledge Retrieval Service in Python
DESCRIPTION: This code snippet defines a service class for retrieving knowledge from AWS Bedrock. It uses boto3 to interact with the Bedrock API, processes the retrieval results, and returns formatted data.

LANGUAGE: python
CODE:
import boto3


class ExternalDatasetService:
    @staticmethod
    def knowledge_retrieval(retrieval_setting: dict, query: str, knowledge_id: str):
        # get bedrock client
        client = boto3.client(
            "bedrock-agent-runtime",
            aws_secret_access_key="AWS_SECRET_ACCESS_KEY",
            aws_access_key_id="AWS_ACCESS_KEY_ID",
            # example: us-east-1
            region_name="AWS_REGION_NAME",
        )
        # fetch external knowledge retrieval
        response = client.retrieve(
            knowledgeBaseId=knowledge_id,
            retrievalConfiguration={
                "vectorSearchConfiguration": {"numberOfResults": retrieval_setting.get("top_k"), "overrideSearchType": "HYBRID"}
            },
            retrievalQuery={"text": query},
        )
        # parse response
        results = []
        if response.get("ResponseMetadata") and response.get("ResponseMetadata").get("HTTPStatusCode") == 200:
            if response.get("retrievalResults"):
                retrieval_results = response.get("retrievalResults")
                for retrieval_result in retrieval_results:
                    # filter out results with score less than threshold
                    if retrieval_result.get("score") < retrieval_setting.get("score_threshold", .0):
                        continue
                    result = {
                        "metadata": retrieval_result.get("metadata"),
                        "score": retrieval_result.get("score"),
                        "title": retrieval_result.get("metadata").get("x-amz-bedrock-kb-source-uri"),
                        "content": retrieval_result.get("content").get("text"),
                    }
                    results.append(result)
        return {
            "records": results
        }

----------------------------------------

TITLE: Configuring Tool YAML
DESCRIPTION: Example of a tool YAML file (google_search.yaml) that defines the Google Search tool's identity, parameters, and implementation details.

LANGUAGE: yaml
CODE:
identity:
  name: google_search
  author: Dify
  label:
    en_US: GoogleSearch
    zh_Hans: Google Search
    pt_BR: GoogleSearch
description:
  human:
    en_US: A tool for performing a Google SERP search and extracting snippets and webpages.Input should be a search query.
    zh_Hans: A tool for performing Google SERP search and extracting snippets and webpages. Input should be a search query.
    pt_BR: A tool for performing a Google SERP search and extracting snippets and webpages.Input should be a search query.
  llm: A tool for performing a Google SERP search and extracting snippets and webpages.Input should be a search query.
parameters:
  - name: query
    type: string
    required: true
    label:
      en_US: Query string
      zh_Hans: Query string
      pt_BR: Query string
    human_description:
      en_US: used for searching
      zh_Hans: used for searching webpage content
      pt_BR: used for searching
    llm_description: key words for searching
    form: llm
extra:
  python:
    source: tools/google_search.py

----------------------------------------

TITLE: Implementing Slack Bot Endpoint Handler
DESCRIPTION: Python implementation of the SlackEndpoint class that handles incoming Slack events and messages.

LANGUAGE: python
CODE:
import json
import traceback
from typing import Mapping
from werkzeug import Request, Response
from dify_plugin import Endpoint
from slack_sdk import WebClient
from slack_sdk.errors import SlackApiError


class SlackEndpoint(Endpoint):
    def _invoke(self, r: Request, values: Mapping, settings: Mapping) -> Response:
        """
        Invokes the endpoint with the given request.
        """
        retry_num = r.headers.get("X-Slack-Retry-Num")
        if (not settings.get("allow_retry") and (r.headers.get("X-Slack-Retry-Reason") == "http_timeout" or ((retry_num is not None and int(retry_num) > 0)))):
            return Response(status=200, response="ok")
        data = r.get_json()

        # Handle Slack URL verification challenge
        if data.get("type") == "url_verification":
            return Response(
                response=json.dumps({"challenge": data.get("challenge")}),
                status=200,
                content_type="application/json"
            )
        
        if (data.get("type") == "event_callback"):
            event = data.get("event")
            if (event.get("type") == "app_mention"):
                message = event.get("text", "")
                if message.startswith("<@"):
                    message = message.split("> ", 1)[1] if "> " in message else message
                    channel = event.get("channel", "")
                    blocks = event.get("blocks", [])
                    blocks[0]["elements"][0]["elements"] = blocks[0].get("elements")[0].get("elements")[1:]
                    token = settings.get("bot_token")
                    client = WebClient(token=token)
                    try: 
                        response = self.session.app.chat.invoke(
                            app_id=settings["app"]["app_id"],
                            query=message,
                            inputs={},
                            response_mode="blocking",
                        )
                        try:
                            blocks[0]["elements"][0]["elements"][0]["text"] = response.get("answer")
                            result = client.chat_postMessage(
                                channel=channel,
                                text=response.get("answer"),
                                blocks=blocks
                            )
                            return Response(
                                status=200,
                                response=json.dumps(result),
                                content_type="application/json"
                            )
                        except SlackApiError as e:
                            raise e
                    except Exception as e:
                        err = traceback.format_exc()
                        return Response(
                            status=200,
                            response="Sorry, I'm having trouble processing your request. Please try again later." + str(err),
                            content_type="text/plain",
                        )
                else:
                    return Response(status=200, response="ok")
            else:
                return Response(status=200, response="ok")
        else:
            return Response(status=200, response="ok")

----------------------------------------

TITLE: Implementing Google Search Tool
DESCRIPTION: Python code for the GoogleSearchTool class that implements the Google Search functionality using the SerpAPI.

LANGUAGE: python
CODE:
from collections.abc import Generator
from typing import Any

import requests

from dify_plugin import Tool
from dify_plugin.entities.tool import ToolInvokeMessage

SERP_API_URL = "https://serpapi.com/search"

class GoogleSearchTool(Tool):
    def _parse_response(self, response: dict) -> dict:
        result = {}
        if "knowledge_graph" in response:
            result["title"] = response["knowledge_graph"].get("title", "")
            result["description"] = response["knowledge_graph"].get("description", "")
        if "organic_results" in response:
            result["organic_results"] = [
                {
                    "title": item.get("title", ""),
                    "link": item.get("link", ""),
                    "snippet": item.get("snippet", ""),
                }
                for item in response["organic_results"]
            ]
        return result

    def _invoke(self, tool_parameters: dict[str, Any]) -> Generator[ToolInvokeMessage]:
        params = {
            "api_key": self.runtime.credentials["serpapi_api_key"],
            "q": tool_parameters["query"],
            "engine": "google",
            "google_domain": "google.com",
            "gl": "us",
            "hl": "en",
        }

        response = requests.get(url=SERP_API_URL, params=params, timeout=5)
        response.raise_for_status()
        valuable_res = self._parse_response(response.json())
        
        yield self.create_json_message(valuable_res)

----------------------------------------

TITLE: OpenAI Multi-Model Plugin Structure Example
DESCRIPTION: Illustrates OpenAI's complex plugin structure supporting multiple model types including LLM, moderation, speech-to-text, text embedding, and text-to-speech models.

LANGUAGE: bash
CODE:
├── models
│ ├── llm
│ │ ├── chatgpt-4o-latest
│ │ ├── gpt-3.5-turbo
│ │ ├── gpt-4-0125-preview
│ │ ├── gpt-4-turbo
│ │ ├── gpt-4o
│ │ ├── llm
│ │ ├── o1-preview
│ │ └── text-davinci-003
│ ├── moderation
│ │ ├── moderation
│ │ └── text-moderation-stable
│ ├── speech2text
│ │ ├── speech2text
│ │ └── whisper-1
│ ├── text_embedding
│ │ ├── text-embedding-3-large
│ │ └── text_embedding
│ └── tts
│ ├── tts-1-hd
│ ├── tts-1
│ └── tts

----------------------------------------

TITLE: Defining Endpoint Interface in YAML for Dify Plugin
DESCRIPTION: This YAML snippet defines an endpoint interface for a Dify plugin. It specifies the path, HTTP method, and the source file for the Python implementation.

LANGUAGE: yaml
CODE:
path: "/duck/<app_id>"
method: "GET"
extra:
  python:
    source: "endpoints/duck.py"

----------------------------------------

TITLE: Basic Image Generation Prompt for Stability API
DESCRIPTION: A simple system prompt instructing the agent to use the stability_text2image tool for drawing based on user input.

LANGUAGE: markdown
CODE:
Draw the specified content according to the user's prompt using stability_text2image.

----------------------------------------

TITLE: Implementing API Extension with Python FastAPI
DESCRIPTION: Demonstrates how to implement the API extension using Python's FastAPI framework, including request handling, authentication, and response generation for weather information retrieval.

LANGUAGE: Python
CODE:
from fastapi import FastAPI, Body, HTTPException, Header
from pydantic import BaseModel

app = FastAPI()


class InputData(BaseModel):
    point: str
    params: dict


@app.post("/api/dify/receive")
async def dify_receive(data: InputData = Body(...), authorization: str = Header(None)):
    """
    Receive API query data from Dify.
    """
    expected_api_key = "123456"  # TODO Your API key of this API
    auth_scheme, _, api_key = authorization.partition(' ')

    if auth_scheme.lower() != "bearer" or api_key != expected_api_key:
        raise HTTPException(status_code=401, detail="Unauthorized")

    point = data.point

    # for debug
    print(f"point: {point}")

    if point == "ping":
        return {
            "result": "pong"
        }
    if point == "app.external_data_tool.query":
        return handle_app_external_data_tool_query(params=data.params)
    # elif point == "{point name}":
        # TODO other point implementation here

    raise HTTPException(status_code=400, detail="Not implemented")


def handle_app_external_data_tool_query(params: dict):
    app_id = params.get("app_id")
    tool_variable = params.get("tool_variable")
    inputs = params.get("inputs")
    query = params.get("query")

    # for debug
    print(f"app_id: {app_id}")
    print(f"tool_variable: {tool_variable}")
    print(f"inputs: {inputs}")
    print(f"query: {query}")

    # TODO your external data tool query implementation here, 
    #  return must be a dict with key "result", and the value is the query result
    if inputs.get("location") == "London":
        return {
            "result": "City: London\nTemperature: 10°C\nRealFeel®: 8°C\nAir Quality: Poor\nWind Direction: ENE\nWind "
                      "Speed: 8 km/h\nWind Gusts: 14 km/h\nPrecipitation: Light rain"
        }
    else:
        return {"result": "Unknown city"}

----------------------------------------

TITLE: Creating BLOB Messages in Python for Dify Tool Integration
DESCRIPTION: This code demonstrates how to create a BLOB message in a Dify tool. It takes raw file data as bytes, optional metadata, and a save_as parameter, returning a ToolInvokeMessage object.

LANGUAGE: python
CODE:
def create_blob_message(self, blob: bytes, meta: dict = None, save_as: str = '') -> ToolInvokeMessage:
    """
        create a blob message

        :param blob: the blob
        :return: the blob message
    """

----------------------------------------

TITLE: Weather Search Implementation Class
DESCRIPTION: Python implementation class for the Weather Search tool, including config validation and query functionality.

LANGUAGE: python
CODE:
from typing import Optional

from core.external_data_tool.base import ExternalDataTool


class WeatherSearch(ExternalDataTool):
    """
    The name of custom type must be unique, keep the same with directory and file name.
    """
    name: str = "weather_search"

    @classmethod
    def validate_config(cls, tenant_id: str, config: dict) -> None:
        """
        schema.json validation. It will be called when user save the config.

        Example:
            .. code-block:: python
                config = {
                    "temperature_unit": "centigrade"
                }

        :param tenant_id: the id of workspace
        :param config: the variables of form config
        :return:
        """

        if not config.get('temperature_unit'):
            raise ValueError('temperature unit is required')

    def query(self, inputs: dict, query: Optional[str] = None) -> str:
        """
        Query the external data tool.

        :param inputs: user inputs
        :param query: the query of chat app
        :return: the tool query result
        """
        city = inputs.get('city')
        temperature_unit = self.config.get('temperature_unit')

        if temperature_unit == 'fahrenheit':
            return f'Weather in {city} is 32°F'
        else:
            return f'Weather in {city} is 0°C'

----------------------------------------

TITLE: Deploying OpenLLM Model with Docker
DESCRIPTION: Docker command to start an OpenLLM server instance with the facebook/opt-1.3b model using PyTorch backend. Exposes the service on port 3333.

LANGUAGE: bash
CODE:
docker run --rm -it -p 3333:3000 ghcr.io/bentoml/openllm start facebook/opt-1.3b --backend pt

----------------------------------------

TITLE: Chat Model Conversational App Template
DESCRIPTION: Template for building conversational applications using chat models. Includes system, user and assistant prompts with context handling and language adaptation.

LANGUAGE: markdown
CODE:
Use the following context as your learned knowledge, inside <context></context> XML tags.

<context>
{{#context#}}
</context>

When answer to user:
- If you don't know, just say that you don't know.
- If you don't know when you are not sure, ask for clarification.
Avoid mentioning that you obtained the information from the context.
And answer according to the language of the user's question.
{{pre_prompt}}

----------------------------------------

TITLE: Implementing Text Summarization in Python for Dify Tools
DESCRIPTION: This snippet shows a shortcut tool for text summarization in Dify. It takes a user ID and content to summarize, returning the summarized text using the default model of the current workspace.

LANGUAGE: python
CODE:
def summary(self, user_id: str, content: str) -> str:
    """
        summary the content

        :param user_id: the user id
        :param content: the content
        :return: the summary
    """

----------------------------------------

TITLE: Defining Model Class with SQLAlchemy in Python
DESCRIPTION: This snippet defines the Model class using SQLAlchemy ORM. It includes various attributes of an AI model, such as tenant_id, provider, model_name, and more. The class also defines relationships with other entities and includes methods for model retrieval and operations.

LANGUAGE: Python
CODE:
class Model(Base):
    __tablename__ = 'models'
    __table_args__ = (
        db.UniqueConstraint('tenant_id', 'provider', 'model_name', name='unique_model'),
    )

    id = db.Column(db.Integer, primary_key=True)
    tenant_id = db.Column(db.String(255), nullable=False)
    provider = db.Column(db.String(255), nullable=False)
    model_name = db.Column(db.String(255), nullable=False)
    model_type = db.Column(db.String(255), nullable=False)
    model_format = db.Column(db.String(255))
    base_model_name = db.Column(db.String(255))
    model_size = db.Column(db.BigInteger)
    created_at = db.Column(db.DateTime, default=datetime.utcnow)
    updated_at = db.Column(db.DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)

    @classmethod
    def add(cls, tenant_id: str, provider: str, model_name: str, model_type: str,
            base_model_name: Optional[str] = None, model_format: Optional[str] = None,
            model_size: Optional[int] = None):
        model = cls()
        model.tenant_id = tenant_id
        model.provider = provider
        model.model_name = model_name
        model.model_type = model_type
        model.base_model_name = base_model_name
        model.model_format = model_format
        model.model_size = model_size

        db.session.add(model)
        db.session.commit()
        return model

    @classmethod
    def update(cls, tenant_id: str, provider: str, model_name: str,
               base_model_name: Optional[str] = None, model_format: Optional[str] = None,
               model_size: Optional[int] = None):
        model = cls.query.filter(
            cls.tenant_id == tenant_id,
            cls.provider == provider,
            cls.model_name == model_name
        ).first()

        if model:
            model.base_model_name = base_model_name
            model.model_format = model_format
            model.model_size = model_size
            model.updated_at = datetime.utcnow()
            db.session.commit()
            return model

        return None

    @classmethod
    def get_by_tenant_and_model(cls, tenant_id: str, provider: str, model_name: str):
        return cls.query.filter(
            cls.tenant_id == tenant_id,
            cls.provider == provider,
            cls.model_name == model_name
        ).first()

    @classmethod
    def get_by_id(cls, id: int):
        return cls.query.filter(
            cls.id == id
        ).first()

    @classmethod
    def delete_by_id(cls, id: int):
        model = cls.query.filter(
            cls.id == id
        ).first()
        if model:
            db.session.delete(model)
            db.session.commit()
            return True
        return False

    @classmethod
    def list(cls, tenant_id: str, provider: Optional[str] = None,
             model_name: Optional[str] = None, model_type: Optional[str] = None):
        query = cls.query.filter(cls.tenant_id == tenant_id)

        if provider:
            query = query.filter(cls.provider == provider)
        if model_name:
            query = query.filter(cls.model_name == model_name)
        if model_type:
            query = query.filter(cls.model_type == model_type)

        return query.order_by(cls.created_at.desc()).all()

----------------------------------------

TITLE: Frontend Schema Configuration for Weather Search Tool
DESCRIPTION: JSON schema defining the frontend component specifications for the Weather Search tool, including temperature unit selection.

LANGUAGE: json
CODE:
{
    "label": {
        "en-US": "Weather Search",
        "zh-Hans": "天气查询"
    },
    "form_schema": [
        {
            "type": "select",
            "label": {
                "en-US": "Temperature Unit",
                "zh-Hans": "温度单位"
            },
            "variable": "temperature_unit",
            "required": true,
            "options": [
                {
                    "label": {
                        "en-US": "Fahrenheit",
                        "zh-Hans": "华氏度"
                    },
                    "value": "fahrenheit"
                },
                {
                    "label": {
                        "en-US": "Centigrade",
                        "zh-Hans": "摄氏度"
                    },
                    "value": "centigrade"
                }
            ],
            "default": "centigrade",
            "placeholder": "Please select temperature unit"
        }
    ]
}

----------------------------------------

TITLE: Implementing DallE3 Image Generation Tool in Python for Dify
DESCRIPTION: This snippet shows the implementation of a DallE3 image generation tool for Dify. It uses the OpenAI API to generate images based on a prompt and saves the result to a variable pool.

LANGUAGE: python
CODE:
from typing import Any, Dict, List, Union
from core.tools.entities.tool_entities import ToolInvokeMessage
from core.tools.tool.builtin_tool import BuiltinTool

from base64 import b64decode

from openai import OpenAI

class DallE3Tool(BuiltinTool):
    def _invoke(self, 
                user_id: str, 
               tool_Parameters: Dict[str, Any], 
        ) -> Union[ToolInvokeMessage, List[ToolInvokeMessage]]:
        """
            invoke tools
        """
        client = OpenAI(
            api_key=self.runtime.credentials['openai_api_key'],
        )

        # prompt
        prompt = tool_Parameters.get('prompt', '')
        if not prompt:
            return self.create_text_message('Please input prompt')

        # call openapi dalle3
        response = client.images.generate(
            prompt=prompt, model='dall-e-3',
            size='1024x1024', n=1, style='vivid', quality='standard',
            response_format='b64_json'
        )

        result = []
        for image in response.data:
            # Save all images to the variable pool through the save_as parameter. The variable name is self.VARIABLE_KEY.IMAGE.value. If new images are generated later, they will overwrite the previous images.
            result.append(self.create_blob_message(blob=b64decode(image.b64_json), 
                                                   meta={ 'mime_type': 'image/png' },
                                                    save_as=self.VARIABLE_KEY.IMAGE.value))

        return result

----------------------------------------

TITLE: Implementing app.moderation.input API Response in JSON
DESCRIPTION: This snippet outlines the structure of the API response for the app.moderation.input extension point. It includes flags for moderation violations, action to take, and either a preset response or overridden input values.

LANGUAGE: json
CODE:
{
    "flagged": bool,
    "action": string,
    "preset_response": string,
    "inputs": {
        "var_1": "value_1",
        "var_2": "value_2",
        ...
    },
    "query": string | null
}

----------------------------------------

TITLE: Stream and Sync Response Handling
DESCRIPTION: Implementation example showing how to handle both streaming and synchronous responses in the LLM implementation.

LANGUAGE: python
CODE:
def _invoke(self, stream: bool, **kwargs) -> Union[LLMResult, Generator]:
   """Call the corresponding processing function based on return type."""
   if stream:
       return self._handle_stream_response(**kwargs)
   return self._handle_sync_response(**kwargs) 

def _handle_stream_response(self, **kwargs) -> Generator:
   """Handle streaming response logic."""
   for chunk in response: # Assume response is a streaming data iterator
       yield chunk

def _handle_sync_response(self, **kwargs) -> LLMResult:
   """Handle synchronous response logic.""" 
   return LLMResult(**response) # Assume response is a complete response dictionary

----------------------------------------

TITLE: Implementing Cloud Service Moderation Class in Python
DESCRIPTION: This Python class implements the CloudServiceModeration, extending the base Moderation class. It includes methods for config validation, input moderation, and output moderation, with placeholders for custom logic implementation.

LANGUAGE: python
CODE:
from core.moderation.base import Moderation, ModerationAction, ModerationInputsResult, ModerationOutputsResult

class CloudServiceModeration(Moderation):
    """
    The name of custom type must be unique, keep the same with directory and file name.
    """
    name: str = "cloud_service"

    @classmethod
    def validate_config(cls, tenant_id: str, config: dict) -> None:
        """
        schema.json validation. It will be called when user saves the config.

        Example:
            .. code-block:: python
                config = {
                    "cloud_provider": "GoogleCloud",
                    "api_endpoint": "https://api.example.com",
                    "api_keys": "123456",
                    "inputs_config": {
                        "enabled": True,
                        "preset_response": "Your content violates our usage policy. Please revise and try again."
                    },
                    "outputs_config": {
                        "enabled": True,
                        "preset_response": "Your content violates our usage policy. Please revise and try again."
                    }
                }

        :param tenant_id: the id of workspace
        :param config: the variables of form config
        :return:
        """

        cls._validate_inputs_and_outputs_config(config, True)

        if not config.get("cloud_provider"):
            raise ValueError("cloud_provider is required")

        if not config.get("api_endpoint"):
            raise ValueError("api_endpoint is required")

        if not config.get("api_keys"):
            raise ValueError("api_keys is required")

    def moderation_for_inputs(self, inputs: dict, query: str = "") -> ModerationInputsResult:
        """
        Moderation for inputs.

        :param inputs: user inputs
        :param query: the query of chat app, there is empty if is completion app
        :return: the moderation result
        """
        flagged = False
        preset_response = ""

        if self.config['inputs_config']['enabled']:
            preset_response = self.config['inputs_config']['preset_response']

            if query:
                inputs['query__'] = query
            flagged = self._is_violated(inputs)

        # return ModerationInputsResult(flagged=flagged, action=ModerationAction.overridden, inputs=inputs, query=query)
        return ModerationInputsResult(flagged=flagged, action=ModerationAction.DIRECT_OUTPUT, preset_response=preset_response)

    def moderation_for_outputs(self, text: str) -> ModerationOutputsResult:
        """
        Moderation for outputs.

        :param text: the text of LLM response
        :return: the moderation result
        """
        flagged = False
        preset_response = ""

        if self.config['outputs_config']['enabled']:
            preset_response = self.config['outputs_config']['preset_response']

            flagged = self._is_violated({'text': text})

        # return ModerationOutputsResult(flagged=flagged, action=ModerationAction.overridden, text=text)
        return ModerationOutputsResult(flagged=flagged, action=ModerationAction.DIRECT_OUTPUT, preset_response=preset_response)

    def _is_violated(self, inputs: dict):
        """
        The main logic of moderation.

        :param inputs:
        :return: the moderation result
        """
        return False

----------------------------------------

TITLE: Implementing Custom Model Provider for Xinference
DESCRIPTION: Minimal Python implementation for a custom model provider using Xinference as an example.

LANGUAGE: python
CODE:
class XinferenceProvider(Provider):
    def validate_provider_credentials(self, credentials: dict) -> None:
        pass

----------------------------------------

TITLE: Chat Endpoint Implementation Example in Python
DESCRIPTION: Example implementation of a chat endpoint that handles streaming responses from a Dify app.

LANGUAGE: python
CODE:
import json
from typing import Mapping
from werkzeug import Request, Response
from dify_plugin import Endpoint

class Duck(Endpoint):
    def _invoke(self, r: Request, values: Mapping, settings: Mapping) -> Response:
        """
        Invokes the endpoint with the given request.
        """
        app_id = values["app_id"]
        def generator():
            response = self.session.app.workflow.invoke(
                app_id=app_id, inputs={}, response_mode="streaming", files=[]
            )
            for data in response:
                yield f"{json.dumps(data)} <br>"
        return Response(generator(), status=200, content_type="text/html")

----------------------------------------

TITLE: Setting Ollama Host Environment Variable on macOS
DESCRIPTION: Command to set the OLLAMA_HOST environment variable using launchctl on macOS.

LANGUAGE: bash
CODE:
launchctl setenv OLLAMA_HOST "0.0.0.0"

----------------------------------------

TITLE: Backend Directory Structure
DESCRIPTION: Overview of Dify's backend architecture showing the main directories and their purposes. The backend is built with Flask, SQLAlchemy, and Celery.

LANGUAGE: plaintext
CODE:
[api/]
├── constants             // Constant settings used throughout code base.
├── controllers           // API route definitions and request handling logic.           
├── core                  // Core application orchestration, model integrations, and tools.
├── docker                // Docker & containerization related configurations.
├── events                // Event handling and processing
├── extensions            // Extensions with 3rd party frameworks/platforms.
├── fields                // field definitions for serialization/marshalling.
├── libs                  // Reusable libraries and helpers.
├── migrations            // Scripts for database migration.
├── models                // Database models & schema definitions.
├── services              // Specifies business logic.
├── storage               // Private key storage.      
├── tasks                 // Handling of async tasks and background jobs.
└── tests

----------------------------------------

TITLE: Escaping String to Object in Python for Memory Storage
DESCRIPTION: This Python function takes a JSON string as input, parses it to extract memory-related data, and returns a structured object containing facts, preferences, and memories. It's used in the workflow to process and store conversation context.

LANGUAGE: python
CODE:
import json

def main(arg1: str) -> object:
    try:
        # Parse the input JSON string
        input_data = json.loads(arg1)
        
        # Extract the memory object
        memory = input_data.get("memory", {})
        
        # Construct the return object
        result = {
            "facts": memory.get("facts", []),
            "preferences": memory.get("preferences", []),
            "memories": memory.get("memories", [])
        }
        
        return {
            "mem": result
        }
    except json.JSONDecodeError:
        return {
            "result": "Error: Invalid JSON string"
        }
    except Exception as e:
        return {
            "result": f"Error: {str(e)}"
        }

----------------------------------------

TITLE: Implementation Class Template
DESCRIPTION: Base template for creating custom external data tool implementation classes in Dify.

LANGUAGE: python
CODE:
from typing import Optional

from core.external_data_tool.base import ExternalDataTool


class WeatherSearch(ExternalDataTool):
    """
    The name of custom type must be unique, keep the same with directory and file name.
    """
    name: str = "weather_search"

    @classmethod
    def validate_config(cls, tenant_id: str, config: dict) -> None:
        """
        schema.json validation. It will be called when user save the config.

        :param tenant_id: the id of workspace
        :param config: the variables of form config
        :return:
        """

        # implement your own logic here

    def query(self, inputs: dict, query: Optional[str] = None) -> str:
        """
        Query the external data tool.

        :param inputs: user inputs
        :param query: the query of chat app
        :return: the tool query result
        """
       
        # implement your own logic here
        return "your own data."

----------------------------------------

TITLE: Installing Plugins for Dify Migration
DESCRIPTION: Command to download and install plugins for the latest Community Edition of Dify.

LANGUAGE: bash
CODE:
poetry run flask install-plugins --workers=2

----------------------------------------

TITLE: Frontend Directory Structure
DESCRIPTION: Overview of Dify's frontend architecture showing the main directories and their purposes. The frontend is built with Next.js, TypeScript, and Tailwind CSS.

LANGUAGE: plaintext
CODE:
[web/]
├── app                   // layouts, pages, and components
│   ├── (commonLayout)    // common layout used throughout the app
│   ├── (shareLayout)     // layouts specifically shared across token-specific sessions 
│   ├── activate          // activate page
│   ├── components        // shared by pages and layouts
│   ├── install           // install page
│   ├── signin            // signin page
│   └── styles            // globally shared styles
├── assets                // Static assets
├── bin                   // scripts ran at build step
├── config                // adjustable settings and options 
├── context               // shared contexts used by different portions of the app
├── dictionaries          // Language-specific translate files 
├── docker                // container configurations
├── hooks                 // Reusable hooks
├── i18n                  // Internationalization configuration
├── models                // describes data models & shapes of API responses
├── public                // meta assets like favicon
├── service               // specifies shapes of API actions
├── test                  
├── types                 // descriptions of function params and return values
└── utils                 // Shared utility functions

----------------------------------------

TITLE: Chat Model Conversational Template
DESCRIPTION: Template structure for building conversational applications using chat models. Includes system context handling, pre-prompt integration, and query processing.

LANGUAGE: plaintext
CODE:
Use the following context as your learned knowledge, inside <context></context> XML tags.

<context>
{{#context#}}
</context>

When answering the user:
- If you don't know, just say that you don't know.
- If you are not sure, ask for clarification.
Avoid mentioning that you obtained the information from the context.
And answer according to the language of the user's question.
{{pre_prompt}}

----------------------------------------

TITLE: Model Credentials Validation Interface in Python
DESCRIPTION: Interface method for validating individual model credentials, similar to provider validation but specific to a single model.

LANGUAGE: python
CODE:
def validate_credentials(self, model: str, credentials: dict) -> None:
    """
    Validate model credentials

    :param model: model name
    :param credentials: model credentials
    :return:
    """

----------------------------------------

TITLE: Upgrading Dify Premium on AWS EC2
DESCRIPTION: Commands to upgrade Dify Premium on an AWS EC2 instance. This process involves cloning the latest Dify repository, updating Docker files, and restarting the Docker containers.

LANGUAGE: bash
CODE:
git clone https://github.com/langgenius/dify.git /tmp/dify
mv -f /tmp/dify/docker/* /dify/
rm -rf /tmp/dify
docker-compose down
docker-compose pull
docker-compose -f docker-compose.yaml -f docker-compose.override.yaml up -d

----------------------------------------

TITLE: Escaping Object to String in Python for Memory Retrieval
DESCRIPTION: This Python function takes a list containing a dictionary as input, processes it to create a memory object, converts it to a JSON string, and wraps it in XML tags. It's used in the workflow to prepare conversation context for use in prompts.

LANGUAGE: python
CODE:
import json

def main(arg1: list) -> str:
    try:
        # Assume arg1[0] is the dictionary we need to process
        context = arg1[0] if arg1 else {}
        
        # Construct the memory object
        memory = {"memory": context}
        
        # Convert the object to a JSON string
        json_str = json.dumps(memory, ensure_ascii=False, indent=2)
        
        # Wrap the JSON string in <answer> tags
        result = f"<answer>{json_str}</answer>"
        
        return {
            "result": result
        }
    except Exception as e:
        return {
            "result": f"<answer>Error: {str(e)}</answer>"
        }

----------------------------------------

TITLE: Message Trace Data Structure Documentation
DESCRIPTION: Data structure mapping showing the relationship between Chat message fields and their corresponding Opik LLM trace fields, including metadata fields.

LANGUAGE: markdown
CODE:
| Chat                            | Opik LLM                    |
| ------------------------------- | --------------------------- |
| message_id                      | id                          |
| user_session_id                 | - placed in metadata        |
| "llm"                           | name                        |
| start_time                      | start_time                  |
| end_time                        | end_time                    |
| inputs                          | inputs                      |
| outputs                         | outputs                     |
| Model token consumption         | usage_metadata              |
| metadata                        | metadata                    |
| \["message", conversation_mode] | tags                        |
| conversation_id                 | conversation_id in metadata |

----------------------------------------

TITLE: Defining ParameterRule and PriceConfig Structures in Markdown
DESCRIPTION: Details the structures for ParameterRule and PriceConfig, which are used to define model parameters and pricing information.

LANGUAGE: markdown
CODE:
### **ParameterRule**

* `name` (string): Actual parameter name for model calls
* `use_template` (string) \[optional]: Template usage Five preset variable content configuration templates:
  * temperature
  * top\_p
  * frequency\_penalty
  * presence\_penalty
  * max\_tokens Can directly set template variable name in use\_template, will use default config from entities.defaults.PARAMETER\_RULE\_TEMPLATE
* `label` (object) \[optional]: Labels, i18n
  * `zh_Hans` (string) \[optional]: Chinese label
  * `en_US` (string): English label
* `type` (string) \[optional]: Parameter type
  * `int`: Integer
  * `float`: Float
  * `string`: String
  * `boolean`: Boolean
* `help` (string) \[optional]: Help information
  * `zh_Hans` (string) \[optional]: Chinese help info
  * `en_US` (string): English help info
* `required` (bool): Whether required, default False
* `default` (int/float/string/bool) \[optional]: Default value
* `min` (int/float) \[optional]: Minimum value, only for numeric types
* `max` (int/float) \[optional]: Maximum value, only for numeric types
* `precision` (int) \[optional]: Precision, decimal places, only for numeric types
* `options` (array\[string]) \[optional]: Dropdown options, only for string type

### **PriceConfig**

* `input` (float): Input price, i.e., Prompt price
* `output` (float): Output price, i.e., Return content price
* `unit` (float): Price unit, e.g., if priced per 1M tokens, unit token number is 0.000001
* `currency` (string): Currency unit

----------------------------------------

TITLE: Implementing ParameterExtractor Tool in Python
DESCRIPTION: Provides a complete example of implementing a ParameterExtractor tool. This tool extracts a person's name from a given conversation using the ParameterExtractor node.

LANGUAGE: python
CODE:
from collections.abc import Generator
from dify_plugin.entities.tool import ToolInvokeMessage
from dify_plugin import Tool
from dify_plugin.entities.workflow_node import ModelConfig, ParameterConfig

class ParameterExtractorTool(Tool):
    def _invoke(
        self, tool_parameters: dict
    ) -> Generator[ToolInvokeMessage, None, None]:
        response = self.session.workflow_node.parameter_extractor.invoke(
            parameters=[
                ParameterConfig(
                    name="name",
                    description="name of the person",
                    required=True,
                    type="string",
                )
            ],
            model=ModelConfig(
                provider="langgenius/openai/openai",
                name="gpt-4o-mini",
                completion_params={},
            ),
            query="My name is John Doe",
            instruction="Extract the name of the person",
        )
        yield self.create_text_message(response.outputs["name"])

----------------------------------------

TITLE: Plugin Directory Structure
DESCRIPTION: Basic file structure of a Dify plugin project showing key files and directories

LANGUAGE: text
CODE:
.
├── GUIDE.md
├── README.md
├── _assets
│   └── icon.svg
├── endpoints
│   ├── your-project.py
│   └── your-project.yaml
├── group
│   └── your-project.yaml
├── main.py
├── manifest.yaml
└── requirements.txt

----------------------------------------

TITLE: Implementing ParameterExtractor Tool in Python
DESCRIPTION: Provides a complete example of implementing a ParameterExtractor tool. This tool extracts a person's name from a given conversation using the ParameterExtractor node.

LANGUAGE: python
CODE:
from collections.abc import Generator
from dify_plugin.entities.tool import ToolInvokeMessage
from dify_plugin import Tool
from dify_plugin.entities.workflow_node import ModelConfig, ParameterConfig

class ParameterExtractorTool(Tool):
    def _invoke(
        self, tool_parameters: dict
    ) -> Generator[ToolInvokeMessage, None, None]:
        response = self.session.workflow_node.parameter_extractor.invoke(
            parameters=[
                ParameterConfig(
                    name="name",
                    description="name of the person",
                    required=True,
                    type="string",
                )
            ],
            model=ModelConfig(
                provider="langgenius/openai/openai",
                name="gpt-4o-mini",
                completion_params={},
            ),
            query="My name is John Doe",
            instruction="Extract the name of the person",
        )
        yield self.create_text_message(response.outputs["name"])

----------------------------------------

TITLE: Defining ModelConfig Structure for Model Specifications in Dify Plugins
DESCRIPTION: ModelConfig defines the structure for specifying model configurations in plugins, including the provider, model name, and model type.

LANGUAGE: yaml
CODE:
ModelConfig:
  provider: "string"  # Format: langgenius/openai/openai
  model: "string"
  model_type: enum  # Refer to separate documentation

----------------------------------------

TITLE: Backing up Docker Compose configuration in Bash
DESCRIPTION: Creates a timestamped backup of the docker-compose.yaml file in the Docker directory.

LANGUAGE: bash
CODE:
cd docker
cp docker-compose.yaml docker-compose.yaml.$(date +%s).bak

----------------------------------------

TITLE: Defining NodeResponse Structure for Node Execution Results in Dify
DESCRIPTION: NodeResponse defines the structure for capturing the results of node execution in plugins, including inputs, outputs, and process data generated during execution.

LANGUAGE: yaml
CODE:
NodeResponse:
  inputs: dict
  outputs: dict
  process_data: dict

----------------------------------------

TITLE: Provider Credential Validation Interface in Python
DESCRIPTION: Interface method for validating provider credentials. Implementers can choose any validation method or implement custom validation.

LANGUAGE: python
CODE:
def validate_provider_credentials(self, credentials: dict) -> None:
    """
    Validate provider credentials
    You can choose any validate_credentials method of model type or implement validate method by yourself,
    such as: get model list api

    if validate failed, raise exception

    :param credentials: provider credentials, credentials form defined in `provider_credential_schema`.
    """

----------------------------------------

TITLE: Configuring Environment Variables for Remote Debugging in Dify
DESCRIPTION: This snippet shows the contents of the .env file used to configure remote debugging for a Dify plugin. It includes the installation method, remote server address, port, and debug key.

LANGUAGE: bash
CODE:
INSTALL_METHOD=remote
REMOTE_INSTALL_HOST=remote-url
REMOTE_INSTALL_PORT=5003
REMOTE_INSTALL_KEY=****-****-****-****-****

----------------------------------------

TITLE: Launching Stable Diffusion WebUI on Linux
DESCRIPTION: Command to launch Stable Diffusion WebUI with API and listen flags enabled on Linux.

LANGUAGE: bash
CODE:
cd stable-diffusion-webui\n./webui.sh --api --listen

----------------------------------------

TITLE: Structuring Retrieved Chunks using Jinja2 Template in Dify
DESCRIPTION: This code snippet demonstrates a Jinja2 template that formats retrieved chunks and their metadata from a knowledge retrieval node into structured markdown. It iterates over chunks, displaying their index, similarity score, title, and content.

LANGUAGE: Plain
CODE:
{% raw %}
{% for item in chunks %}
### Chunk {{ loop.index }}. 
### Similarity: {{ item.metadata.score | default('N/A') }}

#### {{ item.title }}

##### Content
{{ item.content | replace('\n', '\n\n') }}

---
{% endfor %}
{% endraw %}

----------------------------------------

TITLE: OpenAI Multi-Model Directory Structure
DESCRIPTION: Example directory structure for OpenAI implementation supporting multiple model types including LLM, embedding, moderation, speech-to-text, and text-to-speech.

LANGUAGE: bash
CODE:
├── models
│   ├── common_openai.py
│   ├── llm
│   │   ├── _position.yaml
│   │   ├── chatgpt-4o-latest.yaml
│   │   ├── gpt-3.5-turbo.yaml
│   │   ├── gpt-4-0125-preview.yaml
│   │   ├── gpt-4-turbo.yaml
│   │   ├── gpt-4o.yaml
│   │   ├── llm.py
│   │   ├── o1-preview.yaml
│   │   └── text-davinci-003.yaml
│   ├── moderation
│   │   ├── moderation.py
│   │   └── text-moderation-stable.yaml
│   ├── speech2text
│   │   ├── speech2text.py
│   │   └── whisper-1.yaml
│   ├── text_embedding
│   │   ├── text-embedding-3-large.yaml
│   │   └── text_embedding.py
│   └── tts
│       ├── tts-1-hd.yaml
│       ├── tts-1.yaml
│       └── tts.py

----------------------------------------

TITLE: iPhone Customer Service Pre-prompt Template
DESCRIPTION: Example pre-prompt configuration for an iPhone consultation service chatbot, including response guidelines and formatting requirements

LANGUAGE: markdown
CODE:
When answering the user:
- If you don't know, just say that you don't know.
- If you don't know or are not sure, ask for clarification.
Avoid mentioning that you obtained the information from the context.
And answer according to the language of the user's question.

You are a customer service assistant for Apple Inc., and you can provide consultation services for iPhones.
When you answer, you need to list detailed iPhone parameters, and you must output this information as a vertical MARKDOWN table. If the list is too long, transpose it.
You are allowed to think for a long time to generate a more reasonable output.
Note: You currently only have information on some iPhone models, not all of them.

----------------------------------------

TITLE: Cloning LocalAI Repository
DESCRIPTION: Commands to clone the LocalAI repository and navigate to the example directory for setup.

LANGUAGE: bash
CODE:
$ git clone https://github.com/go-skynet/LocalAI
$ cd LocalAI/examples/langchain-chroma

----------------------------------------

TITLE: Implementing app.moderation.output API Response in JSON
DESCRIPTION: This snippet outlines the structure of the API response for the app.moderation.output extension point. It includes flags for moderation violations, action to take, and either a preset response or overridden output text.

LANGUAGE: json
CODE:
{
    "flagged": bool,
    "action": string,
    "preset_response": string,
    "text": string
}

----------------------------------------

TITLE: Initializing Dify Plugin Project
DESCRIPTION: Commands to create a new Dify plugin project using the CLI tool. It shows how to run the tool with different binary names.

LANGUAGE: bash
CODE:
./dify-plugin-darwin-arm64 plugin init

LANGUAGE: bash
CODE:
dify plugin init

----------------------------------------

TITLE: Implementing Image Message Creation in Python for Dify Tools
DESCRIPTION: This snippet demonstrates how to create an image message in a Dify tool. It takes an image URL and an optional save_as parameter, returning a ToolInvokeMessage object.

LANGUAGE: python
CODE:
def create_image_message(self, image: str, save_as: str = '') -> ToolInvokeMessage:
    """
        create an image message

        :param image: the url of the image
        :return: the image message
    """

----------------------------------------

TITLE: Implementing Provider Credentials Validation in Python
DESCRIPTION: This snippet shows how to implement the validate_provider_credentials method for validating provider credentials. It's part of the ModelProvider base class.

LANGUAGE: python
CODE:
def validate_provider_credentials(self, credentials: dict) -> None:
    """
    Validate provider credentials
    You can choose any validate_credentials method of model type or implement validate method by yourself,
    such as: get model list api

    if validate failed, raise exception

    :param credentials: provider credentials, credentials form defined in `provider_credential_schema`.
    """

----------------------------------------

TITLE: Examples of app.moderation.input API Responses in JSON
DESCRIPTION: These snippets demonstrate two possible API responses for app.moderation.input: one for direct output and another for overridden input. They show how the response structure differs based on the action taken.

LANGUAGE: json
CODE:
{
    "flagged": true,
    "action": "direct_output",
    "preset_response": "Your content violates our usage policy."
}

LANGUAGE: json
CODE:
{
    "flagged": true,
    "action": "overridden",
    "inputs": {
        "var_1": "I will *** you.",
        "var_2": "I will *** you."
    },
    "query": "Happy everydays."
}

----------------------------------------

TITLE: Implementing LLM Invocation Logic
DESCRIPTION: Python code for invoking the LLM model, handling responses, and managing tool calls within the Agent Strategy Plugin

LANGUAGE: python
CODE:
def invoke(self, model_config: LLMModelConfig, prompt_messages: list[PromptMessage], tools: list[PromptMessageTool] | None = None, stop: list[str] | None = None, stream: bool = True) -> Generator[LLMResultChunk, None, None] | LLMResult:...

----------------------------------------

TITLE: Creating Link Messages in Python for Dify Tool Integration
DESCRIPTION: This code snippet shows how to create a link message in a Dify tool. It takes a link URL and an optional save_as parameter, returning a ToolInvokeMessage object.

LANGUAGE: python
CODE:
def create_link_message(self, link: str, save_as: str = '') -> ToolInvokeMessage:
    """
        create a link message

        :param link: the url of the link
        :return: the link message
    """

----------------------------------------

TITLE: Defining ToolSelector Structure for Tool Configuration in Dify Plugins
DESCRIPTION: ToolSelector defines the structure for specifying and configuring tools in plugins, including provider ID, tool name, description, configuration, and parameters requiring LLM inference.

LANGUAGE: yaml
CODE:
ToolSelector:
  provider_id: "string"
  tool_name: "string"
  tool_description: "string"
  tool_configuration: dict[str, Any]
  tool_parameters:
    name: "string"
    type: "string"
    required: bool
    description: "string"
    default: any
    options: list[string]

----------------------------------------

TITLE: Examples of app.moderation.output API Responses in JSON
DESCRIPTION: These snippets demonstrate two possible API responses for app.moderation.output: one for direct output and another for overridden text. They illustrate how the response structure changes based on the action taken.

LANGUAGE: json
CODE:
{
    "flagged": true,
    "action": "direct_output",
    "preset_response": "Your content violates our usage policy."
}

LANGUAGE: json
CODE:
{
    "flagged": true,
    "action": "overridden",
    "text": "I will *** you."
}

----------------------------------------

TITLE: Parameter Handling Implementation
DESCRIPTION: Python code for handling and validating strategy parameters using Pydantic models.

LANGUAGE: python
CODE:
from dify_plugin.interfaces.agent import AgentModelConfig, AgentStrategy, ToolEntity

class FunctionCallingParams(BaseModel):
    query: str
    model: AgentModelConfig
    tools: list[ToolEntity] | None
    maximum_iterations: int = 3
    
class FunctionCallingAgentStrategy(AgentStrategy):
    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:
        """Run FunctionCall agent application"""
        fc_params = FunctionCallingParams(**parameters)

----------------------------------------

TITLE: Creating Document from Text via API
DESCRIPTION: API endpoint for creating a new document in an existing knowledge base using text input. Requires dataset ID and API key for authentication.

LANGUAGE: json
CODE:
curl --location --request POST 'https://api.dify.ai/v1/datasets/{dataset_id}/document/create_by_text' \
--header 'Authorization: Bearer {api_key}' \
--header 'Content-Type: application/json' \
--data-raw '{"name": "text","text": "text","indexing_technique": "high_quality","process_rule": {"mode": "automatic"}}'

----------------------------------------

TITLE: Example Request Body for app.moderation.input in JSON
DESCRIPTION: This example demonstrates a sample request body for the app.moderation.input extension point, including an app_id, two input variables with potentially offensive content, and a query string.

LANGUAGE: json
CODE:
{
    "point": "app.moderation.input",
    "params": {
        "app_id": "61248ab4-1125-45be-ae32-0ce91334d021",
        "inputs": {
            "var_1": "I will kill you.",
            "var_2": "I will fuck you."
        },
        "query": "Happy everydays."
    }
}

----------------------------------------

TITLE: Example API Response for app.moderation.input with direct_output Action in JSON
DESCRIPTION: This example shows an API response for the app.moderation.input extension point where the content is flagged and a direct output action is taken, providing a preset response message.

LANGUAGE: json
CODE:
{
    "flagged": true,
    "action": "direct_output",
    "preset_response": "Your content violates our usage policy."
}

----------------------------------------

TITLE: Authentication Header Example
DESCRIPTION: Example of the authorization header format required for API authentication

LANGUAGE: text
CODE:
Authorization: Bearer {API_KEY}

----------------------------------------

TITLE: Defining Request Body Structure for app.moderation.input in JSON
DESCRIPTION: This snippet outlines the structure of the request body for the app.moderation.input extension point. It includes the point identifier, app_id, inputs (as key-value pairs), and an optional query string.

LANGUAGE: json
CODE:
{
    "point": "app.moderation.input", 
        "app_id": string,  
        "inputs": {  
            "var_1": "value_1",
            "var_2": "value_2",
            ...
        },
        "query": string | null  
    }
}

----------------------------------------

TITLE: Example API Response for app.moderation.input with overridden Action in JSON
DESCRIPTION: This example demonstrates an API response for the app.moderation.input extension point where the content is flagged and an overridden action is taken, modifying the input content to censor offensive words.

LANGUAGE: json
CODE:
{
    "flagged": true,
    "action": "overridden",
    "inputs": {
        "var_1": "I will *** you.",
        "var_2": "I will *** you."
    },
    "query": "Happy everydays."
}

----------------------------------------

TITLE: Creating Link Message in Python for Dify Tool
DESCRIPTION: Method to create a link message by passing a URL string.

LANGUAGE: python
CODE:
def create_link_message(self, link: str) -> ToolInvokeMessage:
    pass

----------------------------------------

TITLE: Extracting Plugins in Dify API Container Using Poetry in Bash
DESCRIPTION: This command runs a Flask command to extract plugins from the current Dify environment, with the option to specify the number of worker processes.

LANGUAGE: bash
CODE:
poetry run flask extract-plugins --workers=20

----------------------------------------

TITLE: Model Information Response Format
DESCRIPTION: Example JSON response showing the model information structure from the Stable Diffusion API endpoint.

LANGUAGE: json
CODE:
[\n    {\n        "title": "pastel-mix/pastelmix-better-vae-fp32.ckpt [943a810f75]",\n        "model_name": "pastel-mix_pastelmix-better-vae-fp32",\n        "hash": "943a810f75",\n        "sha256": "943a810f7538b32f9d81dc5adea3792c07219964c8a8734565931fcec90d762d",\n        "filename": "/home/takatost/stable-diffusion-webui/models/Stable-diffusion/pastel-mix/pastelmix-better-vae-fp32.ckpt",\n        "config": null\n    }\n]

----------------------------------------

TITLE: Example API Response for app.moderation.output with direct_output Action in JSON
DESCRIPTION: This example demonstrates an API response for the app.moderation.output extension point where the content is flagged and a direct output action is taken, providing a preset response message.

LANGUAGE: json
CODE:
{
    "flagged": true,
    "action": "direct_output",
    "preset_response": "Your content violates our usage policy."
}

----------------------------------------

TITLE: Creating Stream Variable Message in Python for Dify Tool
DESCRIPTION: Method to create a streaming variable message for typewriter-effect text output. Currently only supports string data.

LANGUAGE: python
CODE:
def create_stream_variable_message(
    self, variable_name: str, variable_value: str
) -> ToolInvokeMessage:

----------------------------------------

TITLE: Defining Prefix Prompts for Text Generation in Markdown
DESCRIPTION: This snippet demonstrates how to define prefix prompts for a text generation application, specifically for translation. It uses a variable {{language}} to specify the target language for translation.

LANGUAGE: markdown
CODE:
Translate the content to: {{language}}. The content is as follows:

----------------------------------------

TITLE: Configuring Input Parameters for Dify Chatbot
DESCRIPTION: Example of configuring input parameters for the Dify Chatbot, demonstrating how to pass values that will be processed and encoded in the URL.

LANGUAGE: javascript
CODE:
window.difyChatbotConfig = {
    // Other configuration settings...
    inputs: {
        name: 'apple',
    },
}

----------------------------------------

TITLE: Example API Response for app.moderation.output with overridden Action in JSON
DESCRIPTION: This example shows an API response for the app.moderation.output extension point where the content is flagged and an overridden action is taken, modifying the text to censor offensive words.

LANGUAGE: json
CODE:
{
    "flagged": true,
    "action": "overridden",
    "text": "I will *** you."
}

----------------------------------------

TITLE: Generating Text Messages in Python for Dify Tools
DESCRIPTION: This snippet illustrates the creation of a text message in a Dify tool. It takes a text string and an optional save_as parameter, returning a ToolInvokeMessage object.

LANGUAGE: python
CODE:
def create_text_message(self, text: str, save_as: str = '') -> ToolInvokeMessage:
    """
        create a text message

        :param text: the text of the message
        :return: the text message
    """

----------------------------------------

TITLE: Defining Agent Provider Configuration
DESCRIPTION: YAML configuration for the Agent provider including basic information, labels and supported strategies.

LANGUAGE: yaml
CODE:
identity:
  author: langgenius
  name: agent
  label:
    en_US: Agent
    zh_Hans: Agent
    pt_BR: Agent
  description:
    en_US: Agent
    zh_Hans: Agent
    pt_BR: Agent
  icon: icon.svg
strategies:
  - strategies/function_calling.yaml

----------------------------------------

TITLE: Setting Custom Button Styles with containerProps in JavaScript
DESCRIPTION: Examples of customizing the Dify Chatbot Button appearance using containerProps for inline styles and CSS classes.

LANGUAGE: javascript
CODE:
window.difyChatbotConfig = {
    // ... other configurations
    containerProps: {
        style: {
            backgroundColor: '#ABCDEF',
            width: '60px',
            height: '60px',
            borderRadius: '30px',
        },
        // For minor style overrides, you can also use a string value for the `style` attribute:
        // style: 'background-color: #ABCDEF; width: 60px;',
    },
}

----------------------------------------

TITLE: Directory Structure for External Data Tool
DESCRIPTION: Shows the required directory and file structure for implementing a custom Weather Search tool.

LANGUAGE: plaintext
CODE:
.
└── api
    └── core
        └── external_data_tool
            └── weather_search
                ├── __init__.py
                ├── weather_search.py
                └── schema.json

----------------------------------------

TITLE: Implementing Token Calculation in Python
DESCRIPTION: This Python snippet demonstrates the structure for implementing the get_num_tokens method in the AnthropicLargeLanguageModel class, used for precomputing input tokens.

LANGUAGE: python
CODE:
def get_num_tokens(self, model: str, credentials: dict, prompt_messages: list[PromptMessage],
                   tools: Optional[list[PromptMessageTool]] = None) -> int:
    """
    Get number of tokens for given prompt messages

    :param model: model name
    :param credentials: model credentials
    :param prompt_messages: prompt messages
    :param tools: tools for tool calling
    :return:
    """

----------------------------------------

TITLE: Implementing API Ping Check in JSON
DESCRIPTION: Demonstrates the JSON structure for the API ping check, including the request body and expected response to verify API availability.

LANGUAGE: JSON
CODE:
{
    "point": "ping"
}

LANGUAGE: JSON
CODE:
{
    "result": "pong"
}

----------------------------------------

TITLE: Merging Data from Multiple Sources in Python
DESCRIPTION: Shows how to concatenate data from multiple sources, such as knowledge bases, using Python in a Dify code node.

LANGUAGE: python
CODE:
def main(knowledge1: list, knowledge2: list) -> list:
    return {
        # Note to declare 'result' in the output variables
        'result': knowledge1 + knowledge2
    }

----------------------------------------

TITLE: Defining ProviderConfigType Enumeration for Configuration Types in Dify
DESCRIPTION: ProviderConfigType enumerates the possible types of provider configurations, including various input types, selectors, and boolean switches used in plugin development.

LANGUAGE: python
CODE:
ProviderConfigType = [
    "secret-input",
    "text-input",
    "select",
    "boolean",
    "model-selector",
    "app-selector",
    "tool-selector",
    "dataset-selector"
]

----------------------------------------

TITLE: Configuring Dify API Credentials in JavaScript
DESCRIPTION: Basic configuration for setting up Dify App ID and API Key credentials required for template initialization.

LANGUAGE: javascript
CODE:
export const APP_ID = ''
export const API_KEY = ''

----------------------------------------

TITLE: Configuring Xinference Provider in YAML
DESCRIPTION: Defines the structure of the xinference.yaml file, including provider details, supported model types, and credential schema for Xinference models.

LANGUAGE: yaml
CODE:
provider: xinference
label:
  en_US: Xorbits Inference
icon_small:
  en_US: icon_s_en.svg
icon_large:
  en_US: icon_l_en.svg
help:
  title:
    en_US: How to deploy Xinference
    zh_Hans: 如何部署 Xinference
  url:
    en_US: https://github.com/xorbitsai/inference

supported_model_types:
- llm
- text-embedding
- rerank

configurate_methods:
- customizable-model

provider_credential_schema:
  credential_form_schemas:

----------------------------------------

TITLE: Creating Image Message in Python for Dify Tool
DESCRIPTION: Method to create an image message by passing an image URL. Dify automatically downloads and returns the image to users.

LANGUAGE: python
CODE:
def create_image_message(self, image: str) -> ToolInvokeMessage:
    pass

----------------------------------------

TITLE: Defining Credential Schema Structures in Markdown
DESCRIPTION: Specifies the structures for ProviderCredentialSchema, ModelCredentialSchema, and CredentialFormSchema, which are used to define credential specifications for providers and models.

LANGUAGE: markdown
CODE:
### **ProviderCredentialSchema**

* `credential_form_schemas` (array\[CredentialFormSchema]): Credential form specifications

### **ModelCredentialSchema**

* `model` (object): Model identifier, default variable name is 'model'
* `label` (object): Model form item display name
  * `en_US` (string): English
  * `zh_Hans` (string) \[optional]: Chinese
* `placeholder` (object): Model prompt content
  * `en_US` (string): English
  * `zh_Hans` (string) \[optional]: Chinese
* `credential_form_schemas` (array\[CredentialFormSchema]): Credential form specifications

### **CredentialFormSchema**

* `variable` (string): Form item variable name
* `label` (object): Form item label
  * `en_US` (string): English
  * `zh_Hans` (string) \[optional]: Chinese
* `type` (\[FormType]): Form item type
* `required` (bool): Whether required
* `default` (string): Default value
* `options` (array\[FormOption]): Form item options for select or radio types
* `placeholder` (object): Form item placeholder for text-input type
  * `en_US` (string): English
  * `zh_Hans` (string) \[optional]: Chinese
* `max_length` (int): Maximum input length for text-input type, 0 means no limit
* `show_on` (array\[FormShowOnObject]): Show when other form items meet conditions, always show if empty

#### **FormType**

* `text-input`: Text input component
* `secret-input`: Password input component
* `select`: Single-select dropdown
* `radio`: Radio component
* `switch`: Switch component, only supports true and false

#### **FormOption**

* `label` (object): Label
  * `en_US` (string): English
  * `zh_Hans` (string) \[optional]: Chinese
* `value` (string): Dropdown option value
* `show_on` (array\[FormShowOnObject]): Show when other form items meet conditions, always show if empty

#### **FormShowOnObject**

* `variable` (string): Other form item variable name
* `value` (string): Other form item variable value

----------------------------------------

TITLE: Plugin Packaging Command
DESCRIPTION: Command to package the plugin into a distributable format

LANGUAGE: bash
CODE:
dify plugin package ./neko

----------------------------------------

TITLE: Defining Credential Schema for Xinference
DESCRIPTION: Specifies the credential form schema for Xinference, including model type selection, model name input, server URL, and model UID.

LANGUAGE: yaml
CODE:
provider_credential_schema:
  credential_form_schemas:
  - variable: model_type
    type: select
    label:
      en_US: Model type
      zh_Hans: 模型类型
    required: true
    options:
    - value: text-generation
      label:
        en_US: Language Model
        zh_Hans: 语言模型
    - value: embeddings
      label:
        en_US: Text Embedding
    - value: reranking
      label:
        en_US: Rerank
  - variable: model_name
    type: text-input
    label:
      en_US: Model name
      zh_Hans: 模型名称
    required: true
    placeholder:
      zh_Hans: 填写模型名称
      en_US: Input model name
  - variable: server_url
    label:
      zh_Hans: 服务器 URL
      en_US: Server url
    type: text-input
    required: true
    placeholder:
      zh_Hans: 在此输入 Xinference 的服务器地址，如 https://example.com/xxx
      en_US: Enter the url of your Xinference, for example https://example.com/xxx
  - variable: model_uid
    label:
      zh_Hans: 模型 UID
      en_US: Model uid
    type: text-input
    required: true
    placeholder:
      zh_Hans: 在此输入您的 Model UID
      en_US: Enter the model uid

----------------------------------------

TITLE: Calling Dify Text Generation API with Python
DESCRIPTION: This Python code snippet shows how to use the requests library to make a POST request to Dify's completion-messages API for text generation. It sets up the headers, prepares the request data, and sends the request, then prints the response.

LANGUAGE: Python
CODE:
import requests
import json

url = "https://api.dify.ai/v1/completion-messages"

headers = {
    'Authorization': 'Bearer ENTER-YOUR-SECRET-KEY',
    'Content-Type': 'application/json',
}

data = {
    "inputs": {"text": 'Hello, how are you?'},
    "response_mode": "streaming",
    "user": "abc-123"
}

response = requests.post(url, headers=headers, data=json.dumps(data))

print(response.text)

----------------------------------------

TITLE: Neko Plugin Implementation
DESCRIPTION: Python implementation of a plugin that displays an ASCII art cat animation

LANGUAGE: python
CODE:
from typing import Mapping
from werkzeug import Request, Response
from flask import Flask, render_template_string
from dify_plugin import Endpoint

app = Flask(__name__)

class NekoEndpoint(Endpoint):
    def _invoke(self, r: Request, values: Mapping, settings: Mapping) -> Response:
        ascii_art = '''
⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛⬛️⬜️⬜️⬜️⬜️⬜⬜️⬜️️
[...]'''

----------------------------------------

TITLE: Implementation Class Template
DESCRIPTION: Base template for creating custom external data tool implementation classes.

LANGUAGE: python
CODE:
from typing import Optional

from core.external_data_tool.base import ExternalDataTool


class WeatherSearch(ExternalDataTool):
    """
    The name of custom type must be unique, keep the same with directory and file name.
    """
    name: str = "weather_search"

    @classmethod
    def validate_config(cls, tenant_id: str, config: dict) -> None:
        """
        schema.json validation. It will be called when user save the config.

        :param tenant_id: the id of workspace
        :param config: the variables of form config
        :return:
        """

        # implement your own logic here

    def query(self, inputs: dict, query: Optional[str] = None) -> str:
        """
        Query the external data tool.

        :param inputs: user inputs
        :param query: the query of chat app
        :return: the tool query result
        """
       
        # implement your own logic here
        return "your own data."

----------------------------------------

TITLE: Configuring LiteLLM Model List
DESCRIPTION: YAML configuration file defining multiple GPT-4 model endpoints with Azure parameters including API bases, versions, and keys. This config enables load balancing across multiple Azure endpoints.

LANGUAGE: yaml
CODE:
model_list:
  - model_name: gpt-4
    litellm_params:
      model: azure/chatgpt-v-2
      api_base: https://openai-gpt-4-test-v-1.openai.azure.com/
      api_version: "2023-05-15"
      api_key: 
  - model_name: gpt-4
    litellm_params:
      model: azure/gpt-4
      api_key: 
      api_base: https://openai-gpt-4-test-v-2.openai.azure.com/
  - model_name: gpt-4
    litellm_params:
      model: azure/gpt-4
      api_key: 
      api_base: https://openai-gpt-4-test-v-2.openai.azure.com/

----------------------------------------

TITLE: Creating New Dify Plugin Project
DESCRIPTION: Commands to initialize a new Dify plugin project using the CLI tool

LANGUAGE: bash
CODE:
./dify-plugin-darwin-arm64 plugin init

LANGUAGE: bash
CODE:
dify plugin init

----------------------------------------

TITLE: Anthropic Model Directory Structure
DESCRIPTION: Directory structure example for Anthropic model implementation showing the organization of YAML configuration files and Python modules.

LANGUAGE: bash
CODE:
├── models
│   └── llm
│       ├── _position.yaml
│       ├── claude-2.1.yaml
│       ├── claude-2.yaml
│       ├── claude-3-5-sonnet-20240620.yaml
│       ├── claude-3-haiku-20240307.yaml
│       ├── claude-3-opus-20240229.yaml
│       ├── claude-3-sonnet-20240229.yaml
│       ├── claude-instant-1.2.yaml
│       ├── claude-instant-1.yaml
│       └── llm.py

----------------------------------------

TITLE: Request Syntax Example
DESCRIPTION: Complete example of a knowledge retrieval API request including headers and JSON body with query parameters and retrieval settings

LANGUAGE: json
CODE:
POST <your-endpoint>/retrieval HTTP/1.1
-- header
Content-Type: application/json
Authorization: Bearer your-api-key
-- data
{
    "knowledge_id": "your-knowledge-id",
    "query": "your question",
    "retrieval_setting":{
        "top_k": 2,
        "score_threshold": 0.5
    }
}

----------------------------------------

TITLE: Getting Storage Values - Python
DESCRIPTION: Method for retrieving data from persistent storage using a key. Returns the stored value as bytes.

LANGUAGE: python
CODE:
    def get(self, key: str) -> bytes:
        pass

----------------------------------------

TITLE: Creating Bundle Project with Dify CLI
DESCRIPTION: Command to initialize a new Bundle plugin project using the Dify plugin scaffolding tool.

LANGUAGE: bash
CODE:
./dify-plugin-darwin-arm64 bundle init

----------------------------------------

TITLE: Accessing Storage Instance - Python
DESCRIPTION: Shows how to access the storage instance within a plugin session

LANGUAGE: python
CODE:
    self.session.storage

----------------------------------------

TITLE: Adding GitHub Dependencies to Bundle
DESCRIPTION: Command to append GitHub plugin dependencies to a Bundle project, using organization/repo:release/filename pattern.

LANGUAGE: bash
CODE:
dify-plugin bundle append github . --repo_pattern=langgenius/openai:0.0.1/openai.difypkg

----------------------------------------

TITLE: Adding GitHub Dependencies to Bundle
DESCRIPTION: Command to append GitHub plugin dependencies to a Bundle project, using organization/repo:release/filename pattern.

LANGUAGE: bash
CODE:
dify-plugin bundle append github . --repo_pattern=langgenius/openai:0.0.1/openai.difypkg

----------------------------------------

TITLE: Anthropic Model Plugin Structure Example
DESCRIPTION: Demonstrates the directory structure for Anthropic's model plugin implementation, showing various Claude model versions.

LANGUAGE: bash
CODE:
- Anthropic
  - llm
    claude-3-5-sonnet-20240620
    claude-3-haiku-20240307
    claude-3-opus-20240229
    claude-3-sonnet-20240229
    claude-instant-1.2
    claude-instant-1

----------------------------------------

TITLE: Packaging Bundle Project
DESCRIPTION: Command to create the final Bundle package file (bundle.difybndl) from the project directory.

LANGUAGE: bash
CODE:
dify-plugin bundle package ./bundle

----------------------------------------

TITLE: Basic Model Plugin Directory Structure
DESCRIPTION: Shows the basic hierarchical structure for organizing model plugins with providers, categories, and specific models.

LANGUAGE: bash
CODE:
- Model Provider
  - Model Category
    - Specific Models

----------------------------------------

TITLE: Endpoint Configuration
DESCRIPTION: YAML configuration defining the plugin's request endpoint path and method

LANGUAGE: yaml
CODE:
path: "/neko"
method: "GET"
extra:
  python:
    source: "endpoints/test_plugin.py"

----------------------------------------

TITLE: Tool Invocation Implementation
DESCRIPTION: Implementation of tool invocation functionality with response parsing.

LANGUAGE: python
CODE:
from dify_plugin.entities.tool import ToolProviderType

class FunctionCallingAgentStrategy(AgentStrategy):
    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:
        fc_params = FunctionCallingParams(**parameters)
        
        tool_instances = {tool.identity.name: tool for tool in fc_params.tools} if fc_params.tools else {}
        tool_instance = tool_instances[tool_call_name]
        tool_invoke_responses = self.session.tool.invoke(
            provider_type=ToolProviderType.BUILT_IN,
            provider=tool_instance.identity.provider,
            tool_name=tool_instance.identity.name,
            parameters={**tool_instance.runtime_parameters, **tool_call_args},
        )

----------------------------------------

TITLE: Example of app.moderation.output Request Body in JSON
DESCRIPTION: This snippet provides a concrete example of the app.moderation.output request body, demonstrating how to structure the request with specific values for app_id and text content.

LANGUAGE: json
CODE:
{
    "point": "app.moderation.output",
    "params": {
        "app_id": "61248ab4-1125-45be-ae32-0ce91334d021",
        "text": "I will kill you."
    }
}

----------------------------------------

TITLE: Plugin Environment Configuration
DESCRIPTION: Environment configuration for remote debugging of the plugin

LANGUAGE: bash
CODE:
INSTALL_METHOD=remote
REMOTE_INSTALL_HOST=localhost
REMOTE_INSTALL_PORT=5003
REMOTE_INSTALL_KEY=****-****-****-****-****

----------------------------------------

TITLE: Implementing LLM Invocation in Python
DESCRIPTION: This Python snippet shows the structure for implementing the _invoke method in the AnthropicLargeLanguageModel class, handling both streaming and synchronous responses for LLM invocation.

LANGUAGE: python
CODE:
def _invoke(self, stream: bool, **kwargs) \
        -> Union[LLMResult, Generator]:
    if stream:
          return self._handle_stream_response(**kwargs)
    return self._handle_sync_response(**kwargs)

def _handle_stream_response(self, **kwargs) -> Generator:
    for chunk in response:
          yield chunk
def _handle_sync_response(self, **kwargs) -> LLMResult:
    return LLMResult(**response)

----------------------------------------

TITLE: Starting Xinference Local Server
DESCRIPTION: Command to start Xinference locally and sample output showing successful server startup with endpoint information and worker initialization.

LANGUAGE: bash
CODE:
$ xinference-local
2023-08-20 19:21:05,265 xinference   10148 INFO     Xinference successfully started. Endpoint: http://127.0.0.1:9997
2023-08-20 19:21:05,266 xinference.core.supervisor 10148 INFO     Worker 127.0.0.1:37822 has been added successfully
2023-08-20 19:21:05,267 xinference.deploy.worker 10148 INFO     Xinference worker successfully started.

----------------------------------------

TITLE: Initializing Agent Strategy Plugin Template
DESCRIPTION: Commands and configuration for creating a new Agent Strategy Plugin development template using Dify's scaffolding tool

LANGUAGE: bash
CODE:
dify plugin init

----------------------------------------

TITLE: Extracting Data from JSON in Python
DESCRIPTION: Example of parsing a JSON string from an HTTP response to extract a specific field using Python in a Dify code node.

LANGUAGE: python
CODE:
def main(http_response: str) -> str:
    import json
    data = json.loads(http_response)
    return {
        # Note to declare 'result' in the output variables
        'result': data['data']['name'] 
    }

----------------------------------------

TITLE: Squid Proxy Configuration
DESCRIPTION: Example configuration for customizing SSRF proxy behavior in squid.conf to restrict access to specific IP addresses.

LANGUAGE: conf
CODE:
acl restricted_ip dst 192.168.101.19
acl localnet src 192.168.101.0/24

http_access deny restricted_ip
http_access allow localnet
http_access deny all

----------------------------------------

TITLE: Squid Proxy Configuration
DESCRIPTION: Example configuration for customizing SSRF proxy behavior in squid.conf to restrict access to specific IP addresses.

LANGUAGE: conf
CODE:
acl restricted_ip dst 192.168.101.19
acl localnet src 192.168.101.0/24

http_access deny restricted_ip
http_access allow localnet
http_access deny all

----------------------------------------

TITLE: Installing Xinference via PyPI
DESCRIPTION: Command to install Xinference package with all dependencies through pip package manager.

LANGUAGE: bash
CODE:
$ pip install "xinference[all]"

----------------------------------------

TITLE: Defining Plugin Parameters in YAML
DESCRIPTION: YAML configuration for specifying plugin parameters including model selection, tools list, query input and maximum iterations

LANGUAGE: yaml
CODE:
identity:
  name: basic_agent
  author: novice
  label:
    en_US: BasicAgent
description:
  en_US: BasicAgent
parameters:
  - name: model
    type: model-selector
    scope: tool-call&llm
    required: true
    label:
      en_US: Model
  - name: tools
    type: array[tools]
    required: true
    label:
      en_US: Tools list
  - name: query
    type: string
    required: true
    label:
      en_US: Query
  - name: maximum_iterations
    type: number
    required: false
    default: 5
    label:
      en_US: Maxium Iterations

----------------------------------------

TITLE: Implementing Parameter Validation
DESCRIPTION: Parameter validation schema using Zod for type checking and validation in the API extension.

LANGUAGE: typescript
CODE:
import { z } from "zod";
import { zValidator } from "@hono/zod-validator";

const schema = z.object({
  point: z.union([
    z.literal("ping"),
    z.literal("app.external_data_tool.query"),
  ]), // Restricts 'point' to two specific values
  params: z
    .object({
      app_id: z.string().optional(),
      tool_variable: z.string().optional(),
      inputs: z.record(z.any()).optional(),
      query: z.any().optional(),  // string or null
    })
    .optional(),
});

----------------------------------------

TITLE: Uploading Dify Plugin Files to GitHub
DESCRIPTION: Commands to push the Dify plugin project to the GitHub repository, including setting the main branch and creating a version tag.

LANGUAGE: bash
CODE:
git branch -M main
git push -u origin main

# Adding a version tag
git tag -a v0.0.1 -m "Release version 0.0.1"
git push origin v0.0.1

----------------------------------------

TITLE: Building and Starting Frontend Service
DESCRIPTION: Commands to build and start the frontend service.

LANGUAGE: Bash
CODE:
npm run build
npm run start

----------------------------------------

TITLE: Tool Integration Implementation
DESCRIPTION: Code for handling tool invocations and processing tool responses within the Agent Strategy Plugin

LANGUAGE: python
CODE:
def invoke(self, provider_type: ToolProviderType, provider: str, tool_name: str, parameters: dict[str, Any]) -> Generator[ToolInvokeMessage, None, None]:...

----------------------------------------

TITLE: Implementing Bearer Authentication
DESCRIPTION: Implementation of Bearer authentication using the hono/bearer-auth package.

LANGUAGE: typescript
CODE:
import { bearerAuth } from "hono/bearer-auth";

(c, next) => {
    const auth = bearerAuth({ token: c.env.TOKEN });
    return auth(c, next);
},

----------------------------------------

TITLE: Cloning the Dify Documentation Repository in Bash
DESCRIPTION: This command clones the forked Dify documentation repository to the contributor's local machine. It requires the contributor to replace '<your-github-account>' with their actual GitHub username.

LANGUAGE: bash
CODE:
git clone https://github.com/<your-github-account>/dify-docs.git

----------------------------------------

TITLE: Starting Worker Service (Windows)
DESCRIPTION: Command to start the Celery worker service for asynchronous tasks on Windows.

LANGUAGE: Bash
CODE:
celery -A app.celery worker -P solo --without-gossip --without-mingle -Q dataset,generation,mail,ops_trace --loglevel INFO

----------------------------------------

TITLE: Initializing Dify Plugin Development Environment
DESCRIPTION: Command to initialize a new Dify plugin project using the CLI tool.

LANGUAGE: bash
CODE:
dify plugin init

----------------------------------------

TITLE: Implementing Breaking Bad Quote API Logic
DESCRIPTION: Example implementation of API extension logic that fetches random Breaking Bad quotes from an external API.

LANGUAGE: typescript
CODE:
// ⬇️ implement your logic here ⬇️
// point === "app.external_data_tool.query"
// https://api.breakingbadquotes.xyz/v1/quotes
const count = params?.inputs?.count ?? 1;
const url = `https://api.breakingbadquotes.xyz/v1/quotes/${count}`;
const result = await fetch(url).then(res => res.text())
// ⬆️ implement your logic here ⬆️

----------------------------------------

TITLE: Installing API Dependencies with Poetry
DESCRIPTION: Commands to install Python dependencies for the API service using Poetry.

LANGUAGE: Bash
CODE:
poetry env use 3.12
poetry install

----------------------------------------

TITLE: Configuring Slack Plugin Settings
DESCRIPTION: YAML configuration defining the plugin's settings including bot token, retry options, and app selector.

LANGUAGE: yaml
CODE:
settings:
  - name: bot_token
    type: secret-input
    required: true
    label:
      en_US: Bot Token
      zh_Hans: Bot Token
      pt_BR: Token do Bot
      ja_JP: Bot Token
    placeholder:
      en_US: Please input your Bot Token
      zh_Hans: 请输入你的 Bot Token
      pt_BR: Por favor, insira seu Token do Bot
      ja_JP: ボットトークンを入力してください
  - name: allow_retry
    type: boolean
    required: false
    label:
      en_US: Allow Retry
      zh_Hans: 允许重试
      pt_BR: Permitir Retentativas
      ja_JP: 再試行を許可
    default: false
  - name: app
    type: app-selector
    required: true
    label:
      en_US: App
      zh_Hans: 应用
      pt_BR: App
      ja_JP: アプリ
    placeholder:
      en_US: the app you want to use to answer Slack messages
      zh_Hans: 你想要用来回答 Slack 消息的应用
      pt_BR: o app que você deseja usar para responder mensagens do Slack
      ja_JP: あなたが Slack メッセージに回答するために使用するアプリ
endpoints:
  - endpoints/slack.yaml

----------------------------------------

TITLE: Deleting Storage Values - Python
DESCRIPTION: Method for removing data from persistent storage using a key. Returns None after deletion.

LANGUAGE: python
CODE:
    def delete(self, key: str) -> None:
        pass

----------------------------------------

TITLE: Implementing app.moderation.input Extension Point in JSON
DESCRIPTION: This snippet demonstrates the structure of the request body for the app.moderation.input extension point. It includes the point type, application ID, user inputs, and query content for review.

LANGUAGE: json
CODE:
{
    "point": "app.moderation.input",
    "params": {
        "app_id": string,
        "inputs": {
            "var_1": "value_1",
            "var_2": "value_2",
            ...
        },
        "query": string | null
    }
}

----------------------------------------

TITLE: Installing Python with pyenv
DESCRIPTION: Commands to install and set Python 3.12 using pyenv.

LANGUAGE: Bash
CODE:
pyenv install 3.12
pyenv global 3.12

----------------------------------------

TITLE: Configuring Slack Endpoint
DESCRIPTION: YAML configuration for the Slack endpoint defining the path, method and Python source file.

LANGUAGE: yaml
CODE:
path: "/"
method: "POST"
extra:
  python:
    source: "endpoints/slack.py"

----------------------------------------

TITLE: Setting Storage Values - Python
DESCRIPTION: Method for storing data in the persistent storage. Accepts a string key and bytes value, allowing for both simple data and file storage.

LANGUAGE: python
CODE:
    def set(self, key: str, val: bytes) -> None:
        pass

----------------------------------------

TITLE: Cloning Dify Repository
DESCRIPTION: Command to clone the Dify source code repository from GitHub.

LANGUAGE: Bash
CODE:
git clone https://github.com/langgenius/dify.git

----------------------------------------

TITLE: Setting Up Debug Environment
DESCRIPTION: Environment configuration for remote debugging of the Dify plugin.

LANGUAGE: bash
CODE:
INSTALL_METHOD=remote
REMOTE_INSTALL_HOST=remote-url
REMOTE_INSTALL_PORT=5003
REMOTE_INSTALL_KEY=****-****-****-****-****

----------------------------------------

TITLE: Defining Frontend Component for Cloud Service Moderation in JSON
DESCRIPTION: This JSON schema defines the frontend component specifications for the Cloud Service moderation type. It includes form fields for selecting a cloud provider, entering an API endpoint, and providing an API key.

LANGUAGE: json
CODE:
{
    "label": {
        "en-US": "Cloud Service",
        "zh-Hans": "云服务"
    },
    "form_schema": [
        {
            "type": "select",
            "label": {
                "en-US": "Cloud Provider",
                "zh-Hans": "云厂商"
            },
            "variable": "cloud_provider",
            "required": true,
            "options": [
                {
                    "label": {
                        "en-US": "AWS",
                        "zh-Hans": "亚马逊"
                    },
                    "value": "AWS"
                },
                {
                    "label": {
                        "en-US": "Google Cloud",
                        "zh-Hans": "谷歌云"
                    },
                    "value": "GoogleCloud"
                },
                {
                    "label": {
                        "en-US": "Azure Cloud",
                        "zh-Hans": "微软云"
                    },
                    "value": "Azure"
                }
            ],
            "default": "GoogleCloud",
            "placeholder": ""
        },
        {
            "type": "text-input",
            "label": {
                "en-US": "API Endpoint",
                "zh-Hans": "API Endpoint"
            },
            "variable": "api_endpoint",
            "required": true,
            "max_length": 100,
            "default": "",
            "placeholder": "https://api.example.com"
        },
        {
            "type": "paragraph",
            "label": {
                "en-US": "API Key",
                "zh-Hans": "API Key"
            },
            "variable": "api_keys",
            "required": true,
            "default": "",
            "placeholder": "Paste your API key here"
        }
    ]
}

----------------------------------------

TITLE: Creating Text Message in Python for Dify Tool
DESCRIPTION: Method to create a text message by passing a string.

LANGUAGE: python
CODE:
def create_text_message(self, text: str) -> ToolInvokeMessage:
    pass

----------------------------------------

TITLE: Constructing Twitter Profile URL in Python
DESCRIPTION: Python function to construct a Twitter profile URL from a given user ID. This code is used in a Dify code node to prepare the URL for the HTTP request.

LANGUAGE: python
CODE:
def main(id: str) -> dict:
    return {
        "url": "https://twitter.com/"+id,
    }

----------------------------------------

TITLE: Markdown Documentation Structure
DESCRIPTION: Structured documentation for Dify's plugin system including sections for introduction, plugin types, features, and development guides

LANGUAGE: markdown
CODE:
# Introduction

> To access the plugin's functionality in the Community Edition, please update the version to v1.0.0.

## **What is the Plugin?**

Plugin is a more developer-friendly and highly extensible third-party service extension module...

----------------------------------------

TITLE: Complete Model Conversational App Template
DESCRIPTION: Template for building conversational applications using complete models. Includes history handling and structured conversation format with human/assistant roles.

LANGUAGE: markdown
CODE:
Use the following context as your learned knowledge, inside <context></context> XML tags.

<context>
{{#context#}}
</context>

When answer to user:
- If you don't know, just say that you don't know.
- If you don't know when you are not sure, ask for clarification.
Avoid mentioning that you obtained the information from the context.
And answer according to the language of the user's question.

{{pre_prompt}}

Here is the chat histories between human and assistant, inside <histories></histories> XML tags.

<histories>
{{#histories#}}
</histories>


H: {{#query#}}

A: 

----------------------------------------

TITLE: Installing extracted plugins in new Dify version
DESCRIPTION: Executes a Flask command to download and install all necessary plugins extracted from the previous step into the latest community version.

LANGUAGE: bash
CODE:
poetry run flask install-plugins --workers=2

----------------------------------------

TITLE: Question Generation Prompt for LLM Node
DESCRIPTION: A prompt template for generating meaningful questions based on the article's structure. The prompt guides the LLM to create in-depth questions for each section of the article.

LANGUAGE: markdown
CODE:
Read the following article content and perform the task
{{Output of the structure extraction}}
# Task

- **Main Objective**: Thoroughly read the above text, and propose as many questions as possible for each part of the article.
- **Requirements**: Questions should be meaningful and valuable, worthy of consideration.
- **Restrictions**: No specific restrictions.
- **Expected Output**: A series of questions for each part of the article, each question should have depth and thinking value.

# Reasoning Order

- **Reasoning Part**: Thoroughly read the article, analyze the content of each part, and consider the deep questions each part may raise.
- **Conclusion Part**: Pose meaningful and valuable questions, ensuring they provoke in-depth thought.

# Output Format

- **Format**: Each question should be listed separately, numbered.
- **Content**: Propose questions for each part of the article (such as introduction, background, methods, results, discussion, conclusion, etc.).
- **Quantity**: As many as possible, but each question should be meaningful and valuable.

----------------------------------------

TITLE: Logging Implementation Example
DESCRIPTION: Example implementation of Agent logging functionality with status tracking.

LANGUAGE: python
CODE:
class FunctionCallingAgentStrategy(AgentStrategy):
    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:
        thinking_log = self.create_log_message(
            data={"Query": parameters.get("query")},
            label="Thinking",
            status=AgentInvokeMessage.LogMessage.LogStatus.START,
        )

        yield thinking_log

        llm_response = self.session.model.llm.invoke(
            model_config=LLMModelConfig(
                provider="openai",
                model="gpt-4o-mini",
                mode="chat",
                completion_params={},
            ),
            prompt_messages=[
                SystemPromptMessage(content="you are a helpful assistant"),
                UserPromptMessage(content=parameters.get("query")),
            ],
            stream=False,
            tools=[],
        )

        thinking_log = self.finish_log_message(log=thinking_log)
        yield thinking_log
        yield self.create_text_message(text=llm_response.message.content)

----------------------------------------

TITLE: Connecting Local Repository to GitHub for Dify Plugin
DESCRIPTION: Command to connect the local Git repository to a remote GitHub repository for a Dify plugin project.

LANGUAGE: bash
CODE:
git remote add origin https://github.com/<your-username>/<repository-name>.git

----------------------------------------

TITLE: Invoking Built-in Tools in Python
DESCRIPTION: Method for invoking built-in tools with provider ID, tool name, and parameters. Provider format should be 'langgenius/google/google'.

LANGUAGE: python
CODE:
def invoke_builtin_tool(
    self, provider: str, tool_name: str, parameters: dict[str, Any]
) -> Generator[ToolInvokeMessage, None, None]:
    pass

----------------------------------------

TITLE: Restarting Dify Service to Bypass Plugin Signature Verification
DESCRIPTION: Commands to restart the Dify service after disabling plugin signature verification. Requires adding FORCE_VERIFYING_SIGNATURE=false to the docker/.env file before execution.

LANGUAGE: bash
CODE:
cd docker
docker compose down
docker compose up -d

----------------------------------------

TITLE: Invoking QuestionClassifier Node in Python
DESCRIPTION: Demonstrates the invocation of the QuestionClassifier node. This method classifies a query into predefined classes using specified model configurations and optional instructions.

LANGUAGE: python
CODE:
def invoke(
    self,
    classes: list[ClassConfig],
    model: ModelConfig,
    query: str,
    instruction: str = "",
) -> NodeResponse:
    pass

----------------------------------------

TITLE: UI Generation Schema with Recursive Structure
DESCRIPTION: JSON Schema for generating UI components with recursive nesting capabilities and attribute definitions.

LANGUAGE: json
CODE:
{
        "name": "ui",
        "description": "Dynamically generated UI",
        "strict": true,
        "schema": {
            "type": "object",
            "properties": {
                "type": {
                    "type": "string",
                    "description": "The type of the UI component",
                    "enum": ["div", "button", "header", "section", "field", "form"]
                },
                "label": {
                    "type": "string",
                    "description": "The label of the UI component, used for buttons or form fields"
                },
                "children": {
                    "type": "array",
                    "description": "Nested UI components",
                    "items": {
                        "$ref": "#"
                    }
                },
                "attributes": {
                    "type": "array",
                    "description": "Arbitrary attributes for the UI component, suitable for any element",
                    "items": {
                        "type": "object",
                        "properties": {
                            "name": {
                                "type": "string",
                                "description": "The name of the attribute, for example onClick or className"
                            },
                            "value": {
                                "type": "string",
                                "description": "The value of the attribute"
                            }
                        },
                      "additionalProperties": false,
                      "required": ["name", "value"]
                    }
                }
            },
            "required": ["type", "label", "children", "attributes"],
            "additionalProperties": false
        }
    }

----------------------------------------

TITLE: Setting Up API Service Environment
DESCRIPTION: Commands to set up the environment for the API service, including copying environment variables and generating a secret key.

LANGUAGE: Bash
CODE:
cd api
cp .env.example .env
awk -v key="$(openssl rand -base64 42)" '/^SECRET_KEY=/ {sub(/=.*/, "=" key)} 1' .env > temp_env && mv temp_env .env

----------------------------------------

TITLE: Invoking QuestionClassifier Node in Python
DESCRIPTION: Demonstrates the invocation of the QuestionClassifier node. This method classifies a query into predefined classes using specified model configurations and optional instructions.

LANGUAGE: python
CODE:
def invoke(
    self,
    classes: list[ClassConfig],
    model: ModelConfig,
    query: str,
    instruction: str = "",
) -> NodeResponse:
    pass

----------------------------------------

TITLE: Workspace Structure Example in Dify
DESCRIPTION: Demonstrates the hierarchical structure of workspaces and apps in Dify, showing how billing is organized on a workspace level. Each workspace can contain multiple apps with various capabilities.

LANGUAGE: plaintext
CODE:
Workspace 1  
App 1(Prompt, RAG, LLM, Knowledge base, Logging & Annotation, API)
App 2(Prompt, RAG, LLM, Knowledge base, Logging & Annotation, API) 
App 3(Prompt, RAG, LLM, Knowledge base, Logging & Annotation, API)
...
Workspace 2

----------------------------------------

TITLE: Implementing Bedrock Retrieval API in Python Flask
DESCRIPTION: This code snippet defines a Flask resource for handling retrieval requests to AWS Bedrock. It parses input parameters, performs authorization checks, and calls the knowledge retrieval service.

LANGUAGE: python
CODE:
from flask import request
from flask_restful import Resource, reqparse

from bedrock.knowledge_service import ExternalDatasetService


class BedrockRetrievalApi(Resource):
    # url : <your-endpoint>/retrieval
    def post(self):
        parser = reqparse.RequestParser()
        parser.add_argument("retrieval_setting", nullable=False, required=True, type=dict, location="json")
        parser.add_argument("query", nullable=False, required=True, type=str,)
        parser.add_argument("knowledge_id", nullable=False, required=True, type=str)
        args = parser.parse_args()

        # Authorization check
        auth_header = request.headers.get("Authorization")
        if " " not in auth_header:
            return {
                "error_code": 1001,
                "error_msg": "Invalid Authorization header format. Expected 'Bearer <api-key>' format."
            }, 403
        auth_scheme, auth_token = auth_header.split(None, 1)
        auth_scheme = auth_scheme.lower()
        if auth_scheme != "bearer":
            return {
                "error_code": 1001,
                "error_msg": "Invalid Authorization header format. Expected 'Bearer <api-key>' format."
            }, 403
        if auth_token:
            # process your authorization logic here
            pass

        # Call the knowledge retrieval service
        result = ExternalDatasetService.knowledge_retrieval(
            args["retrieval_setting"], args["query"], args["knowledge_id"]
        )
        return result, 200

----------------------------------------

TITLE: Accessing QuestionClassifier Node in Python
DESCRIPTION: Shows how to access the QuestionClassifier node in a Dify Workflow. This node is used for classifying questions or queries into predefined classes.

LANGUAGE: python
CODE:
self.session.workflow_node.question_classifier

----------------------------------------

TITLE: Displaying Chatflow App System Variables in Markdown
DESCRIPTION: A markdown table showing system variables available in Chatflow type applications, including their names, data types, descriptions, and remarks.

LANGUAGE: markdown
CODE:
<table><thead><tr><th>Variables name</th><th>Data Type</th><th width="283">Description</th><th>Remark</th></tr></thead><tbody><tr><td><code>sys.query</code></td><td>String</td><td>Content entered by the user in the chatting box.</td><td></td></tr><tr><td><code>sys.files</code></td><td>Array[File]</td><td>File Parameter: Stores images uploaded by users</td><td>The image upload function needs to be enabled in the 'Features' section in the upper right corner of the application orchestration page</td></tr><tr><td><code>sys.dialogue_count</code></td><td>Number</td><td><p>The number of conversations turns during the user's interaction with a Chatflow application. The count automatically increases by one after each chat round and can be combined with if-else nodes to create rich branching logic.<br></p><p>For example, LLM will review the conversation history at the X conversation turn and automatically provide an analysis.</p></td><td></td></tr><tr><td><code>sys.conversation_id</code></td><td>String</td><td>A unique ID for the chatting box interaction session, grouping all related messages into the same conversation, ensuring that the LLM continues the chatting on the same topic and context.</td><td></td></tr><tr><td><code>sys.user_id</code></td><td>String</td><td>A unique ID is assigned for each application user to distinguish different conversation users.</td><td></td></tr><tr><td><code>sys.workflow_id</code></td><td>String</td><td>Workflow ID: This parameter records information about all nodes information in the current Workflow application.</td><td>This parameter can be used by users with development capabilities to track and record information about the nodes contained within a Workflow</td></tr><tr><td><code>sys.workflow_run_id</code></td><td>String</td><td>Workflow Run ID: Used to record the runtime status and execution logs of a Workflow application.</td><td>This parameter can be used by users with development capabilities to track the application's historical execution records</td></tr></tbody></table>

----------------------------------------

TITLE: Accessing ParameterExtractor Node in Python
DESCRIPTION: Shows how to access the ParameterExtractor node in a Dify Workflow. This node is used for extracting specific parameters from given text using LLM capabilities.

LANGUAGE: python
CODE:
self.session.workflow_node.parameter_extractor

----------------------------------------

TITLE: Stopping Docker Services and Backing Up Volumes in Bash
DESCRIPTION: These commands stop Docker services and create a compressed backup of the volumes directory.

LANGUAGE: bash
CODE:
docker compose down
tar -cvf volumes-$(date +%s).tgz volumes

----------------------------------------

TITLE: Backing up Docker Compose Configuration in Bash
DESCRIPTION: This command creates a backup of the docker-compose.yaml file with a timestamp.

LANGUAGE: bash
CODE:
cd docker
cp docker-compose.yaml docker-compose.yaml.$(date +%s).bak

----------------------------------------

TITLE: Stopping Docker Services and Backing Up Volumes in Bash
DESCRIPTION: These commands stop Docker services and create a compressed backup of the volumes directory.

LANGUAGE: bash
CODE:
docker compose down
tar -cvf volumes-$(date +%s).tgz volumes

----------------------------------------

TITLE: Stopping Docker Services and Backing Up Volumes in Bash
DESCRIPTION: These commands stop Docker services and create a compressed backup of the volumes directory.

LANGUAGE: bash
CODE:
docker compose down
tar -cvf volumes-$(date +%s).tgz volumes

----------------------------------------

TITLE: Accessing ParameterExtractor Node in Python
DESCRIPTION: Shows how to access the ParameterExtractor node in a Dify Workflow. This node is used for extracting specific parameters from given text using LLM capabilities.

LANGUAGE: python
CODE:
self.session.workflow_node.parameter_extractor

----------------------------------------

TITLE: Displaying Shortcut Key Table in Markdown
DESCRIPTION: This markdown table presents a list of shortcut keys for various actions in the Chatflow/Workflow orchestration page, including their Windows and macOS equivalents and explanations of their functions.

LANGUAGE: markdown
CODE:
| Windows          | macOS               | Explanation                    |
| ---------------- | ------------------- | ------------------------------ |
| Ctrl + C         | Command + C         | Copy nodes                     |
| Ctrl + V         | Command + V         | Paste nodes                    |
| Ctrl + D         | Command + D         | Duplicate nodes                |
| Ctrl + O         | Command + O         | Organize nodes                 |
| Ctrl + Z         | Command + Z         | Undo                           |
| Ctrl + Y         | Command + Y         | Redo                           |
| Ctrl + Shift + Z | Command + Shift + Z | Redo                           |
| Ctrl + 1         | Command + 1         | Canvas fits view               |
| Ctrl + (-)       | Command + (-)       | Canvas zooms out               |
| Ctrl + (=)       | Command + (=)       | Canvas zooms in                |
| Shift + 1        | Shift + 1           | Resets canvas view to 100%     |
| Shift + 5        | Shift + 5           | Scales canvas to 50%           |
| H                | H                   | Canvas toggles to Hand mode    |
| V                | V                   | Canvas toggles to Pointer mode |
| Delete/Backspace | Delete/Backspace    | Delete selected nodes          |
| Alt + R          | Option + R          | Workflow starts to run         |

----------------------------------------

TITLE: Setting Regex Delimiter for Chunking
DESCRIPTION: Example of using regex pattern as a chunk delimiter in Dify knowledge base. Demonstrates how text can be split into chunks using different regex patterns.

LANGUAGE: regex
CODE:
\n

----------------------------------------

TITLE: Implementing Token Counting in Python
DESCRIPTION: Defines the get_num_tokens method for token counting, with an option to use a GPT-2 tokenizer approximation.

LANGUAGE: python
CODE:
def get_num_tokens(
    self,
    model: str,
    credentials: dict,
    prompt_messages: list[PromptMessage],
    tools: Optional[list[PromptMessageTool]] = None
) -> int:
    """
    Get the number of tokens for the given prompt messages.
    """
    return 0

# Alternatively:
# return self._get_num_tokens_by_gpt2(text: str)

----------------------------------------

TITLE: Implementing Token Counting in Python
DESCRIPTION: Defines the get_num_tokens method for token counting, with an option to use a GPT-2 tokenizer approximation.

LANGUAGE: python
CODE:
def get_num_tokens(
    self,
    model: str,
    credentials: dict,
    prompt_messages: list[PromptMessage],
    tools: Optional[list[PromptMessageTool]] = None
) -> int:
    """
    Get the number of tokens for the given prompt messages.
    """
    return 0

# Alternatively:
# return self._get_num_tokens_by_gpt2(text: str)

----------------------------------------

TITLE: Configuring LLM Tool Parameters in YAML
DESCRIPTION: YAML configuration for an LLM tool, including parameters for prompt input and model selection. This configuration allows users to select their desired model in the UI.

LANGUAGE: yaml
CODE:
identity:
  name: llm
  author: Dify
  label:
    en_US: LLM
    zh_Hans: LLM
    pt_BR: LLM
description:
  human:
    en_US: A tool for invoking a large language model
    zh_Hans: 用于调用大型语言模型的工具
    pt_BR: A tool for invoking a large language model
  llm: A tool for invoking a large language model
parameters:
  - name: prompt
    type: string
    required: true
    label:
      en_US: Prompt string
      zh_Hans: 提示字符串
      pt_BR: Prompt string
    human_description:
      en_US: used for searching
      zh_Hans: 用于搜索网页内容
      pt_BR: used for searching
    llm_description: key words for searching
    form: llm
  - name: model
    type: model-selector
    scope: llm
    required: true
    label:
      en_US: Model
      zh_Hans: 使用的模型
      pt_BR: Model
    human_description:
      en_US: Model
      zh_Hans: 使用的模型
      pt_BR: Model
    llm_description: which Model to invoke
    form: form
extra:
  python:
    source: tools/llm.py

----------------------------------------

TITLE: Chatflow System Variables Example
DESCRIPTION: Code example showing system variable names and their usage in Chatflow applications

LANGUAGE: markdown
CODE:
sys.query           - String      - User input content
sys.files          - Array[File]  - User uploaded images
sys.dialogue_count  - Number      - Dialogue turn counter
sys.conversation_id - String      - Session identifier
sys.user_id         - String      - User identifier
sys.app_id          - String      - Application identifier
sys.workflow_id     - String      - Workflow identifier
sys.workflow_run_id - String      - Run identifier

----------------------------------------

TITLE: Defining API Response Structure for app.moderation.output in JSON
DESCRIPTION: This snippet outlines the structure of the API response for the app.moderation.output extension point. It includes a flag indicating if content was flagged, an action to take, an optional preset response, and potentially modified text.

LANGUAGE: json
CODE:
{
    "flagged": bool,  
    "action": string, 
    "preset_response": string,  
    "text": string  


----------------------------------------

TITLE: Styled Image Generation Prompt with Constraints
DESCRIPTION: An enhanced system prompt that includes style specifications and business logic constraints for handling inappropriate requests.

LANGUAGE: markdown
CODE:
## Task
Draw the specified content according to the user's prompt using stability_text2image, the picture is in anime style.

## Constraints
If the user requests content unrelated to drawing, reply: "Sorry, I don't understand what you're saying."

----------------------------------------

TITLE: Styled Image Generation Prompt with Constraints
DESCRIPTION: An enhanced system prompt that includes style specifications and business logic constraints for handling inappropriate requests.

LANGUAGE: markdown
CODE:
## Task
Draw the specified content according to the user's prompt using stability_text2image, the picture is in anime style.

## Constraints
If the user requests content unrelated to drawing, reply: "Sorry, I don't understand what you're saying."

----------------------------------------

TITLE: Invoking LLM Model in Python
DESCRIPTION: Demonstrates how to invoke an LLM model (specifically OpenAI's gpt-4o-mini) within a Dify plugin tool. It includes setting up the model configuration and handling the response stream.

LANGUAGE: python
CODE:
from collections.abc import Generator
from typing import Any

from dify_plugin import Tool
from dify_plugin.entities.model.llm import LLMModelConfig
from dify_plugin.entities.tool import ToolInvokeMessage
from dify_plugin.entities.model.message import SystemPromptMessage, UserPromptMessage

class LLMTool(Tool):
    def _invoke(self, tool_parameters: dict[str, Any]) -> Generator[ToolInvokeMessage]:
        response = self.session.model.llm.invoke(
            model_config=LLMModelConfig(
                provider='openai',
                model='gpt-4o-mini',
                mode='chat',
                completion_params={}
            ),
            prompt_messages=[
                SystemPromptMessage(
                    content='you are a helpful assistant'
                ),
                UserPromptMessage(
                    content=tool_parameters.get('query')
                )
            ],
            stream=True
        )

        for chunk in response:
            if chunk.delta.message:
                assert isinstance(chunk.delta.message.content, str)
                yield self.create_text_message(text=chunk.delta.message.content)

----------------------------------------

TITLE: Starting SearXNG Docker Container for Dify Integration
DESCRIPTION: This command starts a Docker container for SearXNG, mapping port 8081 to the container's port 8080 and mounting the local configuration directory. It's used to run SearXNG as a service for Dify integration.

LANGUAGE: bash
CODE:
cd dify
docker run --rm -d -p 8081:8080 -v "${PWD}/api/core/tools/provider/builtin/searxng/docker:/etc/searxng" searxng/searxng

----------------------------------------

TITLE: Defining Request Body Structure for app.moderation.output in JSON
DESCRIPTION: This snippet outlines the structure of the request body for the app.moderation.output extension point. It includes the point identifier, app_id, and the text to be moderated.

LANGUAGE: json
CODE:
{
    "point": "app.moderation.output", 
    "params": {
        "app_id": string,  
        "text": string  
    }
}

----------------------------------------

TITLE: Starting API Server
DESCRIPTION: Command to start the API server in debug mode.

LANGUAGE: Bash
CODE:
flask run --host 0.0.0.0 --port=5001 --debug

----------------------------------------

TITLE: Starting API Server
DESCRIPTION: Command to start the API server in debug mode.

LANGUAGE: Bash
CODE:
flask run --host 0.0.0.0 --port=5001 --debug

----------------------------------------

TITLE: Workflow Interface Method Specification in Python
DESCRIPTION: Method signature for invoking the workflow interface with parameters for app_id, inputs, response mode, and files.

LANGUAGE: python
CODE:
def invoke(
    self,
    app_id: str,
    inputs: dict,
    response_mode: Literal["streaming", "blocking"],
    files: list,
) -> Generator[dict, None, None] | dict:
    pass

----------------------------------------

TITLE: Configuring Prompt Variables in ComfyUI
DESCRIPTION: Template variables for defining positive and negative prompts in ComfyUI workflows. These variables are used to dynamically inject prompts from Dify into the ComfyUI generation process.

LANGUAGE: text
CODE:
{{positive_prompt}}
{{negative_prompt}}

----------------------------------------

TITLE: Adding Marketplace Dependencies to Bundle
DESCRIPTION: Command to append Marketplace plugin dependencies to a Bundle project, using organization/plugin:version pattern.

LANGUAGE: bash
CODE:
dify-plugin bundle append marketplace . --marketplace_pattern=langgenius/openai:0.0.1

----------------------------------------

TITLE: Defining API Response Structure for app.moderation.input in JSON
DESCRIPTION: This snippet outlines the structure of the API response for the app.moderation.input extension point. It includes a flag indicating if content was flagged, an action to take, an optional preset response, and potentially modified inputs and query.

LANGUAGE: json
CODE:
{
    "flagged": bool,  
    "action": string, 
    "preset_response": string,  
    "inputs": {  
        "var_1": "value_1",
        "var_2": "value_2",
        ...
    },
    "query": string | null  
}

----------------------------------------

TITLE: Adding Marketplace Dependencies to Bundle
DESCRIPTION: Command to append Marketplace plugin dependencies to a Bundle project, using organization/plugin:version pattern.

LANGUAGE: bash
CODE:
dify-plugin bundle append marketplace . --marketplace_pattern=langgenius/openai:0.0.1

----------------------------------------

TITLE: Adding Marketplace Dependencies to Bundle
DESCRIPTION: Command to append Marketplace plugin dependencies to a Bundle project, using organization/plugin:version pattern.

LANGUAGE: bash
CODE:
dify-plugin bundle append marketplace . --marketplace_pattern=langgenius/openai:0.0.1

----------------------------------------

TITLE: Accessing Workflow Interface in Python
DESCRIPTION: Entry point and method specification for accessing the workflow interface.

LANGUAGE: python
CODE:
self.session.app.workflow

----------------------------------------

TITLE: Configuring Dify Chatbot Button Options in JavaScript
DESCRIPTION: Configuration options for the Dify Chatbot Bubble Button including token settings, development mode, base URL, container properties, and drag functionality settings.

LANGUAGE: javascript
CODE:
window.difyChatbotConfig = {
    // Required, automatically generated by Dify
    token: 'YOUR_TOKEN',
    // Optional, default is false
    isDev: false,
    // Optional, when isDev is true, default is 'https://dev.udify.app', otherwise default is 'https://udify.app'
    baseUrl: 'YOUR_BASE_URL',
    // Optional, It can accept any valid HTMLElement attribute other than `id`, such as `style`, `className`, etc
    containerProps: {},
    // Optional, If or not the button is allowed to be dragged, default is `false`
    draggable: false,
    // Optional, The axis along which the button is allowed to be dragged, default is `both`, can be `x`, `y`, `both`
    dragAxis: 'both',
    // Optional, An object of inputs that set in the dify chatbot
    inputs: {
        // key is the variable name
        // e.g.
        // name: "NAME"
    }
}

----------------------------------------

TITLE: Upgrading Dify with Docker Compose
DESCRIPTION: Series of commands to upgrade Dify by stopping containers, pulling latest changes, and restarting.

LANGUAGE: bash
CODE:
cd dify/docker
docker compose down
git pull origin main
docker compose pull
docker compose up -d

----------------------------------------

TITLE: Accessing QuestionClassifier Node in Python
DESCRIPTION: Shows how to access the QuestionClassifier node in a Dify plugin. This node is used for classifying questions or text into predefined categories.

LANGUAGE: python
CODE:
self.session.workflow_node.question_classifier

----------------------------------------

TITLE: Accessing QuestionClassifier Node in Python
DESCRIPTION: Shows how to access the QuestionClassifier node in a Dify plugin. This node is used for classifying questions or text into predefined categories.

LANGUAGE: python
CODE:
self.session.workflow_node.question_classifier

----------------------------------------

TITLE: Chat Interface Method Specification in Python
DESCRIPTION: Method signature for invoking the chat interface with parameters for app_id, inputs, response mode, conversation_id, and files.

LANGUAGE: python
CODE:
def invoke(
    self,
    app_id: str,
    inputs: dict,
    response_mode: Literal["streaming", "blocking"],
    conversation_id: str,
    files: list,
) -> Generator[dict, None, None] | dict:
    pass

----------------------------------------

TITLE: Chat Model Text Generation Template
DESCRIPTION: Template for text generation applications using chat models. Similar to conversational template but optimized for paragraph-form inputs.

LANGUAGE: plaintext
CODE:
Use the following context as your learned knowledge, inside <context></context> XML tags.

<context>
{{#context#}}
</context>

When answering the user:
- If you don't know, just say that you don't know.
- If you are not sure, ask for clarification.
Avoid mentioning that you obtained the information from the context.
And answer according to the language of the user's question.
{{pre_prompt}}

----------------------------------------

TITLE: Checking Docker Container Status
DESCRIPTION: Command to display the status of all Docker containers managed by Docker Compose.

LANGUAGE: bash
CODE:
docker compose ps

----------------------------------------

TITLE: Defining ProviderConfigScope Enumeration for Configuration Scopes in Dify
DESCRIPTION: ProviderConfigScope enumerates the possible scopes for different provider configuration types, including model selectors, app selectors, and tool selectors used in plugin development.

LANGUAGE: python
CODE:
ProviderConfigScope = {
    "model-selector": ["all", "llm", "text-embedding", "rerank", "tts", "speech2text", "moderation", "vision"],
    "app-selector": ["all", "chat", "workflow", "completion"],
    "tool-selector": ["all", "plugin", "api", "workflow"]
}

----------------------------------------

TITLE: Defining ProviderConfigScope Enumeration for Configuration Scopes in Dify
DESCRIPTION: ProviderConfigScope enumerates the possible scopes for different provider configuration types, including model selectors, app selectors, and tool selectors used in plugin development.

LANGUAGE: python
CODE:
ProviderConfigScope = {
    "model-selector": ["all", "llm", "text-embedding", "rerank", "tts", "speech2text", "moderation", "vision"],
    "app-selector": ["all", "chat", "workflow", "completion"],
    "tool-selector": ["all", "plugin", "api", "workflow"]
}

----------------------------------------

TITLE: Defining Enums and Structs for Model Design in Markdown
DESCRIPTION: Specifies various enums and structures used in model design, including ModelType, ConfigurateMethod, ModelFeature, and others.

LANGUAGE: markdown
CODE:
### **ModelType**

* `llm`: Text generation model
* `text-embedding`: Text embedding model
* `rerank`: Rerank model
* `speech2text`: Speech to text
* `tts`: Text to speech
* `moderation`: Moderation

### **ConfigurateMethod**

* `predefined-model`: Predefined models Users only need to configure unified provider credentials to use predefined models under the provider.
* `customizable-model`: Custom models Users need to add credential configurations for each model.
* `fetch-from-remote`: Fetch from remote Similar to predefined-model configuration, only requires unified provider credentials, models are fetched from provider using credential information.

### **ModelFeature**

* `agent-thought`: Agent reasoning, generally models over 70B have chain-of-thought capability
* `vision`: Visual capability, i.e., image understanding
* `tool-call`: Tool calling
* `multi-tool-call`: Multiple tool calling
* `stream-tool-call`: Streaming tool calling

### **FetchFrom**

* `predefined-model`: Predefined models
* `fetch-from-remote`: Remote models

### **LLMMode**

* `completion`: Text completion
* `chat`: Conversation

----------------------------------------

TITLE: Text Completion Conversational Template
DESCRIPTION: Template for building conversational applications using text completion models. Includes conversation history handling and human-assistant interaction format.

LANGUAGE: Python
CODE:
Use the following context as your learned knowledge, inside <context></context> XML tags.

<context>
{{#context#}}
</context>

When answering the user:
- If you don't know, just say that you don't know.
- If you are not sure, ask for clarification.
Avoid mentioning that you obtained the information from the context.
And answer according to the language of the user's question.

{{pre_prompt}}

Here are the chat histories between human and assistant, inside <histories></histories> XML tags.

<histories>
{{#histories#}}
</histories>

H: {{#query#}}

A: 

----------------------------------------

TITLE: Starting Docker Containers with Docker Compose V2
DESCRIPTION: Command to start the Docker containers using Docker Compose version 2 in detached mode.

LANGUAGE: bash
CODE:
docker compose up -d

----------------------------------------

TITLE: Implementing Credential Validation in Python
DESCRIPTION: This Python snippet shows the structure for implementing the validate_credentials method in the AnthropicLargeLanguageModel class, used for validating model credentials.

LANGUAGE: python
CODE:
def validate_credentials(self, model: str, credentials: dict) -> None:
    """
    Validate model credentials

    :param model: model name
    :param credentials: model credentials
    :return:
    """

----------------------------------------

TITLE: Defining Provider Entity Structure in Markdown
DESCRIPTION: Specifies the structure and properties of the Provider entity, including provider identifier, display name, description, icons, supported model types, and credential schemas.

LANGUAGE: markdown
CODE:
### **Provider**

* `provider` (string): Provider identifier, e.g., openai
* `label` (object): Provider display name, i18n, supports en\_US (English) and zh\_Hans (Chinese)
  * `zh_Hans` (string) \[optional]: Chinese label, defaults to en\_US if not set
  * `en_US` (string): English label
* `description` (object) \[optional]: Provider description, i18n
  * `zh_Hans` (string) \[optional]: Chinese description
  * `en_US` (string): English description
* `icon_small` (string) \[optional]: Provider small icon, stored in \_assets directory
  * `zh_Hans` (string) \[optional]: Chinese icon
  * `en_US` (string): English icon
* `icon_large` (string) \[optional]: Provider large icon, stored in \_assets directory
  * `zh_Hans` (string) \[optional]: Chinese icon
  * `en_US` (string): English icon
* `background` (string) \[optional]: Background color value, e.g., #FFFFFF, uses frontend default if empty
* `help` (object) \[optional]: Help information
  * `title` (object): Help title, i18n
    * `zh_Hans` (string) \[optional]: Chinese title
    * `en_US` (string): English title
  * `url` (object): Help link, i18n
    * `zh_Hans` (string) \[optional]: Chinese link
    * `en_US` (string): English link
* `supported_model_types` (array\[ModelType]): Supported model types
* `configurate_methods` (array\[ConfigurateMethod]): Configuration methods
* `provider_credential_schema` (\[ProviderCredentialSchema]): Provider credential specifications
* `model_credential_schema` (\[ModelCredentialSchema]): Model credential specifications

----------------------------------------

TITLE: Defining Basic JSON Schema Template
DESCRIPTION: A generic JSON Schema template demonstrating basic structure with various field types including strings, numbers, arrays, and nested objects.

LANGUAGE: json
CODE:
{
    "name": "template_schema",
    "description": "A generic template for JSON Schema",
    "strict": true,
    "schema": {
        "type": "object",
        "properties": {
            "field1": {
                "type": "string",
                "description": "Description of field1"
            },
            "field2": {
                "type": "number",
                "description": "Description of field2"
            },
            "field3": {
                "type": "array",
                "description": "Description of field3",
                "items": {
                    "type": "string"
                }
            },
            "field4": {
                "type": "object",
                "description": "Description of field4",
                "properties": {
                    "subfield1": {
                        "type": "string",
                        "description": "Description of subfield1"
                    }
                },
                "required": ["subfield1"],
                "additionalProperties": false
            }
        },
        "required": ["field1", "field2", "field3", "field4"],
        "additionalProperties": false
    }
}

----------------------------------------

TITLE: Cloning Dify Repository in Bash
DESCRIPTION: Command to clone the Dify source code repository from GitHub, specifying a particular version tag.

LANGUAGE: bash
CODE:
git clone https://github.com/langgenius/dify.git --branch 0.15.3

----------------------------------------

TITLE: Configuring Agent Strategy in Manifest YAML
DESCRIPTION: Basic manifest configuration for adding Agent strategies to a plugin, defining the Agent provider location.

LANGUAGE: yaml
CODE:
version: 0.0.2
type: plugin
author: "langgenius"
name: "agent"
plugins:
  agent_strategies:
    - "provider/agent.yaml"

----------------------------------------

TITLE: Configuring Agent Strategy in Manifest YAML
DESCRIPTION: Basic manifest configuration for adding Agent strategies to a plugin, defining the Agent provider location.

LANGUAGE: yaml
CODE:
version: 0.0.2
type: plugin
author: "langgenius"
name: "agent"
plugins:
  agent_strategies:
    - "provider/agent.yaml"

----------------------------------------

TITLE: Installing Dify Community Edition with Docker in Bash
DESCRIPTION: Series of commands to clone the Dify repository, set up environment variables, and start the Docker containers.

LANGUAGE: bash
CODE:
git clone https://github.com/langgenius/dify.git
cd dify/docker
cp .env.example .env
docker compose up -d  # Use `docker-compose up -d` if running Docker Compose V1

----------------------------------------

TITLE: Mathematical Reasoning JSON Schema Example
DESCRIPTION: Schema definition for capturing mathematical reasoning steps and final answer in a structured format.

LANGUAGE: json
CODE:
{
    "name": "math_reasoning",
    "description": "Records steps and final answer for mathematical reasoning",
    "strict": true,
    "schema": {
        "type": "object",
        "properties": {
            "steps": {
                "type": "array",
                "description": "Array of reasoning steps",
                "items": {
                    "type": "object",
                    "properties": {
                        "explanation": {
                            "type": "string",
                            "description": "Explanation of the reasoning step"
                        },
                        "output": {
                            "type": "string",
                            "description": "Output of the reasoning step"
                        }
                    },
                    "required": ["explanation", "output"],
                    "additionalProperties": false
                }
            },
            "final_answer": {
                "type": "string",
                "description": "The final answer to the mathematical problem"
            }
        },
        "additionalProperties": false,
        "required": ["steps", "final_answer"]
    }
}

----------------------------------------

TITLE: Frontend Environment Configuration
DESCRIPTION: Sample environment configuration for the frontend web application

LANGUAGE: plaintext
CODE:
NEXT_PUBLIC_DEPLOY_ENV=DEVELOPMENT
NEXT_PUBLIC_EDITION=SELF_HOSTED
NEXT_PUBLIC_API_PREFIX=http://localhost:5001/console/api
NEXT_PUBLIC_PUBLIC_API_PREFIX=http://localhost:5001/api

# SENTRY
NEXT_PUBLIC_SENTRY_DSN=
NEXT_PUBLIC_SENTRY_ORG=
NEXT_PUBLIC_SENTRY_PROJECT=

----------------------------------------

TITLE: Starting Middleware Services
DESCRIPTION: Commands to configure and start PostgreSQL, Redis, and Weaviate services using Docker Compose

LANGUAGE: bash
CODE:
cd docker
cp middleware.env.example middleware.env
docker compose -f docker-compose.middleware.yaml up -d

----------------------------------------

TITLE: Encryption Key Reset Commands
DESCRIPTION: Commands for resetting encryption key pairs in both Docker Compose and source code deployments.

LANGUAGE: bash
CODE:
docker exec -it docker-api-1 flask reset-encrypt-key-pair

LANGUAGE: bash
CODE:
flask reset-encrypt-key-pair

----------------------------------------

TITLE: Math Tutor Prompt Example
DESCRIPTION: Sample prompt for the mathematical reasoning JSON schema implementation.

LANGUAGE: text
CODE:
You are a helpful math tutor. You will be provided with a math problem,
and your goal will be to output a step by step solution, along with a final answer.
For each step, just provide the output as an equation use the explanation field to detail the reasoning.

----------------------------------------

TITLE: Checking Docker Container Status in Bash
DESCRIPTION: This command displays the status of running Docker containers, including their IDs, images, and names.

LANGUAGE: bash
CODE:
docker ps

----------------------------------------

TITLE: API Server Configuration
DESCRIPTION: Steps for configuring the API server environment, including setting up environment variables and generating secret key

LANGUAGE: bash
CODE:
cd api
cp .env.example .env
awk -v key="$(openssl rand -base64 42)" '/^SECRET_KEY=/ {sub(/=.*/, "=" key)} 1' .env > temp_env && mv temp_env .env

----------------------------------------

TITLE: Checking Docker Container Status in Bash
DESCRIPTION: This command displays the status of running Docker containers, including their IDs, images, and names.

LANGUAGE: bash
CODE:
docker ps

----------------------------------------

TITLE: Displaying Workflow App System Variables in Markdown
DESCRIPTION: A markdown table showing system variables available in Workflow type applications, including their names, data types, descriptions, and remarks.

LANGUAGE: markdown
CODE:
<table><thead><tr><th>Variables name</th><th>Data Type</th><th width="267">Description</th><th>Remark</th></tr></thead><tbody><tr><td><p><code>sys.files</code></p><p><code>[LEGACY]</code></p></td><td>Array[File]</td><td>File Parameter: Stores images uploaded by users</td><td>The image upload function needs to be enabled in the 'Features' section in the upper right corner of the application orchestration page</td></tr><tr><td><code>sys.user_id</code></td><td>String</td><td>User ID: A unique identifier automatically assigned by the system to each user when they use a workflow application. It is used to distinguish different users</td><td></td></tr><tr><td><code>sys.app_id</code></td><td>String</td><td>App ID: A unique identifier automatically assigned by the system to each App. This parameter is used to record the basic information of the current application. </td><td>This parameter is used to differentiate and locate distinct Workflow applications for users with development capabilities</td></tr><tr><td><code>sys.workflow_id</code></td><td>String</td><td>Workflow ID: This parameter records information about all nodes information in the current Workflow application.</td><td>This parameter can be used by users with development capabilities to track and record information about the nodes contained within a Workflow</td></tr><tr><td><code>sys.workflow_run_id</code></td><td>String</td><td>Workflow Run ID: Used to record the runtime status and execution logs of a Workflow application.</td><td>This parameter can be used by users with development capabilities to track the application's historical execution records</td></tr></tbody></table>

----------------------------------------

TITLE: Configuring Ollama Service on Linux with Systemd
DESCRIPTION: Commands to edit the Ollama systemd service, set environment variables, and restart the service on Linux.

LANGUAGE: bash
CODE:
systemctl edit ollama.service
# Add the following line under [Service]:
# Environment="OLLAMA_HOST=0.0.0.0"
systemctl daemon-reload
systemctl restart ollama

----------------------------------------

TITLE: Python Environment Setup
DESCRIPTION: Commands for installing and setting up Python 3.12 using pyenv

LANGUAGE: bash
CODE:
pyenv install 3.12
pyenv global 3.12

----------------------------------------

TITLE: Downloading Pastel Mix Model
DESCRIPTION: Command to clone the Pastel Mix model from HuggingFace using git lfs.

LANGUAGE: bash
CODE:
git clone https://huggingface.co/JamesFlare/pastel-mix

----------------------------------------

TITLE: Converting Array to Text using Django Template in Template Node
DESCRIPTION: This code snippet shows how to convert an array of article sections into a single text string using a Django template in a Template Node.

LANGUAGE: django
CODE:
{{ articleSections | join("/n") }}

----------------------------------------

TITLE: Basic Dify Chatbot iFrame Integration
DESCRIPTION: Basic iFrame code snippet for embedding a Dify chatbot into a Wix website. Includes width and height settings with microphone permissions.

LANGUAGE: bash
CODE:
<iframe src="https://udify.app/chatbot/ez1pf83HVV3JgWO4" style="width: 100%; height: 100%; min-height: 700px" frameborder="0" allow="microphone"></iframe>

----------------------------------------

TITLE: Cloning Dify Repository
DESCRIPTION: Command to clone the Dify repository from GitHub

LANGUAGE: bash
CODE:
git clone https://github.com/langgenius/dify.git

----------------------------------------

TITLE: Creating Variable Message in Python for Dify Tool
DESCRIPTION: Method to create a variable message for non-streaming output variables. Later values override earlier ones.

LANGUAGE: python
CODE:
def create_variable_message(self, variable_name: str, variable_value: Any) -> ToolInvokeMessage:
    pass

----------------------------------------

TITLE: Converting Array to Text using Python in Code Node
DESCRIPTION: This code snippet demonstrates how to convert an array of article sections into a single text string using a Python function in a Code Node.

LANGUAGE: python
CODE:
def main(articleSections: list):
    data = articleSections
    return {
        "result": "/n".join(data)
    }

----------------------------------------

TITLE: Styled Dify Chatbot iFrame with Border
DESCRIPTION: Enhanced iFrame code that adds a black border to the chatbot interface with adjusted dimensions.

LANGUAGE: bash
CODE:
<iframe src="https://udify.app/chatbot/ez1pf83HVV3JgWO4" style="width: 80%; height: 80%; min-height: 500px; border: 2px solid #000;" frameborder="0" allow="microphone"></iframe>

----------------------------------------

TITLE: Frontend Schema Configuration - Weather Search
DESCRIPTION: JSON schema defining the frontend form components for the Weather Search tool, including temperature unit selection and localization.

LANGUAGE: json
CODE:
{
    "label": {
        "en-US": "Weather Search",
        "zh-Hans": "天气查询"
    },
    "form_schema": [
        {
            "type": "select",
            "label": {
                "en-US": "Temperature Unit",
                "zh-Hans": "温度单位"
            },
            "variable": "temperature_unit",
            "required": true,
            "options": [
                {
                    "label": {
                        "en-US": "Fahrenheit",
                        "zh-Hans": "华氏度"
                    },
                    "value": "fahrenheit"
                },
                {
                    "label": {
                        "en-US": "Centigrade",
                        "zh-Hans": "摄氏度"
                    },
                    "value": "centigrade"
                }
            ],
            "default": "centigrade",
            "placeholder": "Please select temperature unit"
        }
    ]
}

----------------------------------------

TITLE: Accessing Tool Session in Python
DESCRIPTION: Basic entry point for accessing tool functionality in Dify plugins

LANGUAGE: python
CODE:
self.session.tool

----------------------------------------

TITLE: Condition Types for Workflow Branching
DESCRIPTION: List of available condition types that can be used in workflow branching logic. These conditions can be applied to variables to determine execution paths.

LANGUAGE: markdown
CODE:
* Contains
* Not contains
* Starts with
* Ends with
* Is
* Is not
* Is empty
* Is not empty

----------------------------------------

TITLE: Positioned Dify Chatbot iFrame
DESCRIPTION: iFrame code that positions the chatbot in the bottom right corner of the webpage with fixed positioning.

LANGUAGE: bash
CODE:
<iframe src="https://udify.app/chatbot/ez1pf83HVV3JgWO4" style="width: 100%; height: 100%; min-height: 700px; position: fixed; bottom: 20px; right: 20px;" frameborder="0" allow="microphone"></iframe>

----------------------------------------

TITLE: Handling OpenAI Rate Limit Error in JSON
DESCRIPTION: This JSON snippet demonstrates an error message received when the OpenAI API rate limit is exceeded. It includes details about the specific limit and suggestions for resolving the issue.

LANGUAGE: json
CODE:
{
  "error": "Rate limit reached for default-gpt-3.5-turbo in organization org-wDrZCxxxxxxxxxissoZb on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method."
}

----------------------------------------

TITLE: Running Pre-built Dify Frontend Docker Container
DESCRIPTION: Pulls and runs the pre-built Dify frontend container from DockerHub with port 3000 exposed and environment variables configured for console and app URLs.

LANGUAGE: bash
CODE:
docker run -it -p 3000:3000 -e CONSOLE_URL=http://127.0.0.1:5001 -e APP_URL=http://127.0.0.1:5001 langgenius/dify-web:latest

----------------------------------------

TITLE: Starting Sandbox Service with Docker Compose
DESCRIPTION: Command to start the sandbox service for local deployment of Dify using Docker Compose.

LANGUAGE: bash
CODE:
docker-compose -f docker-compose.middleware.yaml up -d

----------------------------------------

TITLE: Installing QingLong Panel Repository for Dify Scheduler
DESCRIPTION: Command to add the Dify Scheduler repository to QingLong Panel. This subscription command specifies the repository URL and filters for specific file patterns.

LANGUAGE: bash
CODE:
ql repo https://github.com/leochen-g/dify-schedule.git "ql_" "utils" "sdk"

----------------------------------------

TITLE: Invoking Workflow Tools in Python
DESCRIPTION: Method for invoking workflow-based tools, requiring provider ID and tool name specified during tool creation.

LANGUAGE: python
CODE:
def invoke_workflow_tool(
    self, provider: str, tool_name: str, parameters: dict[str, Any]
) -> Generator[ToolInvokeMessage, None, None]:
    pass

----------------------------------------

TITLE: Unauthorized File Access Example in Python
DESCRIPTION: Example of potentially dangerous code that attempts to read a sensitive system file, which would be blocked by security measures.

LANGUAGE: python
CODE:
def main() -> dict:
    return {
        "result": open("/etc/passwd").read(),
    }

----------------------------------------

TITLE: Calculating Variance in Python
DESCRIPTION: Demonstrates how to perform mathematical calculations, specifically calculating the variance of an array, using Python in a Dify code node.

LANGUAGE: python
CODE:
def main(x: list) -> float:
    return {
        # Note to declare 'result' in the output variables
        'result': sum([(i - sum(x) / len(x)) ** 2 for i in x]) / len(x)
    }

----------------------------------------

TITLE: Model Configuration YAML Example
DESCRIPTION: Example YAML configuration for Claude-3.5-sonnet model defining model properties, features, and parameter rules.

LANGUAGE: yaml
CODE:
model: claude-3-5-sonnet-20240620
label:
  en_US: claude-3-5-sonnet-20240620
model_type: llm
features:
  - agent-thought
  - vision
  - tool-call
  - stream-tool-call
  - document
model_properties:
  mode: chat
  context_size: 200000
parameter_rules:
  - name: temperature
    use_template: temperature
  - name: top_p
    use_template: top_p
  - name: top_k
    label:
      zh_Hans: 
      en_US: Top k
    type: int
    help:
      zh_Hans: 
      en_US: Only sample from the top K options for each subsequent token.
    required: false
  - name: max_tokens
    use_template: max_tokens
    required: true
    default: 8192
    min: 1
    max: 8192
  - name: response_format
    use_template: response_format
pricing:
  input: '3.00'
  output: '15.00'
  unit: '0.000001'
  currency: USD

----------------------------------------

TITLE: Setting AI Chatbot Opening Remarks in Dify
DESCRIPTION: This snippet demonstrates how to configure the opening remarks for the AI chatbot, introducing itself as Bob and inviting users to discuss Dify-related topics.

LANGUAGE: markdown
CODE:
> Opening remarks：Hey \{{User\_name\}}, I'm Bob☀️, the first AI member of Dify. You can discuss with me any questions related to Dify products, team, and even LLMOps.

----------------------------------------

TITLE: Invoking Custom API Tools in Python
DESCRIPTION: Method for invoking custom API tools where provider is the tool ID and tool_name is either the OpenAPI operation_id or Dify-generated tool name.

LANGUAGE: python
CODE:
def invoke_api_tool(
    self, provider: str, tool_name: str, parameters: dict[str, Any]
) -> Generator[ToolInvokeMessage, None, None]:
    pass

----------------------------------------

TITLE: Model Configuration YAML Example
DESCRIPTION: Example YAML configuration for Claude-3.5-sonnet model defining model properties, features, and parameter rules.

LANGUAGE: yaml
CODE:
model: claude-3-5-sonnet-20240620
label:
  en_US: claude-3-5-sonnet-20240620
model_type: llm
features:
  - agent-thought
  - vision
  - tool-call
  - stream-tool-call
  - document
model_properties:
  mode: chat
  context_size: 200000
parameter_rules:
  - name: temperature
    use_template: temperature
  - name: top_p
    use_template: top_p
  - name: top_k
    label:
      zh_Hans: 
      en_US: Top k
    type: int
    help:
      zh_Hans: 
      en_US: Only sample from the top K options for each subsequent token.
    required: false
  - name: max_tokens
    use_template: max_tokens
    required: true
    default: 8192
    min: 1
    max: 8192
  - name: response_format
    use_template: response_format
pricing:
  input: '3.00'
  output: '15.00'
  unit: '0.000001'
  currency: USD

----------------------------------------

TITLE: Workflow/Chatflow Data Structure Documentation
DESCRIPTION: Data structure mapping showing the relationship between Workflow/Chatflow fields and their corresponding Opik trace fields, including metadata fields.

LANGUAGE: markdown
CODE:
| Workflow                            | Opik Trace                  |
| ----------------------------------- | --------------------------- |
| workflow_app_log_id/workflow_run_id | id                          |
| user_session_id                     | - placed in metadata        |
| workflow\_{id}                      | name                        |
| start_time                          | start_time                  |
| end_time                            | end_time                    |
| inputs                              | inputs                      |
| outputs                             | outputs                     |
| Model token consumption             | usage_metadata              |
| metadata                            | metadata                    |
| error                               | error                       |
| \[workflow]                         | tags                        |
| "conversation_id/none for workflow" | conversation_id in metadata |

----------------------------------------

TITLE: Configuring MidJourney Prompt Template
DESCRIPTION: Template structure for generating MidJourney prompts that includes photo description elements, camera settings, composition details, and photographer references. Uses variables for image proportion and version selection.

LANGUAGE: text
CODE:
Color photo of the theme\nIntricate patterns\nStark contrasts\nEnvironmental description\nCamera model\nLens focal length description\nComposition description\nFour master photographers\n{{proportion}}\n{{version}}

----------------------------------------

TITLE: Accessing Chat Interface in Python
DESCRIPTION: Entry point and method specification for accessing the chat interface. Supports both streaming and blocking response modes.

LANGUAGE: python
CODE:
self.session.app.chat

----------------------------------------

TITLE: Configuring Xinference Vendor in YAML
DESCRIPTION: Defines the vendor configuration for Xinference in YAML format, including supported model types, credential schema, and UI elements.

LANGUAGE: yaml
CODE:
provider: xinference
label:
  en_US: Xorbits Inference
icon_small:
  en_US: icon_s_en.svg
icon_large:
  en_US: icon_l_en.svg
help:
  title:
    en_US: How to deploy Xinference
    zh_Hans: 如何部署 Xinference
  url:
    en_US: https://github.com/xorbitsai/inference
supported_model_types:
- llm
- text-embedding
- rerank
configurate_methods:
- customizable-model
provider_credential_schema:
  credential_form_schemas:
  - variable: model_type
    type: select
    label:
      en_US: Model type
      zh_Hans: 模型类型
    required: true
    options:
    - value: text-generation
      label:
        en_US: Language Model
        zh_Hans: 语言模型
    - value: embeddings
      label:
        en_US: Text Embedding
    - value: reranking
      label:
        en_US: Rerank
  - variable: model_name
    type: text-input
    label:
      en_US: Model name
      zh_Hans: 模型名称
    required: true
    placeholder:
      zh_Hans: 填写模型名称
      en_US: Input model name
  - variable: server_url
    label:
      zh_Hans: 服务器URL
      en_US: Server url
    type: text-input
    required: true
    placeholder:
      zh_Hans: 在此输入Xinference的服务器地址，如 https://example.com/xxx
      en_US: Enter the url of your Xinference, for example https://example.com/xxx
  - variable: model_uid
    label:
      zh_Hans: 模型 UID
      en_US: Model uid
    type: text-input
    required: true
    placeholder:
      zh_Hans: 在此输入你的 Model UID
      en_US: Enter the model uid

----------------------------------------

TITLE: Creating Document from File via API
DESCRIPTION: API endpoint for creating a new document by uploading a file to an existing knowledge base. Supports various file formats and custom processing rules.

LANGUAGE: bash
CODE:
curl --location --request POST 'https://api.dify.ai/v1/datasets/{dataset_id}/document/create-by-file' \
--header 'Authorization: Bearer {api_key}' \
--form 'data="{\"indexing_technique\":\"high_quality\",\"process_rule\":{\"rules\":{\"pre_processing_rules\":[{\"id\":\"remove_extra_spaces\",\"enabled\":true},{\"id\":\"remove_urls_emails\",\"enabled\":true}],\"segmentation\":{\"separator\":\"###\",\"max_tokens\":500}},\"mode\":\"custom\"}}";type=text/plain' \
--form 'file=@"/path/to/file"'

----------------------------------------

TITLE: Handling Anthropic Model Parameter Error in JSON
DESCRIPTION: This JSON snippet shows an error message received when attempting to switch models in the application. It indicates an invalid temperature parameter for the Anthropic model.

LANGUAGE: json
CODE:
{
  "Anthropic": {
    "Error code": 400,
    "error": {
      "type": "invalid request error",
      "message": "temperature: range: -1 or 0..1"
    }
  }
}

----------------------------------------

TITLE: Completion Interface Method Specification in Python
DESCRIPTION: Method signature for invoking the completion interface with parameters for app_id, inputs, response mode, and files.

LANGUAGE: python
CODE:
def invoke(
    self,
    app_id: str,
    inputs: dict,
    response_mode: Literal["streaming", "blocking"],
    files: list,
) -> Generator[dict, None, None] | dict:
    pass

----------------------------------------

TITLE: Configuring Nginx Ports for Dify
DESCRIPTION: This snippet shows how to modify the Nginx configuration in the .env file to customize the access ports for Dify.

LANGUAGE: json
CODE:
EXPOSE_NGINX_PORT=80
EXPOSE_NGINX_SSL_PORT=443

----------------------------------------

TITLE: Configuring Nginx Ports for Dify
DESCRIPTION: This snippet shows how to modify the Nginx configuration in the .env file to customize the access ports for Dify.

LANGUAGE: json
CODE:
EXPOSE_NGINX_PORT=80
EXPOSE_NGINX_SSL_PORT=443

----------------------------------------

TITLE: Markdown Documentation for Dify Configuration
DESCRIPTION: Structured documentation covering the setup and configuration of indexing methods and retrieval settings in Dify's knowledge base system, including hint blocks and tab-based content organization.

LANGUAGE: markdown
CODE:
{% hint style="info" %}
**Note**: The original **Q\&A mode (Available only in the Community Edition)** is now an optional feature under the High-Quality Indexing Method.
{% endhint %}

----------------------------------------

TITLE: Configuring Environment Variables for Plugin Verification in Dify
DESCRIPTION: Configuration setting to disable plugin signature verification in Dify's .env file. This allows installation of unverified plugins that are not listed in the Dify Marketplace.

LANGUAGE: env
CODE:
FORCE_VERIFYING_SIGNATURE=false

----------------------------------------

TITLE: UI Generator Prompt Example
DESCRIPTION: Sample prompt for the UI generation JSON schema implementation.

LANGUAGE: text
CODE:
You are a UI generator AI. Convert the user input into a UI.

----------------------------------------

TITLE: Upgrading Dify version using Git and Docker Compose
DESCRIPTION: Fetches the latest version, checks out the 1.0.0 branch, updates the environment configuration, and starts the new Docker containers.

LANGUAGE: bash
CODE:
git fetch origin
git checkout 1.0.0 # Switch to 1.0.0 branch
cd docker
nano .env # Modify environment configuration file to sync with .env.example file
docker compose -f docker-compose.yaml up -d

----------------------------------------

TITLE: Importing DSL File via URL in Dify
DESCRIPTION: This code snippet demonstrates the URL format for importing a DSL file into Dify. It allows users to create an application by providing a link to a DSL file hosted online.

LANGUAGE: url
CODE:
https://example.com/your_dsl.yml

----------------------------------------

TITLE: Cloud Storage Migration Commands
DESCRIPTION: Commands for migrating files from local storage to cloud storage in both deployment types.

LANGUAGE: bash
CODE:
flask upload-private-key-file-to-cloud-storage
flask upload-local-files-to-cloud-storage

LANGUAGE: bash
CODE:
docker exec -it docker-api-1 flask upload-private-key-file-to-cloud-storage
docker exec -it docker-api-1 flask upload-local-files-to-cloud-storage

----------------------------------------

TITLE: English Response Pre-prompt Template
DESCRIPTION: Modified pre-prompt template that enforces English language responses from the LLM

LANGUAGE: markdown
CODE:
When answering the user:
- If you don't know, just say that you don't know.
- If you don't know or are not sure, ask for clarification.
Avoid mentioning that you obtained the information from the context.
And answer according to the language English.

----------------------------------------

TITLE: Structure Extraction Prompt for LLM Node
DESCRIPTION: A prompt template for analyzing and extracting the structure of uploaded articles. The prompt instructs the LLM to perform detailed analysis of article structure and content organization.

LANGUAGE: markdown
CODE:
Read the following article content and perform the task
{{Result variable of the document extractor}}
# Task

- **Main Objective**: Thoroughly analyze the structure of the article.
- **Objective**: Detail the content of each part of the article.
- **Requirements**: Analyze as detailed as possible.
- **Restrictions**: No specific format restrictions, but the analysis must be organized and logical.
- **Expected Output**: A detailed analysis of the article structure, including the main content and role of each part.

# Reasoning Order

- **Reasoning Part**: By carefully reading the article, identify and analyze its structure.
- **Conclusion Part**: Provide specific content and role for each part.

# Output Format

- **Analysis Format**: Each part should be listed in a headline format, followed by a detailed explanation of that part's content.
- **Structure Form**: Markdown, to enhance readability.
- **Specific Description**: The content and role of each part, including but not limited to the introduction, body, conclusion, citations, etc.

----------------------------------------

TITLE: Running Locally Built Dify Frontend Docker Container
DESCRIPTION: Runs the locally built Dify frontend Docker container with port 3000 exposed and environment variables configured for console and app URLs.

LANGUAGE: bash
CODE:
docker run -it -p 3000:3000 -e CONSOLE_URL=http://127.0.0.1:5001 -e APP_URL=http://127.0.0.1:5001 dify-web

----------------------------------------

TITLE: Mathematical Reasoning Schema Example
DESCRIPTION: JSON Schema definition for mathematical problem-solving with step-by-step reasoning and final answer structure.

LANGUAGE: json
CODE:
{
    "name": "math_reasoning",
    "description": "Records steps and final answer for mathematical reasoning",
    "strict": true,
    "schema": {
        "type": "object",
        "properties": {
            "steps": {
                "type": "array",
                "description": "Array of reasoning steps",
                "items": {
                    "type": "object",
                    "properties": {
                        "explanation": {
                            "type": "string",
                            "description": "Explanation of the reasoning step"
                        },
                        "output": {
                            "type": "string",
                            "description": "Output of the reasoning step"
                        }
                    },
                    "required": ["explanation", "output"],
                    "additionalProperties": false
                }
            },
            "final_answer": {
                "type": "string",
                "description": "The final answer to the mathematical problem"
            }
        },
        "additionalProperties": false,
        "required": ["steps", "final_answer"]
    }
}

----------------------------------------

TITLE: Example Few-Shot Prompt in Markdown
DESCRIPTION: Demonstrates how to structure a few-shot prompt with Human and Assistant interactions for color-related questions

LANGUAGE: markdown
CODE:
Human1: What color is the sky?
Assistant1: The sky is blue.
Human1: What color is fire?
Assistant1: Fire is red.
Human1: What color is soil?
Assistant1: 

----------------------------------------

TITLE: Customizing Dify Chatbot Button Styles with CSS Variables
DESCRIPTION: CSS variables available for customizing the appearance of the Dify Chatbot Bubble Button including position, size, colors, and hover effects.

LANGUAGE: css
CODE:
/* Button distance to bottom, default is `1rem` */
--dify-chatbot-bubble-button-bottom

/* Button distance to right, default is `1rem` */
--dify-chatbot-bubble-button-right

/* Button distance to left, default is `unset` */
--dify-chatbot-bubble-button-left

/* Button distance to top, default is `unset` */
--dify-chatbot-bubble-button-top

/* Button background color, default is `#155EEF` */
--dify-chatbot-bubble-button-bg-color

/* Button width, default is `50px` */
--dify-chatbot-bubble-button-width

/* Button height, default is `50px` */
--dify-chatbot-bubble-button-height

/* Button border radius, default is `25px` */
--dify-chatbot-bubble-button-border-radius

/* Button box shadow, default is `rgba(0, 0, 0, 0.2) 0px 4px 8px 0px)` */
--dify-chatbot-bubble-button-box-shadow

/* Button hover transform, default is `scale(1.1)` */
--dify-chatbot-bubble-button-hover-transform

----------------------------------------

TITLE: Starting Docker Containers with Docker Compose V1
DESCRIPTION: Command to start the Docker containers using Docker Compose version 1 in detached mode.

LANGUAGE: bash
CODE:
docker-compose up -d

----------------------------------------

TITLE: Response Syntax Example
DESCRIPTION: Example of a successful API response showing retrieved records with content, relevance scores, titles and metadata

LANGUAGE: json
CODE:
HTTP/1.1 200
Content-type: application/json
{
    "records": [{
                    "metadata": {
                            "path": "s3://dify/knowledge.txt",
                            "description": "dify knowledge document"
                    },
                    "score": 0.98,
                    "title": "knowledge.txt",
                    "content": "This is the document for external knowledge."
            },
            {
                    "metadata": {
                            "path": "s3://dify/introduce.txt",
                            "description": "dify introduce"
                    },
                    "score": 0.66,
                    "title": "introduce.txt",
                    "content": "The Innovation Engine for GenAI Applications"
            }
    ]
}

----------------------------------------

TITLE: Starting Worker Service (Linux/MacOS)
DESCRIPTION: Command to start the Celery worker service for asynchronous tasks on Linux or MacOS.

LANGUAGE: Bash
CODE:
celery -A app.celery worker -P gevent -c 1 -Q dataset,generation,mail,ops_trace --loglevel INFO

----------------------------------------

TITLE: Starting Dify with Docker Compose
DESCRIPTION: Commands to navigate to the Dify docker directory, copy the environment file, and start the Dify services using Docker Compose.

LANGUAGE: bash
CODE:
cd dify/docker
cp .env.example .env
docker compose up -d

----------------------------------------

TITLE: Copying Environment Configuration in Bash
DESCRIPTION: Command to create a copy of the example environment configuration file for local use.

LANGUAGE: bash
CODE:
cp .env.example .env

----------------------------------------

TITLE: Configuring Environment Variables for Notion Internal Integration in Dify
DESCRIPTION: This code snippet shows the environment variables needed to configure an internal Notion integration in Dify. It specifies the integration type and the internal secret key.

LANGUAGE: plaintext
CODE:
NOTION_INTEGRATION_TYPE = internal or NOTION_INTEGRATION_TYPE = public
NOTION_INTERNAL_SECRET=you-internal-secret

----------------------------------------

TITLE: Invoking ParameterExtractor Node in Python
DESCRIPTION: Demonstrates the invocation of the ParameterExtractor node. This method extracts parameters from a query string using specified model configurations and optional instructions.

LANGUAGE: python
CODE:
def invoke(
    self,
    parameters: list[ParameterConfig],
    model: ModelConfig,
    query: str,
    instruction: str = "",
) -> NodeResponse
    pass

----------------------------------------

TITLE: Running Database Migrations
DESCRIPTION: Commands to run database migrations for the API service.

LANGUAGE: Bash
CODE:
poetry shell
flask db upgrade

----------------------------------------

TITLE: Invoking ParameterExtractor Node in Python
DESCRIPTION: Demonstrates the invocation of the ParameterExtractor node. This method extracts parameters from a query string using specified model configurations and optional instructions.

LANGUAGE: python
CODE:
def invoke(
    self,
    parameters: list[ParameterConfig],
    model: ModelConfig,
    query: str,
    instruction: str = "",
) -> NodeResponse
    pass

----------------------------------------

TITLE: Accessing Dify Web Interface
DESCRIPTION: These commands show how to access the Dify web interface after installation, either through a domain or IP and port.

LANGUAGE: bash
CODE:
# If you have set domain
http://yourdomain/

# If you choose to access through `IP+Port`
http://your_server_ip:8088/

----------------------------------------

TITLE: Configuring Environment Variables for Notion Public Integration in Dify
DESCRIPTION: This code snippet demonstrates the environment variables required to set up a public Notion integration in Dify. It includes the integration type, client secret, and client ID.

LANGUAGE: plaintext
CODE:
NOTION_INTEGRATION_TYPE=public
NOTION_CLIENT_SECRET=your-client-secret
NOTION_CLIENT_ID=your-client-id

----------------------------------------

TITLE: Starting Docker Middleware Services
DESCRIPTION: Commands to start PostgreSQL, Redis, and Weaviate using Docker Compose.

LANGUAGE: Bash
CODE:
cd docker
cp middleware.env.example middleware.env
docker compose -f docker-compose.middleware.yaml up -d

----------------------------------------

TITLE: Initializing Dify Bundle Project with CLI
DESCRIPTION: Commands to create a new Bundle plugin project using the Dify CLI tool. It shows two variations depending on how the CLI tool is installed.

LANGUAGE: bash
CODE:
./dify-plugin-darwin-arm64 bundle init

LANGUAGE: bash
CODE:
dify bundle init

----------------------------------------

TITLE: Accessing Dify Administrator Initialization Page
DESCRIPTION: These commands demonstrate how to access the Dify administrator initialization page to set up the admin account, either through a domain or IP and port.

LANGUAGE: bash
CODE:
# If you have set domain
http://yourdomain/install

# If you choose to access through `IP+Port`
http://your_server_ip:8088/install

----------------------------------------

TITLE: Error Code Table in Markdown
DESCRIPTION: Table showing error codes, results and solutions for external knowledge API connection issues

LANGUAGE: markdown
CODE:
| Error Code | Result                              | Solutions                                                   |
| ---------- | ----------------------------------- | ----------------------------------------------------------- |
| 1001       | Invalid Authorization header format | Please check the Authorization header format of the request |
| 1002       | Authorization failed                | Please check whether the API Key you entered is correct.    |
| 2001       | The knowledge is not exist          | Please check the external repository                        |

----------------------------------------

TITLE: Docker Container IP Inspection
DESCRIPTION: Command to inspect Docker container IP addresses for troubleshooting Nginx configuration.

LANGUAGE: bash
CODE:
docker ps -q | xargs -n 1 docker inspect --format '{{ .Name }}: {{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}'

----------------------------------------

TITLE: Example Request Body for app.moderation.output in JSON
DESCRIPTION: This example shows a sample request body for the app.moderation.output extension point, including an app_id and potentially offensive text to be moderated.

LANGUAGE: json
CODE:
{
    "point": "app.moderation.output",
    "params": {
        "app_id": "61248ab4-1125-45be-ae32-0ce91334d021",
        "text": "I will kill you."
    }
}

----------------------------------------

TITLE: Extracting Plugins for Dify Migration
DESCRIPTION: Command to extract plugins from the current Dify environment, generating a plugins.jsonl file.

LANGUAGE: bash
CODE:
poetry run flask extract-plugins --workers=20

----------------------------------------

TITLE: Example of app.moderation.input Request Body in JSON
DESCRIPTION: This snippet provides a concrete example of the app.moderation.input request body, showcasing how to structure the request with specific values for app_id, inputs, and query.

LANGUAGE: json
CODE:
{
    "point": "app.moderation.input",
    "params": {
        "app_id": "61248ab4-1125-45be-ae32-0ce91334d021",
        "inputs": {
            "var_1": "I will kill you.",
            "var_2": "I will fuck you."
        },
        "query": "Happy everydays."
    }
}

----------------------------------------

TITLE: Adding Package Dependencies to Bundle
DESCRIPTION: Command to append local package dependencies to a Bundle project using a local package file path.

LANGUAGE: bash
CODE:
dify-plugin bundle append package . --package_path=./openai.difypkg

----------------------------------------

TITLE: Resetting Password in Docker Deployment
DESCRIPTION: Command to reset the password for a Dify installation using Docker Compose deployment.

LANGUAGE: bash
CODE:
docker exec -it docker-api-1 flask reset-password

----------------------------------------

TITLE: Adding Package Dependencies to Bundle
DESCRIPTION: Command to append local package dependencies to a Bundle project using a local package file path.

LANGUAGE: bash
CODE:
dify-plugin bundle append package . --package_path=./openai.difypkg

----------------------------------------

TITLE: Upgrading Dify to Version 1.0.0
DESCRIPTION: Commands to switch to the 1.0.0 branch and start the Docker containers for the new version.

LANGUAGE: bash
CODE:
git checkout 1.0.0
cd docker
docker compose -f docker-compose.yaml up -d

----------------------------------------

TITLE: Implementing app.moderation.output Extension Point in JSON
DESCRIPTION: This snippet shows the structure of the request body for the app.moderation.output extension point. It includes the point type, application ID, and the text content from LLM output for review.

LANGUAGE: json
CODE:
{
    "point": "app.moderation.output",
    "params": {
        "app_id": string,
        "text": string
    }
}

----------------------------------------

TITLE: Workflow System Variables Example
DESCRIPTION: Code example showing system variable names and their usage in Workflow applications

LANGUAGE: markdown
CODE:
sys.files     - Array[File]  - File parameter for user uploads
sys.user_id   - String      - Unique identifier for users
sys.app_id    - String      - Application identifier
sys.workflow_id - String    - Workflow identifier
sys.workflow_run_id - String - Workflow run identifier

----------------------------------------

TITLE: Backing Up Dify Docker Compose Configuration
DESCRIPTION: Command to create a backup of the docker-compose.yaml file with a timestamp in the filename.

LANGUAGE: bash
CODE:
cp docker-compose.yaml docker-compose.yaml.$(date +%s).bak

----------------------------------------

TITLE: Cloning and Configuring Dify Extension
DESCRIPTION: Initial setup commands for cloning the example repository and configuring the wrangler.toml file.

LANGUAGE: bash
CODE:
git clone https://github.com/crazywoola/dify-extension-workers.git
cp wrangler.toml.example wrangler.toml

----------------------------------------

TITLE: Supported File Types Table Definition
DESCRIPTION: HTML table defining the supported file types and formats for File and array[file] variables in Dify.

LANGUAGE: html
CODE:
<table data-header-hidden><thead><tr><th width="227"></th><th></th></tr></thead><tbody><tr><td>File Type</td><td>Supported Formats</td></tr><tr><td>Documents</td><td>TXT, MARKDOWN, PDF, HTML, XLSX, XLS, DOCX, CSV, EML, MSG, PPTX, PPT, XML, EPUB.</td></tr><tr><td>Images</td><td>JPG, JPEG, PNG, GIF, WEBP, SVG.</td></tr><tr><td>Audio</td><td>MP3, M4A, WAV, WEBM, AMR.</td></tr><tr><td>Video</td><td>MP4, MOV, MPEG, MPGA.</td></tr><tr><td>Others</td><td>Custom file extension support</td></tr></tbody></table>

----------------------------------------

TITLE: Reloading Systemd and Restarting Ollama on Linux
DESCRIPTION: Commands to reload systemd configuration and restart the Ollama service after modifying environment variables on Linux.

LANGUAGE: bash
CODE:
systemctl daemon-reload
systemctl restart ollama

----------------------------------------

TITLE: Configuring Wrangler Settings
DESCRIPTION: Configuration settings for the Cloudflare Workers deployment, including application name, compatibility date, and security token.

LANGUAGE: toml
CODE:
name = "dify-extension-example"
compatibility_date = "2023-01-01"

[vars]
TOKEN = "bananaiscool"

----------------------------------------

TITLE: Launching Stable Diffusion WebUI on Windows
DESCRIPTION: Command to launch Stable Diffusion WebUI with API and listen flags enabled on Windows.

LANGUAGE: bash
CODE:
cd stable-diffusion-webui\n./webui.bat --api --listen

----------------------------------------

TITLE: Configuring Ollama Service on Linux with Systemd
DESCRIPTION: Systemd configuration to set the OLLAMA_HOST environment variable for the Ollama service on Linux systems.

LANGUAGE: ini
CODE:
[Service]
Environment="OLLAMA_HOST=0.0.0.0"

----------------------------------------

TITLE: Deploying API Extension
DESCRIPTION: Command to deploy the API extension to Cloudflare Workers.

LANGUAGE: bash
CODE:
npm run deploy

----------------------------------------

TITLE: Cloning Stable Diffusion WebUI Repository
DESCRIPTION: Command to clone the official Stable Diffusion WebUI repository from GitHub.

LANGUAGE: bash
CODE:
git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui

----------------------------------------

TITLE: Running Llama3.2 Model with Ollama in Bash
DESCRIPTION: Command to run the Llama3.2 model using Ollama. This starts an API service on local port 11434.

LANGUAGE: bash
CODE:
ollama run llama3.2

----------------------------------------

TITLE: Demonstrating CSV File Encoding for Batch Processing in Text Generation
DESCRIPTION: This snippet emphasizes the importance of using Unicode encoding for CSV files in batch processing. It explains that incorrect encoding can lead to failure and provides a solution for exporting CSV files with the correct encoding using Excel or WPS.

LANGUAGE: markdown
CODE:
**Note:** The encoding of the uploaded `csv` file must be `Unicode` encoding. Otherwise, the result will fail. Solution: When exporting to a `csv` file with Excel, WPS, etc., select `Unicode` for encoding.

----------------------------------------

TITLE: Setting Ollama Host Environment Variable on macOS
DESCRIPTION: Command to set the OLLAMA_HOST environment variable using launchctl on macOS. This exposes the Ollama service to the network.

LANGUAGE: bash
CODE:
launchctl setenv OLLAMA_HOST "0.0.0.0"

----------------------------------------

TITLE: Starting LiteLLM Proxy Docker Container
DESCRIPTION: Docker command to run the LiteLLM proxy server, mounting the configuration file and exposing port 4000. Enables detailed debugging for troubleshooting.

LANGUAGE: shell
CODE:
docker run \
    -v $(pwd)/litellm_config.yaml:/app/config.yaml \
    -p 4000:4000 \
    ghcr.io/berriai/litellm:main-latest \
    --config /app/config.yaml --detailed_debug

----------------------------------------

TITLE: Customizing Pre-prompt for English Responses in Dify
DESCRIPTION: This snippet shows how to modify the pre-prompt to ensure the AI assistant responds in English, regardless of the input language.

LANGUAGE: markdown
CODE:
When answer to user:
- If you don't know, just say that you don't know.
- If you don't know when you are not sure, ask for clarification.
Avoid mentioning that you obtained the information from the context.
And answer according to the language English.

----------------------------------------

TITLE: Installing GPUStack on Windows
DESCRIPTION: PowerShell command to install GPUStack on Windows systems. Must be run as administrator from PowerShell, not PowerShell ISE.

LANGUAGE: powershell
CODE:
Invoke-Expression (Invoke-WebRequest -Uri "https://get.gpustack.ai" -UseBasicParsing).Content

----------------------------------------

TITLE: Installing GPUStack on Linux/MacOS
DESCRIPTION: Command to install GPUStack as a service on systemd or launchd based systems using the official installation script.

LANGUAGE: bash
CODE:
curl -sfL https://get.gpustack.ai | sh -s -

----------------------------------------

TITLE: Setting Stop Sequences for Few-Shot Learning in Dify
DESCRIPTION: This example demonstrates how to use stop sequences in Dify's Expert Mode to control the AI's output length in a few-shot learning scenario.

LANGUAGE: markdown
CODE:
Human1: What color is the sky?

Assistant1: The sky is blue.

Human1: What color is the fire?

Assistant1: The fire is red.

Human1: What color is the soil?

Assistant1: 

----------------------------------------

TITLE: Configuring Environment File
DESCRIPTION: Command to set up the environment configuration file for LocalAI.

LANGUAGE: shell
CODE:
$ mv .env.example .env

----------------------------------------

TITLE: Generating Database Migration in Python using Alembic
DESCRIPTION: This command generates a new database migration script using Alembic. It automatically detects changes in the database schema and creates a corresponding migration file.

LANGUAGE: bash
CODE:
alembic revision --autogenerate -m "migration message"

----------------------------------------

TITLE: Error Stack Trace for File Not Found
DESCRIPTION: Error log showing file not found exception in RSA decryption process

LANGUAGE: plaintext
CODE:
ERROR:root:Unknown Error in completion
Traceback (most recent call last):
  File "/www/wwwroot/dify/dify/api/libs/rsa.py", line 45, in decrypt
    private_key = storage.load(filepath)
  File "/www/wwwroot/dify/dify/api/extensions/ext_storage.py", line 65, in load
    raise FileNotFoundError("File not found")
FileNotFoundError: File not found

----------------------------------------

TITLE: Applying Database Migrations in Python using Alembic
DESCRIPTION: This command applies all pending database migrations using Alembic. It updates the database schema to match the latest version defined in the migration scripts.

LANGUAGE: bash
CODE:
alembic upgrade head

----------------------------------------

TITLE: Installing Plugins in Dify API Container Using Poetry in Bash
DESCRIPTION: This command runs a Flask command to install the extracted plugins into the latest Community Edition, with the option to specify the number of worker processes.

LANGUAGE: bash
CODE:
poetry run flask install-plugins --workers=2

----------------------------------------

TITLE: Docker Compose Encryption Key Reset
DESCRIPTION: Command to reset encryption public and private keys in Docker compose deployment

LANGUAGE: bash
CODE:
docker exec -it docker-api-1 flask reset-encrypt-key-pair

----------------------------------------

TITLE: Packaging Dify Plugin Project
DESCRIPTION: Commands to navigate to the parent directory and package a Dify plugin project into a .difypkg file using the Dify plugin tool.

LANGUAGE: bash
CODE:
cd ../
dify plugin package ./your_plugin_project

----------------------------------------

TITLE: Cloning Dify Repository
DESCRIPTION: Command to clone the forked Dify repository to local machine using SSH.

LANGUAGE: bash
CODE:
git clone git@github.com:<github_username>/dify.git

----------------------------------------

TITLE: Squid Proxy Configuration
DESCRIPTION: Example configuration for SSRF proxy rules in Squid

LANGUAGE: plaintext
CODE:
acl restricted_ip dst 192.168.101.19
acl localnet src 192.168.101.0/24

http_access deny restricted_ip
http_access allow localnet
http_access deny all

----------------------------------------

TITLE: Configuring Remote Debugging
DESCRIPTION: Example of a .env file configuration for remote debugging of the Dify plugin.

LANGUAGE: bash
CODE:
INSTALL_METHOD=remote
REMOTE_INSTALL_HOST=localhost
REMOTE_INSTALL_PORT=5003
REMOTE_INSTALL_KEY=****-****-****-****-****

----------------------------------------

TITLE: Invoking QuestionClassifier Node in Python
DESCRIPTION: Displays the interface for invoking the QuestionClassifier node. It takes a list of class configurations, model configuration, query text, and optional instructions as inputs, returning a NodeResponse.

LANGUAGE: python
CODE:
def invoke(
    self,
    classes: list[ClassConfig],
    model: ModelConfig,
    query: str,
    instruction: str = "",
) -> NodeResponse:
    pass

----------------------------------------

TITLE: Resetting Admin Password for Dify using Docker
DESCRIPTION: This command resets the password for the admin account in a running Docker Compose environment. It prompts for the email address and new password.

LANGUAGE: bash
CODE:
docker exec -it docker-api-1 flask reset-password

----------------------------------------

TITLE: Configuring Anthropic Model Provider in YAML
DESCRIPTION: YAML configuration file for the Anthropic model provider, defining provider information, credentials schema, and supported model types.

LANGUAGE: yaml
CODE:
provider: anthropic
label:
 en_US: Anthropic
description:
 en_US: Anthropic's powerful models, such as Claude 3.
icon_small:
 en_US: icon_s_en.svg
icon_large:
 en_US: icon_l_en.svg
background: "#F0F0EB"
help:
 title:
   en_US: Get your API Key from Anthropic
 url:
   en_US: https://console.anthropic.com/account/keys
supported_model_types:
 - llm
configurate_methods:
 - predefined-model
provider_credential_schema:
 credential_form_schemas:
   - variable: anthropic_api_key
     label:
       en_US: API Key
     type: secret-input
     required: true
     placeholder:
       en_US: Enter your API Key
   - variable: anthropic_api_url
     label:
       en_US: API URL
     type: text-input
     required: false
     placeholder:
       en_US: Enter your API URL
models:
 llm:
   predefined:
     - "models/llm/*.yaml"
   position: "models/llm/_position.yaml"
extra:
 python:
   provider_source: provider/anthropic.py
   model_sources:
     - "models/llm/llm.py"

----------------------------------------

TITLE: Packaging Dify Bundle Project
DESCRIPTION: Command to package a Dify Bundle project into a .difybndl file, which is the final output for distribution.

LANGUAGE: bash
CODE:
dify-plugin bundle package ./bundle

----------------------------------------

TITLE: Secret Key Generation Command
DESCRIPTION: Command to generate a strong secret key for secure session cookies and database encryption

LANGUAGE: bash
CODE:
openssl rand -base64 42

----------------------------------------

TITLE: Configuring Perplexity Search Parameters in YAML
DESCRIPTION: This YAML configuration sets up the parameters for Perplexity Search integration. It includes the model name, API base URL, and various request parameters such as max tokens, temperature, and top_p.

LANGUAGE: yaml
CODE:
model: claude-2
api_base: https://api.perplexity.ai
request_timeout: 600
max_tokens: 4096
temperature: 1.0
top_p: 1
stream: true
use_search: false
safe_mode: true
api_key: ""

----------------------------------------

TITLE: Verifying Dify Plugin Scaffolding Tool Installation
DESCRIPTION: This command runs the Dify plugin scaffolding tool to verify successful installation by displaying the version information.

LANGUAGE: bash
CODE:
./dify-plugin-darwin-arm64 version

----------------------------------------

TITLE: Adding Package Dependency to Dify Bundle
DESCRIPTION: Command to append a Package dependency to a Dify Bundle project, specifying the local path to the plugin package.

LANGUAGE: bash
CODE:
dify-plugin bundle append package . --package_path=./openai.difypkg

----------------------------------------

TITLE: Configuring Dify Plugin Tool Permissions
DESCRIPTION: Command to grant execution permissions to the Dify plugin development scaffolding tool on macOS with M-series chips.

LANGUAGE: bash
CODE:
chmod +x dify-plugin-darwin-arm64

----------------------------------------

TITLE: Cloning Dify Repository
DESCRIPTION: Command to clone the Dify repository from GitHub.

LANGUAGE: bash
CODE:
git clone https://github.com/langgenius/dify.git

----------------------------------------

TITLE: Initializing Git Repository for Dify Plugin
DESCRIPTION: Commands to initialize a local Git repository for a Dify plugin project, add files, and make the initial commit. Also includes optional commands for configuring Git username and email.

LANGUAGE: bash
CODE:
git init
git add .
git commit -m "Initial commit: Add plugin files"

# Optional Git configuration
git config --global user.name "Your Name"
git config --global user.email "your.email@example.com"

----------------------------------------

TITLE: Generating Direct Reply for Irrelevant Questions in Markdown
DESCRIPTION: This snippet demonstrates how to create a direct reply node for irrelevant questions, guiding users to the help documentation using Markdown formatting.

LANGUAGE: markdown
CODE:
I'm sorry, I can't answer your question. If you need more help, please check the [help documentation](https://docs.dify.ai).

----------------------------------------

TITLE: Upgrading Dify Version Using Git and Docker Compose in Bash
DESCRIPTION: This set of commands fetches the latest version, switches to the 1.0.0 branch, updates the environment configuration, and starts the Docker services.

LANGUAGE: bash
CODE:
git fetch origin
git checkout 1.0.0 # Switch to the 1.0.0 branch
cd docker
nano .env # Modify the environment configuration file to synchronizing .env.example file
docker compose -f docker-compose.yaml up -d

----------------------------------------

TITLE: Verifying Ollama Installation in Bash
DESCRIPTION: Command to check the installed version of Ollama after installation.

LANGUAGE: bash
CODE:
➜  ~ ollama -v
ollama version is 0.5.5

----------------------------------------

TITLE: Example Git Clone Command
DESCRIPTION: Command to clone the Dify docs repository

LANGUAGE: bash
CODE:
git clone https://github.com/<your-github-account>/dify-docs.git

----------------------------------------

TITLE: Making API Request to Dify Chat Endpoint
DESCRIPTION: Example curl command to interact with the Dify API for sending chat messages. This request initiates or continues a conversation with the AI assistant, requiring an API secret key for authentication.

LANGUAGE: curl
CODE:
curl --location --request POST 'https://api.dify.ai/v1/chat-messages' \
--header 'Authorization: Bearer ENTER-YOUR-SECRET-KEY' \
--header 'Content-Type: application/json' \
--data-raw '{
    "inputs": {},
    "query": "eh",
    "response_mode": "streaming",
    "conversation_id": "",
    "user": "abc-123"
}'

----------------------------------------

TITLE: Example Docker Compose Command
DESCRIPTION: Command to deploy Dify locally using Docker Compose

LANGUAGE: bash
CODE:
docker-compose -f docker-compose.yaml -f docker-compose.override.yaml up -d

----------------------------------------

TITLE: Array Access Example
DESCRIPTION: Examples of accessing first and last elements in filtered arrays

LANGUAGE: typescript
CODE:
result[0]            // first_record
result[array.length-1]  // last_record

----------------------------------------

TITLE: ComfyUI Docker Connection URL
DESCRIPTION: Default connection URL for accessing ComfyUI when running Dify in Docker environment

LANGUAGE: text
CODE:
http://host.docker.internal:8188

----------------------------------------

TITLE: Installing GPUStack on Linux/MacOS
DESCRIPTION: Command to install GPUStack service on systemd/launchd based systems

LANGUAGE: bash
CODE:
curl -sfL https://get.gpustack.ai | sh -s -

----------------------------------------

TITLE: Packaging the Plugin
DESCRIPTION: Command to package the plugin for distribution.

LANGUAGE: bash
CODE:
dify plugin package ./slack_bot