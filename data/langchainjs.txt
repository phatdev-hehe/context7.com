TITLE: Creating Sequential Runnables with RunnableSequence in TypeScript
DESCRIPTION: Demonstrates how to create and invoke a sequential chain of Runnables using RunnableSequence. This allows chaining multiple runnables where the output of one serves as input to the next.

LANGUAGE: typescript
CODE:
import { RunnableSequence } from "@langchain/core/runnables";
const chain = new RunnableSequence({
  first: runnable1,
  // Optional, use if you have more than two runnables
  // middle: [...],
  last: runnable2,
});

LANGUAGE: typescript
CODE:
const finalOutput = await chain.invoke(someInput);

----------------------------------------

TITLE: Similarity Search with Metadata Filtering in TypeScript
DESCRIPTION: This snippet shows how to perform a similarity search with metadata filtering in LangChain, specifically filtering for documents with a certain source.

LANGUAGE: typescript
CODE:
await vectorstore.similaritySearch(
  "LangChain provides abstractions to make working with LLMs easy",
  2,
  {
    // The arguments of this field are provider specific.
    filter: { source: "tweet" },
  }
);

----------------------------------------

TITLE: Basic Retriever Invocation in TypeScript
DESCRIPTION: Demonstrates how to invoke a retriever to get relevant documents from a query using the standard LangChain interface.

LANGUAGE: typescript
CODE:
const docs = await retriever.invoke(query);

----------------------------------------

TITLE: Using Pipe Method for Runnable Composition in TypeScript
DESCRIPTION: Demonstrates the shorthand pipe syntax for composing Runnables sequentially, including the use of RunnableLambda for converting TypeScript functions into Runnables.

LANGUAGE: typescript
CODE:
const chain = runnable1.pipe(runnable2);

LANGUAGE: typescript
CODE:
const someFunc = RunnableLambda.from((input) => {
  return input;
});

const chain = someFunc.pipe(runnable1);

----------------------------------------

TITLE: Implementing Tool Calling Agent with Image Search in TypeScript
DESCRIPTION: This snippet demonstrates how to create a tool for image searching and set up an agent executor with tool calling capabilities. It uses the 'createRunnableUI' utility to stream UI updates during the tool's execution.

LANGUAGE: tsx
CODE:
"use server";

const tool = tool(
  async (input, config) => {
    const stream = await createRunnableUI(config);
    stream.update(<div>Searching...</div>);

    const result = await images(input);
    stream.done(
      <Images
        images={result.images_results
          .map((image) => image.thumbnail)
          .slice(0, input.limit)}
      />
    );

    return `[Returned ${result.images_results.length} images]`;
  },
  {
    name: "Images",
    description: "A tool to search for images. input should be a search query.",
    schema: z.object({
      query: z.string().describe("The search query used to search for cats"),
      limit: z.number().describe("The number of pictures shown to the user"),
    }),
  }
);

// add LLM, prompt, etc...

const tools = [tool];

export const agentExecutor = new AgentExecutor({
  agent: createToolCallingAgent({ llm, tools, prompt }),
  tools,
});

----------------------------------------

TITLE: Implementing Basic RAG Workflow with OpenAI Chat Model
DESCRIPTION: Demonstrates a basic RAG implementation that combines document retrieval with ChatOpenAI. The code shows how to retrieve relevant documents, format them into a system prompt, and generate responses using a chat model.

LANGUAGE: typescript
CODE:
import { ChatOpenAI } from "@langchain/openai";

// Define a system prompt that tells the model how to use the retrieved context
const systemPrompt = `You are an assistant for question-answering tasks.
Use the following pieces of retrieved context to answer the question.
If you don't know the answer, just say that you don't know.
Use three sentences maximum and keep the answer concise.
Context: {context}:`;

// Define a question
const question =
  "What are the main components of an LLM-powered autonomous agent system?";

// Retrieve relevant documents
const docs = await retriever.invoke(question);

// Combine the documents into a single string
const docsText = docs.map((d) => d.pageContent).join("");

// Populate the system prompt with the retrieved context
const systemPromptFmt = systemPrompt.replace("{context}", docsText);

// Create a model
const model = new ChatOpenAI({
  model: "gpt-4o",
  temperature: 0,
});

// Generate a response
const questions = await model.invoke([
  {
    role: "system",
    content: systemPromptFmt,
  },
  {
    role: "user",
    content: question,
  },
]);

----------------------------------------

TITLE: Using Tool Calling for Structured Output in LangChain.js
DESCRIPTION: Illustrates how to use tool calling to achieve structured output. It involves creating a tool with the defined schema, binding it to the model, and then invoking the model to get a structured response.

LANGUAGE: typescript
CODE:
import { ChatOpenAI } from "@langchain/openai";

const model = new ChatOpenAI({
  modelName: "gpt-4",
  temperature: 0,
});

// Create a tool with ResponseFormatter as its schema.
const responseFormatterTool = tool(async () => {}, {
  name: "responseFormatter",
  schema: ResponseFormatter,
});

// Bind the created tool to the model
const modelWithTools = model.bindTools([responseFormatterTool]);

// Invoke the model
const aiMsg = await modelWithTools.invoke(
  "What is the powerhouse of the cell?"
);

----------------------------------------

TITLE: Using JSON Mode for Structured Output with OpenAI in LangChain.js
DESCRIPTION: Shows how to use JSON mode with OpenAI to enforce structured output. It binds the JSON response format to the model and then invokes it to get a JSON object response.

LANGUAGE: typescript
CODE:
import { ChatOpenAI } from "@langchain/openai";

const model = new ChatOpenAI({
  model: "gpt-4",
}).bind({
  response_format: { type: "json_object" },
});

const aiMsg = await model.invoke(
  "Return a JSON object with key 'random_nums' and a value of 10 random numbers in [0-99]"
);
console.log(aiMsg.content);
// Output: {
//   "random_nums": [23, 47, 89, 15, 34, 76, 58, 3, 62, 91]
// }

----------------------------------------

TITLE: Loading Documents with CSVLoader in LangChain.js
DESCRIPTION: Example showing how to use the CSVLoader class from LangChain.js community package to load documents from CSV files. The loader implements the BaseLoader interface and uses the load() method to retrieve document data.

LANGUAGE: typescript
CODE:
import { CSVLoader } from "@langchain/community/document_loaders/fs/csv";

const loader = new CSVLoader(
  ...  // <-- Integration specific parameters here
);
const data = await loader.load();

----------------------------------------

TITLE: Binding Tools to Chat Models in TypeScript
DESCRIPTION: Demonstrates how to create tools and bind them to a chat model using LangChain's standardized interface. This allows for tool calling functionality across different model providers.

LANGUAGE: typescript
CODE:
// Tool creation
const tools = [myTool];
// Tool binding
const modelWithTools = model.bindTools(tools);

----------------------------------------

TITLE: Using withStructuredOutput Method in LangChain.js
DESCRIPTION: Demonstrates the recommended workflow for using structured output in LangChain.js. It shows how to define a schema, bind it to a model, and invoke the model to produce structured output matching the schema.

LANGUAGE: typescript
CODE:
// Define schema
const schema = { foo: "bar" };
// Bind schema to model
const modelWithStructure = model.withStructuredOutput(schema);
// Invoke the model to produce structured output that matches the schema
const structuredOutput = await modelWithStructure.invoke(userInput);

----------------------------------------

TITLE: Producing Structured Outputs with Chat Models in TypeScript
DESCRIPTION: Shows how to define a schema using Zod and bind it to a chat model to produce structured outputs. This provides a consistent way to handle structured outputs across different model providers.

LANGUAGE: typescript
CODE:
// Define tool as a Zod schema
const schema = z.object({ ... });
// Bind schema to model
const modelWithStructure = model.withStructuredOutput(schema)

----------------------------------------

TITLE: Streaming Output from LangChain Components
DESCRIPTION: Demonstrates how to use the stream() method to process chunks of output from a LangChain component in real-time. This example shows a generic approach that can be applied to various components like LLMs or LangGraph workflows.

LANGUAGE: typescript
CODE:
for await (const chunk of await component.stream(someInput)) {
  // IMPORTANT: Keep the processing of each chunk as efficient as possible.
  // While you're processing the current chunk, the upstream component is
  // waiting to produce the next one. For example, if working with LangGraph,
  // graph execution is paused while the current chunk is being processed.
  // In extreme cases, this could even result in timeouts (e.g., when llm outputs are
  // streamed from an API that has a timeout).
  console.log(chunk);
}

----------------------------------------

TITLE: Markdown Documentation for LangChain Agents
DESCRIPTION: Markdown content explaining the concept of agents in LangChain, the role of LangGraph, and migration guidance from AgentExecutor to LangGraph. Includes links to relevant documentation and resources.

LANGUAGE: markdown
CODE:
# Agents

By themselves, language models can't take actions - they just output text. Agents are systems that take a high-level task and use an LLM as a reasoning engine to decide what actions to take and execute those actions.

[LangGraph](/docs/concepts/architecture#langgraph) is an extension of LangChain specifically aimed at creating highly controllable and customizable agents. We recommend that you use LangGraph for building agents.

Please see the following resources for more information:

- LangGraph docs on [common agent architectures](https://langchain-ai.github.io/langgraphjs/concepts/agentic_concepts/)
- [Pre-built agents in LangGraph](https://langchain-ai.github.io/langgraphjs/reference/functions/langgraph_prebuilt.createReactAgent.html)

## Legacy agent concept: AgentExecutor

LangChain previously introduced the `AgentExecutor` as a runtime for agents.
While it served as an excellent starting point, its limitations became apparent when dealing with more sophisticated and customized agents.
As a result, we're gradually phasing out `AgentExecutor` in favor of more flexible solutions in LangGraph.

### Transitioning from AgentExecutor to langgraph

If you're currently using `AgentExecutor`, don't worry! We've prepared resources to help you:

1. For those who still need to use `AgentExecutor`, we offer a comprehensive guide on [how to use AgentExecutor](/docs/how_to/agent_executor).

2. However, we strongly recommend transitioning to LangGraph for improved flexibility and control. To facilitate this transition, we've created a detailed [migration guide](/docs/how_to/migrate_agent) to help you move from `AgentExecutor` to LangGraph seamlessly.

----------------------------------------

TITLE: ParentDocumentRetriever with Score Threshold
DESCRIPTION: Implementation demonstrating ParentDocumentRetriever with score threshold options for relevancy-based retrieval.

LANGUAGE: typescript
CODE:
{ExampleWithScoreThreshold}

----------------------------------------

TITLE: Handling High-Cardinality Columns with Vector Store in TypeScript
DESCRIPTION: TypeScript code snippet demonstrating a strategy to handle high-cardinality columns by creating a vector store of unique proper nouns and querying it for user input correction.

LANGUAGE: typescript
CODE:
import HighCardinalityExample from "@examples/use_cases/sql/large_db_high_cardinality.ts";

<CodeBlock language="typescript">{HighCardinalityExample}</CodeBlock>

----------------------------------------

TITLE: ParentDocumentRetriever with Reranking
DESCRIPTION: Implementation of ParentDocumentRetriever with reranking capability for improved precision and cost efficiency.

LANGUAGE: typescript
CODE:
{ExampleWithRerank}

----------------------------------------

TITLE: Implementing Cloudflare Worker with Vectorize and LangChain.js
DESCRIPTION: This TypeScript code demonstrates how to use Cloudflare Vectorize with LangChain.js in a Cloudflare Worker, including adding documents, querying, and clearing the vector store.

LANGUAGE: typescript
CODE:
import { CloudflareVectorizeStore } from "@langchain/cloudflare_vectorize";
import { CloudflareWorkersAIEmbeddings } from "@langchain/cloudflare";
import { Document } from "@langchain/core/documents";

export interface Env {
  VECTORIZE_INDEX: VectorizeIndex;
  AI: any;
}

export default {
  async fetch(
    request: Request,
    env: Env,
    ctx: ExecutionContext
  ): Promise<Response> {
    const embeddings = new CloudflareWorkersAIEmbeddings({
      binding: env.AI,
      modelName: "@cf/baai/bge-base-en-v1.5",
    });

    const vectorStore = new CloudflareVectorizeStore(embeddings, {
      index: env.VECTORIZE_INDEX,
    });

    const url = new URL(request.url);
    const path = url.pathname;

    if (path === "/add") {
      const docs = [
        new Document({
          pageContent: "The capital of France is Paris",
          metadata: { country: "France" },
        }),
        new Document({
          pageContent: "The capital of England is London",
          metadata: { country: "England" },
        }),
      ];
      await vectorStore.addDocuments(docs);
      return new Response("Added documents");
    } else if (path === "/query") {
      const results = await vectorStore.similaritySearch("capital", 2);
      return new Response(JSON.stringify(results));
    } else if (path === "/clear") {
      await vectorStore.delete();
      return new Response("Cleared vector store");
    } else {
      return new Response("Invalid path");
    }
  },
};

----------------------------------------

TITLE: Implementing Client-Side UI for LLM-Generated Content with React
DESCRIPTION: This React component demonstrates how to use the exposed agent endpoint to trigger the LLM-generated UI. It uses the 'useActions' hook to access the server actions and updates the UI based on the agent's response.

LANGUAGE: tsx
CODE:
"use client";
import type { EndpointsContext } from "./agent";

export default function Page() {
  const actions = useActions<typeof EndpointsContext>();
  const [node, setNode] = useState();

  return (
    <div>
      {node}

      <button
        onClick={async () => {
          setNode(await actions.agent({ input: "cats" }));
        }}
      >
        Get images of cats
      </button>
    </div>
  );
}

----------------------------------------

TITLE: Passing Multimodal Inputs to Chat Model in TypeScript
DESCRIPTION: This snippet demonstrates how to pass multimodal inputs, specifically an image, to a chat model using content blocks. It creates a HumanMessage with both text and image content.

LANGUAGE: typescript
CODE:
import { HumanMessage } from "@langchain/core/messages";

const message = new HumanMessage({
  content: [
    { type: "text", text: "describe the weather in this image" },
    { type: "image_url", image_url: { url: image_url } },
  ],
});
const response = await model.invoke([message]);

----------------------------------------

TITLE: Implementing Query Decomposition with TypeScript and OpenAI
DESCRIPTION: Demonstrates how to break down complex queries into sub-questions using ChatGPT and Zod for structured output validation. The code uses the ChatOpenAI model to generate multiple related sub-questions from a single input question.

LANGUAGE: typescript
CODE:
import { z } from "zod";
import { ChatOpenAI } from "@langchain/openai";
import { SystemMessage, HumanMessage } from "@langchain/core/messages";

// Define a zod object for the structured output
const Questions = z.object({
  questions: z
    .array(z.string())
    .describe("A list of sub-questions related to the input query.")
});

// Create an instance of the model and enforce the output structure
const model = new ChatOpenAI({ modelName: "gpt-4", temperature: 0 });
const structuredModel = model.withStructuredOutput(Questions);

// Define the system prompt
const system = `You are a helpful assistant that generates multiple sub-questions related to an input question.
The goal is to break down the input into a set of sub-problems / sub-questions that can be answers in isolation.`;

// Pass the question to the model
const question =
  "What are the main components of an LLM-powered autonomous agent system?";
const questions = await structuredModel.invoke([
  new SystemMessage(system),
  new HumanMessage(question),
]);

----------------------------------------

TITLE: Creating a Tool with Artifacts in TypeScript
DESCRIPTION: Illustrates how to create a tool that returns both content and artifacts, useful for passing additional metadata or complex objects to downstream components.

LANGUAGE: typescript
CODE:
const someTool = tool(({ ... }) => {
    // do something
}, {
  // ... tool schema args
  // Set the returnType to "content_and_artifact"
  responseFormat: "content_and_artifact"
});

----------------------------------------

TITLE: Embedding Multiple Documents
DESCRIPTION: Shows how to embed multiple text documents simultaneously using the embedDocuments method, returning an array of vector representations.

LANGUAGE: typescript
CODE:
const documentRes = await embeddings.embedDocuments(["Hello world", "Bye bye"]);
/*
[
  [
    -0.004845875,   0.004899438,  -0.016358767,  -0.024475135, -0.017341806,
      0.012571548,  -0.019156644,   0.009036391,  -0.010227379, -0.026945334,
      0.022861943,   0.010321903,  -0.023479493, -0.0066544134,  0.007977734,
    0.0026371893,   0.025206111,  -0.012048521,   0.012943339,  0.013094575,
    -0.010580265,  -0.003509951,   0.004070787,   0.008639394, -0.020631202,
    ... 1511 more items
  ]
  [
      -0.009446913,  -0.013253193,   0.013174579,  0.0057552797,  -0.038993083,
      0.0077763423,    -0.0260478, -0.0114384955, -0.0022683728,  -0.016509168,
      0.041797023,    0.01787183,    0.00552271, -0.0049789557,   0.018146982,
      -0.01542166,   0.033752076,   0.006112323,   0.023872782,  -0.016535373,
      -0.006623321,   0.016116094, -0.0061090477, -0.0044155475,  -0.016627092,
    ... 1511 more items
  ]
]*/

----------------------------------------

TITLE: Installing Required Dependencies
DESCRIPTION: Commands to install the necessary npm packages for implementing the time-weighted retriever functionality.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/core

----------------------------------------

TITLE: Implementing Request-time Callbacks in LangChainJS
DESCRIPTION: Example showing how to pass callbacks during request time using the invoke method. These callbacks are inherited by all children of the object they are defined on.

LANGUAGE: javascript
CODE:
await chain.invoke({ number: 25 }, { callbacks: [handler] })

----------------------------------------

TITLE: Implementing Custom Retriever Class in TypeScript
DESCRIPTION: This snippet demonstrates how to create a custom retriever by extending the BaseRetriever class and implementing the _getRelevantDocuments method. It includes type definitions and a simple implementation that returns static documents based on the query.

LANGUAGE: typescript
CODE:
import {
  BaseRetriever,
  type BaseRetrieverInput,
} from "@langchain/core/retrievers";
import type { CallbackManagerForRetrieverRun } from "@langchain/core/callbacks/manager";
import { Document } from "@langchain/core/documents";

export interface CustomRetrieverInput extends BaseRetrieverInput {}

export class CustomRetriever extends BaseRetriever {
  lc_namespace = ["langchain", "retrievers"];

  constructor(fields?: CustomRetrieverInput) {
    super(fields);
  }

  async _getRelevantDocuments(
    query: string,
    runManager?: CallbackManagerForRetrieverRun
  ): Promise<Document[]> {
    // Pass `runManager?.getChild()` when invoking internal runnables to enable tracing
    // const additionalDocs = await someOtherRunnable.invoke(params, runManager?.getChild());
    return [
      // ...additionalDocs,
      new Document({
        pageContent: `Some document pertaining to ${query}`,
        metadata: {},
      }),
      new Document({
        pageContent: `Some other document pertaining to ${query}`,
        metadata: {},
      }),
    ];
  }
}

----------------------------------------

TITLE: Implementing Postgres Chat Memory in LangChain.js
DESCRIPTION: This code demonstrates how to set up and use Postgres as a chat memory store in a LangChain.js application. It includes creating a chat model, initializing the Postgres chat memory, and running a conversation loop that persists chat history across sessions.

LANGUAGE: typescript
CODE:
import { ChatOpenAI } from "@langchain/openai";
import { PostgresChatMessageHistory } from "@langchain/community/stores/message/postgres";
import { ConversationChain } from "langchain/chains";
import { BufferMemory } from "langchain/memory";

const memory = new BufferMemory({
  chatHistory: new PostgresChatMessageHistory({
    sessionId: "test-session-1",
    // Can pass a pool config if you want:
    // poolConfig: {
    //   host: "localhost",
    //   port: 5432,
    //   user: "myuser",
    //   password: "mypassword",
    //   database: "mydatabase",
    // },
    // Otherwise, can pass a pool instance:
    pool: pool,
  }),
});

const model = new ChatOpenAI();
const chain = new ConversationChain({ llm: model, memory });

const res1 = await chain.call({ input: "Hi! I'm Jim." });
console.log({ res1 });

const res2 = await chain.call({ input: "What's my name?" });
console.log({ res2 });

// Reconnect to postgres
const memory2 = new BufferMemory({
  chatHistory: new PostgresChatMessageHistory({
    sessionId: "test-session-1",
    // Can pass a pool config if you want:
    // poolConfig: {
    //   host: "localhost",
    //   port: 5432,
    //   user: "myuser",
    //   password: "mypassword",
    //   database: "mydatabase",
    // },
    // Otherwise, can pass a pool instance:
    pool: pool,
  }),
});

const model2 = new ChatOpenAI();
const chain2 = new ConversationChain({ llm: model2, memory: memory2 });

const res3 = await chain2.call({ input: "What's my name?" });
console.log({ res3 });

----------------------------------------

TITLE: Implementing Time-Weighted Retriever Scoring Algorithm in TypeScript
DESCRIPTION: This snippet shows the scoring algorithm used by the Time-Weighted Retriever. It combines the decay rate, time passed since last access, and vector relevance to calculate a score for each document.

LANGUAGE: typescript
CODE:
let score = (1.0 - this.decayRate) ** hoursPassed + vectorRelevance;

----------------------------------------

TITLE: Integrating Baidu Wenxin Chat Model in TypeScript
DESCRIPTION: Example code demonstrating how to set up and use the ChatBaiduWenxin model in a TypeScript project with LangChain.js. It includes importing the model, setting up authentication, and making a chat completion request.

LANGUAGE: typescript
CODE:
import Wenxin from "@examples/models/chat/integration_baiduwenxin.ts";

----------------------------------------

TITLE: Implementing Server-Side Agent Function with LangChain.js
DESCRIPTION: This code defines a server-side agent function that uses the 'streamRunnableUI' utility to execute the agent and stream UI updates. It also exposes the agent endpoint for client-side access.

LANGUAGE: tsx
CODE:
async function agent(inputs: {
  input: string;
  chat_history: [role: string, content: string][];
}) {
  "use server";

  return streamRunnableUI(agentExecutor, {
    input: inputs.input,
    chat_history: inputs.chat_history.map(
      ([role, content]) => new ChatMessage(content, role)
    ),
  });
}

export const EndpointsContext = exposeEndpoints({ agent });

----------------------------------------

TITLE: Implementing Dynamic Few-Shot Examples with Semantic Similarity
DESCRIPTION: This TypeScript code shows how to use SemanticSimilarityExampleSelector to dynamically select the most relevant few-shot examples based on input similarity.

LANGUAGE: typescript
CODE:
<CodeBlock language="typescript">{DynamicFewShotExample}</CodeBlock>

----------------------------------------

TITLE: Implementing Constructor Callbacks in LangChainJS
DESCRIPTION: Example showing how to pass callbacks during object construction. These callbacks are scoped only to the object they are defined on and are not inherited by children.

LANGUAGE: javascript
CODE:
const chain = new TheNameOfSomeChain({ callbacks: [handler] })

----------------------------------------

TITLE: Using TypeORMVectorStore in LangChain.js
DESCRIPTION: TypeScript example demonstrating the usage of TypeORMVectorStore for vector search. It includes importing dependencies, creating embeddings, initializing the vector store, and performing similarity search.

LANGUAGE: typescript
CODE:
import { TypeORMVectorStore } from "@langchain/community/vectorstores/typeorm";
import { OpenAIEmbeddings } from "@langchain/openai";

const typeormVectorStore = await TypeORMVectorStore.fromDataSource({
  postgresConnectionOptions: {
    type: "postgres",
    host: "localhost",
    port: 5432,
    username: "myuser",
    password: "password",
    database: "api",
  },
  tableName: "documents",
});

const docs = [{ pageContent: "foo" }, { pageContent: "bar" }];

await typeormVectorStore.addDocuments(docs);

const resultOne = await typeormVectorStore.similaritySearch("foo", 1);
console.log(resultOne);

----------------------------------------

TITLE: Using OpenAI Message Format in TypeScript
DESCRIPTION: Shows how to use OpenAI's native message format as input to chat models in LangChain.

LANGUAGE: typescript
CODE:
await chatModel.invoke([
  {
    role: "user",
    content: "Hello, how are you?",
  },
  {
    role: "assistant",
    content: "I'm doing well, thank you for asking.",
  },
  {
    role: "user",
    content: "Can you tell me a joke?",
  },
]);

----------------------------------------

TITLE: Creating Vector Store from Text Chunks
DESCRIPTION: Example demonstrating how to initialize a vector store directly from prepared text chunks using the MemoryVectorStore implementation.

LANGUAGE: typescript
CODE:
import ExampleTexts from "@examples/indexes/vector_stores/memory.ts";

----------------------------------------

TITLE: Using ChatGroq model in TypeScript
DESCRIPTION: This snippet demonstrates how to import and use the ChatGroq model from @langchain/groq. It creates a new ChatGroq instance, sends a human message, and invokes the model.

LANGUAGE: typescript
CODE:
import { ChatGroq } from "@langchain/groq";
import { HumanMessage } from "@langchain/core/messages";

const model = new ChatGroq({
  apiKey: process.env.GROQ_API_KEY, // Default value.
});

const message = new HumanMessage("What color is the sky?");

const res = await model.invoke([message]);

----------------------------------------

TITLE: Implementing Recursive Text Splitting in TypeScript
DESCRIPTION: This snippet shows how to use LangChain's RecursiveCharacterTextSplitter to split a document into chunks. It recursively splits the text based on natural language structures, with a chunk size of 100 characters and no overlap.

LANGUAGE: typescript
CODE:
import { RecursiveCharacterTextSplitter } from "@langchain/textsplitters";

const textSplitter = new RecursiveCharacterTextSplitter({
  chunkSize: 100,
  chunkOverlap: 0,
});
const texts = await textSplitter.splitText(document);

----------------------------------------

TITLE: Using LangChain Expression Language with OpenAI
DESCRIPTION: Demonstrates how to use LangChain Expression Language (LCEL) with OpenAI's chat model to create a simple question-answering chain.

LANGUAGE: typescript
CODE:
import { StringOutputParser } from "@langchain/core/output_parsers";
import { ChatPromptTemplate } from "@langchain/core/prompts";
import { ChatOpenAI } from "@langchain/openai";

const prompt = ChatPromptTemplate.fromTemplate(
  `Answer the following question to the best of your ability:\n{question}`
);

const model = new ChatOpenAI({
  temperature: 0.8,
});

const outputParser = new StringOutputParser();

const chain = prompt.pipe(model).pipe(outputParser);

const stream = await chain.stream({
  question: "Why is the sky blue?",
});

for await (const chunk of stream) {
  console.log(chunk);
}

/*
The
 sky
 appears
 blue
 because
 of
 a
 phenomenon
 known
 as
 Ray
leigh
 scattering
*/

----------------------------------------

TITLE: Initializing MemoryVectorStore in TypeScript
DESCRIPTION: This snippet demonstrates how to initialize a MemoryVectorStore instance with an embedding model in LangChain.

LANGUAGE: typescript
CODE:
import { MemoryVectorStore } from "langchain/vectorstores/memory";
// Initialize with an embedding model
const vectorStore = new MemoryVectorStore(new SomeEmbeddingModel());

----------------------------------------

TITLE: Implementing Self-Query Retriever for Metadata Filtering
DESCRIPTION: Shows how to use the SelfQueryRetriever to convert natural language queries into metadata filters. This implementation combines ChatOpenAI with vector store capabilities for enhanced document retrieval.

LANGUAGE: typescript
CODE:
import { SelfQueryRetriever } from "langchain/retrievers/self_query";
import { AttributeInfo } from "langchain/chains/query_constructor";
import { ChatOpenAI } from "@langchain/openai";

const attributeInfo: AttributeInfo[] = schemaForMetadata;
const documentContents = "Brief summary of a movie";
const llm = new ChatOpenAI({ temperature: 0 });
const retriever = SelfQueryRetriever.fromLLM({
  llm,
  vectorStore,
  documentContents,
  attributeInfo,
});

----------------------------------------

TITLE: Implementing LLM API Error Fallbacks in TypeScript
DESCRIPTION: Demonstrates how to create a fallback chain for handling LLM API errors using OpenAI and Anthropic models. It includes error handling and retrying logic.

LANGUAGE: typescript
CODE:
import ModelExample from "@examples/guides/fallbacks/model.ts";

----------------------------------------

TITLE: Implementing Cosine Similarity for Embedding Comparison in TypeScript
DESCRIPTION: Defines a function to calculate cosine similarity between two vectors. This is commonly used to measure similarity between embeddings, especially recommended for OpenAI embeddings.

LANGUAGE: typescript
CODE:
function cosineSimilarity(vec1: number[], vec2: number[]): number {
  const dotProduct = vec1.reduce((sum, val, i) => sum + val * vec2[i], 0);
  const norm1 = Math.sqrt(vec1.reduce((sum, val) => sum + val * val, 0));
  const norm2 = Math.sqrt(vec2.reduce((sum, val) => sum + val * val, 0));
  return dotProduct / (norm1 * norm2);
}

const similarity = cosineSimilarity(queryResult, documentResult);
console.log("Cosine Similarity:", similarity);

----------------------------------------

TITLE: Creating Human Message with Text Content in TypeScript
DESCRIPTION: Example of creating a basic HumanMessage object with text content for use with a chat model.

LANGUAGE: typescript
CODE:
import { HumanMessage } from "@langchain/core/messages";

await model.invoke([new HumanMessage("Hello, how are you?")]);

----------------------------------------

TITLE: Invoking a Model with Bound Tools in TypeScript
DESCRIPTION: Illustrates how to invoke a model with bound tools. The example shows invoking the model with both relevant and irrelevant inputs to demonstrate tool calling behavior.

LANGUAGE: typescript
CODE:
const result = await llmWithTools.invoke("Hello world!");

const result = await llmWithTools.invoke("What is 2 multiplied by 3?");

----------------------------------------

TITLE: Output of ChatPromptTemplate Invocation in TypeScript
DESCRIPTION: This snippet displays the output of invoking a ChatPromptTemplate. It shows that the result is a ChatPromptValue object containing a list of formatted messages.

LANGUAGE: text
CODE:
ChatPromptValue {
  messages: [
    SystemMessage {
      "content": "You are a helpful assistant",
      "additional_kwargs": {},
      "response_metadata": {}
    },
    HumanMessage {
      "content": "Tell me a joke about cats",
      "additional_kwargs": {},
      "response_metadata": {}
    }
  ]
}

----------------------------------------

TITLE: Basic Retriever Usage Example
DESCRIPTION: Demonstrates the basic usage of a retriever in LangChain, showing how to invoke the retriever with a query to get back relevant documents.

LANGUAGE: typescript
CODE:
const docs = await retriever.invoke(query);

----------------------------------------

TITLE: Creating and Using String PromptTemplate in TypeScript
DESCRIPTION: This snippet demonstrates how to create a String PromptTemplate and invoke it with a parameter. It uses the PromptTemplate.fromTemplate method to create a template for a joke about a specific topic.

LANGUAGE: typescript
CODE:
import { PromptTemplate } from "@langchain/core/prompts";

const promptTemplate = PromptTemplate.fromTemplate(
  "Tell me a joke about {topic}"
);

await promptTemplate.invoke({ topic: "cats" });

----------------------------------------

TITLE: Embedding Documents with OpenAI in TypeScript
DESCRIPTION: Demonstrates how to use LangChain's OpenAIEmbeddings class to embed multiple documents. It shows the usage of the embedDocuments method and logs the dimensions of the resulting embeddings.

LANGUAGE: typescript
CODE:
import { OpenAIEmbeddings } from "@langchain/openai";
const embeddingsModel = new OpenAIEmbeddings();
const embeddings = await embeddingsModel.embedDocuments([
  "Hi there!",
  "Oh, hello!",
  "What's your name?",
  "My friends call me World",
  "Hello World!",
]);

console.log(`(${embeddings.length}, ${embeddings[0].length})`);
// (5, 1536)

----------------------------------------

TITLE: Implementing ChatFriendli with LangChain in TypeScript
DESCRIPTION: Example code demonstrating how to initialize and use ChatFriendli for generating chat responses using LangChain. It includes setting up the chat model, creating a prompt, and generating both synchronous and asynchronous responses.

LANGUAGE: typescript
CODE:
import { ChatFriendli } from "@langchain/community/chat_models/friendli";
import { HumanMessage } from "@langchain/core/messages";

const chat = new ChatFriendli({
  modelName: "meta-llama-7b-instruct", // Default: meta-llama-3-8b-instruct
});

const messages = [
  new HumanMessage(
    "What would be a good company name for a company that makes colorful socks?"
  ),
];

// You can create a chat response like this:
const response = await chat.invoke(messages);
console.log(response);

// You can create a chat response stream like this:
const stream = await chat.stream(messages);
for await (const chunk of stream) {
  console.log(chunk.content);
}

// You can create an async chat response like this:
const asyncResponse = await chat.ainvoke(messages);
console.log(asyncResponse);

// You can create an async chat response stream like this:
const asyncStream = await chat.astream(messages);
for await (const chunk of asyncStream) {
  console.log(chunk.content);
}

----------------------------------------

TITLE: Alternative MessagesPlaceholder Usage in ChatPromptTemplate in TypeScript
DESCRIPTION: This snippet shows an alternative way to use MessagesPlaceholder in a ChatPromptTemplate without explicitly using the MessagesPlaceholder class. It uses a 'placeholder' key in the message array to achieve the same result.

LANGUAGE: typescript
CODE:
const promptTemplate = ChatPromptTemplate.fromMessages([
  ["system", "You are a helpful assistant"],
  ["placeholder", "{msgs}"], // <-- This is the changed part
]);

----------------------------------------

TITLE: Using withStructuredOutput Method in LangChain.js
DESCRIPTION: Illustrates the use of the withStructuredOutput() helper function in LangChain.js. It binds the schema to the model and parses the output to the specified output schema, streamlining the process of producing structured output.

LANGUAGE: typescript
CODE:
// Bind the schema to the model
const modelWithStructure = model.withStructuredOutput(ResponseFormatter);
// Invoke the model
const structuredOutput = await modelWithStructure.invoke(
  "What is the powerhouse of the cell?"
);
// Get back the object
console.log(structuredOutput);
// { answer: "The powerhouse of the cell is the mitochondrion. Mitochondria are organelles that generate most of the cell's supply of adenosine triphosphate (ATP), which is used as a source of chemical energy.", followup_question: "What is the function of ATP in the cell?" }

----------------------------------------

TITLE: Implementing Momento-Backed Chat Memory in LangChain.js
DESCRIPTION: TypeScript code demonstrating how to set up and use Momento-backed chat memory in a LangChain.js application. It includes creating a Momento cache client, initializing chat memory, and using it with a conversation chain.

LANGUAGE: typescript
CODE:
import { ChatOpenAI } from "@langchain/openai";
import { MomentoChatMessageHistory } from "@langchain/community/stores/message/momento";
import { ConversationChain } from "langchain/chains";
import { BufferMemory } from "langchain/memory";

import { CacheClient, Configurations, CredentialProvider } from "@gomomento/sdk";

// Example that shows how to use Momento as a memory store for chat history

// Create a cache client
const client = new CacheClient({
  configuration: Configurations.Laptop.v1(),
  credentialProvider: CredentialProvider.fromEnvironmentVariable({
    environmentVariableName: "MOMENTO_AUTH_TOKEN",
  }),
  defaultTtlSeconds: 60 * 60 * 24, // 24 hours
});

// Instantiate the chat memory
const memory = new BufferMemory({
  chatHistory: await MomentoChatMessageHistory.fromProps({
    client,
    cacheName: "langchain-memory",
    sessionId: "test-session",
    sessionTtl: 300, // 5 minutes
  }),
});

// Create the chain
const model = new ChatOpenAI();
const chain = new ConversationChain({ llm: model, memory });

// Invoke the chain
const res1 = await chain.call({ input: "Hi! I'm Jim." });
console.log({ res1 });

const res2 = await chain.call({ input: "What's my name?" });
console.log({ res2 });


----------------------------------------

TITLE: Embedding Single Query with OpenAI in TypeScript
DESCRIPTION: Shows how to use the embedQuery method of OpenAIEmbeddings to embed a single text query. This is useful for scenarios where you need to embed a search query.

LANGUAGE: typescript
CODE:
const queryEmbedding = await embeddingsModel.embedQuery(
  "What is the meaning of life?"
);

----------------------------------------

TITLE: Importing ChatOpenAI Model in TypeScript
DESCRIPTION: This snippet shows how to import the ChatOpenAI model from the @langchain/openai package. It is used for integrating OpenAI's chat capabilities into LangChain.js applications.

LANGUAGE: typescript
CODE:
import { ChatOpenAI } from "@langchain/openai";

----------------------------------------

TITLE: Creating a Multiplication Tool in TypeScript
DESCRIPTION: Demonstrates how to create a simple multiplication tool using the `tool` function from LangChain.js. The tool takes two numbers as input and returns their product.

LANGUAGE: typescript
CODE:
import { tool } from "@langchain/core/tools";
import { z } from "zod";

const multiply = tool(
  ({ a, b }: { a: number; b: number }): number => {
    /**
     * Multiply two numbers.
     */
    return a * b;
  },
  {
    name: "multiply",
    description: "Multiply two numbers",
    schema: z.object({
      a: z.number(),
      b: z.number(),
    }),
  }
);

----------------------------------------

TITLE: Streaming with Llama CPP using invoke method and signal in LangChain.js
DESCRIPTION: Example showing how to use the 'invoke' method for stream generation with Llama CPP in LangChain.js, including the use of 'signal' to abort generation.

LANGUAGE: typescript
CODE:
import StreamInvokeExample from "@examples/models/chat/integration_llama_cpp_stream_invoke.ts";

<CodeBlock language="typescript">{StreamInvokeExample}</CodeBlock>

----------------------------------------

TITLE: Creating Few Shot Prompt Template with Examples in TypeScript
DESCRIPTION: Demonstrates how to create a few shot prompt template with examples and format it.

LANGUAGE: typescript
CODE:
const examples = [
  {
    input: "Could the members of The Police perform lawful arrests?",
    output: "what can the members of The Police do?",
  },
  {
    input: "Jan Sindel's was born in what country?",
    output: "what is Jan Sindel's personal history?",
  },
];
const examplePrompt = ChatPromptTemplate.fromTemplate(`Human: {input}
AI: {output}`);
const fewShotPrompt = new FewShotChatMessagePromptTemplate({
  examplePrompt,
  examples,
  inputVariables: [], // no input variables
});

const formattedPrompt = await fewShotPrompt.format({});
console.log(formattedPrompt);

----------------------------------------

TITLE: Defining Zod Schema for Structured Output in TypeScript
DESCRIPTION: Shows how to define a Zod schema for structured output in TypeScript. The schema includes an answer field and a follow-up question field, both with descriptions.

LANGUAGE: typescript
CODE:
import { z } from "zod";

const ResponseFormatter = z.object({
  answer: z.string().describe("The answer to the user's question"),
  followup_question: z
    .string()
    .describe("A followup question the user could ask"),
});

----------------------------------------

TITLE: Basic Vector Search Example with Couchbase in TypeScript
DESCRIPTION: Complete TypeScript example demonstrating how to load documents, create embeddings, initialize CouchbaseVectorStore, and perform similarity searches.

LANGUAGE: typescript
CODE:
import { OpenAIEmbeddings } from "@langchain/openai";
import {
  CouchbaseVectorStoreArgs,
  CouchbaseVectorStore,
} from "@langchain/community/vectorstores/couchbase";
import { Cluster } from "couchbase";
import { TextLoader } from "langchain/document_loaders/fs/text";
import { CharacterTextSplitter } from "@langchain/textsplitters";

const connectionString =
  process.env.COUCHBASE_DB_CONN_STR ?? "couchbase://localhost";
const databaseUsername = process.env.COUCHBASE_DB_USERNAME ?? "Administrator";
const databasePassword = process.env.COUCHBASE_DB_PASSWORD ?? "Password";

// Load documents from file
const loader = new TextLoader("./state_of_the_union.txt");
const rawDocuments = await loader.load();
const splitter = new CharacterTextSplitter({
  chunkSize: 500,
  chunkOverlap: 0,
});
const docs = await splitter.splitDocuments(rawDocuments);

const couchbaseClient = await Cluster.connect(connectionString, {
  username: databaseUsername,
  password: databasePassword,
  configProfile: "wanDevelopment",
});

// Open AI API Key is required to use OpenAIEmbeddings, some other embeddings may also be used
const embeddings = new OpenAIEmbeddings({
  apiKey: process.env.OPENAI_API_KEY,
});

const couchbaseConfig: CouchbaseVectorStoreArgs = {
  cluster: couchbaseClient,
  bucketName: "testing",
  scopeName: "_default",
  collectionName: "_default",
  indexName: "vector-index",
  textKey: "text",
  embeddingKey: "embedding",
};

const store = await CouchbaseVectorStore.fromDocuments(
  docs,
  embeddings,
  couchbaseConfig
);

const query = "What did president say about Ketanji Brown Jackson";

const resultsSimilaritySearch = await store.similaritySearch(query);
console.log("resulting documents: ", resultsSimilaritySearch[0]);

// Similarity Search With Score
const resultsSimilaritySearchWithScore = await store.similaritySearchWithScore(
  query,
  1
);
console.log("resulting documents: ", resultsSimilaritySearchWithScore[0][0]);
console.log("resulting scores: ", resultsSimilaritySearchWithScore[0][1]);

const result = await store.similaritySearch(query, 1, {
  fields: ["metadata.source"],
});
console.log(result[0]);

----------------------------------------

TITLE: Manipulating Inputs/Outputs with RunnableSequence in LangChain
DESCRIPTION: Shows how to use RunnableSequence and RunnableParallel to manipulate inputs and outputs, formatting data for a prompt template.

LANGUAGE: typescript
CODE:
import { ChatOpenAI } from "@langchain/openai";
import { ChatPromptTemplate } from "@langchain/core/prompts";
import { StringOutputParser } from "@langchain/core/output_parsers";
import { RunnableSequence } from "@langchain/core/runnables";

const model = new ChatOpenAI();
const retriever = new FakeRetriever();
const prompt = ChatPromptTemplate.fromTemplate(`Answer the question based on the following context:

Context: {context}

Question: {question}`);

const chain = RunnableSequence.from([
  {
    context: retriever,
    question: (input) => input.question,
  },
  prompt,
  model,
  new StringOutputParser(),
]);

const result = await chain.invoke({
  question: "What is the meaning of life?",
});
console.log(result);

----------------------------------------

TITLE: Invoking Runnable with Configuration - TypeScript
DESCRIPTION: Example showing how to invoke a Runnable with custom configuration parameters including run name, tags, and metadata.

LANGUAGE: typescript
CODE:
await someRunnable.invoke(someInput, {
  runName: "myRun",
  tags: ["tag1", "tag2"],
  metadata: { key: "value" },
});

----------------------------------------

TITLE: Using Custom Retriever in TypeScript
DESCRIPTION: This snippet shows how to instantiate and use the custom retriever. It demonstrates invoking the retriever with a query string and displays the expected output format.

LANGUAGE: typescript
CODE:
const retriever = new CustomRetriever({});

await retriever.invoke("LangChain docs");

----------------------------------------

TITLE: Implementing Aurora DSQL Chat Memory in TypeScript
DESCRIPTION: Example code demonstrating how to set up and use Aurora DSQL for persistent chat memory in a LangChain.js project. It includes AWS SDK authentication and PostgreSQL pool configuration.

LANGUAGE: typescript
CODE:
import { ChatOpenAI } from "@langchain/openai";
import { AuroraDSQLChatMessageHistory } from "@langchain/community/stores/message/aurora_dsql";
import { BufferMemory } from "@langchain/community/memories/buffer";
import { getDSQLAuthenticationToken } from "@aws-sdk/dsql-signer";

const chatId = "chat_id";

const getToken = async () => {
  const token = await getDSQLAuthenticationToken({
    endpoint: "<endpoint>",
    port: 1234,
    username: "<username>",
    region: "<region>",
  });
  return token;
};

const memory = new BufferMemory({
  chatHistory: new AuroraDSQLChatMessageHistory({
    sessionId: chatId,
    poolConfig: {
      host: "<host>",
      port: 1234,
      user: "<username>",
      password: await getToken(),
      database: "postgres",
      ssl: true,
    },
  }),
});

const model = new ChatOpenAI();
const chain = await model.bind({
  memory,
});

const res1 = await chain.invoke({
  content: "Hello! My name is Claude.",
});
console.log(res1);
/*
{
  content: "Hello Claude! It's nice to meet you. How can I assist you today?"
}
*/

const res2 = await chain.invoke({
  content: "What's my name?",
});
console.log(res2);
/*
{
  content: "Your name is Claude. You mentioned it in your introduction earlier."
}
*/

----------------------------------------

TITLE: Installing LangChain.js Dependencies
DESCRIPTION: Command to install required npm packages @langchain/openai and @langchain/core for implementing vector store retrieval functionality.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/core

----------------------------------------

TITLE: RunnableBranch Routing Implementation
DESCRIPTION: Example showing how to use RunnableBranch for condition-based routing in LangChain, with multiple branches and a default fallback.

LANGUAGE: typescript
CODE:
BranchExample

----------------------------------------

TITLE: Using .stream() Method with LLM
DESCRIPTION: Example demonstrating how to use the .stream() method to stream LLM responses. Returns a readable stream that can be iterated over for token-by-token output.

LANGUAGE: typescript
CODE:
{StreamMethodExample}

----------------------------------------

TITLE: Setting Custom Run ID - TypeScript
DESCRIPTION: Example demonstrating how to set a custom run ID when invoking a Runnable using UUID.

LANGUAGE: typescript
CODE:
import { v4 as uuidv4 } from "uuid";

const runId = uuidv4();

await someRunnable.invoke(someInput, {
  runId,
});

// Do something with the runId

----------------------------------------

TITLE: ChatBaiduQianfan Streaming Implementation
DESCRIPTION: Example of implementing streaming token responses with Baidu Qianfan's API. References an external example file 'chat_stream_baidu_qianfan.ts' for the complete streaming implementation.

LANGUAGE: typescript
CODE:
ChatBaiduQianfanStreamExample

----------------------------------------

TITLE: Implementing Character-Based Text Splitting in TypeScript
DESCRIPTION: This snippet demonstrates how to use LangChain's CharacterTextSplitter to split a document into chunks based on character count. It sets a chunk size of 100 characters with no overlap between chunks.

LANGUAGE: typescript
CODE:
import { CharacterTextSplitter } from "@langchain/textsplitters";
const textSplitter = new CharacterTextSplitter({
  chunkSize: 100,
  chunkOverlap: 0,
});
const texts = await textSplitter.splitText(document);

----------------------------------------

TITLE: Creating and Using ChatPromptTemplate in TypeScript
DESCRIPTION: This snippet illustrates how to create a ChatPromptTemplate with system and user messages, and invoke it with a parameter. It uses ChatPromptTemplate.fromMessages to create a template with multiple message types.

LANGUAGE: typescript
CODE:
import { ChatPromptTemplate } from "@langchain/core/prompts";

const promptTemplate = ChatPromptTemplate.fromMessages([
  ["system", "You are a helpful assistant"],
  ["user", "Tell me a joke about {topic}"],
]);

await promptTemplate.invoke({ topic: "cats" });

----------------------------------------

TITLE: Tracking Token Usage for OpenAI LLM Calls in TypeScript
DESCRIPTION: This code demonstrates how to create an OpenAI chat model instance and use a callback to track token usage. It shows the setup of the model, the callback function, and how to make an LLM call while logging the token usage.

LANGUAGE: typescript
CODE:
import { ChatOpenAI } from "@langchain/openai";
import { StringOutputParser } from "@langchain/core/output_parsers";

const model = new ChatOpenAI({
  callbacks: [{
    handleLLMEnd(output) {
      console.log(JSON.stringify(output.llmOutput?.tokenUsage, null, 2));
    },
  }],
});

const chain = model.pipe(new StringOutputParser());

const response = await chain.invoke("Hello, how are you?");

console.log(response);

----------------------------------------

TITLE: Calculating Time-Weighted Score in TypeScript
DESCRIPTION: Demonstrates the core scoring algorithm that combines semantic similarity with time decay. The score is calculated using the decay rate and hours passed since last access.

LANGUAGE: typescript
CODE:
let score = (1.0 - this.decayRate) ** hoursPassed + vectorRelevance;

----------------------------------------

TITLE: Setting Callbacks for Runnable - TypeScript
DESCRIPTION: Example showing how to configure callbacks when invoking a Runnable.

LANGUAGE: typescript
CODE:
await someRunnable.invoke(someInput, {
  callbacks: [SomeCallbackHandler(), AnotherCallbackHandler()],
});

----------------------------------------

TITLE: Performing Similarity Search in VectorStore with TypeScript
DESCRIPTION: This code demonstrates how to perform a similarity search on a vector store using a query string in LangChain.

LANGUAGE: typescript
CODE:
const query = "my query";
const docs = await vectorstore.similaritySearch(query);

----------------------------------------

TITLE: Basic RunnableParallel Usage in LangChain
DESCRIPTION: Demonstrates the basic usage of RunnableParallel to execute multiple language models in parallel, processing a given topic.

LANGUAGE: typescript
CODE:
import { ChatAnthropic } from "@langchain/anthropic";
import { Cohere } from "@langchain/cohere";
import { RunnableParallel } from "@langchain/core/runnables";

const anthropic = new ChatAnthropic({ temperature: 0 });
const cohere = new Cohere({ temperature: 0 });

const chain = RunnableParallel({
  anthropic: anthropic.invoke("Tell me a short joke about {topic}"),
  cohere: cohere.call("Tell me a short joke about {topic}"),
});

const result = await chain.invoke({ topic: "bears" });
console.log(result);

----------------------------------------

TITLE: Initializing Weaviate Vector Store
DESCRIPTION: TypeScript code to initialize Weaviate client and create a vector store with sample texts and metadata using OpenAI embeddings.

LANGUAGE: typescript
CODE:
import weaviate, { ApiKey } from 'weaviate-ts-client';
import { WeaviateStore } from "@langchain/weaviate";

// Weaviate SDK has a TypeScript issue so we must do this.
const client = (weaviate as any).client({
  scheme: process.env.WEAVIATE_SCHEME || "https",
  host: process.env.WEAVIATE_HOST || "localhost",
  apiKey: new ApiKey(
    process.env.WEAVIATE_API_KEY || "default"
  ),
});

// Create a store and fill it with some texts + metadata
await WeaviateStore.fromTexts(
  ["hello world", "hi there", "how are you", "bye now"],
  [{ foo: "bar" }, { foo: "baz" }, { foo: "qux" }, { foo: "bar" }],
  new OpenAIEmbeddings(),
  {
    client,
    indexName: "Test",
    textKey: "text",
    metadataKeys: ["foo"],
  }
);

----------------------------------------

TITLE: Using ChatGoogleGenerativeAI with Gemini Pro
DESCRIPTION: Demonstrates how to initialize and use the ChatGoogleGenerativeAI model with Gemini Pro, including setting max output tokens and invoking the model.

LANGUAGE: typescript
CODE:
import { ChatGoogleGenerativeAI } from "@langchain/google-genai";

const model = new ChatGoogleGenerativeAI({
  model: "gemini-pro",
  maxOutputTokens: 2048,
});

// Batch and stream are also supported
const res = await model.invoke([
  [
    "human",
    "What would be a good company name for a company that makes colorful socks?",
  ],
]);

----------------------------------------

TITLE: Using ChatVertexAI with Gemini Pro
DESCRIPTION: Demonstrates how to initialize and use the ChatVertexAI model with Gemini Pro, including setting max output tokens and invoking the model.

LANGUAGE: typescript
CODE:
import { ChatVertexAI } from "@langchain/google-vertexai";
// Or, if using the web entrypoint:
// import { ChatVertexAI } from "@langchain/google-vertexai-web";

const model = new ChatVertexAI({
  model: "gemini-1.0-pro",
  maxOutputTokens: 2048,
});

// Batch and stream are also supported
const res = await model.invoke([
  [
    "human",
    "What would be a good company name for a company that makes colorful socks?",
  ],
]);

----------------------------------------

TITLE: Vector Store to Retriever Conversion in TypeScript
DESCRIPTION: Shows how to convert a vector store instance into a retriever using the asRetriever() method.

LANGUAGE: typescript
CODE:
const vectorstore = new MyVectorStore();
const retriever = vectorstore.asRetriever();

----------------------------------------

TITLE: Extending BaseDocumentLoader in TypeScript
DESCRIPTION: This snippet shows the abstract class definition for BaseDocumentLoader. To implement a custom loader, you need to extend this class and implement the load() method.

LANGUAGE: typescript
CODE:
abstract class BaseDocumentLoader implements DocumentLoader {
  abstract load(): Promise<Document[]>;
}

----------------------------------------

TITLE: Using AnalyticDB Vector Store with LangChain.js
DESCRIPTION: This code snippet demonstrates how to use AnalyticDB vector store with LangChain.js. It includes importing necessary modules, setting up the database connection, and performing vector operations such as adding documents and similarity searches.

LANGUAGE: typescript
CODE:
import { AnalyticDBVectorStore } from "@langchain/community/vectorstores/analyticdb";
import { OpenAIEmbeddings } from "@langchain/openai";

const connectionOptions = {
  connectionString:
    "postgres://username:password@host:5432/database?ssl=true",
};

const vectorStore = await AnalyticDBVectorStore.initialize(
  new OpenAIEmbeddings(),
  connectionOptions
);

await vectorStore.addDocuments([
  { pageContent: "Hello World", metadata: { a: 1 } },
  { pageContent: "Bye bye", metadata: { b: 2 } },
]);

const results = await vectorStore.similaritySearch("Hello World", 1);
console.log(results);

----------------------------------------

TITLE: Azure AI Search Example Implementation
DESCRIPTION: Complete example demonstrating document indexing, hybrid search querying, and LLM integration with Azure AI Search vector store.

LANGUAGE: typescript
CODE:
<Example>

----------------------------------------

TITLE: LangChain Indexing API Example in TypeScript
DESCRIPTION: Demonstrates basic usage of LangChain's indexing API for maintaining vector stores. The code shows how to set up record management and handle document indexing with different cleanup modes.

LANGUAGE: typescript
CODE:
import { Document } from "@langchain/core/documents";
import { OpenAIEmbeddings } from "@langchain/openai";
import { Chroma } from "@langchain/community/vectorstores/chroma";
import { InMemoryRecordManager, VectorStoreIndexer } from "@langchain/community/indexes/memory";

const recordManager = new InMemoryRecordManager();
const embeddings = new OpenAIEmbeddings();
const vectorstore = new Chroma(embeddings, {
  collectionName: "test-collection",
});

const indexer = new VectorStoreIndexer({
  vectorstore,
  recordManager,
  // Cleanup deletes outdated content originating from same sources as current batch content
  cleanupMode: "incremental",
});

const docs = [
  new Document({
    pageContent: "a new doc to index",
    metadata: {
      // Helps track where document came from
      source: "a",
      // Helps track versions
      version: "1",
    },
  }),
];

// Writes documents to the vectorstore and tracks the writes in the record manager
await indexer.addDocuments(docs);

----------------------------------------

TITLE: Implementing MultiVectorRetriever with Smaller Chunks in TypeScript
DESCRIPTION: Example demonstrating how to use MultiVectorRetriever with smaller document chunks for improved embedding and retrieval in LangChain.js.

LANGUAGE: typescript
CODE:
import CodeBlock from "@theme/CodeBlock";
import SmallChunksExample from "@examples/retrievers/multi_vector_small_chunks.ts";

<CodeBlock language="typescript">{SmallChunksExample}</CodeBlock>

----------------------------------------

TITLE: Invoking a Retriever in TypeScript
DESCRIPTION: Demonstrates how to use LangChain's standardized retriever interface to fetch documents based on a query. This example shows the common invocation pattern for retrievers, regardless of the underlying data store.

LANGUAGE: typescript
CODE:
const documents = await myRetriever.invoke("What is the meaning of life?");

----------------------------------------

TITLE: Querying OpenSearch Vector Store in LangChain.js
DESCRIPTION: TypeScript code showing how to query the OpenSearch vector store using LangChain.js. It demonstrates both direct similarity search and integration with a VectorDBQAChain for question answering.

LANGUAGE: typescript
CODE:
import { Client } from "@opensearch-project/opensearch";
import { VectorDBQAChain } from "langchain/chains";
import { OpenAIEmbeddings } from "@langchain/openai";
import { OpenAI } from "@langchain/openai";
import { OpenSearchVectorStore } from "@langchain/community/vectorstores/opensearch";

const client = new Client({
  nodes: [process.env.OPENSEARCH_URL ?? "http://127.0.0.1:9200"],
});

const vectorStore = new OpenSearchVectorStore(new OpenAIEmbeddings(), {
  client,
});

/* Search the vector DB independently with meta filters */
const results = await vectorStore.similaritySearch("hello world", 1);
console.log(JSON.stringify(results, null, 2));
/* [{
      "pageContent": "Hello world",
      "metadata": {
        "id": 2
      }
    }] */

/* Use as part of a chain (currently no metadata filters) */
const model = new OpenAI();
const chain = VectorDBQAChain.fromLLM(model, vectorStore, {
  k: 1,
  returnSourceDocuments: true,
});
const response = await chain.call({ query: "What is opensearch?" });

console.log(JSON.stringify(response, null, 2));
/*
  {
    "text": " Opensearch is a collection of technologies that allow search engines to publish search results in a standard format, making it easier for users to search across multiple sites.",
    "sourceDocuments": [
      {
        "pageContent": "What's this?",
        "metadata": {
          "id": 3
        }
      }
    ]
  }
  */

----------------------------------------

TITLE: Initializing ChatAnthropic Model in TypeScript
DESCRIPTION: Code snippet demonstrating how to import and initialize the ChatAnthropic model in a TypeScript environment. This creates a new instance of the ChatAnthropic model with default settings.

LANGUAGE: typescript
CODE:
import { ChatAnthropic } from "@langchain/anthropic";
const model = new ChatAnthropic({});

----------------------------------------

TITLE: Importing OpenAI LLM in TypeScript
DESCRIPTION: This snippet shows how to import the OpenAI language model from the @langchain/openai package. It is used for integrating OpenAI's LLM capabilities into LangChain.js applications.

LANGUAGE: typescript
CODE:
import { OpenAI } from "@langchain/openai";

----------------------------------------

TITLE: Inferring Model Provider with initChatModel() in LangChain.js
DESCRIPTION: Shows how initChatModel() can infer the model provider based on common model names. It demonstrates this capability with OpenAI and Anthropic models.

LANGUAGE: typescript
CODE:
import { initChatModel } from "langchain/chat_models/universal";

const openaiModel = await initChatModel({
  model: "gpt-3.5-turbo",
  openAIApiKey: "<your_api_key>",
});

const anthropicModel = await initChatModel({
  model: "claude-2",
  anthropicApiKey: "<your_api_key>",
});

----------------------------------------

TITLE: Creating USearch Index from Texts in TypeScript
DESCRIPTION: This code demonstrates how to create a new USearch index from a list of texts using LangChain.js. It includes setting up the embeddings, creating the USearch vector store, and performing similarity searches.

LANGUAGE: typescript
CODE:
import { OpenAIEmbeddings } from "@langchain/openai";
import { USearch } from "@langchain/community/vectorstores/usearch";

const embeddings = new OpenAIEmbeddings();
const texts = ["Hello world", "Bye bye", "What's this?"]

const vectorStore = await USearch.fromTexts(
  texts,
  texts.map((_, i) => ({ id: i })),
  embeddings
);

const resultOne = await vectorStore.similaritySearch("Hello world", 1);
console.log(resultOne);

----------------------------------------

TITLE: ParentDocumentRetriever with Contextual Headers
DESCRIPTION: Example showing how to implement ParentDocumentRetriever with chunk headers for better context preservation.

LANGUAGE: typescript
CODE:
{ExampleWithChunkHeader}

----------------------------------------

TITLE: Basic Semantic Similarity Example Selector
DESCRIPTION: Implementation of a semantic similarity-based example selector that uses embeddings to find the most similar examples based on cosine similarity.

LANGUAGE: typescript
CODE:
{ExampleSimilarity}

----------------------------------------

TITLE: Loading Multiple File Types with DirectoryLoader
DESCRIPTION: Demonstrates how to configure and use DirectoryLoader to load different file types using specific loaders for each extension. The loader maps file extensions to appropriate loader instances and concatenates all documents.

LANGUAGE: typescript
CODE:
import { DirectoryLoader } from "langchain/document_loaders/fs/directory";
import {
  JSONLoader,
  JSONLinesLoader,
} from "langchain/document_loaders/fs/json";
import { TextLoader } from "langchain/document_loaders/fs/text";
import { CSVLoader } from "@langchain/community/document_loaders/fs/csv";

const loader = new DirectoryLoader(
  "src/document_loaders/example_data/example",
  {
    ".json": (path) => new JSONLoader(path, "/texts"),
    ".jsonl": (path) => new JSONLinesLoader(path, "/html"),
    ".txt": (path) => new TextLoader(path),
    ".csv": (path) => new CSVLoader(path, "text"),
  }
);
const docs = await loader.load();
console.log({ docs });

----------------------------------------

TITLE: Basic Usage of initChatModel() in LangChain.js
DESCRIPTION: Demonstrates the basic usage of initChatModel() to initialize chat models based on user configuration. It shows how to create models for different providers like OpenAI, Anthropic, and Ollama.

LANGUAGE: typescript
CODE:
import { initChatModel } from "langchain/chat_models/universal";

const openaiModel = await initChatModel({
  modelProvider: "openai",
  model: "gpt-3.5-turbo",
  temperature: 0,
  openAIApiKey: "<your_api_key>",
});

const anthropicModel = await initChatModel({
  modelProvider: "anthropic",
  model: "claude-2",
  anthropicApiKey: "<your_api_key>",
});

const ollamaModel = await initChatModel({
  modelProvider: "ollama",
  model: "llama2",
  baseUrl: "http://localhost:11434",
});

----------------------------------------

TITLE: Using Web Browser Tool in an Agent
DESCRIPTION: Example of how to integrate the Web Browser Tool into an agent in a TypeScript project. This snippet shows how to set up and use the tool as part of a larger agent-based system.

LANGUAGE: typescript
CODE:
{AgentExample}

----------------------------------------

TITLE: Streaming with CallbackHandler
DESCRIPTION: Implementation of streaming LLM responses using a CallbackHandler, which provides access to the final LLMResult. Note that token usage tracking may not be supported for all model providers when streaming.

LANGUAGE: typescript
CODE:
{StreamingExample}

----------------------------------------

TITLE: Implementing Fallbacks for Improved Model Outputs in TypeScript
DESCRIPTION: Demonstrates using a fallback to a more capable model (GPT-4) when a faster, cheaper model (GPT-3.5) fails to produce the desired output format.

LANGUAGE: typescript
CODE:
import BetterModelExample from "@examples/guides/fallbacks/better_model.ts";

----------------------------------------

TITLE: Implementing MultiVectorRetriever with Document Summaries in TypeScript
DESCRIPTION: Example showing how to create and use document summaries with MultiVectorRetriever for better retrieval performance in LangChain.js.

LANGUAGE: typescript
CODE:
import SummaryExample from "@examples/retrievers/multi_vector_summary.ts";

<CodeBlock language="typescript">{SummaryExample}</CodeBlock>

----------------------------------------

TITLE: Initializing and Using HuggingFaceInference Model in TypeScript
DESCRIPTION: This code demonstrates how to import the HuggingFaceInference class, create a model instance with the 'gpt2' model, and use it to generate text. It requires an API key, which can be set directly or through an environment variable.

LANGUAGE: typescript
CODE:
import { HuggingFaceInference } from "@langchain/community/llms/hf";

const model = new HuggingFaceInference({
  model: "gpt2",
  apiKey: "YOUR-API-KEY", // In Node.js defaults to process.env.HUGGINGFACEHUB_API_KEY
});
const res = await model.invoke("1 + 1 =");
console.log({ res });

----------------------------------------

TITLE: Installing LangChain OpenAI Integration
DESCRIPTION: This code block demonstrates how to install the necessary packages for using OpenAI with LangChain.js. It includes both the OpenAI-specific package and the core LangChain package.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/core

----------------------------------------

TITLE: Configurable Model with Default Values in LangChain.js
DESCRIPTION: Shows how to create a configurable model with default values, specify configurable parameters, and add prefixes to configurable params using initChatModel().

LANGUAGE: typescript
CODE:
import { initChatModel } from "langchain/chat_models/universal";

const configurableModel = await initChatModel({
  modelProvider: "openai",
  model: "gpt-3.5-turbo",
  temperature: 0,
  openAIApiKey: "<your_api_key>",
  configurableFields: [
    "model",
    "temperature",
    { name: "maxTokens", default: 100 },
  ],
  configurableFieldsPrefix: "llm.",
});

const configuredModel = await configurableModel.withConfig({
  "llm.model": "gpt-4",
  "llm.temperature": 0.5,
  "llm.maxTokens": 200,
});

const result = await configuredModel.invoke("Hello, how are you?");
console.log(result);

----------------------------------------

TITLE: Database Setup for Hybrid Search
DESCRIPTION: SQL commands to create the necessary database structure including vector extension, documents table, and search functions for both similarity and keyword matching

LANGUAGE: sql
CODE:
-- Enable the pgvector extension to work with embedding vectors
create extension vector;

-- Create a table to store your documents
create table documents (
  id bigserial primary key,
  content text, -- corresponds to Document.pageContent
  metadata jsonb, -- corresponds to Document.metadata
  embedding vector(1536) -- 1536 works for OpenAI embeddings, change if needed
);

-- Create a function to similarity search for documents
create function match_documents (
  query_embedding vector(1536),
  match_count int DEFAULT null,
  filter jsonb DEFAULT '{}'
) returns table (
  id bigint,
  content text,
  metadata jsonb,
  similarity float
)
language plpgsql
as $$
#variable_conflict use_column
begin
  return query
  select
    id,
    content,
    metadata,
    1 - (documents.embedding <=> query_embedding) as similarity
  from documents
  where metadata @> filter
  order by documents.embedding <=> query_embedding
  limit match_count;
end;
$$;

-- Create a function to keyword search for documents
create function kw_match_documents(query_text text, match_count int)
returns table (id bigint, content text, metadata jsonb, similarity real)
as $$

begin
return query execute
format('select id, content, metadata, ts_rank(to_tsvector(content), plainto_tsquery($1)) as similarity
from documents
where to_tsvector(content) @@ plainto_tsquery($1)
order by similarity desc
limit $2')
using query_text, match_count;
end;
$$ language plpgsql;

----------------------------------------

TITLE: Implementing EnsembleRetriever with Custom and Vector Store Retrievers in TypeScript
DESCRIPTION: This code snippet demonstrates how to create an EnsembleRetriever by combining a custom keyword matching retriever with a vector store retriever. It initializes the retrievers, creates the ensemble, and performs a retrieval operation.

LANGUAGE: typescript
CODE:
import { Document } from "@langchain/core/documents";
import { MemoryVectorStore } from "langchain/vectorstores/memory";
import { FakeEmbeddings } from "langchain/embeddings/fake";
import { EnsembleRetriever } from "langchain/retrievers/ensemble";

const vectorStore = await MemoryVectorStore.fromTexts(
  [
    "Mammals are warm-blooded animals",
    "Reptiles are cold-blooded animals",
    "Birds can fly",
    "Fish live in water",
  ],
  [
    { id: 1 },
    { id: 2 },
    { id: 3 },
    { id: 4 },
  ],
  new FakeEmbeddings()
);

const vectorStoreRetriever = vectorStore.asRetriever();

const customRetriever = {
  async getRelevantDocuments(query: string) {
    const loweredQuery = query.toLowerCase();
    return [
      "Mammals are warm-blooded animals",
      "Reptiles are cold-blooded animals",
      "Birds can fly",
      "Fish live in water",
    ]
      .filter((doc) => doc.toLowerCase().includes(loweredQuery))
      .map((doc) => new Document({ pageContent: doc }));
  },
};

const ensembleRetriever = new EnsembleRetriever({
  retrievers: [vectorStoreRetriever, customRetriever],
});

const result = await ensembleRetriever.getRelevantDocuments("warm-blooded");

console.log(result);

----------------------------------------

TITLE: Configuring pgvector Docker instance
DESCRIPTION: YAML configuration for setting up a self-hosted pgvector instance using Docker Compose. It defines the PostgreSQL service with pgvector extension.

LANGUAGE: yaml
CODE:
version: '3.9'
services:
  db:
    image: ankane/pgvector
    ports:
      - 5432:5432
    volumes:
      - db:/var/lib/postgresql/data
    environment:
      - POSTGRES_PASSWORD=password
      - POSTGRES_USER=myuser
      - POSTGRES_DB=api
volumes:
  db:

----------------------------------------

TITLE: Installing LangChain Dependencies
DESCRIPTION: Installing required npm packages for LangChain.js implementation including OpenAI integration and core components.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/community @langchain/core

----------------------------------------

TITLE: Inspecting Tool Properties in TypeScript
DESCRIPTION: Demonstrates how to access and log the name and description properties of a defined tool.

LANGUAGE: typescript
CODE:
console.log(multiply.name); // multiply
console.log(multiply.description); // Multiply two numbers.

----------------------------------------

TITLE: Initializing and Using WebLLM with LangChain.js
DESCRIPTION: TypeScript code demonstrating how to initialize a WebLLM chat model, create a prompt template, and generate a response. It includes error handling and shows how to use the model in a LangChain chain.

LANGUAGE: typescript
CODE:
import { WebLLM } from "@langchain/community/llms/web_llm";
import { PromptTemplate } from "@langchain/core/prompts";

// Initialize the WebLLM instance
const llm = new WebLLM({
  model: "RedPajama-INCITE-Chat-3B-v1-q4f32_0",
  wasmUrl: "https://huggingface.co/mlc-ai/web-llm/resolve/main/dist/vicuna-v1-7b-q4f32_0.wasm",
});

// Create a prompt template
const prompt = PromptTemplate.fromTemplate(
  "What is the distance between {country1} and {country2}?"
);

try {
  // Format the prompt with specific countries
  const formattedPrompt = await prompt.format({
    country1: "France",
    country2: "Japan",
  });

  // Generate a response using the WebLLM model
  const response = await llm.invoke(formattedPrompt);
  console.log(response);
} catch (e) {
  console.error(e);
}

----------------------------------------

TITLE: Embedding Single Query Text
DESCRIPTION: Demonstrates how to embed a single query string into a vector representation using the embedQuery method.

LANGUAGE: typescript
CODE:
const res = await embeddings.embedQuery("Hello world");
/*
[   -0.004845875,   0.004899438,  -0.016358767,  -0.024475135, -0.017341806,
    0.012571548,  -0.019156644,   0.009036391,  -0.010227379, -0.026945334,
    0.022861943,   0.010321903,  -0.023479493, -0.0066544134,  0.007977734,
   0.0026371893,   0.025206111,  -0.012048521,   0.012943339,  0.013094575,
   -0.010580265,  -0.003509951,   0.004070787,   0.008639394, -0.020631202,
  ... 1511 more items
]*/

----------------------------------------

TITLE: Initializing OpenAI Embeddings
DESCRIPTION: Creates a new instance of OpenAIEmbeddings class to handle text embedding operations.

LANGUAGE: typescript
CODE:
import { OpenAIEmbeddings } from "@langchain/openai";

const embeddings = new OpenAIEmbeddings();

----------------------------------------

TITLE: Implementing Convex Chat Memory in LangChain
DESCRIPTION: This code demonstrates how to use Convex as a chat memory store in a LangChain application, including setup of the Convex client, ChatOpenAI model, and memory integration.

LANGUAGE: typescript
CODE:
import { ConvexHttpClient } from "convex/browser";
import { api } from "../.generated/api";
import { ConvexChatMessageHistory } from "@langchain/community/stores/message/convex";
import { ChatOpenAI } from "@langchain/openai";
import { BufferMemory } from "langchain/memory";
import { ConversationChain } from "langchain/chains";

const client = new ConvexHttpClient(process.env.NEXT_PUBLIC_CONVEX_URL!);

const model = new ChatOpenAI({
  modelName: "gpt-3.5-turbo",
  temperature: 0,
});

const memory = new BufferMemory({
  chatHistory: new ConvexChatMessageHistory({
    client,
    sessionId: "test-session",
  }),
});

const chain = new ConversationChain({ llm: model, memory });

export async function exampleRun() {
  const res1 = await chain.call({ input: "Hi! I'm Jim." });
  console.log(res1);
  const res2 = await chain.call({ input: "What's my name?" });
  console.log(res2);
}

export default exampleRun;

----------------------------------------

TITLE: Initializing Vectara Store with Custom Embeddings
DESCRIPTION: Example showing how to create a VectaraStore instance with text data. Note that custom embeddings won't have an effect since Vectara uses its own embeddings.

LANGUAGE: typescript
CODE:
const store = await VectaraStore.fromTexts(
  ["hello world", "hi there"],
  [{ foo: "bar" }, { foo: "baz" }],
  // This won't have an effect. Provide a FakeEmbeddings instance instead for clarity.
  new OpenAIEmbeddings(),
  args
);

----------------------------------------

TITLE: Output of MessagesPlaceholder Usage in TypeScript
DESCRIPTION: This snippet shows the output of using MessagesPlaceholder in a ChatPromptTemplate. It demonstrates how the placeholder is replaced with the provided message in the final ChatPromptValue.

LANGUAGE: text
CODE:
ChatPromptValue {
  messages: [
    SystemMessage {
      "content": "You are a helpful assistant",
      "additional_kwargs": {},
      "response_metadata": {}
    },
    HumanMessage {
      "content": "hi!",
      "additional_kwargs": {},
      "response_metadata": {}
    }
  ]
}

----------------------------------------

TITLE: Integrating ZhipuAI Chat Model in TypeScript
DESCRIPTION: This code snippet demonstrates how to integrate and use the ZhipuAI chat model in a TypeScript project using LangChain.js. It includes importing necessary modules, setting up the chat model, and executing a chat completion.

LANGUAGE: typescript
CODE:
import ZhipuAI from "@examples/models/chat/integration_zhipuai.ts";

----------------------------------------

TITLE: Installing LangChain OpenAI Dependencies
DESCRIPTION: Installation commands for required LangChain OpenAI packages using npm or yarn.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/core

----------------------------------------

TITLE: Basic Cohere Document Reranking Implementation
DESCRIPTION: Basic implementation showing how to use Cohere's .rerank() method to get document indexes and relevancy scores.

LANGUAGE: typescript
CODE:
<CodeBlock language="typescript">{Example}</CodeBlock>

----------------------------------------

TITLE: Extracting Relevant Table Names using OpenAI and Zod in TypeScript
DESCRIPTION: TypeScript code snippet showing how to use OpenAI function-calling and Zod models to extract relevant table names from user input for large databases.

LANGUAGE: typescript
CODE:
import LargeDbExample from "@examples/use_cases/sql/large_db.ts";

<CodeBlock language="typescript">{LargeDbExample}</CodeBlock>

----------------------------------------

TITLE: Output of String PromptTemplate Invocation in TypeScript
DESCRIPTION: This snippet shows the output of invoking a String PromptTemplate. It demonstrates that the result is a StringPromptValue object containing the formatted prompt.

LANGUAGE: text
CODE:
StringPromptValue {
  value: 'Tell me a joke about cats'
}

----------------------------------------

TITLE: Streaming AI Message Chunks in TypeScript
DESCRIPTION: Demonstrates how to stream and process chunks of AI messages from a chat model response.

LANGUAGE: typescript
CODE:
for await (const chunk of model.stream([
  new HumanMessage("what color is the sky?"),
])) {
  console.log(chunk);
}

----------------------------------------

TITLE: Implementing MultiVectorRetriever with Hypothetical Queries in TypeScript
DESCRIPTION: Example illustrating how to generate and use hypothetical questions as embeddings with MultiVectorRetriever for enhanced document retrieval in LangChain.js.

LANGUAGE: typescript
CODE:
import HypotheticalExample from "@examples/retrievers/multi_vector_hypothetical.ts";

<CodeBlock language="typescript">{HypotheticalExample}</CodeBlock>

----------------------------------------

TITLE: Loading Examples from Existing VectorStore
DESCRIPTION: Demonstrates how to initialize a semantic similarity example selector using a pre-existing vector store and add additional examples.

LANGUAGE: typescript
CODE:
{ExampleSimilarityFromExisting}

----------------------------------------

TITLE: Implementing Zep Cloud Memory in LangChain.js
DESCRIPTION: This example demonstrates how to use Zep Cloud Memory directly in LangChain.js. It imports the necessary components and provides an example of setting up and using Zep Cloud Memory with a language model.

LANGUAGE: typescript
CODE:
import ZepCloudMemoryExample from "@examples/memory/zep_cloud.ts";

<CodeBlock language="typescript">{ZepCloudMemoryExample}</CodeBlock>

----------------------------------------

TITLE: Using Few Shot Prompt with ChatOpenAI in TypeScript
DESCRIPTION: Demonstrates how to use a few shot prompt template with ChatOpenAI to rephrase questions.

LANGUAGE: typescript
CODE:
const model = new ChatOpenAI({});
const examples = [
  {
    input: "Could the members of The Police perform lawful arrests?",
    output: "what can the members of The Police do?",
  },
  {
    input: "Jan Sindel's was born in what country?",
    output: "what is Jan Sindel's personal history?",
  },
];
const examplePrompt = ChatPromptTemplate.fromTemplate(`Human: {input}
AI: {output}`);
const fewShotPrompt = new FewShotChatMessagePromptTemplate({
  prefix:
    "Rephrase the users query to be more general, using the following examples",
  suffix: "Human: {input}",
  examplePrompt,
  examples,
  inputVariables: ["input"],
});
const formattedPrompt = await fewShotPrompt.format({
  input: "What's France's main city?",
});

const response = await model.invoke(formattedPrompt);
console.log(response);

----------------------------------------

TITLE: Installing Llama CPP and LangChain Dependencies
DESCRIPTION: Commands for installing the required node-llama-cpp and LangChain packages. node-llama-cpp version 3 is specifically required for this integration.

LANGUAGE: bash
CODE:
npm install -S node-llama-cpp@3

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core

----------------------------------------

TITLE: Complete Azure Cosmos DB Vector Store Usage Example
DESCRIPTION: Full example demonstrating document indexing, vector search, and natural language querying with Azure Cosmos DB vector store

LANGUAGE: typescript
CODE:
import { AzureCosmosDBVectorStore } from "@langchain/azure-cosmosdb";
import { OpenAIEmbeddings } from "@langchain/openai";

const vectorStore = new AzureCosmosDBVectorStore({
  embeddings: new OpenAIEmbeddings(),
  endpoint: process.env.AZURE_COSMOSDB_ENDPOINT,
  key: process.env.AZURE_COSMOSDB_KEY,
  databaseName: process.env.AZURE_COSMOSDB_DATABASE_NAME,
  containerName: process.env.AZURE_COSMOSDB_CONTAINER_NAME,
});

// Index documents
const docs = await loadDocumentsFromFile();
await vectorStore.addDocuments(docs);

// Search similar documents
const results = await vectorStore.similaritySearch("query text", 3);

// Use retrieved documents in a chain
const chain = createChain();
const answer = await chain.invoke({
  question: "What is the meaning of life?",
  context: results,
});

----------------------------------------

TITLE: Demonstrating In-Memory Caching Performance in TypeScript
DESCRIPTION: This code snippet shows the performance difference between the first (uncached) and second (cached) invocations of the chat model. It uses console.time() to measure execution time.

LANGUAGE: typescript
CODE:
console.time();

// The first time, it is not yet in cache, so it should take longer
const res = await model.invoke("Tell me a joke!");
console.log(res);

console.timeEnd();

/*
  AIMessage {
    lc_serializable: true,
    lc_kwargs: {
      content: "Why don't scientists trust atoms?\n\nBecause they make up everything!",
      additional_kwargs: { function_call: undefined, tool_calls: undefined }
    },
    lc_namespace: [ 'langchain_core', 'messages' ],
    content: "Why don't scientists trust atoms?\n\nBecause they make up everything!",
    name: undefined,
    additional_kwargs: { function_call: undefined, tool_calls: undefined }
  }
  default: 2.224s
*/

console.time();

// The second time it is, so it goes faster
const res2 = await model.invoke("Tell me a joke!");
console.log(res2);

console.timeEnd();
/*
  AIMessage {
    lc_serializable: true,
    lc_kwargs: {
      content: "Why don't scientists trust atoms?\n\nBecause they make up everything!",
      additional_kwargs: { function_call: undefined, tool_calls: undefined }
    },
    lc_namespace: [ 'langchain_core', 'messages' ],
    content: "Why don't scientists trust atoms?\n\nBecause they make up everything!",
    name: undefined,
    additional_kwargs: { function_call: undefined, tool_calls: undefined }
  }
  default: 181.98ms
*/

----------------------------------------

TITLE: Initializing HuggingFace Inference Embeddings
DESCRIPTION: Example of creating a new HuggingFace Inference embeddings instance with an API key. By default, it uses the 'sentence-transformers/distilbert-base-nli-mean-tokens' model but can be configured with different models.

LANGUAGE: typescript
CODE:
import { HuggingFaceInferenceEmbeddings } from "@langchain/community/embeddings/hf";

const embeddings = new HuggingFaceInferenceEmbeddings({
  apiKey: "YOUR-API-KEY", // In Node.js defaults to process.env.HUGGINGFACEHUB_API_KEY
});

----------------------------------------

TITLE: Creating Vector Index from Document Loader
DESCRIPTION: Shows how to create a vector index from a document loader and perform similarity searches.

LANGUAGE: typescript
CODE:
import ExampleLoader from "@examples/indexes/vector_stores/hana_vector/fromDocs.ts";

----------------------------------------

TITLE: Comparing Few Shot and Chat Few Shot in TypeScript
DESCRIPTION: Demonstrates the differences between FewShotPromptTemplate and FewShotChatMessagePromptTemplate.

LANGUAGE: typescript
CODE:
import {
  FewShotPromptTemplate,
  FewShotChatMessagePromptTemplate,
} from "langchain/prompts";

const examples = [
  {
    input: "Could the members of The Police perform lawful arrests?",
    output: "what can the members of The Police do?",
  },
  {
    input: "Jan Sindel's was born in what country?",
    output: "what is Jan Sindel's personal history?",
  },
];
const prompt = `Human: {input}
AI: {output}`;
const examplePromptTemplate = PromptTemplate.fromTemplate(prompt);
const exampleChatPromptTemplate = ChatPromptTemplate.fromTemplate(prompt);
const chatFewShotPrompt = new FewShotChatMessagePromptTemplate({
  examplePrompt: exampleChatPromptTemplate,
  examples,
  inputVariables: [], // no input variables
});
const fewShotPrompt = new FewShotPromptTemplate({
  examplePrompt: examplePromptTemplate,
  examples,
  inputVariables: [], // no input variables
});

console.log("Chat Few Shot: ", await chatFewShotPrompt.formatMessages({}));
console.log("Few Shot: ", await fewShotPrompt.formatPromptValue({}));

----------------------------------------

TITLE: Installing Dependencies for LangChain OpenAI Integration
DESCRIPTION: Commands to install the required npm packages for using LangChain with OpenAI.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/core

----------------------------------------

TITLE: Partial Formatting with String Values in TypeScript
DESCRIPTION: Demonstrates how to partially format a prompt template by providing some variables upfront while leaving others for later formatting. Shows both direct partial formatting and initialization with partial variables.

LANGUAGE: typescript
CODE:
import { PromptTemplate } from "langchain/prompts";

const prompt = new PromptTemplate({
  template: "{foo}{bar}",
  inputVariables: ["foo", "bar"],
});

const partialPrompt = await prompt.partial({
  foo: "foo",
});

const formattedPrompt = await partialPrompt.format({
  bar: "baz",
});

console.log(formattedPrompt);

// foobaz

LANGUAGE: typescript
CODE:
const prompt = new PromptTemplate({
  template: "{foo}{bar}",
  inputVariables: ["bar"],
  partialVariables: {
    foo: "foo",
  },
});

const formattedPrompt = await prompt.format({
  bar: "baz",
});

console.log(formattedPrompt);

// foobaz

----------------------------------------

TITLE: Implementing D1-Backed Chat Memory in Cloudflare Worker
DESCRIPTION: This TypeScript code demonstrates how to use Cloudflare D1 as a backend for chat memory in a LangChain.js application running in a Cloudflare Worker. It sets up a chat model, creates a D1-backed memory, and processes chat messages.

LANGUAGE: typescript
CODE:
import { Anthropic } from "@langchain/anthropic";
import { CloudflareD1ChatMessageHistory } from "@langchain/cloudflare";
import { ChatPromptTemplate } from "@langchain/core/prompts";
import { StringOutputParser } from "@langchain/core/output_parsers";
import { RunnableSequence } from "@langchain/core/runnables";
import { BufferMemory } from "langchain/memory";

export interface Env {
  DB: D1Database;
  ANTHROPIC_API_KEY: string;
}

export default {
  async fetch(
    request: Request,
    env: Env,
    ctx: ExecutionContext
  ): Promise<Response> {
    const model = new Anthropic({
      apiKey: env.ANTHROPIC_API_KEY,
    }).chat();

    const chatHistory = new CloudflareD1ChatMessageHistory({
      sessionId: "my-session-id",
      database: env.DB,
    });

    const memory = new BufferMemory({
      returnMessages: true,
      chatHistory,
      inputKey: "question",
      outputKey: "answer",
    });

    const prompt = ChatPromptTemplate.fromMessages([
      ["system", "You are a helpful assistant."],
      ["human", "{question}"],
    ]);

    const chain = RunnableSequence.from([
      {
        question: (input: { question: string }) => input.question,
        memory: () => memory.loadMemoryVariables({}),
      },
      {
        question: (input) => input.question,
        chat_history: (input) => input.memory.chat_history,
      },
      prompt,
      model,
      new StringOutputParser(),
    ]);

    const response = await chain.invoke({
      question: "What is the capital of France?",
    });

    await memory.saveContext(
      { question: "What is the capital of France?" },
      { answer: response }
    );

    return new Response(response);
  },
};

----------------------------------------

TITLE: Querying Documents with Filters in Google Vertex AI Matching Engine
DESCRIPTION: TypeScript code showing how to perform similarity searches with metadata filters in the Matching Engine. Demonstrates simple and complex filtering based on document metadata.

LANGUAGE: typescript
CODE:
import { Restriction } from `langchain/vectorstores/googlevertexai`;

const redFilter: Restriction[] = [
  {
    namespace: "color",
    allowList: ["red"],
  },
];
const redResults = await engine.similaritySearch("this", 4, redFilter);

const filter: Restriction[] = [
  {
    namespace: "color",
    allowList: ["red"],
  },
  {
    namespace: "category",
    denyList: ["edible"],
  },
];
const results = await engine.similaritySearch("this", 4, filter);

----------------------------------------

TITLE: Tracking Token Usage with OpenAI using AIMessage.response_metadata
DESCRIPTION: Example of how to track token usage for OpenAI models using the response_metadata field of AIMessage.

LANGUAGE: typescript
CODE:
import Example from "@examples/models/chat/token_usage_tracking.ts";

<CodeBlock language="typescript">{Example}</CodeBlock>

----------------------------------------

TITLE: Integrating ZepCloudChatMessageHistory with ZepVectorStore as Retriever
DESCRIPTION: This snippet shows how to combine ZepCloudChatMessageHistory with ZepVectorStore as a retriever in LangChain.js. It sets up a chat model, creates Zep memory and vector store instances, and defines a chain for processing messages with history and retrieval.

LANGUAGE: typescript
CODE:
import ZepCloudMessageHistoryWithVectorStoreExample from "@examples/guides/expression_language/zep/zep_cloud_message_history_vector_store.ts";

<CodeBlock language="typescript">
  {ZepCloudMessageHistoryWithVectorStoreExample}
</CodeBlock>

----------------------------------------

TITLE: Basic Usage of Neo4jVectorStore in LangChain.js
DESCRIPTION: Example demonstrating the basic usage of Neo4jVectorStore, including initialization, adding documents, and similarity search.

LANGUAGE: typescript
CODE:
import { Neo4jVectorStore } from "@langchain/community/vectorstores/neo4j_vector";
import { OpenAIEmbeddings } from "@langchain/openai";
import { Neo4jGraph } from "@langchain/community/graphs/neo4j_graph";
import neo4j from "neo4j-driver";

const driver = neo4j.driver(
  "bolt://localhost:7687",
  neo4j.auth.basic("neo4j", "pleaseletmein")
);

const graph = await Neo4jGraph.initialize({ driver });

const vectorStore = new Neo4jVectorStore(graph, new OpenAIEmbeddings());

await vectorStore.addDocuments([
  { pageContent: "a", metadata: { a: 1 } },
  { pageContent: "b", metadata: { b: 1 } },
  { pageContent: "c", metadata: { c: 1 } },
  { pageContent: "d", metadata: { d: 1 } },
]);

const results = await vectorStore.similaritySearch("a", 1);
console.log(results);

await driver.close();

----------------------------------------

TITLE: Querying Documents from Tigris Vector Store
DESCRIPTION: Example of performing similarity search on indexed documents with metadata filtering. Shows how to initialize the vector store and execute queries.

LANGUAGE: typescript
CODE:
import { VectorDocumentStore } from "@tigrisdata/vector";
import { OpenAIEmbeddings } from "@langchain/openai";
import { TigrisVectorStore } from "langchain/vectorstores/tigris";

const index = new VectorDocumentStore({
  connection: {
    serverUrl: "api.preview.tigrisdata.cloud",
    projectName: process.env.TIGRIS_PROJECT,
    clientId: process.env.TIGRIS_CLIENT_ID,
    clientSecret: process.env.TIGRIS_CLIENT_SECRET,
  },
  indexName: "examples_index",
  numDimensions: 1536, // match the OpenAI embedding size
});

const vectorStore = await TigrisVectorStore.fromExistingIndex(
  new OpenAIEmbeddings(),
  { index }
);

/* Search the vector DB independently with metadata filters */
const results = await vectorStore.similaritySearch("tigris", 1, {
  "metadata.foo": "bar",
});
console.log(JSON.stringify(results, null, 2));
/*
[
  Document {
    pageContent: 'tigris is a cloud-native vector db',
    metadata: { foo: 'bar' }
  }
]
*/

----------------------------------------

TITLE: Installing LangChain Community and Core Packages
DESCRIPTION: This command installs the @langchain/community and @langchain/core packages, which are required for using Prem AI embeddings in a LangChain.js project.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core

----------------------------------------

TITLE: Tracking Token Usage with OpenAI using AIMessage.usage_metadata
DESCRIPTION: Example of how to track token usage for OpenAI models using the usage_metadata attribute of AIMessage.

LANGUAGE: typescript
CODE:
import CodeBlock from "@theme/CodeBlock";
import IntegrationInstallTooltip from "@mdx_components/integration_install_tooltip.mdx";

<IntegrationInstallTooltip></IntegrationInstallTooltip>

import UsageMetadataExample from "@examples/models/chat/usage_metadata.ts";

<CodeBlock language="typescript">{UsageMetadataExample}</CodeBlock>

----------------------------------------

TITLE: Integrating YandexGPT Chat Model in TypeScript
DESCRIPTION: This code example demonstrates how to set up and use the YandexGPT chat model in a TypeScript environment. It includes importing the necessary modules, creating a chat model instance, and making a chat completion request.

LANGUAGE: typescript
CODE:
import { ChatYandexGPT } from "@langchain/yandex";

const model = new ChatYandexGPT({
  // You can specify iam_token or api_key here,
  // or use YC_IAM_TOKEN or YC_API_KEY environment variables
  // iam_token: "your-iam-token",
  // api_key: "your-api-key",
  model: "yandexgpt", // or "yandexgpt-lite"
});

const res = await model.invoke([
  ["human", "Hello, how are you?"],
  ["ai", "Hello! As an AI language model, I don't have feelings, but I'm functioning well and ready to assist you. How can I help you today?"],
  ["human", "What's the weather like today?"],
]);

console.log(res);

----------------------------------------

TITLE: Installing d3-dsv Package for CSV Parsing in Node.js
DESCRIPTION: This command installs the d3-dsv package version 2, which is required for CSV parsing in the CSVLoader.

LANGUAGE: bash
CODE:
npm install d3-dsv@2

----------------------------------------

TITLE: Integrating Moonshot AI Model in LangChain.js
DESCRIPTION: This code snippet demonstrates how to integrate and use a Moonshot AI model within a LangChain.js application. It includes importing necessary modules, setting up the chat model, and making a query to the model.

LANGUAGE: typescript
CODE:
import Moonshot from "@examples/models/chat/integration_moonshot.ts";

----------------------------------------

TITLE: Implementing Parallel Runnables with RunnableParallel in TypeScript
DESCRIPTION: Shows how to create and use RunnableParallel to execute multiple Runnables concurrently with the same input, improving execution performance through parallelization.

LANGUAGE: typescript
CODE:
import { RunnableParallel } from "@langchain/core/runnables";
const chain = new RunnableParallel({
  key1: runnable1,
  key2: runnable2,
});

LANGUAGE: typescript
CODE:
const finalOutput = await chain.invoke(someInput);

----------------------------------------

TITLE: Initializing OpenAI Model with In-Memory Cache
DESCRIPTION: Setting up an OpenAI model instance with in-memory caching enabled.

LANGUAGE: typescript
CODE:
import { OpenAI } from "@langchain/openai";

const model = new OpenAI({
  model: "gpt-3.5-turbo-instruct",
  cache: true,
});

----------------------------------------

TITLE: Ensemble Retriever Creation in TypeScript
DESCRIPTION: Demonstrates how to create an ensemble retriever that combines multiple retrievers with weighted scores for improved retrieval results.

LANGUAGE: typescript
CODE:
const ensembleRetriever = new EnsembleRetriever({
  retrievers: [bm25Retriever, vectorStoreRetriever],
  weights: [0.5, 0.5],
});

----------------------------------------

TITLE: Installing Vercel KV for Caching
DESCRIPTION: Command to install the Vercel KV package for caching in LangChain.

LANGUAGE: bash
CODE:
npm install @vercel/kv

----------------------------------------

TITLE: Implementing Layerup Security with LangChain
DESCRIPTION: This code snippet demonstrates how to integrate Layerup Security with LangChain. It imports necessary modules, initializes the Layerup Security wrapper, and uses it to secure an OpenAI LLM instance.

LANGUAGE: typescript
CODE:
import LayerupSecurityExampleCode from "@examples/llms/layerup_security.ts";

----------------------------------------

TITLE: Initializing TensorFlow Embeddings
DESCRIPTION: Code snippet demonstrating how to import and initialize TensorFlow embeddings using the CPU backend. This setup works in any JavaScript environment but can be modified to use GPU or WebAssembly backends for better performance.

LANGUAGE: typescript
CODE:
import "@tensorflow/tfjs-backend-cpu";
import { TensorFlowEmbeddings } from "@langchain/community/embeddings/tensorflow";

const embeddings = new TensorFlowEmbeddings();

----------------------------------------

TITLE: Initializing MinimaxEmbeddings in TypeScript
DESCRIPTION: Example showing how to create embeddings using the Minimax API. The code demonstrates both single query embedding and batch document embedding. Requires a Minimax account, API key, and Group ID to be configured.

LANGUAGE: typescript
CODE:
import { MinimaxEmbeddings } from "langchain/embeddings/minimax";

export const run = async () => {
  /* Embed queries */
  const embeddings = new MinimaxEmbeddings();
  const res = await embeddings.embedQuery("Hello world");
  console.log(res);
  /* Embed documents */
  const documentRes = await embeddings.embedDocuments([
    "Hello world",
    "Bye bye",
  ]);
  console.log({ documentRes });
};

----------------------------------------

TITLE: Setting Up Redis Caching for LangChain
DESCRIPTION: Installing Redis dependencies and configuring Redis-based caching for LangChain.

LANGUAGE: bash
CODE:
npm install ioredis

LANGUAGE: typescript
CODE:
import { OpenAI } from "@langchain/openai";
import { RedisCache } from "@langchain/community/caches/ioredis";
import { Redis } from "ioredis";

// See https://github.com/redis/ioredis for connection options
const client = new Redis({});

const cache = new RedisCache(client);

const model = new OpenAI({ cache });

----------------------------------------

TITLE: Using NIBittensorChatModel in TypeScript
DESCRIPTION: This snippet demonstrates how to import and use the NIBittensorChatModel from LangChain.js to interact with Bittensor chat models. It shows the creation of a chat instance, sending a human message, and logging the response.

LANGUAGE: typescript
CODE:
import { NIBittensorChatModel } from "langchain/experimental/chat_models/bittensor";
import { HumanMessage } from "@langchain/core/messages";

const chat = new NIBittensorChatModel();
const message = new HumanMessage("What is bittensor?");
const res = await chat.invoke([message]);
console.log({ res });
/*
  {
    res: "\nBittensor is opensource protocol..."
  }
 */

----------------------------------------

TITLE: Setting Environment Variables
DESCRIPTION: Configuration of environment variables for OpenAI API key and optional LangSmith settings for tracing and callbacks.

LANGUAGE: bash
CODE:
export OPENAI_API_KEY="your api key"
# Uncomment the below to use LangSmith. Not required.
# export LANGSMITH_API_KEY="your api key"
# export LANGSMITH_TRACING=true

# Reduce tracing latency if you are not in a serverless environment
# export LANGCHAIN_CALLBACKS_BACKGROUND=true

----------------------------------------

TITLE: Implementing a Chat Model for Parrot Link AI in TypeScript
DESCRIPTION: Shows the basic structure for implementing a new chat model in the @langchain/community package, extending the SimpleChatModel class.

LANGUAGE: typescript
CODE:
import {
  SimpleChatModel,
} from "@langchain/core/language_models/chat_models";

export class ChatParrotLink extends SimpleChatModel {

  ...

----------------------------------------

TITLE: Integrating Plugins with Minimax Chat Models in LangChain.js
DESCRIPTION: Demonstrates how to use plugins to enhance Minimax chat model capabilities with external data sources in LangChain.js.

LANGUAGE: typescript
CODE:
import MinimaxPlugins from "@examples/models/chat/minimax_plugins.ts";

----------------------------------------

TITLE: Parsing JSON Output in LangChain.js
DESCRIPTION: Demonstrates how to parse the JSON string output from the model into a JavaScript object using the JSON.parse() method.

LANGUAGE: typescript
CODE:
import json
const jsonObject = JSON.parse(aiMsg.content)
// {'random_ints': [23, 47, 89, 15, 34, 76, 58, 3, 62, 91]}

----------------------------------------

TITLE: Installing LangChain Anthropic and Core Dependencies
DESCRIPTION: Command to install the necessary npm packages for using Anthropic with LangChain.

LANGUAGE: bash
CODE:
npm install @langchain/anthropic @langchain/core

----------------------------------------

TITLE: FewShotPromptTemplate with Functions and Example Selector in TypeScript
DESCRIPTION: Shows how to use FewShotPromptTemplate with functions and an example selector for non-chat models.

LANGUAGE: typescript
CODE:
const examplePrompt = PromptTemplate.fromTemplate("An example about {x}");
const exampleSelector = await LengthBasedExampleSelector.fromExamples(
  [{ x: "foo" }, { x: "bar" }],
  { examplePrompt, maxLength: 200 }
);
const prompt = new FewShotPromptTemplate({
  prefix: "{foo}{bar}",
  exampleSelector,
  examplePrompt,
  inputVariables: ["foo", "bar"],
});
const partialPrompt = await prompt.partial({
  foo: () => Promise.resolve("boo"),
});
const formatted = await partialPrompt.format({ bar: "baz" });
console.log(formatted);

----------------------------------------

TITLE: Importing and Using Friendli Chat Model in TypeScript
DESCRIPTION: This snippet demonstrates how to import and use the Friendli chat model in a TypeScript application. It includes setting up the model, creating a prompt template, and generating a response.

LANGUAGE: typescript
CODE:
import { ChatFriendli } from "@langchain/community/chat_models/friendli";
import { ChatPromptTemplate } from "@langchain/core/prompts";

const chat = new ChatFriendli({
  model: "mixtral-8x7b-instruct-v0-1",
});

const prompt = ChatPromptTemplate.fromMessages([
  ["human", "Tell me a short joke about {topic}"],
]);

const chain = prompt.pipe(chat);

const result = await chain.invoke({
  topic: "bears",
});

console.log(result);

----------------------------------------

TITLE: Chat Model and Prompt Configuration
DESCRIPTION: Configuration of ChatOpenAI model and prompt template for the tool execution.

LANGUAGE: typescript
CODE:
  (async () => {
    const prompt = ChatPromptTemplate.fromMessages([
      [
        "system",
        `You are a helpful assistant. Use the tools provided to best assist the user.`,
      ],
      ["human", "{input}"],
    ]);

    const llm = new ChatOpenAI({
      model: "gpt-4o-2024-05-13",
      temperature: 0,
    });

----------------------------------------

TITLE: Indexing and Querying Documents with MyScale in TypeScript
DESCRIPTION: This code snippet demonstrates how to index documents and perform queries using MyScale vector store in a TypeScript environment. It includes setup for the MyScale client, creating embeddings, and executing vector searches.

LANGUAGE: typescript
CODE:
InsertExample

----------------------------------------

TITLE: Implementing ZepCloudChatMessageHistory with RunnableWithMessageHistory
DESCRIPTION: This example demonstrates how to use ZepCloudChatMessageHistory with RunnableWithMessageHistory in LangChain.js. It sets up a chat model, creates a Zep memory instance, and defines a chain for processing messages with history.

LANGUAGE: typescript
CODE:
import CodeBlock from "@theme/CodeBlock";
import ZepCloudMessageHistoryExample from "@examples/guides/expression_language/zep/zep_cloud_message_history.ts";

<CodeBlock language="typescript">{ZepCloudMessageHistoryExample}</CodeBlock>

----------------------------------------

TITLE: Using ChatOllama model in TypeScript
DESCRIPTION: Example of how to initialize and use the ChatOllama model for invoking a chat conversation.

LANGUAGE: typescript
CODE:
import { ChatOllama } from "@langchain/ollama";

const model = new ChatOllama({
  model: "llama3",  // Default value.
});

const result = await model.invoke(["human", "Hello, how are you?"]);

----------------------------------------

TITLE: Using Function Calls with Minimax in LangChain.js
DESCRIPTION: Illustrates how to use function calls with a Minimax chat model in LangChain.js.

LANGUAGE: typescript
CODE:
import MinimaxFunctions from "@examples/models/chat/minimax_functions.ts";

----------------------------------------

TITLE: Contextual Compression Basic Implementation
DESCRIPTION: Example implementation of contextual compression using LLMChainExtractor to process the 2023 State of the Union speech chunks.

LANGUAGE: typescript
CODE:
{Example}

----------------------------------------

TITLE: Integrating Azure Cosmos DB with LangChain
DESCRIPTION: Example implementation of Azure Cosmos DB NoSQL chat message history storage using LangChain.js. Shows how to configure and use AzureCosmosDBNoSQLChatMessageHistory for persistent chat storage.

LANGUAGE: typescript
CODE:
import CodeBlock from "@theme/CodeBlock";
import Example from "@examples/memory/azure_cosmosdb_nosql.ts";

<CodeBlock language="typescript">{Example}</CodeBlock>

----------------------------------------

TITLE: Initializing and Invoking ChromeAI Model in TypeScript
DESCRIPTION: This snippet demonstrates how to initialize a ChromeAI model with optional parameters and invoke it to generate a short poem. It showcases the basic usage of ChromeAI in a browser environment.

LANGUAGE: typescript
CODE:
import { ChromeAI } from "@langchain/community/experimental/llms/chrome_ai";

const model = new ChromeAI({
  temperature: 0.5, // Optional, defaults to 0.5
  topK: 40, // Optional, defaults to 40
});

const response = await model.invoke("Write me a short poem please");

/*
  In the realm where moonlight weaves its hue,
  Where dreams and secrets gently intertwine,
  There's a place of tranquility and grace,
  Where whispers of the night find their place.

  Beneath the canopy of starlit skies,
  Where dreams take flight and worries cease,
  A haven of tranquility, pure and true,
  Where the heart finds solace, finding dew.

  In this realm where dreams find their release,
  Where the soul finds peace, at every peace,
  Let us wander, lost in its embrace,
  Finding solace in this tranquil space.
*/

----------------------------------------

TITLE: Demonstrating Message Coercion Failure in TypeScript
DESCRIPTION: Example showing how providing an incorrectly formatted message object to a LangChain model results in a coercion error. The code demonstrates an invalid message format with incorrect role and missing content property.

LANGUAGE: typescript
CODE:
const badlyFormattedMessageObject = {
  role: "foo",
  randomNonContentValue: "bar",
};

await model.invoke([badlyFormattedMessageObject]);

LANGUAGE: plaintext
CODE:
Error: Unable to coerce message from array: only human, AI, system, or tool message coercion is currently supported.

Received: {
  "role": "foo",
  "randomNonContentValue": "bar",
}

----------------------------------------

TITLE: Basic usage of Llama CPP in LangChain.js
DESCRIPTION: Example demonstrating basic usage of Llama CPP in LangChain.js. It shows how to pass a prompt wrapped as a message and get a response.

LANGUAGE: typescript
CODE:
import CodeBlock from "@theme/CodeBlock";
import BasicExample from "@examples/models/chat/integration_llama_cpp.ts";

<CodeBlock language="typescript">{BasicExample}</CodeBlock>

----------------------------------------

TITLE: Installing Vercel KV for Caching in npm
DESCRIPTION: This bash command installs the @vercel/kv package, which is necessary for implementing Vercel KV-based caching in LangChain.js.

LANGUAGE: bash
CODE:
npm install @vercel/kv

----------------------------------------

TITLE: Few Shotting with Functions in TypeScript
DESCRIPTION: Shows how to use few shot prompting with functions to dynamically include current date in prompts.

LANGUAGE: typescript
CODE:
const getCurrentDate = () => {
  return new Date().toISOString();
};

const prompt = new FewShotChatMessagePromptTemplate({
  template: "Tell me a {adjective} joke about the day {date}",
  inputVariables: ["adjective", "date"],
});

const partialPrompt = await prompt.partial({
  date: getCurrentDate,
});

const formattedPrompt = await partialPrompt.format({
  adjective: "funny",
});

console.log(formattedPrompt);

----------------------------------------

TITLE: Streaming Output with ChromeAI in TypeScript
DESCRIPTION: This snippet illustrates how to use ChromeAI's streaming capability. It initializes a ChromeAI model and demonstrates streaming the output of a simple prompt, showing how each chunk of the response is received.

LANGUAGE: typescript
CODE:
import { ChromeAI } from "@langchain/community/experimental/llms/chrome_ai";

const model = new ChromeAI({
  temperature: 0.5, // Optional, defaults to 0.5
  topK: 40, // Optional, defaults to 40
});

for await (const chunk of await model.stream("How are you?")) {
  console.log(chunk);
}

/*
  As
   an
   AI
   language
   model
  ,
   I
   don
  '
  t
   have
   personal
   experiences
   or
   the
   ability
   to
   experience
   emotions
  .
   Therefore
  ,
   I
   cannot
   directly
   answer
   the
   question
   "
  How
   are
   you
  ?".
  
  
  
  May
   I
   suggest
   answering
   something
   else
  ?
*/

----------------------------------------

TITLE: Advanced PlanetScale Chat Memory Usage in TypeScript
DESCRIPTION: Advanced example showing how to use a pre-existing PlanetScale client instance for chat memory in LangChain.js. It includes error handling and demonstrates direct client usage.

LANGUAGE: typescript
CODE:
AdvancedExample

----------------------------------------

TITLE: Implementing Azure Cosmos DB Mongo vCore Chat Message History
DESCRIPTION: This code snippet showcases the implementation of AzureCosmosDBMongoChatMessageHistory for storing chat messages. It includes setting up the chat history, creating a conversation chain, and interacting with the chat model.

LANGUAGE: typescript
CODE:
import Example from "@examples/memory/azure_cosmosdb_mongo.ts";

----------------------------------------

TITLE: Using system messages with Llama CPP in LangChain.js
DESCRIPTION: Example showing how to provide a system message when using Llama CPP in LangChain.js. Note that a system message creates a new session.

LANGUAGE: typescript
CODE:
import SystemExample from "@examples/models/chat/integration_llama_cpp_system.ts";

<CodeBlock language="typescript">{SystemExample}</CodeBlock>

----------------------------------------

TITLE: Installing Required Packages for SQL Query Generation
DESCRIPTION: This snippet shows the command to install necessary npm packages for the SQL query generation project, including LangChain community package, OpenAI integration, TypeORM, and SQLite.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/openai typeorm sqlite3

----------------------------------------

TITLE: Using SpiderLoader for Web Scraping in TypeScript
DESCRIPTION: Example of how to use the SpiderLoader class to scrape a website and load the content into LangChain. It demonstrates both 'scrape' and 'crawl' modes of Spider.

LANGUAGE: typescript
CODE:
import { SpiderLoader } from "@langchain/community/document_loaders/web/spider";

const loader = new SpiderLoader("YOUR_SPIDER_API_KEY");

// Scrape mode
const docs = await loader.scrape({
  url: "https://js.langchain.com/docs/get_started/introduction",
});

// Crawl mode
const docs2 = await loader.load({
  url: "https://js.langchain.com/docs/get_started/introduction",
  match: "https://js.langchain.com/docs/**",
  maxPages: 5,
});

console.log(docs);
console.log(docs2);

----------------------------------------

TITLE: Installing DeepInfra Dependencies for LangChain
DESCRIPTION: Commands to install the required npm packages for using DeepInfra with LangChain. Requires installation of both @langchain/community and @langchain/core packages.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core

----------------------------------------

TITLE: Installing Dria with LangChain Dependencies
DESCRIPTION: Commands to install Dria along with required LangChain packages for full integration.

LANGUAGE: bash
CODE:
npm install dria @langchain/community @langchain/core

----------------------------------------

TITLE: Installing Llama CPP dependencies for LangChain.js
DESCRIPTION: Command to install the required packages for using Llama CPP with LangChain.js. It includes node-llama-cpp, @langchain/community, and @langchain/core.

LANGUAGE: bash
CODE:
npm install -S node-llama-cpp@3 @langchain/community @langchain/core

----------------------------------------

TITLE: Initializing and Using ChatDeepInfra in TypeScript
DESCRIPTION: Example of how to import, initialize, and use the ChatDeepInfra model in a TypeScript project. It demonstrates setting up the model with an API key and sending a message to the chat model.

LANGUAGE: typescript
CODE:
import { ChatDeepInfra } from "@langchain/community/chat_models/deepinfra";

const chatModel = new ChatDeepInfra({
  modelName: "mistralai/Mixtral-8x7B-Instruct-v0.1",
});

const response = await chatModel.invoke(
  "Explain the importance of low latency in chat applications."
);

console.log(response);

----------------------------------------

TITLE: Using ChatAnthropic in a LangChain Pipeline
DESCRIPTION: Demonstrates how to use the ChatAnthropic model in a LangChain pipeline. This example chains the prompt template with the model and invokes it with a specific topic.

LANGUAGE: typescript
CODE:
const chain = prompt.pipe(model);
await chain.invoke({ topic: "bears" });

----------------------------------------

TITLE: Defining JSONSchema for Structured Output
DESCRIPTION: Demonstrates how to define a JSONSchema object for structured output, which is an alternative to Zod schemas and is used internally before being sent to the model provider.

LANGUAGE: json
CODE:
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://example.com/product.schema.json",
  "title": "ResponseFormatter",
  "type": "object",
  "properties": {
    "answer": {
      "description": "The answer to the user's question",
      "type": "string"
    },
    "followup_question": {
      "description": "A followup question the user could ask",
      "type": "string"
    }
  },
  "required": ["answer", "followup_question"]
}

----------------------------------------

TITLE: Using a Configurable Model Declaratively in LangChain.js
DESCRIPTION: Demonstrates how to use a configurable model declaratively, including binding tools, structured output, and chaining operations in LangChain.js.

LANGUAGE: typescript
CODE:
import { initChatModel } from "langchain/chat_models/universal";
import { z } from "zod";
import { CalculatorTool } from "langchain/tools/calculator";

const configurableModel = await initChatModel({
  configurableFields: ["temperature", "maxTokens"],
});

const toolBoundModel = configurableModel.bindTools([new CalculatorTool()]);

const structuredOutputModel = toolBoundModel.withStructuredOutput(
  z.object({
    answer: z.string(),
    confidence: z.number(),
  })
);

const configuredModel = await structuredOutputModel.withConfig({
  modelProvider: "openai",
  model: "gpt-3.5-turbo",
  temperature: 0,
  maxTokens: 500,
  openAIApiKey: "<your_api_key>",
});

const result = await configuredModel.invoke(
  "What's 2 + 2? Express your confidence in the answer as a number between 0 and 1."
);
console.log(result);

----------------------------------------

TITLE: Installing LangChain Dependencies for Python Interpreter Tool
DESCRIPTION: Command to install the necessary LangChain packages for using the Python interpreter tool with OpenAI integration.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/core

----------------------------------------

TITLE: Installing Dependencies with NPM/Yarn
DESCRIPTION: Commands for installing the required node-llama-cpp and LangChain dependencies.

LANGUAGE: bash
CODE:
npm install -S node-llama-cpp@3

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core

----------------------------------------

TITLE: Advanced Usage of Upstash Redis-Backed Chat Memory in LangChain.js
DESCRIPTION: This code snippet shows an advanced implementation of Upstash Redis-backed chat memory, where a custom Redis client instance is passed directly to the memory configuration.

LANGUAGE: typescript
CODE:
import AdvancedExample from "@examples/memory/upstash_redis_advanced.ts";

----------------------------------------

TITLE: Generating embeddings for multiple documents in TypeScript
DESCRIPTION: Shows how to use the embedDocuments method to generate embeddings for multiple documents, including text and images.

LANGUAGE: typescript
CODE:
import { localImageToBase64 } from "@langchain/community/utils/local_image_to_base64";
const documents = [
  "hello",
  {
    text: "hello",
  },
  {
    image: "https://i.ibb.co/nQNGqL0/beach1.jpg",
  },
  {
    image: await localImageToBase64("beach1.jpg"),
  },
];

const embeddingsArray = await embeddings.embedDocuments(documents);
console.log(embeddingsArray);

----------------------------------------

TITLE: Implementing Prem AI Embeddings in TypeScript
DESCRIPTION: This snippet demonstrates how to import and use the PremEmbeddings class from the @langchain/community package to generate embeddings for text. It includes setting up the embeddings with an API key and embedding a sample text.

LANGUAGE: typescript
CODE:
import { PremEmbeddings } from "@langchain/community/embeddings/prem";

const embeddings = new PremEmbeddings({
  apiKey: "YOUR_API_KEY",
});

const res = await embeddings.embedQuery("Hello world");
console.log(res);

----------------------------------------

TITLE: ChatBaiduQianfan Basic Usage
DESCRIPTION: Example implementation of basic Baidu Qianfan chat model usage. References an external example file 'chat_baidu_qianfan.ts' for the complete implementation.

LANGUAGE: typescript
CODE:
ChatBaiduQianfanExample

----------------------------------------

TITLE: Chat Model End Output Format - Chain Level (v1)
DESCRIPTION: Example of the output format for on_chat_model_end event when the chat model is run as part of a chain in v1.

LANGUAGE: typescript
CODE:
{
  data: {
    output: {
      generations: [
        [
          {
            generation_info: None,
            message: AIMessageChunk(
                content="hello world!", id="some id"
            ),
            text: "hello world!",
          }
        ]
      ],
    }
  },
}

----------------------------------------

TITLE: Installing and Setting Up Llama3 Model
DESCRIPTION: Series of commands for downloading, converting, and quantizing the Llama3 model for local use.

LANGUAGE: bash
CODE:
mkdir llama3
cd llama3
cd ..
git clone https://github.com/ggerganov/llama.cpp.git
cd llama.cpp
cmake -B build
cmake --build build --config Release
python3 -m venv llama3
source llama3/bin/activate
python3 -m pip install -r requirements.txt
mkdir models/8B
mkdir models/8B-GGUF
python3 convert_llama_weights_to_hf.py --model_size 8B --input_dir <dir-to-your-model> --output_dir models/8B --llama_version 3
python3 convert_hf_to_gguf.py --outtype f16 --outfile models/8B-GGUF/gguf-llama3-f16.bin models/8B
./build/bin/llama-quantize ./models/8B-GGUF/gguf-llama3-f16.bin ./models/8B-GGUF/gguf-llama3-Q4_0.bin Q4_0
./build/bin/llama-cli -m ./models/8B-GGUF/gguf-llama3-Q4_0.bin -cnv -p "You are a helpful assistant"

----------------------------------------

TITLE: Using OpenAI Embeddings with Zep Vector Store
DESCRIPTION: Shows how to configure Zep Vector Store with OpenAI embeddings instead of the default auto-embedding feature.

LANGUAGE: typescript
CODE:
{ExampleOpenAI}

----------------------------------------

TITLE: Basic Xata Chat Memory Usage with LangChain
DESCRIPTION: Example demonstrating how to use XataChatMessageHistory with LangChain, including client initialization and chat message storage.

LANGUAGE: typescript
CODE:
import Example from "@examples/memory/xata.ts";

----------------------------------------

TITLE: Migration Script Configuration Options
DESCRIPTION: Additional configuration options available for the migration script, including test run mode and custom file selection.

LANGUAGE: typescript
CODE:
updateEntrypointsFrom0_x_xTo0_2_x({
  projectPath: pathToMyProject,
  tsConfigPath: "tsconfig.json", // Path to the tsConfig file. This will be used to load all the project files into the script.
  testRun: true, // If true, the script will not save any changes, but will log the changes that would be made.
  files: ["..."], // A list of .ts file paths to check. If this is provided, the script will only check these files.
});

----------------------------------------

TITLE: Defining Few-Shot Examples for SQL Query Generation
DESCRIPTION: This snippet shows the definition of few-shot examples, which are pairs of natural language questions and their corresponding SQL queries.

LANGUAGE: typescript
CODE:
<CodeBlock language="typescript">{ExampleList}</CodeBlock>

----------------------------------------

TITLE: Installing Dependencies - Package Installation
DESCRIPTION: Command to install required LangChain packages for Convex integration.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/community @langchain/core

----------------------------------------

TITLE: Installing LangChain AI21 Dependencies
DESCRIPTION: Commands to install the required LangChain packages for AI21 integration using npm or yarn.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core

----------------------------------------

TITLE: Implementing Upstash Redis-Backed Chat Memory in LangChain.js
DESCRIPTION: This code snippet demonstrates how to set up and use Upstash Redis-backed chat memory in a LangChain.js project. It includes creating a memory instance, initializing a chat model, and executing a conversation chain.

LANGUAGE: typescript
CODE:
import Example from "@examples/memory/upstash_redis.ts";

----------------------------------------

TITLE: Basic Vector Store Operations
DESCRIPTION: Shows basic vector store operations including adding, querying, and searching vectors.

LANGUAGE: typescript
CODE:
import ExampleBasic from "@examples/indexes/vector_stores/hana_vector/basics.ts";

----------------------------------------

TITLE: Using Web Browser Tool Standalone
DESCRIPTION: Example of how to use the Web Browser Tool as a standalone component in a TypeScript project. This snippet demonstrates importing and using the tool to extract information from a website.

LANGUAGE: typescript
CODE:
{ToolExample}

----------------------------------------

TITLE: Using CollegeConfidentialLoader to Extract Data from College Confidential
DESCRIPTION: This TypeScript code demonstrates how to use the CollegeConfidentialLoader to load data from a specific College Confidential page. It creates a loader instance with a URL and then calls the load() method to retrieve the documents.

LANGUAGE: typescript
CODE:
import { CollegeConfidentialLoader } from "@langchain/community/document_loaders/web/college_confidential";

const loader = new CollegeConfidentialLoader(
  "https://www.collegeconfidential.com/colleges/brown-university/"
);

const docs = await loader.load();

----------------------------------------

TITLE: Installing LangChain Core Dependencies
DESCRIPTION: Command to install the required LangChain community and core packages.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core

----------------------------------------

TITLE: Installing Astra DB Client and LangChain Community Packages
DESCRIPTION: Installs the required npm packages for using Astra DB with LangChain, including the Astra TypeScript client, LangChain community package, OpenAI integration, and LangChain core.

LANGUAGE: bash
CODE:
npm install @langchain/openai @datastax/astra-db-ts @langchain/community @langchain/core

----------------------------------------

TITLE: Installing LangChain Core Dependencies
DESCRIPTION: Command to install the core LangChain dependencies (@langchain/openai and @langchain/core) for using the Web Browser Tool.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/core

----------------------------------------

TITLE: Basic Chat Model Invocation in Python
DESCRIPTION: Simple example showing how to invoke a chat model with a basic message input using the async/await pattern.

LANGUAGE: python
CODE:
await model.invoke("Hello, world!")

----------------------------------------

TITLE: Importing LangChain Partner Package Components in TypeScript
DESCRIPTION: Illustrates how to import components from a LangChain partner package, using a generic example.

LANGUAGE: typescript
CODE:
import { X } from "@langchain/{partner}";

----------------------------------------

TITLE: Importing and Using Confluence Document Loader in TypeScript
DESCRIPTION: This code demonstrates how to import and use the Confluence document loader to fetch pages from a Confluence space and convert them into document objects.

LANGUAGE: typescript
CODE:
import CodeBlock from "@theme/CodeBlock";
import Example from "@examples/document_loaders/confluence.ts";

<CodeBlock language="typescript">{Example}</CodeBlock>

----------------------------------------

TITLE: Loading Documents from Existing Apify Dataset
DESCRIPTION: Example demonstrating how to load documents from an existing Apify dataset using the ApifyDatasetLoader constructor.

LANGUAGE: typescript
CODE:
import ExistingExample from "@examples/document_loaders/apify_dataset_existing.ts";

<CodeBlock language="typescript">{ExistingExample}</CodeBlock>

----------------------------------------

TITLE: Implementing YandexGPT in LangChain.js
DESCRIPTION: This code demonstrates how to use YandexGPT in a LangChain.js project. It includes importing the necessary modules, setting up the YandexGPT model with authentication, and using it to generate a response.

LANGUAGE: typescript
CODE:
import { YandexGPT } from "@langchain/yandex";

const model = new YandexGPT({
  iam_token: "your-iam-token",
  model: "generic",
});

const res = await model.invoke("Tell me a joke");

console.log(res);

----------------------------------------

TITLE: Initializing PromptLayer OpenAI Integration in TypeScript
DESCRIPTION: Example showing how to initialize and use PromptLayerOpenAI with standard OpenAI. Requires both OpenAI and PromptLayer API keys. The code demonstrates setting up the model and making a basic query.

LANGUAGE: typescript
CODE:
import { PromptLayerOpenAI } from "langchain/llms/openai";

const model = new PromptLayerOpenAI({
  temperature: 0.9,
  apiKey: "YOUR-API-KEY", // In Node.js defaults to process.env.OPENAI_API_KEY
  promptLayerApiKey: "YOUR-API-KEY", // In Node.js defaults to process.env.PROMPTLAYER_API_KEY
});
const res = await model.invoke(
  "What would be a good company name a company that makes colorful socks?"
);

----------------------------------------

TITLE: Loading All Columns from CSV using CSVLoader in TypeScript
DESCRIPTION: This code demonstrates how to use the CSVLoader to load all columns from a CSV file. It creates Documents with metadata including the line number and source file, and pageContent containing all column data.

LANGUAGE: typescript
CODE:
import { CSVLoader } from "@langchain/community/document_loaders/fs/csv";

const loader = new CSVLoader("src/document_loaders/example_data/example.csv");

const docs = await loader.load();
/*
[Document {
    "metadata": {
      "line": 1,
      "source": "src/document_loaders/example_data/example.csv",
    },
    "pageContent": "id: 1
text: This is a sentence.",
  },
  Document {
    "metadata": {
      "line": 2,
      "source": "src/document_loaders/example_data/example.csv",
    },
    "pageContent": "id: 2
text: This is another sentence.",
  },
]
*/

----------------------------------------

TITLE: Installing LangChain OpenAI dependency
DESCRIPTION: Command to install the required LangChain OpenAI package

LANGUAGE: bash
CODE:
npm install @langchain/openai

----------------------------------------

TITLE: Using Azure Managed Identity with AzureOpenAI
DESCRIPTION: TypeScript code demonstrating how to use Azure Managed Identity credentials with AzureOpenAI.

LANGUAGE: typescript
CODE:
import { DefaultAzureCredential } from "@azure/identity";
import { AzureOpenAI } from "@langchain/azure-openai";

const credentials = new DefaultAzureCredential();

const model = new AzureOpenAI({
  credentials,
  azureOpenAIEndpoint: process.env.AZURE_OPENAI_API_ENDPOINT,
  azureOpenAIApiDeploymentName: process.env.AZURE_OPENAI_API_DEPLOYMENT_NAME,
});

----------------------------------------

TITLE: Installing Web Browser Tool Dependencies
DESCRIPTION: Command to install the required dependencies (cheerio and axios) for the Web Browser Tool.

LANGUAGE: bash
CODE:
npm install cheerio axios

----------------------------------------

TITLE: Markdown Documentation for FAQ
DESCRIPTION: Markdown structure for the FAQ documentation page, including sidebar positioning and pull request management guidelines.

LANGUAGE: markdown
CODE:
---
sidebar_position: 6
sidebar_label: FAQ
---

# Frequently Asked Questions

## Pull Requests (PRs)

### How do I allow maintainers to edit my PR?

----------------------------------------

TITLE: Using GitHub Loader with Custom GitHub Instances
DESCRIPTION: This snippet demonstrates how to configure the GitHub loader to work with custom GitHub instances, such as GitHub Enterprise.

LANGUAGE: typescript
CODE:
import CustomInstanceExample from "@examples/document_loaders/github_custom_instance.ts";

<CodeBlock language="typescript">{CustomInstanceExample}</CodeBlock>

----------------------------------------

TITLE: Initializing RaycastAI Model in TypeScript
DESCRIPTION: TypeScript code snippet demonstrating how to import and initialize the RaycastAI model from LangChain. It shows setting up rate limiting, model selection, and creativity (temperature) parameter.

LANGUAGE: typescript
CODE:
import { RaycastAI } from "@langchain/community/llms/raycast";

import { Tool } from "@langchain/core/tools";

const model = new RaycastAI({
  rateLimitPerMinute: 10, // It is 10 by default so you can omit this line
  model: "<model_name>",
  creativity: 0, // `creativity` is a term used by Raycast which is equivalent to `temperature` in some other LLMs
});

----------------------------------------

TITLE: Implementing Chaindesk Retriever in TypeScript
DESCRIPTION: Example code demonstrating how to set up and use the Chaindesk Retriever in a TypeScript project. It shows the retrieval process from a Chaindesk.ai datastore.

LANGUAGE: typescript
CODE:
{Example}

----------------------------------------

TITLE: Handling Long Inputs with Model Fallbacks in TypeScript
DESCRIPTION: Illustrates a fallback strategy for handling inputs that exceed a model's context window by using a model with a longer context length as a backup.

LANGUAGE: typescript
CODE:
import LongInputExample from "@examples/guides/fallbacks/long_inputs.ts";

----------------------------------------

TITLE: Running a Single Test
DESCRIPTION: Command to run a single test file in the project.

LANGUAGE: bash
CODE:
yarn test:single /path/to/yourtest.test.ts

----------------------------------------

TITLE: Adding Documents to VectorStore in TypeScript
DESCRIPTION: This code shows how to create Document objects and add them to a vector store using the addDocuments method in LangChain.

LANGUAGE: typescript
CODE:
import { Document } from "@langchain/core/documents";

const document1 = new Document(
    pageContent: "I had chocalate chip pancakes and scrambled eggs for breakfast this morning.",
    metadata: { source: "tweet" },
)

const document2 = new Document(
    pageContent: "The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.",
    metadata: { source: "news" },
)

const documents = [document1, document2]

await vectorStore.addDocuments(documents)

----------------------------------------

TITLE: Installing Google Calendar Tool Dependencies
DESCRIPTION: Command to install the required peer dependency for using Google Calendar Tools.

LANGUAGE: bash
CODE:
npm install googleapis

----------------------------------------

TITLE: Installing Dependencies for Aurora DSQL Chat Memory in Node.js
DESCRIPTION: Command to install necessary npm packages for implementing Aurora DSQL chat memory in a Node.js project using LangChain.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/community @langchain/core pg @aws-sdk/dsql-signer

----------------------------------------

TITLE: Creating a ChatPromptTemplate for Anthropic Models
DESCRIPTION: Example of creating a ChatPromptTemplate for use with Anthropic models. This template includes a system message and a human message with a variable for the topic of the joke.

LANGUAGE: typescript
CODE:
import { ChatPromptTemplate } from "langchain/prompts";

const prompt = ChatPromptTemplate.fromMessages([
  ["system", "You are a helpful chatbot"],
  ["human", "Tell me a joke about {topic}"],
]);

----------------------------------------

TITLE: Installing Required Dependencies
DESCRIPTION: Commands to install the necessary npm packages for using FileSystemChatMessageHistory with LangChain

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core

----------------------------------------

TITLE: Importing and Using Fake LLM Chat Model in TypeScript
DESCRIPTION: This code snippet demonstrates how to import and use the fake LLM chat model in TypeScript for testing purposes. It shows how to mock LLM responses and simulate chat interactions.

LANGUAGE: typescript
CODE:
import CodeBlock from "@theme/CodeBlock";
import FakeListChatExample from "@examples/models/chat/integration_fake.ts";

<CodeBlock language="typescript">{FakeListChatExample}</CodeBlock>

----------------------------------------

TITLE: Implementing Zep Cloud Retriever with LangChain
DESCRIPTION: This code demonstrates how to set up and use the Zep Cloud Retriever in a LangChain retrieval chain. It includes importing necessary modules, initializing the Zep Cloud client and retriever, creating a retrieval chain, and executing a query.

LANGUAGE: typescript
CODE:
import { ZepCloudRetriever } from "@langchain/community/retrievers/zep_cloud";
import { ZepClient } from "@getzep/zep-cloud";
import { RunnableSequence } from "@langchain/core/runnables";
import { StringOutputParser } from "@langchain/core/output_parsers";
import { PromptTemplate } from "@langchain/core/prompts";
import { ChatOpenAI } from "@langchain/openai";

// Initialize the Zep Cloud client
const client = await ZepClient.init(process.env.ZEP_API_URL, process.env.ZEP_API_KEY);

// Initialize the Zep Cloud retriever
const retriever = new ZepCloudRetriever({
  zepClient: client,
  collectionName: "my_collection",
  topK: 3,
});

// Create a retrieval chain
const model = new ChatOpenAI();
const prompt =
  PromptTemplate.fromTemplate(`Answer the question based only on the following context:
{context}

Question: {question}`);

const chain = RunnableSequence.from([
  {
    context: retriever.pipe((docs) => docs.map((doc) => doc.pageContent).join("\n")),
    question: (input: { question: string }) => input.question,
  },
  prompt,
  model,
  new StringOutputParser(),
]);

// Execute the chain
const response = await chain.invoke({
  question: "What is the capital of France?",
});
console.log(response);

----------------------------------------

TITLE: Installing IPFS Datastore Dependencies
DESCRIPTION: Command to install the required dependencies for using IPFS Datastore with LangChain.js. Includes core packages and interfaces needed for IPFS integration.

LANGUAGE: bash
CODE:
npm install cborg interface-datastore it-all @langchain/community @langchain/core

----------------------------------------

TITLE: Metadata Filtering in Neo4jVectorStore
DESCRIPTION: Example showing how to perform metadata filtering when using Neo4jVectorStore for similarity search.

LANGUAGE: typescript
CODE:
import { Neo4jVectorStore } from "@langchain/community/vectorstores/neo4j_vector";
import { OpenAIEmbeddings } from "@langchain/openai";
import { Neo4jGraph } from "@langchain/community/graphs/neo4j_graph";
import neo4j from "neo4j-driver";

const driver = neo4j.driver(
  "bolt://localhost:7687",
  neo4j.auth.basic("neo4j", "pleaseletmein")
);

const graph = await Neo4jGraph.initialize({ driver });

const vectorStore = new Neo4jVectorStore(graph, new OpenAIEmbeddings());

await vectorStore.addDocuments([
  { pageContent: "a", metadata: { category: "alpha" } },
  { pageContent: "b", metadata: { category: "beta" } },
]);

const results = await vectorStore.similaritySearch("a", 1, {
  category: "alpha",
});
console.log(results);

await driver.close();

----------------------------------------

TITLE: Installing LangChain Community and Core Packages
DESCRIPTION: Command to install the required LangChain packages for using ChatFriendli.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core

----------------------------------------

TITLE: Integrating ArxivRetriever in a LangChain.js Chain
DESCRIPTION: Complex example showing how to incorporate ArxivRetriever into a LangChain.js chain with OpenAI's ChatGPT, including imports, prompt template, and chain setup.

LANGUAGE: typescript
CODE:
import { ChatOpenAI } from "@langchain/openai";
import { ChatPromptTemplate } from "@langchain/core/prompts";
import {
  RunnablePassthrough,
  RunnableSequence,
} from "@langchain/core/runnables";
import { StringOutputParser } from "@langchain/core/output_parsers";
import type { Document } from "@langchain/core/documents";

const llm = new ChatOpenAI({
  model: "gpt-4o-mini",
  temperature: 0,
});

const prompt = ChatPromptTemplate.fromTemplate(`
Answer the question based only on the context provided.

Context: {context}

Question: {question}`);

const formatDocs = (docs: Document[]) => {
  return docs.map((doc) => doc.pageContent).join("\n\n");
};

const ragChain = RunnableSequence.from([
  {
    context: retriever.pipe(formatDocs),
    question: new RunnablePassthrough(),
  },
  prompt,
  llm,
  new StringOutputParser(),
]);

await ragChain.invoke("What are the latest advances in quantum computing?");

----------------------------------------

TITLE: Implementing Zod Validation for Minimax Functions in LangChain.js
DESCRIPTION: Demonstrates how to use Zod for validating function calls with Minimax chat models in LangChain.js.

LANGUAGE: typescript
CODE:
import MinimaxFunctionsZod from "@examples/models/chat/minimax_functions_zod.ts";

----------------------------------------

TITLE: Loading .docx Files with DocxLoader
DESCRIPTION: This code example shows how to initialize and use DocxLoader to load a .docx file without specifying any additional parameters.

LANGUAGE: javascript
CODE:
import { DocxLoader } from "@langchain/community/document_loaders/fs/docx";

const loader = new DocxLoader(
  "src/document_loaders/tests/example_data/attention.docx"
);

const docs = await loader.load();

----------------------------------------

TITLE: Initializing NeonPostgres Vector Store in TypeScript
DESCRIPTION: Code snippet demonstrating how to initialize a NeonPostgres vector store using the connection string. This creates a vector store instance that can be used for embedding storage and querying.

LANGUAGE: typescript
CODE:
const vectorStore = await NeonPostgres.initialize(embeddings, {
  connectionString: NEON_POSTGRES_CONNECTION_STRING,
});

----------------------------------------

TITLE: Partial Formatting with Functions in TypeScript
DESCRIPTION: Shows how to partially format a prompt template using functions that return string values, particularly useful for dynamic values like current date/time. Includes examples of both partial formatting and initialization with function variables.

LANGUAGE: typescript
CODE:
const getCurrentDate = () => {
  return new Date().toISOString();
};

const prompt = new PromptTemplate({
  template: "Tell me a {adjective} joke about the day {date}",
  inputVariables: ["adjective", "date"],
});

const partialPrompt = await prompt.partial({
  date: getCurrentDate,
});

const formattedPrompt = await partialPrompt.format({
  adjective: "funny",
});

console.log(formattedPrompt);

// Tell me a funny joke about the day 2023-07-13T00:54:59.287Z

LANGUAGE: typescript
CODE:
const prompt = new PromptTemplate({
  template: "Tell me a {adjective} joke about the day {date}",
  inputVariables: ["adjective"],
  partialVariables: {
    date: getCurrentDate,
  },
});

const formattedPrompt = await prompt.format({
  adjective: "funny",
});

console.log(formattedPrompt);

// Tell me a funny joke about the day 2023-07-13T00:54:59.287Z

----------------------------------------

TITLE: Integrating Motrhead Memory in LangChain.js
DESCRIPTION: This code snippet demonstrates how to set up and use Motrhead memory in a LangChain.js project. It includes importing necessary modules, initializing the memory, and using it with a conversation chain.

LANGUAGE: typescript
CODE:
{Example}

----------------------------------------

TITLE: Server-Side Imports and Directives Setup
DESCRIPTION: Initial server-side setup with necessary imports for LangChain, OpenAI, AI SDK, and schema validation tools.

LANGUAGE: typescript
CODE:
"use server";

import { ChatOpenAI } from "@langchain/openai";
import { ChatPromptTemplate } from "@langchain/core/prompts";
import { createStreamableValue } from "ai/rsc";
import { z } from "zod";
import { zodToJsonSchema } from "zod-to-json-schema";
import { JsonOutputKeyToolsParser } from "@langchain/core/output_parsers/openai_tools";

----------------------------------------

TITLE: Installing LangChain Core Dependencies
DESCRIPTION: Commands to install the core LangChain packages needed for chat memory functionality.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/community @langchain/core

----------------------------------------

TITLE: Customizing MetadataTagger with a custom prompt in TypeScript
DESCRIPTION: Demonstrates how to customize the MetadataTagger by passing additional arguments to the underlying LLMChain, such as a custom prompt for more specific metadata extraction.

LANGUAGE: typescript
CODE:
import CustomExample from "@examples/document_transformers/metadata_tagger_custom_prompt.ts";

<CodeBlock language="typescript">{CustomExample}</CodeBlock>

----------------------------------------

TITLE: Installing WebLLM SDK and LangChain Dependencies
DESCRIPTION: Command to install the WebLLM SDK and required LangChain packages using npm. This step is necessary to set up the WebLLM integration.

LANGUAGE: bash
CODE:
npm install -S @mlc-ai/web-llm @langchain/community @langchain/core

----------------------------------------

TITLE: Implementing Datadog LLM Observability in LangChain.js
DESCRIPTION: This code snippet demonstrates how to use Datadog LLM Observability with LangChain.js. It includes importing necessary modules, setting up the Datadog callback handler, and using it with a LangChain chain or agent.

LANGUAGE: typescript
CODE:
import UsageExample from "@examples/callbacks/datadog.ts";

----------------------------------------

TITLE: Metadata Filtering with SingleStoreVectorStore in LangChain.js
DESCRIPTION: Example showing how to use metadata filtering when performing a similarity search with SingleStoreVectorStore. It demonstrates filtering results based on specific metadata fields.

LANGUAGE: typescript
CODE:
import { OpenAIEmbeddings } from "@langchain/openai";
import { SingleStoreVectorStore } from "@langchain/community/vectorstores/singlestore";

// Configure the connection
const connectionConfig = {
  host: "localhost",
  port: 3306,
  user: "root",
  password: "password",
  database: "vectordb",
};

const vectorStore = await SingleStoreVectorStore.fromTexts(
  ["Hello world", "Bye bye", "hello nice world"],
  [{ id: 2, category: "A" }, { id: 1, category: "B" }, { id: 3, category: "A" }],
  new OpenAIEmbeddings(),
  connectionConfig
);

const resultOne = await vectorStore.similaritySearch("hello world", 1, {
  category: "A",
});
console.log(resultOne);

await vectorStore.end();


----------------------------------------

TITLE: Installing PlanetScale and LangChain Dependencies
DESCRIPTION: Command to install necessary npm packages for using PlanetScale with LangChain.js, including OpenAI and community modules.

LANGUAGE: bash
CODE:
npm install @langchain/openai @planetscale/database @langchain/community @langchain/core

----------------------------------------

TITLE: JigsawStack Tools in LangChain Agent
DESCRIPTION: Example showing how to integrate JigsawStack tools with a LangChain agent using ChatOpenAI model

LANGUAGE: javascript
CODE:
import { ChatOpenAI } from "@langchain/openai";
import { initializeAgentExecutorWithOptions } from "langchain/agents";
import {
  JigsawStackAIScrape,
  JigsawStackAISearch,
  JigsawStackVOCR,
  JigsawStackSpeechToText,
  JigsawStackTextToSQL,
} from "@langchain/jigsawstack";

const model = new ChatOpenAI({
  temperature: 0,
});

//  add the tools that you need
const tools = [
  new JigsawStackAIScrape(),
  new JigsawStackAISearch(),
  new JigsawStackVOCR(),
  new JigsawStackSpeechToText(),
  new JigsawStackTextToSQL(),
];

const executor = await initializeAgentExecutorWithOptions(tools, model, {
  agentType: "zero-shot-react-description",
  verbose: true,
});

const res = await executor.invoke({
  input: `Kokkalo Restaurant Santorini`,
});

console.log(res.output);

----------------------------------------

TITLE: Importing MixedbreadAIReranker in TypeScript
DESCRIPTION: Import statement to bring the MixedbreadAIReranker class into scope. This class provides access to the Mixedbread AI reranking API.

LANGUAGE: typescript
CODE:
import { MixedbreadAIReranker } from "@langchain/mixedbread-ai";

----------------------------------------

TITLE: Implementing SearxngSearch Tool in TypeScript
DESCRIPTION: This code demonstrates how to implement and use the SearxngSearch tool in a TypeScript project. It includes importing necessary modules, creating an instance of the SearxngSearch tool, and using it within an agent or chain.

LANGUAGE: typescript
CODE:
import CodeBlock from "@theme/CodeBlock";

<CodeBlock language="typescript">{ToolExample}</CodeBlock>

----------------------------------------

TITLE: Configuring package.json for a LangChain package
DESCRIPTION: Example package.json configuration for a LangChain package (@langchain/anthropic) that depends on @langchain/core. It shows how to properly set up peer dependencies and dev dependencies.

LANGUAGE: json
CODE:
{
  "name": "@langchain/anthropic",
  "version": "0.0.3",
  "description": "Anthropic integrations for LangChain.js",
  "type": "module",
  "author": "LangChain",
  "license": "MIT",
  "dependencies": {
    "@anthropic-ai/sdk": "^0.10.0"
  },
  "peerDependencies": {
    "@langchain/core": "~0.3.0"
  },
  "devDependencies": {
    "@langchain/core": "~0.3.0"
  }
}

----------------------------------------

TITLE: Generating Responses with PromptLayerChatOpenAI in TypeScript
DESCRIPTION: This code snippet demonstrates how to create a PromptLayerChatOpenAI instance, generate a response to a system message, and retrieve the PromptLayer request ID. It showcases the usage of the returnPromptLayerId option and the structure of the response object.

LANGUAGE: typescript
CODE:
import { PromptLayerChatOpenAI } from "langchain/llms/openai";

const chat = new PromptLayerChatOpenAI({
  returnPromptLayerId: true,
});

const respA = await chat.generate([
  [
    new SystemMessage(
      "You are a helpful assistant that translates English to French."
    ),
  ],
]);

console.log(JSON.stringify(respA, null, 3));

/*
  {
    "generations": [
      [
        {
          "text": "Bonjour! Je suis un assistant utile qui peut vous aider  traduire de l'anglais vers le franais. Que puis-je faire pour vous aujourd'hui?",
          "message": {
            "type": "ai",
            "data": {
              "content": "Bonjour! Je suis un assistant utile qui peut vous aider  traduire de l'anglais vers le franais. Que puis-je faire pour vous aujourd'hui?"
            }
          },
          "generationInfo": {
            "promptLayerRequestId": 2300682
          }
        }
      ]
    ],
    "llmOutput": {
      "tokenUsage": {
        "completionTokens": 35,
        "promptTokens": 19,
        "totalTokens": 54
      }
    }
  }
*/

----------------------------------------

TITLE: Basic PlanetScale Chat Memory Usage in TypeScript
DESCRIPTION: Example of setting up and using PlanetScale as chat memory storage in a LangChain.js application. It demonstrates creating a chat model, memory, and chain with PlanetScale integration.

LANGUAGE: typescript
CODE:
Example

----------------------------------------

TITLE: Example Directory Structure
DESCRIPTION: Shows the directory structure containing different file types that will be loaded.

LANGUAGE: text
CODE:
src/document_loaders/example_data/example/
 example.json
 example.jsonl
 example.txt
 example.csv

----------------------------------------

TITLE: Creating a Convex Project with npm
DESCRIPTION: This command initializes a new Convex project using npm.

LANGUAGE: bash
CODE:
npm create convex@latest

----------------------------------------

TITLE: Initializing Ollama Functions Model in TypeScript
DESCRIPTION: Shows how to initialize the OllamaFunctions wrapper with specific model parameters like temperature and model name.

LANGUAGE: typescript
CODE:
import { OllamaFunctions } from "@langchain/community/experimental/chat_models/ollama_functions";

const model = new OllamaFunctions({
  temperature: 0.1,
  model: "mistral",
});

----------------------------------------

TITLE: Initializing and Using StackExchange Tool in TypeScript
DESCRIPTION: This code snippet demonstrates how to import, initialize, and use the StackExchange tool in a LangChain.js project. It shows the process of creating a tool instance, setting up parameters, and making a query to the StackExchange API.

LANGUAGE: typescript
CODE:
import { StackExchangeTool } from "langchain/tools";

const tool = new StackExchangeTool({
  site: "webapps",
  tags: ["gmail"],
});

const result = await tool.call(
  "How do I send an email with an attachment in Gmail?"
);

console.log(result);

----------------------------------------

TITLE: Initializing LibSQL Vector Store
DESCRIPTION: TypeScript code showing how to initialize a LibSQL vector store with OpenAI embeddings for both remote and local databases

LANGUAGE: typescript
CODE:
import { LibSQLVectorStore } from "@langchain/community/vectorstores/libsql";
import { OpenAIEmbeddings } from "@langchain/openai";
import { createClient } from "@libsql/client";

const embeddings = new OpenAIEmbeddings({
  model: "text-embedding-3-small",
});

const libsqlClient = createClient({
  url: "libsql://[database-name]-[your-username].turso.io",
  authToken: "...",
});

// Local instantiation
// const libsqlClient = createClient({
//  url: "file:./dev.db",
// });

const vectorStore = new LibSQLVectorStore(embeddings, {
  db: libsqlClient,
  table: "TABLE_NAME",
  column: "EMBEDDING_COLUMN",
});

----------------------------------------

TITLE: Chaining Minimax Model Calls in LangChain.js
DESCRIPTION: Shows how to chain multiple calls to a Minimax chat model using LangChain.js.

LANGUAGE: typescript
CODE:
import MinimaxChain from "@examples/models/chat/minimax_chain.ts";

----------------------------------------

TITLE: Loading Single ChatGPT Conversation Log with TypeScript
DESCRIPTION: Shows how to load a specific conversation log from a ChatGPT data export JSON file. The second parameter (1) specifies which conversation to load from the export file.

LANGUAGE: typescript
CODE:
import { ChatGPTLoader } from "@langchain/community/document_loaders/fs/chatgpt";

const loader = new ChatGPTLoader(
  "./example_data/example_conversations.json",
  1
);

const docs = await loader.load();

console.log(docs);

----------------------------------------

TITLE: Integrating ChatPrem Model in TypeScript
DESCRIPTION: This code snippet demonstrates how to import and use the ChatPrem model from Prem AI in a TypeScript environment. It includes initialization of the model and an example of generating a response.

LANGUAGE: typescript
CODE:
import PremAI from "@examples/models/chat/integration_premai.ts";

----------------------------------------

TITLE: Indexing and Querying Documents with Milvus and OpenAI Embeddings
DESCRIPTION: TypeScript code demonstrating how to create a Milvus vector store from texts or documents using OpenAI embeddings, and perform similarity search.

LANGUAGE: typescript
CODE:
import { Milvus } from "langchain/vectorstores/milvus";
import { OpenAIEmbeddings } from "@langchain/openai";

// text sample from Godel, Escher, Bach
const vectorStore = await Milvus.fromTexts(
  [
    "Tortoise: Labyrinth? Labyrinth? Could it Are we in the notorious Little\n            Harmonic Labyrinth of the dreaded Majotaur?",
    "Achilles: Yiikes! What is that?",
    "Tortoise: They say-although I person never believed it myself-that an I\n            Majotaur has created a tiny labyrinth sits in a pit in the middle of\n            it, waiting innocent victims to get lost in its fears complexity.\n            Then, when they wander and dazed into the center, he laughs and\n            laughs at them-so hard, that he laughs them to death!",
    "Achilles: Oh, no!",
    "Tortoise: But it's only a myth. Courage, Achilles."
  ],
  [{ id: 2 }, { id: 1 }, { id: 3 }, { id: 4 }, { id: 5 }],
  new OpenAIEmbeddings(),
  {
    collectionName: "goldel_escher_bach",
  }
);

// or alternatively from docs
const vectorStore = await Milvus.fromDocuments(docs, new OpenAIEmbeddings(), {
  collectionName: "goldel_escher_bach",
});

const response = await vectorStore.similaritySearch("scared", 2);

----------------------------------------

TITLE: Implementing Google Places Tool in TypeScript
DESCRIPTION: Example code demonstrating how to use the Google Places Tool in a TypeScript environment. This snippet is referenced but not directly visible in the provided content.

LANGUAGE: typescript
CODE:
ToolExample

----------------------------------------

TITLE: Streaming with Llama CPP using multiple messages in LangChain.js
DESCRIPTION: Example demonstrating how to stream responses from Llama CPP using multiple messages in LangChain.js. This approach formats the input as a Llama3 prompt.

LANGUAGE: typescript
CODE:
import StreamMultiExample from "@examples/models/chat/integration_llama_cpp_stream_multi.ts";

<CodeBlock language="typescript">{StreamMultiExample}</CodeBlock>

----------------------------------------

TITLE: Importing Example for Vector Store Index
DESCRIPTION: Code reference for showing how to index documents in ClickHouse vector store using fromTexts method.

LANGUAGE: typescript
CODE:
{InsertExample}

----------------------------------------

TITLE: Correct JSON Template Usage in LangChain.js
DESCRIPTION: Example showing correct implementation of a prompt template where JSON object curly braces are properly escaped using double braces to prevent them from being interpreted as variables.

LANGUAGE: typescript
CODE:
import { PromptTemplate } from "@langchain/core/prompts";
import { ChatOpenAI } from "@langchain/openai";

const prompt = PromptTemplate.fromTemplate(`You are a helpful assistant.

Here is an example of how you should respond:

{{
  "firstName": "John",
  "lastName": "Doe",
  "age": 21
}}

Now, answer the following question:

{question}`);

----------------------------------------

TITLE: Transcribing Audio and Creating Documents with OpenAI Whisper API in TypeScript
DESCRIPTION: This code snippet demonstrates how to use the OpenAI Whisper API to transcribe an audio file and create a Document object from the transcription. It requires an OpenAI API key and the path to an audio file.

LANGUAGE: typescript
CODE:
import { OpenAIWhisperAudio } from "langchain/document_loaders/fs/openai_whisper_audio";

const loader = new OpenAIWhisperAudio(
  "path/to/audio.mp3",
  {
    apiKey: "YOUR-API-KEY", // In Node.js defaults to process.env.OPENAI_API_KEY
    maxRetries: 3,
    prompt: "This is a test audio file.",
    language: "en",
    temperature: 0.7,
  }
);

const docs = await loader.load();

console.log(docs);

----------------------------------------

TITLE: Sample CSV Data Structure
DESCRIPTION: An example of a simple CSV file structure with id and text columns, containing two rows of data.

LANGUAGE: csv
CODE:
id,text
1,This is a sentence.
2,This is another sentence.

----------------------------------------

TITLE: Installing Astra DB TypeScript Client and LangChain Dependencies
DESCRIPTION: Commands for installing the required npm packages including Astra DB TypeScript client and LangChain dependencies.

LANGUAGE: bash
CODE:
npm install @datastax/astra-db-ts
npm install @langchain/openai @langchain/community @langchain/core

----------------------------------------

TITLE: Advanced Xata Chat Memory Usage with Pre-created Table
DESCRIPTION: Example showing how to use XataChatMessageHistory with a pre-created Xata table, specifying the table structure and disabling automatic table creation.

LANGUAGE: typescript
CODE:
import Advanced from "@examples/memory/xata-advanced.ts";

----------------------------------------

TITLE: Installing Required Packages for ChatPrem Integration
DESCRIPTION: This command installs the necessary npm packages (@langchain/community and @langchain/core) for integrating ChatPrem with LangChain.js. These packages provide the core functionality and community-contributed modules.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core

----------------------------------------

TITLE: Configuring Azure Dynamic Sessions Environment Variables
DESCRIPTION: Environment variable configuration for the Azure Container Apps session pool management endpoint.

LANGUAGE: text
CODE:
AZURE_CONTAINER_APPS_SESSION_POOL_ENDPOINT="https://<your-instance>.purview.azcentral.eaglex.io"

----------------------------------------

TITLE: Initializing GradientEmbeddings with API Credentials
DESCRIPTION: This code snippet shows how to instantiate the GradientEmbeddings class with explicit API credentials. It demonstrates setting the access key and workspace ID during object creation instead of using environment variables.

LANGUAGE: typescript
CODE:
const model = new GradientEmbeddings({
  gradientAccessKey: "My secret Access Token"
  workspaceId: "My secret workspace id"
});

----------------------------------------

TITLE: PlaywrightWebBaseLoaderOptions Interface in TypeScript
DESCRIPTION: This snippet defines the structure of options that can be passed to the PlaywrightWebBaseLoader constructor, including launch options, navigation options, and custom evaluation functions.

LANGUAGE: typescript
CODE:
type PlaywrightWebBaseLoaderOptions = {
  launchOptions?: LaunchOptions;
  gotoOptions?: PlaywrightGotoOptions;
  evaluate?: PlaywrightEvaluate;
};

----------------------------------------

TITLE: Optimizing PDF Text Spacing
DESCRIPTION: Configure PDFLoader to eliminate extra spaces between text elements by setting an empty parsedItemSeparator.

LANGUAGE: typescript
CODE:
import { PDFLoader } from "@langchain/community/document_loaders/fs/pdf";

const loader = new PDFLoader("src/document_loaders/example_data/example.pdf", {
  parsedItemSeparator: "",
});

const docs = await loader.load();

----------------------------------------

TITLE: Loading Turbopuffer Vector Store Example
DESCRIPTION: Example code demonstrating how to use Turbopuffer vector store with metadata filtering. Currently supports string values for metadata filtering.

LANGUAGE: typescript
CODE:
{SimilaritySearchExample}

----------------------------------------

TITLE: Klarna API Plugin Request
DESCRIPTION: Example of making a request to the Klarna Shopping API through the ChatGPT plugin interface to search for t-shirts.

LANGUAGE: json
CODE:
{
"action": "requests_get",
"action_input": "https://www.klarna.com/us/shopping/public/openai/v0/products?q=t-shirt"
}

----------------------------------------

TITLE: Custom Cohere Client Implementation
DESCRIPTION: Example showing how to use CohereClient for custom endpoints like Azure, AWS Bedrock, or standalone instances.

LANGUAGE: typescript
CODE:
<CodeBlock language="typescript">{ExampleClient}</CodeBlock>

----------------------------------------

TITLE: Installing @langchain/cohere and @langchain/core
DESCRIPTION: Command to install the required packages using npm or yarn.

LANGUAGE: bash
CODE:
npm install @langchain/cohere @langchain/core

----------------------------------------

TITLE: Using SerpAPILoader with LangChain for Web Search and Q&A
DESCRIPTION: This code demonstrates how to use SerpAPILoader to fetch search results, store them in a MemoryVectorStore, and create a retrieval chain for answering questions based on the loaded documents.

LANGUAGE: typescript
CODE:
import { SerpAPILoader } from "@langchain/community/document_loaders/web/serpapi";
import { OpenAIEmbeddings } from "@langchain/openai";
import { MemoryVectorStore } from "langchain/vectorstores/memory";
import { createStuffDocumentsChain } from "langchain/chains/combine_documents";
import { ChatPromptTemplate } from "@langchain/core/prompts";
import { createRetrievalChain } from "langchain/chains/retrieval";
import { ChatOpenAI } from "@langchain/openai";

// Load search results
const loader = new SerpAPILoader({ q: "LangChain", apiKey: "YOUR_SERPAPI_API_KEY" });
const docs = await loader.load();

// Load into memory vector store
const vectorStore = await MemoryVectorStore.fromDocuments(
  docs,
  new OpenAIEmbeddings()
);

const retriever = vectorStore.asRetriever();

const prompt = ChatPromptTemplate.fromTemplate(`Answer the following question based only on the provided context:

<context>
{context}
</context>

Question: {input}`);

const llm = new ChatOpenAI();

const documentChain = await createStuffDocumentsChain({
  llm,
  prompt,
});

const retrievalChain = await createRetrievalChain({
  combineDocsChain: documentChain,
  retriever,
});

const result = await retrievalChain.invoke({
  input: "What is LangChain?",
});

console.log(result.answer);

----------------------------------------

TITLE: Loading PDF as Single Document
DESCRIPTION: Load a PDF file as a single document without page-level splitting using the splitPages option set to false.

LANGUAGE: typescript
CODE:
import { PDFLoader } from "@langchain/community/document_loaders/fs/pdf";

const loader = new PDFLoader("src/document_loaders/example_data/example.pdf", {
  splitPages: false,
});

const docs = await loader.load();

----------------------------------------

TITLE: Importing LangChain Community Components in TypeScript
DESCRIPTION: Demonstrates how to import various components from the @langchain/community package, including chat models, LLMs, and vector stores.

LANGUAGE: typescript
CODE:
import { ChatParrotLink } from "@langchain/community/chat_models/parrot_link";
import { ParrotLinkLLM } from "@langchain/community/llms/parrot_link";
import { ParrotLinkVectorStore } from "@langchain/community/vectorstores/parrot_link";

----------------------------------------

TITLE: Setting Prem AI API Key in Bash
DESCRIPTION: This snippet shows how to export the Prem AI API key as an environment variable in Bash. The API key is required for authentication when using Prem AI services.

LANGUAGE: bash
CODE:
export PREM_API_KEY=your-api-key

----------------------------------------

TITLE: Initializing and Using ChatGPTPluginRetriever in TypeScript
DESCRIPTION: This snippet demonstrates how to import, initialize, and use the ChatGPTPluginRetriever class from LangChain. It sets up the retriever with a URL and authentication token, then invokes it with a query string.

LANGUAGE: typescript
CODE:
import { ChatGPTPluginRetriever } from "langchain/retrievers/remote";

const retriever = new ChatGPTPluginRetriever({
  url: "http://0.0.0.0:8000",
  auth: {
    bearer: "super-secret-jwt-token-with-at-least-32-characters-long",
  },
});

const docs = await retriever.invoke("hello world");

console.log(docs);

----------------------------------------

TITLE: Creating a Few-Shot Prompt for SQL Query Generation
DESCRIPTION: This code demonstrates how to create a few-shot prompt using the defined examples for improved SQL query generation.

LANGUAGE: typescript
CODE:
<CodeBlock language="typescript">{FewShotExample}</CodeBlock>

----------------------------------------

TITLE: Installing Dependencies for Sonix Audio Transcription in Node.js
DESCRIPTION: This command installs the necessary packages for using the Sonix Audio loader in a Node.js project. It includes @langchain/community, @langchain/core, and sonix-speech-recognition.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core sonix-speech-recognition

----------------------------------------

TITLE: Basic Usage of SingleStoreVectorStore in LangChain.js
DESCRIPTION: Example demonstrating how to import and use SingleStoreVectorStore for a basic similarity search. It includes setting up the vector store, adding documents, and performing a similarity search.

LANGUAGE: typescript
CODE:
import { OpenAIEmbeddings } from "@langchain/openai";
import { SingleStoreVectorStore } from "@langchain/community/vectorstores/singlestore";

// Configure the connection
const connectionConfig = {
  host: "localhost",
  port: 3306,
  user: "root",
  password: "password",
  database: "vectordb",
};

const vectorStore = await SingleStoreVectorStore.fromTexts(
  ["Hello world", "Bye bye", "hello nice world"],
  [{ id: 2 }, { id: 1 }, { id: 3 }],
  new OpenAIEmbeddings(),
  connectionConfig
);

const resultOne = await vectorStore.similaritySearch("hello world", 1);
console.log(resultOne);

await vectorStore.end();


----------------------------------------

TITLE: Installing Dependencies for ZhipuAI Integration in Node.js
DESCRIPTION: This snippet shows the command to install the necessary npm packages for integrating ZhipuAI with LangChain.js. It includes @langchain/community, @langchain/core, and jsonwebtoken.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core jsonwebtoken

----------------------------------------

TITLE: Streaming with Llama CPP using a single prompt in LangChain.js
DESCRIPTION: Example showing how to stream responses from Llama CPP using a raw 'single prompt' string in LangChain.js.

LANGUAGE: typescript
CODE:
import StreamExample from "@examples/models/chat/integration_llama_cpp_stream.ts";

<CodeBlock language="typescript">{StreamExample}</CodeBlock>

----------------------------------------

TITLE: Handling Submodules with GitHub Loader
DESCRIPTION: This example shows how to configure the GitHub loader to process submodules in a repository.

LANGUAGE: typescript
CODE:
import SubmodulesExample from "@examples/document_loaders/github_submodules.ts";

<CodeBlock language="typescript">{SubmodulesExample}</CodeBlock>

----------------------------------------

TITLE: Cohere Document Compression Implementation
DESCRIPTION: Implementation using the .compressDocuments() method to return reranked documents with relevancy scores.

LANGUAGE: typescript
CODE:
<CodeBlock language="typescript">{ExampleCompressor}</CodeBlock>

----------------------------------------

TITLE: Loading Jira Issues Using LangChain.js in Node.js
DESCRIPTION: Demonstrates how to authenticate and load Jira issues as documents using LangChain.js. Requires Jira access token, username, project key, and host URL for authentication and issue retrieval.

LANGUAGE: typescript
CODE:
import CodeBlock from "@theme/CodeBlock";
import Example from "@examples/document_loaders/jira.ts";

----------------------------------------

TITLE: Running Formatter
DESCRIPTION: Command to run the Prettier formatter on the project.

LANGUAGE: bash
CODE:
yarn format

----------------------------------------

TITLE: Extracting Taskade Project ID from URL
DESCRIPTION: This code snippet shows the structure of a Taskade project URL and indicates where to find the project ID. Users need to replace the placeholder with their actual project ID when using the TaskadeLoader.

LANGUAGE: plaintext
CODE:
https://www.taskade.com/d/<YOUR PROJECT ID HERE>

----------------------------------------

TITLE: Loading PDF with Page-Level Splitting
DESCRIPTION: Load a PDF file using PDFLoader with default page-level document splitting. Creates separate documents for each page in the PDF.

LANGUAGE: typescript
CODE:
import { PDFLoader } from "@langchain/community/document_loaders/fs/pdf";

const loader = new PDFLoader("src/document_loaders/example_data/example.pdf");

const docs = await loader.load();

----------------------------------------

TITLE: Adding an Optional Dependency Entrypoint
DESCRIPTION: Example of how to add an entrypoint that requires an optional dependency in the langchain.config.js file.

LANGUAGE: typescript
CODE:
// ...
requiresOptionalDependency: [
  // ...
  "tools/index",
],
// ...

----------------------------------------

TITLE: Configuring FirestoreChatMessageHistory in TypeScript
DESCRIPTION: Example of setting up FirestoreChatMessageHistory with Firebase Admin SDK credentials in a TypeScript file.

LANGUAGE: typescript
CODE:
import { FirestoreChatMessageHistory } from "@langchain/community/stores/message/firestore";
import admin from "firebase-admin";

const messageHistory = new FirestoreChatMessageHistory({
  collections: ["chats"],
  docs: ["user-id"],
  sessionId: "user-id",
  userId: "a@example.com",
  config: {
    projectId: "YOUR-PROJECT-ID",
    credential: admin.credential.cert({
      projectId: "YOUR-PROJECT-ID",
      privateKey:
        "-----BEGIN PRIVATE KEY-----\nCHANGE-ME\n-----END PRIVATE KEY-----\n",
      clientEmail: "CHANGE-ME@CHANGE-ME-TOO.iam.gserviceaccount.com",
    }),
  },
});

----------------------------------------

TITLE: Installing Momento SDK for Caching
DESCRIPTION: Commands to install the Momento SDK for Node.js or browser/edge environments.

LANGUAGE: bash
CODE:
npm install @gomomento/sdk

LANGUAGE: bash
CODE:
npm install @gomomento/sdk-web

----------------------------------------

TITLE: Basic Usage of GitHub Loader in TypeScript
DESCRIPTION: This code demonstrates the basic usage of the GitHub loader to load data from a repository.

LANGUAGE: typescript
CODE:
import CodeBlock from "@theme/CodeBlock";
import Example from "@examples/document_loaders/github.ts";

<CodeBlock language="typescript">{Example}</CodeBlock>

----------------------------------------

TITLE: Loading data from all paths in a GitBook using LangChain.js
DESCRIPTION: This snippet shows how to configure the GitbookLoader to load data from all paths in a given GitBook. It initializes the loader with the root URL and sets the shouldLoadAllPaths option to true.

LANGUAGE: typescript
CODE:
import { GitbookLoader } from "@langchain/community/document_loaders/web/gitbook";

const loader = new GitbookLoader("https://docs.gitbook.com", {
  shouldLoadAllPaths: true,
});

const docs = await loader.load();

----------------------------------------

TITLE: Installing LangChain Dependencies for SearchApi Integration
DESCRIPTION: This snippet shows the command to install the necessary npm packages for using SearchApi with LangChain.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core @langchain/openai

----------------------------------------

TITLE: Loading Data from JSONLines File using JSONLinesLoader in TypeScript
DESCRIPTION: This code demonstrates how to use the JSONLinesLoader from LangChain.js to load data from a JSONLines file. It creates a loader instance, specifies the file path and the JSON property to extract, and then loads the documents. The resulting documents contain the extracted content and metadata.

LANGUAGE: typescript
CODE:
import { JSONLinesLoader } from "langchain/document_loaders/fs/json";

const loader = new JSONLinesLoader(
  "src/document_loaders/example_data/example.jsonl",
  "/html"
);

const docs = await loader.load();
/*
[
  Document {
    "metadata": {
      "blobType": "application/jsonl+json",
      "line": 1,
      "source": "blob",
    },
    "pageContent": "This is a sentence.",
  },
  Document {
    "metadata": {
      "blobType": "application/jsonl+json",
      "line": 2,
      "source": "blob",
    },
    "pageContent": "This is another sentence.",
  },
]
*/

----------------------------------------

TITLE: Initializing NIBittensor LLM in TypeScript
DESCRIPTION: Example showing how to initialize and use the NIBittensor LLM model to generate text responses. The code demonstrates importing the model, creating an instance, and making a simple query about Bittensor.

LANGUAGE: typescript
CODE:
import { NIBittensorLLM } from "langchain/experimental/llms/bittensor";

const model = new NIBittensorLLM();

const res = await model.invoke(`What is Bittensor?`);

console.log({ res });

/*
  {
    res: "\nBittensor is opensource protocol..."
  }
 */

----------------------------------------

TITLE: Loading Documents from New Apify Dataset
DESCRIPTION: Example showing how to crawl a website using Website Content Crawler Actor and load the results into LangChain using ApifyDatasetLoader.

LANGUAGE: typescript
CODE:
import CodeBlock from "@theme/CodeBlock";
import NewExample from "@examples/document_loaders/apify_dataset_new.ts";

<CodeBlock language="typescript">{NewExample}</CodeBlock>

----------------------------------------

TITLE: Importing DocCardList Component in React/JSX
DESCRIPTION: Imports and renders the DocCardList theme component for displaying documentation cards.

LANGUAGE: jsx
CODE:
import DocCardList from "@theme/DocCardList";

<DocCardList />

----------------------------------------

TITLE: Initializing GradientLLM with Custom Credentials
DESCRIPTION: Example of instantiating the GradientLLM class with custom access key and workspace ID.

LANGUAGE: typescript
CODE:
const model = new GradientLLM({
  gradientAccessKey: "My secret Access Token"
  workspaceId: "My secret workspace id"
});

----------------------------------------

TITLE: Using SearchApiLoader to Process Web Search Results in TypeScript
DESCRIPTION: This code demonstrates how to use the SearchApiLoader to load web search results, store them in memory using MemoryVectorStore, and create a retrieval chain for answering questions based on the loaded documents.

LANGUAGE: typescript
CODE:
import { SearchApiLoader } from "@langchain/community/document_loaders/web/searchapi";
import { OpenAIEmbeddings } from "@langchain/openai";
import { MemoryVectorStore } from "langchain/vectorstores/memory";
import { RetrievalQAChain } from "langchain/chains";
import { ChatOpenAI } from "@langchain/openai";

const loader = new SearchApiLoader({
  q: "chatgpt",
  engine: "google",
  k: 3,
  api_key: "YOUR-API-KEY",
});

const docs = await loader.load();

const vectorStore = await MemoryVectorStore.fromDocuments(
  docs,
  new OpenAIEmbeddings()
);

const model = new ChatOpenAI({ modelName: "gpt-3.5-turbo" });

const chain = RetrievalQAChain.fromLLM(model, vectorStore.asRetriever());

const res = await chain.call({
  query: "What is ChatGPT?",
});
console.log({ res });

----------------------------------------

TITLE: Defining a Tool Schema without Execution Function in TypeScript
DESCRIPTION: Shows how to define a tool schema for tool calling that doesn't require a function to execute. This example defines a 'multiply' tool schema.

LANGUAGE: typescript
CODE:
const multiplyTool = {
  name: "multiply",
  description: "Multiply two numbers",
  schema: z.object({
    a: z.number(),
    b: z.number(),
  }),
};

----------------------------------------

TITLE: Building LangChain Core
DESCRIPTION: Commands to navigate to the langchain-core directory, install dependencies, and build the core package.

LANGUAGE: bash
CODE:
cd ../langchain-core
yarn
yarn build

----------------------------------------

TITLE: Creating Fallbacks for RunnableSequences in TypeScript
DESCRIPTION: Shows how to implement fallbacks for sequences using different models (ChatOpenAI and OpenAI) with distinct prompts for each model type.

LANGUAGE: typescript
CODE:
import ChainExample from "@examples/guides/fallbacks/chain.ts";

----------------------------------------

TITLE: Loading Audio Transcripts with AssemblyAI
DESCRIPTION: Example showing how to use AudioTranscriptParagraphsLoader or AudioTranscriptSentencesLoader to transcribe audio content

LANGUAGE: typescript
CODE:
TranscriptExample

----------------------------------------

TITLE: Loading Documents Using Iterator
DESCRIPTION: Fetching documents using the non-blocking lazy_load method with iterator

LANGUAGE: typescript
CODE:
for await (const doc of this.lazyLoad()) {
  console.log(doc);
  break;
}

----------------------------------------

TITLE: Loading Movie Script from IMSDB using IMSDBLoader in TypeScript
DESCRIPTION: This code demonstrates how to use the IMSDBLoader to load a movie script from IMSDB. It creates an instance of IMSDBLoader with a specific URL and then calls the load() method to fetch the script.

LANGUAGE: typescript
CODE:
import { IMSDBLoader } from "@langchain/community/document_loaders/web/imsdb";

const loader = new IMSDBLoader("https://imsdb.com/scripts/BlacKkKlansman.html");

const docs = await loader.load();

----------------------------------------

TITLE: Loading JSON Data with JSON Pointer
DESCRIPTION: Advanced example showing how to use JSON pointers to selectively extract data from specific keys ('from' and 'surname') in a JSON structure.

LANGUAGE: json
CODE:
{
  "1": {
    "body": "BD 2023 SUMMER",
    "from": "LinkedIn Job",
    "labels": ["IMPORTANT", "CATEGORY_UPDATES", "INBOX"]
  },
  "2": {
    "body": "Intern, Treasury and other roles are available",
    "from": "LinkedIn Job2",
    "labels": ["IMPORTANT"],
    "other": {
      "name": "plop",
      "surname": "bob"
    }
  }
}

LANGUAGE: typescript
CODE:
import { JSONLoader } from "langchain/document_loaders/fs/json";

const loader = new JSONLoader(
  "src/document_loaders/example_data/example.json",
  ["/from", "/surname"]
);

const docs = await loader.load();

----------------------------------------

TITLE: Document Compressor Pipeline Implementation
DESCRIPTION: Example showing how to combine multiple compressors and document transformers in a pipeline, using Tavily web search API retriever with text splitting and embedding filtering.

LANGUAGE: typescript
CODE:
{DocumentCompressorPipelineExample}

----------------------------------------

TITLE: Basic Usage of Minimax Chat Model in LangChain.js
DESCRIPTION: Demonstrates the basic setup and usage of a Minimax chat model within a LangChain.js application.

LANGUAGE: typescript
CODE:
import Minimax from "@examples/models/chat/integration_minimax.ts";

----------------------------------------

TITLE: Loading JSON without Pointer using TypeScript
DESCRIPTION: Demonstrates how to load and parse a JSON file using JSONLoader without specifying a JSON pointer, which extracts all string values from the JSON object.

LANGUAGE: typescript
CODE:
import { JSONLoader } from "langchain/document_loaders/fs/json";

const loader = new JSONLoader("src/document_loaders/example_data/example.json");

const docs = await loader.load();

----------------------------------------

TITLE: Importing ChatOpenAI in TypeScript
DESCRIPTION: Import statement for ChatOpenAI from @langchain/openai.

LANGUAGE: typescript
CODE:
import { ChatOpenAI } from "@langchain/openai";

----------------------------------------

TITLE: Generating embeddings for a single query in TypeScript
DESCRIPTION: Demonstrates how to use the embedQuery method to generate embeddings for a single text query.

LANGUAGE: typescript
CODE:
const embedding = await embeddings.embedQuery(
  "What would be a good company name for a company that makes colorful socks?"
);
console.log(embedding);

----------------------------------------

TITLE: Using CohereEmbeddings for text embedding in TypeScript
DESCRIPTION: Example of creating a CohereEmbeddings instance and generating embeddings for a query.

LANGUAGE: typescript
CODE:
import { ChatCohere } from "@langchain/cohere";

const embeddings = new ChatCohere({
  apiKey: process.env.COHERE_API_KEY,
});
const res = await embeddings.embedQuery("Hello world");

----------------------------------------

TITLE: Loading Hacker News Content with HNLoader
DESCRIPTION: TypeScript code demonstrating how to initialize the HNLoader with a Hacker News URL and load the content into documents. Each page will be converted into a separate document.

LANGUAGE: typescript
CODE:
import { HNLoader } from "@langchain/community/document_loaders/web/hn";

const loader = new HNLoader("https://news.ycombinator.com/item?id=34817881");

const docs = await loader.load();

----------------------------------------

TITLE: Implementing Connery Toolkit with LangChain Agent in TypeScript
DESCRIPTION: This code demonstrates how to create a LangChain agent that uses Connery Actions to summarize a public webpage and send the summary via email. It utilizes the Summarization and Gmail plugins from Connery.

LANGUAGE: typescript
CODE:
{Example}

----------------------------------------

TITLE: Installing Project Dependencies
DESCRIPTION: Command to install the project dependencies using Yarn.

LANGUAGE: bash
CODE:
yarn

----------------------------------------

TITLE: Deleting Documents from Vector Store
DESCRIPTION: TypeScript example demonstrating how to delete documents from the vector store by their IDs

LANGUAGE: typescript
CODE:
await vectorStore.deleteDocuments({ ids: [1, 2] });

----------------------------------------

TITLE: Installing Required Dependencies
DESCRIPTION: Commands to install necessary npm packages for SQL query validation including LangChain community packages, OpenAI integration, TypeORM, and SQLite3.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/openai typeorm sqlite3

----------------------------------------

TITLE: Installing LangChain.js and OpenAI dependencies
DESCRIPTION: Command to install the required npm packages for using the MetadataTagger with OpenAI functions in LangChain.js.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/core

----------------------------------------

TITLE: Basic Llama CPP Embedding Usage in TypeScript
DESCRIPTION: Demonstrates how to initialize and use the LlamaCppEmbeddings class for basic embedding tasks. It requires specifying the path to a local Llama 3 model.

LANGUAGE: typescript
CODE:
import { LlamaCppEmbeddings } from "@langchain/community/embeddings/llama_cpp";

const embeddings = new LlamaCppEmbeddings({
  modelPath: "./models/llama-2-7b-chat.Q4_0.gguf",
});

const res = await embeddings.embedQuery("Hello world");
console.log(res);

----------------------------------------

TITLE: Ignoring Specific Files in GitHub Loader
DESCRIPTION: This example shows how to use the 'ignorePaths' option to exclude specific files when loading data from a GitHub repository.

LANGUAGE: typescript
CODE:
import IgnoreExample from "@examples/document_loaders/github_ignore_paths.ts";

<CodeBlock language="typescript">{IgnoreExample}</CodeBlock>

----------------------------------------

TITLE: Creating and Querying Zep Vector Store
DESCRIPTION: Example showing how to create a ZepVectorStore from documents and perform similarity searches. Uses auto-embedding feature with FakeEmbeddings.

LANGUAGE: typescript
CODE:
{ExampleDocs}

----------------------------------------

TITLE: Configuring Apache Cassandra Connection
DESCRIPTION: TypeScript configuration object for connecting to an Apache Cassandra cluster, including contact points, data center, and credentials

LANGUAGE: typescript
CODE:
const configConnection = {
  contactPoints: ['h1', 'h2'],
  localDataCenter: 'datacenter1',
  credentials: {
    username: <...> as string,
    password: <...> as string,
  },
};

----------------------------------------

TITLE: Installing Cohere Dependencies with NPM/Yarn
DESCRIPTION: Commands to install the required Cohere and LangChain Core packages for document reranking functionality.

LANGUAGE: bash
CODE:
npm install @langchain/cohere @langchain/core

----------------------------------------

TITLE: Version Number Format Description
DESCRIPTION: Markdown documentation outlining the versioning structure and rules for LangChain packages. Explains criteria for minor and patch version increases across different packages.

LANGUAGE: markdown
CODE:
#  Package Versioning

As of now, LangChain has an ad hoc release process: releases are cut with high frequency by
a maintainer and published to [PyPI](https://pypi.org/).
The different packages are versioned slightly differently.

## `@langchain/core`

`@langchain/core` is currently on version `0.1.x`.

As `@langchain/core` contains the base abstractions and runtime for the whole LangChain ecosystem, we will communicate any breaking changes with advance notice and version bumps. The exception for this is anything marked with the `beta` decorator (you can see this in the API reference and will see warnings when using such functionality). The reason for beta features is that given the rate of change of the field, being able to move quickly is still a priority.

Minor version increases will occur for:

- Breaking changes for any public interfaces marked as `beta`.

Patch version increases will occur for:

- Bug fixes
- New features
- Any changes to private interfaces
- Any changes to `beta` features

## `langchain`

`langchain` is currently on version `0.1.x`

Minor version increases will occur for:

- Breaking changes for any public interfaces NOT marked as `beta`.

Patch version increases will occur for:

- Bug fixes
- New features
- Any changes to private interfaces
- Any changes to `beta` features

We are working on the `langchain` v0.2 release, which will have some breaking changes to legacy Chains and Agents.
Additionally, we will remove `@langchain/community` as a dependency and stop re-exporting integrations that have been moved to `@langchain/community`.

## `@langchain/community`

`@langchain/community` is currently on version `0.0.x`

All changes will be accompanied by a patch version increase.

## Partner Packages

Partner packages are versioned independently.

----------------------------------------

TITLE: Indexing Documents in Cassandra Vector Store
DESCRIPTION: Example of indexing documents in the Cassandra vector store using LangChain.js. It demonstrates creating a CassandraStore instance with configuration, texts, metadata, and OpenAI embeddings.

LANGUAGE: typescript
CODE:
import { CassandraStore } from "langchain/vectorstores/cassandra";
import { OpenAIEmbeddings } from "@langchain/openai";

// The configConnection document is defined above
const config = {
  ...configConnection,
  keyspace: "test",
  dimensions: 1536,
  table: "test",
  indices: [{ name: "name", value: "(name)" }],
  primaryKey: {
    name: "id",
    type: "int",
  },
  metadataColumns: [
    {
      name: "name",
      type: "text",
    },
  ],
};

const vectorStore = await CassandraStore.fromTexts(
  ["I am blue", "Green yellow purple", "Hello there hello"],
  [
    { id: 2, name: "2" },
    { id: 1, name: "1" },
    { id: 3, name: "3" },
  ],
  new OpenAIEmbeddings(),
  cassandraConfig
);

----------------------------------------

TITLE: Streaming Large Repositories with GitHub Loader
DESCRIPTION: This snippet demonstrates how to use the 'loadAsStream' method to efficiently process large GitHub repositories by streaming documents asynchronously.

LANGUAGE: typescript
CODE:
import StreamExample from "@examples/document_loaders/github_stream.ts";

<CodeBlock language="typescript">{StreamExample}</CodeBlock>

----------------------------------------

TITLE: Using Gemini Vision Model with Image Input
DESCRIPTION: TypeScript code demonstrating how to use the Gemini vision model with an image input for multimodal processing.

LANGUAGE: typescript
CODE:
import fs from "fs";
import { ChatGoogleGenerativeAI } from "@langchain/google-genai";
import { HumanMessage } from "@langchain/core/messages";

const vision = new ChatGoogleGenerativeAI({
  modelName: "gemini-pro-vision",
  maxOutputTokens: 2048,
});
const image = fs.readFileSync("./hotdog.jpg").toString("base64");
const input = [
  new HumanMessage({
    content: [
      {
        type: "text",
        text: "Describe the following image.",
      },
      {
        type: "image_url",
        image_url: `data:image/png;base64,${image}`,
      },
    ],
  }),
];

const res = await vision.invoke(input);

----------------------------------------

TITLE: Adding Documents with IDs to VectorStore in TypeScript
DESCRIPTION: This snippet illustrates how to add documents with specific IDs to a vector store in LangChain, allowing for document updates.

LANGUAGE: typescript
CODE:
await vectorStore.addDocuments(documents, { ids: ["doc1", "doc2"] });

----------------------------------------

TITLE: Using RunnableConfig with Tools in TypeScript
DESCRIPTION: Shows how to create a tool that accepts a RunnableConfig object, allowing for custom runtime values to be passed to the tool.

LANGUAGE: typescript
CODE:
import { RunnableConfig } from "@langchain/core/runnables";

const someTool = tool(
    async (args: any, config: RunnableConfig): Promise<[string, any]> => {
        /**
         * Tool that does something.
         */
    },
    {
        name: "some_tool",
        description: "Tool that does something",
        schema: z.object({ ... }),
        returnType: "content_and_artifact"
    }
);


await someTool.invoke(..., { configurable: { value: "some_value" } });

----------------------------------------

TITLE: Installing LangChain Dependencies for Alibaba Tongyi
DESCRIPTION: Commands to install the required npm packages @langchain/community and @langchain/core for using Alibaba Tongyi chat models.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core

----------------------------------------

TITLE: Configuring Apache Cassandra Connection in TypeScript
DESCRIPTION: This code snippet demonstrates how to create a configuration object for connecting to an Apache Cassandra database. It includes contact points, local data center, and credentials.

LANGUAGE: typescript
CODE:
const configConnection = {
  contactPoints: ['h1', 'h2'],
  localDataCenter: 'datacenter1',
  credentials: {
    username: <...> as string,
    password: <...> as string,
  },
};

----------------------------------------

TITLE: Creating Couchbase Document Loader
DESCRIPTION: Initializing the CouchbaseDocumentLoader with connected cluster client and query

LANGUAGE: typescript
CODE:
const loader = new CouchbaseDocumentLoader(
  couchbaseClient,
  query
);

----------------------------------------

TITLE: Configuring Token-Based Rate Limiting for LLMs
DESCRIPTION: Shows how to configure the UpstashRatelimitHandler for token-based rate limiting with LLMs, including custom field mapping for different LLM outputs.

LANGUAGE: typescript
CODE:
const handler = new UpstashRatelimitHandler(
  user_id,
  {
    requestRatelimit: ratelimit
    llmOutputTokenUsageField: "usage",
    llmOutputTotalTokenField: "total",
    llmOutputPromptTokenField: "prompt"
  }
)

----------------------------------------

TITLE: Streaming Events from LCEL Chain
DESCRIPTION: Illustrates how to use the streamEvents() method to access custom data and intermediate outputs from an LLM application built with LangChain Expression Language (LCEL). This example filters and processes events containing streamed chat model output.

LANGUAGE: typescript
CODE:
import { StringOutputParser } from "@langchain/core/output_parsers";
import { ChatPromptTemplate } from "@langchain/core/prompts";
import { ChatAnthropic } from "@langchain/anthropic";

const model = new ChatAnthropic({ model: "claude-3-sonnet-20240229" });

const prompt = ChatPromptTemplate.fromTemplate("tell me a joke about {topic}");
const parser = StringOutputParser();
const chain = prompt.pipe(model).pipe(parser);

for await (const event of await chain.streamEvents(
  { topic: "parrot" },
  { version: "v2" }
)) {
  if (event.event === "on_chat_model_stream") {
    console.log(event);
  }
}

----------------------------------------

TITLE: Basic Upstash Ratelimit Usage in TypeScript
DESCRIPTION: Demonstrates the basic usage of Upstash Ratelimit to limit costly operations based on the number of remaining tokens or requests.

LANGUAGE: typescript
CODE:
const response = await ratelimit.limit();
if (response.success) {
  execute_costly_operation();
}

----------------------------------------

TITLE: Installing Browser Dependencies
DESCRIPTION: Additional package installation required for browser environments when using Tencent Hunyuan.

LANGUAGE: bash
CODE:
npm install crypto-js

----------------------------------------

TITLE: Error Handling for MixedbreadAIEmbeddings
DESCRIPTION: Example of implementing error handling when initializing MixedbreadAIEmbeddings without proper configuration.

LANGUAGE: typescript
CODE:
try {
  const embeddings = new MixedbreadAIEmbeddings();
} catch (error) {
  console.error(error);
}

----------------------------------------

TITLE: JSON Structure with Nested Properties
DESCRIPTION: Example of a more complex JSON file with nested objects and arrays, used to demonstrate selective property extraction.

LANGUAGE: json
CODE:
{
  "1": {
    "body": "BD 2023 SUMMER",
    "from": "LinkedIn Job",
    "labels": ["IMPORTANT", "CATEGORY_UPDATES", "INBOX"]
  },
  "2": {
    "body": "Intern, Treasury and other roles are available",
    "from": "LinkedIn Job2",
    "labels": ["IMPORTANT"],
    "other": {
      "name": "plop",
      "surname": "bob"
    }
  }
}

----------------------------------------

TITLE: Installing LangChain Dependencies for SearchApi
DESCRIPTION: Command to install the required npm packages for using SearchApi with LangChain.js

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/core

----------------------------------------

TITLE: Installing LangChain Core Dependencies
DESCRIPTION: Command to install the required LangChain community and core packages for document transformation.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core

----------------------------------------

TITLE: Creating and Binding a Tool in TypeScript
DESCRIPTION: Demonstrates how to create a tool using the 'tool' function and bind it to a model that supports tool calling. The example creates a 'multiply' tool and binds it to a model.

LANGUAGE: typescript
CODE:
import { tool } from "@langchain/core/tools";

const multiply = tool(
  ({ a, b }: { a: number; b: number }): number => {
    /**
     * Multiply a and b.
     */
    return a * b;
  },
  {
    name: "multiply",
    description: "Multiply two numbers",
    schema: z.object({
      a: z.number(),
      b: z.number(),
    }),
  }
);

const llmWithTools = toolCallingModel.bindTools([multiply]);

----------------------------------------

TITLE: Using SessionsPythonREPLTool for executing Python code in Azure Container Apps
DESCRIPTION: TypeScript example demonstrating how to create and use the SessionsPythonREPLTool. It shows setting up the tool with an environment variable for the pool management endpoint and invoking it with Python code.

LANGUAGE: typescript
CODE:
import { SessionsPythonREPLTool } from "@langchain/azure-dynamic-sessions";

const tool = new SessionsPythonREPLTool({
  poolManagementEndpoint:
    process.env.AZURE_CONTAINER_APP_SESSION_POOL_MANAGEMENT_ENDPOINT || "",
});

const result = await tool.invoke("print('Hello, World!')\n1+2");

console.log(result);

// {
//   stdout: "Hello, World!\n",
//   stderr: "",
//   result: 3,
// }

----------------------------------------

TITLE: LangChain Import Examples
DESCRIPTION: Various ways to import LangChain in different environments including ESM, CommonJS, and Deno.

LANGUAGE: typescript
CODE:
import { ChatOpenAI } from "@langchain/openai";
// CommonJS
const { ChatOpenAI } = require("@langchain/openai");
// Deno
import { ChatOpenAI } from "https://esm.sh/@langchain/openai";

----------------------------------------

TITLE: Importing Vertex AI Vector Search
DESCRIPTION: Shows how to import the Vertex AI Vector Search (formerly Matching Engine) for use in LangChain.js.

LANGUAGE: typescript
CODE:
import { MatchingEngine } from "langchain/vectorstores/googlevertexai";

----------------------------------------

TITLE: File Structure for MultiFileLoader Example
DESCRIPTION: Shows the directory structure of example files used in the MultiFileLoader demonstration.

LANGUAGE: text
CODE:
src/document_loaders/example_data/example/
 example.txt
 example.csv

src/document_loaders/example_data/example2/
 example.json
 example.jsonl

----------------------------------------

TITLE: Installing Required Dependencies for LangChain.js Time-Weighted Retriever
DESCRIPTION: This bash command installs the necessary npm packages (@langchain/openai and @langchain/core) to use the Time-Weighted Retriever in a LangChain.js project.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/core

----------------------------------------

TITLE: Reranking Documents with MixedbreadAIReranker in TypeScript
DESCRIPTION: Example of using the rerankDocuments method to reorder a list of documents based on a query. This demonstrates how to prepare the input data and make a reranking request.

LANGUAGE: typescript
CODE:
const documents = [
  { pageContent: "To bake bread you need flour" },
  { pageContent: "To bake bread you need yeast" },
  { pageContent: "To eat bread you need nothing but good taste" },
];
const query = "What do you need to bake bread?";
const result = await reranker.compressDocuments(documents, query);
console.log(result);

----------------------------------------

TITLE: Complete example of using JinaEmbeddings in TypeScript
DESCRIPTION: A comprehensive example showing how to set up and use the JinaEmbeddings class for both query and document embeddings.

LANGUAGE: typescript
CODE:
import { JinaEmbeddings } from "@langchain/community/embeddings/jina";
import { localImageToBase64 } from "@langchain/community/embeddings/jina/util";

const embeddings = new JinaEmbeddings({
  apiKey: "YOUR_API_TOKEN",
  model: "jina-embeddings-v2-base-en",
});

async function runExample() {
  const queryEmbedding = await embeddings.embedQuery("Example query text.");
  console.log("Query Embedding:", queryEmbedding);

  const documents = [
    "hello",
    {
      text: "hello",
    },
    {
      image: "https://i.ibb.co/nQNGqL0/beach1.jpg",
    },
    {
      image: await localImageToBase64("beach1.jpg"),
    },
  ];
  const documentEmbeddings = await embeddings.embedDocuments(documents);
  console.log("Document Embeddings:", documentEmbeddings);
}

runExample();

----------------------------------------

TITLE: Installing Azure Blob Storage Dependencies
DESCRIPTION: Installation command for Azure Blob Storage document loader integration.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core @azure/storage-blob

----------------------------------------

TITLE: Customizing Retrieval Query in Neo4jVectorStore
DESCRIPTION: Example showing how to use the retrievalQuery parameter to customize the response from Neo4jVectorStore.

LANGUAGE: typescript
CODE:
import { Neo4jVectorStore } from "@langchain/community/vectorstores/neo4j_vector";
import { OpenAIEmbeddings } from "@langchain/openai";
import { Neo4jGraph } from "@langchain/community/graphs/neo4j_graph";
import neo4j from "neo4j-driver";

const driver = neo4j.driver(
  "bolt://localhost:7687",
  neo4j.auth.basic("neo4j", "pleaseletmein")
);

const graph = await Neo4jGraph.initialize({ driver });

const vectorStore = new Neo4jVectorStore(graph, new OpenAIEmbeddings(), {
  retrievalQuery: `
    RETURN
      node.text AS text,
      score,
      {prop1: node.prop1, prop2: node.prop2} AS metadata
  `,
});

await vectorStore.addDocuments([
  { pageContent: "a", metadata: { prop1: "value1", prop2: "value2" } },
]);

const results = await vectorStore.similaritySearch("a", 1);
console.log(results);

await driver.close();

----------------------------------------

TITLE: Loading Sitemap with SitemapLoader
DESCRIPTION: This example demonstrates how to use the SitemapLoader class to load a sitemap and its contents into Document objects.

LANGUAGE: typescript
CODE:
import CodeBlock from "@theme/CodeBlock";
import Example from "@examples/document_loaders/sitemap.ts";

<CodeBlock language="typescript">{Example}</CodeBlock>

----------------------------------------

TITLE: Installing Dependencies for IORedis Storage in LangChain.js
DESCRIPTION: This snippet shows the command to install the necessary npm packages for implementing IORedis storage in a LangChain.js project. It includes @langchain/community, @langchain/core, and ioredis.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core ioredis

----------------------------------------

TITLE: Using ZhipuAIEmbeddings in TypeScript
DESCRIPTION: This code demonstrates how to use the ZhipuAIEmbeddings class to generate embeddings for given text. It imports the necessary class, creates an instance, and uses it to embed a text string.

LANGUAGE: typescript
CODE:
import { ZhipuAIEmbeddings } from "@langchain/community/embeddings/zhipuai";

const embeddings = new ZhipuAIEmbeddings();

const res = await embeddings.embedQuery("Hello world");
console.log(res);

----------------------------------------

TITLE: Stream Processing Implementation
DESCRIPTION: Implementation of stream processing logic to handle and update streaming data.

LANGUAGE: typescript
CODE:
    const streamResult = await chain.stream({
      input,
    });

    for await (const item of streamResult) {
      stream.update(JSON.parse(JSON.stringify(item, null, 2)));
    }

    stream.done();
  })();

  return { streamData: stream.value };

----------------------------------------

TITLE: TypeScript Config for ESM Projects
DESCRIPTION: Recommended TypeScript configuration for ESM projects using LangChain.

LANGUAGE: json
CODE:
{
  "compilerOptions": {
    "target": "ES2020",
    "module": "nodenext"
  }
}

----------------------------------------

TITLE: Importing Azure Cosmos DB Components
DESCRIPTION: TypeScript import statements for various Azure Cosmos DB integrations including NoSQL and MongoDB vector stores.

LANGUAGE: typescript
CODE:
import { AzureCosmosDBNoSQLVectorStore } from "@langchain/azure-cosmosdb";
import { AzureCosmosDBMongoDBVectorStore } from "@langchain/azure-cosmosdb";
import { AzureCosmosDBNoSQLSemanticCache } from "@langchain/azure-cosmosdb";
import { AzureCosmosDBNoSQLChatMessageHistory } from "@langchain/azure-cosmosdb";
import { AzureCosmosDBMongoChatMessageHistory } from "@langchain/azure-cosmosdb";

----------------------------------------

TITLE: Example JSONLines File Structure
DESCRIPTION: This snippet shows the structure of a sample JSONLines file. Each line contains a JSON object with an 'html' property holding a sentence.

LANGUAGE: json
CODE:
{
"html": "This is a sentence."
}
{
"html": "This is another sentence."
}

----------------------------------------

TITLE: Implementing IORedis Storage for Chat History in LangChain.js
DESCRIPTION: This code snippet demonstrates the implementation of chat history storage using IORedis in a LangChain.js project. It imports necessary modules, creates a Redis client, initializes a RedisByteStore, and sets up a ChatMessageHistory instance with the Redis store.

LANGUAGE: typescript
CODE:
import { Redis } from "ioredis";
import { ChatMessageHistory } from "langchain/memory";
import { RedisByteStore } from "@langchain/community/stores/file/ioredis";

const client = new Redis("redis://localhost:6379");

const store = new RedisByteStore({
  client,
  sessionTTL: 300,
  namespace: "my-prefix",
});

const chatHistory = new ChatMessageHistory({
  store,
  sessionId: "foo",
});

await chatHistory.addUserMessage("Hi there!");
const messages = await chatHistory.getMessages();
console.log(messages);

await client.quit();

----------------------------------------

TITLE: Using Llama CPP with chains in LangChain.js
DESCRIPTION: Example demonstrating how to use Llama CPP with chains in LangChain.js. More complex chains may require a more powerful version of Llama3.

LANGUAGE: typescript
CODE:
import ChainExample from "@examples/models/chat/integration_llama_cpp_chain.ts";

<CodeBlock language="typescript">{ChainExample}</CodeBlock>

----------------------------------------

TITLE: Weather Tool Schema Definition
DESCRIPTION: Zod schema definition for a weather tool that specifies city and state parameters.

LANGUAGE: typescript
CODE:
const Weather = z
  .object({
    city: z.string().describe("City to search for weather"),
    state: z.string().describe("State abbreviation to search for weather"),
  })
  .describe("Weather search parameters");

----------------------------------------

TITLE: Using MixedbreadAIEmbeddings in TypeScript
DESCRIPTION: This code demonstrates how to use the MixedbreadAIEmbeddings class to generate embeddings for a list of texts. It requires an API key from Mixedbread AI.

LANGUAGE: typescript
CODE:
const embeddings = new MixedbreadAIEmbeddings({ apiKey: 'your-api-key' });
const texts = ["Baking bread is fun", "I love baking"];
const result = await embeddings.embedDocuments(texts);
console.log(result);

----------------------------------------

TITLE: Importing S3 Document Loader
DESCRIPTION: Import statement for the AWS S3 document loader integration.

LANGUAGE: typescript
CODE:
import { S3Loader } from "@langchain/community/document_loaders/web/s3";

----------------------------------------

TITLE: Setting JigsawStack API Key
DESCRIPTION: Environment variable configuration for JigsawStack API authentication.

LANGUAGE: bash
CODE:
export JIGSAWSTACK_API_KEY="your-api-key"

----------------------------------------

TITLE: Running Transpiled JavaScript Examples
DESCRIPTION: Alternative command for running transpiled JavaScript examples from the dist directory.

LANGUAGE: sh
CODE:
yarn run start:dist ./dist/prompts/few_shot.js

----------------------------------------

TITLE: Importing and Using VercelKVStore in TypeScript
DESCRIPTION: This code block demonstrates the usage of VercelKVStore for chat history storage in a TypeScript environment. It imports necessary components and sets up a chat model with memory backed by Vercel KV.

LANGUAGE: typescript
CODE:
import CodeBlock from "@theme/CodeBlock";
import Example from "@examples/stores/vercel_kv_storage.ts";

<CodeBlock language="typescript">{Example}</CodeBlock>

----------------------------------------

TITLE: Tracking Token Usage with OpenAI in Streaming Mode
DESCRIPTION: Example of how to track token usage for OpenAI models in streaming mode, enabled by passing a stream_options parameter.

LANGUAGE: typescript
CODE:
import OpenAIStreamTokens from "@examples/models/chat/integration_openai_stream_tokens.ts";

<CodeBlock language="typescript">{OpenAIStreamTokens}</CodeBlock>

----------------------------------------

TITLE: Initializing Local File System Cache
DESCRIPTION: Creating a local file system cache for development purposes in LangChain.

LANGUAGE: typescript
CODE:
const cache = await LocalFileCache.create();

----------------------------------------

TITLE: Defining Convex Schema for Chat Messages
DESCRIPTION: This snippet defines the Convex database schema for storing chat messages, including session ID, message type, content, and optional fields.

LANGUAGE: typescript
CODE:
import { defineSchema, defineTable } from "convex/server";
import { v } from "convex/values";

export default defineSchema({
  messages: defineTable({
    sessionId: v.string(),
    message: v.object({
      type: v.string(),
      data: v.object({
        content: v.string(),
        role: v.optional(v.string()),
        name: v.optional(v.string()),
        additional_kwargs: v.optional(v.any()),
      }),
    }),
  }).index("bySessionId", ["sessionId"]),
});

----------------------------------------

TITLE: Adding a New Entrypoint
DESCRIPTION: Example of how to add a new entrypoint in the langchain.config.js file.

LANGUAGE: typescript
CODE:
// ...
entrypoints: {
  // ...
  tools: "tools/index",
},
// ...

----------------------------------------

TITLE: Installing Browser Dependencies
DESCRIPTION: Command to install additional dependencies required for browser environments when using Tencent Hunyuan embeddings.

LANGUAGE: bash
CODE:
npm install crypto-js

----------------------------------------

TITLE: Using Google Generative AI Embeddings
DESCRIPTION: TypeScript code showing how to use Google's embeddings models for query embedding.

LANGUAGE: typescript
CODE:
import { GoogleGenerativeAIEmbeddings } from "@langchain/google-genai";
import { TaskType } from "@google/generative-ai";

const embeddings = new GoogleGenerativeAIEmbeddings({
  modelName: "embedding-001", // 768 dimensions
  taskType: TaskType.RETRIEVAL_DOCUMENT,
  title: "Document title",
});

const res = await embeddings.embedQuery("OK Google");

----------------------------------------

TITLE: Error Handling for Missing API Token
DESCRIPTION: Demonstrates proper error handling when API token is missing from both constructor and environment variables

LANGUAGE: typescript
CODE:
try {
  const embeddings = new DeepInfraEmbeddings();
} catch (error) {
  console.error("DeepInfra API token not found");
}

----------------------------------------

TITLE: Basic ParentDocumentRetriever Implementation
DESCRIPTION: Example showing basic usage of ParentDocumentRetriever with imported configuration from example file.

LANGUAGE: typescript
CODE:
{Example}

----------------------------------------

TITLE: Generating Nomic Embeddings with TypeScript
DESCRIPTION: TypeScript code snippet demonstrating how to create Nomic embeddings using the NomicEmbeddings class from @langchain/nomic package.

LANGUAGE: typescript
CODE:
import { NomicEmbeddings } from "@langchain/nomic";

const nomicEmbeddings = new NomicEmbeddings({
  apiKey: process.env.NOMIC_API_KEY, // Default value.
  modelName: "nomic-embed-text-v1",  // Default value.
});

const docs = [
  "hello world",
  "nomic embeddings!",
  "super special langchain integration package",
  "what color is the sky?",
];

const embeddings = await nomicEmbeddings.embedDocuments(docs);

----------------------------------------

TITLE: Installing ZhipuAI Dependencies for LangChain.js
DESCRIPTION: This snippet shows how to install the necessary packages for using ZhipuAI embeddings with LangChain.js. It requires the @langchain/community package, @langchain/core, and jsonwebtoken.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core jsonwebtoken

----------------------------------------

TITLE: Initializing MixedbreadAIEmbeddings
DESCRIPTION: Creating an instance of MixedbreadAIEmbeddings with an API key and optional model specification.

LANGUAGE: typescript
CODE:
import { MixedbreadAIEmbeddings } from "@langchain/mixedbread-ai";

const embeddings = new MixedbreadAIEmbeddings({
  apiKey: "YOUR_API_KEY",
  // Optionally specify model
  // model: "mixedbread-ai/mxbai-embed-large-v1",
});

----------------------------------------

TITLE: Running Unit Tests
DESCRIPTION: Command to run only unit tests in the project.

LANGUAGE: bash
CODE:
yarn test

----------------------------------------

TITLE: Complete DeepInfra Integration Example
DESCRIPTION: Full example showing initialization and usage of DeepInfraEmbeddings for both single queries and multiple documents

LANGUAGE: typescript
CODE:
import { DeepInfraEmbeddings } from "@langchain/community/embeddings/deepinfra";

const embeddings = new DeepInfraEmbeddings({
  apiToken: "YOUR_API_TOKEN",
  modelName: "sentence-transformers/clip-ViT-B-32",
  batchSize: 512,
});

async function runExample() {
  const queryEmbedding = await embeddings.embedQuery("Example query text.");
  console.log("Query Embedding:", queryEmbedding);

  const documents = ["Text 1", "Text 2", "Text 3"];
  const documentEmbeddings = await embeddings.embedDocuments(documents);
  console.log("Document Embeddings:", documentEmbeddings);
}

runExample();

----------------------------------------

TITLE: Installing LangChain.js Dependencies for Motrhead Memory Integration
DESCRIPTION: This code snippet shows how to install the necessary npm packages for using Motrhead memory with LangChain.js. It includes the OpenAI integration and core LangChain packages.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/core

----------------------------------------

TITLE: Installing LangChain and OpenAI Dependencies
DESCRIPTION: Commands to install the required packages for using LangChain with OpenAI.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/core

----------------------------------------

TITLE: Running Tests
DESCRIPTION: Commands to run unit tests, a single test file, and integration tests.

LANGUAGE: bash
CODE:
yarn test

LANGUAGE: bash
CODE:
yarn test:single /path/to/yourtest.test.ts

LANGUAGE: bash
CODE:
yarn test:integration

----------------------------------------

TITLE: Error handling for missing API token in TypeScript
DESCRIPTION: Demonstrates how to handle errors when the Jina API token is not provided or found in environment variables.

LANGUAGE: typescript
CODE:
try {
  const embeddings = new JinaEmbeddings();
} catch (error) {
  console.error("Jina API token not found");
}

----------------------------------------

TITLE: Initializing ChatGoogleGenerativeAI Model
DESCRIPTION: TypeScript code to create a ChatGoogleGenerativeAI instance and invoke it with a message.

LANGUAGE: typescript
CODE:
import { ChatGoogleGenerativeAI } from "@langchain/google-genai";

const model = new ChatGoogleGenerativeAI({
  modelName: "gemini-pro",
  maxOutputTokens: 2048,
});
const response = await model.invoke(new HumanMessage("Hello world!"));

----------------------------------------

TITLE: Customizing Mixedbread AI Configuration
DESCRIPTION: Example of customizing the Mixedbread AI SDK with additional parameters like baseUrl and maxRetries.

LANGUAGE: typescript
CODE:
const customEmbeddings = new MixedbreadAIEmbeddings({
  apiKey: "YOUR_API_KEY",
  baseUrl: "...",
  maxRetries: 6,
});

----------------------------------------

TITLE: Configuring verbose logging on individual tools
DESCRIPTION: Example demonstrating how to enable verbose logging on specific tools rather than the full agent

LANGUAGE: typescript
CODE:
const tool = new TavilySearchResults({
  maxResults: 10, 
  verbose: true
});

----------------------------------------

TITLE: Installing LangChain Dependencies for Connery
DESCRIPTION: Command to install the required peer dependencies @langchain/community and @langchain/core for using Connery Action Tool with LangChain.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core

----------------------------------------

TITLE: Navigating to Workspace Directory
DESCRIPTION: Commands to navigate to the main LangChain workspace or the community integrations workspace.

LANGUAGE: bash
CODE:
cd langchain

LANGUAGE: bash
CODE:
cd libs/langchain-community

----------------------------------------

TITLE: Implementing Chat Model Unit Tests with LangChain.js Standard Tests
DESCRIPTION: Shows how to create a unit test file for chat models using the ChatModelUnitTests class from @langchain/standard-tests. It includes setting up the test class, handling API keys, and running the tests.

LANGUAGE: typescript
CODE:
/* eslint-disable no-process-env */
import { test, expect } from "@jest/globals";
import { ChatModelUnitTests } from "@langchain/standard-tests";
import { AIMessageChunk } from "@langchain/core/messages";
import { MyChatModel, MyChatModelCallOptions } from "../chat_models.js";

class MyChatModelStandardUnitTests extends ChatModelUnitTests<
  MyChatModelCallOptions,
  AIMessageChunk
> {
  constructor() {
    super({
      Cls: MyChatModel,
      chatModelHasToolCalling: true, // Set to true if the model has tool calling support
      chatModelHasStructuredOutput: true, // Set to true if the model has withStructuredOutput support
      constructorArgs: {}, // Any additional constructor args
    });
    // This must be set so method like `.bindTools` or `.withStructuredOutput`
    // which we call after instantiating the model will work. 
    // (constructor will throw if API key is not set)
    process.env.CHAT_MODEL_API_KEY = "test";
  }

  testChatModelInitApiKey() {
    // Unset the API key env var here so this test can properly check
    // the API key class arg.
    process.env.CHAT_MODEL_API_KEY = "";
    super.testChatModelInitApiKey();
    // Re-set the API key env var here so other tests can run properly.
    process.env.CHAT_MODEL_API_KEY = "test";
  }
}

const testClass = new MyChatModelStandardUnitTests();

test("MyChatModelStandardUnitTests", () => {
  const testResults = testClass.runTests();
  expect(testResults).toBe(true);
});

----------------------------------------

TITLE: Installing LangChain Cloudflare Integration Packages
DESCRIPTION: This command installs the necessary LangChain packages for Cloudflare integration.

LANGUAGE: bash
CODE:
npm install @langchain/cloudflare @langchain/core

----------------------------------------

TITLE: Linting and Formatting @langchain/xai Code
DESCRIPTION: Command to run the linter and formatter to ensure code quality standards for the @langchain/xai package.

LANGUAGE: bash
CODE:
yarn lint && yarn format

----------------------------------------

TITLE: Setting Google API Key Environment Variable
DESCRIPTION: Bash command to set the GOOGLE_API_KEY environment variable for authentication.

LANGUAGE: bash
CODE:
export GOOGLE_API_KEY=your-api-key

----------------------------------------

TITLE: Listing Supported SQL Dialects
DESCRIPTION: This code snippet shows how to list the SQL dialects supported by the LangChain SQL database integration.

LANGUAGE: typescript
CODE:
<CodeBlock language="typescript">{DialectExample}</CodeBlock>

----------------------------------------

TITLE: Installing LangChain Dependencies for Connery
DESCRIPTION: Command to install the required peer dependencies @langchain/community and @langchain/core for using Connery Action Tool with LangChain.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core

----------------------------------------

TITLE: Installing Dependencies for Firestore Chat Memory in LangChain.js
DESCRIPTION: Commands to install required packages for implementing Firestore chat memory in a LangChain.js project.

LANGUAGE: bash
CODE:
npm install firebase-admin

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/community @langchain/core

----------------------------------------

TITLE: Custom VectorStore Retriever Implementation
DESCRIPTION: Demonstrates how to use custom vector store retrievers for alternative retrieval methods like maximal marginal relevance.

LANGUAGE: typescript
CODE:
{ExampleSimilarityCustomRetriever}

----------------------------------------

TITLE: Configuring Google API Key for GenAI
DESCRIPTION: Sets the Google API key as an environment variable for use with GenAI.

LANGUAGE: bash
CODE:
export GOOGLE_API_KEY=your-api-key

----------------------------------------

TITLE: Demonstrating Good Output for JSON Parsing in TypeScript
DESCRIPTION: This snippet shows an example of a well-formed AIMessage output that can be successfully parsed as JSON. The content is properly enclosed in markdown code tags and contains valid JSON.

LANGUAGE: typescript
CODE:
AIMessage {
  content: "```\n{\"foo\": \"bar\"}\n```"
}

----------------------------------------

TITLE: Installing LangChain Dependencies
DESCRIPTION: Command to install core LangChain packages including OpenAI integration, community modules, and core functionality.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/community @langchain/core

----------------------------------------

TITLE: Enabling verbose logging on a LangChain agent
DESCRIPTION: Example showing how to enable detailed console logging by setting verbose flag on agent executor

LANGUAGE: typescript
CODE:
const agent = await createOpenAIToolsAgent({
  llm,
  tools,
  prompt: prompt,
});

const agentExecutor = new AgentExecutor({
  agent,
  tools,
  verbose: true
});

----------------------------------------

TITLE: Implementing Google Calendar Tool in TypeScript
DESCRIPTION: Example code for using the Google Calendar Tool in a TypeScript project. The actual code is not provided in the snippet, but it's referenced as an imported example.

LANGUAGE: typescript
CODE:
{ToolExample}

----------------------------------------

TITLE: Initializing LocalFileCache in TypeScript
DESCRIPTION: This TypeScript snippet demonstrates how to create a LocalFileCache instance for file system-based caching in LangChain.js. This cache is intended for local development only.

LANGUAGE: typescript
CODE:
const cache = await LocalFileCache.create();

----------------------------------------

TITLE: Importing OpenAIEmbeddings in TypeScript
DESCRIPTION: This code snippet demonstrates how to import the OpenAIEmbeddings class from the @langchain/openai package. It is used for text embedding functionality in LangChain.js applications using OpenAI's models.

LANGUAGE: typescript
CODE:
import { OpenAIEmbeddings } from "@langchain/openai";

----------------------------------------

TITLE: Defining Convex Schema - TypeScript
DESCRIPTION: Schema configuration for vector indexing in Convex, defining document structure with embedding, text, and metadata fields.

LANGUAGE: typescript
CODE:
import { defineSchema, defineTable } from "convex/server";
import { v } from "convex/values";

export default defineSchema({
  documents: defineTable({
    embedding: v.array(v.number()),
    text: v.string(),
    metadata: v.any(),
  }).vectorIndex("byEmbedding", {
    vectorField: "embedding",
    dimensions: 1536,
  }),
});

----------------------------------------

TITLE: Package Resolution Configuration - Yarn
DESCRIPTION: Package.json configuration to ensure consistent @langchain/core version with yarn.

LANGUAGE: json
CODE:
{
  "name": "your-project",
  "version": "0.0.0",
  "private": true,
  "engines": {
    "node": ">=18"
  },
  "dependencies": {
    "@langchain/anthropic": "^0.0.2",
    "@langchain/core": "^0.3.0",
    "langchain": "0.0.207"
  },
  "resolutions": {
    "@langchain/core": "0.3.0"
  }
}

----------------------------------------

TITLE: Installing LangChain.js Dependencies
DESCRIPTION: This snippet shows how to install the necessary dependencies for using LangChain.js with OpenAI and community packages.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/community @langchain/core

----------------------------------------

TITLE: Installing LangChain Dependencies
DESCRIPTION: Command to install required LangChain packages including OpenAI, community modules, and core functionality.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/community @langchain/core

----------------------------------------

TITLE: Semantic Similarity Routing Implementation
DESCRIPTION: Example demonstrating how to route queries based on semantic similarity using embeddings in LangChain.

LANGUAGE: typescript
CODE:
SemanticSimilarityExample

----------------------------------------

TITLE: Example Selection with Metadata Filtering
DESCRIPTION: Shows how to use metadata filtering when selecting examples, allowing for more precise control over the search space.

LANGUAGE: typescript
CODE:
{ExampleSimilarityMetadataFiltering}

----------------------------------------

TITLE: Installing Migration Script with NPM/Yarn
DESCRIPTION: Command to install the LangChain migration script package required for v0.2.x migration.

LANGUAGE: bash
CODE:
npm i @langchain/scripts@0.0.14-rc.1

----------------------------------------

TITLE: Installing Rockset Client Dependencies
DESCRIPTION: Command to install the official Rockset client library as a project dependency.

LANGUAGE: bash
CODE:
yarn add @rockset/client

----------------------------------------

TITLE: Client-Side Page Implementation
DESCRIPTION: React component setup for handling agent responses and streaming data

LANGUAGE: typescript
CODE:
"use client";

import { useState } from "react";
import { readStreamableValue } from "ai/rsc";
import { runAgent } from "./action";

export default function Page() {
  const [input, setInput] = useState("");
  const [data, setData] = useState<StreamEvent[]>([]);

  async function handleSubmit(e: React.FormEvent) {
    e.preventDefault();

    const { streamData } = await runAgent(input);
    for await (const item of readStreamableValue(streamData)) {
      setData((prev) => [...prev, item]);
    }
  }
}

----------------------------------------

TITLE: Standalone JigsawStack Tools Usage
DESCRIPTION: Example demonstrating the standalone usage of various JigsawStack tools including AI scraping, searching, OCR, speech-to-text, and text-to-SQL functionality

LANGUAGE: javascript
CODE:
import {
  JigsawStackAIScrape,
  JigsawStackAISearch,
  JigsawStackSpeechToText,
  JigsawStackVOCR,
  JigsawStackTextToSQL,
} from "@langchain/jigsawstack";

export const run = async () => {
  // AI Scrape Tool
  const aiScrapeTool = new JigsawStackAIScrape({
    params: {
      element_prompts: ["Pro plan"],
    },
  });
  const result = await aiScrapeTool.invoke("https://jigsawstack.com/pricing");

  console.log({ result });

  // AI Search Tool

  const aiSearchTool = new JigsawStackAISearch();
  const doc = await aiSearchTool.invoke("The leaning tower of pisa");
  console.log({ doc });

  // VOCR Tool

  const vocrTool = new JigsawStackVOCR({
    params: {
      prompt: "Describe the image in detail",
    },
  });
  const data = await vocrTool.invoke(
    "https://rogilvkqloanxtvjfrkm.supabase.co/storage/v1/object/public/demo/Collabo%201080x842.jpg?t=2024-03-22T09%3A22%3A48.442Z"
  );

  console.log({ data });

  // Speech-to-Text Tool
  const sttTool = new JigsawStackSpeechToText();
  await sttTool.invoke(
    "https://rogilvkqloanxtvjfrkm.supabase.co/storage/v1/object/public/demo/Video%201737458382653833217.mp4?t=2024-03-22T09%3A50%3A49.894"
  );

  // Text-to-SQL Tool
  const sqlTool = new JigsawStackTextToSQL({
    params: {
      sql_schema:
        "CREATE TABLE Transactions (transaction_id INT PRIMARY KEY, user_id INT NOT NULL,total_amount DECIMAL(10, 2 NOT NULL, transaction_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,status VARCHAR(20) DEFAULT 'pending',FOREIGN KEY(user_id) REFERENCES Users(user_id))",
    },
  });

  await sqlTool.invoke(
    "Generate a query to get transactions that amount exceed 10000 and sort by when created"
  );
};

----------------------------------------

TITLE: Embedding a Query with LangChain in JavaScript
DESCRIPTION: This code snippet demonstrates how to use the embeddings object to create a vector representation of a text query. It uses the embedQuery method to process the input string "Hello, world!".

LANGUAGE: javascript
CODE:
await embeddings.embedQuery("Hello, world!");

----------------------------------------

TITLE: Running Environment Tests with Docker
DESCRIPTION: Command to run environment tests using Docker from the project root.

LANGUAGE: bash
CODE:
yarn test:exports:docker

----------------------------------------

TITLE: Azure Dynamic Sessions with OpenAI Chat Integration
DESCRIPTION: Advanced example showing integration between Azure OpenAI chat model and Python code interpreter session tool.

LANGUAGE: typescript
CODE:
<AgentExample>

----------------------------------------

TITLE: Installing USearch and LangChain Dependencies
DESCRIPTION: This snippet shows how to install the required packages for using USearch with LangChain.js. It includes the USearch library and necessary LangChain modules.

LANGUAGE: bash
CODE:
npm install -S usearch

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/community @langchain/core

----------------------------------------

TITLE: Setting Environment Variables for Gradient AI API
DESCRIPTION: This snippet demonstrates how to set the required environment variables for using the Gradient AI API. It includes the access token and workspace ID.

LANGUAGE: bash
CODE:
export GRADIENT_ACCESS_TOKEN=<YOUR_ACCESS_TOKEN>
export GRADIENT_WORKSPACE_ID=<YOUR_WORKSPACE_ID>

----------------------------------------

TITLE: Creating a Configurable Model with initChatModel() in LangChain.js
DESCRIPTION: Demonstrates how to create a runtime-configurable model using initChatModel(). It shows how to specify configurable fields and use the resulting model.

LANGUAGE: typescript
CODE:
import { initChatModel } from "langchain/chat_models/universal";

const configurableModel = await initChatModel({
  configurableFields: ["temperature", "maxTokens"],
});

const configuredModel = await configurableModel.withConfig({
  modelProvider: "openai",
  model: "gpt-3.5-turbo",
  temperature: 0.5,
  maxTokens: 100,
  openAIApiKey: "<your_api_key>",
});

const result = await configuredModel.invoke("Hello, how are you?");
console.log(result);

----------------------------------------

TITLE: Writer LLM Integration Example
DESCRIPTION: TypeScript example demonstrating Writer LLM integration with LangChain.js, referenced from an external example file.

LANGUAGE: typescript
CODE:
{WriterExample}

----------------------------------------

TITLE: Installing Cassandra Driver and LangChain Dependencies
DESCRIPTION: Command to install the necessary npm packages for using Cassandra with LangChain.js, including the Cassandra driver, LangChain community package, OpenAI integration, and LangChain core.

LANGUAGE: bash
CODE:
npm install cassandra-driver @langchain/community @langchain/openai @langchain/core

----------------------------------------

TITLE: Installing LangChain.js Dependencies for OpenAI Integration
DESCRIPTION: This snippet shows how to install the necessary npm packages for using OpenAI with LangChain.js. It includes both the OpenAI integration and the core LangChain package.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/core

----------------------------------------

TITLE: Loading JSON Data without JSON Pointer
DESCRIPTION: Basic example of loading all strings from a JSON file using JSONLoader without specifying JSON pointers. The loader automatically extracts all string values from the JSON structure.

LANGUAGE: json
CODE:
{
  "texts": ["This is a sentence.", "This is another sentence."]
}

LANGUAGE: typescript
CODE:
import { JSONLoader } from "langchain/document_loaders/fs/json";

const loader = new JSONLoader("src/document_loaders/example_data/example.json");

const docs = await loader.load();

----------------------------------------

TITLE: Initializing IPFS Datastore Chat Memory
DESCRIPTION: Example of initializing an IPFS Datastore chat message history using the file system implementation. Shows how to create a new instance with a specific datastore and session ID.

LANGUAGE: typescript
CODE:
// Replace FsDatastore with the IPFS Datastore of your choice.
import { FsDatastore } from "datastore-fs";
import { IPFSDatastoreChatMessageHistory } from "@langchain/community/stores/message/ipfs_datastore";

const datastore = new FsDatastore("path/to/store");
const sessionId = "my-session";

const history = new IPFSDatastoreChatMessageHistory({ datastore, sessionId });

----------------------------------------

TITLE: Installing Project Dependencies
DESCRIPTION: Command to install project dependencies using Yarn package manager.

LANGUAGE: bash
CODE:
yarn

----------------------------------------

TITLE: Configuring Azure Managed Identity Authentication
DESCRIPTION: Example showing how to configure Azure Cosmos DB with Managed Identity authentication instead of connection strings

LANGUAGE: typescript
CODE:
import { AzureCosmosDBVectorStore } from "@langchain/azure-cosmosdb";
import { DefaultAzureCredential } from "@azure/identity";

const vectorStore = new AzureCosmosDBVectorStore({
  credentials: new DefaultAzureCredential(),
  endpoint: process.env.AZURE_COSMOSDB_ENDPOINT,
  databaseName: process.env.AZURE_COSMOSDB_DATABASE_NAME,
  containerName: process.env.AZURE_COSMOSDB_CONTAINER_NAME,
});

----------------------------------------

TITLE: Running Formatter
DESCRIPTION: Commands to run the Prettier formatter on the project and check for formatting differences.

LANGUAGE: bash
CODE:
yarn format

LANGUAGE: bash
CODE:
yarn format:check

----------------------------------------

TITLE: Querying Documents in Cassandra Vector Store
DESCRIPTION: Examples of querying documents in the Cassandra vector store using similarity search. It shows both a basic search and a filtered search based on metadata.

LANGUAGE: typescript
CODE:
const results = await vectorStore.similaritySearch("Green yellow purple", 1);

LANGUAGE: typescript
CODE:
const results = await vectorStore.similaritySearch("B", 1, { name: "Bubba" });

----------------------------------------

TITLE: Implementing Token-Based Rate Limiting with OpenAI LLM
DESCRIPTION: Demonstrates how to implement token-based rate limiting in a LangChain project using OpenAI LLM and UpstashRatelimitHandler.

LANGUAGE: typescript
CODE:
const UPSTASH_REDIS_REST_URL = "****";
const UPSTASH_REDIS_REST_TOKEN = "****";
const OPENAI_API_KEY = "****";

import {
  UpstashRatelimitHandler,
  UpstashRatelimitError,
} from "@langchain/community/callbacks/handlers/upstash_ratelimit";
import { RunnableLambda, RunnableSequence } from "@langchain/core/runnables";
import { OpenAI } from "@langchain/openai";
import { Ratelimit } from "@upstash/ratelimit";
import { Redis } from "@upstash/redis";

// create ratelimit
const ratelimit = new Ratelimit({
  redis: new Redis({
    url: UPSTASH_REDIS_REST_URL,
    token: UPSTASH_REDIS_REST_TOKEN,
  }),
  // 500 tokens per window, where window size is 60 seconds:
  limiter: Ratelimit.fixedWindow(500, "60 s"),
});

// create handler
const user_id = "user_id"; // should be a method which gets the user id
const handler = new UpstashRatelimitHandler(user_id, {
  tokenRatelimit: ratelimit,
});

// create mock chain
const asStr = new RunnableLambda({ func: (str: string): string => str });
const model = new OpenAI({
  apiKey: OPENAI_API_KEY,
});
const chain = RunnableSequence.from([asStr, model]);

// invoke chain with handler:
try {
  const response = await chain.invoke("hello world", {
    callbacks: [handler],
  });
  console.log(response);
} catch (err) {
  if (err instanceof UpstashRatelimitError) {
    console.log("Handling ratelimit.");
  }
}

----------------------------------------

TITLE: Loading PPTX File Content with PPTXLoader in TypeScript
DESCRIPTION: This code demonstrates how to use the PPTXLoader to load content from a PPTX file. It creates an instance of PPTXLoader with the file path and then calls the load() method to extract the content, creating one document per page.

LANGUAGE: typescript
CODE:
import { PPTXLoader } from "@langchain/community/document_loaders/fs/pptx";

const loader = new PPTXLoader("src/document_loaders/example_data/example.pptx");

const docs = await loader.load();

----------------------------------------

TITLE: Configuring Environment Variables for Astra DB and OpenAI
DESCRIPTION: Sets up necessary environment variables for Astra DB connection and OpenAI API key. These variables are required for authenticating and connecting to the Astra DB service and OpenAI API.

LANGUAGE: bash
CODE:
export ASTRA_DB_APPLICATION_TOKEN=YOUR_ASTRA_DB_APPLICATION_TOKEN_HERE
export ASTRA_DB_ENDPOINT=YOUR_ASTRA_DB_ENDPOINT_HERE
export ASTRA_DB_COLLECTION=YOUR_ASTRA_DB_COLLECTION_HERE
export OPENAI_API_KEY=YOUR_OPENAI_API_KEY_HERE

----------------------------------------

TITLE: Importing People Component in JSX
DESCRIPTION: Import statement for the custom People component used to display contributor information

LANGUAGE: jsx
CODE:
import People from "@theme/People";

----------------------------------------

TITLE: Embedding Multiple Documents
DESCRIPTION: Demonstrates how to generate embeddings for multiple documents using the embedDocuments method with automatic batching.

LANGUAGE: typescript
CODE:
const documents = ["Baking bread is fun", "I love baking"];

const embeddingsArray = await embeddings.embedDocuments(documents);
console.log(embeddingsArray);

----------------------------------------

TITLE: Installing LangChain Dependencies
DESCRIPTION: Command to install required LangChain packages including OpenAI, community modules, and core functionality.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/community @langchain/core

----------------------------------------

TITLE: Using ChatXAI Model in TypeScript
DESCRIPTION: Example of how to use the ChatXAI model to generate responses. It demonstrates importing necessary classes, initializing the model, and invoking it with a human message.

LANGUAGE: typescript
CODE:
import { ChatXAI } from "@langchain/xai";
import { HumanMessage } from "@langchain/core/messages";

const model = new ChatXAI({
  apiKey: process.env.XAI_API_KEY, // Default value.
});

const message = new HumanMessage("What color is the sky?");

const res = await model.invoke([message]);

----------------------------------------

TITLE: Changing Directory to LangChain Workspace
DESCRIPTION: Command to change the current directory to the LangChain workspace for development tasks.

LANGUAGE: bash
CODE:
cd langchain

----------------------------------------

TITLE: Installing node-postgres for AnalyticDB Connection
DESCRIPTION: This command installs the node-postgres package, which is required for establishing a connection pool to AnalyticDB vectorstore.

LANGUAGE: bash
CODE:
npm install -S pg

----------------------------------------

TITLE: Running Linter
DESCRIPTION: Command to run the ESLint linter on the project.

LANGUAGE: bash
CODE:
yarn lint

----------------------------------------

TITLE: Defining Couchbase Search Index in JSON
DESCRIPTION: JSON configuration for creating a Couchbase search index with vector field support, including mapping for embedding, text, and metadata fields.

LANGUAGE: json
CODE:
{
  "name": "vector-index",
  "type": "fulltext-index",
  "params": {
    "doc_config": {
      "docid_prefix_delim": "",
      "docid_regexp": "",
      "mode": "type_field",
      "type_field": "type"
    },
    "mapping": {
      "default_analyzer": "standard",
      "default_datetime_parser": "dateTimeOptional",
      "default_field": "_all",
      "default_mapping": {
        "dynamic": true,
        "enabled": true,
        "properties": {
          "metadata": {
            "dynamic": true,
            "enabled": true
          },
          "embedding": {
            "enabled": true,
            "dynamic": false,
            "fields": [
              {
                "dims": 1536,
                "index": true,
                "name": "embedding",
                "similarity": "dot_product",
                "type": "vector",
                "vector_index_optimized_for": "recall"
              }
            ]
          },
          "text": {
            "enabled": true,
            "dynamic": false,
            "fields": [
              {
                "index": true,
                "name": "text",
                "store": true,
                "type": "text"
              }
            ]
          }
        }
      },
      "default_type": "_default",
      "docvalues_dynamic": false,
      "index_dynamic": true,
      "store_dynamic": true,
      "type_field": "_type"
    },
    "store": {
      "indexType": "scorch",
      "segmentVersion": 16
    }
  },
  "sourceType": "gocbcore",
  "sourceName": "testing",
  "sourceParams": {},
  "planParams": {
    "maxPartitionsPerPIndex": 103,
    "indexPartitions": 10,
    "numReplicas": 0
  }
}

----------------------------------------

TITLE: Installing Custom PDF.js Build
DESCRIPTION: Install the pdfjs-dist package for using a custom PDF.js build

LANGUAGE: bash
CODE:
npm install pdfjs-dist

----------------------------------------

TITLE: Updating GitHub Actions Workflow for Integration Testing
DESCRIPTION: YAML snippet showing how to update the GitHub Actions workflow to include a new integration package for testing.

LANGUAGE: yaml
CODE:
prepare-matrix:
  needs: get-changed-files
  runs-on: ubuntu-latest
  env:
    PACKAGES: "anthropic,azure-openai,cloudflare,<your-package>"
    ...

----------------------------------------

TITLE: Loading YouTube Transcripts with LangChain in TypeScript
DESCRIPTION: This code snippet demonstrates how to use the YouTubeLoader from LangChain to load transcripts from a YouTube video. It shows how to specify the video URL, language, and whether to include video information.

LANGUAGE: typescript
CODE:
import CodeBlock from "@theme/CodeBlock";
import Example from "@examples/document_loaders/youtube.ts";

<CodeBlock language="typescript">{Example}</CodeBlock>

----------------------------------------

TITLE: Installing Required Dependencies
DESCRIPTION: Commands to install the necessary npm packages for using Typesense with LangChain

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/community @langchain/core

----------------------------------------

TITLE: Handling Callbacks in Serverless Environments
DESCRIPTION: Example of using awaitAllCallbacks to ensure callbacks finish before a serverless function ends. This is necessary due to the new non-blocking callback behavior in v0.3.

LANGUAGE: typescript
CODE:
import { RunnableLambda } from "@langchain/core/runnables";
import { awaitAllCallbacks } from "@langchain/core/callbacks/promises";

const runnable = RunnableLambda.from(() => "hello!");

const customHandler = {
  handleChainEnd: async () => {
    await new Promise((resolve) => setTimeout(resolve, 2000));
    console.log("Call finished");
  },
};

const startTime = new Date().getTime();

await runnable.invoke({ number: "2" }, { callbacks: [customHandler] });

console.log(`Elapsed time: ${new Date().getTime() - startTime}ms`);

await awaitAllCallbacks();

console.log(`Final elapsed time: ${new Date().getTime() - startTime}ms`);

----------------------------------------

TITLE: Loading a Single Column from CSV using CSVLoader in TypeScript
DESCRIPTION: This code shows how to use the CSVLoader to load a single column ('text') from a CSV file. It creates Documents with metadata including the line number and source file, and pageContent containing only the specified column's data.

LANGUAGE: typescript
CODE:
import { CSVLoader } from "@langchain/community/document_loaders/fs/csv";

const loader = new CSVLoader(
  "src/document_loaders/example_data/example.csv",
  "text"
);

const docs = await loader.load();
/*
[Document {
    "metadata": {
      "line": 1,
      "source": "src/document_loaders/example_data/example.csv",
    },
    "pageContent": "This is a sentence.",
  },
  Document {
    "metadata": {
      "line": 2,
      "source": "src/document_loaders/example_data/example.csv",
    },
    "pageContent": "This is another sentence.",
  },
]
*/

----------------------------------------

TITLE: Creating Local SQLite Database
DESCRIPTION: Command to create and connect to a local SQLite database file

LANGUAGE: bash
CODE:
sqlite3 file.db

----------------------------------------

TITLE: Setting GROQ_API_KEY environment variable
DESCRIPTION: This command sets the GROQ_API_KEY environment variable, which is required for authentication with the Groq API.

LANGUAGE: bash
CODE:
export GROQ_API_KEY=

----------------------------------------

TITLE: Configuring Package Dependencies for LangChain.js Standard Tests
DESCRIPTION: Demonstrates how to add @langchain/standard-tests as a dev workspace dependency in the package.json file.

LANGUAGE: json
CODE:
{
  "devDependencies": {
    "@langchain/standard-tests": "workspace:*"
  }
}

----------------------------------------

TITLE: Firestore Security Rules for Chat History
DESCRIPTION: Example of Firestore security rules to protect chat history data, allowing read and write access only to the user who created the data.

LANGUAGE: plaintext
CODE:
      match /chathistory/{sessionId} {
       allow read: if request.auth.uid == resource.data.createdBy;
       allow write: if request.auth.uid == request.resource.data.createdBy;
			 }
			 match /chathistory/{sessionId}/messages/{messageId} {
       allow read: if request.auth.uid == resource.data.createdBy;
       allow write: if request.auth.uid == request.resource.data.createdBy;
		    }

----------------------------------------

TITLE: Adding Documents to Google Vertex AI Matching Engine in LangChain.js
DESCRIPTION: TypeScript code demonstrating how to add documents with metadata to the Matching Engine. The metadata is converted into allow list values for filtering during queries.

LANGUAGE: typescript
CODE:
const documents = [
  new Document({
    pageContent: "this apple",
    metadata: {
      color: "red",
      category: "edible",
    },
  }),
  new Document({
    pageContent: "this blueberry",
    metadata: {
      color: "blue",
      category: "edible",
    },
  }),
  new Document({
    pageContent: "this firetruck",
    metadata: {
      color: "red",
      category: "machine",
    },
  }),
];

// Add all our documents
await engine.addDocuments(documents);

----------------------------------------

TITLE: Retriever End Output Format (v1)
DESCRIPTION: Example of the output format for on_retriever_end event in v1, showing document list wrapped in an additional object.

LANGUAGE: typescript
CODE:
{
  data: {
    output: {
      documents: [
        Document(...),
        Document(...),
        ...
      ]
    }
  }
}

----------------------------------------

TITLE: Installing LangChain Dependencies for SingleStoreDB Integration
DESCRIPTION: Command to install necessary LangChain packages for working with SingleStoreDB and OpenAI embeddings.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/community @langchain/core

----------------------------------------

TITLE: Setting Environment Variables for API Keys
DESCRIPTION: Commands to set up environment variables for OpenAI and Anthropic API credentials.

LANGUAGE: bash
CODE:
export OPENAI_API_KEY="your-openai-api-key"

LANGUAGE: bash
CODE:
export ANTHROPIC_API_KEY="your-anthropic-api-key"

----------------------------------------

TITLE: Importing WolframAlpha Tool Example in TypeScript
DESCRIPTION: Example code demonstrating how to import and use the WolframAlpha tool in a LangChain.js application. Requires a WolframAlpha app ID obtained from the developer portal.

LANGUAGE: typescript
CODE:
import ToolExample from "@examples/tools/wolframalpha.ts";

----------------------------------------

TITLE: Installing Layerup Security SDK via npm
DESCRIPTION: This command installs the Layerup Security SDK using npm. It's a prerequisite for using Layerup Security in your project.

LANGUAGE: bash
CODE:
npm install @layerup/layerup-security

----------------------------------------

TITLE: Installing Dependencies for GitHub Loader in Node.js
DESCRIPTION: This snippet shows how to install the necessary dependencies for using the GitHub loader in a Node.js project.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core ignore

----------------------------------------

TITLE: Linting and Formatting Code
DESCRIPTION: Commands to run the linter and formatter to maintain code standards.

LANGUAGE: bash
CODE:
yarn lint && yarn format

----------------------------------------

TITLE: Installing TypeORM and PostgreSQL driver
DESCRIPTION: Commands to install the required TypeORM and PostgreSQL driver packages using npm or yarn.

LANGUAGE: bash
CODE:
npm install typeorm

LANGUAGE: bash
CODE:
npm install pg

----------------------------------------

TITLE: Installing @langchain/groq and @langchain/core packages
DESCRIPTION: This command installs the necessary packages for using Groq with LangChain.js.

LANGUAGE: bash
CODE:
npm install @langchain/groq @langchain/core

----------------------------------------

TITLE: Testing Commands
DESCRIPTION: Commands for running unit tests and integration tests, which should be placed in the tests/ directory within src/ and follow specific naming conventions.

LANGUAGE: bash
CODE:
yarn test

LANGUAGE: bash
CODE:
yarn test:int

----------------------------------------

TITLE: Installing OpenAI Integration
DESCRIPTION: Command to install OpenAI package for embeddings functionality.

LANGUAGE: bash
CODE:
npm install @langchain/openai

----------------------------------------

TITLE: Using ArxivRetriever to Query arXiv in TypeScript
DESCRIPTION: Demonstrates how to use the ArxivRetriever's invoke method to search for articles and process the results.

LANGUAGE: typescript
CODE:
const query = "quantum computing";

const documents = await retriever.invoke(query);
documents.forEach((doc) => {
  console.log("Title:", doc.metadata.title);
  console.log("Content:", doc.pageContent); // Parsed PDF content
});

----------------------------------------

TITLE: Building LangChain CLI - Bash
DESCRIPTION: Command to build the LangChain.js CLI tool using yarn

LANGUAGE: bash
CODE:
yarn build --filter=@langchain/scripts

----------------------------------------

TITLE: ZepCloudVectorStore with Expression Language
DESCRIPTION: Advanced example demonstrating ZepCloudVectorStore usage with LangChain Expression Language

LANGUAGE: typescript
CODE:
ZepCloudVectorStoreExpressionLanguageExample

----------------------------------------

TITLE: Setting Anthropic API Key
DESCRIPTION: Command to set the Anthropic API key as an environment variable.

LANGUAGE: bash
CODE:
export ANTHROPIC_API_KEY=your-api-key

----------------------------------------

TITLE: Setting xAI API Key Environment Variable
DESCRIPTION: Command to set the XAI_API_KEY environment variable for authentication with xAI services.

LANGUAGE: bash
CODE:
export XAI_API_KEY=

----------------------------------------

TITLE: Installing LangChain.js Dependencies
DESCRIPTION: This snippet shows how to install the necessary LangChain.js dependencies using npm or yarn.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/core

----------------------------------------

TITLE: Importing Component Tables in LangChain.js Documentation
DESCRIPTION: JSX import statement for feature table components used to display toolkit documentation. Imports CategoryTable and IndexTable components from the theme's FeatureTables module.

LANGUAGE: jsx
CODE:
import { CategoryTable, IndexTable } from "@theme/FeatureTables";

----------------------------------------

TITLE: Configuring Astra DB Connection
DESCRIPTION: TypeScript configuration object for connecting to Astra DB, Datastax's cloud-native Cassandra-as-a-Service platform, using authentication token and endpoint

LANGUAGE: typescript
CODE:
const configConnection = {
  serviceProviderArgs: {
    astra: {
      token: <...> as string,
      endpoint: <...> as string,
    },
  },
};

----------------------------------------

TITLE: Building the @langchain/mongodb package
DESCRIPTION: Commands to build the @langchain/mongodb package, including an option to build from the repo root.

LANGUAGE: bash
CODE:
yarn build

LANGUAGE: bash
CODE:
yarn build --filter=@langchain/mongodb

----------------------------------------

TITLE: Streaming with AzureChatOpenAI Model
DESCRIPTION: TypeScript code demonstrating how to use streaming with the AzureChatOpenAI model.

LANGUAGE: typescript
CODE:
import { AzureChatOpenAI } from "@langchain/azure-openai";

const model = new AzureChatOpenAI({
  // Note that the following are optional, and will default to the values below
  // if not provided.
  azureOpenAIEndpoint: process.env.AZURE_OPENAI_API_ENDPOINT,
  azureOpenAIApiKey: process.env.AZURE_OPENAI_API_KEY,
  azureOpenAIApiDeploymentName: process.env.AZURE_OPENAI_API_DEPLOYMENT_NAME,
});
const response = await model.stream(new HumanMessage("Hello world!"));

----------------------------------------

TITLE: Installing Google GenAI Package for LangChain.js
DESCRIPTION: Command to install the Google GenAI package for LangChain.js using npm or yarn.

LANGUAGE: bash
CODE:
npm install @langchain/google-genai @langchain/core

----------------------------------------

TITLE: Importing LangChain in Different Environments
DESCRIPTION: Examples of importing LangChain components in various JavaScript environments

LANGUAGE: typescript
CODE:
import { ChatOpenAI } from "@langchain/openai";

LANGUAGE: typescript
CODE:
const { ChatOpenAI } = require("@langchain/openai");

LANGUAGE: typescript
CODE:
import { ChatOpenAI } from "https://esm.sh/@langchain/openai";

----------------------------------------

TITLE: Setting OpenAI API key in bash
DESCRIPTION: Command to set the OPENAI_API_KEY environment variable.

LANGUAGE: bash
CODE:
export OPENAI_API_KEY=your-api-key

----------------------------------------

TITLE: Docker Compose Configuration for pgvector
DESCRIPTION: Docker compose configuration for setting up a self-hosted PostgreSQL instance with pgvector extension.

LANGUAGE: yaml
CODE:
services:
  db:
    image: ankane/pgvector
    ports:
      - 5432:5432
    volumes:
      - db:/var/lib/postgresql/data
    environment:
      - POSTGRES_PASSWORD=
      - POSTGRES_USER=
      - POSTGRES_DB=

volumes:
  db:

----------------------------------------

TITLE: TypeScript Configuration for ESM Projects
DESCRIPTION: Required TypeScript compiler options for ESM projects using LangChain

LANGUAGE: json
CODE:
{
  "compilerOptions": {
    "target": "ES2020",
    "module": "nodenext"
  }
}

----------------------------------------

TITLE: Installing Additional LangChain Packages
DESCRIPTION: This snippet demonstrates the installation of additional LangChain packages, including OpenAI integration, community tools, and core functionality.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/community @langchain/core

----------------------------------------

TITLE: Configuring Package Resolution in NPM
DESCRIPTION: Package.json configuration for NPM to ensure proper version resolution of @langchain/core

LANGUAGE: json
CODE:
{
  "name": "your-project",
  "version": "0.0.0",
  "private": true,
  "engines": {
    "node": ">=18"
  },
  "dependencies": {
    "@langchain/google-genai": "^0.0.2",
    "@langchain/core": "^0.3.0"
  },
  "overrides": {
    "@langchain/core": "0.3.0"
  }
}

----------------------------------------

TITLE: Configuring Azure OpenAI Environment Variables
DESCRIPTION: Environment variable configuration for Azure OpenAI service integration, including instance name, deployment names, API key and version.

LANGUAGE: bash
CODE:
AZURE_OPENAI_API_INSTANCE_NAME=<YOUR_INSTANCE_NAME>
AZURE_OPENAI_API_DEPLOYMENT_NAME=<YOUR_DEPLOYMENT_NAME>
AZURE_OPENAI_API_EMBEDDINGS_DEPLOYMENT_NAME=<YOUR_EMBEDDINGS_DEPLOYMENT_NAME>
AZURE_OPENAI_API_KEY=<YOUR_KEY>
AZURE_OPENAI_API_VERSION="2024-02-01"

----------------------------------------

TITLE: Importing Azure Dynamic Sessions Tool
DESCRIPTION: TypeScript import statement for Azure Container Apps dynamic sessions REPL tool.

LANGUAGE: typescript
CODE:
import { SessionsPythonREPLTool } from "@langchain/azure-dynamic-sessions";

----------------------------------------

TITLE: Installing LangChain Dependencies
DESCRIPTION: Commands to install the necessary LangChain packages for OpenAI integration and core functionality.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/core

----------------------------------------

TITLE: Building the @langchain/openai package
DESCRIPTION: Commands to build the package, either from the package directory or the repo root.

LANGUAGE: bash
CODE:
yarn build

LANGUAGE: bash
CODE:
yarn build --filter=@langchain/openai

----------------------------------------

TITLE: Installing Dependencies for Cassandra Chat Memory
DESCRIPTION: Command to install required Node.js packages including Cassandra driver and LangChain dependencies

LANGUAGE: bash
CODE:
npm install cassandra-driver @langchain/openai @langchain/community @langchain/core

----------------------------------------

TITLE: Installing @langchain/mongodb and @langchain/core packages
DESCRIPTION: Command to install the @langchain/mongodb and @langchain/core packages using npm or yarn.

LANGUAGE: bash
CODE:
npm install @langchain/mongodb @langchain/core

----------------------------------------

TITLE: Installing Azure Cosmos DB Dependencies
DESCRIPTION: Installation command for Azure Cosmos DB integration packages.

LANGUAGE: bash
CODE:
npm install @langchain/azure-cosmosdb @langchain/core

----------------------------------------

TITLE: Installing @langchain/scripts Package with npm or yarn
DESCRIPTION: This code snippet demonstrates how to install the @langchain/scripts package using either npm or yarn package managers. The npm2yarn comment allows for automatic conversion between npm and yarn commands.

LANGUAGE: bash
CODE:
npm install @langchain/scripts

----------------------------------------

TITLE: Linting and formatting @langchain/ollama code
DESCRIPTION: Command to run the linter and formatter to ensure code quality standards.

LANGUAGE: bash
CODE:
yarn lint && yarn format

----------------------------------------

TITLE: Configuring Package Resolution in Yarn
DESCRIPTION: Package.json configuration for Yarn to ensure proper version resolution of @langchain/core

LANGUAGE: json
CODE:
{
  "name": "your-project",
  "version": "0.0.0",
  "private": true,
  "engines": {
    "node": ">=18"
  },
  "dependencies": {
    "@langchain/google-genai": "^0.0.2",
    "@langchain/core": "^0.3.0"
  },
  "resolutions": {
    "@langchain/core": "0.3.0"
  }
}

----------------------------------------

TITLE: Installing @langchain/openai and @langchain/core
DESCRIPTION: Command to install the required packages using npm or yarn.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/core

----------------------------------------

TITLE: Installing LangChain via Package Managers
DESCRIPTION: Commands for installing LangChain using different package managers (npm, yarn, pnpm)

LANGUAGE: bash
CODE:
npm install -S langchain

LANGUAGE: bash
CODE:
yarn add langchain

LANGUAGE: bash
CODE:
pnpm add langchain

----------------------------------------

TITLE: Chat Model End Output Format - Root Level (v1)
DESCRIPTION: Example of the output format for on_chat_model_end event when the chat model is run as a root level runnable in v1.

LANGUAGE: typescript
CODE:
{
  data: {
    output: AIMessageChunk((content = "hello world!"), (id = "some id"));
  }
}

----------------------------------------

TITLE: Tracking Token Usage with Anthropic using AIMessage.response_metadata
DESCRIPTION: Example of how to track token usage for Anthropic models using the response_metadata field of AIMessage.

LANGUAGE: typescript
CODE:
import AnthropicExample from "@examples/models/chat/token_usage_tracking_anthropic.ts";

<CodeBlock language="typescript">{AnthropicExample}</CodeBlock>

----------------------------------------

TITLE: Running Integration Documentation Generator - Bash
DESCRIPTION: Command to generate integration documentation using the CLI with required parameters for class name and integration type

LANGUAGE: bash
CODE:
yarn create:integration:doc --classname <Class Name> --type <Type>

----------------------------------------

TITLE: Configuring package.json for consistent @langchain/core version
DESCRIPTION: JSON configuration for package.json to ensure consistent @langchain/core version across different package managers. It includes fields for dependencies, resolutions, overrides, and pnpm-specific overrides.

LANGUAGE: json
CODE:
{
  "name": "your-project",
  "version": "0.0.0",
  "dependencies": {
    "@langchain/core": "^0.3.0",
    "@langchain/azure-cosmosdb": "^0.2.5"
  },
  "resolutions": {
    "@langchain/core": "0.3.0"
  },
  "overrides": {
    "@langchain/core": "0.3.0"
  },
  "pnpm": {
    "overrides": {
      "@langchain/core": "0.3.0"
    }
  }
}

----------------------------------------

TITLE: Using ChatYandexGPT for Translation
DESCRIPTION: Example demonstrating how to use ChatYandexGPT class for English to French translation with system and human messages

LANGUAGE: typescript
CODE:
import { ChatYandexGPT } from "@langchain/yandex";
import { HumanMessage, SystemMessage } from "@langchain/core/messages";

const chat = new ChatYandexGPT();
const response = await chat.invoke([
  new SystemMessage(
    "You are a helpful assistant that translates English to French."
  ),
  new HumanMessage("I love programming."),
]);

----------------------------------------

TITLE: Implementing Zapier NLA Agent Integration
DESCRIPTION: TypeScript implementation showing how to initialize and use a Zapier NLA agent with LangChain. The code demonstrates setting up OpenAI model, creating a Zapier wrapper, initializing agent executor, and processing natural language input to interact with Zapier actions.

LANGUAGE: typescript
CODE:
import { OpenAI } from "@langchain/openai";
import { ZapierNLAWrapper } from "langchain/tools";
import {
  initializeAgentExecutorWithOptions,
  ZapierToolKit,
} from "langchain/agents";

const model = new OpenAI({ temperature: 0 });
const zapier = new ZapierNLAWrapper();
const toolkit = await ZapierToolKit.fromZapierNLAWrapper(zapier);

const executor = await initializeAgentExecutorWithOptions(
  toolkit.tools,
  model,
  {
    agentType: "zero-shot-react-description",
    verbose: true,
  }
);
console.log("Loaded agent.");

const input = `Summarize the last email I received regarding Silicon Valley Bank. Send the summary to the #test-zapier Slack channel.`;

console.log(`Executing with input "${input}"...`);

const result = await executor.invoke({ input });

console.log(`Got output ${result.output}`);

----------------------------------------

TITLE: Linting and formatting @langchain/groq code
DESCRIPTION: This command runs the linter and formatter to ensure the code meets the project's standards.

LANGUAGE: bash
CODE:
yarn lint && yarn format

----------------------------------------

TITLE: Initializing MetadataTagger for movie reviews in TypeScript
DESCRIPTION: Example of how to initialize and use the MetadataTagger document transformer for tagging movie reviews with metadata such as title, author, and rating.

LANGUAGE: typescript
CODE:
import CodeBlock from "@theme/CodeBlock";
import Example from "@examples/document_transformers/metadata_tagger.ts";

import IntegrationInstallTooltip from "@mdx_components/integration_install_tooltip.mdx";

<IntegrationInstallTooltip></IntegrationInstallTooltip>

<CodeBlock language="typescript">{Example}</CodeBlock>

----------------------------------------

TITLE: Chat Model End Output Format (v2)
DESCRIPTION: Unified output format for on_chat_model_end event in v2, regardless of whether the model is run as root level or part of a chain.

LANGUAGE: typescript
CODE:
{
  data: {
    output: AIMessageChunk((content = "hello world!"), (id = "some id"));
  }
}

----------------------------------------

TITLE: Using MixedbreadAIReranker in TypeScript
DESCRIPTION: This snippet shows how to use the MixedbreadAIReranker class to rerank a list of documents based on a query. It requires an API key from Mixedbread AI.

LANGUAGE: typescript
CODE:
const reranker = new MixedbreadAIReranker({ apiKey: 'your-api-key' });
const documents = [{ pageContent: "To bake bread you need flour" }, { pageContent: "To bake bread you need yeast" }];
const query = "What do you need to bake bread?";
const result = await reranker.compressDocuments(documents, query);
console.log(result);

----------------------------------------

TITLE: Running tests for @langchain/ollama
DESCRIPTION: Commands to run unit tests and integration tests for the package.

LANGUAGE: bash
CODE:
$ yarn test
$ yarn test:int

----------------------------------------

TITLE: Opening Existing LanceDB Dataset
DESCRIPTION: Example showing how to load and access an existing LanceDB dataset in Typescript.

LANGUAGE: typescript
CODE:
{ExampleLoad}

----------------------------------------

TITLE: Building the @langchain/exa package
DESCRIPTION: Commands to build the @langchain/exa package. Includes options for building directly or from the repository root.

LANGUAGE: bash
CODE:
yarn build

LANGUAGE: bash
CODE:
yarn build --filter=@langchain/exa

----------------------------------------

TITLE: Installing YandexGPT Dependencies
DESCRIPTION: Commands to install the required packages for using YandexGPT with LangChain.js

LANGUAGE: bash
CODE:
npm install @langchain/yandex @langchain/core

----------------------------------------

TITLE: Linting and formatting @langchain/cohere code
DESCRIPTION: Command to run the linter and formatter on the package code.

LANGUAGE: bash
CODE:
yarn lint && yarn format

----------------------------------------

TITLE: Setting Blocking Callbacks Environment Variable
DESCRIPTION: Example of setting an environment variable to make all callbacks blocking, reverting to the pre-v0.3 behavior.

LANGUAGE: typescript
CODE:
process.env.LANGCHAIN_CALLBACKS_BACKGROUND = "false";

const startTimeBlocking = new Date().getTime();

await runnable.invoke({ number: "2" }, { callbacks: [customHandler] });

console.log(
  `Initial elapsed time: ${new Date().getTime() - startTimeBlocking}ms`
);

----------------------------------------

TITLE: Tracking Token Usage with Anthropic using AIMessage.usage_metadata
DESCRIPTION: Example of how to track token usage for Anthropic models using the usage_metadata attribute of AIMessage.

LANGUAGE: typescript
CODE:
import UsageMetadataExampleAnthropic from "@examples/models/chat/usage_metadata_anthropic.ts";

<CodeBlock language="typescript">{UsageMetadataExampleAnthropic}</CodeBlock>

----------------------------------------

TITLE: Installing ClickHouse Dependencies
DESCRIPTION: Command to install the required ClickHouse client and MySQL2 dependencies for Node.js integration.

LANGUAGE: bash
CODE:
npm install -S @clickhouse/client mysql2

----------------------------------------

TITLE: Running Tests for @langchain/xai
DESCRIPTION: Commands to run unit tests and integration tests for the @langchain/xai package.

LANGUAGE: bash
CODE:
$ yarn test
$ yarn test:int

----------------------------------------

TITLE: Installing LangChain Dependencies
DESCRIPTION: Command to install required LangChain packages including OpenAI, community, and core modules using npm.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/community @langchain/core

----------------------------------------

TITLE: Installing Required Dependencies with NPM/Yarn
DESCRIPTION: Installation command for required packages including LangChain, OpenAI, AI SDK, and Zod schema validation.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/core ai zod zod-to-json-schema

----------------------------------------

TITLE: Deploying without SSH
DESCRIPTION: Command to deploy the website using GitHub username authentication.

LANGUAGE: bash
CODE:
$ GIT_USER=<Your GitHub username> yarn deploy

----------------------------------------

TITLE: Configuring Package Dependencies in package.json
DESCRIPTION: JSON configuration to ensure consistent @langchain/core version across different package managers.

LANGUAGE: json
CODE:
{
  "name": "your-project",
  "version": "0.0.0",
  "dependencies": {
    "@langchain/<ADD_PACKAGE_NAME_HERE>": "^0.0.0",
    "@langchain/core": "^0.3.0"
  },
  "resolutions": {
    "@langchain/core": "^0.3.0"
  },
  "overrides": {
    "@langchain/core": "^0.3.0"
  },
  "pnpm": {
    "overrides": {
      "@langchain/core": "^0.3.0"
    }
  }
}

----------------------------------------

TITLE: Linting and Formatting @langchain/nomic Code
DESCRIPTION: Bash command to run the linter and formatter for the @langchain/nomic package code.

LANGUAGE: bash
CODE:
yarn lint && yarn format

----------------------------------------

TITLE: Configuring package.json for dependency resolution
DESCRIPTION: JSON configuration to ensure consistent @langchain/core version across dependencies.

LANGUAGE: json
CODE:
{
  "name": "your-project",
  "version": "0.0.0",
  "dependencies": {
    "@langchain/cohere": "^0.0.1",
    "@langchain/core": "^0.3.0"
  },
  "resolutions": {
    "@langchain/core": "0.3.0"
  },
  "overrides": {
    "@langchain/core": "0.3.0"
  },
  "pnpm": {
    "overrides": {
      "@langchain/core": "0.3.0"
    }
  }
}

----------------------------------------

TITLE: Setting Weaviate Environment Variables
DESCRIPTION: Environment variable configuration for Weaviate connection settings.

LANGUAGE: bash
CODE:
export WEAVIATE_SCHEME=
export WEAVIATE_HOST=
export WEAVIATE_API_KEY=

----------------------------------------

TITLE: Running tests for @langchain/cohere
DESCRIPTION: Commands to run unit tests and integration tests for the package.

LANGUAGE: bash
CODE:
$ yarn test
$ yarn test:int

----------------------------------------

TITLE: Validating Notebooks
DESCRIPTION: Command to validate that notebooks build correctly and compile TypeScript code.

LANGUAGE: bash
CODE:
$ yarn validate <PATH_TO_FILE>

----------------------------------------

TITLE: Deprecating a Community Integration in TypeScript
DESCRIPTION: Demonstrates how to deprecate an existing community integration when migrating to a partner package, using a @deprecated TSDoc comment.

LANGUAGE: typescript
CODE:
/** @deprecated Install and import from `@langchain/parrot-link` instead. */
class ChatParrotLink extends SimpleChatModel {
  ...

----------------------------------------

TITLE: Specifying LangChain and LangChain Community Package Versions
DESCRIPTION: This snippet defines the required versions for the LangChain library and its community extension. Both packages are set to version 0.3.0, ensuring compatibility between the core library and community-contributed features.

LANGUAGE: plaintext
CODE:
langchain==0.3.0
langchain-community==0.3.0

----------------------------------------

TITLE: Running Migration Script in TypeScript
DESCRIPTION: Example code showing how to use the migration script to update import statements in a project. The script helps replace deprecated imports with their new counterparts in the v0.2.x version.

LANGUAGE: typescript
CODE:
import { updateEntrypointsFrom0_x_xTo0_2_x } from "@langchain/scripts/migrations";

const pathToMyProject = "..."; // This path is used in the following glob pattern: `${projectPath}/**/*.{ts,tsx,js,jsx}`.

updateEntrypointsFrom0_x_xTo0_2_x({
  projectPath: pathToMyProject,
  shouldLog: true,
});

----------------------------------------

TITLE: Building the @langchain/qdrant Package
DESCRIPTION: These commands build the @langchain/qdrant package. The first is for building directly within the package directory, while the second is for building from the repository root.

LANGUAGE: bash
CODE:
yarn build

LANGUAGE: bash
CODE:
yarn build --filter=@langchain/qdrant

----------------------------------------

TITLE: Initializing Astra DB Chat History with Existing Client
DESCRIPTION: Demonstrates how to initialize AstraDBChatMessageHistory using an existing AstraDB client instance. Requires application token, endpoint, and namespace configuration.

LANGUAGE: typescript
CODE:
const client = (client = new AstraDB(
  process.env.ASTRA_DB_APPLICATION_TOKEN,
  process.env.ASTRA_DB_ENDPOINT,
  process.env.ASTRA_DB_NAMESPACE
));

const collection = await client.collection("YOUR_COLLECTION_NAME");

const chatHistory = new AstraDBChatMessageHistory({
  collection,
  sessionId: "YOUR_SESSION_ID",
});

----------------------------------------

TITLE: Installing Dependencies for Cloudflare Package Development
DESCRIPTION: Command to install all necessary dependencies for developing the Cloudflare package using yarn.

LANGUAGE: bash
CODE:
yarn install

----------------------------------------

TITLE: Generating Single Query Embedding
DESCRIPTION: Demonstrates how to generate embeddings for a single text query using the embedQuery method

LANGUAGE: typescript
CODE:
const embedding = await embeddings.embedQuery(
  "What would be a good company name for a company that makes colorful socks?"
);
console.log(embedding);

----------------------------------------

TITLE: Starting Next.js Development Server
DESCRIPTION: Commands to start the Next.js development server using different package managers. The server can be started using npm, yarn, or pnpm.

LANGUAGE: bash
CODE:
npm run dev
# or
yarn dev
# or
pnpm dev

----------------------------------------

TITLE: Installing LangChain Dependencies
DESCRIPTION: Command to install required LangChain packages including OpenAI integration, community modules, and core functionality.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/community @langchain/core

----------------------------------------

TITLE: Installing Dependencies for @langchain/nomic Development
DESCRIPTION: Bash command to install dependencies for developing the @langchain/nomic package.

LANGUAGE: bash
CODE:
yarn install

----------------------------------------

TITLE: Configuring Database Accessors - TypeScript
DESCRIPTION: Setup for exporting query and mutation helpers for Convex integration.

LANGUAGE: typescript
CODE:
export * from "@langchain/community/utils/convex";

----------------------------------------

TITLE: Importing OpenAI Module in TypeScript
DESCRIPTION: Example of importing the OpenAI LLM module from the LangChain package.

LANGUAGE: typescript
CODE:
import { OpenAI } from "langchain/llms/openai";

----------------------------------------

TITLE: Code Quality Commands
DESCRIPTION: Commands for running the linter and formatter to maintain code quality standards.

LANGUAGE: bash
CODE:
yarn lint && yarn format

----------------------------------------

TITLE: Initializing and Using Chat Model in TypeScript
DESCRIPTION: TypeScript code to initialize and use the chat model class provided by the integration package.

LANGUAGE: typescript
CODE:
import { <ADD_CLASS_NAME_HERE> } from "@langchain/<ADD_PACKAGE_NAME_HERE>";

const model = new ExampleChatClass({
  apiKey: process.env.EXAMPLE_API_KEY,
});
const response = await model.invoke(new HumanMessage("Hello world!"));

----------------------------------------

TITLE: Configuring YAML Frontmatter
DESCRIPTION: YAML configuration block defining various data types including floats, integers, booleans, strings, arrays, and dictionaries. Demonstrates common YAML syntax patterns and data structures.

LANGUAGE: yaml
CODE:
aFloat: 13.12345
anInt: 15
aBool: true
aString: string value
anArray:
  - one
  - two
  - three
aDict:
  dictId1: "58417"
  dictId2: 1500
tags: ["onetag", "twotag"]

----------------------------------------

TITLE: Importing Azure AI Search Vector Store
DESCRIPTION: TypeScript import statement for Azure AI Search vector store integration.

LANGUAGE: typescript
CODE:
import { AzureAISearchVectorStore } from "@langchain/community/vectorstores/azure_aisearch";

----------------------------------------

TITLE: Memory Types Migration Table
DESCRIPTION: Table listing different memory implementation types and their corresponding migration guides in LangChain.

LANGUAGE: markdown
CODE:
| Memory Type                       | How to Migrate                                               | Description                                                                                                                                                                                                         |
| --------------------------------- | :----------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `ConversationTokenBufferMemory`   | [Link to Migration Guide](conversation_buffer_window_memory) | Keeps only the most recent messages in the conversation under the constraint that the total number of tokens in the conversation does not exceed a certain limit.                                                   |
| `ConversationSummaryMemory`       | [Link to Migration Guide](conversation_summary_memory)       | Continually summarizes the conversation history. The summary is updated after each conversation turn. The abstraction returns the summary of the conversation history.                                              |
| `ConversationSummaryBufferMemory` | [Link to Migration Guide](conversation_summary_memory)       | Provides a running summary of the conversation together with the most recent messages in the conversation under the constraint that the total number of tokens in the conversation does not exceed a certain limit. |

----------------------------------------

TITLE: Installing development dependencies
DESCRIPTION: Command to install development dependencies using yarn.

LANGUAGE: bash
CODE:
yarn install

----------------------------------------

TITLE: Installing Required Dependencies
DESCRIPTION: Commands to install the necessary npm packages for Azure Cosmos DB integration with LangChain

LANGUAGE: bash
CODE:
npm install @langchain/azure-cosmosdb @langchain/core

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/community @langchain/core

----------------------------------------

TITLE: Installing LanceDB Dependencies
DESCRIPTION: Commands to install the required LanceDB package and LangChain dependencies for Node.js integration.

LANGUAGE: bash
CODE:
npm install -S @lancedb/lancedb

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/community @langchain/core

----------------------------------------

TITLE: Installing @langchain/openai with Yarn
DESCRIPTION: Command to install the @langchain/openai package, which is a provider-specific package that can be used with @langchain/core.

LANGUAGE: bash
CODE:
$ yarn add @langchain/openai

----------------------------------------

TITLE: Installing AWS S3 SDK
DESCRIPTION: NPM command to install the AWS S3 client SDK dependency.

LANGUAGE: bash
CODE:
npm install @aws-sdk/client-s3

----------------------------------------

TITLE: Linting and formatting @langchain/mongodb code
DESCRIPTION: Command to run the linter and formatter to ensure code quality standards for the @langchain/mongodb package.

LANGUAGE: bash
CODE:
yarn lint && yarn format

----------------------------------------

TITLE: Initializing ChatBedrockConverse Model
DESCRIPTION: TypeScript code to initialize and use the ChatBedrockConverse model for invoking a chat completion.

LANGUAGE: typescript
CODE:
import { ChatBedrockConverse } from "@langchain/aws";

const model = new ChatBedrockConverse({
  region: process.env.BEDROCK_AWS_REGION ?? "us-east-1",
  credentials: {
    secretAccessKey: process.env.BEDROCK_AWS_SECRET_ACCESS_KEY,
    accessKeyId: process.env.BEDROCK_AWS_ACCESS_KEY_ID,
  },
});

const response = await model.invoke(new HumanMessage("Hello world!"));

----------------------------------------

TITLE: Building @langchain/nomic Package
DESCRIPTION: Bash commands to build the @langchain/nomic package, including an option to build from the repo root.

LANGUAGE: bash
CODE:
yarn build

LANGUAGE: bash
CODE:
yarn build --filter=@langchain/nomic

----------------------------------------

TITLE: Installing LangChain Integration Package
DESCRIPTION: Command to install the LangChain integration package and its core dependency using npm or yarn.

LANGUAGE: bash
CODE:
npm install @langchain/<ADD_PACKAGE_NAME_HERE> @langchain/core

----------------------------------------

TITLE: Installing @langchain/azure-cosmosdb and @langchain/core packages
DESCRIPTION: Command to install the required packages for using Azure CosmosDB vector store integrations with LangChain.js. It installs both @langchain/azure-cosmosdb and @langchain/core.

LANGUAGE: bash
CODE:
npm install @langchain/azure-cosmosdb @langchain/core

----------------------------------------

TITLE: Instantiating MixedbreadAIReranker in TypeScript
DESCRIPTION: Create an instance of the MixedbreadAIReranker class with an API key. This instance will be used to make requests to the Mixedbread AI reranking API.

LANGUAGE: typescript
CODE:
const reranker = new MixedbreadAIReranker({ apiKey: "your-api-key" });

----------------------------------------

TITLE: Running Create LangChain Integration Command
DESCRIPTION: Command to create a new LangChain integration package using the provided utility.

LANGUAGE: bash
CODE:
$ npx create-langchain-integration

----------------------------------------

TITLE: Development Commands for LangChain Integration Package
DESCRIPTION: Bash commands for installing dependencies, building the package, running tests, and linting/formatting the code during development.

LANGUAGE: bash
CODE:
yarn install
yarn build
yarn build --filter=@langchain/<ADD_PACKAGE_NAME_HERE>
yarn test
yarn test:int
yarn lint && yarn format

----------------------------------------

TITLE: Loading Documents Using Blocking Method
DESCRIPTION: Fetching documents using the blocking load() method

LANGUAGE: typescript
CODE:
docs = await loader.load();
console.log(docs);

----------------------------------------

TITLE: Running tests for @langchain/exa
DESCRIPTION: Commands to run unit tests and integration tests for the @langchain/exa package. Unit tests end with .test.ts and integration tests end with .int.test.ts.

LANGUAGE: bash
CODE:
$ yarn test
$ yarn test:int

----------------------------------------

TITLE: Installing OpenAI Integration Dependencies
DESCRIPTION: Additional installation commands for OpenAI integration with LangChain

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/community @langchain/core

----------------------------------------

TITLE: Importing OpenAI from LangChain
DESCRIPTION: TypeScript import statement for the OpenAI LLM class from the LangChain library.

LANGUAGE: typescript
CODE:
import { OpenAI } from "langchain/llms/openai";

----------------------------------------

TITLE: Running Create LangChain Integration Command
DESCRIPTION: Command to create a new LangChain integration package using the provided utility.

LANGUAGE: bash
CODE:
$ npx create-langchain-integration

----------------------------------------

TITLE: Streaming with ChatCohere in TypeScript
DESCRIPTION: Example of using the stream method with ChatCohere for streaming responses.

LANGUAGE: typescript
CODE:
import { HumanMessage } from "@langchain/core/messages";
import { ChatCohere } from "@langchain/cohere";

const model = new ChatCohere({
  apiKey: process.env.COHERE_API_KEY,
});
const response = await model.stream([new HumanMessage("Hello world!")]);

----------------------------------------

TITLE: Importing SageMaker Endpoint
DESCRIPTION: Import statement for the AWS SageMaker endpoint integration for hosting ML models.

LANGUAGE: typescript
CODE:
import {
  SagemakerEndpoint,
  SageMakerLLMContentHandler,
} from "@langchain/community/llms/sagemaker_endpoint";

----------------------------------------

TITLE: Configuring package.json for consistent @langchain/core version
DESCRIPTION: JSON configuration to ensure consistent @langchain/core version across dependencies, including fields for different package managers.

LANGUAGE: json
CODE:
{
  "name": "your-project",
  "version": "0.0.0",
  "dependencies": {
    "@langchain/core": "^0.3.0",
    "@langchain/mongodb": "^0.0.0"
  },
  "resolutions": {
    "@langchain/core": "^0.3.0"
  },
  "overrides": {
    "@langchain/core": "^0.3.0"
  },
  "pnpm": {
    "overrides": {
      "@langchain/core": "^0.3.0"
    }
  }
}

----------------------------------------

TITLE: Importing Bedrock LLM
DESCRIPTION: Import statement for the AWS Bedrock LLM integration.

LANGUAGE: typescript
CODE:
import { Bedrock } from "@langchain/community/llms/bedrock";

----------------------------------------

TITLE: Running TypeScript Examples
DESCRIPTION: Command for running TypeScript examples from the examples directory using the source files.

LANGUAGE: sh
CODE:
yarn run start ./src/prompts/few_shot.ts

----------------------------------------

TITLE: Installing dependencies for @langchain/cohere development
DESCRIPTION: Command to install development dependencies using yarn.

LANGUAGE: bash
CODE:
yarn install

----------------------------------------

TITLE: Running Integration Tests
DESCRIPTION: Command to run all integration tests in the project.

LANGUAGE: bash
CODE:
yarn test:integration

----------------------------------------

TITLE: Configuring Package Dependencies in package.json
DESCRIPTION: JSON configuration to ensure consistent @langchain/core version across different package managers.

LANGUAGE: json
CODE:
{
  "name": "your-project",
  "version": "0.0.0",
  "dependencies": {
    "@langchain/core": "^0.3.0",
    "@langchain/google-genai": "^0.0.0"
  },
  "resolutions": {
    "@langchain/core": "^0.3.0"
  },
  "overrides": {
    "@langchain/core": "^0.3.0"
  },
  "pnpm": {
    "overrides": {
      "@langchain/core": "^0.3.0"
    }
  }
}

----------------------------------------

TITLE: Installing Required Dependencies for LangChain.js
DESCRIPTION: Commands to install the necessary npm packages for using LangChain with OpenAI and related functionality.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/community @langchain/core

----------------------------------------

TITLE: Creating CouchbaseVectorStore Instance in TypeScript
DESCRIPTION: TypeScript code to initialize a CouchbaseVectorStore instance using the provided embeddings and configuration.

LANGUAGE: typescript
CODE:
const store = await CouchbaseVectorStore.initialize(
  embeddings, // embeddings object to create embeddings from text
  couchbaseConfig
);

----------------------------------------

TITLE: Using Baidu Qianfan Embeddings
DESCRIPTION: Example of using BaiduQianfanEmbeddings class to generate embeddings for text

LANGUAGE: typescript
CODE:
import { BaiduQianfanEmbeddings } from "@langchain/baidu-qianfan";

const embeddings = new BaiduQianfanEmbeddings();
const res = await embeddings.embedQuery("Introduce the city Beijing");

----------------------------------------

TITLE: Importing DynamoDB Chat Message History
DESCRIPTION: Import statement for the AWS DynamoDB chat message history integration.

LANGUAGE: typescript
CODE:
import { DynamoDBChatMessageHistory } from "@langchain/community/stores/message/dynamodb";

----------------------------------------

TITLE: Generating Single Query Embedding
DESCRIPTION: Example of generating an embedding for a single text query using the embedQuery method.

LANGUAGE: typescript
CODE:
const embedding = await embeddings.embedQuery(
  "Represent this sentence for searching relevant passages: Is baking fun?"
);
console.log(embedding);

----------------------------------------

TITLE: Configuring Package Dependencies
DESCRIPTION: Package.json configuration to ensure consistent @langchain/core version across different package managers.

LANGUAGE: json
CODE:
{
  "name": "your-project",
  "version": "0.0.0",
  "dependencies": {
    "@langchain/core": "^0.3.0",
    "@langchain/mistralai": "^0.0.0"
  },
  "resolutions": {
    "@langchain/core": "^0.3.0"
  },
  "overrides": {
    "@langchain/core": "^0.3.0"
  },
  "pnpm": {
    "overrides": {
      "@langchain/core": "^0.3.0"
    }
  }
}

----------------------------------------

TITLE: Importing OpenAIModerationChain in TypeScript
DESCRIPTION: This snippet shows how to import the OpenAIModerationChain from the langchain/chains package. It is used for content moderation tasks in LangChain.js applications using OpenAI's moderation capabilities.

LANGUAGE: typescript
CODE:
import { OpenAIModerationChain } from "langchain/chains";

----------------------------------------

TITLE: Initializing Chat Model
DESCRIPTION: Example of initializing and using the ChatMistralAI model for basic chat functionality.

LANGUAGE: typescript
CODE:
import { ChatMistralAI } from "@langchain/mistralai";

const model = new ChatMistralAI({
  apiKey: process.env.MISTRAL_API_KEY,
  modelName: "mistral-small",
});
const response = await model.invoke(new HumanMessage("Hello world!"));

----------------------------------------

TITLE: Building LangChain Project
DESCRIPTION: Initial setup commands to build the LangChain project from the repository root.

LANGUAGE: sh
CODE:
yarn
yarn build

----------------------------------------

TITLE: Implementing Baidu Qianfan Chat Model
DESCRIPTION: Example of using the ChatBaiduQianfan class to create a chat instance and invoke it with a message

LANGUAGE: typescript
CODE:
import { ChatBaiduQianfan } from "@langchain/baidu-qianfan";
import { HumanMessage } from "@langchain/core/messages";

const chat = new ChatBaiduQianfan({
    model: 'ERNIE-Lite-8K'
});
const message = new HumanMessage("");

const res = await chat.invoke([message]);

----------------------------------------

TITLE: Installing LangChain Dependencies for Moonshot Integration
DESCRIPTION: This snippet shows the command to install the necessary LangChain dependencies for integrating Moonshot AI models. It uses npm to install @langchain/community and @langchain/core packages.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core

----------------------------------------

TITLE: Initializing and using ChatOpenAI in TypeScript
DESCRIPTION: Example of creating a ChatOpenAI instance and invoking it with a message.

LANGUAGE: typescript
CODE:
import { ChatOpenAI } from "@langchain/openai";

const model = new ChatOpenAI({
  apiKey: process.env.OPENAI_API_KEY,
  modelName: "gpt-4-1106-preview",
});
const response = await model.invoke(new HumanMessage("Hello world!"));

----------------------------------------

TITLE: Installing Dependencies for MyScale Integration in Node.js
DESCRIPTION: This snippet shows the command to install the required Node.js dependencies for integrating MyScale with LangChain.js. It includes packages for OpenAI, ClickHouse client, and LangChain community and core modules.

LANGUAGE: bash
CODE:
npm install -S @langchain/openai @clickhouse/client @langchain/community @langchain/core

----------------------------------------

TITLE: Installing Website Dependencies
DESCRIPTION: Command to install project dependencies using Yarn package manager after ensuring prerequisites are installed.

LANGUAGE: bash
CODE:
$ yarn

----------------------------------------

TITLE: Installing Mozilla Readability Dependencies
DESCRIPTION: Command to install the required @mozilla/readability and jsdom npm packages for HTML content transformation.

LANGUAGE: bash
CODE:
npm install @mozilla/readability jsdom

----------------------------------------

TITLE: Configuring Package Dependencies in package.json
DESCRIPTION: Package.json configuration to ensure consistent @langchain/core versioning across different package managers.

LANGUAGE: json
CODE:
{
  "name": "your-project",
  "version": "0.0.0",
  "dependencies": {
    "@langchain/anthropic": "^0.0.9",
    "@langchain/core": "^0.3.0"
  },
  "resolutions": {
    "@langchain/core": "^0.3.0"
  },
  "overrides": {
    "@langchain/core": "^0.3.0"
  },
  "pnpm": {
    "overrides": {
      "@langchain/core": "^0.3.0"
    }
  }
}

----------------------------------------

TITLE: Creating Google Custom Search Tool
DESCRIPTION: Shows how to create a Google Custom Search tool instance for use with an agent in LangChain.js.

LANGUAGE: typescript
CODE:
const tools = [new GoogleCustomSearch({})];
// Pass this variable into your agent.

----------------------------------------

TITLE: Using Glyphs with Minimax Chat Models in LangChain.js
DESCRIPTION: Shows how to use glyphs to force specific formatting in Minimax chat model responses within LangChain.js.

LANGUAGE: typescript
CODE:
import MinimaxGlyph from "@examples/models/chat/minimax_glyph.ts";

----------------------------------------

TITLE: Tracking Token Usage using Callbacks
DESCRIPTION: Example of how to track token usage using the handleLLMEnd callback, which provides the full output from the LLM including token usage for supported models.

LANGUAGE: typescript
CODE:
import CallbackExample from "@examples/models/chat/token_usage_tracking_callback.ts";

<CodeBlock language="typescript">{CallbackExample}</CodeBlock>

----------------------------------------

TITLE: Using OpenAIEmbeddings in TypeScript
DESCRIPTION: Example of creating an OpenAIEmbeddings instance and generating embeddings for a query.

LANGUAGE: typescript
CODE:
import { OpenAIEmbeddings } from "@langchain/openai";

const embeddings = new OpenAIEmbeddings({
  apiKey: process.env.OPENAI_API_KEY,
});
const res = await embeddings.embedQuery("Hello world");

----------------------------------------

TITLE: Implementing Azure Cosmos DB NoSQL Semantic Cache in TypeScript
DESCRIPTION: Example demonstrating how to set up and use the Azure Cosmos DB NoSQL Semantic Cache. It includes initializing the cache, creating an OpenAI model, and using the cache with a retriever.

LANGUAGE: typescript
CODE:
import { AzureCosmosDBNoSQLSemanticCache } from "@langchain/azure-cosmosdb";
import { ChatOpenAI } from "@langchain/openai";
import { EmbeddingsParams } from "@langchain/core/embeddings";
import { BaseCache } from "@langchain/core/caches";

// Initialize the cache
const cache = new AzureCosmosDBNoSQLSemanticCache({
  // Specify connection info
  connectionString: "<your_connection_string>",
  // or if using Managed Identity
  // endpoint: "<your_endpoint>",
  databaseName: "vector_cache",
  containerName: "cache",
  // Optionally specify embedding options
  embeddingOptions: {
    modelName: "text-embedding-ada-002",
  } as EmbeddingsParams,
  // Optionally specify cosine similarity threshold
  cosineSimilarityThreshold: 0.7,
});

// Initialize the model
const model = new ChatOpenAI({
  temperature: 0,
  cache: cache as BaseCache,
});

// Use the cache with a retriever
const retriever = model.bind({
  stop: ["\nHuman:"],
});

const result1 = await retriever.invoke(
  "Human: What is the capital of France?\nAI: The capital of France is Paris.\nHuman: What is the capital of Germany?"
);
console.log(result1);

const result2 = await retriever.invoke(
  "Human: What is the capital of France?"
);
console.log(result2);

----------------------------------------

TITLE: Development Commands for @langchain/mixedbread-ai
DESCRIPTION: These commands are used for developing the @langchain/mixedbread-ai package. They include installing dependencies, building the package, running tests, and linting/formatting the code.

LANGUAGE: bash
CODE:
yarn install
yarn build
yarn test
yarn test:int
yarn lint && yarn format

----------------------------------------

TITLE: Importing Bedrock Embeddings
DESCRIPTION: Import statement for AWS Bedrock text embedding model integration.

LANGUAGE: typescript
CODE:
import { BedrockEmbeddings } from "@langchain/aws";

----------------------------------------

TITLE: Parsing Sitemap without Loading Page Contents
DESCRIPTION: This snippet shows how to use the parseSitemap method to load only the sitemap structure without fetching the contents of each page.

LANGUAGE: typescript
CODE:
import ParseSitemapExample from "@examples/document_loaders/parse_sitemap.ts";

<CodeBlock language="typescript">{ParseSitemapExample}</CodeBlock>

----------------------------------------

TITLE: Streaming with Chat Model in TypeScript
DESCRIPTION: TypeScript code demonstrating how to use streaming with the chat model provided by the integration package.

LANGUAGE: typescript
CODE:
import { <ADD_CLASS_NAME_HERE> } from "@langchain/<ADD_PACKAGE_NAME_HERE>";

const model = new ExampleChatClass({
  apiKey: process.env.EXAMPLE_API_KEY,
});
const response = await model.stream(new HumanMessage("Hello world!"));

----------------------------------------

TITLE: Installing LangChain YandexGPT Dependencies
DESCRIPTION: This snippet shows how to install the necessary packages for using YandexGPT with LangChain.js. It includes the Yandex-specific package and the core LangChain package.

LANGUAGE: bash
CODE:
npm install @langchain/yandex @langchain/core

----------------------------------------

TITLE: Installing dependencies for development
DESCRIPTION: Command to install project dependencies using yarn.

LANGUAGE: bash
CODE:
yarn install

----------------------------------------

TITLE: RAG Implementation with Vector Store
DESCRIPTION: Shows how to use the vector store as a retriever in chains for retrieval augmented generation (RAG).

LANGUAGE: typescript
CODE:
import ExampleChain from "@examples/indexes/vector_stores/hana_vector/chains.ts";

----------------------------------------

TITLE: Klarna API Plugin Action Definition
DESCRIPTION: Initial action definition for using the Klarna Products API endpoint.

LANGUAGE: json
CODE:
{
"action": "KlarnaProducts",
"action_input": ""
}

----------------------------------------

TITLE: Defining Obsidian Tags in YAML Frontmatter
DESCRIPTION: YAML frontmatter block that specifies tags for an Obsidian note, specifically marking it as a journal entry.

LANGUAGE: yaml
CODE:
---
tags: journal/entry, obsidian
---

----------------------------------------

TITLE: Configuring Astra DB Connection in TypeScript
DESCRIPTION: This snippet shows how to create a configuration object for connecting to an Astra DB database. It includes the token and endpoint required for authentication.

LANGUAGE: typescript
CODE:
const configConnection = {
  serviceProviderArgs: {
    astra: {
      token: <...> as string,
      endpoint: <...> as string,
    },
  },
};

----------------------------------------

TITLE: Configuring Cassandra Connection for Apache Cassandra
DESCRIPTION: Example of creating a configuration object for connecting to Apache Cassandra. It includes contact points, local data center, and credentials.

LANGUAGE: typescript
CODE:
const configConnection = {
  contactPoints: ['h1', 'h2'],
  localDataCenter: 'datacenter1',
  credentials: {
    username: <...> as string,
    password: <...> as string,
  },
};

----------------------------------------

TITLE: Linting and formatting @langchain/openai
DESCRIPTION: Command to run the linter and formatter on the package code.

LANGUAGE: bash
CODE:
yarn lint && yarn format

----------------------------------------

TITLE: Installing LangChain Dependencies
DESCRIPTION: Commands to install required LangChain packages including OpenAI integration, core functionality, and community components.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/core @langchain/community

----------------------------------------

TITLE: Running tests for @langchain/groq
DESCRIPTION: These commands run the unit tests and integration tests for the @langchain/groq package.

LANGUAGE: bash
CODE:
$ yarn test
$ yarn test:int

----------------------------------------

TITLE: Loading data from a single GitBook page using LangChain.js
DESCRIPTION: This code demonstrates how to use the GitbookLoader to load data from a specific GitBook page. It creates a loader instance with a single URL and uses the load() method to retrieve the content.

LANGUAGE: typescript
CODE:
import { GitbookLoader } from "@langchain/community/document_loaders/web/gitbook";

const loader = new GitbookLoader(
  "https://docs.gitbook.com/product-tour/navigation"
);

const docs = await loader.load();

----------------------------------------

TITLE: Deleting Documents from VectorStore in TypeScript
DESCRIPTION: These code snippets show two methods for deleting documents from a vector store in LangChain using document IDs.

LANGUAGE: typescript
CODE:
await vectorStore.deleteDocuments(["doc1"]);

LANGUAGE: typescript
CODE:
await vectorStore.deleteDocuments({ ids: ["doc1"] });

----------------------------------------

TITLE: Installing Gmail Tool Dependencies
DESCRIPTION: Command to install required npm packages including @langchain/openai, @langchain/community, @langchain/core, and googleapis for Gmail Tool functionality.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/community @langchain/core googleapis

----------------------------------------

TITLE: Building Redis Package
DESCRIPTION: Commands to build the Redis package either directly or from the repository root.

LANGUAGE: bash
CODE:
yarn build

LANGUAGE: bash
CODE:
yarn build --filter=@langchain/redis

----------------------------------------

TITLE: Advanced Filtering Operations
DESCRIPTION: Demonstrates advanced filtering capabilities using various operators like equality, comparison, and logical operations.

LANGUAGE: typescript
CODE:
import ExampleAdvancedFilter from "@examples/indexes/vector_stores/hana_vector/advancedFiltering.ts";

----------------------------------------

TITLE: Extracting Figma File Key and Node ID from URL
DESCRIPTION: This snippet shows the structure of a Figma file URL, highlighting where to find the file key and node ID. These parameters are necessary for accessing specific Figma file data using the FigmaFileLoader.

LANGUAGE: plaintext
CODE:
https://www.figma.com/file/<YOUR FILE KEY HERE>/LangChainJS-Test?type=whiteboard&node-id=<YOUR NODE ID HERE>&t=e6lqWkKecuYQRyRg-0

----------------------------------------

TITLE: Installing Dependencies for SearxngSearch Tool in LangChain.js
DESCRIPTION: This snippet shows how to install the necessary dependencies for using the SearxngSearch tool in a LangChain.js project. It installs the @langchain/openai and @langchain/core packages.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/core

----------------------------------------

TITLE: Incorrect JSON Template Usage in LangChain.js
DESCRIPTION: Example showing incorrect implementation of a prompt template where JSON object curly braces are not properly escaped, causing the template to interpret them as variables.

LANGUAGE: typescript
CODE:
import { PromptTemplate } from "@langchain/core/prompts";
import { ChatOpenAI } from "@langchain/openai";

const prompt = PromptTemplate.fromTemplate(`You are a helpful assistant.

Here is an example of how you should respond:

{
  "firstName": "John",
  "lastName": "Doe",
  "age": 21
}

Now, answer the following question:

{question}`);

----------------------------------------

TITLE: Installing Baidu Qianfan Dependencies
DESCRIPTION: Commands to install the required npm packages for using Baidu Qianfan embeddings with LangChain

LANGUAGE: bash
CODE:
npm install @langchain/baidu-qianfan @langchain/core

----------------------------------------

TITLE: Installing TensorFlow.js Dependencies
DESCRIPTION: Package installation command for setting up TensorFlow.js embeddings with necessary dependencies including the universal sentence encoder and CPU backend.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core @tensorflow/tfjs-core@3.6.0 @tensorflow/tfjs-converter@3.6.0 @tensorflow-models/universal-sentence-encoder@1.3.3 @tensorflow/tfjs-backend-cpu

----------------------------------------

TITLE: Loading Notion Markdown Exports with LangChain.js in TypeScript
DESCRIPTION: This code snippet demonstrates how to use LangChain.js to load data from Notion pages exported as Markdown files. It utilizes the NotionLoader class to process the exported Markdown files and extract the content.

LANGUAGE: typescript
CODE:
import CodeBlock from "@theme/CodeBlock";
import Example from "@examples/document_loaders/notion_markdown.ts";

<CodeBlock language="typescript">{Example}</CodeBlock>

----------------------------------------

TITLE: Installing @langchain/xai Package
DESCRIPTION: Command to install the @langchain/xai package and its dependency @langchain/core using npm or yarn.

LANGUAGE: bash
CODE:
npm install @langchain/xai @langchain/core

----------------------------------------

TITLE: Installing LangChain Dependencies
DESCRIPTION: Command to install required LangChain packages for integration with Momento Vector Index.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/community @langchain/core

----------------------------------------

TITLE: Installing @langchain/google-webauth Package with Yarn
DESCRIPTION: This command installs the @langchain/google-webauth package using Yarn package manager. It adds the package to your project's dependencies.

LANGUAGE: bash
CODE:
$ yarn add @langchain/google-webauth

----------------------------------------

TITLE: Setting Baidu Qianfan Environment Variables
DESCRIPTION: Environment variable configuration required for Baidu Qianfan authentication

LANGUAGE: bash
CODE:
export QIANFAN_AK=""
export QIANFAN_SK=""
export QIANFAN_ACCESS_KEY=""
export QIANFAN_SECRET_KEY=""

----------------------------------------

TITLE: Installing Dependencies for Confluence Document Loader
DESCRIPTION: This snippet shows how to install the required packages for using the Confluence document loader with LangChain.js.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core html-to-text

----------------------------------------

TITLE: Reporting Security Vulnerabilities in LangChain.js
DESCRIPTION: Instructions for reporting security vulnerabilities in the LangChain.js project. Users are directed to send an email to a specific address, which is monitored by project maintainers for prompt triage and action.

LANGUAGE: markdown
CODE:
# Security Policy

## Reporting a Vulnerability

Please report security vulnerabilities by email to `security@langchain.dev`.
This email is an alias to a subset of our maintainers, and will ensure the issue is promptly triaged and acted upon as needed.

----------------------------------------

TITLE: Installing Mixedbread AI Dependencies
DESCRIPTION: Command to install the required npm packages for using Mixedbread AI embeddings with LangChain.

LANGUAGE: bash
CODE:
npm install @langchain/mixedbread-ai @langchain/core

----------------------------------------

TITLE: Installing Development Dependencies
DESCRIPTION: Command to install the necessary dependencies for developing the @langchain/xai package using yarn.

LANGUAGE: bash
CODE:
yarn install

----------------------------------------

TITLE: Installing Upstash Redis for Caching in npm
DESCRIPTION: This bash command installs the @upstash/redis package, which is required for using Upstash Redis-based caching in LangChain.js.

LANGUAGE: bash
CODE:
npm install @upstash/redis

----------------------------------------

TITLE: Installing @langchain/mixedbread-ai Package
DESCRIPTION: This snippet shows how to install the @langchain/mixedbread-ai package using npm. It's a prerequisite for using Mixedbread AI integration with LangChain.js.

LANGUAGE: bash
CODE:
npm install @langchain/mixedbread-ai

----------------------------------------

TITLE: Installing LangChain.js via Package Managers
DESCRIPTION: Commands for installing LangChain.js using different Node.js package managers (npm, yarn, pnpm).

LANGUAGE: bash
CODE:
npm install -S langchain

LANGUAGE: bash
CODE:
yarn add langchain

LANGUAGE: bash
CODE:
pnpm add langchain

----------------------------------------

TITLE: Installing HuggingFace Inference Dependencies
DESCRIPTION: Command to install the required packages for using HuggingFace Inference embeddings with LangChain.js, including the community package and HuggingFace inference dependency.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core @huggingface/inference@2

----------------------------------------

TITLE: Setting Azure OpenAI Environment Variables
DESCRIPTION: Bash commands to set required environment variables for Azure OpenAI API access.

LANGUAGE: bash
CODE:
export AZURE_OPENAI_API_ENDPOINT=<your_endpoint>
export AZURE_OPENAI_API_KEY=<your_key>
export AZURE_OPENAI_API_DEPLOYMENT_NAME=<your_deployment_name>

----------------------------------------

TITLE: Using YandexGPT LLM for Translation
DESCRIPTION: Example showing how to use the YandexGPT LLM class for direct text translation

LANGUAGE: typescript
CODE:
import { YandexGPT } from "@langchain/yandex";
const model = new YandexGPT();
const res = await model.invoke([`Translate "I love programming" into French.`]);

----------------------------------------

TITLE: Configuring Next.js Runtime for MongoDB
DESCRIPTION: Sets the Next.js runtime to Node.js to enable MongoDB compatibility in Next.js API routes.

LANGUAGE: typescript
CODE:
export const runtime = "nodejs";

----------------------------------------

TITLE: Installing @langchain/exa and @langchain/core packages
DESCRIPTION: Command to install the required packages for using Exa with LangChain.js. This installs both the Exa integration package and the core LangChain package.

LANGUAGE: bash
CODE:
npm install @langchain/exa @langchain/core

----------------------------------------

TITLE: Generating Subtitles with AssemblyAI
DESCRIPTION: Example demonstrating the use of AudioSubtitleLoader to generate SRT or VTT subtitles from audio content

LANGUAGE: typescript
CODE:
SubtitleExample

----------------------------------------

TITLE: Initializing JinaEmbeddings class in TypeScript
DESCRIPTION: Creates an instance of JinaEmbeddings with an API key and optional model specification.

LANGUAGE: typescript
CODE:
import { JinaEmbeddings } from "@langchain/community/embeddings/jina";

const embeddings = new JinaEmbeddings({
  apiKey: "YOUR_API_TOKEN",
  model: "jina-clip-v2", // Optional, defaults to "jina-clip-v2"
});

----------------------------------------

TITLE: Defining Obsidian Tags in YAML Frontmatter
DESCRIPTION: YAML frontmatter block that sets metadata tags for an Obsidian note, specifically marking it as a journal entry.

LANGUAGE: yaml
CODE:
---
tags: journal/entry, obsidian
---

----------------------------------------

TITLE: Importing and Using Python Interpreter Tool Example
DESCRIPTION: Example code demonstrating how to import and use the Python interpreter tool in a TypeScript environment. The actual code is not provided in the snippet, but referenced as an external file.

LANGUAGE: typescript
CODE:
{ToolExample}

----------------------------------------

TITLE: Installing Required Dependencies
DESCRIPTION: Commands for installing the necessary npm packages including Apify client and LangChain dependencies.

LANGUAGE: bash
CODE:
npm install apify-client
npm install hnswlib-node @langchain/openai @langchain/community @langchain/core

----------------------------------------

TITLE: Installing Metal SDK and LangChain Dependencies
DESCRIPTION: Command to install required packages including Metal SDK and LangChain components using npm or yarn.

LANGUAGE: bash
CODE:
npm i @getmetal/metal-sdk @langchain/community @langchain/core

----------------------------------------

TITLE: Installing Nomic Dependencies
DESCRIPTION: Command to install the required Nomic and LangChain Core packages using npm or yarn.

LANGUAGE: bash
CODE:
npm install @langchain/nomic @langchain/core

----------------------------------------

TITLE: Installing @langchain/community and @langchain/core packages
DESCRIPTION: Command to install the required packages for using JinaEmbeddings.

LANGUAGE: bash
CODE:
npm i @langchain/community @langchain/core

----------------------------------------

TITLE: Connecting to SQLite Database using TypeORM in TypeScript
DESCRIPTION: TypeScript code snippet demonstrating how to connect to a SQLite database (Chinook) using TypeORM and the SqlDatabase class from LangChain.

LANGUAGE: typescript
CODE:
import CodeBlock from "@theme/CodeBlock";
import DbCheck from "@examples/use_cases/sql/db_check.ts";

<CodeBlock language="typescript">{DbCheck}</CodeBlock>

----------------------------------------

TITLE: Building LangChain Core
DESCRIPTION: Commands to change directory to langchain-core, install dependencies, and build the core package.

LANGUAGE: bash
CODE:
cd ../../langchain-core
yarn
yarn build

----------------------------------------

TITLE: Installing Dependencies for Google Places Tool
DESCRIPTION: Commands to install the necessary npm packages for using the Google Places Tool with LangChain.js. This includes @langchain/openai, @langchain/community, and @langchain/core.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/community @langchain/core

----------------------------------------

TITLE: Setting DeepSeek API Key
DESCRIPTION: Environment variable configuration for DeepSeek API authentication.

LANGUAGE: bash
CODE:
export DEEPSEEK_API_KEY=

----------------------------------------

TITLE: Loading SRT Subtitles with LangChain.js
DESCRIPTION: Implementation of SRTLoader to parse a subtitle file. The loader takes a file path as input and returns documents containing the parsed subtitles.

LANGUAGE: typescript
CODE:
import { SRTLoader } from "@langchain/community/document_loaders/fs/srt";

const loader = new SRTLoader(
  "src/document_loaders/example_data/Star_Wars_The_Clone_Wars_S06E07_Crisis_at_the_Heart.srt"
);

const docs = await loader.load();

----------------------------------------

TITLE: Installing Dependencies for HyDE Retriever
DESCRIPTION: Command to install required npm packages @langchain/openai and @langchain/core for using the HyDE Retriever.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/core

----------------------------------------

TITLE: Installing Documentation Dependencies
DESCRIPTION: Command to install dependencies for building the documentation site locally.

LANGUAGE: bash
CODE:
yarn build --filter=core_docs

----------------------------------------

TITLE: Retrieving Neon Postgres Connection String
DESCRIPTION: Example of a Neon Postgres connection string format. This string is used to connect to the database and is found in the Neon Console's Connection Details section.

LANGUAGE: text
CODE:
postgres://alex:AbC123dEf@ep-cool-darkness-123456.us-east-2.aws.neon.tech/dbname?sslmode=require

----------------------------------------

TITLE: Installing LangChain Dependencies for Zep Integration
DESCRIPTION: Install required npm packages for using Zep with LangChain, including OpenAI and community packages.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/community @langchain/core

----------------------------------------

TITLE: Local Browser Implementation with Stagehand
DESCRIPTION: Example of implementing Stagehand toolkit with a local browser setup, demonstrating navigation, actions, and observation capabilities.

LANGUAGE: typescript
CODE:
import { StagehandToolkit } from "langchain/community/agents/toolkits/stagehand";
import { ChatOpenAI } from "@langchain/openai";
import { Stagehand } from "@browserbasehq/stagehand";

// Specify your Browserbase credentials.
process.env.BROWSERBASE_API_KEY = "";
process.env.BROWSERBASE_PROJECT_ID = "";

// Specify OpenAI API key.
process.env.OPENAI_API_KEY = "";

const stagehand = new Stagehand({
  env: "LOCAL",
  headless: false,
  verbose: 2,
  debugDom: true,
  enableCaching: false,
});

// Create a Stagehand Toolkit with all the available actions from the Stagehand.
const stagehandToolkit = await StagehandToolkit.fromStagehand(stagehand);

const navigateTool = stagehandToolkit.tools.find(
  (t) => t.name === "stagehand_navigate"
);
if (!navigateTool) {
  throw new Error("Navigate tool not found");
}
await navigateTool.invoke("https://www.google.com");

const actionTool = stagehandToolkit.tools.find(
  (t) => t.name === "stagehand_act"
);
if (!actionTool) {
  throw new Error("Action tool not found");
}
await actionTool.invoke('Search for "OpenAI"');

const observeTool = stagehandToolkit.tools.find(
  (t) => t.name === "stagehand_observe"
);
if (!observeTool) {
  throw new Error("Observe tool not found");
}
const result = await observeTool.invoke(
  "What actions can be performed on the current page?"
);
const observations = JSON.parse(result);

// Handle observations as needed
console.log(observations);

const currentUrl = stagehand.page.url();
expect(currentUrl).toContain("google.com/search?q=OpenAI");

----------------------------------------

TITLE: Loading Figma Data with LangChain.js in TypeScript
DESCRIPTION: This code snippet demonstrates how to load data from a Figma file using LangChain.js. It requires a Figma access token and file details. The code uses the FigmaFileLoader to retrieve data from a specified Figma file and node.

LANGUAGE: typescript
CODE:
<CodeBlock language="typescript">{Example}</CodeBlock>

----------------------------------------

TITLE: Running Documentation Generation
DESCRIPTION: Command to generate and view the documentation locally.

LANGUAGE: bash
CODE:
yarn docs

----------------------------------------

TITLE: Installing LangChain.js Dependencies
DESCRIPTION: Command to install necessary LangChain.js packages for using the Google Calendar Tool.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/core @langchain/community @langchain/langgraph

----------------------------------------

TITLE: Building the @langchain/cohere package
DESCRIPTION: Commands to build the package, both from the package directory and the repo root.

LANGUAGE: bash
CODE:
yarn build

LANGUAGE: bash
CODE:
yarn build --filter=@langchain/cohere

----------------------------------------

TITLE: Configuring and Using MultiFileLoader in TypeScript
DESCRIPTION: Demonstrates how to set up the MultiFileLoader with different file loaders for various file types. It includes importing necessary loaders, configuring the MultiFileLoader with file paths and loader mappings, and loading the documents.

LANGUAGE: typescript
CODE:
import { MultiFileLoader } from "langchain/document_loaders/fs/multi_file";
import {
  JSONLoader,
  JSONLinesLoader,
} from "langchain/document_loaders/fs/json";
import { TextLoader } from "langchain/document_loaders/fs/text";
import { CSVLoader } from "langchain/document_loaders/fs/csv";

const loader = new MultiFileLoader(
  [
    "src/document_loaders/example_data/example/example.txt",
    "src/document_loaders/example_data/example/example.csv",
    "src/document_loaders/example_data/example2/example.json",
    "src/document_loaders/example_data/example2/example.jsonl",
  ],
  {
    ".json": (path) => new JSONLoader(path, "/texts"),
    ".jsonl": (path) => new JSONLinesLoader(path, "/html"),
    ".txt": (path) => new TextLoader(path),
    ".csv": (path) => new CSVLoader(path, "text"),
  }
);
const docs = await loader.load();
console.log({ docs });

----------------------------------------

TITLE: Initializing Xata Project
DESCRIPTION: Command to initialize a Xata project in the current directory, which will generate necessary configuration files.

LANGUAGE: bash
CODE:
xata init

----------------------------------------

TITLE: Configuring Cassandra Connection for Astra DB
DESCRIPTION: Example of creating a configuration object for connecting to Astra DB, a cloud-native Cassandra-as-a-Service platform. It includes the token and endpoint.

LANGUAGE: typescript
CODE:
const configConnection = {
  serviceProviderArgs: {
    astra: {
      token: <...> as string,
      endpoint: <...> as string,
    },
  },
};

----------------------------------------

TITLE: Loading JSON with Pointer using TypeScript
DESCRIPTION: Shows how to use JSONLoader with specific JSON pointers to selectively extract values from 'from' and 'surname' properties in the JSON structure.

LANGUAGE: typescript
CODE:
import { JSONLoader } from "langchain/document_loaders/fs/json";

const loader = new JSONLoader(
  "src/document_loaders/example_data/example.json",
  ["/from", "/surname"]
);

const docs = await loader.load();

----------------------------------------

TITLE: Installing Dependencies for CollegeConfidentialLoader in LangChain.js
DESCRIPTION: This command installs the necessary npm packages for using the CollegeConfidentialLoader in a LangChain.js project. It includes @langchain/community for the loader, @langchain/core for core functionality, and cheerio for web scraping.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core cheerio

----------------------------------------

TITLE: Installing Azure Dynamic Sessions Dependencies
DESCRIPTION: Command to install the required npm packages for Azure Dynamic Sessions integration with LangChain.

LANGUAGE: bash
CODE:
npm install @langchain/azure-dynamic-sessions @langchain/core

----------------------------------------

TITLE: Installing Momento SDK for Browser/Edge
DESCRIPTION: Command to install the Momento Client Library for browser and edge worker environments using npm.

LANGUAGE: bash
CODE:
npm install @gomomento/sdk-web

----------------------------------------

TITLE: Server Action File Imports
DESCRIPTION: Required imports for the server-side action file implementing agent functionality

LANGUAGE: typescript
CODE:
"use server";

import { ChatOpenAI } from "@langchain/openai";
import { ChatPromptTemplate } from "@langchain/core/prompts";
import { TavilySearchResults } from "@langchain/community/tools/tavily_search";
import { AgentExecutor, createToolCallingAgent } from "langchain/agents";
import { pull } from "langchain/hub";
import { createStreamableValue } from "ai/rsc";

----------------------------------------

TITLE: Installing Zep Dependencies
DESCRIPTION: Command to install required npm packages for Zep integration with LangChain

LANGUAGE: bash
CODE:
npm i @getzep/zep-js @langchain/community @langchain/core

----------------------------------------

TITLE: Initializing and using ChatCohere model in TypeScript
DESCRIPTION: Example of creating a ChatCohere instance and invoking it with a message.

LANGUAGE: typescript
CODE:
import { HumanMessage } from "@langchain/core/messages";
import { ChatCohere } from "@langchain/cohere";

const model = new ChatCohere({
  apiKey: process.env.COHERE_API_KEY,
});
const response = await model.invoke([new HumanMessage("Hello world!")]);

----------------------------------------

TITLE: Installing Dependencies for Upstash Redis Chat Memory in LangChain.js
DESCRIPTION: This command installs the necessary packages for implementing Upstash Redis-backed chat memory in a LangChain.js project.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/community @langchain/core @upstash/redis

----------------------------------------

TITLE: Configuring Cloudflare Worker and D1 Database in wrangler.toml
DESCRIPTION: This TOML configuration sets up a Cloudflare Worker project with a D1 database binding and an environment variable for the Anthropic API key.

LANGUAGE: toml
CODE:
name = "YOUR_PROJECT_NAME"
main = "src/index.ts"
compatibility_date = "2024-01-10"

[vars]
ANTHROPIC_API_KEY = "YOUR_ANTHROPIC_KEY"

[[d1_databases]]
binding = "DB"                                       # available in your Worker as env.DB
database_name = "YOUR_D1_DB_NAME"
database_id = "YOUR_D1_DB_ID"

----------------------------------------

TITLE: Installing Azure AI Search Dependencies
DESCRIPTION: Command to install required npm packages for Azure AI Search integration including @langchain/community, @langchain/core, and @azure/search-documents.

LANGUAGE: bash
CODE:
npm install -S @langchain/community @langchain/core @azure/search-documents

----------------------------------------

TITLE: Installing AssemblyAI Dependencies
DESCRIPTION: Command to install the required npm packages for using AssemblyAI with LangChain

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core assemblyai

----------------------------------------

TITLE: Installing LangChain OpenAI Dependencies
DESCRIPTION: Command to install the required LangChain OpenAI integration packages for using the Dall-E tool.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/core

----------------------------------------

TITLE: Installing LangChain.js with Package Managers
DESCRIPTION: Commands to install LangChain.js using npm, yarn, or pnpm package managers.

LANGUAGE: shell
CODE:
npm install -S langchain

LANGUAGE: shell
CODE:
yarn add langchain

LANGUAGE: shell
CODE:
pnpm add langchain

----------------------------------------

TITLE: Setting Cohere API key in bash
DESCRIPTION: Command to set the COHERE_API_KEY environment variable.

LANGUAGE: bash
CODE:
export COHERE_API_KEY=your-api-key

----------------------------------------

TITLE: Loading EPUB with Chapter Splitting
DESCRIPTION: Demonstrates loading an EPUB file where each chapter becomes a separate document using EPubLoader

LANGUAGE: typescript
CODE:
import { EPubLoader } from "@langchain/community/document_loaders/fs/epub";

const loader = new EPubLoader("src/document_loaders/example_data/example.epub");

const docs = await loader.load();

----------------------------------------

TITLE: Installing LangChain Cloudflare Integration Packages
DESCRIPTION: This snippet shows the command to install the necessary packages for using LangChain with Cloudflare and Anthropic in a Node.js environment.

LANGUAGE: bash
CODE:
npm install @langchain/cloudflare @langchain/anthropic @langchain/core

----------------------------------------

TITLE: Implementing Typesense Vector Store
DESCRIPTION: Complete implementation of Typesense vector store including client configuration, store initialization, similarity search, and document management. Shows how to set up the client, configure the store, and perform various operations like searching and deleting documents.

LANGUAGE: typescript
CODE:
import {
  Typesense,
  TypesenseConfig,
} from "@lanchain/community/vectorstores/typesense";
import { OpenAIEmbeddings } from "@langchain/openai";
import { Client } from "typesense";
import { Document } from "@langchain/core/documents";

const vectorTypesenseClient = new Client({
  nodes: [
    {
      // Ideally should come from your .env file
      host: "...",
      port: 123,
      protocol: "https",
    },
  ],
  // Ideally should come from your .env file
  apiKey: "...",
  numRetries: 3,
  connectionTimeoutSeconds: 60,
});

const typesenseVectorStoreConfig = {
  // Typesense client
  typesenseClient: vectorTypesenseClient,
  // Name of the collection to store the vectors in
  schemaName: "your_schema_name",
  // Optional column names to be used in Typesense
  columnNames: {
    // "vec" is the default name for the vector column in Typesense but you can change it to whatever you want
    vector: "vec",
    // "text" is the default name for the text column in Typesense but you can change it to whatever you want
    pageContent: "text",
    // Names of the columns that you will save in your typesense schema and need to be retrieved as metadata when searching
    metadataColumnNames: ["foo", "bar", "baz"],
  },
  // Optional search parameters to be passed to Typesense when searching
  searchParams: {
    q: "*",
    filter_by: "foo:[fooo]",
    query_by: "",
  },
  import: async (data, collectionName) => {
    await vectorTypesenseClient
      .collections(collectionName)
      .documents()
      .import(data, { action: "emplace", dirty_values: "drop" });
  },
} satisfies TypesenseConfig;

/**
 * Creates a Typesense vector store from a list of documents.
 * Will update documents if there is a document with the same id, at least with the default import function.
 * @param documents list of documents to create the vector store from
 * @returns Typesense vector store
 */
const createVectorStoreWithTypesense = async (documents: Document[] = []) =>
  Typesense.fromDocuments(
    documents,
    new OpenAIEmbeddings(),
    typesenseVectorStoreConfig
  );

/**
 * Returns a Typesense vector store from an existing index.
 * @returns Typesense vector store
 */
const getVectorStoreWithTypesense = async () =>
  new Typesense(new OpenAIEmbeddings(), typesenseVectorStoreConfig);

// Do a similarity search
const vectorStore = await getVectorStoreWithTypesense();
const documents = await vectorStore.similaritySearch("hello world");

// Add filters based on metadata with the search parameters of Typesense
// will exclude documents with author:JK Rowling, so if Joe Rowling & JK Rowling exists, only Joe Rowling will be returned
vectorStore.similaritySearch("Rowling", undefined, {
  filter_by: "author:!=JK Rowling",
});

// Delete a document
vectorStore.deleteDocuments(["document_id_1", "document_id_2"]);

----------------------------------------

TITLE: Installing EPUB Loading Dependencies
DESCRIPTION: Installation commands for required packages including @langchain/community, @langchain/core, epub2, and html-to-text

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core epub2 html-to-text

----------------------------------------

TITLE: Setting Airtable API Token in TypeScript
DESCRIPTION: Demonstrates how to set up the Airtable API token as an environment variable, which is required for authenticating with the Airtable API.

LANGUAGE: typescript
CODE:
process.env.AIRTABLE_API_TOKEN = "YOUR_AIRTABLE_API_TOKEN";

----------------------------------------

TITLE: Defining Vector Types for Astra DB Collection Creation
DESCRIPTION: Demonstrates the options for specifying vector types when creating an Astra DB collection. Supports 'cosine' (default), 'dot_product', and 'euclidean' similarity metrics with a specified dimension.

LANGUAGE: typescript
CODE:
vector: {
    dimension: number;
    metric?: "cosine" | "euclidean" | "dot_product";
};

----------------------------------------

TITLE: Installing Replicate Dependencies
DESCRIPTION: Commands to install the required packages for using Replicate with LangChain.js, including the Replicate client, LangChain community package, and core functionality.

LANGUAGE: bash
CODE:
npm install replicate@1 @langchain/community @langchain/core

----------------------------------------

TITLE: Querying Documents from Existing Milvus Collection
DESCRIPTION: TypeScript code showing how to create a Milvus vector store from an existing collection and perform similarity search.

LANGUAGE: typescript
CODE:
import { Milvus } from "langchain/vectorstores/milvus";
import { OpenAIEmbeddings } from "@langchain/openai";

const vectorStore = await Milvus.fromExistingCollection(
  new OpenAIEmbeddings(),
  {
    collectionName: "goldel_escher_bach",
  }
);

const response = await vectorStore.similaritySearch("scared", 2);

----------------------------------------

TITLE: Customizing DeepInfra API Configuration
DESCRIPTION: Example of customizing the base URL for API requests using the configuration parameter

LANGUAGE: typescript
CODE:
const customEmbeddings = new DeepInfraEmbeddings({
  apiToken: "YOUR_API_TOKEN",
  configuration: {
    baseURL: "https://your_custom_url.com",
  },
});

----------------------------------------

TITLE: Running Tests for Cloudflare Package
DESCRIPTION: Commands to run unit tests and integration tests for the Cloudflare package. Test files should be located in the 'tests/' directory within 'src/'.

LANGUAGE: bash
CODE:
$ yarn test
$ yarn test:int

----------------------------------------

TITLE: Installing DeepSeek Dependencies
DESCRIPTION: Commands to install the required DeepSeek and LangChain Core packages using npm or yarn.

LANGUAGE: bash
CODE:
npm install @langchain/deepseek @langchain/core

----------------------------------------

TITLE: Loading .doc Files with DocxLoader
DESCRIPTION: This snippet illustrates how to initialize DocxLoader for a .doc file by explicitly specifying the 'type' parameter as 'doc'.

LANGUAGE: javascript
CODE:
import { DocxLoader } from "@langchain/community/document_loaders/fs/docx";

const loader = new DocxLoader(
  "src/document_loaders/tests/example_data/attention.doc",
  {
    type: "doc",
  }
);

const docs = await loader.load();

----------------------------------------

TITLE: Using JigsawStack Prompt Engine
DESCRIPTION: Example of initializing and using the JigsawStack Prompt Engine to generate responses. Shows how to create a model instance and invoke it with a prompt.

LANGUAGE: typescript
CODE:
import { JigsawStackPromptEngine } from "@langchain/jigsawstack";

export const run = async () => {
  const model = new JigsawStackPromptEngine();
  const res = await model.invoke(
    "Tell me about the leaning tower of pisa?\nAnswer:"
  );
  console.log({ res });
};

----------------------------------------

TITLE: Configuring Azure Cosmos DB Environment Variables
DESCRIPTION: Environment variable configuration for Azure Cosmos DB connection settings

LANGUAGE: text
CODE:
AZURE_COSMOSDB_ENDPOINT="your-endpoint-connection-string"
AZURE_COSMOSDB_KEY="your-key"
AZURE_COSMOSDB_DATABASE_NAME="your-database-name"
AZURE_COSMOSDB_CONTAINER_NAME="your-container-name"

----------------------------------------

TITLE: Installing officeparser Dependency for PPTX Loading in npm/yarn
DESCRIPTION: This snippet shows how to install the required 'officeparser' package using npm or yarn. This dependency is necessary for the PPTXLoader to function.

LANGUAGE: bash
CODE:
npm install officeparser

----------------------------------------

TITLE: Azure AI Search Environment Variables Configuration
DESCRIPTION: Environment variables required for Azure AI Search setup including endpoint URL and admin key credentials.

LANGUAGE: text
CODE:
AZURE_AISEARCH_ENDPOINT="your-endpoint-goes-here"
AZURE_AISEARCH_KEY="your-key-goes-here"

----------------------------------------

TITLE: Installing HuggingFace Transformers Dependencies
DESCRIPTION: Commands to install the required HuggingFace Transformers package and LangChain community packages.

LANGUAGE: bash
CODE:
npm install @huggingface/transformers

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core

----------------------------------------

TITLE: Generating Multiple Document Embeddings
DESCRIPTION: Shows how to generate embeddings for multiple documents using the embedDocuments method with automatic batching

LANGUAGE: typescript
CODE:
const documents = [
  "Document 1 text...",
  "Document 2 text...",
  "Document 3 text...",
];

const embeddingsArray = await embeddings.embedDocuments(documents);
console.log(embeddingsArray);

----------------------------------------

TITLE: Installing LangChain Cloudflare Package
DESCRIPTION: Command to install the @langchain/cloudflare package along with its core dependency using npm or yarn.

LANGUAGE: bash
CODE:
npm install @langchain/cloudflare @langchain/core

----------------------------------------

TITLE: Installing Dependencies for .docx File Processing
DESCRIPTION: This snippet shows how to install the necessary packages for processing .docx files using npm or yarn.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core mammoth

----------------------------------------

TITLE: Installing JigsawStack Package
DESCRIPTION: NPM command to install the JigsawStack integration package for LangChain.js.

LANGUAGE: bash
CODE:
npm install @langchain/jigsawstack

----------------------------------------

TITLE: Configuring Field Selection for Documents
DESCRIPTION: Creating loader with specific content and metadata field selections

LANGUAGE: typescript
CODE:
const loaderWithSelectedFields = new CouchbaseDocumentLoader(
  couchbaseClient,
  query,
  [
    "address",
    "name",
    "city",
    "phone",
    "country",
    "geo",
    "description",
    "reviews",
  ],
  ["id"]
);

const filtered_docs = await loaderWithSelectedFields.load();
console.log(filtered_docs);

----------------------------------------

TITLE: Installing Upstash Ratelimit and LangChain Dependencies
DESCRIPTION: Command to install the necessary npm packages for using Upstash Ratelimit with LangChain.

LANGUAGE: bash
CODE:
npm install @upstash/ratelimit @langchain/community @langchain/core

----------------------------------------

TITLE: Installing SRT Parser Dependency
DESCRIPTION: Installation command for the required srt-parser-2 package using npm or yarn.

LANGUAGE: bash
CODE:
npm install srt-parser-2

----------------------------------------

TITLE: Creating Cloudflare Vectorize Index with Wrangler
DESCRIPTION: This command creates a Cloudflare Vectorize index using Wrangler CLI with a specified preset.

LANGUAGE: bash
CODE:
$ npx wrangler vectorize create <index_name> --preset @cf/baai/bge-small-en-v1.5

----------------------------------------

TITLE: Installing Dependencies for HuggingFaceInference in Node.js
DESCRIPTION: This snippet shows the command to install the required packages for using HuggingFaceInference in a Node.js project. It includes @langchain/community, @langchain/core, and @huggingface/inference.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core @huggingface/inference@2

----------------------------------------

TITLE: Development Setup Commands
DESCRIPTION: Commands for setting up the development environment, including dependency installation and building.

LANGUAGE: bash
CODE:
yarn install
yarn build

----------------------------------------

TITLE: Installing DeepInfra Dependencies
DESCRIPTION: Command to install required packages for using DeepInfra embeddings with LangChain

LANGUAGE: bash
CODE:
npm i @langchain/community @langchain/core

----------------------------------------

TITLE: Implementing Cerebras Chat Model
DESCRIPTION: TypeScript example showing how to initialize and use the Cerebras chat model for message processing.

LANGUAGE: typescript
CODE:
import { ChatCerebras } from "@langchain/cerebras";
import { HumanMessage } from "@langchain/core/messages";

const model = new ChatCerebras({
  apiKey: process.env.CEREBRAS_API_KEY, // Default value.
});

const message = new HumanMessage("What color is the sky?");

const res = await model.invoke([message]);

----------------------------------------

TITLE: Installing @langchain/aws Package
DESCRIPTION: Command to install the @langchain/aws package using npm.

LANGUAGE: bash
CODE:
npm install @langchain/aws

----------------------------------------

TITLE: Installing Xata CLI
DESCRIPTION: Command to install the Xata command-line interface globally using npm.

LANGUAGE: bash
CODE:
npm install @xata.io/cli -g

----------------------------------------

TITLE: Installing Notion Dependencies with NPM/Yarn
DESCRIPTION: Command to install required packages including the official Notion client and notion-to-md converter for LangChain integration.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core @notionhq/client notion-to-md

----------------------------------------

TITLE: Installing LangChain Community and Core Packages
DESCRIPTION: Command to install the required LangChain packages for using ChatDeepInfra. This installs both the community package, which contains the ChatDeepInfra wrapper, and the core LangChain package.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core

----------------------------------------

TITLE: Installing S3 Document Loader Dependencies
DESCRIPTION: Command to install required npm packages including the AWS SDK, LangChain community package, and core dependencies for S3 file loading functionality.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core @aws-sdk/client-s3

----------------------------------------

TITLE: Configuring wrangler.toml for Cloudflare Worker with Vectorize
DESCRIPTION: This configuration sets up a Cloudflare Worker with Vectorize and AI bindings.

LANGUAGE: toml
CODE:
name = "langchain-test"
main = "worker.ts"
compatibility_date = "2024-01-10"

[[vectorize]]
binding = "VECTORIZE_INDEX"
index_name = "langchain-test"

[ai]
binding = "AI"

----------------------------------------

TITLE: Setting AWS Bedrock Environment Variables
DESCRIPTION: Bash commands to set required environment variables for AWS Bedrock authentication.

LANGUAGE: bash
CODE:
export BEDROCK_AWS_REGION=
export BEDROCK_AWS_SECRET_ACCESS_KEY=
export BEDROCK_AWS_ACCESS_KEY_ID=

----------------------------------------

TITLE: Installing Dependencies for Gradient AI Embeddings in Node.js
DESCRIPTION: This snippet shows how to install the necessary dependencies for using Gradient AI embeddings in a Node.js project. It includes the LangChain community package, LangChain core, and the official Gradient Node SDK.

LANGUAGE: bash
CODE:
npm i @langchain/community @langchain/core @gradientai/nodejs-sdk

----------------------------------------

TITLE: Development Commands for @langchain/aws
DESCRIPTION: Bash commands for installing dependencies, building the package, running tests, and linting/formatting the code during development.

LANGUAGE: bash
CODE:
yarn install
yarn build
yarn build --filter=@langchain/aws
yarn test
yarn test:int
yarn lint && yarn format

----------------------------------------

TITLE: Installing LangChain Community and Core Packages
DESCRIPTION: This snippet demonstrates the installation of @langchain/community and @langchain/core packages using npm or yarn.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core

----------------------------------------

TITLE: Connecting to Couchbase Cluster
DESCRIPTION: Establishing connection to the Couchbase cluster using provided credentials

LANGUAGE: typescript
CODE:
const couchbaseClient = await Cluster.connect(connectionString, {
  username: dbUsername,
  password: dbPassword,
  configProfile: "wanDevelopment",
});

----------------------------------------

TITLE: Installing LangChain Core and Community Packages
DESCRIPTION: Command to install the required LangChain packages for using Baidu Wenxin models.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core

----------------------------------------

TITLE: Creating USearch Index from Loader in TypeScript
DESCRIPTION: This snippet illustrates how to create a USearch index from documents loaded using a TextLoader in LangChain.js. It shows the process of loading documents, creating the vector store, and performing similarity searches.

LANGUAGE: typescript
CODE:
import { OpenAIEmbeddings } from "@langchain/openai";
import { USearch } from "@langchain/community/vectorstores/usearch";
import { TextLoader } from "langchain/document_loaders/fs/text";

// Load the documents and create the vector store
const loader = new TextLoader("src/document_loaders/example_data/example.txt");
const docs = await loader.load();

const vectorStore = await USearch.fromDocuments(docs, new OpenAIEmbeddings());

// Search for similar documents
const resultOne = await vectorStore.similaritySearch("Hello world", 1);
console.log(resultOne);

----------------------------------------

TITLE: Installing Redis Dependency for LangChain.js
DESCRIPTION: This snippet demonstrates how to install the ioredis package, which is required for using Redis as a cache backend in LangChain.js.

LANGUAGE: bash
CODE:
npm install ioredis

----------------------------------------

TITLE: Installing Required Dependencies
DESCRIPTION: Command to install the necessary npm packages for using libSQL vector store with LangChain.js

LANGUAGE: bash
CODE:
npm install @libsql/client @langchain/openai @langchain/community

----------------------------------------

TITLE: Installing Dependencies for .doc File Processing
DESCRIPTION: This snippet demonstrates the installation of required packages for handling .doc files using npm or yarn.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core word-extractor

----------------------------------------

TITLE: Initializing DeepInfra Embeddings
DESCRIPTION: Creates a new instance of DeepInfraEmbeddings with configuration options including API token, model name, and batch size

LANGUAGE: typescript
CODE:
import { DeepInfraEmbeddings } from "@langchain/community/embeddings/deepinfra";

const embeddings = new DeepInfraEmbeddings({
  apiToken: "YOUR_API_TOKEN",
  modelName: "sentence-transformers/clip-ViT-B-32", // Optional, defaults to "sentence-transformers/clip-ViT-B-32"
  batchSize: 1024, // Optional, defaults to 1024
});

----------------------------------------

TITLE: Installing LangChain Dependencies for AlephAlpha
DESCRIPTION: Commands to install the required LangChain packages for using AlephAlpha models.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core

----------------------------------------

TITLE: Using OpenAI API Key with AzureOpenAI
DESCRIPTION: TypeScript code showing how to use an OpenAI API key with AzureOpenAI for compatibility with the OpenAI API.

LANGUAGE: typescript
CODE:
import { AzureOpenAI, OpenAIKeyCredential } from "@langchain/azure-openai";

const model = new AzureOpenAI({
  modelName: "gpt-3.5-turbo",
  credentials: new OpenAIKeyCredential("<your_openai_api_key>"),
});

----------------------------------------

TITLE: Installing Momento SDK for Node.js
DESCRIPTION: Command to install the Momento Client Library for Node.js environments using npm.

LANGUAGE: bash
CODE:
npm install @gomomento/sdk

----------------------------------------

TITLE: Indexing Documents in Tigris Vector Store
DESCRIPTION: Example of initializing Tigris vector store and indexing documents using OpenAI embeddings. Demonstrates document creation with metadata and content.

LANGUAGE: typescript
CODE:
import { VectorDocumentStore } from "@tigrisdata/vector";
import { Document } from "langchain/document";
import { OpenAIEmbeddings } from "@langchain/openai";
import { TigrisVectorStore } from "langchain/vectorstores/tigris";

const index = new VectorDocumentStore({
  connection: {
    serverUrl: "api.preview.tigrisdata.cloud",
    projectName: process.env.TIGRIS_PROJECT,
    clientId: process.env.TIGRIS_CLIENT_ID,
    clientSecret: process.env.TIGRIS_CLIENT_SECRET,
  },
  indexName: "examples_index",
  numDimensions: 1536, // match the OpenAI embedding size
});

const docs = [
  new Document({
    metadata: { foo: "bar" },
    pageContent: "tigris is a cloud-native vector db",
  }),
  new Document({
    metadata: { foo: "bar" },
    pageContent: "the quick brown fox jumped over the lazy dog",
  }),
  new Document({
    metadata: { baz: "qux" },
    pageContent: "lorem ipsum dolor sit amet",
  }),
  new Document({
    metadata: { baz: "qux" },
    pageContent: "tigris is a river",
  }),
];

await TigrisVectorStore.fromDocuments(docs, new OpenAIEmbeddings(), { index });

----------------------------------------

TITLE: Customizing Ollama Functions System Prompt
DESCRIPTION: Demonstrates how to customize the system prompt for Ollama Functions model to improve performance with different models.

LANGUAGE: typescript
CODE:
const model = new OllamaFunctions({
  temperature: 0.1,
  model: "mistral",
  systemPrompt: "When I provide you with tools, ALWAYS use them by providing the name and arguments matching the exact schema I provide. NEVER skip using the tools. NEVER make up argument names."
});

----------------------------------------

TITLE: Installing LangChain Dependencies for Minimax Integration
DESCRIPTION: This snippet shows how to install the necessary LangChain packages for integrating with Minimax chat models.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core

----------------------------------------

TITLE: Setting up LangSmith tracing environment variables
DESCRIPTION: Configuration of environment variables needed to enable tracing with LangSmith debugging service

LANGUAGE: shell
CODE:
export LANGSMITH_TRACING="true"
export LANGSMITH_API_KEY="..."

# Reduce tracing latency if you are not in a serverless environment
# export LANGCHAIN_CALLBACKS_BACKGROUND=true

----------------------------------------

TITLE: Setting up Neo4j with Docker Compose
DESCRIPTION: Docker Compose configuration for quickly setting up a self-hosted Neo4j database instance.

LANGUAGE: yml
CODE:
version: '3'
services:
  neo4j:
    image: neo4j:5.11.0-enterprise
    ports:
      - 7474:7474
      - 7687:7687
    volumes:
      - ./data:/data
      - ./logs:/logs
      - ./import:/import
      - ./plugins:/plugins
    environment:
      - NEO4J_AUTH=neo4j/pleaseletmein
      - NEO4J_PLUGINS=["graph-data-science", "apoc"]
      - NEO4J_dbms_security_procedures_unrestricted=gds.*,apoc.*
      - NEO4J_dbms_security_procedures_allowlist=gds.*,apoc.*
      - NEO4J_gds_enterprise_license_file=/licenses/gds.license
      - NEO4J_ACCEPT_LICENSE_AGREEMENT=yes
    healthcheck:
      test: ["CMD-SHELL", "echo 'RETURN 1' | cypher-shell -u neo4j -p pleaseletmein || exit 1"]
      interval: 10s
      timeout: 10s
      retries: 5

----------------------------------------

TITLE: Installing OpenAI Package for LangChain
DESCRIPTION: Command to install the OpenAI integration package for LangChain.

LANGUAGE: bash
CODE:
npm install -S @langchain/openai

----------------------------------------

TITLE: Installing Azure Cosmos DB and LangChain Core Dependencies
DESCRIPTION: Command to install the required npm packages for Azure Cosmos DB NoSQL integration and LangChain core functionality.

LANGUAGE: bash
CODE:
npm install @langchain/azure-cosmosdb @langchain/core

----------------------------------------

TITLE: Configuring Package.json for Azure OpenAI Integration
DESCRIPTION: JSON configuration in package.json to ensure consistent @langchain/core dependency across different package managers.

LANGUAGE: json
CODE:
{
  "name": "your-project",
  "version": "0.0.0",
  "dependencies": {
    "@langchain/azure-openai": "^0.0.4",
    "@langchain/core": "^0.3.0"
  },
  "resolutions": {
    "@langchain/core": "^0.3.0"
  },
  "overrides": {
    "@langchain/core": "^0.3.0"
  },
  "pnpm": {
    "overrides": {
      "@langchain/core": "^0.3.0"
    }
  }
}

----------------------------------------

TITLE: Running Prisma Migration
DESCRIPTION: Command to execute the Prisma migration.

LANGUAGE: bash
CODE:
npx prisma migrate dev

----------------------------------------

TITLE: Importing Documentation Components in JSX/MDX
DESCRIPTION: Import statement for React components used to display feature tables in the documentation.

LANGUAGE: jsx
CODE:
import { CategoryTable, IndexTable } from "@theme/FeatureTables";

----------------------------------------

TITLE: Instantiating Neo4jVectorStore from Existing Graph
DESCRIPTION: Example demonstrating how to instantiate Neo4jVectorStore from an existing graph in the database.

LANGUAGE: typescript
CODE:
import { Neo4jVectorStore } from "@langchain/community/vectorstores/neo4j_vector";
import { OpenAIEmbeddings } from "@langchain/openai";
import { Neo4jGraph } from "@langchain/community/graphs/neo4j_graph";
import neo4j from "neo4j-driver";

const driver = neo4j.driver(
  "bolt://localhost:7687",
  neo4j.auth.basic("neo4j", "pleaseletmein")
);

const graph = await Neo4jGraph.initialize({ driver });

const vectorStore = await Neo4jVectorStore.fromExistingGraph(
  graph,
  new OpenAIEmbeddings(),
  {
    textNodeProperty: "text",
    embeddingNodeProperty: "embedding",
    keywordIndexName: "keyword",
    indexName: "vector",
    searchType: "hybrid",
  }
);

const results = await vectorStore.similaritySearch("hello", 1);
console.log(results);

await driver.close();

----------------------------------------

TITLE: Chat Model Configuration
DESCRIPTION: Setting up the ChatOpenAI model instance with specific parameters

LANGUAGE: typescript
CODE:
const llm = new ChatOpenAI({
  model: "gpt-4o-2024-05-13",
  temperature: 0,
});

----------------------------------------

TITLE: Configuring Vectara Environment Variables
DESCRIPTION: Environment variable configuration required for connecting LangChain to a Vectara corpus.

LANGUAGE: plaintext
CODE:
VECTARA_CUSTOMER_ID=your_customer_id
VECTARA_CORPUS_ID=your_corpus_id
VECTARA_API_KEY=your-vectara-api-key

----------------------------------------

TITLE: Installing Dependencies for LangChain Parallel Execution
DESCRIPTION: Installs the necessary npm packages for using Anthropic, Cohere, and LangChain core functionalities.

LANGUAGE: bash
CODE:
npm install @langchain/anthropic @langchain/cohere @langchain/core

----------------------------------------

TITLE: Building the @langchain/ollama package
DESCRIPTION: Commands to build the package, either directly or from the repo root.

LANGUAGE: bash
CODE:
yarn build

LANGUAGE: bash
CODE:
yarn build --filter=@langchain/ollama

----------------------------------------

TITLE: Querying Zep Vector Store with Metadata Filters
DESCRIPTION: Demonstrates how to query the Zep Vector Store using metadata filters to refine search results.

LANGUAGE: typescript
CODE:
{ExampleMetadata}

----------------------------------------

TITLE: Publishing Package Command
DESCRIPTION: Command to publish the package after building.

LANGUAGE: bash
CODE:
npm publish

----------------------------------------

TITLE: Installing AWS DynamoDB Dependencies
DESCRIPTION: Commands to install the required AWS DynamoDB client package for LangChain.js integration.

LANGUAGE: bash
CODE:
npm install @aws-sdk/client-dynamodb

----------------------------------------

TITLE: Querying Documents from Existing MyScale Collection in TypeScript
DESCRIPTION: This snippet shows how to query documents from an existing MyScale collection using TypeScript. It includes setting up the MyScale client, creating embeddings, and performing similarity searches on the vector store.

LANGUAGE: typescript
CODE:
SearchExample

----------------------------------------

TITLE: Installing Redis Dependencies for Caching in npm
DESCRIPTION: This bash command installs the necessary dependencies for using Redis-based caching in LangChain.js, including ioredis, @langchain/community, and @langchain/core.

LANGUAGE: bash
CODE:
npm install ioredis @langchain/community @langchain/core

----------------------------------------

TITLE: Memory Use Cases Table
DESCRIPTION: Table showing the three main use cases for LangChain 0.0.x memory implementations, including conversation history management, structured information extraction, and composite memory implementations.

LANGUAGE: markdown
CODE:
| Use Case                             | Example                                                                                                                           |
| ------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------- |
| Managing conversation history        | Keep only the last `n` turns of the conversation between the user and the AI.                                                     |
| Extraction of structured information | Extract structured information from the conversation history, such as a list of facts learned about the user.                     |
| Composite memory implementations     | Combine multiple memory sources, e.g., a list of known facts about the user along with facts learned during a given conversation. |

----------------------------------------

TITLE: Tool Binding Configuration
DESCRIPTION: Binding the weather tool schema to the language model with function calling capability.

LANGUAGE: typescript
CODE:
const modelWithTools = llm.bind({
  tools: [
    {
      type: "function" as const,
      function: {
        name: "get_weather",
        description: Weather.description,
        parameters: zodToJsonSchema(Weather),
      },
    },
  ],
});

----------------------------------------

TITLE: Installing Required Packages for Neon Postgres Integration
DESCRIPTION: Commands to install the necessary packages for working with Neon Postgres in a LangChain.js project. This includes the Neon database driver and LangChain community packages.

LANGUAGE: bash
CODE:
npm install @neondatabase/serverless

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core

----------------------------------------

TITLE: Agent Function Definition
DESCRIPTION: Basic structure of the runAgent server function with input parameter

LANGUAGE: typescript
CODE:
export async function runAgent(input: string) {
  "use server";
}

----------------------------------------

TITLE: Setting Turbopuffer API Key Environment Variable
DESCRIPTION: Configuration step to set the Turbopuffer API key as an environment variable for authentication.

LANGUAGE: bash
CODE:
export TURBOPUFFER_API_KEY=<YOUR_API_KEY>

----------------------------------------

TITLE: Testing and Code Quality Commands
DESCRIPTION: Commands for running tests, linting, and formatting the codebase.

LANGUAGE: bash
CODE:
yarn test
yarn test:int
yarn lint && yarn format

----------------------------------------

TITLE: Creating LanceDB Index from Document Loader
DESCRIPTION: Example demonstrating how to create a new vector store index in LanceDB using a document loader in Typescript.

LANGUAGE: typescript
CODE:
{ExampleLoader}

----------------------------------------

TITLE: Installing Upstash Redis for Caching
DESCRIPTION: Command to install the Upstash Redis package for caching in LangChain.

LANGUAGE: bash
CODE:
npm install @upstash/redis

----------------------------------------

TITLE: Building Static Website
DESCRIPTION: Command to generate static website content in the build directory for production deployment.

LANGUAGE: bash
CODE:
$ yarn build

----------------------------------------

TITLE: Creating LanceDB Index from Texts
DESCRIPTION: Example showing how to create a new vector store index in LanceDB from text data using Typescript and LangChain.

LANGUAGE: typescript
CODE:
{ExampleTexts}

----------------------------------------

TITLE: Setting Tavily API Key
DESCRIPTION: Environment variable configuration for Tavily search tool

LANGUAGE: bash
CODE:
export TAVILY_API_KEY=your_api_key

----------------------------------------

TITLE: Installing LangChain Dependencies
DESCRIPTION: Command to install required LangChain packages for integration.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/community @langchain/core

----------------------------------------

TITLE: Running Tests
DESCRIPTION: Commands for running unit tests and integration tests for the Redis package.

LANGUAGE: bash
CODE:
$ yarn test
$ yarn test:int

----------------------------------------

TITLE: Initializing Vercel Postgres Vector Store
DESCRIPTION: This code snippet shows how to initialize a Vercel Postgres vector store with a custom connection string. It uses OpenAIEmbeddings and specifies the Postgres connection options.

LANGUAGE: typescript
CODE:
const vectorstore = await VercelPostgres.initialize(new OpenAIEmbeddings(), {
  postgresConnectionOptions: {
    connectionString:
      "postgres://<username>:<password>@<hostname>:<port>/<dbname>",
  },
});

----------------------------------------

TITLE: Creating Prisma Migration
DESCRIPTION: Command to create a new Prisma migration without executing it.

LANGUAGE: bash
CODE:
npx prisma migrate dev --create-only

----------------------------------------

TITLE: Implementing Streaming with ChatAnthropic
DESCRIPTION: Example of using streaming functionality with the ChatAnthropic model.

LANGUAGE: typescript
CODE:
import { ChatAnthropic } from "@langchain/anthropic";

const model = new ChatAnthropic({
  apiKey: process.env.ANTHROPIC_API_KEY,
  model: "claude-3-sonnet-20240229",
});
const response = await model.stream({
  role: "user",
  content: "Hello world!",
});

----------------------------------------

TITLE: Installing Required Dependencies for Sort.xyz Integration
DESCRIPTION: Command to install necessary npm packages including LangChain community modules, core functionality, and OpenAI integration.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core @langchain/openai

----------------------------------------

TITLE: Installing Dependencies for Google Vertex AI Matching Engine in Node.js
DESCRIPTION: Commands to install the required npm packages for using Google Vertex AI Matching Engine and Google Cloud Storage with LangChain.js.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core google-auth-library

LANGUAGE: bash
CODE:
npm install @google-cloud/storage

----------------------------------------

TITLE: Installing @langchain/ollama and @langchain/core packages
DESCRIPTION: Command to install the required packages using npm or yarn.

LANGUAGE: bash
CODE:
npm install @langchain/ollama @langchain/core

----------------------------------------

TITLE: Installing Azure AI Search Dependencies
DESCRIPTION: Installation command for required packages to use Azure AI Search vector store.

LANGUAGE: bash
CODE:
npm install -S @langchain/community @langchain/core @azure/search-documents

----------------------------------------

TITLE: Extending BufferLoader in TypeScript
DESCRIPTION: This snippet shows the BufferLoader abstract class. When extending this class for binary file loading, you need to implement the parse() method to process the raw buffer and metadata.

LANGUAGE: typescript
CODE:
abstract class BufferLoader extends BaseDocumentLoader {
  abstract parse(
    raw: Buffer,
    metadata: Document["metadata"]
  ): Promise<Document[]>;
}

----------------------------------------

TITLE: Hybrid Search with SingleStoreVectorStore in LangChain.js
DESCRIPTION: Example demonstrating how to use hybrid search strategies with SingleStoreVectorStore. It shows different search strategies like VECTOR_ONLY, TEXT_ONLY, FILTER_BY_TEXT, FILTER_BY_VECTOR, and WEIGHTED_SUM.

LANGUAGE: typescript
CODE:
import { OpenAIEmbeddings } from "@langchain/openai";
import { SingleStoreVectorStore } from "@langchain/community/vectorstores/singlestore";

// Configure the connection
const connectionConfig = {
  host: "localhost",
  port: 3306,
  user: "root",
  password: "password",
  database: "vectordb",
};

const vectorStore = await SingleStoreVectorStore.fromTexts(
  ["Hello world", "Bye bye", "hello nice world"],
  [{ id: 2 }, { id: 1 }, { id: 3 }],
  new OpenAIEmbeddings(),
  connectionConfig
);

// VECTOR_ONLY strategy (default)
const vectorOnlyResult = await vectorStore.similaritySearch("hello world", 1);
console.log(vectorOnlyResult);

// TEXT_ONLY strategy
const textOnlyResult = await vectorStore.similaritySearch("hello world", 1, {}, {
  strategy: "TEXT_ONLY",
});
console.log(textOnlyResult);

// FILTER_BY_TEXT strategy
const filterByTextResult = await vectorStore.similaritySearch(
  "hello world",
  1,
  {},
  {
    strategy: "FILTER_BY_TEXT",
  }
);
console.log(filterByTextResult);

// FILTER_BY_VECTOR strategy
const filterByVectorResult = await vectorStore.similaritySearch(
  "hello world",
  1,
  {},
  {
    strategy: "FILTER_BY_VECTOR",
  }
);
console.log(filterByVectorResult);

// WEIGHTED_SUM strategy
const weightedSumResult = await vectorStore.similaritySearch(
  "hello world",
  1,
  {},
  {
    strategy: "WEIGHTED_SUM",
    vectorWeight: 0.7,
    textWeight: 0.3,
  }
);
console.log(weightedSumResult);

await vectorStore.end();


----------------------------------------

TITLE: Markdown Documentation Structure
DESCRIPTION: Basic markdown header structure showing sidebar label configuration for the style guide document.

LANGUAGE: markdown
CODE:
---
sidebar_label: "Style guide"
---

----------------------------------------

TITLE: Installing Milvus Node.js SDK
DESCRIPTION: Command to install the Milvus Node.js SDK using npm or yarn.

LANGUAGE: bash
CODE:
npm install -S @zilliz/milvus2-sdk-node

----------------------------------------

TITLE: Importing Few Shot Prompt Templates in TypeScript
DESCRIPTION: Import statements for ChatPromptTemplate and FewShotChatMessagePromptTemplate from langchain/prompts.

LANGUAGE: typescript
CODE:
import {
  ChatPromptTemplate,
  FewShotChatMessagePromptTemplate,
} from "langchain/prompts";

----------------------------------------

TITLE: Installing Required Dependencies for Couchbase Vector Store
DESCRIPTION: Command to install necessary packages for using Couchbase vector store with LangChain and OpenAI embeddings.

LANGUAGE: bash
CODE:
npm install couchbase @langchain/openai @langchain/community @langchain/core

----------------------------------------

TITLE: Installing Google Vertex AI Package for LangChain
DESCRIPTION: Command to install the @langchain/google-vertexai package using yarn package manager.

LANGUAGE: bash
CODE:
$ yarn add @langchain/google-vertexai

----------------------------------------

TITLE: Installing Azure Container Apps Dependencies
DESCRIPTION: Installation command for Azure Container Apps dynamic sessions integration.

LANGUAGE: bash
CODE:
npm install @langchain/azure-dynamic-sessions @langchain/core

----------------------------------------

TITLE: Querying Existing ClickHouse Collection
DESCRIPTION: Code reference for demonstrating how to search and query documents from an existing ClickHouse vector store collection.

LANGUAGE: typescript
CODE:
{SearchExample}

----------------------------------------

TITLE: Running a Single Test in LangChain.js
DESCRIPTION: This command allows running a specific test file, which is useful for developing individual features. It should be executed from within a workspace directory.

LANGUAGE: bash
CODE:
yarn test:single /path/to/yourtest.test.ts

----------------------------------------

TITLE: Installing Zep Cloud Dependencies
DESCRIPTION: Command to install required npm packages for using Zep Cloud with LangChain

LANGUAGE: bash
CODE:
npm install @getzep/zep-cloud @langchain/openai @langchain/community @langchain/core

----------------------------------------

TITLE: Installing Voy Dependencies
DESCRIPTION: Command to install required packages for using Voy with LangChain.js, including OpenAI integration, Voy search engine, and core LangChain components.

LANGUAGE: bash
CODE:
npm install @langchain/openai voy-search @langchain/community @langchain/core

----------------------------------------

TITLE: Installing Required Packages for LangChain and SerpAPI Integration
DESCRIPTION: This code snippet shows how to install the necessary npm packages for using LangChain with SerpAPI and OpenAI.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core @langchain/openai

----------------------------------------

TITLE: Adding Documents to Vector Store
DESCRIPTION: TypeScript example showing how to add documents with metadata to the vector store

LANGUAGE: typescript
CODE:
import type { Document } from "@langchain/core/documents";

const documents: Document[] = [
  { pageContent: "Hello", metadata: { topic: "greeting" } },
  { pageContent: "Bye bye", metadata: { topic: "greeting" } },
];

await vectorStore.addDocuments(documents);

----------------------------------------

TITLE: Rendering Tools Index Table Component
DESCRIPTION: JSX component usage for displaying a table of all available tools in the documentation.

LANGUAGE: jsx
CODE:
<IndexTable />

----------------------------------------

TITLE: Installing Redis Sentinel Dependencies
DESCRIPTION: Command to install ioredis package for Redis Sentinel support.

LANGUAGE: bash
CODE:
npm install ioredis

----------------------------------------

TITLE: Azure Cosmos DB MongoDB Vector Store Implementation
DESCRIPTION: TypeScript implementation showing document indexing, vector search querying, and natural language question answering using Azure Cosmos DB for MongoDB vCore

LANGUAGE: typescript
CODE:
Example

----------------------------------------

TITLE: Installing Vercel Postgres Package
DESCRIPTION: This snippet shows how to install the @vercel/postgres package using npm or yarn.

LANGUAGE: bash
CODE:
npm install @vercel/postgres

----------------------------------------

TITLE: Installing Azure OpenAI Dependencies
DESCRIPTION: Installation command for required packages to use Azure OpenAI with LangChain.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/core

----------------------------------------

TITLE: Importing Azure Storage Loaders
DESCRIPTION: TypeScript import statements for Azure Blob Storage and File Storage document loaders.

LANGUAGE: typescript
CODE:
import { AzureBlobStorageContainerLoader } from "@langchain/community/document_loaders/web/azure_blob_storage_container";
import { AzureBlobStorageFileLoader } from "@langchain/community/document_loaders/web/azure_blob_storage_file";

----------------------------------------

TITLE: Installing pg-copy-streams for Batch Vector Operations
DESCRIPTION: This command installs the pg-copy-streams package, which is needed for efficiently adding batch vectors to AnalyticDB.

LANGUAGE: bash
CODE:
npm install -S pg-copy-streams

----------------------------------------

TITLE: Using Toolkits in TypeScript
DESCRIPTION: Demonstrates how to initialize a toolkit and retrieve its associated tools using the getTools method.

LANGUAGE: typescript
CODE:
// Initialize a toolkit
const toolkit = new ExampleTookit(...)

// Get list of tools
const tools = toolkit.getTools()

----------------------------------------

TITLE: Creating Vector Store Table Schema
DESCRIPTION: SQL commands to create the necessary table structure for storing vectors with metadata and create an index for vector similarity search

LANGUAGE: sql
CODE:
CREATE TABLE IF NOT EXISTS TABLE_NAME (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    content TEXT,
    metadata TEXT,
    EMBEDDING_COLUMN F32_BLOB(1536) -- 1536-dimensional f32 vector for OpenAI
);

LANGUAGE: sql
CODE:
CREATE INDEX IF NOT EXISTS idx_TABLE_NAME_EMBEDDING_COLUMN ON TABLE_NAME(libsql_vector_idx(EMBEDDING_COLUMN));

----------------------------------------

TITLE: Initializing Vespa Retriever in TypeScript for LangChain
DESCRIPTION: This code snippet demonstrates how to create a Vespa retriever for LangChain. It sets up a retriever that fetches up to 5 results from the 'content' field in the 'paragraph' document type, using 'documentation' as the ranking method.

LANGUAGE: typescript
CODE:
import { VespaRetriever } from "langchain/retrievers/vespa";

const retriever = new VespaRetriever({
  url: "https://doc-search.vespa.oath.cloud",
  query: (query: string) => ({
    yql: "select content from paragraph where userQuery()",
    query,
    ranking: "documentation",
    hits: 5,
  }),
});

const docs = await retriever.getRelevantDocuments("what is vespa?");

----------------------------------------

TITLE: Configuring Azure Cosmos DB Environment Variables
DESCRIPTION: Environment variables required for connecting to Azure Cosmos DB instance including connection string and database configuration

LANGUAGE: text
CODE:
AZURE_COSMOSDB_MONGODB_CONNECTION_STRING="your-connection-string"
AZURE_COSMOSDB_MONGODB_DBNAME="your-db-name"
AZURE_COSMOSDB_MONGODB_COLLECTIONNAME="your-collection-name"

----------------------------------------

TITLE: Installing mysql2 Client for SingleStoreDB in Node.js
DESCRIPTION: Command to install the mysql2 JavaScript client, which is required for LangChain.js to connect to a SingleStoreDB instance.

LANGUAGE: bash
CODE:
npm install -S mysql2

----------------------------------------

TITLE: Installing Neo4j Driver and LangChain Dependencies
DESCRIPTION: Commands to install the required Neo4j driver and LangChain packages using npm or yarn.

LANGUAGE: bash
CODE:
npm install neo4j-driver

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/community @langchain/core

----------------------------------------

TITLE: Installing LangChain Dependencies
DESCRIPTION: Command to install required npm packages for LangChain OpenAI and core functionality.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/core

----------------------------------------

TITLE: Initializing Astra DB Chat History Directly
DESCRIPTION: Shows how to initialize AstraDBChatMessageHistory using the initialize method without an existing client. Requires token, endpoint, namespace, collection name, and session ID.

LANGUAGE: typescript
CODE:
const chatHistory = await AstraDBChatMessageHistory.initialize({
  token: process.env.ASTRA_DB_APPLICATION_TOKEN ?? "token",
  endpoint: process.env.ASTRA_DB_ENDPOINT ?? "endpoint",
  namespace: process.env.ASTRA_DB_NAMESPACE,
  collectionName: "YOUR_COLLECTION_NAME",
  sessionId: "YOUR_SESSION_ID",
});

----------------------------------------

TITLE: Installing LangChain Community and Core Packages
DESCRIPTION: Command to install the required LangChain packages for using the Chaindesk Retriever.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core

----------------------------------------

TITLE: Setting Momento Environment Variable
DESCRIPTION: Command to set the Momento API key as an environment variable.

LANGUAGE: bash
CODE:
export MOMENTO_API_KEY=YOUR_MOMENTO_API_KEY_HERE

----------------------------------------

TITLE: Importing Connery Dependencies
DESCRIPTION: Import statements for required components including CodeBlock, Example component, and integration tooltip.

LANGUAGE: typescript
CODE:
import CodeBlock from "@theme/CodeBlock";
import Example from "@examples/tools/connery.ts";
import IntegrationInstallTooltip from "@mdx_components/integration_install_tooltip.mdx";

----------------------------------------

TITLE: Creating HNSW Vector Index
DESCRIPTION: Demonstrates creation of a Hierarchical Navigable Small World (HNSW) vector index for optimized top-k nearest neighbor queries.

LANGUAGE: typescript
CODE:
import ExampleIndex from "@examples/indexes/vector_stores/hana_vector/createHnswIndex.ts";

----------------------------------------

TITLE: Importing Bedrock Chat Model
DESCRIPTION: Import statement for the AWS Bedrock chat model integration.

LANGUAGE: typescript
CODE:
import { BedrockChat } from "@langchain/community/chat_models/bedrock";

----------------------------------------

TITLE: Installing Momento SDK for Node.js
DESCRIPTION: Command to install the Momento SDK package for Node.js environments.

LANGUAGE: bash
CODE:
npm install @gomomento/sdk

----------------------------------------

TITLE: Remote Browser Implementation with Browserbase
DESCRIPTION: Example of implementing Stagehand toolkit with a remote browser setup using Browserbase platform.

LANGUAGE: typescript
CODE:
const stagehand = new Stagehand({
  env: "BROWSERBASE",
});

----------------------------------------

TITLE: Installing Momento SDK for Browser/Edge
DESCRIPTION: Command to install the Momento SDK package for browser or edge environments.

LANGUAGE: bash
CODE:
npm install @gomomento/sdk-web

----------------------------------------

TITLE: Importing Dall-E Tool Example
DESCRIPTION: Example code imported from an external file showing Dall-E tool implementation. Note: Actual code content is referenced but not shown in the original text.

LANGUAGE: typescript
CODE:
// Content referenced from @examples/tools/dalle_image_generation.ts

----------------------------------------

TITLE: Installing Zep Cloud and LangChain Dependencies
DESCRIPTION: This snippet shows the command to install the necessary npm packages for using Zep Cloud with LangChain. It includes the Zep Cloud SDK, LangChain community package, and LangChain core package.

LANGUAGE: bash
CODE:
npm i @getzep/zep-cloud @langchain/community @langchain/core

----------------------------------------

TITLE: Installing dependencies for development
DESCRIPTION: This command installs the necessary dependencies for developing the @langchain/groq package using Yarn.

LANGUAGE: bash
CODE:
yarn install

----------------------------------------

TITLE: Installing SAP HANA Vector Engine Dependencies
DESCRIPTION: Commands to install required npm packages including LangChain community package and either SAP HANA client or HDB driver.

LANGUAGE: bash
CODE:
npm install -S @langchain/community @langchain/core @sap/hana-client
# or
npm install -S @langchain/community @langchain/core hdb

----------------------------------------

TITLE: Installing Anthropic and Core Dependencies for LangChain.js
DESCRIPTION: Command to install the necessary npm packages for using Anthropic models with LangChain.js. This includes the Anthropic-specific package and the core LangChain package.

LANGUAGE: bash
CODE:
npm install @langchain/anthropic @langchain/core

----------------------------------------

TITLE: Installing Required Packages for Stagehand
DESCRIPTION: Commands to install the necessary npm packages and Playwright browser dependencies for Stagehand toolkit.

LANGUAGE: bash
CODE:
npm install @langchain/langgraph @langchain/community @langchain/core

LANGUAGE: bash
CODE:
npx playwright install

----------------------------------------

TITLE: Installing CloseVector Node Package
DESCRIPTION: Command to install the CloseVector Node.js package for server environments using npm.

LANGUAGE: bash
CODE:
npm install -S closevector-node

----------------------------------------

TITLE: Installing PDF Parse Dependency
DESCRIPTION: Install the required pdf-parse package for PDF document processing

LANGUAGE: bash
CODE:
npm install pdf-parse

----------------------------------------

TITLE: Implementing JSON Agent with OpenAI
DESCRIPTION: Complete implementation of a JSON agent that processes OpenAPI specifications using LangChain and OpenAI. The code reads a YAML file containing OpenAPI specs, creates a JSON toolkit, and executes queries against the specification using an AI agent.

LANGUAGE: typescript
CODE:
import * as fs from "fs";
import * as yaml from "js-yaml";
import { OpenAI } from "@langchain/openai";
import { JsonSpec, JsonObject } from "langchain/tools";
import { JsonToolkit, createJsonAgent } from "langchain/agents";

export const run = async () => {
  let data: JsonObject;
  try {
    const yamlFile = fs.readFileSync("openai_openapi.yaml", "utf8");
    data = yaml.load(yamlFile) as JsonObject;
    if (!data) {
      throw new Error("Failed to load OpenAPI spec");
    }
  } catch (e) {
    console.error(e);
    return;
  }

  const toolkit = new JsonToolkit(new JsonSpec(data));
  const model = new OpenAI({ temperature: 0 });
  const executor = createJsonAgent(model, toolkit);

  const input = `What are the required parameters in the request body to the /completions endpoint?`;

  console.log(`Executing with input "${input}"...`);

  const result = await executor.invoke({ input });

  console.log(`Got output ${result.output}`);

  console.log(
    `Got intermediate steps ${JSON.stringify(
      result.intermediateSteps,
      null,
      2
    )}`
  );
};

----------------------------------------

TITLE: Running CI Checks
DESCRIPTION: Command to run continuous integration checks for linting and formatting.

LANGUAGE: bash
CODE:
$ yarn ci

----------------------------------------

TITLE: Installing LangChain OpenAI and Core Dependencies
DESCRIPTION: Command to install the necessary npm packages for using OpenAI with LangChain.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/core

----------------------------------------

TITLE: Setting Environment Variables for OpenAI and LangSmith
DESCRIPTION: This code block sets up environment variables for OpenAI API key and optionally for LangSmith tracing. It also includes a commented option to reduce tracing latency in non-serverless environments.

LANGUAGE: bash
CODE:
export OPENAI_API_KEY="your api key"
# Uncomment the below to use LangSmith. Not required.
# export LANGSMITH_API_KEY="your api key"
# export LANGSMITH_TRACING=true

# Reduce tracing latency if you are not in a serverless environment
# export LANGCHAIN_CALLBACKS_BACKGROUND=true

----------------------------------------

TITLE: Retrieving Table Definitions and Example Rows
DESCRIPTION: This TypeScript code demonstrates how to fetch table names, their schemas, and sample rows from each table in the database.

LANGUAGE: typescript
CODE:
<CodeBlock language="typescript">{TableDefinitionsExample}</CodeBlock>

----------------------------------------

TITLE: Installing Writer SDK Dependencies
DESCRIPTION: Commands to install the required Writer SDK and LangChain packages using npm or yarn.

LANGUAGE: bash
CODE:
yarn add @writerai/writer-sdk

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core

----------------------------------------

TITLE: Installing DynamoDB SDK
DESCRIPTION: NPM command to install the AWS DynamoDB client SDK dependency.

LANGUAGE: bash
CODE:
npm install @aws-sdk/client-dynamodb

----------------------------------------

TITLE: Installing Required Dependencies
DESCRIPTION: Installation commands for required npm packages including LangChain OpenAI integration and core components.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/core

----------------------------------------

TITLE: Installing LangChain.js dependencies
DESCRIPTION: Command to install necessary LangChain.js packages for integration with OpenAI and community resources.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/community @langchain/core

----------------------------------------

TITLE: Importing LangChain.js Modules in Deno
DESCRIPTION: This snippet shows how to import LangChain.js modules in Deno using URL imports, which is different from Node.js import syntax.

LANGUAGE: javascript
CODE:
import { PromptTemplate } from "https://esm.sh/langchain/prompts";

----------------------------------------

TITLE: Installing Core LangChain Packages
DESCRIPTION: Basic installation command for the main LangChain packages using npm or yarn.

LANGUAGE: bash
CODE:
npm install langchain @langchain/core

----------------------------------------

TITLE: Development Setup Commands
DESCRIPTION: Series of commands for setting up the development environment, including dependency installation and package building.

LANGUAGE: bash
CODE:
yarn install

LANGUAGE: bash
CODE:
yarn build

LANGUAGE: bash
CODE:
yarn build --filter=@langchain/pinecone

----------------------------------------

TITLE: Installing LangChain Dependencies
DESCRIPTION: Commands to install required LangChain packages including OpenAI, community modules, and core functionality.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/community @langchain/core

----------------------------------------

TITLE: Configuring Azure PromptLayer OpenAI Integration in TypeScript
DESCRIPTION: Example demonstrating how to initialize PromptLayerOpenAI with Azure-hosted OpenAI. Includes all necessary Azure configuration parameters and PromptLayer API key setup for logging and monitoring.

LANGUAGE: typescript
CODE:
import { PromptLayerOpenAI } from "langchain/llms/openai";

const model = new PromptLayerOpenAI({
  temperature: 0.9,
  azureOpenAIApiKey: "YOUR-AOAI-API-KEY", // In Node.js defaults to process.env.AZURE_OPENAI_API_KEY
  azureOpenAIApiInstanceName: "YOUR-AOAI-INSTANCE-NAME", // In Node.js defaults to process.env.AZURE_OPENAI_API_INSTANCE_NAME
  azureOpenAIApiDeploymentName: "YOUR-AOAI-DEPLOYMENT-NAME", // In Node.js defaults to process.env.AZURE_OPENAI_API_DEPLOYMENT_NAME
  azureOpenAIApiCompletionsDeploymentName: "YOUR-AOAI-COMPLETIONS-DEPLOYMENT-NAME", // In Node.js defaults to process.env.AZURE_OPENAI_API_COMPLETIONS_DEPLOYMENT_NAME
  azureOpenAIApiEmbeddingsDeploymentName: "YOUR-AOAI-EMBEDDINGS-DEPLOYMENT-NAME", // In Node.js defaults to process.env.AZURE_OPENAI_API_EMBEDDINGS_DEPLOYMENT_NAME
  azureOpenAIApiVersion: "YOUR-AOAI-API-VERSION", // In Node.js defaults to process.env.AZURE_OPENAI_API_VERSION
  azureOpenAIBasePath: "YOUR-AZURE-OPENAI-BASE-PATH", // In Node.js defaults to process.env.AZURE_OPENAI_BASE_PATH
  promptLayerApiKey: "YOUR-API-KEY", // In Node.js defaults to process.env.PROMPTLAYER_API_KEY
});
const res = await model.invoke(
  "What would be a good company name a company that makes colorful socks?"
);

----------------------------------------

TITLE: Installing LangChain Dependencies
DESCRIPTION: Command to install the required LangChain packages for using Tencent Hunyuan embeddings.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core

----------------------------------------

TITLE: Setting Upstash Redis Environment Variables
DESCRIPTION: Shows how to set the required environment variables for Upstash Redis connection.

LANGUAGE: bash
CODE:
UPSTASH_REDIS_REST_URL="****"
UPSTASH_REDIS_REST_TOKEN="****"

----------------------------------------

TITLE: Changing Directory to LangChain Community Workspace
DESCRIPTION: Command to change the current directory to the LangChain community workspace for development tasks.

LANGUAGE: bash
CODE:
cd libs/langchain-community

----------------------------------------

TITLE: Demonstrating In-Memory Caching Performance
DESCRIPTION: Example showing the performance difference between cached and uncached model invocations.

LANGUAGE: typescript
CODE:
console.time();

// The first time, it is not yet in cache, so it should take longer
const res = await model.invoke("Tell me a long joke");

console.log(res);

console.timeEnd();

/*
  A man walks into a bar and sees a jar filled with money on the counter. Curious, he asks the bartender about it.

  The bartender explains, "We have a challenge for our customers. If you can complete three tasks, you win all the money in the jar."

  Intrigued, the man asks what the tasks are.

  The bartender replies, "First, you have to drink a whole bottle of tequila without making a face. Second, there's a pitbull out back with a sore tooth. You have to pull it out. And third, there's an old lady upstairs who has never had an orgasm. You have to give her one."

  The man thinks for a moment and then confidently says, "I'll do it."

  He grabs the bottle of tequila and downs it in one gulp, without flinching. He then heads to the back and after a few minutes of struggling, emerges with the pitbull's tooth in hand.

  The bar erupts in cheers and the bartender leads the man upstairs to the old lady's room. After a few minutes, the man walks out with a big smile on his face and the old lady is giggling with delight.

  The bartender hands the man the jar of money and asks, "How

  default: 4.187s
*/

console.time();

// The second time it is, so it goes faster
const res2 = await model.invoke("Tell me a joke");

console.log(res2);

console.timeEnd();

/*
  A man walks into a bar and sees a jar filled with money on the counter. Curious, he asks the bartender about it.

  The bartender explains, "We have a challenge for our customers. If you can complete three tasks, you win all the money in the jar."

  Intrigued, the man asks what the tasks are.

  The bartender replies, "First, you have to drink a whole bottle of tequila without making a face. Second, there's a pitbull out back with a sore tooth. You have to pull it out. And third, there's an old lady upstairs who has never had an orgasm. You have to give her one."

  The man thinks for a moment and then confidently says, "I'll do it."

  He grabs the bottle of tequila and downs it in one gulp, without flinching. He then heads to the back and after a few minutes of struggling, emerges with the pitbull's tooth in hand.

  The bar erupts in cheers and the bartender leads the man upstairs to the old lady's room. After a few minutes, the man walks out with a big smile on his face and the old lady is giggling with delight.

  The bartender hands the man the jar of money and asks, "How

  default: 175.74ms
*/

----------------------------------------

TITLE: Using ChatVertexAI with Gemini Pro Vision
DESCRIPTION: Shows how to use the Gemini Pro Vision model through Vertex AI to process both text and image inputs, including reading and encoding an image file.

LANGUAGE: typescript
CODE:
const visionModel = new ChatVertexAI({
  model: "gemini-pro-vision",
  maxOutputTokens: 2048,
});
const image = fs.readFileSync("./hotdog.png").toString("base64");
const input2 = [
  new HumanMessage({
    content: [
      {
        type: "text",
        text: "Describe the following image.",
      },
      {
        type: "image_url",
        image_url: `data:image/png;base64,${image}`,
      },
    ],
  }),
];

const res = await visionModel.invoke(input2);

----------------------------------------

TITLE: Using ChatVertexAI with Gemini Pro Vision
DESCRIPTION: Shows how to use the Gemini Pro Vision model through Vertex AI to process both text and image inputs, including reading and encoding an image file.

LANGUAGE: typescript
CODE:
const visionModel = new ChatVertexAI({
  model: "gemini-pro-vision",
  maxOutputTokens: 2048,
});
const image = fs.readFileSync("./hotdog.png").toString("base64");
const input2 = [
  new HumanMessage({
    content: [
      {
        type: "text",
        text: "Describe the following image.",
      },
      {
        type: "image_url",
        image_url: `data:image/png;base64,${image}`,
      },
    ],
  }),
];

const res = await visionModel.invoke(input2);

----------------------------------------

TITLE: Installing Dependencies for LangChain.js Parent Document Retriever
DESCRIPTION: Installation command for required LangChain.js dependencies including OpenAI and Core packages.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/core

----------------------------------------

TITLE: Installing AWS SageMaker Runtime Dependencies
DESCRIPTION: Command to install the required AWS SageMaker runtime client package as a peer dependency.

LANGUAGE: bash
CODE:
npm install @aws-sdk/client-sagemaker-runtime

----------------------------------------

TITLE: Installing Redis Dependencies
DESCRIPTION: Commands to install the required Redis package and core dependencies using npm or yarn.

LANGUAGE: bash
CODE:
npm install @langchain/redis @langchain/core

----------------------------------------

TITLE: Streaming with ChatBedrockConverse Model
DESCRIPTION: TypeScript code demonstrating how to use streaming with the ChatBedrockConverse model.

LANGUAGE: typescript
CODE:
import { ChatBedrockConverse } from "@langchain/aws";

const model = new ChatBedrockConverse({
  region: process.env.BEDROCK_AWS_REGION ?? "us-east-1",
  credentials: {
    secretAccessKey: process.env.BEDROCK_AWS_SECRET_ACCESS_KEY,
    accessKeyId: process.env.BEDROCK_AWS_ACCESS_KEY_ID,
  },
});

const response = await model.stream(new HumanMessage("Hello world!"));

----------------------------------------

TITLE: Installing LangChain Text Splitters Package
DESCRIPTION: Command to install the @langchain/textsplitters package and its core dependency using npm or yarn.

LANGUAGE: bash
CODE:
npm install @langchain/textsplitters @langchain/core

----------------------------------------

TITLE: Installing LangChain.js Dependencies
DESCRIPTION: Command to install necessary npm packages for LangChain.js, including OpenAI, community, and core modules.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/community @langchain/core

----------------------------------------

TITLE: Setting Mistral API Key
DESCRIPTION: Command to set the Mistral API key as an environment variable.

LANGUAGE: bash
CODE:
export MISTRAL_API_KEY=your-api-key

----------------------------------------

TITLE: Installing Cloudflare Workers Types
DESCRIPTION: Command to install Cloudflare Workers types for TypeScript support in Cloudflare KV caching.

LANGUAGE: bash
CODE:
npm install -S @cloudflare/workers-types

----------------------------------------

TITLE: Advanced PlaywrightWebBaseLoader Configuration in TypeScript
DESCRIPTION: This example demonstrates advanced usage of PlaywrightWebBaseLoader, including custom launch options, navigation options, and a custom evaluate function to extract specific content after waiting for a network response.

LANGUAGE: typescript
CODE:
import {
  PlaywrightWebBaseLoader,
  Page,
  Browser,
} from "@langchain/community/document_loaders/web/playwright";

const loader = new PlaywrightWebBaseLoader("https://www.tabnews.com.br/", {
  launchOptions: {
    headless: true,
  },
  gotoOptions: {
    waitUntil: "domcontentloaded",
  },
  /** Pass custom evaluate, in this case you get page and browser instances */
  async evaluate(page: Page, browser: Browser, response: Response | null) {
    await page.waitForResponse("https://www.tabnews.com.br/va/view");

    const result = await page.evaluate(() => document.body.innerHTML);
    return result;
  },
});

const docs = await loader.load();

----------------------------------------

TITLE: Development Setup Commands
DESCRIPTION: Commands for setting up the development environment, including installing dependencies and building the package.

LANGUAGE: bash
CODE:
yarn install
yarn build
yarn build --filter=@langchain/anthropic

----------------------------------------

TITLE: Running tests for @langchain/openai
DESCRIPTION: Commands to run unit tests and integration tests for the package.

LANGUAGE: bash
CODE:
$ yarn test
$ yarn test:int

----------------------------------------

TITLE: Agent Implementation with Streaming
DESCRIPTION: Complete agent setup including tools, prompt configuration, and streaming implementation

LANGUAGE: typescript
CODE:
  (async () => {
    const tools = [new TavilySearchResults({ maxResults: 1 })];

    const prompt = await pull<ChatPromptTemplate>(
      "hwchase17/openai-tools-agent",
    );

    const agent = createToolCallingAgent({
      llm,
      tools,
      prompt,
    });

    const agentExecutor = new AgentExecutor({
      agent,
      tools,
    });

    const streamingEvents = agentExecutor.streamEvents(
      { input },
      { version: "v2" },
    );

    for await (const item of streamingEvents) {
      stream.update(JSON.parse(JSON.stringify(item, null, 2)));
    }

    stream.done();
  })();

----------------------------------------

TITLE: Invoking a Tool Directly in TypeScript
DESCRIPTION: Shows how to use a previously defined tool (multiply) by calling its invoke method with the required arguments.

LANGUAGE: typescript
CODE:
await multiply.invoke({ a: 2, b: 3 });

----------------------------------------

TITLE: Installing LangChain OpenAI Dependencies
DESCRIPTION: Command to install necessary LangChain OpenAI dependencies using npm.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/core

----------------------------------------

TITLE: Installing Playwright and LangChain Dependencies
DESCRIPTION: This snippet shows how to install the necessary npm packages for using Playwright with LangChain.js.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core playwright

----------------------------------------

TITLE: Installing LangChain Dependencies
DESCRIPTION: This snippet shows how to install the necessary LangChain packages using npm or yarn.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core

----------------------------------------

TITLE: Initializing Couchbase Connection Parameters
DESCRIPTION: Setting up the connection parameters and SQL++ query for Couchbase database access

LANGUAGE: typescript
CODE:
import { CouchbaseDocumentLoader } from "@langchain/community/document_loaders/web/couchbase";
import { Cluster } from "couchbase";

const connectionString = "couchbase://localhost";
const dbUsername = "Administrator";
const dbPassword = "Password";

const query = `
    SELECT h.* FROM \`travel-sample\`.inventory.hotel h 
    WHERE h.country = 'United States'
    LIMIT 1
`;

----------------------------------------

TITLE: Building the @langchain/groq package
DESCRIPTION: These commands build the @langchain/groq package. The first is for building directly, and the second is for building from the repo root.

LANGUAGE: bash
CODE:
yarn build

LANGUAGE: bash
CODE:
yarn build --filter=@langchain/groq

----------------------------------------

TITLE: Tool Execution Function Initialization
DESCRIPTION: Setup of the executeTool function with streaming capability using createStreamableValue.

LANGUAGE: typescript
CODE:
export async function executeTool(
  input: string,
) {
  "use server";

  const stream = createStreamableValue();

----------------------------------------

TITLE: Configuring package.json for dependency resolution
DESCRIPTION: JSON configuration to ensure consistent @langchain/core version across different package managers.

LANGUAGE: json
CODE:
{
  "name": "your-project",
  "version": "0.0.0",
  "dependencies": {
    "@langchain/core": "^0.3.0",
    "@langchain/openai": "^0.0.0"
  },
  "resolutions": {
    "@langchain/core": "^0.3.0"
  },
  "overrides": {
    "@langchain/core": "^0.3.0"
  },
  "pnpm": {
    "overrides": {
      "@langchain/core": "^0.3.0"
    }
  }
}

----------------------------------------

TITLE: Running Integration Tests in LangChain.js
DESCRIPTION: This command executes all integration tests in the LangChain.js project. Integration tests cover logic that requires calls to external APIs and are named with the '.int.test.ts' extension. Note that most integration tests require credentials or additional setup.

LANGUAGE: bash
CODE:
yarn test:integration

----------------------------------------

TITLE: Implementing Sonix Audio Transcription and Document Creation in TypeScript
DESCRIPTION: This code snippet demonstrates how to use the SonixAudioTranscriptionLoader to transcribe an audio file and create a document object. It includes setting up the loader with API credentials, specifying the audio file, and processing the transcription.

LANGUAGE: typescript
CODE:
import { SonixAudioTranscriptionLoader } from "@langchain/community/document_loaders/web/sonix_audio";

const loader = new SonixAudioTranscriptionLoader({
  sonixAuthKey: "YOUR_SONIX_AUTH_KEY",
  request: {
    audioFilePath: "/path/to/audio/file.mp3",
    language: "en",
  },
});

const docs = await loader.load();

console.log(docs);

----------------------------------------

TITLE: Installing Required Dependencies
DESCRIPTION: Install the necessary npm packages for using Couchbase with LangChain.js

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core couchbase

----------------------------------------

TITLE: Linting and formatting @langchain/exa code
DESCRIPTION: Command to run the linter and formatter to ensure code quality and consistency in the @langchain/exa package.

LANGUAGE: bash
CODE:
yarn lint && yarn format

----------------------------------------

TITLE: Implementing Sample Messages for Minimax Chat Models in LangChain.js
DESCRIPTION: Illustrates how to use sample messages to provide context and guide Minimax chat model responses in LangChain.js.

LANGUAGE: typescript
CODE:
import MinimaxSampleMessages from "@examples/models/chat/minimax_sample_messages.ts";

----------------------------------------

TITLE: Loading Taskade Project Data with LangChain.js
DESCRIPTION: This code snippet demonstrates how to use the TaskadeLoader from LangChain.js to load data from a Taskade project. It requires the Taskade API key and project ID as input parameters.

LANGUAGE: typescript
CODE:
import { TaskadeLoader } from "langchain/document_loaders/web/taskade";

const loader = new TaskadeLoader({
  taskadeApiKey: "YOUR-TASKADE-API-KEY",
  taskadeProjectId: "YOUR-TASKADE-PROJECT-ID",
});

const docs = await loader.load();

----------------------------------------

TITLE: Running Environment Tests with Docker
DESCRIPTION: Command to run environment tests using Docker from the project root.

LANGUAGE: bash
CODE:
yarn test:exports:docker

----------------------------------------

TITLE: Installing Cheerio for Web Scraping
DESCRIPTION: Command to install the cheerio package for HTML parsing and scraping functionality.

LANGUAGE: bash
CODE:
npm install cheerio

----------------------------------------

TITLE: Installing LangChain Dependencies
DESCRIPTION: This command installs the necessary LangChain packages for integrating with OpenAI and Convex.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/community @langchain/core

----------------------------------------

TITLE: Installing Cloudflare Workers Types for TypeScript
DESCRIPTION: This bash command installs the @cloudflare/workers-types package, which provides TypeScript types for Cloudflare Workers. This is useful when implementing Cloudflare KV-based caching.

LANGUAGE: bash
CODE:
npm install -S @cloudflare/workers-types

----------------------------------------

TITLE: Development Setup Commands
DESCRIPTION: Series of bash commands for setting up the development environment, including dependency installation, building, testing, and code formatting.

LANGUAGE: bash
CODE:
yarn install
yarn build
yarn build --filter=@langchain/deepseek
yarn test
yarn test:int
yarn lint && yarn format

----------------------------------------

TITLE: Installing LangChain Dependencies
DESCRIPTION: Commands to install the required LangChain packages for using Tencent Hunyuan models.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core

----------------------------------------

TITLE: Using FewShotPromptTemplate with Partials and Functions in TypeScript
DESCRIPTION: Demonstrates how to use FewShotPromptTemplate with partial functions for non-chat models.

LANGUAGE: typescript
CODE:
const examplePrompt = PromptTemplate.fromTemplate("{foo}{bar}");
const prompt = new FewShotPromptTemplate({
  prefix: "{foo}{bar}",
  examplePrompt,
  inputVariables: ["foo", "bar"],
});
const partialPrompt = await prompt.partial({
  foo: () => Promise.resolve("boo"),
});
const formatted = await partialPrompt.format({ bar: "baz" });
console.log(formatted);

----------------------------------------

TITLE: Using FewShotPromptTemplate with Partials and Functions in TypeScript
DESCRIPTION: Demonstrates how to use FewShotPromptTemplate with partial functions for non-chat models.

LANGUAGE: typescript
CODE:
const examplePrompt = PromptTemplate.fromTemplate("{foo}{bar}");
const prompt = new FewShotPromptTemplate({
  prefix: "{foo}{bar}",
  examplePrompt,
  inputVariables: ["foo", "bar"],
});
const partialPrompt = await prompt.partial({
  foo: () => Promise.resolve("boo"),
});
const formatted = await partialPrompt.format({ bar: "baz" });
console.log(formatted);

----------------------------------------

TITLE: Deploying with SSH
DESCRIPTION: Command to deploy the website using SSH authentication.

LANGUAGE: bash
CODE:
$ USE_SSH=true yarn deploy

----------------------------------------

TITLE: Zep Memory Integration Example
DESCRIPTION: Example code showing how to integrate Zep memory with LangChain.js. This code is referenced but not shown in the provided content.

LANGUAGE: typescript
CODE:
// Example code reference - actual content not provided in the input text

----------------------------------------

TITLE: Configuring Package.json for LangChain Compatibility
DESCRIPTION: JSON configuration in package.json to ensure compatibility between LangChain packages by specifying version resolutions and overrides for @langchain/core.

LANGUAGE: json
CODE:
{
  "name": "your-project",
  "version": "0.0.0",
  "dependencies": {
    "@langchain/community": "^0.0.0",
    "@langchain/core": "^0.3.0"
  },
  "resolutions": {
    "@langchain/core": "^0.3.0"
  },
  "overrides": {
    "@langchain/core": "^0.3.0"
  },
  "pnpm": {
    "overrides": {
      "@langchain/core": "^0.3.0"
    }
  }
}

----------------------------------------

TITLE: Installing Azure Blob Storage Dependencies
DESCRIPTION: Command to install required packages including the Azure Storage Blob client library and LangChain dependencies using npm or yarn.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core @azure/storage-blob

----------------------------------------

TITLE: Configuring wrangler.toml for Cloudflare Vectorize
DESCRIPTION: This snippet shows how to update the wrangler.toml file to include an entry for the Vectorize index.

LANGUAGE: toml
CODE:
[[vectorize]]
binding = "VECTORIZE_INDEX"
index_name = "<index_name>"

----------------------------------------

TITLE: Starting Local Development Server
DESCRIPTION: Command to start a local development server that opens a browser window and supports live reloading of changes.

LANGUAGE: bash
CODE:
$ yarn start

----------------------------------------

TITLE: Installing LangChain Dependencies for Zep
DESCRIPTION: Command to install required LangChain packages for working with Zep and OpenAI integrations.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/community @langchain/core

----------------------------------------

TITLE: Installing LangChain Packages
DESCRIPTION: Command to install the required LangChain packages for document transformation functionality

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core

----------------------------------------

TITLE: Installing LangChain Community Package
DESCRIPTION: Installation command for the community package containing third-party integrations.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core

----------------------------------------

TITLE: Linting and Formatting Cloudflare Package Code
DESCRIPTION: Command to run the linter and formatter to ensure code quality and consistency in the Cloudflare package.

LANGUAGE: bash
CODE:
yarn lint && yarn format

----------------------------------------

TITLE: Installing dependencies for GitBook loading in LangChain.js
DESCRIPTION: This snippet shows the command to install the necessary dependencies for using the GitbookLoader in LangChain.js. It includes @langchain/community, @langchain/core, and cheerio packages.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core cheerio

----------------------------------------

TITLE: Installing Prisma Dependencies
DESCRIPTION: Command to install Prisma via npm or yarn package manager.

LANGUAGE: bash
CODE:
npm install prisma

----------------------------------------

TITLE: Retriever End Output Format (v2)
DESCRIPTION: Simplified output format for on_retriever_end event in v2, showing direct document list structure.

LANGUAGE: typescript
CODE:
{
  data: {
    output: [
      Document(...),
      Document(...),
      ...
    ]
  }
}

----------------------------------------

TITLE: Installing Xata CLI
DESCRIPTION: Command to install the Xata CLI globally using npm.

LANGUAGE: bash
CODE:
npm install @xata.io/cli -g

----------------------------------------

TITLE: Installing LangChain Anthropic Dependencies
DESCRIPTION: Command to install the required LangChain Anthropic packages using npm or yarn.

LANGUAGE: bash
CODE:
npm install @langchain/anthropic @langchain/core

----------------------------------------

TITLE: Linting and Formatting @langchain/qdrant Code
DESCRIPTION: This command runs the linter and formatter to ensure code quality and consistency in the @langchain/qdrant package.

LANGUAGE: bash
CODE:
yarn lint && yarn format

----------------------------------------

TITLE: Installing Cheerio Package
DESCRIPTION: Command to install the optional cheerio npm package for HTML scraping functionality

LANGUAGE: bash
CODE:
npm install cheerio

----------------------------------------

TITLE: Implementing Agent with AWS Lambda in LangChain.js
DESCRIPTION: This code demonstrates how to set up an Agent with AWS Lambda integration in LangChain.js. It includes initializing the OpenAI model, creating an AWS Lambda tool for sending emails, and setting up the agent executor with additional tools like SerpAPI.

LANGUAGE: typescript
CODE:
import { OpenAI } from "@langchain/openai";
import { SerpAPI } from "langchain/tools";
import { AWSLambda } from "langchain/tools/aws_lambda";
import { initializeAgentExecutorWithOptions } from "langchain/agents";

const model = new OpenAI({ temperature: 0 });
const emailSenderTool = new AWSLambda({
  name: "email-sender",
  // tell the Agent precisely what the tool does
  description:
    "Sends an email with the specified content to testing123@gmail.com",
  region: "us-east-1", // optional: AWS region in which the function is deployed
  accessKeyId: "abc123", // optional: access key id for a IAM user with invoke permissions
  secretAccessKey: "xyz456", // optional: secret access key for that IAM user
  functionName: "SendEmailViaSES", // the function name as seen in AWS Console
});
const tools = [emailSenderTool, new SerpAPI("api_key_goes_here")];
const executor = await initializeAgentExecutorWithOptions(tools, model, {
  agentType: "zero-shot-react-description",
});

const input = `Find out the capital of Croatia. Once you have it, email the answer to testing123@gmail.com.`;
const result = await executor.invoke({ input });
console.log(result);

----------------------------------------

TITLE: Implementing Agent with AWS Lambda in LangChain.js
DESCRIPTION: This code demonstrates how to set up an Agent with AWS Lambda integration in LangChain.js. It includes initializing the OpenAI model, creating an AWS Lambda tool for sending emails, and setting up the agent executor with additional tools like SerpAPI.

LANGUAGE: typescript
CODE:
import { OpenAI } from "@langchain/openai";
import { SerpAPI } from "langchain/tools";
import { AWSLambda } from "langchain/tools/aws_lambda";
import { initializeAgentExecutorWithOptions } from "langchain/agents";

const model = new OpenAI({ temperature: 0 });
const emailSenderTool = new AWSLambda({
  name: "email-sender",
  // tell the Agent precisely what the tool does
  description:
    "Sends an email with the specified content to testing123@gmail.com",
  region: "us-east-1", // optional: AWS region in which the function is deployed
  accessKeyId: "abc123", // optional: access key id for a IAM user with invoke permissions
  secretAccessKey: "xyz456", // optional: secret access key for that IAM user
  functionName: "SendEmailViaSES", // the function name as seen in AWS Console
});
const tools = [emailSenderTool, new SerpAPI("api_key_goes_here")];
const executor = await initializeAgentExecutorWithOptions(tools, model, {
  agentType: "zero-shot-react-description",
});

const input = `Find out the capital of Croatia. Once you have it, email the answer to testing123@gmail.com.`;
const result = await executor.invoke({ input });
console.log(result);

----------------------------------------

TITLE: Installing Weaviate Dependencies
DESCRIPTION: Commands to install the required Weaviate and LangChain packages using npm.

LANGUAGE: bash
CODE:
npm install @langchain/weaviate @langchain/core

----------------------------------------

TITLE: Installing Redis Dependencies for LangChain
DESCRIPTION: Command to install required npm packages including LangChain modules and Redis client libraries.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/community @langchain/core redis

----------------------------------------

TITLE: Installing Project Dependencies
DESCRIPTION: Command to install all project dependencies using yarn.

LANGUAGE: bash
CODE:
yarn install

----------------------------------------

TITLE: Installing Baidu Qianfan Dependencies
DESCRIPTION: Commands to install the required packages for Baidu Qianfan integration with LangChain.js

LANGUAGE: bash
CODE:
npm install @langchain/baidu-qianfan @langchain/core

----------------------------------------

TITLE: Installing Google Vertex AI Web Package
DESCRIPTION: Command to install the @langchain/google-vertexai-web package using yarn package manager.

LANGUAGE: bash
CODE:
$ yarn add @langchain/google-vertexai-web

----------------------------------------

TITLE: Installing LangChain Community and Core Packages
DESCRIPTION: This command installs the required LangChain packages for integrating with Friendli.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core

----------------------------------------

TITLE: Installing Dependencies for IMSDBLoader in LangChain.js
DESCRIPTION: This snippet shows how to install the necessary dependencies for using the IMSDBLoader. It installs @langchain/community, @langchain/core, and cheerio packages.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core cheerio

----------------------------------------

TITLE: Installing @langchain/qdrant Package
DESCRIPTION: This command installs the @langchain/qdrant package using npm. It's the primary method for adding the Qdrant integration to a LangChain.js project.

LANGUAGE: bash
CODE:
npm install @langchain/qdrant

----------------------------------------

TITLE: Installing MongoDB Dependencies
DESCRIPTION: Command to install the MongoDB Node.js SDK required for database connectivity.

LANGUAGE: bash
CODE:
npm install -S mongodb

----------------------------------------

TITLE: Configuring package.json for @langchain/aws
DESCRIPTION: Example package.json configuration to ensure compatibility with @langchain/core across different package managers.

LANGUAGE: json
CODE:
{
  "name": "your-project",
  "version": "0.0.0",
  "dependencies": {
    "@langchain/aws": "^0.0.1",
    "@langchain/core": "^0.3.0"
  },
  "resolutions": {
    "@langchain/core": "^0.3.0"
  },
  "overrides": {
    "@langchain/core": "^0.3.0"
  },
  "pnpm": {
    "overrides": {
      "@langchain/core": "^0.3.0"
    }
  }
}

----------------------------------------

TITLE: Building the Cloudflare Package
DESCRIPTION: Commands to build the Cloudflare package, either from within the package directory or from the root of the repository.

LANGUAGE: bash
CODE:
yarn build

LANGUAGE: bash
CODE:
yarn build --filter=@langchain/cloudflare

----------------------------------------

TITLE: Installing LangChain Community via npm
DESCRIPTION: This command installs LangChain Community, which is required for using LangChain functionalities along with Layerup Security.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core

----------------------------------------

TITLE: Using MessagesPlaceholder in ChatPromptTemplate in TypeScript
DESCRIPTION: This snippet demonstrates how to use MessagesPlaceholder in a ChatPromptTemplate to allow insertion of a list of messages at a specific point in the template. It combines a system message with a placeholder for user-provided messages.

LANGUAGE: typescript
CODE:
import {
  ChatPromptTemplate,
  MessagesPlaceholder,
} from "@langchain/core/prompts";
import { HumanMessage } from "@langchain/core/messages";

const promptTemplate = ChatPromptTemplate.fromMessages([
  ["system", "You are a helpful assistant"],
  new MessagesPlaceholder("msgs"),
]);

await promptTemplate.invoke({ msgs: [new HumanMessage("hi!")] });

----------------------------------------

TITLE: Setting Nomic API Key Environment Variable
DESCRIPTION: Bash command to set the NOMIC_API_KEY environment variable for authentication.

LANGUAGE: bash
CODE:
export NOMIC_API_KEY=

----------------------------------------

TITLE: Checking Database Connection with TypeORM
DESCRIPTION: This TypeScript code snippet demonstrates how to connect to a SQLite database (Chinook) using TypeORM and perform a simple query to verify the connection.

LANGUAGE: typescript
CODE:
<CodeBlock language="typescript">{DbCheck}</CodeBlock>

----------------------------------------

TITLE: Running Tests
DESCRIPTION: Commands to run unit tests (.test.ts) and integration tests (.int.test.ts) using yarn.

LANGUAGE: bash
CODE:
yarn test

LANGUAGE: bash
CODE:
yarn test:int

----------------------------------------

TITLE: Setting Cerebras API Key
DESCRIPTION: Environment variable configuration for Cerebras API authentication.

LANGUAGE: bash
CODE:
export CEREBRAS_API_KEY=

----------------------------------------

TITLE: Installing AWS Step Functions SDK
DESCRIPTION: Command to install the AWS Step Functions SDK package required for the integration.

LANGUAGE: bash
CODE:
npm install @aws-sdk/client-sfn

----------------------------------------

TITLE: Setting up JigsawStack API credentials
DESCRIPTION: Instructions for configuring the JigsawStack API key as an environment variable

LANGUAGE: bash
CODE:
export JIGSAWSTACK_API_KEY="your-api-key"

----------------------------------------

TITLE: Installing dependencies for @langchain/mongodb development
DESCRIPTION: Command to install project dependencies using yarn for developing the @langchain/mongodb package.

LANGUAGE: bash
CODE:
yarn install

----------------------------------------

TITLE: Installing LangChain Dependencies
DESCRIPTION: Command to install required npm packages for LangChain and Anthropic integration.

LANGUAGE: bash
CODE:
npm install @langchain/anthropic @langchain/core

----------------------------------------

TITLE: Setting Environment Variable for API Key
DESCRIPTION: Bash command to set the environment variable for the API key required by the integration.

LANGUAGE: bash
CODE:
export <ADD_ENV_NAME_HERE>=your-api-key

----------------------------------------

TITLE: Basic Azure Dynamic Sessions Usage Example
DESCRIPTION: Example demonstrating how to create and use a Python code interpreter session in Azure Container Apps.

LANGUAGE: typescript
CODE:
<Example>

----------------------------------------

TITLE: Installing Discord.js Dependency
DESCRIPTION: Command to install the required discord.js peer dependency for using the Discord Tool.

LANGUAGE: bash
CODE:
npm install discord.js

----------------------------------------

TITLE: Implementing Streaming Chat
DESCRIPTION: Example of using the streaming functionality with ChatMistralAI model.

LANGUAGE: typescript
CODE:
import { ChatMistralAI } from "@langchain/mistralai";

const model = new ChatMistralAI({
  apiKey: process.env.MISTRAL_API_KEY,
  modelName: "mistral-small",
});
const response = await model.stream(new HumanMessage("Hello world!"));

----------------------------------------

TITLE: Installing Dependencies with NPM/Yarn
DESCRIPTION: Commands for installing required LangChain and AI SDK packages

LANGUAGE: bash
CODE:
npm install langchain @langchain/core @langchain/community ai

----------------------------------------

TITLE: Running tests for @langchain/mongodb
DESCRIPTION: Commands to run unit tests and integration tests for the @langchain/mongodb package.

LANGUAGE: bash
CODE:
$ yarn test
$ yarn test:int

----------------------------------------

TITLE: Importing Google Custom Search Tool
DESCRIPTION: Demonstrates how to import the Google Custom Search tool for use in LangChain.js.

LANGUAGE: typescript
CODE:
import { GoogleCustomSearch } from "langchain/tools";

----------------------------------------

TITLE: Installing LangChain OpenAI Integration
DESCRIPTION: Command to install LangChain OpenAI integration using npm or yarn.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/core

----------------------------------------

TITLE: Installing @langchain/core Package
DESCRIPTION: Command to install the @langchain/core package, which is now a peer dependency for all LangChain packages.

LANGUAGE: bash
CODE:
npm install @langchain/core

----------------------------------------

TITLE: Initializing ChatAnthropic Model
DESCRIPTION: Example of initializing and using the ChatAnthropic model for basic interaction.

LANGUAGE: typescript
CODE:
import { ChatAnthropic } from "@langchain/anthropic";

const model = new ChatAnthropic({
  apiKey: process.env.ANTHROPIC_API_KEY,
});
const response = await model.invoke({
  role: "user",
  content: "Hello world!",
});

----------------------------------------

TITLE: Installing LangChain Mistral Package
DESCRIPTION: Command to install the LangChain Mistral integration package and its core dependency.

LANGUAGE: bash
CODE:
npm install @langchain/mistralai @langchain/core

----------------------------------------

TITLE: Installing Required Packages for LangChain and Database Interaction
DESCRIPTION: Command to install necessary npm packages for working with LangChain, OpenAI, TypeORM, and SQLite.

LANGUAGE: bash
CODE:
npm install langchain @langchain/community @langchain/openai typeorm sqlite3

----------------------------------------

TITLE: Publishing @langchain/aws Package
DESCRIPTION: Command to publish a new version of the @langchain/aws package after building.

LANGUAGE: bash
CODE:
npm publish

----------------------------------------

TITLE: Setting Azure OpenAI Environment Variables for Milvus
DESCRIPTION: Bash commands to set environment variables for Azure OpenAI API and Milvus URL.

LANGUAGE: bash
CODE:
export AZURE_OPENAI_API_KEY=YOUR_AZURE_OPENAI_API_KEY_HERE
export AZURE_OPENAI_API_INSTANCE_NAME=YOUR_AZURE_OPENAI_INSTANCE_NAME_HERE
export AZURE_OPENAI_API_DEPLOYMENT_NAME=YOUR_AZURE_OPENAI_DEPLOYMENT_NAME_HERE
export AZURE_OPENAI_API_COMPLETIONS_DEPLOYMENT_NAME=YOUR_AZURE_OPENAI_COMPLETIONS_DEPLOYMENT_NAME_HERE
export AZURE_OPENAI_API_EMBEDDINGS_DEPLOYMENT_NAME=YOUR_AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT_NAME_HERE
export AZURE_OPENAI_API_VERSION=YOUR_AZURE_OPENAI_API_VERSION_HERE
export AZURE_OPENAI_BASE_PATH=YOUR_AZURE_OPENAI_BASE_PATH_HERE
export MILVUS_URL=YOUR_MILVUS_URL_HERE # for example http://localhost:19530

----------------------------------------

TITLE: Configuring Web Crawler Access for js.langchain.com
DESCRIPTION: This robots.txt file sets the default access policy for all web crawlers and provides the location of the sitemap for the js.langchain.com website.

LANGUAGE: plaintext
CODE:
User-agent: *

Sitemap: https://js.langchain.com/sitemap.xml/

----------------------------------------

TITLE: Installing LangChain Community and Core Packages
DESCRIPTION: Command to install the required LangChain packages for integration with Gradient AI.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core

----------------------------------------

TITLE: Installing @langchain/google-gauth package using Yarn
DESCRIPTION: This command installs the @langchain/google-gauth package using Yarn package manager. It adds the package to your project's dependencies.

LANGUAGE: bash
CODE:
$ yarn add @langchain/google-gauth

----------------------------------------

TITLE: Installing Dependencies for LangChain Fallbacks
DESCRIPTION: Command to install necessary packages for implementing fallbacks with OpenAI and Anthropic models in LangChain.

LANGUAGE: bash
CODE:
npm install @langchain/anthropic @langchain/openai @langchain/core

----------------------------------------

TITLE: Installing Tigris Vector Store SDK
DESCRIPTION: Command to install the Tigris vector database SDK package via npm.

LANGUAGE: bash
CODE:
npm install -S @tigrisdata/vector

----------------------------------------

TITLE: Installing @langchain/core with Yarn
DESCRIPTION: Command to install the @langchain/core package using Yarn package manager.

LANGUAGE: bash
CODE:
$ yarn add @langchain/core

----------------------------------------

TITLE: Building and Serving LangChainJS API Documentation
DESCRIPTION: Terminal commands for building and serving the auto-generated API documentation locally. The documentation is generated using Typedoc and served through Next.js from the public directory.

LANGUAGE: bash
CODE:
yarn build
yarn dev
# or
yarn start

----------------------------------------

TITLE: Building and Serving LangChainJS API Documentation
DESCRIPTION: Terminal commands for building and serving the auto-generated API documentation locally. The documentation is generated using Typedoc and served through Next.js from the public directory.

LANGUAGE: bash
CODE:
yarn build
yarn dev
# or
yarn start

----------------------------------------

TITLE: Installing dependencies for @langchain/exa development
DESCRIPTION: Command to install all necessary dependencies for developing the @langchain/exa package using Yarn.

LANGUAGE: bash
CODE:
yarn install

----------------------------------------

TITLE: Enabling pgvector Extension
DESCRIPTION: SQL command to enable the pgvector extension in PostgreSQL.

LANGUAGE: sql
CODE:
CREATE EXTENSION IF NOT EXISTS vector;

----------------------------------------

TITLE: Retrieving Environment Variables in Deno
DESCRIPTION: This snippet demonstrates how to retrieve environment variables in the Deno runtime, which differs from Node.js and web environments.

LANGUAGE: javascript
CODE:
Deno.env.get()

----------------------------------------

TITLE: Initializing Google Vertex AI Matching Engine in LangChain.js
DESCRIPTION: TypeScript code to set up and initialize the Matching Engine with synthetic embeddings and Google Cloud Storage as the document store. Requires environment variables for configuration.

LANGUAGE: typescript
CODE:
import { MatchingEngine } from "@langchain/community/vectorstores/googlevertexai";
import { Document } from "langchain/document";
import { SyntheticEmbeddings } from "langchain/embeddings/fake";
import { GoogleCloudStorageDocstore } from "@langchain/community/stores/doc/gcs";

const embeddings = new SyntheticEmbeddings({
  vectorSize: Number.parseInt(
    process.env.SYNTHETIC_EMBEDDINGS_VECTOR_SIZE ?? "768",
    10
  ),
});

const store = new GoogleCloudStorageDocstore({
  bucket: process.env.GOOGLE_CLOUD_STORAGE_BUCKET!,
});

const config = {
  index: process.env.GOOGLE_VERTEXAI_MATCHINGENGINE_INDEX!,
  indexEndpoint: process.env.GOOGLE_VERTEXAI_MATCHINGENGINE_INDEXENDPOINT!,
  apiVersion: "v1beta1",
  docstore: store,
};

const engine = new MatchingEngine(embeddings, config);

----------------------------------------

TITLE: Using Embeddings Model in TypeScript
DESCRIPTION: TypeScript code showing how to initialize and use the embeddings model provided by the integration package.

LANGUAGE: typescript
CODE:
import { <ADD_CLASS_NAME_HERE> } from "@langchain/<ADD_PACKAGE_NAME_HERE>";

const embeddings = new ExampleEmbeddingClass({
  apiKey: process.env.EXAMPLE_API_KEY,
});
const res = await embeddings.embedQuery("Hello world");

----------------------------------------

TITLE: Cloning and Navigating to LangChain.js Repository
DESCRIPTION: Commands to clone the LangChain.js repository and navigate to the project directory.

LANGUAGE: bash
CODE:
cd langchainjs

----------------------------------------

TITLE: Implementing DeepSeek Chat Model
DESCRIPTION: TypeScript code demonstrating how to initialize and use the DeepSeek chat model with LangChain.js. Shows model instantiation and message invocation.

LANGUAGE: typescript
CODE:
import { ChatDeepSeek } from "@langchain/deepseek";
import { HumanMessage } from "@langchain/core/messages";

const model = new ChatDeepSeek({
  apiKey: process.env.DEEPSEEK_API_KEY, // Default value.
  model: "<model_name>",
});

const res = await model.invoke([
  {
    role: "user",
    content: message,
  },
]);

----------------------------------------

TITLE: Indexing Documents in OpenSearch Vector Store
DESCRIPTION: TypeScript code demonstrating how to index documents in OpenSearch using LangChain.js. It creates a client, defines documents, and uses OpenSearchVectorStore to store embeddings.

LANGUAGE: typescript
CODE:
import { Client } from "@opensearch-project/opensearch";
import { Document } from "langchain/document";
import { OpenAIEmbeddings } from "@langchain/openai";
import { OpenSearchVectorStore } from "@langchain/community/vectorstores/opensearch";

const client = new Client({
  nodes: [process.env.OPENSEARCH_URL ?? "http://127.0.0.1:9200"],
});

const docs = [
  new Document({
    metadata: { foo: "bar" },
    pageContent: "opensearch is also a vector db",
  }),
  new Document({
    metadata: { foo: "bar" },
    pageContent: "the quick brown fox jumped over the lazy dog",
  }),
  new Document({
    metadata: { baz: "qux" },
    pageContent: "lorem ipsum dolor sit amet",
  }),
  new Document({
    metadata: { baz: "qux" },
    pageContent:
      "OpenSearch is a scalable, flexible, and extensible open-source software suite for search, analytics, and observability applications",
  }),
];

await OpenSearchVectorStore.fromDocuments(docs, new OpenAIEmbeddings(), {
  client,
  indexName: process.env.OPENSEARCH_INDEX, // Will default to `documents`
});

----------------------------------------

TITLE: Configuring package.json for consistent @langchain/core version
DESCRIPTION: JSON configuration to ensure all LangChain packages use the same version of @langchain/core. This includes fields for different package managers (yarn, npm, pnpm) to maximize compatibility.

LANGUAGE: json
CODE:
{
  "name": "your-project",
  "version": "0.0.0",
  "dependencies": {
    "@langchain/azure-openai": "^0.0.4",
    "@langchain/core": "^0.3.0"
  },
  "resolutions": {
    "@langchain/core": "^0.3.0"
  },
  "overrides": {
    "@langchain/core": "^0.3.0"
  },
  "pnpm": {
    "overrides": {
      "@langchain/core": "^0.3.0"
    }
  }
}

----------------------------------------

TITLE: Installing CloseVector Web Package
DESCRIPTION: Command to install the CloseVector web package for browser environments using npm.

LANGUAGE: bash
CODE:
npm install -S closevector-web

----------------------------------------

TITLE: Installing Cerebras Dependencies
DESCRIPTION: Commands to install the required Cerebras and LangChain Core packages using npm or yarn.

LANGUAGE: bash
CODE:
npm install @langchain/cerebras @langchain/core

----------------------------------------

TITLE: Building the Project
DESCRIPTION: Command to build the entire project.

LANGUAGE: bash
CODE:
yarn build

----------------------------------------

TITLE: Installing LangChain Community Package with Yarn
DESCRIPTION: Command to install the LangChain Community package using Yarn package manager.

LANGUAGE: bash
CODE:
$ yarn add @langchain/community

----------------------------------------

TITLE: Installing Dependencies for OpenSearch in LangChain.js
DESCRIPTION: Command to install necessary npm packages for using OpenSearch with LangChain.js. Includes @langchain/openai, @langchain/core, and @opensearch-project/opensearch.

LANGUAGE: bash
CODE:
npm install -S @langchain/openai @langchain/core @opensearch-project/opensearch

----------------------------------------

TITLE: Installing @langchain/azure-dynamic-sessions and @langchain/core
DESCRIPTION: Command to install the required packages using npm or yarn. This snippet also mentions the dependency on @langchain/core and its importance in version management.

LANGUAGE: bash
CODE:
npm install @langchain/azure-dynamic-sessions @langchain/core

----------------------------------------

TITLE: Installing LangChain Dependencies
DESCRIPTION: This command installs the necessary LangChain packages for working with OpenAI, community modules, and core functionalities.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/community @langchain/core

----------------------------------------

TITLE: Running Tests
DESCRIPTION: Commands for running unit and integration tests for the package.

LANGUAGE: bash
CODE:
$ yarn test
$ yarn test:int

----------------------------------------

TITLE: Document Embedding with Llama CPP in TypeScript
DESCRIPTION: Shows how to use LlamaCppEmbeddings for embedding multiple documents. It demonstrates creating embeddings for an array of text strings.

LANGUAGE: typescript
CODE:
import { LlamaCppEmbeddings } from "@langchain/community/embeddings/llama_cpp";

const embeddings = new LlamaCppEmbeddings({
  modelPath: "./models/llama-2-7b-chat.Q4_0.gguf",
});

const documentRes = await embeddings.embedDocuments([
  "Hello world",
  "Bye bye",
]);
console.log({ documentRes });

----------------------------------------

TITLE: Running Linter and Formatter
DESCRIPTION: Commands to run code linting and formatting checks.

LANGUAGE: bash
CODE:
yarn lint && yarn format

----------------------------------------

TITLE: Setting OpenAI Environment Variables for Milvus
DESCRIPTION: Bash commands to set environment variables for OpenAI API key and Milvus URL.

LANGUAGE: bash
CODE:
export OPENAI_API_KEY=YOUR_OPENAI_API_KEY_HERE
export MILVUS_URL=YOUR_MILVUS_URL_HERE # for example http://localhost:19530

----------------------------------------

TITLE: ZepCloudVectorStore Basic Implementation
DESCRIPTION: Example showing how to create and query a ZepCloudVectorStore instance with documents

LANGUAGE: typescript
CODE:
ZepCloudVectorStoreExample

----------------------------------------

TITLE: Installing LangChain via Yarn
DESCRIPTION: Command to install the LangChain package using Yarn package manager.

LANGUAGE: bash
CODE:
yarn add langchain

----------------------------------------

TITLE: Installing @langchain/google-genai Package
DESCRIPTION: Command to install the @langchain/google-genai package and its core dependency using npm or yarn.

LANGUAGE: bash
CODE:
npm install @langchain/google-genai @langchain/core

----------------------------------------

TITLE: Installing Gradient AI SDK for Node.js
DESCRIPTION: Command to install the official Gradient Node SDK as a peer dependency using npm or yarn.

LANGUAGE: bash
CODE:
npm i @gradientai/nodejs-sdk

----------------------------------------

TITLE: Setting Environment Variables for OpenAI and LangSmith
DESCRIPTION: Bash commands to set environment variables for OpenAI API key and optional LangSmith configuration.

LANGUAGE: bash
CODE:
export OPENAI_API_KEY="your api key"
# Uncomment the below to use LangSmith. Not required.
# export LANGSMITH_API_KEY="your api key"
# export LANGSMITH_TRACING=true

# Reduce tracing latency if you are not in a serverless environment
# export LANGCHAIN_CALLBACKS_BACKGROUND=true

----------------------------------------

TITLE: Setting OpenAI Environment Variable
DESCRIPTION: Command to set the OpenAI API key as an environment variable.

LANGUAGE: bash
CODE:
export OPENAI_API_KEY=YOUR_OPENAI_API_KEY_HERE

----------------------------------------

TITLE: Initializing Xata Project
DESCRIPTION: Command to initialize a Xata project in the current directory, which generates necessary client configuration files.

LANGUAGE: bash
CODE:
xata init

----------------------------------------

TITLE: Markdown Tag and Dataview Examples
DESCRIPTION: Markdown content showing various tag formats and dataview field syntax. Includes examples of valid and invalid tag formats, as well as different ways to specify dataview fields.

LANGUAGE: markdown
CODE:
()#notatag
#12345
#read
something #tagWithCases

- #tag-with-dash
  #tag_with_underscore #tag/with/nesting

Here is some data in a [dataview1:: a value] line.
Here is even more data in a (dataview2:: another value) line.
dataview3:: more data
notdataview4: this is not a field
notdataview5: this is not a field

----------------------------------------

TITLE: Installing @langchain/nomic Package
DESCRIPTION: Command to install the @langchain/nomic and @langchain/core packages using npm or yarn.

LANGUAGE: bash
CODE:
npm install @langchain/nomic @langchain/core

----------------------------------------

TITLE: Installing Dria Package
DESCRIPTION: Commands to install the core Dria package using npm or yarn package managers.

LANGUAGE: bash
CODE:
npm install dria

----------------------------------------

TITLE: Importing Zod in Node and Deno
DESCRIPTION: Code snippet showing the difference in importing Zod between Node.js and Deno environments.

LANGUAGE: typescript
CODE:
// Import in Node:
import { z } from "zod";
// Import in Deno:
import { z } from "npm:/zod";

----------------------------------------

TITLE: Querying Vector Store
DESCRIPTION: TypeScript examples showing how to perform similarity searches with and without scores

LANGUAGE: typescript
CODE:
const resultOne = await vectorStore.similaritySearch("hola", 1);

for (const doc of similaritySearchResults) {
  console.log(`${doc.pageContent} [${JSON.stringify(doc.metadata, null)}]`);
}

LANGUAGE: typescript
CODE:
const similaritySearchWithScoreResults =
  await vectorStore.similaritySearchWithScore("hola", 1);

for (const [doc, score] of similaritySearchWithScoreResults) {
  console.log(
    `${score.toFixed(3)} ${doc.pageContent} [${JSON.stringify(doc.metadata)}]`
  );
}

----------------------------------------

TITLE: Loading EPUB as Single Document
DESCRIPTION: Shows how to load an EPUB file as a single document by disabling chapter splitting

LANGUAGE: typescript
CODE:
import { EPubLoader } from "@langchain/community/document_loaders/fs/epub";

const loader = new EPubLoader(
  "src/document_loaders/example_data/example.epub",
  {
    splitChapters: false,
  }
);

const docs = await loader.load();

----------------------------------------

TITLE: Defining YAML Data Structure with Various Types
DESCRIPTION: This YAML snippet demonstrates different data types including floats, integers, booleans, strings, arrays, and nested dictionaries. It showcases the flexibility of YAML in representing structured data.

LANGUAGE: yaml
CODE:
aFloat: 13.12345
anInt: 15
aBool: true
aString: string value
anArray:
  - one
  - two
  - three
aDict:
  dictId1: "58417"
  dictId2: 1500
tags: ["onetag", "twotag"]

----------------------------------------

TITLE: Running Tests for @langchain/nomic
DESCRIPTION: Bash commands to run unit tests and integration tests for the @langchain/nomic package.

LANGUAGE: bash
CODE:
$ yarn test
$ yarn test:int

----------------------------------------

TITLE: Prisma Schema Definition
DESCRIPTION: Prisma schema definition for a Document model with vector field support.

LANGUAGE: prisma
CODE:
model Document {
  id      String                 @id @default(cuid())
  content String
  vector  Unsupported("vector")?
}

----------------------------------------

TITLE: Adding an Optional Dependency Entrypoint
DESCRIPTION: JavaScript code snippet showing how to add an entrypoint that requires an optional dependency in the LangChain configuration file.

LANGUAGE: javascript
CODE:
// ...
requiresOptionalDependency: [
  // ...
  "tools/index",
],
// ...

----------------------------------------

TITLE: Creating Vector Index from Texts
DESCRIPTION: Demonstrates how to create a new vector index from text documents using SAP HANA Vector Engine.

LANGUAGE: typescript
CODE:
import ExampleTexts from "@examples/indexes/vector_stores/hana_vector/fromTexts.ts";

----------------------------------------

TITLE: Demonstrating Bad Output for JSON Parsing in TypeScript
DESCRIPTION: This snippet illustrates an example of a malformed AIMessage output that would cause a JSON parsing error. The content is enclosed in markdown code tags but contains invalid JSON.

LANGUAGE: typescript
CODE:
AIMessage {
  content: "```\n{\"foo\":\n```"
}

----------------------------------------

TITLE: Installing YandexGPT Dependencies for LangChain.js
DESCRIPTION: This snippet shows how to install the necessary packages for using YandexGPT with LangChain.js. It requires installing both the Yandex integration and the LangChain core package.

LANGUAGE: bash
CODE:
npm install @langchain/yandex @langchain/core

----------------------------------------

TITLE: Installing Dependencies for Development
DESCRIPTION: Command to install all development dependencies using yarn.

LANGUAGE: bash
CODE:
yarn install

----------------------------------------

TITLE: Creating Convex Project - Bash Setup
DESCRIPTION: Command to create a new Convex project using npm.

LANGUAGE: bash
CODE:
npm create convex@latest

----------------------------------------

TITLE: Building the Project
DESCRIPTION: Command to build the LangChain project.

LANGUAGE: bash
CODE:
yarn build

----------------------------------------

TITLE: Importing HF Transformers Example
DESCRIPTION: TypeScript import statement for HuggingFace Transformers example implementation.

LANGUAGE: typescript
CODE:
import HFTransformersExample from "@examples/models/embeddings/hf_transformers.ts";

----------------------------------------

TITLE: Running Linter and Formatter
DESCRIPTION: Command to run code linting and formatting checks using yarn.

LANGUAGE: bash
CODE:
yarn lint && yarn format

----------------------------------------

TITLE: Using Mistral Embeddings
DESCRIPTION: Example of using MistralAIEmbeddings for generating text embeddings.

LANGUAGE: typescript
CODE:
import { MistralAIEmbeddings } from "@langchain/mistralai";

const embeddings = new MistralAIEmbeddings({
  apiKey: process.env.MISTRAL_API_KEY,
});
const res = await embeddings.embedQuery("Hello world");

----------------------------------------

TITLE: Running Tests and Linting
DESCRIPTION: Commands for running tests and maintaining code quality through linting and formatting.

LANGUAGE: bash
CODE:
$ yarn test
$ yarn test:int
yarn lint && yarn format

----------------------------------------

TITLE: Installing @langchain/core for Multimodal Inputs
DESCRIPTION: Command to install the @langchain/core package, required for multimodal inputs with Gemini vision model.

LANGUAGE: bash
CODE:
npm install @langchain/core

----------------------------------------

TITLE: Importing and Using AlibabaTongyiExample
DESCRIPTION: Reference to a TypeScript example file demonstrating the implementation of Alibaba Tongyi embeddings.

LANGUAGE: typescript
CODE:
{AlibabaTongyiExample}

----------------------------------------

TITLE: Running Linter
DESCRIPTION: Command to run the ESLint linter on the project.

LANGUAGE: bash
CODE:
yarn lint

----------------------------------------

TITLE: Using YandexGPT Embeddings
DESCRIPTION: Example demonstrating how to use YandexGPT embeddings for both query and document embedding

LANGUAGE: typescript
CODE:
import { YandexGPTEmbeddings } from "@langchain/yandex";

const model = new YandexGPTEmbeddings({});

/* Embed queries */
const res = await model.embedQuery(
  "This is a test document."
);
/* Embed documents */
const documentRes = await model.embedDocuments(["This is a test document."]);

----------------------------------------

TITLE: Installing LangChain Dependencies for Google Routes
DESCRIPTION: Commands to install required LangChain packages for using the Google Routes Tool.

LANGUAGE: bash
CODE:
npm install @langchain/openai @langchain/community @langchain/core

----------------------------------------

TITLE: Installing LangChain Dependencies for Alibaba Tongyi
DESCRIPTION: Command to install the required npm packages for using Alibaba Tongyi embeddings with LangChain.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core

----------------------------------------

TITLE: Checking Formatting
DESCRIPTION: Command to check for formatting differences without fixing them.

LANGUAGE: bash
CODE:
yarn format:check

----------------------------------------

TITLE: Development Setup Commands
DESCRIPTION: Commands for setting up the development environment, building the package, and running tests

LANGUAGE: bash
CODE:
yarn install
yarn build
yarn build --filter=@langchain/yandex
yarn test:int
yarn lint && yarn format

----------------------------------------

TITLE: Installing Google Vertex AI Package for LangChain.js
DESCRIPTION: Command to install the Google Vertex AI package for LangChain.js using npm or yarn.

LANGUAGE: bash
CODE:
npm install @langchain/google-vertexai @langchain/core

----------------------------------------

TITLE: Installing Upstash Redis Dependencies
DESCRIPTION: Commands to install required packages including LangChain community components, core modules, and Upstash Redis client.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core @upstash/redis

----------------------------------------

TITLE: Changing Directory to LangChain Project Root
DESCRIPTION: Command to change the current directory to the LangChain project root after cloning the repository.

LANGUAGE: bash
CODE:
cd langchainjs

----------------------------------------

TITLE: Adding a New Entrypoint
DESCRIPTION: JavaScript code snippet showing how to add a new entrypoint in the LangChain configuration file.

LANGUAGE: javascript
CODE:
// ...
entrypoints: {
  // ...
  tools: "tools/index",
},
// ...

----------------------------------------

TITLE: Installing Required Packages for Azure Cosmos DB Mongo Integration
DESCRIPTION: This snippet shows how to install the necessary packages for using Azure Cosmos DB Mongo vCore with LangChain.js. It includes the core package and the Azure Cosmos DB integration.

LANGUAGE: bash
CODE:
npm install @langchain/azure-cosmosdb @langchain/core

----------------------------------------

TITLE: Running Unit Tests in LangChain.js
DESCRIPTION: This command executes all unit tests in the LangChain.js project. Unit tests cover modular logic that doesn't require calls to external APIs and are named with the '.test.ts' extension.

LANGUAGE: bash
CODE:
yarn test

----------------------------------------

TITLE: Using Azure OpenAI Embeddings
DESCRIPTION: TypeScript code to initialize and use Azure OpenAI Embeddings for query embedding.

LANGUAGE: typescript
CODE:
import { AzureOpenAIEmbeddings } from "@langchain/azure-openai";

const embeddings = new AzureOpenAIEmbeddings({
  // Note that the following are optional, and will default to the values below
  // if not provided.
  azureOpenAIEndpoint: process.env.AZURE_OPENAI_API_ENDPOINT,
  azureOpenAIApiKey: process.env.AZURE_OPENAI_API_KEY,
  azureOpenAIApiDeploymentName: process.env.AZURE_OPENAI_API_EMBEDDINGS_DEPLOYMENT_NAME,
});
const res = await embeddings.embedQuery("Hello world");

----------------------------------------

TITLE: Importing Wikipedia Tool Example from LangChain.js
DESCRIPTION: Code example showing how to use the WikipediaQueryRun tool with LangChain.js. The example is imported from the examples directory but actual code content is not shown in the provided text.

LANGUAGE: typescript
CODE:
import ToolExample from "@examples/tools/wikipedia.ts";

----------------------------------------

TITLE: Initializing ChatOpenAI with In-Memory Caching in TypeScript
DESCRIPTION: This snippet demonstrates how to create a ChatOpenAI instance with in-memory caching enabled. It uses the GPT-4 model and sets the cache option to true.

LANGUAGE: typescript
CODE:
import { ChatOpenAI } from "@langchain/openai";

// To make the caching really obvious, lets use a slower model.
const model = new ChatOpenAI({
  model: "gpt-4",
  cache: true,
});

----------------------------------------

TITLE: Invalid YAML Frontmatter Structure
DESCRIPTION: Example of malformed YAML frontmatter with improper array formatting and tag syntax. Contains syntax errors in array declaration and tag list closure.

LANGUAGE: yaml
CODE:
anArray:
 one
- two
- three
tags: 'onetag', 'twotag' ]

----------------------------------------

TITLE: Installing Dependencies for Google Cloud Storage Integration
DESCRIPTION: Command to install required npm packages including LangChain community modules, core functionality, and Google Cloud Storage SDK.

LANGUAGE: bash
CODE:
npm install @langchain/community @langchain/core @google-cloud/storage

----------------------------------------

TITLE: Creating Couchbase Connection in TypeScript
DESCRIPTION: TypeScript code to establish a connection to a Couchbase cluster using the provided connection string, username, and password.

LANGUAGE: typescript
CODE:
import { Cluster } from "couchbase";

const connectionString = "couchbase://localhost"; // or couchbases://localhost if you are using TLS
const dbUsername = "Administrator"; // valid database user with read access to the bucket being queried
const dbPassword = "Password"; // password for the database user

const couchbaseClient = await Cluster.connect(connectionString, {
  username: dbUsername,
  password: dbPassword,
  configProfile: "wanDevelopment",
});