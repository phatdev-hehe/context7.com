TITLE: Configuring Resource Processor in YAML
DESCRIPTION: This snippet demonstrates how to configure the Resource Processor to modify resource attributes. It shows examples of upserting, inserting, and deleting attributes.

LANGUAGE: yaml
CODE:
processors:
  resource:
    attributes:
    - key: cloud.availability_zone
      value: "zone-1"
      action: upsert
    - key: k8s.cluster.name
      from_attribute: k8s-cluster
      action: insert
    - key: redundant-attribute
      action: delete

----------------------------------------

TITLE: Configuring OAuth2 Client Credentials Authenticator in OpenTelemetry
DESCRIPTION: Example configuration for setting up OAuth2 Client Credentials authenticator with OpenTelemetry Collector. Includes extension setup, receiver configuration, and exporter configuration with authentication settings. Demonstrates both HTTP and gRPC exporter configurations.

LANGUAGE: yaml
CODE:
extensions:
  oauth2client:
    client_id: someclientid
    client_secret: someclientsecret
    endpoint_params:
      audience: someaudience
    token_url: https://example.com/oauth2/default/v1/token
    scopes: ["api.metrics"]
    # tls settings for the token client
    tls:
      insecure: true
      ca_file: /var/lib/mycert.pem
      cert_file: certfile
      key_file: keyfile
    # timeout for the token client
    timeout: 2s
    # buffer time before token expiry to refresh
    expiry_buffer: 10s
    
receivers:
  hostmetrics:
    scrapers:
      memory:
  otlp:
    protocols:
      grpc:

exporters:
  otlphttp/withauth:
    endpoint: http://localhost:9000
    auth:
      authenticator: oauth2client
      
  otlp/withauth:
    endpoint: 0.0.0.0:5000
    tls:
      ca_file: /tmp/certs/ca.pem
    auth:
      authenticator: oauth2client

service:
  extensions: [oauth2client]
  pipelines:
    metrics:
      receivers: [hostmetrics]
      processors: []
      exporters: [otlphttp/withauth, otlp/withauth]

----------------------------------------

TITLE: Complete Processor Configuration Example
DESCRIPTION: Full example configuration showing multiple actions including deletion, upsert, update, insert, and conversion operations.

LANGUAGE: yaml
CODE:
processors:
  attributes/example:
    actions:
      - key: db.table
        action: delete
      - key: redacted_span
        value: true
        action: upsert
      - key: copy_key
        from_attribute: key_original
        action: update
      - key: account_id
        value: 2245
        action: insert
      - key: account_password
        action: delete
      - key: account_email
        action: hash
      - key: http.status_code
        action: convert
        converted_type: int

----------------------------------------

TITLE: Basic Filter Processor Configuration - YAML
DESCRIPTION: Demonstrates comprehensive filter processor configuration with error handling mode and conditions for filtering traces, metrics and logs using OTTL expressions.

LANGUAGE: yaml
CODE:
processors:
  filter/ottl:
    error_mode: ignore
    traces:
      span:
        - 'attributes["container.name"] == "app_container_1"'
        - 'resource.attributes["host.name"] == "localhost"'
        - 'name == "app_3"'
      spanevent:
        - 'attributes["grpc"] == true'
        - 'IsMatch(name, ".*grpc.*")'
    metrics:
      metric:
          - 'name == "my.metric" and resource.attributes["my_label"] == "abc123"'
          - 'type == METRIC_DATA_TYPE_HISTOGRAM'
      datapoint:
          - 'metric.type == METRIC_DATA_TYPE_SUMMARY'
          - 'resource.attributes["service.name"] == "my_service_name"'
    logs:
      log_record:
        - 'IsMatch(body, ".*password.*")'
        - 'severity_number < SEVERITY_NUMBER_WARN'

----------------------------------------

TITLE: Parsing JSON Logs in YAML
DESCRIPTION: Configuration example demonstrating how to parse JSON logs and add specific fields as attributes.

LANGUAGE: yaml
CODE:
transform:
  log_statements:
    - statements:
        - merge_maps(log.cache, ParseJSON(log.body), "upsert") where IsMatch(log.body, "^\\{")
        - set(log.attributes["attr1"], log.cache["attr1"])
        - set(log.attributes["attr2"], log.cache["attr2"])
        - set(log.attributes["nested.attr3"], log.cache["nested"]["attr3"])

----------------------------------------

TITLE: Configuring Basic Authentication in OpenTelemetry Collector
DESCRIPTION: Example configuration showing how to set up both server-side and client-side basic authentication. Demonstrates the use of htpasswd file or inline credentials for server authentication and username/password for client authentication. Also shows integration with OTLP receiver and exporter.

LANGUAGE: yaml
CODE:
extensions:
  basicauth/server:
    htpasswd: 
      file: .htpasswd
      inline: |
        ${env:BASIC_AUTH_USERNAME}:${env:BASIC_AUTH_PASSWORD}
  
  basicauth/client:
    client_auth: 
      username: username
      password: password

receivers:
  otlp:
    protocols:
      http:
        auth:
          authenticator: basicauth/server

processors:

exporters:
  otlp:
    auth:
      authenticator: basicauth/client

service:
  extensions: [basicauth/server, basicauth/client]
  pipelines:
    traces:
      receivers: [otlp]
      processors: []
      exporters: [otlp]

----------------------------------------

TITLE: Configuring Transform Processor in YAML
DESCRIPTION: Example YAML configuration for the Transform Processor, showing how to set up error handling and define statements for different signal types.

LANGUAGE: yaml
CODE:
transform:
  error_mode: ignore
  trace_statements:
    - keep_keys(span.attributes, ["service.name", "service.namespace", "cloud.region", "process.command_line"])
    - replace_pattern(span.attributes["process.command_line"], "password\\=[^\\s]*(\\s?)", "password=***")
    - limit(span.attributes, 100, [])
    - truncate_all(span.attributes, 4096)
  metric_statements:
    - keep_keys(resource.attributes, ["host.name"])
    - truncate_all(resource.attributes, 4096)
    - set(metric.description, "Sum") where metric.type == "Sum"
    - convert_sum_to_gauge() where metric.name == "system.processes.count"
    - convert_gauge_to_sum("cumulative", false) where metric.name == "prometheus_metric"
  log_statements:
    - set(log.severity_text, "FAIL") where log.body == "request failed"
    - replace_all_matches(log.attributes, "/user/*/list/*", "/user/{userId}/list/{listId}")
    - replace_all_patterns(log.attributes, "value", "/account/\\d{4}", "/account/{accountId}")
    - set(log.body, log.attributes["http.route"])

----------------------------------------

TITLE: Sample Configuration for Container Insights on EKS
DESCRIPTION: A comprehensive configuration example for using AWS Container Insights with the awscontainerinsightreceiver and awsemfexporter on an EKS cluster.

LANGUAGE: yaml
CODE:
# create namespace
apiVersion: v1
kind: Namespace
metadata:
  name: aws-otel-eks
  labels:
    name: aws-otel-eks

---
# create cwagent service account and role binding
apiVersion: v1
kind: ServiceAccount
metadata:
  name: aws-otel-sa
  namespace: aws-otel-eks

---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: aoc-agent-role
rules:
  - apiGroups: [""]
    resources: ["pods", "nodes", "endpoints"]
    verbs: ["list", "watch"]
  - apiGroups: ["apps"]
    resources: ["replicasets"]
    verbs: ["list", "watch"]
  - apiGroups: ["batch"]
    resources: ["jobs"]
    verbs: ["list", "watch"]
  - apiGroups: [""]
    resources: ["nodes/proxy"]
    verbs: ["get"]
  - apiGroups: [""]
    resources: ["nodes/stats", "configmaps", "events"]
    verbs: ["create", "get"]
  - apiGroups: [""]
    resources: ["configmaps"]
    resourceNames: ["otel-container-insight-clusterleader"]
    verbs: ["get","update"]

---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: aoc-agent-role-binding
subjects:
  - kind: ServiceAccount
    name: aws-otel-sa
    namespace: aws-otel-eks
roleRef:
  kind: ClusterRole
  name: aoc-agent-role
  apiGroup: rbac.authorization.k8s.io

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: otel-agent-conf
  namespace: aws-otel-eks
  labels:
    app: opentelemetry
    component: otel-agent-conf
data:
  otel-agent-config: |
    extensions:
      health_check:

    receivers:
      awscontainerinsightreceiver:

    processors:
      batch/metrics:
        timeout: 60s

    exporters:
      awsemf:
        namespace: ContainerInsights
        log_group_name: '/aws/containerinsights/{ClusterName}/performance'
        log_stream_name: '{NodeName}'
        resource_to_telemetry_conversion:
          enabled: true
        dimension_rollup_option: NoDimensionRollup
        parse_json_encoded_attr_values: [Sources, kubernetes]
        metric_declarations:
          # node metrics
          - dimensions: [[NodeName, InstanceId, ClusterName]]
            metric_name_selectors:
              - node_cpu_utilization
              - node_memory_utilization
              - node_network_total_bytes
              - node_cpu_reserved_capacity
              - node_memory_reserved_capacity
              - node_number_of_running_pods
              - node_number_of_running_containers
          - dimensions: [[ClusterName]]
            metric_name_selectors:
              - node_cpu_utilization
              - node_memory_utilization
              - node_network_total_bytes
              - node_cpu_reserved_capacity
              - node_memory_reserved_capacity
              - node_number_of_running_pods
              - node_number_of_running_containers
              - node_cpu_usage_total
              - node_cpu_limit
              - node_memory_working_set
              - node_memory_limit

          # pod metrics
          - dimensions: [[PodName, Namespace, ClusterName], [Service, Namespace, ClusterName], [Namespace, ClusterName], [ClusterName]]
            metric_name_selectors:
              - pod_cpu_utilization
              - pod_memory_utilization
              - pod_network_rx_bytes
              - pod_network_tx_bytes
              - pod_cpu_utilization_over_pod_limit
              - pod_memory_utilization_over_pod_limit
          - dimensions: [[PodName, Namespace, ClusterName], [ClusterName]]
            metric_name_selectors:
              - pod_cpu_reserved_capacity
              - pod_memory_reserved_capacity
          - dimensions: [[PodName, Namespace, ClusterName]]
            metric_name_selectors:
              - pod_number_of_container_restarts

          # cluster metrics
          - dimensions: [[ClusterName]]
            metric_name_selectors:
              - cluster_node_count
              - cluster_failed_node_count

          # service metrics
          - dimensions: [[Service, Namespace, ClusterName], [ClusterName]]
            metric_name_selectors:
              - service_number_of_running_pods

          # node fs metrics
          - dimensions: [[NodeName, InstanceId, ClusterName], [ClusterName]]
            metric_name_selectors:
              - node_filesystem_utilization

          # namespace metrics
          - dimensions: [[Namespace, ClusterName], [ClusterName]]
            metric_name_selectors:
              - namespace_number_of_running_pods


      debug:
        verbosity: detailed

    service:
      pipelines:
        metrics:
          receivers: [awscontainerinsightreceiver]
          processors: [batch/metrics]
          exporters: [awsemf]

      extensions: [health_check]

---
# create Daemonset
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: aws-otel-eks-ci
  namespace: aws-otel-eks
spec:
  selector:
    matchLabels:
      name: aws-otel-eks-ci
  template:
    metadata:
      labels:
        name: aws-otel-eks-ci
    spec:
      containers:
        - name: aws-otel-collector
          image: {collector-image-url}
          env:
            #- name: AWS_REGION
            #  value: "us-east-1"
            - name: K8S_NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: HOST_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: HOST_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: K8S_NAMESPACE
              valueFrom:
                 fieldRef:
                   fieldPath: metadata.namespace
          imagePullPolicy: Always
          command:
            - "/awscollector"
            - "--config=/conf/otel-agent-config.yaml"
          volumeMounts:
            - name: rootfs
              mountPath: /rootfs
              readOnly: true
            - name: dockersock
              mountPath: /var/run/docker.sock
              readOnly: true
            - name: varlibdocker
              mountPath: /var/lib/docker
              readOnly: true
            - name: containerdsock
              mountPath: /run/containerd/containerd.sock
              readOnly: true
            - name: sys
              mountPath: /sys
              readOnly: true
            - name: devdisk
              mountPath: /dev/disk
              readOnly: true
            - name: otel-agent-config-vol
              mountPath: /conf
          resources:
            limits:
              cpu:  200m
              memory: 200Mi
            requests:
              cpu: 200m
              memory: 200Mi
      volumes:
        - configMap:
            name: otel-agent-conf
            items:
              - key: otel-agent-config
                path: otel-agent-config.yaml
          name: otel-agent-config-vol
        - name: rootfs
          hostPath:
            path: /
        - name: dockersock
          hostPath:
            path: /var/run/docker.sock
        - name: varlibdocker
          hostPath:
            path: /var/lib/docker
        - name: containerdsock
          hostPath:
            path: /run/containerd/containerd.sock
        - name: sys
          hostPath:
            path: /sys
        - name: devdisk
          hostPath:
            path: /dev/disk/
      serviceAccountName: aws-otel-sa

----------------------------------------

TITLE: Enabling Feature Gates in Shell
DESCRIPTION: Shell commands demonstrating how to enable various feature gates for the Prometheus receiver including UseCreatedMetric, UseCollectorStartTimeFallback, EnableNativeHistograms, and other configuration options.

LANGUAGE: shell
CODE:
"--feature-gates=receiver.prometheusreceiver.UseCreatedMetric"
"--feature-gates=receiver.prometheusreceiver.UseCollectorStartTimeFallback"
"--feature-gates=receiver.prometheusreceiver.EnableNativeHistograms"
"--feature-gates=receiver.prometheusreceiver.RemoveLegacyResourceAttributes"
"--feature-gates=receiver.prometheusreceiver.RemoveStartTimeAdjustment"

----------------------------------------

TITLE: Configuring Host Metrics Receiver in YAML
DESCRIPTION: Basic configuration for the Host Metrics Receiver, including collection interval, initial delay, root path, and scrapers.

LANGUAGE: yaml
CODE:
hostmetrics:
  collection_interval: <duration> # default = 1m
  initial_delay: <duration> # default = 1s
  root_path: <string>
  scrapers:
    <scraper1>:
    <scraper2>:
    ...

----------------------------------------

TITLE: Configuring K8slog Receiver for Container Stdout Collection
DESCRIPTION: This YAML configuration snippet demonstrates how to set up the K8slog receiver to collect logs from the stdout of all containers in a Kubernetes environment. It uses the daemonset-stdout discovery mode and includes a recombine operator to handle multi-line logs.

LANGUAGE: yaml
CODE:
receivers:
  k8slog:
    discovery:
      mode: daemonset-stdout
    operators:
      - type: recombine
        combine_field: body
        is_first_entry: body matches "^\\d{4}-\\d{2}-\\d{2}"
        max_log_size: 128kb
        source_identifier: attributes["k8s.pod.uid"]

----------------------------------------

TITLE: Include/Exclude Filter Configuration
DESCRIPTION: Configuration for filtering telemetry data based on various properties including services, resources, libraries, and attributes.

LANGUAGE: yaml
CODE:
attributes:
    {include, exclude}:
      match_type: {strict, regexp}
      regexp:
      services: [<item1>, ..., <itemN>]
      resources:
        - key: <key>
          value: {value}
      libraries: [<item1>, ..., <itemN>]
      span_names: [<item1>, ..., <itemN>]
      span_kinds: [<item1>, ..., <itemN>]
      log_bodies: [<item1>, ..., <itemN>]
      log_severity_texts: [<item1>, ..., <itemN>]
      log_severity_number:
        min: <int>
        match_undefined: <bool>
      metric_names: [<item1>, ..., <itemN>]
      attributes:
        - key: <key>
          value: {value}

----------------------------------------

TITLE: Basic Attributes Processor Action Configuration
DESCRIPTION: Configuration example showing basic attribute manipulation actions including insert, update, and upsert operations with different value sources.

LANGUAGE: yaml
CODE:
- key: <key>
  action: {insert, update, upsert}
  value: <value>

- key: <key>
  action: {insert, update, upsert}
  from_attribute: <other key>

- key: <key>
  action: {insert, update, upsert}
  from_context: <other key>

----------------------------------------

TITLE: Configuring Prometheus Exporter in YAML
DESCRIPTION: Example configuration for the Prometheus exporter showing various options including endpoint, TLS settings, namespace, labels, and other features.

LANGUAGE: yaml
CODE:
exporters:
  prometheus:
    endpoint: "1.2.3.4:1234"
    tls:
      ca_file: "/path/to/ca.pem"
      cert_file: "/path/to/cert.pem"
      key_file: "/path/to/key.pem"
    namespace: test-space
    const_labels:
      label1: value1
      "another label": spaced value
    send_timestamps: true
    metric_expiration: 180m
    enable_open_metrics: true
    add_metric_suffixes: false
    resource_to_telemetry_conversion:
      enabled: true

----------------------------------------

TITLE: Configuring SQL Query Receiver in YAML
DESCRIPTION: This snippet shows how to configure the SQL Query Receiver with PostgreSQL driver, including both logs and metrics queries. It demonstrates the use of tracking columns for logs and attribute columns for metrics.

LANGUAGE: yaml
CODE:
receivers:
  sqlquery:
    driver: postgres
    datasource: "host=localhost port=5432 user=postgres password=s3cr3t sslmode=disable"
    storage: file_storage
    queries:
      - sql: "select * from my_logs where log_id > $$1"
        tracking_start_value: "10000"
        tracking_column: log_id
        logs:
          - body_column: log_body
            attribute_columns: [ "log_attribute_1", "log_attribute_2" ]
      - sql: "select count(*) as count, genre from movie group by genre"
        metrics:
          - metric_name: movie.genres
            value_column: "count"
            attribute_columns: ["genre"]
            static_attributes:
              dbinstance: mydbinstance

----------------------------------------

TITLE: Basic OTTL Statement Example
DESCRIPTION: Demonstrates a basic OTTL statement that sets a span attribute named 'test' to 'pass' when the attribute doesn't exist.

LANGUAGE: ottl
CODE:
set(span.attributes["test"], "pass") where span.attributes["test"] == nil

----------------------------------------

TITLE: Complete Collector Pipeline Configuration
DESCRIPTION: Demonstrates a full OpenTelemetry Collector configuration with multiple pipelines including spanmetrics and sampling.

LANGUAGE: yaml
CODE:
receivers:
  otlp:
    protocols:
      grpc:
exporter:
  otlp:
    endpoint: "localhost:4317"
processors:
  probabilistic_sampler:
    hash_seed: 22
    sampling_percentage: 15
    sampling_priority: priority
connectors:
  spanmetrics:
    dimensions:
      - name: http.method
      - name: http.status_code
      - name: service.name
      - name: deployment.environment
service:
  pipelines:
    traces/red:
      receivers: [otlp]
      exporters: [spanmetrics]
    traces/sampled:
      receivers: [otlp]
      processors: [probabilistic_sampler]
      exporters: [otlp]
    metrics:
      receivers: [spanmetrics]
      exporters: [otlp]

----------------------------------------

TITLE: Full K8sAttributes Processor Configuration
DESCRIPTION: Comprehensive configuration example for the K8sAttributes processor, including authentication, filtering, and attribute extraction.

LANGUAGE: yaml
CODE:
k8sattributes:
k8sattributes/2:
  auth_type: "serviceAccount"
  passthrough: false
  filter:
    node_from_env_var: KUBE_NODE_NAME
  extract:
    metadata:
      - k8s.pod.name
      - k8s.pod.uid
      - k8s.deployment.name
      - k8s.namespace.name
      - k8s.node.name
      - k8s.pod.start_time
    labels:
     - tag_name: app.label.component
       key: app.kubernetes.io/component
       from: pod
  pod_association:
    - sources:
        - from: resource_attribute
          name: k8s.pod.ip
    - sources:
        - from: resource_attribute
          name: k8s.pod.uid
    - sources:
        - from: connection

----------------------------------------

TITLE: Basic Kafka Receiver Configuration in YAML
DESCRIPTION: A minimal configuration example for the Kafka receiver, specifying only the required protocol version.

LANGUAGE: yaml
CODE:
receivers:
  kafka:
    protocol_version: 2.0.0

----------------------------------------

TITLE: Configuring Failover Connector in OpenTelemetry
DESCRIPTION: Example configuration showing how to set up the failover connector with multiple priority levels and pipelines. Demonstrates configuration of retry intervals and pipeline routing for traces with different priority levels.

LANGUAGE: yaml
CODE:
connectors:
  failover:
    priority_levels:
      - [traces/first, traces/also_first]
      - [traces/second]
      - [traces/third]
    retry_interval: 10s

service:
  pipelines:
    traces:
      receivers: [otlp]
      exporters: [failover]
    traces/first:
      receivers: [failover]
      exporters: [otlp/first]
    traces/second:
      receivers: [failover]
      exporters: [otlp/second]
    traces/third:
      receivers: [failover]
      exporters: [otlp/third]
    traces/also_first:
      receivers: [failover]
      exporters: [otlp/fourth]

----------------------------------------

TITLE: Configuring Basic Span Metrics Connector in YAML
DESCRIPTION: Example configuration for the spanmetrics connector with custom histogram buckets, dimensions, exemplars, and event tracking. Shows basic setup with nop receivers and exporters.

LANGUAGE: yaml
CODE:
receivers:
  nop:

exporters:
  nop:

connectors:
  spanmetrics:
    histogram:
      explicit:
        buckets: [100us, 1ms, 2ms, 6ms, 10ms, 100ms, 250ms]
    dimensions:
      - name: http.method
        default: GET
      - name: http.status_code
    exemplars:
      enabled: true
    exclude_dimensions: ['status.code']
    dimensions_cache_size: 1000
    aggregation_temporality: "AGGREGATION_TEMPORALITY_CUMULATIVE"    
    metrics_flush_interval: 15s
    metrics_expiration: 5m
    events:
      enabled: true
      dimensions:
        - name: exception.type
        - name: exception.message
    resource_metrics_key_attributes:
      - service.name
      - telemetry.sdk.language
      - telemetry.sdk.name

service:
  pipelines:
    traces:
      receivers: [nop]
      exporters: [spanmetrics]
    metrics:
      receivers: [spanmetrics]
      exporters: [nop]

----------------------------------------

TITLE: Configuring Elasticsearch Receiver in YAML
DESCRIPTION: Example configuration for the Elasticsearch receiver showing how to set up node filters, disable specific metrics, configure authentication, and set collection intervals. The configuration demonstrates customizing node selection, metric filtering, and basic authentication setup.

LANGUAGE: yaml
CODE:
receivers:
  elasticsearch:
    metrics:
      elasticsearch.node.fs.disk.available:
        enabled: false
    nodes: ["_local"]
    skip_cluster_metrics: true
    indices: [".geoip_databases"]
    endpoint: http://localhost:9200
    username: otel
    password: password
    collection_interval: 10s

----------------------------------------

TITLE: Extracting Container Level Attributes
DESCRIPTION: Configuration example for extracting container-level attributes from Kubernetes metadata.

LANGUAGE: yaml
CODE:
pod_association:
- sources:
    - from: connection
extract:
  metadata:
  - k8s.pod.name
  - k8s.pod.uid
  - container.image.name
  - container.image.tag
  - k8s.container.name

----------------------------------------

TITLE: Configuring External Labels in Prometheus Remote Write Exporter
DESCRIPTION: Example configuration for adding external labels to metrics sent by the Prometheus Remote Write Exporter.

LANGUAGE: yaml
CODE:
exporters:
  prometheusremotewrite:
    endpoint: "https://my-cortex:7900/api/v1/push"
    external_labels:
      label_name1: label_value1
      label_name2: label_value2

----------------------------------------

TITLE: Basic SignalFx Exporter Configuration
DESCRIPTION: Minimal configuration example for the SignalFx exporter showing core settings like access token and realm specification.

LANGUAGE: yaml
CODE:
exporters:
  signalfx:
    access_token: <replace_with_actual_access_token>
    access_token_passthrough: true
    headers:
      added-entry: "added value"
      dot.test: test
    realm: us1
    timeout: 5s
    max_idle_conns: 80

----------------------------------------

TITLE: Routing Logs to Different Parsers Based on Format
DESCRIPTION: Configuration example showing how to route log entries to different parsers based on their format field. Routes JSON formatted logs to json parser and syslog formatted logs to syslog parser.

LANGUAGE: yaml
CODE:
- type: router
  routes:
    - output: my_json_parser
      expr: 'body.format == "json"'
    - output: my_syslog_parser
      expr: 'body.format == "syslog"'

----------------------------------------

TITLE: Basic Prometheus Receiver Configuration
DESCRIPTION: YAML configuration example showing how to set up the Prometheus receiver with basic scraping configuration including job definitions and static targets.

LANGUAGE: yaml
CODE:
receivers:
    prometheus:
      config:
        scrape_configs:
          - job_name: 'otel-collector'
            scrape_interval: 5s
            static_configs:
              - targets: ['0.0.0.0:8888']
          - job_name: k8s
            kubernetes_sd_configs:
            - role: pod
            relabel_configs:
            - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
              regex: "true"
              action: keep
            metric_relabel_configs:
            - source_labels: [__name__]
              regex: "(request_duration_seconds.*|response_duration_seconds.*)"
              action: keep

----------------------------------------

TITLE: Configuring Bearer Token Authentication in OpenTelemetry Collector YAML
DESCRIPTION: This YAML configuration demonstrates how to set up bearer token authentication for OpenTelemetry Collector exporters. It includes examples of single token, multiple tokens, and file-based token configurations, as well as their usage in OTLP exporters.

LANGUAGE: yaml
CODE:
extensions:
  bearertokenauth:
    token: "somerandomtoken"
    filename: "file-containing.token"
  bearertokenauth/withscheme:
    scheme: "Bearer"
    token: "randomtoken"
  bearertokenauth/multipletokens:
    scheme: "Bearer"
    tokens:
      - "randomtoken"
      - "thistokenalsoworks"

receivers:
  hostmetrics:
    scrapers:
      memory:
  otlp:
    protocols:
      grpc:

exporters:
  otlp/withauth:
    endpoint: 0.0.0.0:5000
    ca_file: /tmp/certs/ca.pem
    auth:
      authenticator: bearertokenauth

  otlphttp/withauth:
    endpoint: http://localhost:9000
    auth:
      authenticator: bearertokenauth/withscheme

service:
  extensions: [bearertokenauth, bearertokenauth/withscheme]
  pipelines:
    metrics:
      receivers: [hostmetrics]
      processors: []
      exporters: [otlp/withauth, otlphttp/withauth]

----------------------------------------

TITLE: Configuring Redaction Processor in YAML
DESCRIPTION: Example YAML configuration for the redaction processor, demonstrating various options such as allowed keys, ignored keys, blocked patterns, and value masking.

LANGUAGE: yaml
CODE:
processors:
  redaction:
    allow_all_keys: false
    allowed_keys:
      - description
      - group
      - id
      - name
    ignored_keys:
      - safe_attribute
    blocked_key_patterns:
      - ".*token.*"
      - ".*api_key.*"
    blocked_values:
      - "4[0-9]{12}(?:[0-9]{3})?"
      - "(5[1-5][0-9]{14})"
    allowed_values:
      - ".+@mycompany.com"
    hash_function: md5
    summary: debug

----------------------------------------

TITLE: Configuring Splunk HEC Exporter in YAML
DESCRIPTION: Example YAML configuration for the Splunk HEC Exporter, showcasing various settings including authentication, endpoint, source, sourcetype, index, TLS configuration, and advanced options.

LANGUAGE: yaml
CODE:
exporters:
  splunk_hec:
    # Splunk HTTP Event Collector token.
    token: "00000000-0000-0000-0000-0000000000000"
    # URL to a Splunk instance to send data to.
    endpoint: "https://splunk:8088/services/collector"
    # Optional Splunk source: https://docs.splunk.com/Splexicon:Source
    source: "otel"
    # Optional Splunk source type: https://docs.splunk.com/Splexicon:Sourcetype
    sourcetype: "otel"
    # Splunk index, optional name of the Splunk index targeted.
    index: "metrics"
    # Maximum HTTP connections to use simultaneously when sending data. Defaults to 100.
    max_idle_conns: 200
    # Whether to disable gzip compression over HTTP. Defaults to false.
    disable_compression: false
    # HTTP timeout when sending data. Defaults to 10s.
    timeout: 10s
    tls:
      # Whether to skip checking the certificate of the HEC endpoint when sending data over HTTPS. Defaults to false.
      insecure_skip_verify: false
      # Path to the CA cert to verify the server being connected to.
      ca_file: /certs/ExampleCA.crt
      # Path to the TLS cert to use for client connections when TLS client auth is required.
      cert_file: /certs/HECclient.crt
      # Path to the TLS key to use for TLS required connections.
      key_file: /certs/HECclient.key
    # Application name is used to track telemetry information for Splunk App's using HEC by App name.
    splunk_app_name: "OpenTelemetry-Collector Splunk Exporter"
    # Application version is used to track telemetry information for Splunk App's using HEC by App version.
    splunk_app_version: "v0.0.1"
    heartbeat:
      interval: 30s
    telemetry:
      enabled: true
      override_metrics_names:
        otelcol_exporter_splunkhec_heartbeats_sent: app_heartbeats_success_total
        otelcol_exporter_splunkhec_heartbeats_failed: app_heartbeats_failed_total
      extra_attributes:
        dataset_name: SplunkCloudBeaverStack
        custom_key: custom_value

----------------------------------------

TITLE: Configuring Kubernetes Cluster Receiver
DESCRIPTION: Basic configuration example for the Kubernetes Cluster receiver showing core settings including authentication type, node conditions, and metric filters.

LANGUAGE: yaml
CODE:
  k8s_cluster:
    auth_type: kubeConfig
    node_conditions_to_report: [Ready, MemoryPressure]
    allocatable_types_to_report: [cpu, memory]
    metrics:
      k8s.container.cpu_limit:
        enabled: false
    resource_attributes:
      container.id:
        enabled: false

----------------------------------------

TITLE: Configuring Regex Parser in YAML
DESCRIPTION: Example configuration for parsing the 'message' field with a regular expression. It extracts 'host' and 'type' attributes from the message.

LANGUAGE: yaml
CODE:
- type: regex_parser
  parse_from: body.message
  regex: '^Host=(?P<host>[^,]+), Type=(?P<type>.*)$'

----------------------------------------

TITLE: Configuring Receiver Creator with Kubernetes Observer
DESCRIPTION: Example configuration showing how to setup receiver_creator with Kubernetes observer to discover and monitor pods, services and ingresses. Includes configuration for Prometheus scraping, Redis monitoring, SQL Server monitoring and Kubelet stats collection.

LANGUAGE: yaml
CODE:
extensions:
  k8s_observer:
    observe_nodes: true
    observe_services: true
    observe_ingresses: true
  host_observer:

receivers:
  receiver_creator/1:
    watch_observers: [k8s_observer]
    receivers:
      prometheus_simple:
        rule: type == "pod" && annotations["prometheus.io/scrape"] == "true"
        config:
          metrics_path: '`"prometheus.io/path" in annotations ? annotations["prometheus.io/path"] : "/metrics"`'
          endpoint: '`endpoint`:`"prometheus.io/port" in annotations ? annotations["prometheus.io/port"] : 9090`'

      redis/1:
        rule: type == "port" && port == 6379
        config:
          password: secret
          collection_interval: '`pod.annotations["collection_interval"]`'

----------------------------------------

TITLE: Configuring Routing Processor with OTTL Conditions in YAML
DESCRIPTION: Example configuration for the routing processor using OpenTelemetry Transformation Language (OTTL) statements as routing conditions. It demonstrates how to route traces based on resource attributes and perform attribute modifications.

LANGUAGE: yaml
CODE:
processors:
  routing:
    default_exporters:
    - jaeger
    error_mode: ignore
    table:
      - statement: route() where resource.attributes["X-Tenant"] == "acme"
        exporters: [jaeger/acme]
      - statement: delete_key(resource.attributes, "X-Tenant") where IsMatch(resource.attributes["X-Tenant"], ".*corp")
        exporters: [jaeger/ecorp]

exporters:
  jaeger:
    endpoint: localhost:14250
  jaeger/acme:
    endpoint: localhost:24250
  jaeger/ecorp:
    endpoint: localhost:34250

----------------------------------------

TITLE: Configuring Service Account Authentication for Kubelet Stats
DESCRIPTION: Configuration example for using Kubernetes service account authentication with the downward API to access kubelet metrics.

LANGUAGE: yaml
CODE:
receivers:
  kubeletstats:
    collection_interval: 20s
    auth_type: "serviceAccount"
    endpoint: "https://${env:K8S_NODE_NAME}:10250"
    insecure_skip_verify: true
exporters:
  file:
    path: "fileexporter.txt"
service:
  pipelines:
    metrics:
      receivers: [kubeletstats]
      exporters: [file]

----------------------------------------

TITLE: Configuring Load Balancing Exporter with Kubernetes Resolver
DESCRIPTION: Example YAML configuration for the load balancing exporter using a Kubernetes resolver to discover backend endpoints.

LANGUAGE: yaml
CODE:
receivers:
  otlp:
    protocols:
      grpc:
        endpoint: localhost:4317

processors:

exporters:
  loadbalancing:
    routing_key: "service"
    protocol:
      otlp:
        # all options from the OTLP exporter are supported
        # except the endpoint
        timeout: 1s
    resolver:
      # use k8s service resolver, if collector runs in kubernetes environment
      k8s:
        service: lb-svc.kube-public
        ports:
          - 15317
          - 16317

service:
  pipelines:
    traces:
      receivers:
        - otlp
      processors: []
      exporters:
        - loadbalancing
    logs:
      receivers:
        - otlp
      processors: []
      exporters:
        - loadbalancing

----------------------------------------

TITLE: Configuring AWS Proxy Extension in YAML
DESCRIPTION: Example YAML configuration for the AWS Proxy extension. It demonstrates various optional settings including endpoint, proxy address, TLS configuration, region, role ARN, AWS endpoint, and service name.

LANGUAGE: yaml
CODE:
extensions:
  awsproxy:
    endpoint: 0.0.0.0:2000
    proxy_address: ""
    tls:
      insecure: false
      server_name_override: ""
    region: ""
    role_arn: ""
    aws_endpoint: ""
    local_mode: false
    service_name: "xray"

----------------------------------------

TITLE: Configuring Kubeconfig Authentication for Kubelet Stats
DESCRIPTION: Configuration example for using kubeconfig file authentication with API server proxy to access kubelet metrics.

LANGUAGE: yaml
CODE:
receivers:
  kubeletstats:
    collection_interval: 20s
    auth_type: "kubeConfig"
    context: "my-context"
    insecure_skip_verify: true
    endpoint: "${env:K8S_NODE_NAME}"
exporters:
  file:
    path: "fileexporter.txt"
service:
  pipelines:
    metrics:
      receivers: [kubeletstats]
      exporters: [file]

----------------------------------------

TITLE: Visualizing Schema Processor Components with Mermaid Diagram
DESCRIPTION: This Mermaid diagram illustrates the structure and flow of the Schema Processor components. It shows how data moves from the previous Collector component through the Transformer, Translation Manager, Translator, Revision, ChangeList, and finally through the Interpreter which contains the Transformer and Migrator.

LANGUAGE: mermaid
CODE:
graph LR;
    A[Previous Collector Component] --> B[Transformer]
    B -- Schema URL --> C[Translation Manager]
    C -- Translation --> B
    B --> H[Translator]
    H --> E[Revision]
    E --> I[ChangeList]
    subgraph Interpreter
        direction RL
        I --> F[Transformer]
        F --> G[Migrator]
    end

----------------------------------------

TITLE: Basic Elasticsearch Exporter Configuration
DESCRIPTION: Example configuration showing basic setup with authentication and pipeline definition

LANGUAGE: yaml
CODE:
exporters:
  elasticsearch:
    endpoint: https://elastic.example.com:9200
    auth:
      authenticator: basicauth

extensions:
  basicauth:
    client_auth:
      username: elastic
      password: changeme

service:
  extensions: [basicauth]
  pipelines:
    logs:
      receivers: [otlp]
      processors: [batch]
      exporters: [elasticsearch]
    traces:
      receivers: [otlp]
      processors: [batch] 
      exporters: [elasticsearch]

----------------------------------------

TITLE: Configuring Load Balancing Exporter with Static Resolver
DESCRIPTION: Example YAML configuration for the load balancing exporter using a static resolver with multiple backend endpoints.

LANGUAGE: yaml
CODE:
receivers:
  otlp:
    protocols:
      grpc:
        endpoint: localhost:4317

processors:

exporters:
  loadbalancing:
    routing_key: "service"
    protocol:
      otlp:
        # all options from the OTLP exporter are supported
        # except the endpoint
        timeout: 1s
    resolver:
      static:
        hostnames:
        - backend-1:4317
        - backend-2:4317
        - backend-3:4317
        - backend-4:4317
      # Notice to config a headless service DNS in Kubernetes
      # dns:
      #  hostname: otelcol-headless.observability.svc.cluster.local

service:
  pipelines:
    traces:
      receivers:
        - otlp
      processors: []
      exporters:
        - loadbalancing
    logs:
      receivers:
        - otlp
      processors: []
      exporters:
        - loadbalancing

----------------------------------------

TITLE: Configuring Skywalking Receiver with gRPC and HTTP Protocols in YAML
DESCRIPTION: Example configuration for setting up the Skywalking receiver with both gRPC and HTTP protocols. Demonstrates how to configure endpoints and set up trace and metric pipelines. The receiver supports Apache Skywalking-Java Agent version 8.9.0+ and allows customization of protocol endpoints.

LANGUAGE: yaml
CODE:
receivers:
  skywalking:
    protocols:
      grpc:
        endpoint: 0.0.0.0:11800
      http:
        endpoint: 0.0.0.0:12800

service:
  pipelines:
    traces:
      receivers: [skywalking]
    metrics:
      receivers: [skywalking]


----------------------------------------

TITLE: Target Allocator Configuration
DESCRIPTION: YAML configuration for setting up the OpenTelemetry Operator's Target Allocator integration with the Prometheus receiver.

LANGUAGE: yaml
CODE:
receivers:
  prometheus:
    target_allocator:
      endpoint: http://my-targetallocator-service
      interval: 30s
      collector_id: collector-1

----------------------------------------

TITLE: Configuring Prometheus Remote Write Exporter in YAML
DESCRIPTION: Basic configuration example for the Prometheus Remote Write Exporter, including endpoint, TLS settings, and resource attribute conversion.

LANGUAGE: yaml
CODE:
exporters:
  prometheusremotewrite:
    endpoint: "https://my-cortex:7900/api/v1/push"
    wal: # Enabling the Write-Ahead-Log for the exporter.
      directory: ./prom_rw # The directory to store the WAL in
      buffer_size: 100 # Optional count of elements to be read from the WAL before truncating; default of 300
      truncate_frequency: 45s # Optional frequency for how often the WAL should be truncated. It is a time.ParseDuration; default of 1m
    resource_to_telemetry_conversion:
      enabled: true # Convert resource attributes to metric labels

----------------------------------------

TITLE: Configuring Datadog Connector with Sampling in OpenTelemetry Collector
DESCRIPTION: Example YAML configuration for setting up the Datadog Connector with probabilistic sampling in the OpenTelemetry Collector. It demonstrates how to use the connector in multiple pipelines for both traces and metrics.

LANGUAGE: yaml
CODE:
processors:
  probabilistic_sampler:
    sampling_percentage: 20

connectors:
  datadog/connector:

exporters:
  datadog:
    api:
      key: ${env:DD_API_KEY}

service:
  pipelines:
    traces:
      receivers: [otlp]
      processors: [batch]
      exporters: [datadog/connector]

    traces/2: # this pipeline uses sampling
      receivers: [datadog/connector]
      processors: [batch, probabilistic_sampler]
      exporters: [datadog]

    metrics:
      receivers: [datadog/connector]
      processors: [batch]
      exporters: [datadog]

----------------------------------------

TITLE: Configuring Routing Connector for Log Routing by Tenant
DESCRIPTION: This YAML configuration demonstrates how to route logs based on tenant information using the Routing Connector. It sets up different file exporters for different tenants and uses the 'request' context to route logs.

LANGUAGE: yaml
CODE:
receivers:
    otlp:

exporters:
  file/other:
    path: ./other.log
  file/acme:
    path: ./acme.log
  file/ecorp:
    path: ./ecorp.log

connectors:
  routing:
    default_pipelines: [logs/other]
    table:
      - context: request
        condition: request["X-Tenant"] == "acme"
        pipelines: [logs/acme]
      - context: request
        condition: request["X-Tenant"] == "ecorp"
        pipelines: [logs/ecorp]

service:
  pipelines:
    logs/in:
      receivers: [otlp]
      exporters: [routing]
    logs/acme:
      receivers: [routing]
      exporters: [file/acme]
    logs/ecorp:
      receivers: [routing]
      exporters: [file/ecorp]
    logs/other:
      receivers: [routing]
      exporters: [file/other]

----------------------------------------

TITLE: Configuring CloudWatch Autodiscovery in YAML
DESCRIPTION: Example configuration for CloudWatch receiver using autodiscovery to collect logs from AWS EKS with stream filtering.

LANGUAGE: yaml
CODE:
awscloudwatch:
  region: us-west-1
  logs:
    poll_interval: 1m
    groups:
      autodiscover:
        limit: 100
        prefix: /aws/eks/
        streams:
          prefixes: [kube-api-controller]

----------------------------------------

TITLE: Configuring Traces Pipeline with Logzio Exporter
DESCRIPTION: YAML configuration for setting up traces pipeline with OTLP and Jaeger receivers, batch processor, and Logzio traces exporter. Includes multiple protocol endpoints and debug logging configuration.

LANGUAGE: yaml
CODE:
receivers:
  otlp:
    protocols:
      grpc:
        endpoint: "0.0.0.0:4317"
      http:
        endpoint: "0.0.0.0:4318"
  jaeger:
    protocols:
      thrift_compact:
        endpoint: "0.0.0.0:6831"
      thrift_binary:
        endpoint: "0.0.0.0:6832"
      grpc:
        endpoint: "0.0.0.0:14250"
      thrift_http:
        endpoint: "0.0.0.0:14268"
processors:
  batch:
    send_batch_size: 10000
    timeout: 1s
exporters:
  logzio/traces:
    account_token: "LOGZIOtraceTOKEN"
    region: "us"
service:
  pipelines:
    traces:
      receivers: [ otlp,jaeger ]
      processors: [ batch ]
      exporters: [ logzio/traces ]
  telemetry:
    logs:
      level: "debug"

----------------------------------------

TITLE: Configuring MySQL Receiver in OpenTelemetry Collector
DESCRIPTION: Example configuration for the MySQL receiver showing how to set up connection details, collection intervals, and statement event monitoring parameters. Demonstrates standard configuration options including endpoint, credentials, database selection, and timing settings.

LANGUAGE: yaml
CODE:
receivers:
  mysql:
    endpoint: localhost:3306
    username: otel
    password: ${env:MYSQL_PASSWORD}
    database: otel
    collection_interval: 10s
    initial_delay: 1s
    statement_events:
      digest_text_limit: 120
      time_limit: 24h
      limit: 250

----------------------------------------

TITLE: Configuring Azure Monitor Receiver with Default Credentials Authentication
DESCRIPTION: Example configuration for the Azure Monitor Receiver using Environment Variables (Default Credentials) for authentication. It only requires the subscription ID.

LANGUAGE: yaml
CODE:
receivers:
  azuremonitor:
    subscription_id: "${subscription_id}"
    auth: "default_credentials"

----------------------------------------

TITLE: Configuring Routing Processor in YAML
DESCRIPTION: Example configuration for the routing processor, demonstrating how to route traces based on a tenant header to different Jaeger exporters.

LANGUAGE: yaml
CODE:
processors:
  routing:
    from_attribute: X-Tenant
    default_exporters: [jaeger]
    table:
    - value: acme
      exporters: [jaeger/acme]
exporters:
  jaeger:
    endpoint: localhost:14250
  jaeger/acme:
    endpoint: localhost:24250
service:
  pipelines:
    traces:
      receivers: [otlp]
      processors: [routing]
      exporters: [jaeger, jaeger/acme]

----------------------------------------

TITLE: Configuring TLS Authentication for Kubelet Stats Receiver
DESCRIPTION: Example configuration showing how to set up TLS authentication with certificates for connecting to the kubelet API server.

LANGUAGE: yaml
CODE:
receivers:
  kubeletstats:
    collection_interval: 20s
    initial_delay: 1s
    auth_type: "tls"
    ca_file: "/path/to/ca.crt"
    key_file: "/path/to/apiserver.key"
    cert_file: "/path/to/apiserver.crt"
    endpoint: "https://192.168.64.1:10250"
    insecure_skip_verify: true
exporters:
  file:
    path: "fileexporter.txt"
service:
  pipelines:
    metrics:
      receivers: [kubeletstats]
      exporters: [file]

----------------------------------------

TITLE: Configuring Splunk Enterprise Receiver in YAML
DESCRIPTION: Example configuration showing how to set up the Splunk Enterprise receiver with basic authentication for both indexer and cluster master nodes. Demonstrates required fields like endpoint and auth configuration, as well as optional settings like collection interval and timeout.

LANGUAGE: yaml
CODE:
extensions:
    basicauth/indexer:
        client_auth:
            username: admin
            password: securityFirst
    basicauth/cluster_master:
        client_auth:
            username: admin
            password: securityFirst

receivers:
    splunkenterprise:
        indexer:
            auth: 
              authenticator: basicauth/indexer
            endpoint: "https://localhost:8089"
            timeout: 45s
        cluster_master:
            auth: 
              authenticator: basicauth/cluster_master
            endpoint: "https://localhost:8089"
            timeout: 45s

exporters:
  debug:
    verbosity: basic

service:
  extensions: [basicauth/indexer, basicauth/cluster_master]
  pipelines:
    metrics:
      receivers: [splunkenterprise]
      exporters: [debug]

----------------------------------------

TITLE: Configuring Health Check Extension V2 in YAML
DESCRIPTION: Example YAML configuration for the Health Check Extension V2, including HTTP and gRPC services with component health opt-in.

LANGUAGE: yaml
CODE:
extensions:
  healthcheckv2:
    use_v2: true
    component_health:
      include_permanent_errors: false
      include_recoverable_errors: true
      recovery_duration: 5m
    http:
      endpoint: "localhost:13133"
      status:
        enabled: true
        path: "/health/status"
      config:
        enabled: true
        path: "/health/config"
    grpc:
      endpoint: "localhost:13132"
      transport: "tcp"

----------------------------------------

TITLE: Configuring Apache Doris Exporter in YAML
DESCRIPTION: Example YAML configuration for the Apache Doris exporter, including endpoint, database, authentication, table names, schema creation, and various other settings for optimizing data export to Apache Doris.

LANGUAGE: yaml
CODE:
exporters:
  doris:
    endpoint: http://localhost:8030
    database: otel
    username: admin
    password: admin
    table:
      logs: otel_logs
      traces: otel_traces
      metrics: otel_metrics
    create_schema: true
    mysql_endpoint: localhost:9030
    history_days: 0
    create_history_days: 0
    replication_num: 1
    timezone: Asia/Shanghai
    timeout: 5s
    sending_queue:
      enabled: true
      num_consumers: 10
      queue_size: 1000
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 300s

----------------------------------------

TITLE: Configuring AWS X-Ray Receiver in YAML
DESCRIPTION: Example configuration for setting up the AWS X-Ray receiver with UDP listening endpoint and TCP proxy server settings. Includes options for TLS configuration, AWS authentication, and region settings.

LANGUAGE: yaml
CODE:
receivers:
  awsxray:
    endpoint: 0.0.0.0:2000
    transport: udp
    proxy_server:
      endpoint: 0.0.0.0:2000
      proxy_address: ""
      tls:
        insecure: false
        server_name_override: ""
      region: ""
      role_arn: ""
      aws_endpoint: ""
      local_mode: false

----------------------------------------

TITLE: Configuring Redis Receiver in YAML
DESCRIPTION: This YAML configuration example shows how to set up the Redis receiver in the OpenTelemetry Collector. It specifies the endpoint, collection interval, and password (using an environment variable) for connecting to a Redis instance.

LANGUAGE: yaml
CODE:
receivers:
  redis:
    endpoint: "localhost:6379"
    collection_interval: 10s
    password: ${env:REDIS_PASSWORD}

----------------------------------------

TITLE: Configuring Load Balancing Exporter with Persistent Queue and Retry
DESCRIPTION: Example YAML configuration for the load balancing exporter with persistent queue, retry, and timeout settings.

LANGUAGE: yaml
CODE:
receivers:
  otlp:
    protocols:
      grpc:
        endpoint: localhost:4317

processors:

exporters:
  loadbalancing:
    timeout: 10s
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 300s
    sending_queue:
      enabled: true
      num_consumers: 2
      queue_size: 1000
      storage: file_storage/otc
    routing_key: "service"
    protocol:
      otlp:
        # all options from the OTLP exporter are supported
        # except the endpoint
        timeout: 1s
        sending_queue:
          enabled: true
    resolver:
      static:
        hostnames:
        - backend-1:4317
        - backend-2:4317
        - backend-3:4317
        - backend-4:4317
      # Notice to config a headless service DNS in Kubernetes
      # dns:
      #  hostname: otelcol-headless.observability.svc.cluster.local

extensions:
  file_storage/otc:
    directory: /var/lib/storage/otc
    timeout: 10s

service:
  extensions: [file_storage]
  pipelines:
    traces:
      receivers:
        - otlp
      processors: []
      exporters:
        - loadbalancing
    logs:
      receivers:
        - otlp
      processors: []
      exporters:
        - loadbalancing

----------------------------------------

TITLE: Practical Example of Tail Sampling Configuration
DESCRIPTION: A real-world example of tail sampling configuration implementing multiple sampling rules for different scenarios.

LANGUAGE: yaml
CODE:
tail_sampling:
  decision_wait: 10s
  num_traces: 100
  expected_new_traces_per_sec: 10
  policies: [
      {
        name: backwards-compatibility-policy,
        type: and,
        and:
          {
            and_sub_policy:
              [
                {
                  name: services-using-tail_sampling-policy,
                  type: string_attribute,
                  string_attribute:
                    {
                      key: service.name,
                      values:
                        [
                          list,
                          of,
                          services,
                          using,
                          tail_sampling,
                        ],
                      invert_match: true,
                    },
                },
                { name: sample-all-policy, type: always_sample },
              ],
          },
      },
      {
        name: team_a-probe,
        type: and,
        and:
          {
            and_sub_policy:
              [
                {
                  name: service-name-policy,
                  type: string_attribute,
                  string_attribute:
                    {
                      key: service.name,
                      values: [service-1, service-2, service-3],
                    },
                },
                {
                  name: route-live-ready-policy,
                  type: string_attribute,
                  string_attribute:
                    {
                      key: http.route,
                      values: [/live, /ready],
                      enabled_regex_matching: true,
                    },
                },
                {
                  name: probabilistic-policy,
                  type: probabilistic,
                  probabilistic: { sampling_percentage: 0.1 },
                },
              ],
          },
      },
      {
        name: team_a-noisy-endpoint-1,
        type: and,
        and:
          {
            and_sub_policy:
              [
                {
                  name: service-name-policy,
                  type: string_attribute,
                  string_attribute:
                    { key: service.name, values: [service-1] },
                },
                {
                  name: route-name-policy,
                  type: string_attribute,
                  string_attribute:
                    {
                      key: http.route,
                      values: [/v1/name/.+],
                      enabled_regex_matching: true,
                    },
                },
                {
                  name: probabilistic-policy,
                  type: probabilistic,
                  probabilistic: { sampling_percentage: 1 },
                },
              ],
          },
      },
      {
        name: team_a-service-1,
        type: and,
        and:
          {
            and_sub_policy:
              [
                {
                  name: service-name-policy,
                  type: string_attribute,
                  string_attribute:
                    { key: service.name, values: [service-1] },
                },
                {
                  name: route-name-policy,
                  type: string_attribute,
                  string_attribute:
                    {
                      key: http.route,
                      values: [/v1/name/.+],
                      enabled_regex_matching: true,
                      invert_match: true,
                    },
                },
                {
                  name: probabilistic-policy,
                  type: probabilistic,
                  probabilistic: { sampling_percentage: 100 },
                },
              ],
          },
      },
      {
        name: team_a-status-policy,
        type: and,
        and:
          {
            and_sub_policy:
              [
                {
                  name: service-name-policy,
                  type: string_attribute,
                  string_attribute:
                    {
                      key: service.name,
                      values:
                        [
                          list,
                          of,
                          services,
                          using,
                          tail_sampling,
                        ],
                    },
                },
                {
                  name: trace-status-policy,
                  type: status_code,
                  status_code: { status_codes: [ERROR] },
                },
              ],
          },
      },
      {
        name: team_a-force-sample,
        type: boolean_attribute,
        boolean_attribute: { key: app.force_sample, value: true },
      },
    {
      name: team_a-do-not-sample,
      type: boolean_attribute,
      boolean_attribute: { key: app.do_not_sample, value: true, invert_match: true },
    },
    ]

----------------------------------------

TITLE: Configuring Snowflake Receiver in YAML
DESCRIPTION: Example configuration for setting up the Snowflake metrics receiver with custom credentials, account details, and metric collection settings. Shows how to enable/disable specific metrics and set collection intervals.

LANGUAGE: yaml
CODE:
receivers:
  snowflake:
    username: snowflakeuser
    password: securepassword
    account: bigbusinessaccount
    warehouse: metricWarehouse
    collection_interval: 5m
    metrics:
      snowflake.database.bytes_scanned.avg:
        enabled: true
      snowflake.query.bytes_deleted.avg:
        enabled: false

----------------------------------------

TITLE: Configuring Windows Service Monitoring for Specific Services
DESCRIPTION: YAML configuration example showing how to monitor specific Windows services with a customizable collection interval. The configuration allows listing specific services to monitor.

LANGUAGE: yaml
CODE:
windowsservice:
  collection_interval: <duration> # default = 1m
  include_services:
    - service1
    - service2
    - service3
    ...

----------------------------------------

TITLE: Loki Exporter Metric Definition Table
DESCRIPTION: Markdown table defining the properties of the otelcol_lokiexporter_send_failed_due_to_missing_labels metric, including its unit, metric type, value type, and monotonicity.

LANGUAGE: markdown
CODE:
| Unit | Metric Type | Value Type | Monotonic |
| ---- | ----------- | ---------- | --------- |
| 1 | Sum | Int | true |

----------------------------------------

TITLE: Setting Up MongoDB Atlas Log Collection in YAML
DESCRIPTION: Configuration for receiving logs from MongoDB Atlas, including project-specific settings for audit and host logs.

LANGUAGE: yaml
CODE:
receivers:
  mongodbatlas:
    logs:
      enabled: true
      projects: 
        - name: "project 1"
          collect_audit_logs: true
          collect_host_logs: true

----------------------------------------

TITLE: Configuring PostgreSQL Receiver with Basic Settings
DESCRIPTION: Example configuration showing basic setup of PostgreSQL receiver with authentication, database selection, and collection interval settings.

LANGUAGE: yaml
CODE:
receivers:
  postgresql:
    endpoint: localhost:5432
    transport: tcp
    username: otel
    password: ${env:POSTGRESQL_PASSWORD}
    databases:
      - otel
    collection_interval: 10s
    tls:
      insecure: false
      insecure_skip_verify: false
      ca_file: /home/otel/authorities.crt
      cert_file: /home/otel/mypostgrescert.crt
      key_file: /home/otel/mypostgreskey.key

----------------------------------------

TITLE: Configuring SAP HANA Receiver
DESCRIPTION: YAML configuration example for the SAP HANA receiver showing basic setup with endpoint, collection interval, and metric enablement options.

LANGUAGE: yaml
CODE:
receivers:
  saphana:
    endpoint: "localhost:33015"
    collection_interval: 60s
    metrics:
      saphana.cpu.used:
        enabled: false

----------------------------------------

TITLE: Configuring Splunk HEC Receiver in YAML
DESCRIPTION: Example YAML configuration for the Splunk HEC Receiver, including both basic and advanced settings. Demonstrates how to set up TLS, custom paths, and attribute mappings.

LANGUAGE: yaml
CODE:
receivers:
  splunk_hec:
  splunk_hec/advanced:
    access_token_passthrough: true
    tls:
      cert_file: /test.crt
      key_file: /test.key
    raw_path: "/raw"
    hec_metadata_to_otel_attrs:
      source: "mysource"
      sourcetype: "mysourcetype"
      index: "myindex"
      host: "myhost"
    ack: 
      extension: ack/in_memory

----------------------------------------

TITLE: Configuring StatsD Receiver in YAML
DESCRIPTION: Example configuration for StatsD receiver showing all available options including endpoint, aggregation interval, metric type enabling, and timer histogram mapping settings.

LANGUAGE: yaml
CODE:
receivers:
  statsd:
  statsd/2:
    endpoint: "localhost:8127"
    aggregation_interval: 70s
    enable_metric_type: true
    is_monotonic_counter: false
    timer_histogram_mapping:
      - statsd_type: "histogram"
        observer_type: "gauge"
      - statsd_type: "timing"
        observer_type: "histogram"
        histogram: 
          max_size: 100
      - statsd_type: "distribution"
        observer_type: "summary"
        summary: 
          percentiles: [0, 10, 50, 90, 95, 100]

----------------------------------------

TITLE: Configuring Cassandra Exporter in YAML
DESCRIPTION: Example configuration for the Cassandra exporter showing all available options including connection settings, keyspace configuration, table names, replication strategy, compression settings, and authentication credentials.

LANGUAGE: yaml
CODE:
exporters:
  cassandra:
    dsn: 127.0.0.1
    port: 9042
    timeout: 10s
    keyspace: "otel"
    trace_table: "otel_spans"
    replication:
      class: "SimpleStrategy"
      replication_factor: 1
    compression:
      algorithm: "ZstdCompressor"
    auth:
      username: "your-username"
      password: "your-password"

----------------------------------------

TITLE: Configuring File Log Receiver for Multiline Logs
DESCRIPTION: Example configuration for parsing multiline logs. It specifies a pattern to identify the start of a new log entry, useful for stack traces or multi-line error messages.

LANGUAGE: yaml
CODE:
receivers:
  filelog:
    include:
    - /var/log/example/multiline.log
    multiline:
      line_start_pattern: ^Exception

----------------------------------------

TITLE: Configuring Grafana Data Sources for Service Graph Visualization
DESCRIPTION: This YAML configuration sets up Prometheus and Tempo data sources in Grafana for visualizing service graph metrics. It links the Tempo data source to the Prometheus backend where metrics are sent.

LANGUAGE: yaml
CODE:
apiVersion: 1
datasources:
  # Prometheus backend where metrics are sent
  - name: Prometheus
    type: prometheus
    uid: prometheus
    url: <prometheus-url>
    jsonData:
        httpMethod: GET
    version: 1
  - name: Tempo
    type: tempo
    uid: tempo
    url: <tempo-url>
    jsonData:
      httpMethod: GET
      serviceMap:
        datasourceUid: 'prometheus'
    version: 1

----------------------------------------

TITLE: Configuring JMX Receiver in YAML for OpenTelemetry Collector
DESCRIPTION: This YAML configuration snippet demonstrates how to set up the JMX Receiver with various options including JAR path, endpoint, target system, collection interval, and authentication details.

LANGUAGE: yaml
CODE:
receivers:
  jmx:
    jar_path: /opt/opentelemetry-java-contrib-jmx-metrics.jar
    endpoint: my_jmx_host:12345
    target_system: jvm
    collection_interval: 10s
    initial_delay: 1s
    # optional: the same as specifying OTLP receiver endpoint.
    otlp:
      endpoint: mycollectorotlpreceiver:4317
    username: my_jmx_username
    # determined by the environment variable value
    password: ${env:MY_JMX_PASSWORD}
    resource_attributes:
      my.attr: my.value
      my.other.attr: my.other.value
    log_level: info
    additional_jars:
      - /path/to/other.jar

----------------------------------------

TITLE: SAPM Exporter Configuration Example in YAML
DESCRIPTION: Complete example configuration for the SAPM exporter showing common settings including access token, endpoint configuration, connection limits, and worker settings.

LANGUAGE: yaml
CODE:
exporters:
  sapm:
    access_token: YOUR_ACCESS_TOKEN
    access_token_passthrough: true
    endpoint: https://ingest.YOUR_SIGNALFX_REALM.signalfx.com/v2/trace
    max_connections: 100
    num_workers: 8
    log_detailed_response: true

----------------------------------------

TITLE: Configuring AWS S3 Exporter in YAML
DESCRIPTION: Example YAML configuration for the AWS S3 Exporter, specifying region, bucket, prefix, and optional sending queue settings.

LANGUAGE: yaml
CODE:
exporters:
  awss3:
    s3uploader:
      region: 'eu-central-1'
      s3_bucket: 'databucket'
      s3_prefix: 'metric'

    # Optional (disabled by default)
    sending_queue:
      enabled: true
      num_consumers: 10
      queue_size: 100

----------------------------------------

TITLE: Configuring NGINX Receiver in YAML
DESCRIPTION: Example YAML configuration for the NGINX receiver in OpenTelemetry Collector. It specifies the endpoint for the NGINX status module and the collection interval for metrics.

LANGUAGE: yaml
CODE:
receivers:
  nginx:
    endpoint: "http://localhost:80/status"
    collection_interval: 10s

----------------------------------------

TITLE: Configuring Fluent Forward Receiver in YAML for OpenTelemetry Collector
DESCRIPTION: A basic configuration example for the Fluent Forward receiver that listens on all interfaces on port 8006. This YAML snippet can be included in the OpenTelemetry Collector configuration file.

LANGUAGE: yaml
CODE:
receivers:
  fluentforward:
    endpoint: 0.0.0.0:8006

----------------------------------------

TITLE: Basic Solace Receiver Configuration with SASL Plain Authentication
DESCRIPTION: Simple configuration example showing how to set up the Solace receiver with basic SASL plain authentication. Includes broker connection, authentication details, and queue configuration for trace data collection.

LANGUAGE: yaml
CODE:
receivers:
  solace:
    broker: [localhost:5671]
    auth:
      sasl_plain:
        username: otel
        password: otel01$
    queue: queue://#telemetry-profile123

service:
  pipelines:
    traces:
      receivers: [solace]

----------------------------------------

TITLE: Configuring Kubernetes Objects Receiver in YAML
DESCRIPTION: Example configuration for the Kubernetes Objects Receiver, specifying authentication type, object types to collect, and collection modes.

LANGUAGE: yaml
CODE:
k8sobjects:
  auth_type: serviceAccount
  objects:
    - name: pods
      mode: pull
      label_selector: environment in (production),tier in (frontend)
      field_selector: status.phase=Running
      interval: 15m
    - name: events
      mode: watch
      group: events.k8s.io
      namespaces: [default]

----------------------------------------

TITLE: Basic Jaeger Receiver Configuration with YAML
DESCRIPTION: Basic configuration example showing how to set up Jaeger receiver with default gRPC protocol and custom endpoint configuration.

LANGUAGE: yaml
CODE:
receivers:
  jaeger:
    protocols:
      grpc:
  jaeger/withendpoint:
    protocols:
      grpc:
        endpoint: 0.0.0.0:14260

----------------------------------------

TITLE: Configuring GitLab Receiver with YAML
DESCRIPTION: Example configuration for setting up the GitLab receiver webhook. Demonstrates configuration of endpoint, paths, secret, and custom headers for webhook validation.

LANGUAGE: yaml
CODE:
receivers:
    gitlab:
        webhook:
            endpoint: localhost:19418
            path: /events
            health_path: /health
            secret: ${env:SECRET_STRING_VAR}
            required_headers:
                WAF-Header: "value"

----------------------------------------

TITLE: Configuring ClickHouse Exporter in OpenTelemetry Collector
DESCRIPTION: YAML configuration for the ClickHouse exporter in OpenTelemetry Collector. Sets up connection details, table names, and processing options for logs, traces, and metrics export.

LANGUAGE: yaml
CODE:
receivers:
  examplereceiver:
processors:
  batch:
    timeout: 5s
    send_batch_size: 100000
exporters:
  clickhouse:
    endpoint: tcp://127.0.0.1:9000?dial_timeout=10s
    database: otel
    async_insert: true
    ttl: 72h
    compress: lz4
    create_schema: true
    logs_table_name: otel_logs
    traces_table_name: otel_traces
    timeout: 5s
    metrics_tables:
      gauge: 
        name: "otel_metrics_gauge"
      sum: 
        name: "otel_metrics_sum"
      summary: 
        name: "otel_metrics_summary"
      histogram: 
        name: "otel_metrics_histogram"
      exponential_histogram: 
        name: "otel_metrics_exp_histogram"
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 300s
service:
  pipelines:
    logs:
      receivers: [ examplereceiver ]
      processors: [ batch ]
      exporters: [ clickhouse ]

----------------------------------------

TITLE: Configuring InfluxDB Exporter in YAML
DESCRIPTION: Example YAML configuration for the InfluxDB exporter, including endpoint, authentication, dimensions, and queue settings.

LANGUAGE: yaml
CODE:
exporters:
  influxdb:
    endpoint: http://localhost:8080
    timeout: 500ms
    org: my-org
    bucket: my-bucket
    token: my-token
    span_dimensions:
    - service.name
    - span.name
    log_record_dimensions:
    - service.name
    metrics_schema: telegraf-prometheus-v1

    sending_queue:
      enabled: true
      num_consumers: 3
      queue_size: 10

    retry_on_failure:
      enabled: true
      initial_interval: 1s
      max_interval: 3s
      max_elapsed_time: 10s

----------------------------------------

TITLE: Configuring Zipkin Receiver in YAML
DESCRIPTION: Basic YAML configuration for enabling the Zipkin receiver in OpenTelemetry Collector. The receiver can be configured with custom endpoints and parsing options for string tags.

LANGUAGE: yaml
CODE:
receivers:
  zipkin:

----------------------------------------

TITLE: Configuring AWS Firehose Receiver in YAML
DESCRIPTION: Example configuration for setting up the AWS Kinesis Data Firehose receiver with basic settings including endpoint, record type, access key, and TLS configuration.

LANGUAGE: yaml
CODE:
receivers:
  awsfirehose:
    endpoint: 0.0.0.0:4433
    record_type: cwmetrics
    access_key: "some_access_key"
    tls:
      cert_file: server.crt
      key_file: server.key

----------------------------------------

TITLE: Configuring MongoDB Atlas Alert Polling in YAML
DESCRIPTION: Setup for polling MongoDB Atlas alerts from the API, including project and cluster specifications, poll interval, and storage extension usage.

LANGUAGE: yaml
CODE:
receivers:
  mongodbatlas:
    public_key: <redacted>
    private_key: <redacted>
    alerts:
      enabled: true
      mode: poll
      projects:
      - name: Project 0
        include_clusters: [Cluster0]
      poll_interval: 1m
    storage: file_storage

----------------------------------------

TITLE: Configuring Carbon Receiver with YAML
DESCRIPTION: Example configuration showing both basic receiver settings and advanced regex parser configuration. Demonstrates how to set up endpoints, transport protocols, and custom parsing rules.

LANGUAGE: yaml
CODE:
receivers:
  carbon/receiver_settings:
    endpoint: localhost:8080
    transport: udp
  carbon/regex:
    parser:
      type: regex
      config:
        rules:
          - regexp: "(?P<key_base>test)\\.env(?P<key_env>[^.]*)\\.(?P<key_host>[^.]*)"
            name_prefix: "name-prefix"
            labels:
              dot.key: dot.value
              key: value
            type: cumulative
          - regexp: "(?P<key_just>test)\\.(?P<key_match>.*)"
        name_separator: "_"

----------------------------------------

TITLE: Configuring Azure Blob Receiver with Service Principal Authentication
DESCRIPTION: This YAML configuration snippet shows how to set up the Azure Blob Receiver using service principal authentication. It includes settings for auth method, service principal details, storage account URL, and event hub endpoint.

LANGUAGE: yaml
CODE:
receivers:
  azureblob:
    auth: service_principal
    service_principal:
      tenant_id: "${tenant_id}"
      client_id: "${client_id}"
      client_secret: "${env:CLIENT_SECRET}"
    storage_account_url: https://accountName.blob.core.windows.net
    event_hub:
      endpoint: Endpoint=sb://oteldata.servicebus.windows.net/;SharedAccessKeyName=otelhubbpollicy;SharedAccessKey=mPJVubIK5dJ6mLfZo1ucsdkLysLSQ6N7kddvsIcmoEs=;EntityPath=otellhub

----------------------------------------

TITLE: Configuring Span Metrics with Prometheus Remote Write
DESCRIPTION: Example configuration showing how to use the spanmetrics connector with Prometheus remote write exporter, including target info metric generation.

LANGUAGE: yaml
CODE:
receivers:
  otlp:
    protocols:
      http:
      grpc:

exporters:
  prometheusremotewrite:
    endpoint: http://localhost:9090/api/v1/write
    target_info:
      enabled: true

connectors:
  spanmetrics:
    namespace: span.metrics

service:
  pipelines:
    traces:
      receivers: [otlp]
      exporters: [spanmetrics]
    metrics:
      receivers: [spanmetrics]
      exporters: [prometheusremotewrite]

----------------------------------------

TITLE: Configuring File Stats Receiver in OpenTelemetry YAML
DESCRIPTION: Example configuration for the File Stats receiver showing how to set up file monitoring with a glob pattern, collection interval, and initial delay settings.

LANGUAGE: yaml
CODE:
receivers:
  filestats:
    include: /tmp/files/*
    collection_interval: 10s
    initial_delay: 1s

----------------------------------------

TITLE: Configuring Metric Declaration Rules in AWS EMF Exporter
DESCRIPTION: Example configuration demonstrating metric declaration rules for selecting specific metrics to export. It shows how to configure dimension rollup options and metric name selectors for both labeled and unlabeled metrics.

LANGUAGE: yaml
CODE:
exporters:
  awsemf:
    region: 'us-west-2'
    output_destination: stdout
    dimension_rollup_option: "NoDimensionRollup"
    metric_declarations:
      - dimensions: [[]]
        metric_name_selectors:
          # Metric without label
          - "^node_load15$"
      - dimensions: [[device, fstype], []]
        metric_name_selectors:
          - "^node_filesystem_readonly$"

----------------------------------------

TITLE: AWS ECS Metrics Pipeline Configuration
DESCRIPTION: Complete configuration example showing how to collect ECS metrics and export them to CloudWatch using the awsemf exporter.

LANGUAGE: yaml
CODE:
receivers:
  awsecscontainermetrics:
exporters:
  awsemf:
      namespace: 'ECS/ContainerMetrics/OpenTelemetry'
      log_group_name: '/ecs/containermetrics/opentelemetry'

service:
  pipelines:
      metrics:
          receivers: [awsecscontainermetrics]
          exporters: [awsemf]

----------------------------------------

TITLE: Configuring File Storage Extension in YAML
DESCRIPTION: Example YAML configuration for the File Storage extension, demonstrating basic setup and advanced options including compaction settings.

LANGUAGE: yaml
CODE:
extensions:
  file_storage:
  file_storage/all_settings:
    directory: /var/lib/otelcol/mydir
    timeout: 1s
    compaction:
      on_start: true
      directory: /tmp/
      max_transaction_size: 65_536
    fsync: false

service:
  extensions: [file_storage, file_storage/all_settings]
  pipelines:
    traces:
      receivers: [nop]
      exporters: [nop]

# Data pipeline is required to load the config.
receivers:
  nop:
exporters:
  nop:

----------------------------------------

TITLE: Configuring IIS Receiver in OpenTelemetry Collector
DESCRIPTION: YAML configuration example for the IIS receiver showing how to set collection interval and initial delay parameters. The collection_interval determines metric emission frequency while initial_delay sets the startup wait time.

LANGUAGE: yaml
CODE:
    receivers:
      iis:
        collection_interval: 10s
        initial_delay: 1s


----------------------------------------

TITLE: Basic HAProxy Receiver Configuration in YAML
DESCRIPTION: Basic configuration example showing how to set up the HAProxy receiver with a file socket endpoint and collection interval.

LANGUAGE: yaml
CODE:
haproxy:\n  endpoint: file:///var/run/haproxy.ipc\n  collection_interval: 1m\n  metrics:\n

----------------------------------------

TITLE: Basic Schema Processor Configuration
DESCRIPTION: Example configuration showing how to set up the schema processor with prefetch URLs and target schemas for translation.

LANGUAGE: yaml
CODE:
processors:
  schema:
    prefetch:
      - https://opentelemetry.io/schemas/1.9.0
    targets:
      - https://opentelemetry.io/schemas/1.6.1
      - http://example.com/telemetry/schemas/1.0.1

----------------------------------------

TITLE: Configuring Cumulative to Delta Processor with Specific Metrics in YAML
DESCRIPTION: This YAML configuration example shows how to set up the Cumulative to Delta Processor to convert specific cumulative sum or histogram metrics to delta metrics using a strict match type.

LANGUAGE: yaml
CODE:
processors:
    # processor name: cumulativetodelta
    cumulativetodelta:

        # list the exact cumulative sum or histogram metrics to convert to delta
        include:
            metrics:
                - <metric_1_name>
                - <metric_2_name>
                .
                .
                - <metric_n_name>
            match_type: strict

----------------------------------------

TITLE: Configuring Sematext Exporter in YAML
DESCRIPTION: Example configuration for the Sematext exporter showing timeout settings, queue configuration, retry policy, region selection, and metrics configuration including app token and payload limits.

LANGUAGE: yaml
CODE:
timeout: 500ms
sending_queue:
  enabled: true
  num_consumers: 3
  queue_size: 10
retry_on_failure:
  enabled: true
  initial_interval: 1s
  max_interval: 3s
  max_elapsed_time: 10s
region: US  
metrics:
  app_token: 2064e37c-4fac-45f6-831d-922d43fde759
  payload_max_lines: 100
  payload_max_bytes: 1000

----------------------------------------

TITLE: Configuring Group by Trace Processor in YAML
DESCRIPTION: Example YAML configuration for the Group by Trace processor, showing default settings and a custom configuration with different wait duration, number of traces, and workers.

LANGUAGE: yaml
CODE:
processors:
  groupbytrace:
  groupbytrace/2:
    wait_duration: 10s
    num_traces: 1000
    num_workers: 2

----------------------------------------

TITLE: Configuring TCP Check Receiver in YAML
DESCRIPTION: Example configuration for the TCP Check Receiver, specifying multiple targets with their endpoints and dialer timeouts. This snippet demonstrates how to set up the receiver in the OpenTelemetry Collector's configuration file.

LANGUAGE: yaml
CODE:
receivers:
  tcpcheck:
    targets:
      - endpoint: example.com:443
        dialer:
          timeout: 15s
      - endpoint: foobar.com:8080
        dialer:
          timeout: 15s
      - endpoint: localhost:10901

----------------------------------------

TITLE: Configuring AAD Authentication Proxy in Docker Compose
DESCRIPTION: This snippet demonstrates how to configure the AAD Authentication Proxy in a Docker Compose file, including environment variables for AAD authentication and certificate paths.

LANGUAGE: docker
CODE:
azuremonitor-ingestion-proxy:
    image: mcr.microsoft.com/azuremonitor/auth-proxy/prod/aad-auth-proxy/images/aad-auth-proxy:{latest version}
    restart: always
    volumes:
      - ./certs:/certs
    ports:
      - "8081:8081"
    environment:
      AUDIENCE: "https://monitor.azure.com/.default"
      TARGET_HOST: "{application insights ingestion endpoint}"
      LISTENING_PORT: "8081"
      IDENTITY_TYPE: "aadApplication"
      AAD_CLIENT_ID: "{service principal client id}"
      AAD_TENANT_ID: "{service principal tenant id}"
      AAD_CLIENT_CERTIFICATE_PATH: "{path to certificate}"

----------------------------------------

TITLE: PromQL Queries for Resource Attributes
DESCRIPTION: Examples of PromQL queries for selecting and grouping metrics by resource attributes using target_info joins.

LANGUAGE: promql
CODE:
app_ads_ad_requests_total * on (job, instance) group_left target_info{k8s_namespace_name="my-namespace"}

LANGUAGE: promql
CODE:
sum by (k8s_namespace_name) (app_ads_ad_requests_total * on (job, instance) group_left(k8s_namespace_name) target_info)

LANGUAGE: promql
CODE:
app_ads_ad_requests_total{namespace="my-namespace"}

sum by (namespace) (app_ads_ad_requests_total)

----------------------------------------

TITLE: Configuring Google Client Auth Extension in YAML
DESCRIPTION: This YAML configuration demonstrates how to set up the Google Client Auth extension for use with an OTLP exporter. It includes the extension declaration, receiver and exporter configurations, and service pipeline setup.

LANGUAGE: yaml
CODE:
extensions:
  googleclientauth:

receivers:
  otlp:
    protocols:
      grpc:

exporters:
  otlp/withauth:
    endpoint: 0.0.0.0:5000
    ca_file: /tmp/certs/ca.pem
    auth:
      authenticator: googleclientauth

service:
  extensions: [googleclientauth]
  pipelines:
    metrics:
      receivers: [otlp]
      processors: []
      exporters: [otlp/withauth]

----------------------------------------

TITLE: Configuring Disk Scraper in YAML
DESCRIPTION: Configuration options for the disk scraper, including device inclusion/exclusion and match type.

LANGUAGE: yaml
CODE:
disk:
  <include|exclude>:
    devices: [ <device name>, ... ]
    match_type: <strict|regexp>

----------------------------------------

TITLE: Configuring HTTP Forwarder Extension in YAML
DESCRIPTION: Example configuration for the HTTP Forwarder Extension, showing both ingress and egress settings. This snippet demonstrates how to set up the extension with custom endpoints, headers, and timeout.

LANGUAGE: yaml
CODE:
  http_forwarder:
    ingress:
      endpoint: localhost:7070
    egress:
      endpoint: http://target/
      headers:
        otel_http_forwarder: dev
      timeout: 5s

----------------------------------------

TITLE: Azure Data Explorer Exporter Configuration
DESCRIPTION: YAML configuration for the Azure Data Explorer exporter including cluster settings, authentication, table names and ingestion options.

LANGUAGE: yaml
CODE:
exporters:
  azuredataexplorer:
    cluster_uri: "https://CLUSTER.kusto.windows.net"
    application_id: "f80da32c-108c-415c-a19e-643f461a677a"
    application_key: "xx-xx-xx-xx"
    tenant_id: "21ff9e36-fbaa-43c8-98ba-00431ea10bc3"
    managed_identity_id: "z80da32c-108c-415c-a19e-643f461a677a"
    db_name: "oteldb"
    metrics_table_name: "OTELMetrics"
    logs_table_name: "OTELLogs"
    traces_table_name: "OTELTraces"
    metrics_table_json_mapping: "otelmetrics_mapping"
    logs_table_json_mapping: "otellogs_mapping"
    traces_table_json_mapping: "oteltraces_mapping"
    ingestion_type: "managed"

----------------------------------------

TITLE: Configuring Google Cloud Monitoring Receiver in YAML
DESCRIPTION: Configuration example for the Google Cloud Monitoring receiver showing how to set up metric collection intervals, project ID, and specific metrics to monitor. Includes settings for collection interval, project identification, and metric filtering.

LANGUAGE: yaml
CODE:
receivers:
  googlecloudmonitoring:
    collection_interval: 2m # Can be specified in seconds (s), minutes (m), or hours (h)
    project_id: my-project-id
    metrics_list:
      - metric_name: "compute.googleapis.com/instance/cpu/usage_time"
      - metric_name: "connectors.googleapis.com/flex/instance/cpu/usage_time"

----------------------------------------

TITLE: Configuring Flexible Resource Mapping for Logs in YAML
DESCRIPTION: Example configuration for enabling flexible resource mapping for logs in the LogicMonitor exporter. This snippet demonstrates how to set the resource_mapping_op to 'OR' for more flexible attribute matching.

LANGUAGE: yaml
CODE:
exporters:
  logicmonitor:
    endpoint: https://company.logicmonitor.com/rest
    headers:
      Authorization: Bearer <token>
    logs:
      resource_mapping_op: "OR"

----------------------------------------

TITLE: TLS Server Configuration
DESCRIPTION: TLS configuration settings for secure server connections, including certificate and key file paths, and client certificate verification options.

LANGUAGE: yaml
CODE:
tls:
  ca_file: "path/to/ca.crt"
  cert_file: "path/to/server.crt"
  key_file: "path/to/server.key"
  client_ca_file: "path/to/client-ca.crt"

----------------------------------------

TITLE: Configuring Service Graph Connector for Uninstrumented Services Identification
DESCRIPTION: This YAML configuration shows how to set up the Service Graph Connector with options for identifying uninstrumented services. It includes settings for virtual node peer attributes and an extra label for virtual nodes.

LANGUAGE: yaml
CODE:
receivers:
  otlp:
    protocols:
      grpc:

connectors:
  servicegraph:
    dimensions:
      - db.system
      - messaging.system
    virtual_node_peer_attributes:
      - db.name
      - db.system
      - messaging.system
      - peer.service
    virtual_node_extra_label: true

exporters:
  prometheus/servicegraph:
    endpoint: localhost:9090
    namespace: servicegraph

service:
  pipelines:
    traces:
      receivers: [otlp]
      exporters: [servicegraph]
    metrics/servicegraph:
      receivers: [servicegraph]
      exporters: [prometheus/servicegraph]

----------------------------------------

TITLE: Configuring OpenTelemetry Collector
DESCRIPTION: YAML configuration for the OpenTelemetry collector, including receivers, processors, exporters, and service pipelines.

LANGUAGE: YAML
CODE:
receivers:
  otlp:
    protocols:
      grpc:
        endpoint: localhost:4317

  prometheus:
      config:
        scrape_configs:
          - job_name: 'ki_stats'
            honor_labels: true
            static_configs:
              - targets: ['172.31.32.21:9010', '172.31.32.15:9010', '172.31.32.16:9010', '172.31.32.18:9010', '172.31.33.29:9010', '172.31.32.19:9010', '172.31.32.26:9010', '172.31.32.20:9010', '172.31.32.17:9010']

processors:
  batch:

exporters:
  kinetica:
    host: http://localhost:9191/
    schema: otel
    username: admin
    password: password
    bypasssslcertcheck: true
    logconfigfile: log_config.yaml


service:
  pipelines:
    traces:
      receivers:
      - otlp
      processors:
      - batch
      exporters:
      - kinetica
    metrics:
      receivers:
      - otlp
      - prometheus
      processors:
      - batch
      exporters:
      - kinetica
    logs:
      receivers:
      - otlp
      processors:
      - batch
      exporters:
      - kinetica

----------------------------------------

TITLE: Configuring OIDC Authenticator Extension in YAML
DESCRIPTION: This snippet demonstrates how to configure the OIDC authenticator extension in the OpenTelemetry Collector. It includes settings for the OIDC issuer, audience, and username claim, as well as how to integrate it with an OTLP receiver.

LANGUAGE: yaml
CODE:
extensions:
  oidc:
    issuer_url: http://localhost:8080/auth/realms/opentelemetry
    issuer_ca_path: /etc/pki/tls/cert.pem
    audience: account
    username_claim: email

receivers:
  otlp:
    protocols:
      grpc:
        auth:
          authenticator: oidc

processors:

exporters:
  debug:
    verbosity: detailed

service:
  extensions: [oidc]
  pipelines:
    traces:
      receivers: [otlp]
      processors: []
      exporters: [debug]

----------------------------------------

TITLE: Configuring InfluxDB Receiver in YAML
DESCRIPTION: Basic YAML configuration example for setting up the InfluxDB receiver with a custom endpoint.

LANGUAGE: yaml
CODE:
receivers:\n  influxdb:\n    endpoint: 0.0.0.0:8080

----------------------------------------

TITLE: Configuring Podman Stats Receiver with SSH Connection in YAML
DESCRIPTION: Example configuration for connecting to the Podman Stats Receiver over SSH, including endpoint, SSH key, and passphrase settings.

LANGUAGE: yaml
CODE:
receivers:
  podman_stats:
    endpoint: ssh://core@localhost:53841/run/user/1000/podman/podman.sock
    ssh_key: /path/to/ssh/private/key
    ssh_passphrase: <password>

----------------------------------------

TITLE: Configuring OpenSearch Exporter with Basic Auth
DESCRIPTION: Example configuration for setting up OpenSearch exporter with basic authentication. Shows how to configure the exporter with HTTP endpoints, authentication, and pipeline setup for traces.

LANGUAGE: yaml
CODE:
extensions:
  basicauth/client:
  client_auth:
    username: username
    password: password
    
exporters:
  opensearch/trace:
    http:
      endpoint: https://opensearch.example.com:9200
      auth:
        authenticator: basicauth/client
# 
service:
  pipelines:
    traces:
      receivers: [otlp]
      exporters: [opensearch/trace]
      processors: [batch]

----------------------------------------

TITLE: Configuring Recombine Operator with max_unmatched_batch_size in YAML
DESCRIPTION: Example configurations demonstrating the use of max_unmatched_batch_size parameter in the recombine operator. Three examples show how different values (0, 1, and 3) affect log combination behavior.

LANGUAGE: yaml
CODE:
- type: recombine
  combine_field: body
  is_first_entry: body == 'log1'
  max_unmatched_batch_size: 0

LANGUAGE: yaml
CODE:
- type: recombine
  combine_field: body
  is_first_entry: body == 'log1'
  max_unmatched_batch_size: 1

LANGUAGE: yaml
CODE:
- type: recombine
  combine_field: body
  is_first_entry: body == 'log1'
  max_unmatched_batch_size: 3

LANGUAGE: yaml
CODE:
- type: recombine
  combine_field: body
  is_last_entry: body == 'log1'
  max_unmatched_batch_size: 3

----------------------------------------

TITLE: Configuring Tenant Information for Loki Exporter
DESCRIPTION: YAML configuration example for setting static tenant information using HTTP headers in the Loki exporter.

LANGUAGE: yaml
CODE:
exporters:
  loki:
    endpoint: http://localhost:3100/loki/api/v1/push
    headers:
      "X-Scope-OrgID": acme

----------------------------------------

TITLE: Configuring LogicMonitor Exporter with Bearer Token in YAML
DESCRIPTION: Example configuration for the LogicMonitor exporter using a Bearer token for authentication. This snippet shows how to set up the exporter with the required endpoint and include the Bearer token in the headers.

LANGUAGE: yaml
CODE:
exporters:
  logicmonitor:
    endpoint: "https://<company_name>.logicmonitor.com/rest"
    headers:
      Authorization: Bearer <bearer token of logicmonitor>

----------------------------------------

TITLE: Configuring OTLP Receiver Protocols
DESCRIPTION: Configuration structure for supported OTLP receiver protocols (gRPC and HTTP). Includes settings for server endpoints, TLS, authentication, and protocol-specific parameters.

LANGUAGE: yaml
CODE:
protocols:
  grpc:
    endpoint: 0.0.0.0:4317
    transport: tcp
    tls:
      ca_file: ""
      cert_file: ""
      key_file: ""
  http:
    endpoint: 0.0.0.0:4318
    cors:
      allowed_origins: []
      allowed_headers: []
      max_age: 0

----------------------------------------

TITLE: Configuring OpAMP Extension for OpenTelemetry Collector
DESCRIPTION: This YAML configuration snippet shows how to set up the OpAMP extension within the OpenTelemetry Collector. It includes settings for the OpAMP server endpoint and the instance UID.

LANGUAGE: yaml
CODE:
extensions:
  opamp:
    endpoint:
    instance_uid:

----------------------------------------

TITLE: Configuring Loki Receiver in YAML
DESCRIPTION: Example YAML configuration for setting up the Loki receiver with both HTTP and gRPC protocols, and using the incoming timestamp.

LANGUAGE: yaml
CODE:
receivers:
  loki:
    protocols:
      http:
        endpoint: 0.0.0.0:3500
      grpc:
        endpoint: 0.0.0.0:3600
    use_incoming_timestamp: true

----------------------------------------

TITLE: Configuring Retain Operator for Attribute Fields in YAML
DESCRIPTION: This configuration demonstrates retaining specific fields from the attributes section of a log entry. It keeps 'key1' and 'key2' from the attributes, removing other attribute fields while preserving the resource and body.

LANGUAGE: yaml
CODE:
- type: retain
  fields:
    - attributes.key1
    - attributes.key2

----------------------------------------

TITLE: Configuring Performance Profiler Extension in YAML
DESCRIPTION: Basic YAML configuration example for enabling the pprof extension in OpenTelemetry Collector. This minimal configuration uses default settings for endpoint (localhost:1777) and profile fractions.

LANGUAGE: yaml
CODE:
extensions:
  pprof:

----------------------------------------

TITLE: Configuring File Log Receiver for Plaintext Logs
DESCRIPTION: Example configuration for tailing a plaintext log file. It demonstrates regex parsing to extract timestamp, severity, and message fields from log entries.

LANGUAGE: yaml
CODE:
receivers:
  filelog:
    include: [ /simple.log ]
    operators:
      - type: regex_parser
        regex: '^(?P<time>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}) (?P<sev>[A-Z]*) (?P<msg>.*)$'
        timestamp:
          parse_from: attributes.time
          layout: '%Y-%m-%d %H:%M:%S'
        severity:
          parse_from: attributes.sev

----------------------------------------

TITLE: Configuring S3 Partition Format in YAML
DESCRIPTION: Example YAML configuration demonstrating how to set a custom S3 partition format using strftime formatting options.

LANGUAGE: yaml
CODE:
exporters:
  awss3:
    s3uploader:
      region: 'eu-central-1'
      s3_bucket: 'databucket'
      s3_prefix: 'metric'
      s3_partition_format: '%Y/%m/%d/%H/%M'

----------------------------------------

TITLE: Configuring File Log Receiver for Compressed Logs
DESCRIPTION: Example configuration for reading gzip compressed log files. It demonstrates how to set the compression option to handle compressed log files.

LANGUAGE: yaml
CODE:
receivers:
  filelog:
    include:
    - /var/log/example/compressed.log.gz
    compression: gzip

----------------------------------------

TITLE: Basic Coralogix Exporter Configuration in YAML
DESCRIPTION: Example of a basic configuration for the Coralogix exporter, including domain, private key, and optional attribute mappings.

LANGUAGE: yaml
CODE:
exporters:
  coralogix:
    domain: "coralogix.com"
    private_key: "xxx"
    application_name_attributes:
    - "service.namespace"
    subsystem_name_attributes:
    - "service.name"
    application_name: "MyBusinessEnvironment"
    subsystem_name: "MyBusinessSystem"
    timeout: 30s

----------------------------------------

TITLE: Configuring Delta to Rate Processor in YAML
DESCRIPTION: Configuration example showing how to set up the delta to rate processor. The configuration requires specifying a list of metric names that should be converted from delta sums to rates.

LANGUAGE: yaml
CODE:
processors:
    # processor name: deltatorate
    deltatorate:

        # list the delta sum metrics to calculate the rate. This is a required field.
        metrics:
            - <metric_1_name>
            - <metric_2_name>
            .
            .
            - <metric_n_name>

----------------------------------------

TITLE: Configuring Cumulative to Delta Processor with Exclusion in YAML
DESCRIPTION: This YAML configuration example shows how to set up the Cumulative to Delta Processor to convert cumulative sum or histogram metrics to delta metrics, excluding those with 'metric' in the name.

LANGUAGE: yaml
CODE:
processors:
    # processor name: cumulativetodelta
    cumulativetodelta:

        # Convert cumulative sum or histogram metrics to delta
        # if and only if 'metric' is not in the name
        exclude:
            metrics:
                - ".*metric.*"
            match_type: regexp

----------------------------------------

TITLE: Configuring F5 Big-IP Receiver in YAML for OpenTelemetry Collector
DESCRIPTION: Example YAML configuration for the F5 Big-IP receiver. It specifies the collection interval, endpoint, username, password, and TLS settings.

LANGUAGE: yaml
CODE:
receivers:
  bigip:
    collection_interval: 10s
    endpoint: https://localhost:443
    username: otelu
    password: ${env:BIGIP_PASSWORD}
    tls:
      insecure_skip_verify: true

----------------------------------------

TITLE: Configuring Receiver Creator with Host Observer
DESCRIPTION: Example showing configuration for the receiver creator with host observer to monitor Redis instances running directly on hosts.

LANGUAGE: yaml
CODE:
receiver_creator/2:
  watch_observers: [host_observer]
  receivers:
    redis/on_host:
      rule: type == "port" && port == 6379 && is_ipv6 == true
      resource_attributes:
        service.name: redis_on_host

----------------------------------------

TITLE: Configuring Load Scraper in YAML
DESCRIPTION: Configuration option for the load scraper to specify whether to divide the average load by the number of logical CPUs.

LANGUAGE: yaml
CODE:
load:
  cpu_average: <false|true>

----------------------------------------

TITLE: Configuring SNMP Receiver in YAML
DESCRIPTION: Example configuration showing how to set up the SNMP receiver with v3 authentication, custom metrics, resource attributes, and attribute mappings. This includes connection settings, security parameters, and metric definitions.

LANGUAGE: yaml
CODE:
receivers:
  snmp:
    collection_interval: 60s
    endpoint: udp://localhost:161
    version: v3
    security_level: auth_priv
    user: otel
    auth_type: "MD5"
    auth_password: ${env:SNMP_AUTH_PASSWORD}
    privacy_type: "DES"
    privacy_password: ${env:SNMP_PRIVACY_PASSWORD}

    resource_attributes:
      resource_attr.name.1:
        indexed_value_prefix: probe
      resource_attr.name.2:
        oid: "1.1.1.1"

    attributes:
      attr.name.1:
        value: a2_new_key
        enum:
          - in
          - out
      attr.name.2:
        indexed_value_prefix: device
      attr.name.3:
        oid: "2.2.2.2"

    metrics:
      metric.name.1:
        unit: "1"
        sum:
          aggregation: cumulative
          monotonic: true
          value_type: int
        column_oids:
          - oid: "2.2.2.1"
            attributes:
              - name: attr.name.3
      metric.name.2:
        unit: "By"
        gauge:
          value_type: int
        column_oids:
          - oid: "3.3.3.3"
            attributes:
              - name: attr.name.2
              - name: attr.name.1
                value: in
          - oid: "2"
            attributes:
              - name: attr.name.2
              - name: attr.name.1
                value: out
      metric.name.3:
        unit: "By"
        sum:
          aggregation: delta
          monotonic: false
          value_type: double
        scalar_oids:
          - oid: "4.4.4.4.0"
            attributes:
              - name: attr.name.1
                value: in
          - oid: "4.4.4.5.0"
            attributes:
              - name: attr.name.1
                value: out
      metric.name.4:
        unit: "By"
        gauge:
          value_type: int
        column_oids:
          - oid: "5.5.5.5"
            resource_attributes:
              - resource_attr.name.1
      metric.name.5:
        unit: "By"
        gauge:
          value_type: int
        column_oids:
          - oid: "1.1.1.2"
            resource_attributes:
              - resource_attr.name.2

----------------------------------------

TITLE: Visualizing Daemonset-file Mode Architecture with ASCII Diagram
DESCRIPTION: ASCII diagram depicting the architecture and data flow for the daemonset-file mode of the k8slogreceiver, showing how log files are located and read based on mount points and graph drivers.

LANGUAGE: plaintext
CODE:
  k8sapi         docker/cri-containerd
                                       
        Source    
   medatada                 graph driver, 
                            mount points, env
             
                   assosiate
                  
              
                 Poller      find files based on includes mount point.
              
                   create
                  
              
                 Reader     
              
                   read files
                  
                 files

----------------------------------------

TITLE: Configuring Google Cloud Pubsub Exporter in YAML
DESCRIPTION: Basic configuration for the Google Cloud Pubsub Exporter, specifying the project and topic.

LANGUAGE: yaml
CODE:
exporters:
  googlecloudpubsub:
    project: my-project
    topic: projects/my-project/topics/otlp-traces

----------------------------------------

TITLE: Complete OpenTelemetry Configuration with Traces and Metrics
DESCRIPTION: Full YAML configuration combining traces and metrics pipelines with Jaeger and Prometheus receivers, batch processing, and both Logzio traces and Prometheus remote write exporters.

LANGUAGE: yaml
CODE:
receivers:
  jaeger:
    protocols:
      thrift_http:
        endpoint: "0.0.0.0:14278"

  prometheus:
    config:
      scrape_configs:
      - job_name: 'ratelimiter'
        scrape_interval: 15s
        static_configs:
          - targets: [ "0.0.0.0:8889" ]

exporters:
  logzio/traces:
    account_token: "LOGZIOtraceTOKEN"
    region: "us"

  prometheusremotewrite:
    endpoint: "https://listener.logz.io:8053"
    headers:
      Authorization: "Bearer LOGZIOprometheusTOKEN"

processors:
  batch:
    send_batch_size: 10000
    timeout: 1s
    
service:
  pipelines:
    traces:
      receivers: [jaeger]
      processors: [batch]
      exporters: [logzio/traces]

    metrics:
      receivers: [prometheus]
      exporters: [prometheusremotewrite]
  
  telemetry:
    logs:
      level: debug

----------------------------------------

TITLE: Configuring Zipkin Exporter in YAML
DESCRIPTION: Example configuration showing different Zipkin exporter setups including non-TLS, TLS, and TLS with certificate verification disabled. Demonstrates setting endpoint URLs, data format, and default service name options.

LANGUAGE: yaml
CODE:
exporters:
  zipkin/nontls:
    endpoint: "http://some.url:9411/api/v2/spans"
    format: proto
    default_service_name: unknown-service

  zipkin/withtls:
    endpoint: "https://some.url:9411/api/v2/spans"

  zipkin/tlsnoverify:
    endpoint: "https://some.url:9411/api/v2/spans"
    tls:
      insecure_skip_verify: true

----------------------------------------

TITLE: Configuring OTLP Receiver with TLS in OpenTelemetry Collector (YAML)
DESCRIPTION: This snippet demonstrates how to configure the OTLP receiver in OpenTelemetry Collector to use TLS for data encryption. It specifies the endpoint and the paths to the server certificate and key files.

LANGUAGE: yaml
CODE:
receivers:
  otlp:
    protocols:
      grpc:
        endpoint: mysite.local:55690
        tls:
          cert_file: server.crt
          key_file: server.key

----------------------------------------

TITLE: Creating Kubernetes ConfigMap for OpenTelemetry Collector
DESCRIPTION: YAML configuration to create a ConfigMap containing the OpenTelemetry Collector configuration with the Kubernetes Objects Receiver and OTLP exporter.

LANGUAGE: yaml
CODE:
apiVersion: v1
kind: ConfigMap
metadata:
  name: otelcontribcol
  labels:
    app: otelcontribcol
data:
  config.yaml: |
    receivers:
      k8sobjects:
        objects:
          - name: pods
            mode: pull
          - name: events
            mode: watch
    exporters:
      otlp:
        endpoint: <OTLP_ENDPOINT>
        tls:
          insecure: true

    service:
      pipelines:
        logs:
          receivers: [k8sobjects]
          exporters: [otlp]

----------------------------------------

TITLE: Configuring Basic Coralogix Processor Setup in YAML
DESCRIPTION: Basic configuration for the Coralogix processor without sampling functionality. This setup disables the cache and won't add sampling priority attributes to spans.

LANGUAGE: yaml
CODE:
processors:
  coralogix:
    db_statement_blueprints:

----------------------------------------

TITLE: Configuring Libhoney Receiver in YAML for OpenTelemetry Collector
DESCRIPTION: Example YAML configuration for the Libhoney receiver. It sets up HTTP endpoints, authentication, and field mappings for resources, scopes, and attributes. This configuration allows the receiver to accept and properly format data from Libhoney-instrumented applications.

LANGUAGE: yaml
CODE:
  libhoney:
    http:
      endpoint: 0.0.0.0:8088
      traces_url_paths:
        - "/1/events"
        - "/1/batch"
      include_metadata: true
    auth_api: https://api.honeycomb.io
    fields:
      resources:
        service_name: service_name
      scopes:
        library_name: library.name
        library_version: library.version
      attributes:
        trace_id: trace_id
        parent_id: parent_id
        span_id: span_id
        name: name
        error: error
        spankind: span.kind
        durationFields:
          - duration_ms

----------------------------------------

TITLE: Configuring ECS Observer Extension in YAML
DESCRIPTION: Example YAML configuration for the ecsobserver extension, showing how to set up service discovery for ECS tasks and integrate with the Prometheus receiver.

LANGUAGE: yaml
CODE:
extensions:
  ecs_observer:
    refresh_interval: 60s
    cluster_name: 'Cluster-1'
    cluster_region: 'us-west-2'
    result_file: '/etc/ecs_sd_targets.yaml'
    services:
      - name_pattern: '^retail-.*$'
    docker_labels:
      - port_label: 'ECS_PROMETHEUS_EXPORTER_PORT'
    task_definitions:
      - job_name: 'task_def_1'
        metrics_path: '/metrics'
        metrics_ports:
          - 9113
          - 9090
        arn_pattern: '.*:task-definition/nginx:[0-9]+'

receivers:
  prometheus:
    config:
      scrape_configs:
        - job_name: "ecs-task"
          file_sd_configs:
            - files:
                - '/etc/ecs_sd_targets.yaml'
          relabel_configs:
            - source_labels: [ __meta_ecs_cluster_name ]
              action: replace
              target_label: ClusterName
            - source_labels: [ __meta_ecs_service_name ]
              action: replace
              target_label: ServiceName
            - action: labelmap
              regex: ^__meta_ecs_container_labels_(.+)$
              replacement: '$$1'

processors:
  batch:

exporters:
  awsemf:

service:
  pipelines:
    metrics:
      receivers: [ prometheus ]
      processors: [ batch ]
      exporters: [ awsemf ]
  extensions: [ ecs_observer ]

----------------------------------------

TITLE: Kafka Receiver Configuration with Header Extraction in YAML
DESCRIPTION: An example configuration for extracting specific headers from Kafka messages and adding them as resource attributes.

LANGUAGE: yaml
CODE:
receivers:
  kafka:
    topic: test
    header_extraction: 
      extract_headers: true
      headers: ["header1", "header2"]

----------------------------------------

TITLE: Configuring Sentry Exporter in YAML
DESCRIPTION: Example configuration for the Sentry Exporter showing DSN, environment, and SSL verification settings. The DSN specifies where to send events, environment sets the event tag, and insecure_skip_verify controls SSL certificate validation.

LANGUAGE: yaml
CODE:
exporters:
  sentry:
    dsn: https://key@host/path/42
    environment: prod
    insecure_skip_verify: true

----------------------------------------

TITLE: File Exporter YAML Configuration Examples
DESCRIPTION: Example configurations for the file exporter showing different settings including rotation, compression, and flush intervals.

LANGUAGE: yaml
CODE:
exporters:
  file/no_rotation:
    path: ./foo

  file/rotation_with_default_settings:
    path: ./foo
    rotation:

  file/rotation_with_custom_settings:
    path: ./foo
    rotation:
      max_megabytes: 10
      max_days: 3
      max_backups: 3
      localtime: true
    format: proto
    compression: zstd

  file/flush_every_5_seconds:
    path: ./foo
    flush_interval: 5

----------------------------------------

TITLE: Configuring Conditional JSON Parsing
DESCRIPTION: This YAML configuration sets up the json_parser to parse the body as JSON only if it starts and ends with curly braces, using a regex condition.

LANGUAGE: yaml
CODE:
- type: json_parser
  if: 'body matches "^{.*}$"'

----------------------------------------

TITLE: Configuring Log DeDuplication with Include Fields in YAML
DESCRIPTION: Example configuration where deduplication is applied based on specified fields. Only logs with the same values for 'attributes.id' and 'attributes.name' are deduplicated.

LANGUAGE: yaml
CODE:
receivers:
    filelog:
        include: [./example/*.log]
processors:
    logdedup:
        include_fields:
          - attributes.id
          - attributes.name
        interval: 60s
        log_count_attribute: dedup_count
        timezone: 'America/Los_Angeles'
exporters:
    googlecloud:

service:
    pipelines:
        logs:
            receivers: [filelog]
            processors: [logdedup]
            exporters: [googlecloud]

----------------------------------------

TITLE: Parsing CSV with Tab Delimiter
DESCRIPTION: Example showing CSV parsing with a custom tab delimiter and specific parse_from field configuration.

LANGUAGE: yaml
CODE:
- type: csv_parser
  parse_from: body.message
  header: id,severity,message
  delimiter: "\t"

LANGUAGE: json
CODE:
{
  "body": {
    "message": "1 debug Debug Message"
  }
}

LANGUAGE: json
CODE:
{
  "body": {
    "id": "1",
    "severity": "debug",
    "message": "Debug Message"
  }
}

----------------------------------------

TITLE: Configuring Cumulative to Delta Processor with Regex Matching in YAML
DESCRIPTION: This YAML configuration example shows how to set up the Cumulative to Delta Processor to convert cumulative sum or histogram metrics to delta metrics using a regular expression match.

LANGUAGE: yaml
CODE:
processors:
    # processor name: cumulativetodelta
    cumulativetodelta:

        # Convert cumulative sum or histogram metrics to delta
        # if and only if 'metric' is in the name
        include:
            metrics:
                - ".*metric.*"
            match_type: regexp

----------------------------------------

TITLE: Priority-based Log Sampling Configuration
DESCRIPTION: YAML configuration showing how to configure sampling priority based on a custom priority attribute.

LANGUAGE: yaml
CODE:
processors:
  probabilistic_sampler:
    sampling_percentage: 15
    sampling_priority: priority

----------------------------------------

TITLE: Configuring Docker Observer Extension in YAML
DESCRIPTION: Example configuration for the Docker observer extension showing how to set up endpoint monitoring, excluded images, API version and timeout settings. Also demonstrates integration with a receiver creator for nginx monitoring.

LANGUAGE: yaml
CODE:
extensions:
  docker_observer:
    # url of the docker socket, defaults to unix:///var/run/docker.sock on non-Windows and npipe:////./pipe/docker_engine on Windows
    endpoint: my/path/to/docker.sock
    # list of container image names to exclude
    excluded_images: ['redis', 'another_image_name']
    # client API version, default to 1.24
    api_version: "1.25"
    # max amount of time to wait for a response from Docker API , default to 5s
    timeout: 15s

receivers:
  receiver_creator:
    watch_observers: [docker_observer]
    receivers:
      nginx:
        rule: type == "container" and name matches "nginx" and port == 80
        config:
          endpoint: '`endpoint`/status'
          collection_interval: 10s

----------------------------------------

TITLE: Configuring MongoDB Receiver in YAML
DESCRIPTION: Example configuration for the MongoDB receiver in the OpenTelemetry Collector. It specifies the host, credentials, collection interval, initial delay, and TLS settings.

LANGUAGE: yaml
CODE:
receivers:
  mongodb:
    hosts:
      - endpoint: localhost:27017
    username: otel
    password: ${env:MONGODB_PASSWORD}
    collection_interval: 60s
    initial_delay: 1s
    tls:
      insecure: true
      insecure_skip_verify: true

----------------------------------------

TITLE: Configuring AVRO Log Encoding Extension in YAML
DESCRIPTION: This snippet demonstrates how to configure the AVRO Log encoding extension in a YAML file. It specifies the Avro schema to be used for reading log record bodies.

LANGUAGE: yaml
CODE:
extensions:
  avro_log_encoding:
    schema: |
      {
        "type" : "record",
        "namespace" : "example",
        "name" : "Datapoint",
        "fields" : [
          { "name" : "Key" , "type" : "string" },
          { "name" : "Value" , "type" : "int" }
        ]
      }

----------------------------------------

TITLE: Configuring Leader Elector Extension in YAML
DESCRIPTION: This snippet shows how to configure the k8s_leader_elector extension in the OpenTelemetry Collector configuration file. It includes settings for authentication, lease name, and namespace.

LANGUAGE: yaml
CODE:
receivers:
  my_awesome_receiver:
    k8s_leader_elector: k8s_leader_elector
extensions:
  k8s_leader_elector:
    auth_type: kubeConfig
    lease_name: foo
    lease_namespace: default

service:
  extensions: [k8s_leader_elector]
  pipelines:
    metrics:
      receivers: [my_awesome_receiver]

----------------------------------------

TITLE: Kubernetes ConfigMap Configuration
DESCRIPTION: Example of a Kubernetes ConfigMap that configures the OpenTelemetry Collector with the k8s_cluster receiver.

LANGUAGE: yaml
CODE:
apiVersion: v1
kind: ConfigMap
metadata:
  name: otelcontribcol
  labels:
    app: otelcontribcol
data:
  config.yaml: |
    receivers:
      k8s_cluster:
        collection_interval: 10s
    exporters:
      debug:
    service:
      pipelines:
        metrics:
          receivers: [k8s_cluster]
          exporters: [debug]
        logs/entity_events:
          receivers: [k8s_cluster]
          exporters: [debug]

----------------------------------------

TITLE: Configuring Docker Volume Mount for File Exporter
DESCRIPTION: Commands to set up a writable directory for the file exporter when using the opentelemetry-collector-contrib container. Creates a directory with proper permissions and mounts it as a volume.

LANGUAGE: bash
CODE:
mkdir --mode o+rwx file-exporter
docker run -v "./file-exporter:/file-exporter:rwz" -v "otel-collector-config.yaml:/etc/otelcol-contrib/config.yaml" otel/opentelemetry-collector-contrib:latest

----------------------------------------

TITLE: Configuring RabbitMQ Exporter with OTLP JSON Encoding
DESCRIPTION: Example configuration for setting up the RabbitMQ exporter with AMQP connection details, authentication, and OTLP JSON encoding extension. Shows how to configure the connection endpoint, credentials, and encoding format.

LANGUAGE: yaml
CODE:
exporters:
  rabbitmq:
    connection:
      endpoint: amqp://localhost:5672
      auth:
        plain:
          username: user
          password: pass
    encoding_extension: otlp_encoding/rabbitmq

extensions:
  otlp_encoding/rabbitmq:
    protocol: otlp_json

----------------------------------------

TITLE: Configuring Podman Stats Receiver in YAML
DESCRIPTION: Example configuration for the Podman Stats Receiver, including endpoint, timeout, collection interval, initial delay, and metric settings.

LANGUAGE: yaml
CODE:
receivers:
  podman_stats:
    endpoint: unix://run/podman/podman.sock
    timeout: 10s
    collection_interval: 10s
    initial_delay: 1s
    metrics:
      container.cpu.usage.system:
        enabled: false

----------------------------------------

TITLE: Configuring OTLP Encoding Extension with Protobuf Protocol in YAML
DESCRIPTION: This snippet demonstrates how to configure the OTLP encoding extension using the Protobuf protocol in the collector's configuration file.

LANGUAGE: yaml
CODE:
extensions:
  otlp_encoding:
    protocol: otlp_proto

----------------------------------------

TITLE: Configuring Kafka Exporter in YAML for OpenTelemetry Collector
DESCRIPTION: Example YAML configuration for the Kafka exporter, specifying brokers and protocol version. This is a basic setup to enable exporting telemetry data to Kafka.

LANGUAGE: yaml
CODE:
exporters:
  kafka:
    brokers:
      - localhost:9092
    protocol_version: 2.0.0

----------------------------------------

TITLE: GeoIP Resource Attributes Schema
DESCRIPTION: List of resource attributes that the GeoIP processor can add to telemetry data when geographical information is found for an IP address.

LANGUAGE: text
CODE:
  * geo.city_name
  * geo.postal_code
  * geo.country_name
  * geo.country_iso_code
  * geo.continent_name
  * geo.continent_code
  * geo.region_name
  * geo.region_iso_code
  * geo.timezone
  * geo.location.lat
  * geo.location.lon

----------------------------------------

TITLE: Configuring Process Scraper in YAML
DESCRIPTION: Configuration options for the process scraper, including process inclusion/exclusion, error muting, and scrape delay.

LANGUAGE: yaml
CODE:
process:
  <include|exclude>:
    names: [ <process name>, ... ]
    match_type: <strict|regexp>
  mute_process_all_errors: <true|false>
  mute_process_name_error: <true|false>
  mute_process_exe_error: <true|false>
  mute_process_io_error: <true|false>
  mute_process_user_error: <true|false>
  mute_process_cgroup_error: <true|false>
  scrape_process_delay: <time>

----------------------------------------

TITLE: Configuring Tail Sampling Processor in YAML
DESCRIPTION: Example YAML configuration for the tail sampling processor, demonstrating various sampling policies and options.

LANGUAGE: yaml
CODE:
processors:
  tail_sampling:
    decision_wait: 10s
    num_traces: 100
    expected_new_traces_per_sec: 10
    decision_cache:
      sampled_cache_size: 100_000
      non_sampled_cache_size: 100_000
    policies:
      [
          {
            name: test-policy-1,
            type: always_sample
          },
          {
            name: test-policy-2,
            type: latency,
            latency: {threshold_ms: 5000, upper_threshold_ms: 10000}
          },
          {
            name: test-policy-3,
            type: numeric_attribute,
            numeric_attribute: {key: key1, min_value: 50, max_value: 100}
          },
          {
            name: test-policy-4,
            type: probabilistic,
            probabilistic: {sampling_percentage: 10}
          },
          {
            name: test-policy-5,
            type: status_code,
            status_code: {status_codes: [ERROR, UNSET]}
          },
          {
            name: test-policy-6,
            type: string_attribute,
            string_attribute: {key: key2, values: [value1, value2]}
          },
          {
            name: test-policy-7,
            type: string_attribute,
            string_attribute: {key: key2, values: [value1, val*], enabled_regex_matching: true, cache_max_size: 10}
          },
          {
            name: test-policy-8,
            type: rate_limiting,
            rate_limiting: {spans_per_second: 35}
         },
         {
            name: test-policy-9,
            type: string_attribute,
            string_attribute: {key: url.path, values: [\/health, \/metrics], enabled_regex_matching: true, invert_match: true}
         },
         {
            name: test-policy-10,
            type: span_count,
            span_count: {min_spans: 2, max_spans: 20}
         },
         {
             name: test-policy-11,
             type: trace_state,
             trace_state: { key: key3, values: [value1, value2] }
         },
         {
              name: test-policy-12,
              type: boolean_attribute,
              boolean_attribute: {key: key4, value: true}
         },
         {
              name: test-policy-13,
              type: ottl_condition,
              ottl_condition: {
                   error_mode: ignore,
                   span: [
                        "attributes[\"test_attr_key_1\"] == \"test_attr_val_1\"",
                        "attributes[\"test_attr_key_2\"] != \"test_attr_val_1\"",
                   ],
                   spanevent: [
                        "name != \"test_span_event_name\"",
                        "attributes[\"test_event_attr_key_2\"] != \"test_event_attr_val_1\"",
                   ]
              }
         },
         {
            name: and-policy-1,
            type: and,
            and: {
              and_sub_policy: 
              [
                {
                  name: test-and-policy-1,
                  type: numeric_attribute,
                  numeric_attribute: { key: key1, min_value: 50, max_value: 100 }
                },
                {
                    name: test-and-policy-2,
                    type: string_attribute,
                    string_attribute: { key: key2, values: [ value1, value2 ] }
                },
              ]
            }
         },
         {
            name: composite-policy-1,
            type: composite,
            composite:
              {
                max_total_spans_per_second: 1000,
                policy_order: [test-composite-policy-1, test-composite-policy-2, test-composite-policy-3],
                composite_sub_policy:
                  [
                    {
                      name: test-composite-policy-1,
                      type: numeric_attribute,
                      numeric_attribute: {key: key1, min_value: 50}
                    },
                    {
                      name: test-composite-policy-2,
                      type: string_attribute,
                      string_attribute: {key: key2, values: [value1, value2]}
                    },
                    {
                      name: test-composite-policy-3,
                      type: always_sample
                    }
                  ],
                rate_allocation:
                  [
                    {
                      policy: test-composite-policy-1,
                      percent: 50
                    },
                    {
                      policy: test-composite-policy-2,
                      percent: 25
                    }
                  ]
              }
          },
        ]

----------------------------------------

TITLE: Configuring Syslog Parser for RFC3164 in YAML
DESCRIPTION: Example YAML configuration for the syslog_parser operator to parse messages using the RFC3164 protocol.

LANGUAGE: yaml
CODE:
- type: syslog_parser
  protocol: rfc3164

----------------------------------------

TITLE: Configuring Custom Format File Output in YAML for OpenTelemetry Collector
DESCRIPTION: An advanced configuration for the file_output operator that uses a custom Go template to format log entries before writing them to a file.

LANGUAGE: yaml
CODE:
- type: file_output
  path: /tmp/output.log
  format: "Time: {{.Timestamp}} Body: {{.Body}}\n"

----------------------------------------

TITLE: Attribute-based Log Sampling Configuration
DESCRIPTION: YAML configuration for sampling logs based on a specific log record attribute (logID) rather than trace ID.

LANGUAGE: yaml
CODE:
processors:
  probabilistic_sampler:
    sampling_percentage: 15
    attribute_source: record
    from_attribute: logID

----------------------------------------

TITLE: Enabling Optional OracleDB Metrics in YAML
DESCRIPTION: YAML configuration snippet demonstrating how to enable optional metrics that are not collected by default in the OracleDB collector.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: true

----------------------------------------

TITLE: Configuring Sigv4 Authentication for AWS Services in OpenTelemetry Collector
DESCRIPTION: This YAML configuration demonstrates how to set up Sigv4 authentication for making requests to AWS services, specifically for Prometheus remote write to Amazon Managed Service for Prometheus. It includes role assumption, region specification, and integration with a metrics pipeline.

LANGUAGE: yaml
CODE:
extensions:
  sigv4auth:
    assume_role:
      arn: "arn:aws:iam::123456789012:role/aws-service-role/access"
      sts_region: "us-east-1"

receivers:
  hostmetrics:
    scrapers:
      memory:

exporters:
  prometheusremotewrite:
    endpoint: "https://aps-workspaces.us-west-2.amazonaws.com/workspaces/ws-XXX/api/v1/remote_write"
    auth:
      authenticator: sigv4auth

service:
  extensions: [sigv4auth]
  pipelines:
    metrics:
      receivers: [hostmetrics]
      processors: []
      exporters: [prometheusremotewrite]

----------------------------------------

TITLE: Configuring Log DeDuplication with Excluded Fields in YAML
DESCRIPTION: Example configuration that excludes specific fields from being considered when searching for duplicate logs, including 'timestamp' from the body, 'host.name' from attributes, and 'ip' nested inside 'src' attribute.

LANGUAGE: yaml
CODE:
receivers:
    filelog:
        include: [./example/*.log]
processors:
    logdedup:
        exclude_fields:
          - body.timestamp
          - attributes.host\.name
          - attributes.src.ip
exporters:
    googlecloud:

service:
    pipelines:
        logs:
            receivers: [filelog]
            processors: [logdedup]
            exporters: [googlecloud]

----------------------------------------

TITLE: Basic Faro Exporter Configuration in YAML
DESCRIPTION: Basic configuration example for the Faro exporter showing how to set the endpoint, timeout, and custom headers.

LANGUAGE: yaml
CODE:
exporters:
  faro:
    endpoint: https://faro.example.com/collect
    timeout: 10s
    headers:
      X-API-Key: "my-api-key"

----------------------------------------

TITLE: Configuring Health Check Extension in YAML
DESCRIPTION: Example YAML configuration for the Health Check extension, demonstrating how to set up multiple instances with custom endpoints, TLS settings, and paths.

LANGUAGE: yaml
CODE:
extensions:
  health_check:
  health_check/1:
    endpoint: "localhost:13"
    tls:
      ca_file: "/path/to/ca.crt"
      cert_file: "/path/to/cert.crt"
      key_file: "/path/to/key.key"
    path: "/health/status"

----------------------------------------

TITLE: Displaying MySQL InnoDB Buffer Pool Page Statistics
DESCRIPTION: This snippet shows a table of InnoDB buffer pool statistics, including the count of data pages and free pages. The 'NotANumber' value for data pages suggests a potential error or unexpected output in the metric collection.

LANGUAGE: plaintext
CODE:
name	count
Innodb_buffer_pool_pages_data	NotANumber
Innodb_buffer_pool_pages_free	233

----------------------------------------

TITLE: Configuring Database Storage Extension with PostgreSQL URL in YAML
DESCRIPTION: Example configuration for the Database Storage extension using PostgreSQL driver with a URL-formatted datasource.

LANGUAGE: yaml
CODE:
extensions:
  db_storage:
    driver: "pgx"
    datasource: "postgres://otel:otel_password@localhost:5432/otlp?sslmode=disable"

----------------------------------------

TITLE: Configuring Logs Pipeline with Logzio Exporter
DESCRIPTION: YAML configuration for setting up logs pipeline with file log receiver, resource detection, batch processor, and Logzio logs exporter. Includes file path patterns and attribute operations.

LANGUAGE: yaml
CODE:
receivers:
  filelog:
    include: [ "/private/var/log/*.log" ]
    include_file_name: false
    include_file_path: true 
    operators:
      - type: move
        from: attributes["log.file.path"]
        to: attributes["log_file_path"]
    attributes:
      type: <<your-logzio-type>>
processors:
  batch:
    send_batch_size: 10000
    timeout: 1s
  resourcedetection/system:
    detectors: [ "system" ]
    system:
      hostname_sources: [ "os" ]
exporters:
  logzio/logs:
    account_token: "LOGZIOlogsTOKEN"
    region: "us"
service:
  pipelines:
    logs:
      receivers: [filelog]
      processors: [ resourcedetection/system, batch ]
      exporters: [logzio/logs]
  telemetry:
    logs:
      level: "debug"

----------------------------------------

TITLE: Configuring JSON Parser with Timestamp Parsing
DESCRIPTION: This YAML configuration sets up the json_parser to parse the 'message' field as JSON and extract a timestamp from the 'seconds_since_epoch' field.

LANGUAGE: yaml
CODE:
- type: json_parser
  parse_from: body.message
  timestamp:
    parse_from: body.seconds_since_epoch
    layout_type: epoch
    layout: s

----------------------------------------

TITLE: Enabling Batching for OpenTelemetry Protocol with Apache Arrow Exporter
DESCRIPTION: YAML configuration showing how to enable the experimental batching feature for the OpenTelemetry Protocol with Apache Arrow exporter, along with necessary queue and storage settings.

LANGUAGE: yaml
CODE:
exporters:
  otelarrow:
    batcher:
      enabled: true
    sending_queue:
      enabled: true
      storage: file_storage/otc
extensions:
  file_storage/otc:
    directory: /var/lib/storage/otc

----------------------------------------

TITLE: Configuring Remote Tap Extension in YAML
DESCRIPTION: Basic YAML configuration example for setting up the Remote Tap extension in OpenTelemetry Collector. The extension can be configured with an optional endpoint parameter that defaults to localhost:11000.

LANGUAGE: yaml
CODE:
extensions:
  remotetap:

----------------------------------------

TITLE: Defining Conditional Rules for OpenTelemetry Trace Attributes
DESCRIPTION: This snippet specifies conditional rules for attribute combinations based on span kinds and parent types. It outlines which attributes are allowed for different span kinds and parent types.

LANGUAGE: plaintext
CODE:
IF [Parent] = "Root" THEN [Kind] in {"Server", "Producer"};
IF [Kind] = "Internal" THEN [Attributes] in {"Nil", "Internal"};
IF [Kind] = "Server" THEN [Attributes] in {"Nil", "FaaSHTTP", "FaaSTimer", "FaaSOther", "HTTPServer", "gRPCServer", "MaxCount"};
IF [Kind] = "Client" THEN [Attributes] in {"Empty", "DatabaseSQL", "DatabaseNoSQL", "HTTPClient", "gRPCClient"};
IF [Kind] = "Producer" THEN [Attributes] in {"Empty", "MessagingProducer", "FaaSPubSub"};
IF [Kind] = "Consumer" THEN [Attributes] in {"Nil", "MessagingConsumer", "FaaSDatasource"};

----------------------------------------

TITLE: Running Integration Tests in Go for OpenTelemetry Collector Components
DESCRIPTION: Commands for running integration tests for specific components in the OpenTelemetry Collector Contrib project. These tests are designed to run on local hardware without requiring credentials or environmental infrastructure.

LANGUAGE: bash
CODE:
make integration-test

LANGUAGE: bash
CODE:
cd componentclass/yourcomponent && make mod-integration-test

----------------------------------------

TITLE: Configuring Kubernetes Observer Extension
DESCRIPTION: Example configuration for the k8s_observer extension showing basic setup with authentication, node specification, and resource observation settings along with receiver creator integration.

LANGUAGE: yaml
CODE:
extensions:
  k8s_observer:
    auth_type: serviceAccount
    node: ${env:K8S_NODE_NAME}
    observe_pods: true
    observe_nodes: true
    observe_services: true
    observe_ingresses: true

receivers:
  receiver_creator:
    watch_observers: [k8s_observer]
    receivers:
      redis:
        rule: type == "port" && pod.name matches "redis"
        config:
          password: '`pod.labels["SECRET"]`'
      kubeletstats:
        rule: type == "k8s.node"
        config:
          auth_type: serviceAccount
          collection_interval: 10s
          endpoint: "`endpoint`:`kubelet_endpoint_port`"
          extra_metadata_labels:
            - container.id
          metric_groups:
            - container
            - pod
            - node

----------------------------------------

TITLE: Multi-Frequency Counter Collection Configuration
DESCRIPTION: Configuration example showing how to collect different performance counters at varying intervals using multiple receiver instances.

LANGUAGE: yaml
CODE:
receivers:
  windowsperfcounters/memory:
    metrics:
      bytes.committed:
        description: the number of bytes committed to memory
        unit: By
        gauge:
    collection_interval: 30s
    perfcounters:
      - object: Memory
        counters:
          - name: Committed Bytes
            metric: bytes.committed

  windowsperfcounters/processor:
    collection_interval: 1m
    metrics:
      processor.time:
        description: active and idle time of the processor
        unit: "%"
        gauge:
    perfcounters:
      - object: "Processor"
        instances: "*"
        counters:
          - name: "% Processor Time"
            metric: processor.time
            attributes:
              state: active
      - object: "Processor"
        instances: ["1", "2"]
        counters:
          - name: "% Idle Time"
            metric: processor.time
            attributes:
              state: idle

service:
  pipelines:
    metrics:
      receivers: [windowsperfcounters/memory, windowsperfcounters/processor]

----------------------------------------

TITLE: Configuring Resource Attribute Conversion in AWS EMF Exporter
DESCRIPTION: Example configuration showing how to enable resource attribute to metric label conversion in the AWS EMF exporter. This configuration enables converting all resource attributes to metric labels.

LANGUAGE: yaml
CODE:
exporters:
    awsemf:
        region: 'us-west-2'
        resource_to_telemetry_conversion:
            enabled: true

----------------------------------------

TITLE: Configuring AWS S3 Receiver with Text Encoding Extension in YAML
DESCRIPTION: Example configuration for the AWS S3 Receiver, including a text encoding extension and specific S3 downloader settings. It demonstrates how to set up time range, region, bucket, prefix, and custom encoding for retrieving data.

LANGUAGE: yaml
CODE:
extension:
  # example of text encoding extension
  text_encoding:
    encoding: utf8
    marshaling_separator: "\n"
    unmarshaling_separator: "\r?\n"
    
receivers:
  awss3:
    starttime: "2024-01-01 01:00"
    endtime: "2024-01-02"
    s3downloader:
        region: "us-west-1"
        s3_bucket: "mybucket"
        s3_prefix: "trace"
        s3_partition: "minute"
    encodings:
      - extension: text_encoding
        suffix: ".txt"

----------------------------------------

TITLE: Configuring Multiple Compression Levels for OpenTelemetry Protocol with Apache Arrow Exporters
DESCRIPTION: YAML configuration example demonstrating how to set up multiple OpenTelemetry Protocol with Apache Arrow exporters with different Zstd compression levels.

LANGUAGE: yaml
CODE:
exporters:
  otelarrow/best:
    compression: zstd
    arrow:
      zstd:
        level: 10
  otelarrow/fastest:
    compression: zstd
    arrow:
      zstd:
        level: 1

----------------------------------------

TITLE: Advanced Exceptions Connector Configuration with Prometheus and Loki
DESCRIPTION: A more complex example of using the exceptions connector with Prometheus and Loki as exporters. It shows how to integrate the connector into a pipeline with OTLP receivers and specific metric and log exporters.

LANGUAGE: yaml
CODE:
receivers:
  otlp:
    protocols:
      grpc:
      http:

exporters:
  prometheusremotewrite:
    endpoint: http://prometheus:9090/api/v1/write
  loki:
    endpoint: http://loki:3100/loki/api/v1/push

connectors:
  exceptions:

service:
  pipelines:
    traces:
      receivers: [otlp]
      exporters: [exceptions]
    metrics:
      receivers: [exceptions]
      exporters: [prometheusremotewrite]
    logs:
      receivers: [exceptions]
      exporters: [loki]

----------------------------------------

TITLE: Configuring osquery Receiver in YAML for OpenTelemetry Collector
DESCRIPTION: Example YAML configuration for the osquery receiver. It specifies the collection interval, extensions socket path, and queries to run on the osquery daemon.

LANGUAGE: yaml
CODE:
  osquery:
    collection_internal: 10s
    extensions_socket: /var/osquery/osquery.em
    queries:
      - "select * from certificates"
      - "select * from block_devices"

----------------------------------------

TITLE: Example of Attribute Extraction from Span Names in YAML
DESCRIPTION: This snippet provides a practical example of extracting a 'documentId' attribute from a span name using a regular expression. It shows two variations: one that modifies the span name and another that keeps the original name.

LANGUAGE: yaml
CODE:
span/to_attributes:
  name:
    to_attributes:
      rules:
        - ^/api/v1/document/(?P<documentId>.*)/update$

span/to_attributes_keep_original_name:
  name:
    to_attributes:
      keep_original_name: true
      rules:
        - ^/api/v1/document/(?P<documentId>.*)/update$

----------------------------------------

TITLE: Configuring Routing Connector for Log Routing by Severity and Tenant
DESCRIPTION: This YAML configuration shows how to route logs based on severity level and tenant information using the Routing Connector. It routes low-level logs to cheap storage and the remainder based on tenant.

LANGUAGE: yaml
CODE:
receivers:
    otlp:

exporters:
  file/cheap:
    path: ./cheap.log
  file/acme:
    path: ./acme.log
  file/ecorp:
    path: ./ecorp.log

connectors:
  routing:
    table:
      - context: log
        condition: severity_number < SEVERITY_NUMBER_ERROR
        pipelines: [logs/cheap]
      - context: request
        condition: request["X-Tenant"] == "acme"
        pipelines: [logs/acme]
      - context: request
        condition: request["X-Tenant"] == "ecorp"
        pipelines: [logs/ecorp]

service:
  pipelines:
    logs/in:
      receivers: [otlp]
      exporters: [routing]
    logs/cheap:
      receivers: [routing]
      exporters: [file/cheap]
    logs/acme:
      receivers: [routing]
      exporters: [file/acme]
    logs/ecorp:
      receivers: [routing]
      exporters: [file/ecorp]

----------------------------------------

TITLE: Configuring Resource Filters for Google Managed Prometheus Exporter
DESCRIPTION: Example YAML configuration for adding resource filters to preserve identifying attributes as metric labels.

LANGUAGE: yaml
CODE:
  googlemanagedprometheus:
    metric:
      resource_filters:
      - prefix: "cloud"
      - prefix: "k8s"
      - prefix: "faas"
      - regex: "container.id"
      - regex: "process.pid"
      - regex: "host.name"
      - regex: "host.id"

----------------------------------------

TITLE: Configuring Basic SQL Server Receiver with Direct Connection
DESCRIPTION: Example configuration showing basic setup and direct connection options for the SQL Server receiver. Demonstrates collection interval setting and database connection parameters.

LANGUAGE: yaml
CODE:
    receivers:
      sqlserver:
        collection_interval: 10s
      sqlserver/1:
        collection_interval: 5s
        username: sa
        password: securepassword
        server: 0.0.0.0
        port: 1433

----------------------------------------

TITLE: Sending Custom Messages via OpAMP in Go
DESCRIPTION: Shows how to send messages using a custom capability handler with proper error handling and retry logic when a message is already pending.

LANGUAGE: go
CODE:
for {
	sendingChan, err := handler.SendMessage("messageType", []byte("message-data"))
	switch {
	case err == nil:
		break
	case errors.Is(err, types.ErrCustomMessagePending):
		<-sendingChan
		continue
	default:
		return fmt.Errorf("failed to send message: %w", err)
	}
}

----------------------------------------

TITLE: Configuring Cumulative to Delta Processor with Include and Exclude in YAML
DESCRIPTION: This YAML configuration example demonstrates how to set up the Cumulative to Delta Processor to convert cumulative sum metrics with 'metric' in their name, while excluding histogram metrics.

LANGUAGE: yaml
CODE:
processors:
    # processor name: cumulativetodelta
    cumulativetodelta:

        # Convert cumulative sum metrics with 'metric' in their name,
        # but exclude histogram metrics
        include:
            metrics:
                - ".*metric.*"
            match_type: regexp
        exclude:
          metric_types:
            - histogram

----------------------------------------

TITLE: Configuring Pulsar Exporter in YAML
DESCRIPTION: Example YAML configuration for the Pulsar exporter, demonstrating basic settings such as endpoint, topic, encoding, authentication, and TLS options.

LANGUAGE: yaml
CODE:
exporters:
  pulsar:
    endpoint: pulsar://localhost:6650
    topic: otlp-spans
    encoding: otlp_proto
    auth:
      tls:
        cert_file: cert.pem
        key_file: key.pem
    timeout: 10s
    tls_allow_insecure_connection: false
    tls_trust_certs_file_path: ca.pem

----------------------------------------

TITLE: Configuring Recombine Operator for Stack Traces in YAML
DESCRIPTION: Example configuration for recombining stack traces into multiline logs. It uses a regular expression to identify the start of a new log entry based on the absence of leading whitespace.

LANGUAGE: yaml
CODE:
- type: recombine
  combine_field: body
  is_first_entry: body matches "^[^\\s]"

----------------------------------------

TITLE: Disabling Prometheus Name Normalization in Shell
DESCRIPTION: Command to disable the Prometheus metric name normalization feature using feature gates in the OpenTelemetry Collector.

LANGUAGE: shell
CODE:
$ otelcol --config=config.yaml --feature-gates=-pkg.translator.prometheus.NormalizeName

----------------------------------------

TITLE: Configuring Basic Kafka Metrics Receiver with All Scrapers in YAML
DESCRIPTION: A basic configuration example for the Kafka Metrics Receiver that enables all available scrapers (brokers, topics, and consumers) using YAML.

LANGUAGE: yaml
CODE:
receivers:
  kafkametrics:
    protocol_version: 2.0.0
    scrapers:
      - brokers
      - topics
      - consumers

----------------------------------------

TITLE: Starting OpAMP Server - Shell Commands
DESCRIPTION: Commands to clone and run the OpAMP example server for testing the supervisor implementation.

LANGUAGE: shell
CODE:
git clone git@github.com:open-telemetry/opamp-go.git
cd opamp-go/internal/examples/server
go run .

----------------------------------------

TITLE: Configuring Log DeDuplication with Conditions in YAML
DESCRIPTION: Example configuration that performs deduplication only on logs where Attribute 'ID' equals 1 OR where Resource Attribute 'service.name' equals 'my-service'.

LANGUAGE: yaml
CODE:
receivers:
    filelog:
        include: [./example/*.log]
processors:
    logdedup:
        conditions:
            - attributes["ID"] == 1
            - resource.attributes["service.name"] == "my-service"
        interval: 60s
        log_count_attribute: dedup_count
        timezone: 'America/Los_Angeles'
exporters:
    googlecloud:

service:
    pipelines:
        logs:
            receivers: [filelog]
            processors: [logdedup]
            exporters: [googlecloud]

----------------------------------------

TITLE: Renaming an Attribute in YAML
DESCRIPTION: Example showing how to rename an attribute by setting a new attribute and deleting the old one.

LANGUAGE: yaml
CODE:
transform:
  error_mode: ignore
  trace_statements:
    - set(resource.attributes["namespace"], resource.attributes["k8s.namespace.name"])
    - delete_key(resource.attributes, "k8s.namespace.name")

----------------------------------------

TITLE: Invalid Metrics Filter Configuration - YAML
DESCRIPTION: Configuration example for filtering out metrics with invalid type.

LANGUAGE: yaml
CODE:
processors:
  filter:
    error_mode: ignore
    metrics:
      metric:
        - type == METRIC_DATA_TYPE_NONE

----------------------------------------

TITLE: Resource-Based Filter Configuration - YAML
DESCRIPTION: Shows how to configure filtering based on resource attributes, specifically for Kubernetes pod names.

LANGUAGE: yaml
CODE:
processors:
  filter:
    error_mode: ignore
    traces:
      span:
        - IsMatch(resource.attributes["k8s.pod.name"], "my-pod-name.*")

----------------------------------------

TITLE: Configuring Recombine Operator for Kubernetes CRI Logs in YAML
DESCRIPTION: Example configuration for recombining Kubernetes logs in the CRI format using the recombine operator. It uses a regex parser to extract log components and then recombines them based on the logtag field.

LANGUAGE: yaml
CODE:
- type: file_input
  include:
    - ./input.log
- type: regex_parser
  regex: '^(?P<timestamp>[^\s]+) (?P<stream>\w+) (?P<logtag>\w) (?P<message>.*)'
- type: recombine
  combine_field: body.message
  combine_with: ""
  is_last_entry: "body.logtag == 'F'"
  overwrite_with: "newest"

----------------------------------------

TITLE: Enabling Permissive Label Sanitization in Shell
DESCRIPTION: Command to enable permissive label sanitization for Prometheus metrics using feature gates in the OpenTelemetry Collector.

LANGUAGE: shell
CODE:
$ otelcol --config=config.yaml --feature-gates=pkg.translator.prometheus.PermissiveLabelSanitization

----------------------------------------

TITLE: HAProxy Receiver Metrics Configuration in YAML
DESCRIPTION: Example showing how to selectively enable or disable specific metrics in the HAProxy receiver configuration.

LANGUAGE: yaml
CODE:
receivers:\n  haproxy:\n    endpoint: http://127.0.0.1:8080/stats\n    metrics:\n      haproxy.connection_rate:\n        enabled: false\n      haproxy.requests:\n        enabled: true

----------------------------------------

TITLE: Configuring Advanced gRPC Settings for OpenTelemetry Protocol with Apache Arrow Receiver
DESCRIPTION: Example of configuring advanced gRPC settings for the OpenTelemetry Protocol with Apache Arrow receiver. This includes specifying protocols and potential additional gRPC-specific configurations.

LANGUAGE: yaml
CODE:
receivers:
  otelarrow:
    protocols:
      grpc:
        ...

----------------------------------------

TITLE: Text Encoding Extension Configuration
DESCRIPTION: Extended YAML configuration showing how to set up text encoding extension for processing arbitrary text messages from a subscription into OTLP Log messages.

LANGUAGE: yaml
CODE:
extensions:
  text_encoding:
    encoding: utf8
    unmarshaling_separator: "\r?\n"

service:
  extensions: [text_encoding]
  pipelines:
    logs:
      receivers: [googlecloudpubsub]
      processors: []
      exporters: [debug]

----------------------------------------

TITLE: Configuring Oracle DB Receiver with Selective Metrics
DESCRIPTION: Example showing how to enable or disable specific metrics using the metrics configuration block.

LANGUAGE: yaml
CODE:
receivers:
  oracledb:
    datasource: "oracle://otel:password@localhost:51521/XE"
    metrics:
      oracledb.query.cpu_time:
        enabled: false
      oracledb.query.physical_read_requests:
        enabled: true

----------------------------------------

TITLE: Configuring Default Expvar Receiver in YAML
DESCRIPTION: The default configuration for the Expvar receiver, which sends requests to http://localhost:8000/debug/vars every 60 seconds.

LANGUAGE: yaml
CODE:
receivers:
  expvar:

----------------------------------------

TITLE: Configuring Network Scraper in YAML
DESCRIPTION: Configuration options for the network scraper, including interface inclusion/exclusion and match type.

LANGUAGE: yaml
CODE:
network:
  <include|exclude>:
    interfaces: [ <interface name>, ... ]
    match_type: <strict|regexp>

----------------------------------------

TITLE: Basic AWS ECS Container Metrics Configuration
DESCRIPTION: Basic configuration example showing how to set up the AWS ECS Container Metrics receiver with a collection interval.

LANGUAGE: yaml
CODE:
receivers:
  awsecscontainermetrics:
    collection_interval: 20s

----------------------------------------

TITLE: Adding Label to Multiple Metrics in YAML
DESCRIPTION: Example of adding a version label to all system metrics using the Metrics Transform Processor.

LANGUAGE: yaml
CODE:
include: ^system\.
match_type: regexp
action: update
operations:
  - action: add_label
    new_label: version
    new_value: opentelemetry collector {{version}}

----------------------------------------

TITLE: Setting Up MongoDB Atlas Alert Listener in YAML
DESCRIPTION: Configuration for listening to MongoDB Atlas alerts using a webhook with a secret and specified endpoint.

LANGUAGE: yaml
CODE:
receivers:
  mongodbatlas:
    alerts:
      enabled: true
      secret: "some_secret"
      endpoint: "0.0.0.0:7706"

----------------------------------------

TITLE: Input and Output JSON for Key Value Parsing with Custom Pair Delimiter
DESCRIPTION: Example JSON showing the input and output for key-value parsing using a custom pair delimiter ('!') in the 'message' field.

LANGUAGE: json
CODE:
{
  "timestamp": "",
  "body": {
    "message": "name=stanza ! org=otel      ! group=dev"
  }
}

LANGUAGE: json
CODE:
{
  "timestamp": "",
  "body": {
    "name": "stanza",
    "org": "otel",
    "group": "dev"
  }
}

----------------------------------------

TITLE: Configuring Local Authentication with Environment Variable in YAML
DESCRIPTION: This snippet shows how to use an environment variable to store the connection string for Local Authentication in the YAML configuration file.

LANGUAGE: yaml
CODE:
exporters:
   azuremonitor:
      connection_string: ${env:APPLICATIONINSIGHTS_CONNECTION_STRING}

----------------------------------------

TITLE: Configuring Multiple Host Metrics Receivers in YAML
DESCRIPTION: Example configuration for multiple Host Metrics Receivers with different collection intervals for various scrapers.

LANGUAGE: yaml
CODE:
receivers:
  hostmetrics:
    collection_interval: 30s
    scrapers:
      cpu:
      memory:

  hostmetrics/disk:
    collection_interval: 1m
    scrapers:
      disk:
      filesystem:

service:
  pipelines:
    metrics:
      receivers: [hostmetrics, hostmetrics/disk]

----------------------------------------

TITLE: Describing OTel Arrow Admission Waiting Bytes Metric
DESCRIPTION: Documentation for a metric that tracks the number of bytes waiting to begin processing in the OTel Arrow component.

LANGUAGE: markdown
CODE:
| Unit | Metric Type | Value Type | Monotonic |
| ---- | ----------- | ---------- | --------- |
| By | Sum | Int | false |

----------------------------------------

TITLE: Extract and Convert Action Configuration
DESCRIPTION: Configuration for extract action using regex patterns and convert action for type conversion.

LANGUAGE: yaml
CODE:
- key: <key>
  pattern: <regular pattern with named matchers>
  action: extract

- key: <key>
  action: convert
  converted_type: <int|double|string>

----------------------------------------

TITLE: Configuring DataSet Exporter in OpenTelemetry Collector
DESCRIPTION: Example YAML configuration for setting up the DataSet exporter for logs and traces, including processors for attribute handling and resource management.

LANGUAGE: yaml
CODE:
processors:
  attributes:
    - key: serverHost
      action: insert
      from_attribute: container_id
  resource:
    attributes:
      - key: serverHost
        from_attribute: node_id
        action: insert      

exporters:
  dataset/logs:
    # DataSet API URL, https://app.eu.scalyr.com for DataSet EU instance
    dataset_url: https://app.scalyr.com
    # API Key
    api_key: your_api_key
    buffer:
      # Send buffer to the API at least every 5s
      max_lifetime: 5s
      # Group data based on these attributes
      group_by:
        - container_id
      # try to send data to the DataSet for at most 30s during shutdown
      retry_shutdown_timeout: 30s
    server_host:
      # If the serverHost attribute is not specified or empty,
      # use the value from the env variable SERVER_HOST
      server_host: ${env:SERVER_HOST}
      # If server_host is not set, use the hostname value
      use_hostname: true

  dataset/traces:
    # DataSet API URL, https://app.eu.scalyr.com for DataSet EU instance
    dataset_url: https://app.scalyr.com
    # API Key
    api_key: your_api_key
    buffer:
      max_lifetime: 15s
      group_by:
        - resource_service.instance.id

service:
  pipelines:
    logs:
      receivers: [otlp]
      processors: [batch, attributes]
      # add dataset among your exporters
      exporters: [dataset/logs]
    traces:
      receivers: [otlp]
      processors: [batch]
      # add dataset among your exporters
      exporters: [dataset/traces]

----------------------------------------

TITLE: Configuring Sumo Logic Processor in YAML
DESCRIPTION: YAML configuration for the Sumo Logic processor, including options for cloud namespace, attribute translation, telegraf and docker metric translation, attribute nesting, and attribute aggregation.

LANGUAGE: yaml
CODE:
processors:
  sumologic:
    add_cloud_namespace: {true,false}
    translate_attributes: {true,false}
    translate_telegraf_attributes: {true, false}
    translate_docker_metrics: {true, false}
    nest_attributes:
      enabled: {true, false}
      separator: <separator>
      include: [<prefix>]
      exclude: [<prefix>]
      squash_single_values: {true, false}
    aggregate_attributes:
      - attribute: <attribute>
        prefixes: [<prefix>]
      - ...
    field_attributes:
      severity_number:
        enabled: true
        name: "loglevel"

----------------------------------------

TITLE: Configuring vCenter Receiver in YAML
DESCRIPTION: Example configuration for the vCenter receiver in the OpenTelemetry Collector. It specifies the endpoint, credentials, collection interval, and initial delay for fetching metrics from a vCenter or ESXi host.

LANGUAGE: yaml
CODE:
receivers:
  vcenter:
    endpoint: http://localhost:15672
    username: otelu
    password: ${env:VCENTER_PASSWORD}
    collection_interval: 5m
    initial_delay: 1s
    metrics: []

----------------------------------------

TITLE: Input and Output JSON for Key Value Parsing with Custom Delimiter
DESCRIPTION: Example JSON showing the input and output for key-value parsing using a custom delimiter (':') in the 'message' field.

LANGUAGE: json
CODE:
{
  "timestamp": "",
  "body": {
    "message": "name:stanza"
  }
}

LANGUAGE: json
CODE:
{
  "timestamp": "",
  "body": {
    "name": "stanza"
  }
}

----------------------------------------

TITLE: Configuring Key Value Parser with Custom Delimiter in YAML
DESCRIPTION: YAML configuration for the key_value_parser operator using a non-default delimiter (':') to parse the 'message' field.

LANGUAGE: yaml
CODE:
- type: key_value_parser
  parse_from: message
  delimiter: ":"

----------------------------------------

TITLE: Multi-Team Coralogix Export Configuration
DESCRIPTION: Example of configuring multiple Coralogix exporters for different teams based on attributes.

LANGUAGE: yaml
CODE:
processors:  
  filter/teamA:
    metrics:
      datapoint:
          - 'attributes["your_label"] != "teamA"'
  filter/teamB:
    metrics:
      datapoint:
          - 'attributes["your_label"] != "teamB"'

exporters:
  coralogix/teamA:
    metrics:
      endpoint: "otel-metrics.coralogix.com:443"
    private_key: <private_key_for_teamA>
    application_name: "MyBusinessEnvironment"
    subsystem_name: "MyBusinessSystem"
  coralogix/teamB:
    metrics:
      endpoint: "otel-metrics.coralogix.com:443"
    private_key: <private_key_for_teamB>
    application_name: "MyBusinessEnvironment"
    subsystem_name: "MyBusinessSystem"

service:
  pipelines:
    metrics/1:
      receivers: [prometheus]
      processors: [filter/teamA]
      exporters: [coralogix/teamA]
    metrics/2:
      receivers: [prometheus]
      processors: [filter/teamB]
      exporters: [coralogix/teamB]

----------------------------------------

TITLE: Moving Value to Attributes
DESCRIPTION: Demonstrates moving a value from body to attributes section

LANGUAGE: yaml
CODE:
- type: move
  from: body.ip
  to: attributes.ip

LANGUAGE: json
CODE:
{
  "resource": { },
  "attributes": { },
  "body": {
    "ip": "8.8.8.8"
  }
}

----------------------------------------

TITLE: Implementing Sigv4 Signing RoundTripper in Go
DESCRIPTION: Implements the signingRoundTripper struct and its RoundTrip method to sign HTTP requests with AWS Sigv4. It includes logic for cloning requests, adding runtime information, and performing the actual signing process.

LANGUAGE: go
CODE:
type signingRoundTripper struct {
    transport http.RoundTripper
    signer *v4.Signer
    region string
    service string
    credsProvider *aws.CredentialsProvider
    awsSDKInfo string
	logger *zap.Logger
}

func (si *signingRoundTripper) RoundTrip(req *http.Request) (*http.Response, error) {
    // Implementation details omitted for brevity
    // Includes: cloning request, adding User-Agent info, hashing request,
    // inferring service/region, signing the request, and sending it
}

func (si *signingRoundTripper) inferServiceAndRegionFromRequestURL(r *http.Request) (service string, region string) {
    // Implementation details omitted for brevity
}

----------------------------------------

TITLE: Configuring Memory Metrics in OpenTelemetry YAML
DESCRIPTION: Example configuration to disable default metrics or enable optional metrics in the OpenTelemetry Collector. Uses a simple YAML structure to toggle metric collection.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Configuring CouchDB Receiver in YAML
DESCRIPTION: Example configuration for the CouchDB receiver in the OpenTelemetry Collector. It specifies the endpoint, username, password, and collection interval.

LANGUAGE: yaml
CODE:
receivers:
  couchdb:
    endpoint: http://localhost:5984
    username: otelu
    password: ${env:COUCHDB_PASSWORD}
    collection_interval: 60s

----------------------------------------

TITLE: Configuring Datadog Connector Options in OpenTelemetry Collector
DESCRIPTION: Detailed YAML configuration options for the Datadog Connector, including trace handling, span naming, stat computation, peer tag aggregation, and various other customization options.

LANGUAGE: yaml
CODE:
connectors:
    datadog/connector:
      traces:
        # ignore_resources: ["(GET|POST) /healthcheck"]
        # span_name_remappings:
        #   io.opentelemetry.javaagent.spring.client: spring.client
        #   instrumentation:express.server: express
        #   go.opentelemetry.io_contrib_instrumentation_net_http_otelhttp.client: http.client
        # span_name_as_resource_name: true
        # compute_stats_by_span_kind: true
        # peer_tags_aggregation: false
        # trace_buffer: 1000
        # peer_tags: ["tag"]
        # resource_attributes_as_container_tags: ["cloud.availability_zone", "cloud.region"]
        # bucket_interval: 30s

----------------------------------------

TITLE: Configuring URI Parser for Absolute URI Parsing in YAML
DESCRIPTION: This snippet shows how to configure the uri_parser operator to parse the body.message field as an absolute URI. It demonstrates the basic configuration syntax for the operator.

LANGUAGE: yaml
CODE:
- type: uri_parser
  parse_from: body.message

----------------------------------------

TITLE: Configuring URI Parser for Absolute URI Parsing in YAML
DESCRIPTION: This snippet shows how to configure the uri_parser operator to parse the body.message field as an absolute URI. It demonstrates the basic configuration syntax for the operator.

LANGUAGE: yaml
CODE:
- type: uri_parser
  parse_from: body.message

----------------------------------------

TITLE: Configuring RabbitMQ Receiver in YAML
DESCRIPTION: Example configuration for the RabbitMQ receiver in OpenTelemetry Collector. It sets up the endpoint, credentials, collection interval, and enables specific node metrics.

LANGUAGE: yaml
CODE:
receivers:
  rabbitmq:
    endpoint: http://localhost:15672
    username: otelu
    password: ${env:RABBITMQ_PASSWORD}
    collection_interval: 10s
     metrics:  # Enable node metrics by explicitly setting them to true
      rabbitmq.node.disk_free:
        enabled: true
      rabbitmq.node.fd_used:
        enabled: true
      rabbitmq.node.mem_limit:
        enabled: true
      rabbitmq.node.mem_used:
        enabled: true

----------------------------------------

TITLE: Configuring Pure Storage FlashBlade Receiver in YAML
DESCRIPTION: Example configuration for setting up the Pure Storage FlashBlade receiver with bearer token authentication, multiple endpoint scraping, and custom reload intervals. The configuration includes array and client endpoints with separate authentication tokens and environment settings.

LANGUAGE: yaml
CODE:
extensions:
  bearertokenauth/fb01:
    token: "..."

receivers:
  purefb:
    endpoint: http://172.31.60.207:9491/metrics
    arrays:
      - address: fb01
        auth:
          authenticator: bearertokenauth/fb01
    clients:
      - address: fb01
        auth:
          authenticator: bearertokenauth/fb01
    env: dev
    settings:
      reload_intervals:
        array: 5m
        clients: 6m
        usage: 6m

----------------------------------------

TITLE: Configuring JSON Array Parser to Parse Body into Attributes
DESCRIPTION: YAML configuration for parsing the 'body' field containing a JSON array into an 'attributes.output' field, along with input and output examples.

LANGUAGE: yaml
CODE:
- type: json_array_parser
  parse_from: body
  parse_to: attributes.output

LANGUAGE: json
CODE:
{
  "body": "[1,\"debug\",\"Debug Message\", true]"
}

LANGUAGE: json
CODE:
{
  "attributes": {
    "output": [1, "debug", "Debug Message", true]
  }
}

----------------------------------------

TITLE: Configuring Key Value Parser with Timestamp Parsing in YAML
DESCRIPTION: YAML configuration for the key_value_parser operator that parses the 'message' field and includes timestamp parsing from an epoch format.

LANGUAGE: yaml
CODE:
- type: key_value_parser
  parse_from: message
  timestamp:
    parse_from: seconds_since_epoch
    layout_type: epoch
    layout: s

----------------------------------------

TITLE: Configuring Keepalive Settings for OpenTelemetry Protocol with Apache Arrow Receiver
DESCRIPTION: Example of configuring keepalive settings for the OpenTelemetry Protocol with Apache Arrow receiver. This includes setting max connection age and grace period for gRPC connections.

LANGUAGE: yaml
CODE:
receivers:
  otelarrow:
    protocols:
      grpc:
        keepalive:
          server_parameters:
            max_connection_age: 1m
            max_connection_age_grace: 10m

----------------------------------------

TITLE: Enabling Optional Docker Stats Metrics
DESCRIPTION: YAML configuration example showing how to enable optional metrics that are not collected by default

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: true

----------------------------------------

TITLE: Configuring Batch Processor for Datadog Export
DESCRIPTION: Example configuration for setting up a dedicated batch processor to handle payload size limits when exporting to Datadog. Demonstrates how to configure separate batch processors for Datadog and other exporters.

LANGUAGE: yaml
CODE:
processors:
  batch:  # To be used by other exporters
    timeout: 1s
    # Default value for send_batch_size is 8192
  batch/datadog:
    send_batch_max_size: 100
    send_batch_size: 10
    timeout: 10s
...
service:
  pipelines:
    metrics:
      receivers: ...
      processors: [batch/datadog]
      exporters: [datadog]

----------------------------------------

TITLE: Configuring Memcached Receiver in YAML
DESCRIPTION: Example configuration for the Memcached receiver showing basic setup with endpoint, collection interval, and transport protocol settings. The receiver connects to a local Memcached instance on the default port 11211 with TCP transport.

LANGUAGE: yaml
CODE:
receivers:
  memcached:
    endpoint: "localhost:11211"
    collection_interval: 10s
    transport: tcp

----------------------------------------

TITLE: Defining Redis CPU Time Metric in Go
DESCRIPTION: This Go function defines a Redis metric for CPU time usage. It specifies the key, name, units, metric type, and labels for the 'used_cpu_sys' metric from Redis INFO command.

LANGUAGE: go
CODE:
func usedCPUSys() *redisMetric {
	return &redisMetric{
		key:    "used_cpu_sys",
		name:   "redis.cpu.time",
		units:  "s",
		mdType: metricspb.MetricDescriptor_GAUGE_DOUBLE,
		labels: map[string]string{"state": "sys"},
	}
}

----------------------------------------

TITLE: Disabling gRPC-level Compression for OpenTelemetry Protocol with Apache Arrow Exporter
DESCRIPTION: YAML configuration snippet showing how to disable gRPC-level compression for the OpenTelemetry Protocol with Apache Arrow exporter.

LANGUAGE: yaml
CODE:
exporters:
  otelarrow:
    compression: none
    endpoint: ...
    tls: ...

----------------------------------------

TITLE: Flattening Object at Base Level
DESCRIPTION: Example showing how to flatten an object at the base level of the body using the flatten operator. Demonstrates moving nested fields 'nested1' and 'nested2' up one level.

LANGUAGE: yaml
CODE:
- type: flatten
  field: body.key1

LANGUAGE: json
CODE:
{
  "resource": { },
  "attributes": { },
  "body": {
    "key1": {
      "nested1": "nestedval1",
      "nested2": "nestedval2"
    },
    "key2": "val2"
  }
}

LANGUAGE: json
CODE:
{
    "resource": { },
    "attributes": { },
    "body": {
      "nested1": "nestedval1",
      "nested2": "nestedval2",
      "key2": "val2"
    }
  }

----------------------------------------

TITLE: Configuring Key Value Parser with Custom Pair Delimiter in YAML
DESCRIPTION: YAML configuration for the key_value_parser operator using a non-default pair delimiter ('!') to parse the 'message' field.

LANGUAGE: yaml
CODE:
- type: key_value_parser
  parse_from: message
  pair_delimiter: "!"

----------------------------------------

TITLE: Configuring PostgreSQL Receiver with Connection Pool
DESCRIPTION: Example configuration demonstrating connection pool settings for the PostgreSQL receiver to optimize connection management and audit log generation.

LANGUAGE: yaml
CODE:
receivers:
  postgresql:
    endpoint: localhost:5432
    transport: tcp
    username: otel
    password: ${env:POSTGRESQL_PASSWORD}
    connection_pool:
      max_idle_time: 10m
      max_lifetime: 0
      max_idle: 2
      max_open: 5

----------------------------------------

TITLE: Configuring MongoDB Atlas Receiver for Metrics Collection in YAML
DESCRIPTION: Basic configuration to receive metrics from MongoDB Atlas using public and private API keys.

LANGUAGE: yaml
CODE:
receivers:
  mongodbatlas:
    public_key: ${env:MONGODB_ATLAS_PUBLIC_KEY}
    private_key: ${env:MONGODB_ATLAS_PRIVATE_KEY}

----------------------------------------

TITLE: Configuring MongoDB Atlas Receiver for Metrics Collection in YAML
DESCRIPTION: Basic configuration to receive metrics from MongoDB Atlas using public and private API keys.

LANGUAGE: yaml
CODE:
receivers:
  mongodbatlas:
    public_key: ${env:MONGODB_ATLAS_PUBLIC_KEY}
    private_key: ${env:MONGODB_ATLAS_PRIVATE_KEY}

----------------------------------------

TITLE: Creating Sigv4 Authenticator Factory in Go
DESCRIPTION: Implements the factory for creating the Sigv4 Authenticator extension, including functions for creating default configurations and the actual extension instance.

LANGUAGE: go
CODE:
func NewFactory() extension.Factory {
    return extensionhelper.NewFactory(
        "sigv4auth",
        createDefaultConfig,
        createExtension)
}

func createDefaultConfig() component.Config {
    return &Config{}
}

func createExtension(_ context.Context, set extension.CreateSettings, cfg component.Config) (extension.Extension, error) {
    awsSDKInfo := fmt.Sprintf("%s/%s", aws.SDKName, aws.SDKVersion)
    return newSigv4Extension(cfg.(*Config), awsSDKInfo, set.Logger)
}

----------------------------------------

TITLE: Creating ClusterRoleBinding for OpenTelemetry Collector in Kubernetes
DESCRIPTION: Bash script to create a Kubernetes ClusterRoleBinding to grant the ClusterRole to the Service Account for the OpenTelemetry Collector.

LANGUAGE: bash
CODE:
<<EOF | kubectl apply -f -
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: otelcontribcol
  labels:
    app: otelcontribcol
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: otelcontribcol
subjects:
- kind: ServiceAccount
  name: otelcontribcol
  namespace: default
EOF

----------------------------------------

TITLE: Creating Kubernetes ClusterRole for OpenTelemetry Collector
DESCRIPTION: YAML configuration to create a Kubernetes ClusterRole with permissions for the Kubernetes Objects Receiver to access pods and events.

LANGUAGE: yaml
CODE:
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: otelcontribcol
  labels:
    app: otelcontribcol
rules:
- apiGroups:
  - ""
  resources:
  - events
  - pods
  verbs:
  - get
  - list
  - watch
- apiGroups: 
  - "events.k8s.io"
  resources:
  - events
  verbs:
  - watch
  - list

----------------------------------------

TITLE: Configuring Container Log Parser for Docker Format in YAML
DESCRIPTION: This snippet demonstrates how to configure the container operator to parse Docker format logs and add metadata from the file path.

LANGUAGE: yaml
CODE:
- type: container
  format: docker
  add_metadata_from_filepath: true

----------------------------------------

TITLE: Configuring Container Log Parser for Docker Format in YAML
DESCRIPTION: This snippet demonstrates how to configure the container operator to parse Docker format logs and add metadata from the file path.

LANGUAGE: yaml
CODE:
- type: container
  format: docker
  add_metadata_from_filepath: true

----------------------------------------

TITLE: Implementing Export Function for Prometheus Remote Write in Go
DESCRIPTION: This code snippet shows the basic structure of the export function for the Prometheus Remote Write/Cortex exporter. It converts TimeSeries to a byte array and sends an HTTP request to the backend.

LANGUAGE: go
CODE:
func export(*map) error {
	// Stores timeseries
	arr := make([]TimeSeries)

	for timeseries in map:
		arr = append(arr, timeseries)

		// Converts arr to WriteRequest
		request := proto.Marshal(arr)

	// Sends HTTP request to endpoint
}

----------------------------------------

TITLE: Namespace-Scoped RBAC Configuration
DESCRIPTION: YAML configuration for setting up namespace-scoped RBAC permissions for the K8sAttributes processor.

LANGUAGE: yaml
CODE:
apiVersion: v1
kind: ServiceAccount
metadata:
  name: otel-collector
  namespace: <OTEL_COL_NAMESPACE>
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: otel-collector
  namespace: <WORKLOAD_NAMESPACE>
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "watch", "list"]
- apiGroups: ["apps"]
  resources: ["replicasets"]
  verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: otel-collector
  namespace: <WORKLOAD_NAMESPACE>
subjects:
- kind: ServiceAccount
  name: otel-collector
  namespace: <OTEL_COL_NAMESPACE>
roleRef:
  kind: Role
  name: otel-collector
  apiGroup: rbac.authorization.k8s.io

----------------------------------------

TITLE: Input/Output JSON Examples for Copy Operations
DESCRIPTION: These JSON snippets demonstrate the input and output for various copy operations, including copying between body, resource, and attributes fields.

LANGUAGE: json
CODE:
{
  "resource": { },
  "attributes": { },
  "body": {
    "key":"value"
  }
}

LANGUAGE: json
CODE:
{
  "resource": {
       "newkey":"value"
  },
  "attributes": { },
  "body": {
    "key":"value"
  }
}

LANGUAGE: json
CODE:
{
  "resource": { },
  "attributes": { },
  "body": {
    "key1": "val1",
    "key2": "val2"
  }
}

LANGUAGE: json
CODE:
{
  "resource": { },
  "attributes": {
      "newkey": "val2"
  },
  "body": {
    "key3": "val1",
    "key2": "val2"
  }
}

LANGUAGE: json
CODE:
{
  "resource": { },
  "attributes": {
      "key": "newval"
  },
  "body": {
    "key1": "val1",
    "key2": "val2"
  }
}

LANGUAGE: json
CODE:
{
  "resource": { },
  "attributes": {
      "key": "newval"
  },
  "body": {
    "key3": "val1",
    "key2": "val2",
    "newkey": "newval"
  }
}

LANGUAGE: json
CODE:
{
  "resource": { },
  "attributes": { },
  "body": {
      "obj": {
        "nested":"nestedvalue"
    }
  }
}

LANGUAGE: json
CODE:
{
  "resource": { },
  "attributes": { },
  "body": {
    "obj": {
        "nested":"nestedvalue"
    },
    "newkey":"nestedvalue"
  }
}

----------------------------------------

TITLE: Input and Output JSON for Basic Key Value Parsing
DESCRIPTION: Example JSON showing the input and output for basic key-value parsing of the 'message' field.

LANGUAGE: json
CODE:
{
  "timestamp": "",
  "body": {
    "message": "name=stanza"
  }
}

LANGUAGE: json
CODE:
{
  "timestamp": "",
  "body": {
    "name": "stanza"
  }
}

----------------------------------------

TITLE: Configuring Retain Operator for Multiple Sources in YAML
DESCRIPTION: This example shows how to retain fields from multiple sources (resource, attributes, and body) in a single configuration. It keeps one field from each source, removing all other fields.

LANGUAGE: yaml
CODE:
- type: retain
  fields:
    - resource.key1
    - attributes.key3
    - body.key5

----------------------------------------

TITLE: Compaction Configuration Example in YAML
DESCRIPTION: YAML configuration showing how to set up the processor for data compaction alongside batch processing.

LANGUAGE: yaml
CODE:
processors:
  batch:
  groupbyattrs:

pipelines:
  traces:
    processors: [batch, groupbyattrs/grouping]
    ...

----------------------------------------

TITLE: Delete and Hash Action Configuration
DESCRIPTION: Configuration for delete and hash actions that can operate on specific keys or patterns.

LANGUAGE: yaml
CODE:
- key: <key>
  action: delete
  pattern: <regular pattern>

- key: <key>
  action: hash
  pattern: <regular pattern>

----------------------------------------

TITLE: Configuring Datadog Receiver in OpenTelemetry Collector
DESCRIPTION: Example configuration for setting up the Datadog receiver with metrics and traces pipelines. Demonstrates basic configuration including endpoint and read timeout settings, along with pipeline setup for both metrics and traces exporters.

LANGUAGE: yaml
CODE:
receivers:
  datadog:
    endpoint: localhost:8126
    read_timeout: 60s

exporters:
  debug:

service:
  pipelines:
    metrics:
      receivers: [datadog]
      exporters: [debug]
    traces:
      receivers: [datadog]
      exporters: [debug]

----------------------------------------

TITLE: Cluster-Scoped RBAC Configuration
DESCRIPTION: YAML configuration for setting up cluster-scoped RBAC permissions for the K8sAttributes processor.

LANGUAGE: yaml
CODE:
apiVersion: v1
kind: ServiceAccount
metadata:
  name: collector
  namespace: <OTEL_COL_NAMESPACE>
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: otel-collector
rules:
- apiGroups: [""]
  resources: ["pods", "namespaces", "nodes"]
  verbs: ["get", "watch", "list"]
- apiGroups: ["apps"]
  resources: ["replicasets"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["extensions"]
  resources: ["replicasets"]
  verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: otel-collector
subjects:
- kind: ServiceAccount
  name: collector
  namespace: <OTEL_COL_NAMESPACE>
roleRef:
  kind: ClusterRole
  name: otel-collector
  apiGroup: rbac.authorization.k8s.io

----------------------------------------

TITLE: Copying Value from Attributes to Body in YAML
DESCRIPTION: This example demonstrates how to use the 'copy' operator to move a value from the attributes field to the body.

LANGUAGE: yaml
CODE:
- type: copy
  from: attributes.key
  to: body.newkey

----------------------------------------

TITLE: Input and Output JSON for Key Value Parsing with Timestamp Parsing
DESCRIPTION: Example JSON showing the input and output for key-value parsing with timestamp parsing from an epoch format in the 'message' field.

LANGUAGE: json
CODE:
{
  "timestamp": "",
  "body": {
    "message": "name=stanza seconds_since_epoch=1136214245"
  }
}

LANGUAGE: json
CODE:
{
  "timestamp": "2006-01-02T15:04:05-07:00",
  "body": {
    "name": "stanza"
  }
}

----------------------------------------

TITLE: Configuring OTLP JSON File Receiver in YAML
DESCRIPTION: Example YAML configuration for the OTLP JSON File Receiver. It demonstrates how to set up file inclusion and exclusion patterns for data collection.

LANGUAGE: yaml
CODE:
receivers:
  otlpjsonfile:
    include:
      - "/var/log/*.log"
    exclude:
      - "/var/log/example.log"

----------------------------------------

TITLE: Enabling Metrics in OpenTelemetry Collector for DataSet Exporter
DESCRIPTION: YAML configuration snippet for enabling metrics scraping in the OpenTelemetry Collector, including the Prometheus receiver setup.

LANGUAGE: yaml
CODE:
receivers:
  prometheus:
    config:
      scrape_configs:
        - job_name: 'otel-collector'
          scrape_interval: 5s
          static_configs:
            - targets: ['0.0.0.0:8888']
...
service:
  pipelines:
    metrics:
      # add prometheus among metrics receivers
      receivers: [prometheus]
      processors: [batch]
      exporters: [otlphttp/prometheus, debug]

----------------------------------------

TITLE: Disabling Specific Metrics in YAML Configuration
DESCRIPTION: Shows how to disable specific metrics in the collector's YAML configuration. This can be applied to any of the default metrics listed in the document.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Configuring Carbon Exporter in YAML
DESCRIPTION: Example YAML configuration for the Carbon exporter, showing default settings and a custom configuration with all available options.

LANGUAGE: yaml
CODE:
exporters:
  carbon:
    # by default it will export to localhost:2003 using tcp
  carbon/allsettings:
    # use endpoint to specify alternative destinations for the exporter,
    # the default is localhost:2003
    endpoint: localhost:8080
    # timeout is the maximum duration allowed to connecting and sending the
    # data to the configured endpoint.
    # The default is 5 seconds.
    timeout: 10s

----------------------------------------

TITLE: Creating Kubernetes ClusterRoleBinding for OpenTelemetry Collector
DESCRIPTION: YAML configuration to create a Kubernetes ClusterRoleBinding, linking the ClusterRole to the Service Account for the OpenTelemetry Collector.

LANGUAGE: yaml
CODE:
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: otelcontribcol
  labels:
    app: otelcontribcol
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: otelcontribcol
subjects:
- kind: ServiceAccount
  name: otelcontribcol
  namespace: default

----------------------------------------

TITLE: Configuring Routing Connector for Log Routing by Region
DESCRIPTION: This YAML configuration shows how to route logs based on region information using the Routing Connector. It sets up different file exporters for different regions and uses the 'log' context to route logs.

LANGUAGE: yaml
CODE:
receivers:
    otlp:

exporters:
  file/other:
    path: ./other.log
  file/east:
    path: ./east.log
  file/west:
    path: ./west.log

connectors:
  routing:
    default_pipelines: [logs/other]
    table:
      - context: log
        condition: attributes["region"] == "east"
        pipelines: [logs/east]
      - context: log
        condition: attributes["region"] == "west"
        pipelines: [logs/west]

service:
  pipelines:
    logs/in:
      receivers: [otlp]
      exporters: [routing]
    logs/east:
      receivers: [routing]
      exporters: [file/east]
    logs/west:
      receivers: [routing]
      exporters: [file/west]
    logs/other:
      receivers: [routing]
      exporters: [file/other]

----------------------------------------

TITLE: Configuring Routing Connector for Log Routing by Region
DESCRIPTION: This YAML configuration shows how to route logs based on region information using the Routing Connector. It sets up different file exporters for different regions and uses the 'log' context to route logs.

LANGUAGE: yaml
CODE:
receivers:
    otlp:

exporters:
  file/other:
    path: ./other.log
  file/east:
    path: ./east.log
  file/west:
    path: ./west.log

connectors:
  routing:
    default_pipelines: [logs/other]
    table:
      - context: log
        condition: attributes["region"] == "east"
        pipelines: [logs/east]
      - context: log
        condition: attributes["region"] == "west"
        pipelines: [logs/west]

service:
  pipelines:
    logs/in:
      receivers: [otlp]
      exporters: [routing]
    logs/east:
      receivers: [routing]
      exporters: [file/east]
    logs/west:
      receivers: [routing]
      exporters: [file/west]
    logs/other:
      receivers: [routing]
      exporters: [file/other]

----------------------------------------

TITLE: Configuring Exponential Histogram Metrics in YAML
DESCRIPTION: Example configuration for exponential histogram metrics, showing max_size, count, and value settings.

LANGUAGE: yaml
CODE:
exponential_histogram:
  max_size: <int64>
  count: <ottl_value_expression>
  value: <ottl_value_expression>

----------------------------------------

TITLE: Parsing Timestamp Using Epoch Layout
DESCRIPTION: This snippet shows how to configure a time_parser operator to parse a timestamp using the epoch layout type. It specifies the field to parse from and the epoch format (seconds in this case).

LANGUAGE: yaml
CODE:
- type: time_parser
  parse_from: body.timestamp_field
  layout_type: epoch
  layout: s

----------------------------------------

TITLE: Parsing Timestamp with Regex Parser in YAML
DESCRIPTION: Configuration example that parses both the body with a regex and extracts a timestamp. It uses strptime to parse the timestamp field.

LANGUAGE: yaml
CODE:
- type: regex_parser
  regex: '^Time=(?P<timestamp_field>\d{4}-\d{2}-\d{2}), Host=(?P<host>[^,]+), Type=(?P<type>.*)$'
  timestamp:
    parse_from: body.timestamp_field
    layout_type: strptime
    layout: '%Y-%m-%d'

----------------------------------------

TITLE: Debug Logging Configuration - YAML
DESCRIPTION: Example configuration for enabling debug logging to troubleshoot OTTL conditions in the filter processor.

LANGUAGE: yaml
CODE:
receivers:
  filelog:
    start_at: beginning
    include: [ /Users/tylerhelmuth/projects/opentelemetry-collector-contrib/local/test.log ]

processors:
  filter:
    error_mode: ignore
    logs:
      log_record:
        - body == "test"

exporters:
  debug:

service:
  telemetry:
    logs:
      level: debug
  pipelines:
    logs:
      receivers:
        - filelog
      processors:
        - filter
      exporters:
        - debug

----------------------------------------

TITLE: Configuring Alertmanager Exporter in YAML
DESCRIPTION: Example configuration for the Alertmanager exporter in the OpenTelemetry Collector. It demonstrates how to set up multiple exporter instances with various options including TLS, timeout, sending queue, and retry on failure settings.

LANGUAGE: yaml
CODE:
exporters:
  alertmanager:
  alertmanager/2:
    endpoint: "https://a.new.alertmanager.target:9093"
    severity: "debug"
    severity_attribute: "foo"
    tls:
      cert_file: /var/lib/mycert.pem
      key_file: /var/lib/key.pem
    timeout: 10s
    sending_queue:
      enabled: true
      num_consumers: 2
      queue_size: 10
    retry_on_failure:
      enabled: true
      initial_interval: 10s
      max_interval: 60s
      max_elapsed_time: 10m
    generator_url: "opentelemetry-collector"

----------------------------------------

TITLE: Configuring Alertmanager Exporter in YAML
DESCRIPTION: Example configuration for the Alertmanager exporter in the OpenTelemetry Collector. It demonstrates how to set up multiple exporter instances with various options including TLS, timeout, sending queue, and retry on failure settings.

LANGUAGE: yaml
CODE:
exporters:
  alertmanager:
  alertmanager/2:
    endpoint: "https://a.new.alertmanager.target:9093"
    severity: "debug"
    severity_attribute: "foo"
    tls:
      cert_file: /var/lib/mycert.pem
      key_file: /var/lib/key.pem
    timeout: 10s
    sending_queue:
      enabled: true
      num_consumers: 2
      queue_size: 10
    retry_on_failure:
      enabled: true
      initial_interval: 10s
      max_interval: 60s
      max_elapsed_time: 10m
    generator_url: "opentelemetry-collector"

----------------------------------------

TITLE: Moving Value to Resource
DESCRIPTION: Shows how to move a value from body to resource section

LANGUAGE: yaml
CODE:
- type: move
  from: body.uuid
  to: resource.uuid

LANGUAGE: json
CODE:
{
  "resource": { },
  "attributes": { },
  "body": {
    "uuid": "091edc50-d91a-460d-83cd-089a62937738"
  }
}

----------------------------------------

TITLE: Setting AES Key Environment Variable in Shell
DESCRIPTION: This command sets the OTEL_AES_CREDENTIAL_PROVIDER environment variable with a base64 encoded AES key.

LANGUAGE: shell
CODE:
export OTEL_AES_CREDENTIAL_PROVIDER="GQi+Y8HwOYzs8lAOjHUqB7vXlN8bVU2k0TAKtzwJzac="

----------------------------------------

TITLE: Configuring Active Directory DS Receiver in YAML
DESCRIPTION: Example configuration for the Active Directory DS receiver showing how to set collection interval and disable specific metrics. The receiver supports customizable collection intervals and metric enabling/disabling.

LANGUAGE: yaml
CODE:
receivers:
  active_directory_ds:
    collection_interval: 10s
    metrics:
      # Disable the active_directory.ds.replication.network.io metric from being emitted
      active_directory.ds.replication.network.io:
        enabled: false

----------------------------------------

TITLE: Aggregating Label Values in YAML
DESCRIPTION: Example of aggregating specific label values for system memory usage using the Metrics Transform Processor.

LANGUAGE: yaml
CODE:
include: system.memory.usage
action: update
operations:
  - action: aggregate_label_values
    label: state
    aggregated_values: [ slab_reclaimable, slab_unreclaimable ]
    new_value: slab 
    aggregation_type: sum

----------------------------------------

TITLE: Parsing Timestamp Using Strptime Layout
DESCRIPTION: This snippet shows how to configure a time_parser operator to parse a timestamp using the strptime layout type. It specifies the field to parse from and the exact layout of the timestamp.

LANGUAGE: yaml
CODE:
- type: time_parser
  parse_from: body.timestamp_field
  layout_type: strptime
  layout: '%a %b %e %H:%M:%S %Z %Y'

----------------------------------------

TITLE: Input and Output JSON Examples for Regex Parsing
DESCRIPTION: JSON examples showing input and output for various regex parsing scenarios, including basic parsing, timestamp extraction, and conditional parsing.

LANGUAGE: json
CODE:
{
  "timestamp": "",
  "body": {
    "message": "Host=127.0.0.1, Type=HTTP"
  }
}

LANGUAGE: json
CODE:
{
  "timestamp": "",
  "body": {
    "message": "Host=127.0.0.1, Type=HTTP"
  },
  "attributes": {
    "host": "127.0.0.1",
    "type": "HTTP"
  }
}

LANGUAGE: json
CODE:
{
  "timestamp": "",
  "body": "Time=2020-01-31, Host=127.0.0.1, Type=HTTP"
}

LANGUAGE: json
CODE:
{
  "timestamp": "2020-01-31T00:00:00-00:00",
  "body": "Time=2020-01-31, Host=127.0.0.1, Type=HTTP"
  "attributes": {
    "host": "127.0.0.1",
    "type": "HTTP"
  }
}

LANGUAGE: json
CODE:
{
  "body": {
    "message": "Host=testhost",
    "type": "hostname"
  }
}

LANGUAGE: json
CODE:
{
  "body": {
    "message": "Host=testhost",
    "type": "hostname"
  },
  "attributes": {
    "host": "testhost"
  }
}

LANGUAGE: json
CODE:
{
  "body": {
    "message": "Key=value",
    "type": "keypair"
  }
}

LANGUAGE: json
CODE:
{
  "body": {
    "message": "Key=value",
    "type": "keypair"
  }
}

----------------------------------------

TITLE: AWS X-Ray PostgreSQL Subsegment Configuration
DESCRIPTION: JSON configuration for an AWS X-Ray subsegment tracking a PostgreSQL database query. Includes database connection details, timing information, trace context, and SQL query information with sanitized query string.

LANGUAGE: json
CODE:
{
  "name": "ebdb@aawijb5u25wdoy.cpamxznpdoq8.us-west-2.rds.amazonaws.com",
  "id": "3fd8634e78ca9560",
  "start_time": 1484872218.696,
  "end_time": 1484872218.697,
  "namespace": "remote",
  "type" : "subsegment",
  "trace_id" : "1-581cf771-a006649127e371903a2de979",
  "parent_id" : "defdfd9912dc5a56",
  "sql" : {
    "url": "jdbc:postgresql://aawijb5u25wdoy.cpamxznpdoq8.us-west-2.rds.amazonaws.com:5432/ebdb?myInterceptor=foo",
    "preparation": "statement",
    "database_type": "PostgreSQL",
    "database_version": "9.5.4",
    "driver_version": "PostgreSQL 9.4.1211.jre7",
    "user" : "dbuser",
    "sanitized_query" : "SELECT  *  FROM  customers  WHERE  customer_id=?;"
  }
}

----------------------------------------

TITLE: Unquoting Body Field Configuration - YAML
DESCRIPTION: Configuration example showing how to unquote the body field of an entry using the unquote operator.

LANGUAGE: yaml
CODE:
- type: unquote
  field: body

LANGUAGE: json
CODE:
{
  "resource": { },
  "attributes": { },
  "body": "\"hello\""
}

LANGUAGE: json
CODE:
{
  "resource": { },
  "attributes": { },
  "body": "hello"
}

----------------------------------------

TITLE: Configuring Cloud Foundry Garden Observer Extension in YAML
DESCRIPTION: Example configuration for setting up the cfgarden_observer extension with receiver_creator to monitor Garden containers. Includes settings for refresh intervals, authentication, and container discovery rules.

LANGUAGE: yaml
CODE:
extensions:
  cfgarden_observer:
    refresh_interval: 30s
    cache_sync_interval: 10m
    include_app_labels: true
    garden:
      endpoint: my/path/to/garden.sock
    cloud_foundry:
      endpoint: https://api.cf.mydomain.com
      auth:
        type: client_credentials
        client_id: myclientid
        client_secret: myclientsecret

receivers:
  receiver_creator:
    watch_observers: [cfgarden_observer]
    receivers:
      prometheus_simple:
        rule: type == "container" && labels["prometheus.io/scrape"] == "true" 
        config:
          metrics_path: /metrics
          endpoint: '`endpoint`'

----------------------------------------

TITLE: Configuring Metric Collection in Kubelet Stats
DESCRIPTION: YAML configuration template for enabling or disabling specific metrics in the kubeletstats receiver. This configuration can be applied to both default and optional metrics.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Configuring Transform Processor for BMC Helix Attributes
DESCRIPTION: YAML configuration for a transform processor using OTTL to set required attributes for BMC Helix metrics, including entityName, entityTypeId, and instanceName.

LANGUAGE: yaml
CODE:
transform/hw_to_helix:
   # Apply transformations to all metrics
    metric_statements:

      - context: datapoint
        statements:
          # Create a new attribute 'entityName' with the value of 'id'
          - set(attributes["entityName"], attributes["id"]) where attributes["id"] != nil
          # Create a new attribute 'instanceName' with the value of 'name'
          - set(attributes["instanceName"], attributes["name"]) where attributes["name"] != nil

      - context: datapoint
        conditions:
          - IsMatch(metric.name, ".*\.agent\..*")
        statements:
          - set(attributes["entityName"], attributes["host.id"]) where attributes["host.id"] != nil
          - set(attributes["instanceName"], attributes["service.name"]) where attributes["service.name"] != nil
          - set(attributes["entityTypeId"], "agent")

      - context: datapoint
        statements:
          # Mapping entityTypeId based on metric names and attributes
          - set(attributes["entityTypeId"], "connector") where IsMatch(metric.name, ".*\.connector\..*")
          - set(attributes["entityTypeId"], "host") where IsMatch(metric.name, ".*\.host\..*") or attributes["hw.type"] == "host"
          - set(attributes["entityTypeId"], "battery") where IsMatch(metric.name, "hw\.battery\..*") or attributes["hw.type"] == "battery"
          - set(attributes["entityTypeId"], "blade") where IsMatch(metric.name, "hw\.blade\..*") or attributes["hw.type"] == "blade"
          - set(attributes["entityTypeId"], "cpu") where IsMatch(metric.name, "hw\.cpu\..*") or attributes["hw.type"] == "cpu"
          - set(attributes["entityTypeId"], "disk_controller") where IsMatch(metric.name, "hw\.disk_controller\..*") or attributes["hw.type"] == "disk_controller"
          - set(attributes["entityTypeId"], "enclosure") where IsMatch(metric.name, "hw\.enclosure\..*") or attributes["hw.type"] == "enclosure"
          - set(attributes["entityTypeId"], "fan") where IsMatch(metric.name, "hw\.fan\..*") or attributes["hw.type"] == "fan"
          - set(attributes["entityTypeId"], "gpu") where IsMatch(metric.name, "hw\.gpu\..*") or attributes["hw.type"] == "gpu"
          - set(attributes["entityTypeId"], "led") where IsMatch(metric.name, "hw\.led\..*") or attributes["hw.type"] == "led"
          - set(attributes["entityTypeId"], "logical_disk") where IsMatch(metric.name, "hw\.logical_disk\..*") or attributes["hw.type"] == "logical_disk"
          - set(attributes["entityTypeId"], "lun") where IsMatch(metric.name, "hw\.lun\..*") or attributes["hw.type"] == "lun"
          - set(attributes["entityTypeId"], "memory") where IsMatch(metric.name, "hw\.memory\..*") or attributes["hw.type"] == "memory"
          - set(attributes["entityTypeId"], "network") where IsMatch(metric.name, "hw\.network\..*") or attributes["hw.type"] == "network"
          - set(attributes["entityTypeId"], "other_device") where IsMatch(metric.name, "hw\.other_device\..*") or attributes["hw.type"] == "other_device"
          - set(attributes["entityTypeId"], "physical_disk") where IsMatch(metric.name, "hw\.physical_disk\..*") or attributes["hw.type"] == "physical_disk"
          - set(attributes["entityTypeId"], "power_supply") where IsMatch(metric.name, "hw\.power_supply\..*") or attributes["hw.type"] == "power_supply"
          - set(attributes["entityTypeId"], "robotics") where IsMatch(metric.name, "hw\.robotics\..*") or attributes["hw.type"] == "robotics"
          - set(attributes["entityTypeId"], "tape_drive") where IsMatch(metric.name, "hw\.tape_drive\..*") or attributes["hw.type"] == "tape_drive"
          - set(attributes["entityTypeId"], "temperature") where IsMatch(metric.name, "hw\.temperature.*") or attributes["hw.type"] == "temperature"
          - set(attributes["entityTypeId"], "vm") where IsMatch(metric.name, "hw\.vm\..*") or attributes["hw.type"] == "vm"
          - set(attributes["entityTypeId"], "voltage") where IsMatch(metric.name, "hw\.voltage.*") or attributes["hw.type"] == "voltage"

----------------------------------------

TITLE: Creating Kubernetes Deployment for OpenTelemetry Collector
DESCRIPTION: YAML configuration to create a Kubernetes Deployment for the OpenTelemetry Collector with the Kubernetes Objects Receiver.

LANGUAGE: yaml
CODE:
apiVersion: apps/v1
kind: Deployment
metadata:
  name: otelcontribcol
  labels:
    app: otelcontribcol
spec:
  replicas: 1
  selector:
    matchLabels:
      app: otelcontribcol
  template:
    metadata:
      labels:
        app: otelcontribcol
    spec:
      serviceAccountName: otelcontribcol
      containers:
      - name: otelcontribcol
        image: otelcontribcol:latest
        args: ["--config", "/etc/config/config.yaml"]
        volumeMounts:
        - name: config
          mountPath: /etc/config
        imagePullPolicy: IfNotPresent
      volumes:
        - name: config
          configMap:
            name: otelcontribcol

----------------------------------------

TITLE: Configuring Azure Monitor Receiver with Dimension Overrides
DESCRIPTION: Example configuration for the Azure Monitor Receiver with dimension overrides for specific metrics. It demonstrates how to limit dimensions for a particular metric in the Microsoft.Network/azureFirewalls namespace.

LANGUAGE: yaml
CODE:
receivers:
  azuremonitor:
    dimensions:
      enabled: true
      overrides:
        "Microsoft.Network/azureFirewalls":
          "NetworkRuleHit": [Reason, Status]

----------------------------------------

TITLE: Parsing CRI-O Container Log with Automatic Format Detection
DESCRIPTION: This example demonstrates parsing a CRI-O container log using automatic format detection.

LANGUAGE: yaml
CODE:
- type: container

----------------------------------------

TITLE: Renaming Metric with Regular Expression in YAML
DESCRIPTION: Example of renaming multiple metrics using regular expression substitution in the Metrics Transform Processor.

LANGUAGE: yaml
CODE:
include: ^system\.cpu\.(.*$$)
match_type: regexp
action: update
new_name: system.processor.$${1}.stat

----------------------------------------

TITLE: Parsing Timestamps from JSON Logs
DESCRIPTION: This configuration example demonstrates how to parse timestamps from JSON logs. It uses a json_parser to parse the log body and a time_parser to extract and parse the timestamp field.

LANGUAGE: yaml
CODE:
exporters:
  debug:
    verbosity: detailed
receivers:
  filelog:
    include:
    - logs-json.log
    start_at: beginning
    operators:
    - type: json_parser
      parse_to: body
    - type: time_parser
      parse_from: body.time
      layout: '%Y-%m-%dT%H:%M:%S.%LZ'
service:
  pipelines:
    logs:
      receivers:
      - filelog
      exporters:
      - debug

----------------------------------------

TITLE: Parsing CSV with Basic Header Configuration
DESCRIPTION: Basic example of parsing a CSV string using a predefined header configuration. Demonstrates transformation of a comma-separated string into structured JSON fields.

LANGUAGE: yaml
CODE:
- type: csv_parser
  header: id,severity,message

LANGUAGE: json
CODE:
{
  "body": "1,debug,Debug Message"
}

LANGUAGE: json
CODE:
{
  "body": {
    "id": "1",
    "severity": "debug",
    "message": "Debug Message"
  }
}

----------------------------------------

TITLE: Configuring Metric Enablement in YAML
DESCRIPTION: Example YAML configuration to enable or disable specific metrics in the sshcheck component. This snippet demonstrates how to toggle individual metrics on or off.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Enabling Optional CPU Metrics in YAML Configuration
DESCRIPTION: YAML configuration snippet to enable an optional CPU metric in the OpenTelemetry Collector. Replace <metric_name> with the specific metric to enable.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: true

----------------------------------------

TITLE: Configuring JSON Array Parser to Parse Body
DESCRIPTION: YAML configuration for parsing the 'body' field containing a JSON array directly into the 'body' field, along with input and output examples.

LANGUAGE: yaml
CODE:
- type: json_array_parser
  parse_to: body

LANGUAGE: json
CODE:
{
  "body": "[1,\"debug\",\"Debug Message\", true]"
}

LANGUAGE: json
CODE:
{
  "body": [1, "debug", "Debug Message", true]
}

----------------------------------------

TITLE: Configuring TCP Input Operator in YAML
DESCRIPTION: A simple YAML configuration for the tcp_input operator, setting up a listener on all interfaces on port 54525.

LANGUAGE: yaml
CODE:
- type: tcp_input
  listen_address: "0.0.0.0:54525"

----------------------------------------

TITLE: Adding a Value to Attributes in YAML Configuration
DESCRIPTION: This snippet shows how to add a value to the attributes of an entry using YAML configuration. It adds a new key-value pair to the attributes.

LANGUAGE: yaml
CODE:
- type: add
  field: attributes.key2
  value: val2

----------------------------------------

TITLE: Configuring Metrics Transform Processor in YAML
DESCRIPTION: Basic YAML configuration structure for the Metrics Transform Processor, including transformation options and operations.

LANGUAGE: yaml
CODE:
processors:
  metricstransform:
    transforms:
      - include: <metric_name>
        match_type: {strict, regexp}
        experimental_match_labels: {<label1>: <label_value1>, <label2>: <label_value2>}
        action: {update, insert, combine}
        new_name: <new_metric_name_inserted>
        aggregation_type: {sum, mean, min, max, count, median}
        submatch_case: {lower, upper}
        operations:
          - action: {add_label, update_label, delete_label_value, toggle_scalar_data_type, experimental_scale_value, aggregate_labels, aggregate_label_values}
            label: <label>
            new_label: <new_label>
            aggregated_values: [values...]
            new_value: <new_value>
            label_value: <label_value>
            label_set: [labels...]
            aggregation_type: {sum, mean, min, max, count, median}
            experimental_scale: <scalar>
            value_actions:
              - value: <current_label_value>
                new_value: <new_label_value>

----------------------------------------

TITLE: Representing Entry Structure in JSON Format
DESCRIPTION: This JSON snippet demonstrates the structure of an Entry object, including resource information, attributes, body content, timestamp, severity, and severity text. It serves as an example of how log data is represented in the pipeline.

LANGUAGE: json
CODE:
{
  "resource": {
    "uuid": "11112222-3333-4444-5555-666677778888"
  },
  "attributes": {
    "env": "prod"
  },
  "body": {
    "message": "Something happened.",
    "details": {
      "count": 100,
      "reason": "event"
    }
  },
  "timestamp": "2020-01-31T00:00:00-00:00",
  "severity": 30,
  "severity_text": "INFO"
}

----------------------------------------

TITLE: Parsing JSON Array String Examples
DESCRIPTION: Examples of JSON array strings and their parsed results, including simple arrays, complex arrays with different types, and arrays with nested objects.

LANGUAGE: json
CODE:
["Foo", "Bar", "Charlie"]

LANGUAGE: json
CODE:
["Hello", 42, true, null]

LANGUAGE: json
CODE:
["Hello", 42, {"name": "Alice", "age": 25}, [1, 2, 3], true, null]

LANGUAGE: json
CODE:
["Hello", 42, "{\"name\": \"Alice\", \"age\": 25}", "[1, 2, 3]", true, null]

----------------------------------------

TITLE: Debugging Configuration for Metrics Filtering
DESCRIPTION: Example YAML configuration for filtering problematic metrics and enabling detailed debug output.

LANGUAGE: yaml
CODE:
processors:
  filter:
    error_mode: ignore
    metrics:
      - name != "problematic.metric.name"
exporters:
  debug:
    verbosity: detailed

----------------------------------------

TITLE: Enabling Optional Process Metrics in YAML
DESCRIPTION: Configuration example for enabling optional process metrics that are disabled by default.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: true

----------------------------------------

TITLE: Filtering Entries Using Environment Variable in YAML
DESCRIPTION: This configuration illustrates how to use an environment variable in the filter expression to determine which entries to drop.

LANGUAGE: yaml
CODE:
- type: filter
  expr: 'body.message == env("MY_ENV_VARIABLE")'
  output: my_output

----------------------------------------

TITLE: Deploying OpenTelemetry Collectors and RBAC Resources in Kubernetes
DESCRIPTION: This multi-resource YAML configuration creates a namespace, RBAC resources, and two OpenTelemetryCollector instances: a load balancer and multiple backends. It sets up the necessary permissions and configurations for trace ID aware load balancing.

LANGUAGE: yaml
CODE:
apiVersion: v1
kind: Namespace
metadata:
  name: observability
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: loadbalancer-role
  namespace: observability
rules:
- apiGroups:
  - ""
  resources:
  - endpoints
  verbs:
  - list
  - watch
  - get
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: loadbalancer
  namespace: observability
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: loadbalancer-rolebinding
  namespace: observability
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: loadbalancer-role
subjects:
- kind: ServiceAccount
  name: loadbalancer
  namespace: observability
---
apiVersion: opentelemetry.io/v1alpha1
kind: OpenTelemetryCollector
metadata:
  name: loadbalancer
  namespace: observability
spec:
  image: docker.io/otel/opentelemetry-collector-contrib:latest
  serviceAccount: loadbalancer
  config: |
    receivers:
      otlp:
        protocols:
          grpc:

    processors:

    exporters:
      loadbalancing:
        protocol:
          otlp:
            tls:
              insecure: true
        resolver:
          k8s:
            service: backends-collector-headless.observability

    service:
      pipelines:
        traces:
          receivers:
            - otlp
          processors: []
          exporters:
            - loadbalancing
---
apiVersion: opentelemetry.io/v1alpha1
kind: OpenTelemetryCollector
metadata:
  name: backends
  namespace: observability
spec:
  replicas: 5
  config: |
    receivers:
      otlp:
        protocols:
          grpc:

    processors:

    exporters:
      debug:

    service:
      pipelines:
        traces:
          receivers:
            - otlp
          processors: []
          exporters:
            - debug

----------------------------------------

TITLE: TLS Configuration Example
DESCRIPTION: Example showing how to configure TLS settings for secure connections.

LANGUAGE: yaml
CODE:
exporters:
  signalfx:
    ingest_tls:
      ca_file: "/etc/opt/certs/ca.pem"
    api_tls:
      ca_file: "/etc/opt/certs/ca.pem"

----------------------------------------

TITLE: Configuring Jaeger Remote Sampling Extension in YAML
DESCRIPTION: Example YAML configuration for the Jaeger Remote Sampling extension, demonstrating remote and file-based sources with reload intervals.

LANGUAGE: yaml
CODE:
extensions:
  jaegerremotesampling:
    source:
      reload_interval: 30s
      remote:
        endpoint: jaeger-collector:14250
  jaegerremotesampling/1:
    source:
      reload_interval: 1s
      file: /etc/otelcol/sampling_strategies.json
  jaegerremotesampling/2:
    source:
      reload_interval: 1s
      file: http://jaeger.example.com/sampling_strategies.json

----------------------------------------

TITLE: Markdown Documentation for OpenTelemetry Instrumentation Scope Paths
DESCRIPTION: Table of supported paths for accessing instrumentation scope data, including field names, descriptions, and data types. The documentation covers cache, resource attributes, scope attributes, and other scope-related fields.

LANGUAGE: markdown
CODE:
| path                              | field accessed                                                                                                                                     | type                                                                    |
|-----------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------|
| scope.cache                       | the value of the current transform context's temporary cache. cache can be used as a temporary placeholder for data during complex transformations | pcommon.Map                                                             |
| scope.cache[""]                 | the value of an item in cache. Supports multiple indexes to access nested fields.                                                                  | string, bool, int64, float64, pcommon.Map, pcommon.Slice, []byte or nil |
| resource                          | resource of the instrumentation scope being processed                                                                                              | pcommon.Resource                                                        |
| resource.attributes               | resource attributes of the instrumentation scope being processed                                                                                   | pcommon.Map                                                             |
| resource.attributes[""]         | the value of the resource attribute of the instrumentation scope being processed. Supports multiple indexes to access nested fields.               | string, bool, int64, float64, pcommon.Map, pcommon.Slice, []byte or nil |
| resource.dropped_attributes_count | number of dropped attributes of the resource of the instrumentation scope being processed                                                          | int64                                                                   |
| scope.name                        | name of the instrumentation scope of the scope being processed                                                                                     | string                                                                  |
| scope.version                     | version of the instrumentation scope of the scope being processed                                                                                  | string                                                                  |
| scope.dropped_attributes_count    | number of dropped attributes of the instrumentation scope of the scope being processed                                                             | int64                                                                   |
| scope.attributes                  | instrumentation scope attributes of the scope being processed                                                                                      | pcommon.Map                                                             |
| scope.attributes[""]            | the value of the instrumentation scope attribute of the scope being processed. Supports multiple indexes to access nested fields.                  | string, bool, int64, float64, pcommon.Map, pcommon.Slice, []byte or nil |

----------------------------------------

TITLE: Configuring UDP Syslog Receiver in OpenTelemetry
DESCRIPTION: Basic configuration for receiving RFC3164 format syslogs over UDP connection on port 54526 with UTC timezone setting.

LANGUAGE: yaml
CODE:
receivers:
  syslog:
    udp:
      listen_address: "0.0.0.0:54526"
    protocol: rfc3164
    location: UTC

----------------------------------------

TITLE: Advanced Round-Robin Pipeline Configuration in YAML
DESCRIPTION: Shows complete pipeline configuration with preprocessing steps using resource detection and batch processing before load balancing across multiple Prometheus remote write exporters.

LANGUAGE: yaml
CODE:
receivers:
  otlp:
processors:
  resourcedetection:
  batch:
exporters:
  prometheusremotewrite/1:
  prometheusremotewrite/2:
connectors:
  roundrobin:
service:
  pipelines:
    metrics:
      receivers: [otlp]
      processors: [resourcedetection, batch]
      exporters: [roundrobin]
    metrics/1:
      receivers: [roundrobin]
      exporters: [prometheusremotewrite/1]
    metrics/2:
      receivers: [roundrobin]
      exporters: [prometheusremotewrite/2]

----------------------------------------

TITLE: Configuring UDP Syslog Input in YAML
DESCRIPTION: This snippet shows a simple configuration for the syslog_input operator using UDP. It sets the listen address, specifies the syslog protocol as RFC3164, and sets the location to UTC.

LANGUAGE: yaml
CODE:
- type: syslog_input
  udp:
     listen_address: "0.0.0.0:54526"
  syslog:
     protocol: rfc3164
     location: UTC

----------------------------------------

TITLE: Configuring Read-Only Endpoint Access for Kubelet Stats
DESCRIPTION: Example showing how to configure the receiver to collect metrics from the read-only kubelet endpoint on port 10255.

LANGUAGE: yaml
CODE:
receivers:
  kubeletstats:
    collection_interval: 20s
    auth_type: "none"
    endpoint: "http://${env:K8S_NODE_NAME}:10255"
exporters:
  file:
    path: "fileexporter.txt"
service:
  pipelines:
    metrics:
      receivers: [kubeletstats]
      exporters: [file]

----------------------------------------

TITLE: Running OpAMP Supervisor - Shell Command
DESCRIPTION: Command to run the supervisor with OS-specific configuration file.

LANGUAGE: shell
CODE:
cd cmd/opampsupervisor
go run . --config examples/supervisor_<OS>.yaml

----------------------------------------

TITLE: HTTP Status Endpoint Response in JSON
DESCRIPTION: Example JSON response from the HTTP status endpoint, showing detailed collector health information including overall status and individual component statuses.

LANGUAGE: json
CODE:
{
    "start_time": "2024-01-18T17:27:12.570394-08:00",
    "healthy": true,
    "status": "StatusRecoverableError",
    "error": "rpc error: code = ResourceExhausted desc = resource exhausted",
    "status_time": "2024-01-18T17:27:32.572301-08:00",
    "components": {
        "extensions": {
            "healthy": true,
            "status": "StatusOK",
            "status_time": "2024-01-18T17:27:12.570428-08:00",
            "components": {
                "extension:healthcheckv2": {
                    "healthy": true,
                    "status": "StatusOK",
                    "status_time": "2024-01-18T17:27:12.570428-08:00"
                }
            }
        },
        "pipeline:metrics/grpc": {
            "healthy": true,
            "status": "StatusRecoverableError",
            "error": "rpc error: code = ResourceExhausted desc = resource exhausted",
            "status_time": "2024-01-18T17:27:32.572301-08:00",
            "components": {
                "exporter:otlp/staging": {
                    "healthy": true,
                    "status": "StatusRecoverableError",
                    "error": "rpc error: code = ResourceExhausted desc = resource exhausted",
                    "status_time": "2024-01-18T17:27:32.572301-08:00"
                },
                "processor:batch": {
                    "healthy": true,
                    "status": "StatusOK",
                    "status_time": "2024-01-18T17:27:12.571132-08:00"
                },
                "receiver:otlp": {
                    "healthy": true,
                    "status": "StatusOK",
                    "status_time": "2024-01-18T17:27:12.571576-08:00"
                }
            }
        },
        "pipeline:traces/http": {
            "healthy": true,
            "status": "StatusOK",
            "status_time": "2024-01-18T17:27:12.571625-08:00",
            "components": {
                "exporter:otlphttp/staging": {
                    "healthy": true,
                    "status": "StatusOK",
                    "status_time": "2024-01-18T17:27:12.571615-08:00"
                },
                "processor:batch": {
                    "healthy": true,
                    "status": "StatusOK",
                    "status_time": "2024-01-18T17:27:12.571621-08:00"
                },
                "receiver:otlp": {
                    "healthy": true,
                    "status": "StatusOK",
                    "status_time": "2024-01-18T17:27:12.571625-08:00"
                }
            }
        }
    }
}

----------------------------------------

TITLE: Defining X-Ray Trace Structure in JSON
DESCRIPTION: This JSON structure defines an X-Ray trace for a server request. It includes trace identifiers, timing information, HTTP request and response details, and service metadata. The structure is designed to capture key aspects of a server interaction for tracing and analysis purposes.

LANGUAGE: json
CODE:
{
    "trace_id": "1-5f2aebcc-b475d14618c51eaa28753d37",
    "id": "bda182a644eee9b3",
    "name": "SampleServer",
    "start_time": 1596648396.6399446,
    "end_time": 1596648396.6401389,
    "http": {
        "request": {
            "method": "GET",
            "url": "http://localhost:8000/",
            "client_ip": "127.0.0.1",
            "user_agent": "Go-http-client/1.1",
            "x_forwarded_for": true
        },
        "response": {
            "status": 200
        }
    },
    "service": {
        "compiler_version": "go1.14.6",
        "compiler": "gc"
    },
    "Dummy": false
}

----------------------------------------

TITLE: Input/Output JSON Examples for ANSI Code Removal
DESCRIPTION: Example JSON showing the removal of ANSI escape codes from text.

LANGUAGE: json
CODE:
{
  "resource": { },
  "attributes": { },
  "body": "\x1b[31mred\x1b[0m"
}

----------------------------------------

TITLE: Configuring Apache Spark Receiver in YAML
DESCRIPTION: Example configuration for the Apache Spark Receiver, specifying collection interval, endpoint, and application names to monitor.

LANGUAGE: yaml
CODE:
receivers:
  apachespark:
    collection_interval: 60s
    endpoint: http://localhost:4040
    application_names:
    - PythonStatusAPIDemo
    - PythonLR

----------------------------------------

TITLE: Log Count with Attributes Configuration
DESCRIPTION: Configuration example demonstrating how to count logs with custom attributes and default values.

LANGUAGE: yaml
CODE:
receivers:
  foo:
exporters:
  bar:
connectors:
  count:
    logs:
      my.log.count:
        description: The number of logs from each environment.
        attributes:
          - key: env
            default_value: unspecified_environment

----------------------------------------

TITLE: Configuring TCP Syslog Input in YAML
DESCRIPTION: This snippet demonstrates a simple configuration for the syslog_input operator using TCP. It specifies the listen address and sets the syslog protocol to RFC5424.

LANGUAGE: yaml
CODE:
- type: syslog_input
  tcp:
     listen_address: "0.0.0.0:54526"
  syslog:
     protocol: rfc5424

----------------------------------------

TITLE: Filtering Entries by Label Value in YAML
DESCRIPTION: This example shows how to set up the filter operator to drop entries based on a specific label value, in this case, the 'env' attribute.

LANGUAGE: yaml
CODE:
- type: filter
  expr: 'attributes.env == "production"'
  output: my_output

----------------------------------------

TITLE: OpAMP Supervisor Storage Configuration - YAML
DESCRIPTION: YAML configuration for specifying the persistent storage directory used by the supervisor to maintain state between restarts.

LANGUAGE: yaml
CODE:
storage:
  directory: "/path/to/storage/dir"

----------------------------------------

TITLE: Simple Journald Input Configuration
DESCRIPTION: Basic configuration example with default settings.

LANGUAGE: yaml
CODE:
- type: journald_input

----------------------------------------

TITLE: Removing a Value from Resource using YAML Configuration
DESCRIPTION: This example illustrates how to remove a specific resource field from the record using the 'remove' operator.

LANGUAGE: yaml
CODE:
- type: remove
  field: resource.otherkey

----------------------------------------

TITLE: Enabling Optional Metrics in YAML
DESCRIPTION: YAML configuration example for enabling optional metrics that are not emitted by default in the sshcheck component. This configuration allows users to activate additional metrics as needed.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: true

----------------------------------------

TITLE: Disabling Default PostgreSQL Metrics in YAML Configuration
DESCRIPTION: Shows how to disable a default metric using YAML configuration. This can be applied to any of the default metrics listed in the document.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Configuring Google Managed Prometheus Exporter in YAML
DESCRIPTION: Example YAML configuration for setting up the Google Managed Prometheus Exporter with receivers, processors, and exporters.

LANGUAGE: yaml
CODE:
receivers:
    prometheus:
        config:
          scrape_configs:
            # Add your prometheus scrape configuration here.
            # Using kubernetes_sd_configs with namespaced resources (e.g. pod)
            # ensures the namespace is set on your metrics.
            - job_name: 'kubernetes-pods'
                kubernetes_sd_configs:
                - role: pod
                relabel_configs:
                - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
                action: keep
                regex: true
                - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
                action: replace
                target_label: __metrics_path__
                regex: (.+)
                - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
                action: replace
                regex: (.+):(?:\d+);(\d+)
                replacement: $$1:$$2
                target_label: __address__
                - action: labelmap
                regex: __meta_kubernetes_pod_label_(.+)
processors:
    batch:
        # batch metrics before sending to reduce API usage
        send_batch_max_size: 200
        send_batch_size: 200
        timeout: 5s
    memory_limiter:
        # drop metrics if memory usage gets too high
        check_interval: 1s
        limit_percentage: 65
        spike_limit_percentage: 20
    resourcedetection:
        # detect cluster name and location
        detectors: [gcp]
        timeout: 10s
    transform:
      # "location", "cluster", "namespace", "job", "instance", and "project_id" are reserved, and 
      # metrics containing these labels will be rejected.  Prefix them with exported_ to prevent this.
      metric_statements:
      - context: datapoint
        statements:
        - set(attributes["exported_location"], attributes["location"])
        - delete_key(attributes, "location")
        - set(attributes["exported_cluster"], attributes["cluster"])
        - delete_key(attributes, "cluster")
        - set(attributes["exported_namespace"], attributes["namespace"])
        - delete_key(attributes, "namespace")
        - set(attributes["exported_job"], attributes["job"])
        - delete_key(attributes, "job")
        - set(attributes["exported_instance"], attributes["instance"])
        - delete_key(attributes, "instance")
        - set(attributes["exported_project_id"], attributes["project_id"])
        - delete_key(attributes, "project_id")

exporters:
    googlemanagedprometheus:

service:
  pipelines:
    metrics:
      receivers: [prometheus]
      processors: [memory_limiter, batch, transform, resourcedetection]
      exporters: [googlemanagedprometheus]

----------------------------------------

TITLE: Disabling Metrics Configuration in YAML
DESCRIPTION: This YAML configuration snippet demonstrates how to disable specific metrics in the system. The <metric_name> placeholder should be replaced with the actual metric name to be disabled.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Configuring Detailed Sum Connector in YAML
DESCRIPTION: This snippet shows a more detailed configuration for the Sum Connector. It processes logs, creates a 'checkout.total' metric, includes a condition check, and specifies attribute handling for 'payment.processor'.

LANGUAGE: yaml
CODE:
receivers:
  foo:
connectors:
  sum:
    logs:
      checkout.total:
        source_attribute: total.payment
        conditions:
          - attributes["total.payment"] != "NULL"
        attributes:
          - key: payment.processor
            default_value: unspecified_processor
exporters:
  bar:

service:
  pipelines:
    metrics/sum:
       receivers: [sum]
       exporters: [bar]
    logs:
       receivers: [foo]
       exporters: [sum]

----------------------------------------

TITLE: Executing Stanza with stdin Input in Bash
DESCRIPTION: A bash command demonstrating how to pipe input to the Stanza tool using the stdin operator configuration.

LANGUAGE: bash
CODE:
echo "test" | stanza -c ./config.yaml

----------------------------------------

TITLE: Configuring MongoDB Metrics Collection
DESCRIPTION: Configuration to disable specific metrics collection in MongoDB monitoring using YAML format. This shows the basic structure for enabling/disabling individual metrics.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Configuring Zstd Compression for Coralogix Exporter
DESCRIPTION: Example of configuring zstd compression for the Coralogix exporter instead of the default gzip compression.

LANGUAGE: yaml
CODE:
exporters:
  coralogix:
    domain_settings:
      compression: "zstd"

----------------------------------------

TITLE: Configuring Database Storage Extension with SQLite in YAML
DESCRIPTION: Example configuration for the Database Storage extension using SQLite driver with custom options for busy timeout, journal mode, and synchronous mode.

LANGUAGE: yaml
CODE:
extensions:
  db_storage:
    driver: "sqlite"
    datasource: "file:///path/to/foo.db?_pragma=busy_timeout(10000)&_pragma=journal_mode(WAL)&_pragma=synchronous(NORMAL)"

service:
  extensions: [db_storage]
  pipelines:
    traces:
      receivers: [nop]
      exporters: [nop]

# Data pipeline is required to load the config.
receivers:
  nop:
exporters:
  nop:

----------------------------------------

TITLE: Configuring Database Storage Extension with SQLite in YAML
DESCRIPTION: Example configuration for the Database Storage extension using SQLite driver with custom options for busy timeout, journal mode, and synchronous mode.

LANGUAGE: yaml
CODE:
extensions:
  db_storage:
    driver: "sqlite"
    datasource: "file:///path/to/foo.db?_pragma=busy_timeout(10000)&_pragma=journal_mode(WAL)&_pragma=synchronous(NORMAL)"

service:
  extensions: [db_storage]
  pipelines:
    traces:
      receivers: [nop]
      exporters: [nop]

# Data pipeline is required to load the config.
receivers:
  nop:
exporters:
  nop:

----------------------------------------

TITLE: Configuring Retain Operator for Body Fields in YAML
DESCRIPTION: This snippet demonstrates how to configure the Retain operator to keep specific fields in the body of a log entry. It retains 'key1' and 'key2' from the body, removing all other fields.

LANGUAGE: yaml
CODE:
- type: retain
  fields:
    - body.key1
    - body.key2

----------------------------------------

TITLE: Grouping Metrics by Resource Labels in YAML
DESCRIPTION: Example of grouping Kubernetes pod and container metrics into separate ResourceMetrics using the Metrics Transform Processor.

LANGUAGE: yaml
CODE:
- include: ^k8s\.pod\.(.*$$)
  match_type: regexp
  action: group
  group_resource_labels: {"resource.type": "k8s.pod", "source": "kubelet"}
- include: ^container\.(.*$$)
  match_type: regexp
  action: group
  group_resource_labels: {"resource.type": "container", "source": "kubelet"}

----------------------------------------

TITLE: Copying Value from Body to Resource in YAML
DESCRIPTION: This snippet demonstrates how to configure the 'copy' operator to copy a value from the body to the resource field.

LANGUAGE: yaml
CODE:
- type: copy
  from: body.key
  to: resource.newkey

----------------------------------------

TITLE: Configuring Grafana Cloud Connector in YAML
DESCRIPTION: Example configuration for the Grafana Cloud Connector showing how to set up host identifiers and metrics flush interval. The connector generates host info metrics based on resource attributes from spans. Flush intervals must be between 15 seconds and 5 minutes.

LANGUAGE: yaml
CODE:
connectors:
  grafanacloud:
    host_identifiers: ["host.id"]
    metrics_flush_interval: 60s

----------------------------------------

TITLE: Configuring stdout Operator in YAML
DESCRIPTION: This snippet demonstrates a simple configuration for the stdout operator. It shows how to define the operator with a custom identifier.

LANGUAGE: yaml
CODE:
- id: my_stdout
  type: stdout

----------------------------------------

TITLE: Configuring Group by Attributes Processor in YAML
DESCRIPTION: Basic YAML configuration example showing how to specify attribute keys for grouping telemetry data.

LANGUAGE: yaml
CODE:
processors:
  groupbyattrs:
    keys:
      - host.name

----------------------------------------

TITLE: Grouping Metrics by Attributes in YAML Configuration
DESCRIPTION: Example YAML configuration for using the groupbyattrs processor to promote metric labels to resource labels.

LANGUAGE: yaml
CODE:
processors:
  groupbyattrs:
    keys:
    - namespace
    - cluster
    - location

----------------------------------------

TITLE: Setting Loki Format Hint
DESCRIPTION: YAML configuration for setting the log format hint for the Loki exporter using a resource processor.

LANGUAGE: yaml
CODE:
processors:
  resource:
    attributes:
    - action: insert
      key: loki.format
      value: logfmt

----------------------------------------

TITLE: Configuring OTLP Encoding Extension with JSON Protocol in YAML
DESCRIPTION: This snippet shows the configuration for the OTLP encoding extension using the JSON protocol in the collector's YAML configuration.

LANGUAGE: yaml
CODE:
extensions:
  otlp_encoding:
    protocol: otlp_json

----------------------------------------

TITLE: Basic Severity Mapping Configuration in YAML
DESCRIPTION: Example showing how to configure basic severity mapping with single values, lists, ranges and special HTTP status codes.

LANGUAGE: yaml
CODE:
mapping:
  error: oops
  warn:
    - hey!
    - YSK
  info:
    - min: 300
      max: 399
  debug: 2xx
  info3: medium
  fatal:
    - really serious
    - min: 9001
      max: 9050
    - 5xx

----------------------------------------

TITLE: Configuring Cloudflare Receiver with Custom Attributes
DESCRIPTION: Example configuration for Cloudflare receiver with TLS settings, endpoint specification, secret key, timestamp field, and custom attribute mapping for specific log fields.

LANGUAGE: yaml
CODE:
receivers:
  cloudflare:
    logs:
      tls:
        key_file: some_key_file
        cert_file: some_cert_file
      endpoint: 0.0.0.0:12345
      secret: 1234567890abcdef1234567890abcdef
      timestamp_field: EdgeStartTimestamp
      attributes:
        ClientIP: http_request.client_ip
        ClientRequestURI: http_request.uri

----------------------------------------

TITLE: Configuring Signal to Metrics Connector in YAML
DESCRIPTION: Example configuration for producing delta temporality counters from spans, datapoints, and logs.

LANGUAGE: yaml
CODE:
signaltometrics:
  spans:
    - name: span.count
      description: Count of spans
      sum:
        value: Int(AdjustedCount()) # Count of total spans represented by each span
  datapoints:
    - name: datapoint.count
      description: Count of datapoints
      sum:
        value: "1" # increment by 1 for each datapoint
  logs:
    - name: logrecord.count
      description: Count of log records
      sum:
        value: "1" # increment by 1 for each log record

----------------------------------------

TITLE: Disabling Default Snowflake Metrics in YAML Configuration
DESCRIPTION: Example YAML configuration to disable a default Snowflake metric. This can be applied to any of the default metrics listed in the document.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Configuring TLS Check Receiver in YAML
DESCRIPTION: Example configuration for the TLS Check Receiver, specifying multiple targets with custom dialer timeouts.

LANGUAGE: yaml
CODE:
receivers:
  tlscheck:
    targets:
      - endpoint: example.com:443
        dialer: 
          timeout: 15s
      - endpoint: foobar.com:8080
        dialer: 
          timeout: 15s
      - endpoint: localhost:10901

----------------------------------------

TITLE: Configuring Log Collection with Receiver Creator
DESCRIPTION: Example showing how to configure log collection from containers using the receiver creator and filelog receiver.

LANGUAGE: yaml
CODE:
receiver_creator/logs:
  watch_observers: [ k8s_observer ]
  receivers:
    filelog/busybox:
      rule: type == "pod.container" && container_name == "busybox"
      config:
        include:
          - /var/log/pods/`pod.namespace`_`pod.name`_`pod.uid`/`container_name`/*.log
        operators:
          - id: container-parser
            type: container

----------------------------------------

TITLE: Removing a Value from Attributes using YAML Configuration
DESCRIPTION: This configuration demonstrates how to remove a specific attribute from the record using the 'remove' operator.

LANGUAGE: yaml
CODE:
- type: remove
  field: attributes.otherkey

----------------------------------------

TITLE: Example CES Metric JSON Representation
DESCRIPTION: JSON representation of CES metrics before conversion to OpenTelemetry format. Includes multiple metrics with their respective units, datapoints, and dimensions.

LANGUAGE: json
CODE:
[
    {
      "unit": "%",
      "datapoints": [
        { "average": 10, "timestamp": 1722580500000 },
        { "average": 20, "timestamp": 1722580800000 }
      ],
      "namespace": "SYS.ECS",
      "metric_name": "cpu_util",
      "dimensions": [
        {
          "name": "instance_id",
          "value": "faea5b75-e390-4e2b-8733-9226a9026070"
        }
      ]
    },
    {
      "unit": "%",
      "datapoints": [
        { "average": 30, "timestamp": 1722580500000 },
        { "average": 40, "timestamp": 1722580800000 }
      ],
      "namespace": "SYS.ECS",
      "metric_name": "mem_util",
      "dimensions": [
        {
          "name": "instance_id",
          "value": "abcea5b75-e390-4e2b-8733-9226a9026070"
        }
      ]
    },
    {
      "unit": "bit/s",
      "datapoints": [
        { "average": 1024, "timestamp": 1722580500000},
        { "average": 2048, "timestamp": 1722580800000}
      ],
      "namespace": "SYS.VPC",
      "metric_name": "upstream_bandwidth_usage",
      "dimensions": [
        {
          "name": "publicip_id",
          "value": "test-baae-4dd9-ad3f-1234"
        }
      ]
    }
]

----------------------------------------

TITLE: Configuring Key Value Parser in YAML
DESCRIPTION: Example YAML configuration for parsing the 'message' field into key-value pairs using the key_value_parser operator.

LANGUAGE: yaml
CODE:
- type: key_value_parser
  parse_from: message

----------------------------------------

TITLE: Copying Value from Body to Attributes in YAML
DESCRIPTION: This snippet shows the configuration for copying a value from the body to the attributes field using the 'copy' operator.

LANGUAGE: yaml
CODE:
- type: copy
  from: body.key2
  to: attributes.newkey

----------------------------------------

TITLE: Unregistering Custom Capability Handler in Go
DESCRIPTION: Shows how to properly unregister a custom capability handler when it's no longer needed.

LANGUAGE: go
CODE:
handler.Unregister()

----------------------------------------

TITLE: Filtering Logs Using Pattern Matching
DESCRIPTION: Example showing how to filter log entries using pattern matching. Only forwards entries that match the specified regular expression pattern.

LANGUAGE: yaml
CODE:
- type: router
  routes:
    - output: my_output
      expr: 'body.message matches "^LOG: .* END$"'

----------------------------------------

TITLE: Routing with Default Handler Configuration
DESCRIPTION: Configuration example demonstrating how to set up a router with a default handler. Routes JSON formatted logs to a specific parser while sending all other logs to a catchall handler.

LANGUAGE: yaml
CODE:
- type: router
  routes:
    - output: my_json_parser
      expr: 'body.format == "json"'
  default: catchall

----------------------------------------

TITLE: Configuring Metric Start Time Processor in YAML
DESCRIPTION: Basic YAML configuration for the metricstarttime processor, showing how to specify the strategy for setting start times for cumulative metrics.

LANGUAGE: yaml
CODE:
processors:
    # processor name: metricstarttime
    metricstarttime:

        # specify the strategy to use for setting the start time
        strategy: true_reset_point

----------------------------------------

TITLE: Generating Logs with Telemetrygen
DESCRIPTION: Command to generate logs using telemetrygen for a specified duration.

LANGUAGE: console
CODE:
telemetrygen logs --duration 5s --otlp-insecure

----------------------------------------

TITLE: Resolved YAML Configuration with Decrypted Value
DESCRIPTION: This YAML snippet shows the resolved configuration after the AES provider has decrypted the value.

LANGUAGE: yaml
CODE:
password: '1'

----------------------------------------

TITLE: ANSI Control Sequence Removal Configuration in YAML
DESCRIPTION: Configuration showing how to remove ANSI color escape codes using a predefined regex pattern.

LANGUAGE: yaml
CODE:
- type: regex_replace
  regex_name: ansi_control_sequences
  field: body

----------------------------------------

TITLE: Configuring Delta to Cumulative Processor in YAML
DESCRIPTION: YAML configuration for the delta to cumulative processor. Includes settings for max_stale duration to control when inactive series are removed and max_streams to limit the number of tracked streams.

LANGUAGE: yaml
CODE:
processors:
    deltatocumulative:
        # how long until a series not receiving new samples is removed
        [ max_stale: <duration> | default = 5m ]
 
        # upper limit of streams to track. new streams exceeding this limit
        # will be dropped
        [ max_streams: <int> | default = 9223372036854775807 (max int) ]

----------------------------------------

TITLE: Receiving Custom Messages via OpAMP in Go
DESCRIPTION: Demonstrates how to receive messages from the custom capability handler's message channel.

LANGUAGE: go
CODE:
msg := <-handler.Message()
// process the message...

----------------------------------------

TITLE: Sending Test Metrics via NetCat
DESCRIPTION: Shell commands for sending test StatsD metrics to the receiver using netcat for both IPv4 and IPv6.

LANGUAGE: shell
CODE:
echo "test.metric:42|c|#myKey:myVal" | nc -w 1 -u -4 localhost 8125;
echo "test.metric:42|c|#myKey:myVal" | nc -w 1 -u -6 localhost 8125;

----------------------------------------

TITLE: Configuring Apache Metrics Collection in YAML
DESCRIPTION: Configuration example showing how to disable specific metrics collection for Apache HTTP Server monitoring. The configuration allows selective enabling/disabling of individual metrics.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Simple Memory Counter Configuration
DESCRIPTION: Basic example showing how to configure memory counter collection with metric output formatting.

LANGUAGE: yaml
CODE:
receivers:
  windowsperfcounters:
    metrics:
      bytes.committed:
        description: the number of bytes committed to memory
        unit: By
        gauge:
    collection_interval: 30s
    perfcounters:
    - object: Memory
      counters:
        - name: Committed Bytes
          metric: bytes.committed

service:
  pipelines:
    metrics:
      receivers: [windowsperfcounters]

----------------------------------------

TITLE: Configuring Cumulative to Delta Processor for All Sum Metrics in YAML
DESCRIPTION: This YAML configuration example demonstrates how to set up the Cumulative to Delta Processor to convert all sum metrics to delta metrics.

LANGUAGE: yaml
CODE:
processors:
    # processor name: cumulativetodelta
    cumulativetodelta:

        # Convert all sum metrics
        include:
            metric_types:
              - sum

----------------------------------------

TITLE: Parsing CSV with Timestamp Processing
DESCRIPTION: Advanced example demonstrating CSV parsing with integrated timestamp parsing using strptime layout.

LANGUAGE: yaml
CODE:
- type: csv_parser
  header: 'timestamp_field,severity,message'
  timestamp:
    parse_from: body.timestamp_field
    layout_type: strptime
    layout: '%Y-%m-%d'

LANGUAGE: json
CODE:
{
  "timestamp": "",
  "body": {
    "message": "2021-03-17,debug,Debug Message"
  }
}

LANGUAGE: json
CODE:
{
  "timestamp": "2021-03-17T00:00:00-00:00",
  "body": {
    "severity": "debug",
    "message": "Debug Message"
  }
}

----------------------------------------

TITLE: Defining OpenTelemetry Trace Attributes and Constraints
DESCRIPTION: This snippet outlines the various categories and possible values for OpenTelemetry trace attributes. It includes parent-child relationships, tracestate, span kinds, attributes, events, links, and status options.

LANGUAGE: plaintext
CODE:
Parent: Root, Child
Tracestate: Empty, One, Four
Kind: Unspecified, Internal, Server, Client, Producer, Consumer
Attributes: Empty, DatabaseSQL, DatabaseNoSQL, FaaSDatasource, FaaSHTTP, FaaSPubSub, FaaSTimer, FaaSOther, HTTPClient, HTTPServer, MessagingProducer, MessagingConsumer, gRPCClient, gRPCServer, Internal, MaxCount
Events: Empty, One, Two, Eight
Links: Empty, One, Two, Eight
Status: Unset, Ok, Error

----------------------------------------

TITLE: Building Telemetrygen Docker Image
DESCRIPTION: Command to build a Docker image for telemetrygen locally using make.

LANGUAGE: bash
CODE:
make docker-telemetrygen

----------------------------------------

TITLE: Parsing Cloudflare Log Data in JSON Format
DESCRIPTION: This snippet shows the structure of Cloudflare log data in JSON format. It includes information about client requests, server responses, and timing details. Some entries also include a 'ZoneName' field, which represents the domain being accessed.

LANGUAGE: json
CODE:
{
  "ClientIP": "89.163.253.200",
  "ClientRequestHost": "www.theburritobot0.com",
  "ClientRequestMethod": "GET",
  "ClientRequestURI": "/static/img/testimonial-hipster.png",
  "EdgeEndTimestamp": "2023-03-03T05:30:05Z",
  "EdgeResponseBytes": 69045,
  "EdgeResponseStatus": 200,
  "EdgeStartTimestamp": "2023-03-03T05:29:05Z",
  "RayID": "3a6050bcbe121a87"
}
{
  "ClientIP": "89.163.253.201",
  "ClientRequestHost": "www.theburritobot1.com",
  "ClientRequestMethod": "GET",
  "ClientRequestURI": "/static/img/testimonial-hipster.png",
  "EdgeEndTimestamp": "2023-03-03T05:30:05Z",
  "EdgeResponseBytes": 69045,
  "EdgeResponseStatus": 200,
  "EdgeStartTimestamp": "2023-03-03T05:29:05Z",
  "RayID": "3a6050bcbe121a87"
}
{
  "ClientIP": "89.163.253.202",
  "ClientRequestHost": "www.theburritobot2.com",
  "ClientRequestMethod": "GET",
  "ClientRequestURI": "/static/img/testimonial-hipster.png",
  "EdgeEndTimestamp": "2023-03-03T05:30:05Z",
  "EdgeResponseBytes": 69045,
  "EdgeResponseStatus": 200,
  "EdgeStartTimestamp": "2023-03-03T05:29:05Z",
  "RayID": "3a6050bcbe121a87",
  "ZoneName": "example.com"
}
{
  "ClientIP": "89.163.253.203",
  "ClientRequestHost": "www.theburritobot3.com",
  "ClientRequestMethod": "GET",
  "ClientRequestURI": "/static/img/testimonial-hipster.png",
  "EdgeEndTimestamp": "2023-03-03T05:30:05Z",
  "EdgeResponseBytes": 69045,
  "EdgeResponseStatus": 200,
  "EdgeStartTimestamp": "2023-03-03T05:29:05Z",
  "RayID": "3a6050bcbe121a87",
  "ZoneName": "abc.com"
}
{
  "ClientIP": "89.163.253.204",
  "ClientRequestHost": "www.theburritobot4.com",
  "ClientRequestMethod": "GET",
  "ClientRequestURI": "/static/img/testimonial-hipster.png",
  "EdgeEndTimestamp": "2023-03-03T05:30:05Z",
  "EdgeResponseBytes": 69045,
  "EdgeResponseStatus": 200,
  "EdgeStartTimestamp": "2023-03-03T05:29:05Z",
  "RayID": "3a6050bcbe121a87",
  "ZoneName": "example.com"
}

----------------------------------------

TITLE: Configuring HAProxy Metric Collection in YAML
DESCRIPTION: Example configuration to disable specific metrics in the HAProxy collector. This pattern can be applied to any metric to control whether it is emitted.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Configuring Load Balancer for OpenTelemetry Protocol with Apache Arrow Exporter
DESCRIPTION: YAML configuration example demonstrating how to set a specific gRPC load balancer for the OpenTelemetry Protocol with Apache Arrow exporter.

LANGUAGE: yaml
CODE:
exporters:
  otelarrow:
    balancer_name: pick_first
    endpoint: ...
    tls: ...

----------------------------------------

TITLE: Registering Custom Capability Handler in Go
DESCRIPTION: Demonstrates how to obtain and register a custom capability handler from an OpAMP extension using the component host. Includes error handling and type assertions to ensure proper setup.

LANGUAGE: go
CODE:
func Start(_ context.Context, host component.Host) error {
	ext, ok := host.GetExtensions()[opampExtensionID]
	if !ok {
		return fmt.Errorf("extension %q does not exist", opampExtensionID)
	}

	registry, ok := ext.(opampcustommessages.CustomCapabilityRegistry)
	if !ok {
		return fmt.Errorf("extension %q is not a custom message registry", opampExtensionID)
	}

	handler, err := registry.Register("io.opentelemetry.custom-capability")
	if err != nil {
		return fmt.Errorf("failed to register custom capability: %w", err)
	}

	// ... send/receive messages using the given handler

	return nil
}

----------------------------------------

TITLE: Scope Name Parsing with Regex Parser in YAML
DESCRIPTION: Example configuration for parsing a scope name from a log entry using regex_parser operator. The configuration extracts the scope name and message from a space-separated string.

LANGUAGE: yaml
CODE:
- type: regex_parser
  regexp: '^(?P<scope_name_field>\S*)\s-\s(?P<message>.*)'
  scope_name:
    parse_from: body.scope_name_field

----------------------------------------

TITLE: Generating Go Models from Protobuf for Solace Receiver
DESCRIPTION: Commands to generate Go models from protobuf definitions for the Solace receiver. It uses protoc with the go_out option and goimports for formatting. The commands generate models for receive, egress, and move protos.

LANGUAGE: shell
CODE:
protoc --go_out=../ --go_opt=paths=import --go_opt=Mreceive_v1.proto=model/receive/v1 receive_v1.proto
protoc --go_out=../ --go_opt=paths=import --go_opt=Megress_v1.proto=model/egress/v1 egress_v1.proto
protoc --go_out=../ --go_opt=paths=import --go_opt=Mmove_v1.proto=model/move/v1 move_v1.proto
goimports -w .

----------------------------------------

TITLE: Parsing Containerd Container Log with Automatic Format Detection
DESCRIPTION: This example shows how to parse a containerd container log using automatic format detection.

LANGUAGE: yaml
CODE:
- type: container

----------------------------------------

TITLE: Installing Telemetrygen via Go
DESCRIPTION: Command to install the latest version of telemetrygen using Go's package manager.

LANGUAGE: console
CODE:
go install github.com/open-telemetry/opentelemetry-collector-contrib/cmd/telemetrygen@latest

----------------------------------------

TITLE: Querying SQL Server Database I/O Performance Metrics in TSQL
DESCRIPTION: Constructs and executes a dynamic SQL query to retrieve detailed I/O performance metrics for all databases on the SQL Server instance. Includes version-specific columns and filters for a specific instance name.

LANGUAGE: TSQL
CODE:
SET @SqlStatement = N'
SELECT
	''sqlserver_database_io'' AS [measurement]
	,REPLACE(@@SERVERNAME,''\''','':'') AS [sql_instance]
	,HOST_NAME() AS [computer_name]
	,DB_NAME(vfs.[database_id]) AS [database_name]
	,COALESCE(mf.[physical_name],''RBPEX'') AS [physical_filename]	--RPBEX = Resilient Buffer Pool Extension
	,COALESCE(mf.[name],''RBPEX'') AS [logical_filename]	--RPBEX = Resilient Buffer Pool Extension
	,mf.[type_desc] AS [file_type]
	,vfs.[io_stall_read_ms] AS [read_latency_ms]
	,vfs.[num_of_reads] AS [reads]
	,vfs.[num_of_bytes_read] AS [read_bytes]
	,vfs.[io_stall_write_ms] AS [write_latency_ms]
	,vfs.[num_of_writes] AS [writes]
	,vfs.[num_of_bytes_written] AS [write_bytes]'
	+ @Columns + N'
FROM sys.dm_io_virtual_file_stats(NULL, NULL) AS vfs
INNER JOIN sys.master_files AS mf WITH (NOLOCK)
	ON vfs.[database_id] = mf.[database_id] AND vfs.[file_id] = mf.[file_id]
WHERE @@SERVERNAME = ''instanceName'''
+ @Tables;

EXEC sp_executesql @SqlStatement

----------------------------------------

TITLE: Buffer Pool Size Configuration
DESCRIPTION: Displays the memory buffer pool size setting of 134,217,728 bytes (128MB) used for temporary data storage in the OpenTelemetry Collector.

LANGUAGE: plaintext
CODE:
name	count
buffer_pool_size	134217728

----------------------------------------

TITLE: Enabling Optional Metrics in YAML Configuration
DESCRIPTION: This snippet demonstrates how to enable an optional metric using YAML configuration. Replace <metric_name> with the specific optional metric you want to enable.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: true

----------------------------------------

TITLE: Configuring URI Parser for Query String Parsing in YAML
DESCRIPTION: This configuration example shows how to set up the uri_parser operator to parse a query string from the body.query field. It demonstrates the flexibility of the operator in parsing different URI components.

LANGUAGE: yaml
CODE:
- type: uri_parser
  parse_from: body.query

----------------------------------------

TITLE: Creating SAP HANA Monitoring User and Role
DESCRIPTION: SQL script to create a restricted monitoring user and role with necessary SELECT permissions on monitoring views for SAP HANA metrics collection.

LANGUAGE: sql
CODE:
--Create the user
CREATE RESTRICTED USER otel_monitoring_user PASSWORD <password>;

--Enable user login
ALTER USER otel_monitoring_user ENABLE CLIENT CONNECT;

--Create the monitoring role
CREATE ROLE OTEL_MONITORING;

--Grant permissions to the relevant views
GRANT CATALOG READ TO OTEL_MONITORING;
GRANT SELECT ON SYS.M_BACKUP_CATALOG TO OTEL_MONITORING;
GRANT SELECT ON SYS.M_BLOCKED_TRANSACTIONS TO OTEL_MONITORING;
GRANT SELECT ON SYS.M_CONNECTIONS TO OTEL_MONITORING;
GRANT SELECT ON SYS.M_CS_ALL_COLUMNS TO OTEL_MONITORING;
GRANT SELECT ON SYS.M_CS_TABLES TO OTEL_MONITORING;
GRANT SELECT ON SYS.M_DATABASE TO OTEL_MONITORING;
GRANT SELECT ON SYS.M_DISKS TO OTEL_MONITORING;
GRANT SELECT ON SYS.M_HOST_RESOURCE_UTILIZATION TO OTEL_MONITORING;
GRANT SELECT ON SYS.M_LICENSES TO OTEL_MONITORING;
GRANT SELECT ON SYS.M_RS_TABLES TO OTEL_MONITORING;
GRANT SELECT ON SYS.M_SERVICE_COMPONENT_MEMORY TO OTEL_MONITORING;
GRANT SELECT ON SYS.M_SERVICE_MEMORY TO OTEL_MONITORING;
GRANT SELECT ON SYS.M_SERVICE_REPLICATION TO OTEL_MONITORING;
GRANT SELECT ON SYS.M_SERVICE_STATISTICS TO OTEL_MONITORING;
GRANT SELECT ON SYS.M_SERVICE_THREADS TO OTEL_MONITORING;
GRANT SELECT ON SYS.M_SERVICES TO OTEL_MONITORING;
GRANT SELECT ON SYS.M_VOLUME_IO_TOTAL_STATISTICS TO OTEL_MONITORING;
GRANT SELECT ON SYS.M_WORKLOAD TO OTEL_MONITORING;
GRANT SELECT ON _SYS_STATISTICS.STATISTICS_CURRENT_ALERTS TO OTEL_MONITORING;

--Add the OTEL_MONITOR role to the monitoring user
GRANT OTEL_MONITORING TO otel_monitoring_user;

----------------------------------------

TITLE: Running OpenTelemetry Collector via Docker
DESCRIPTION: Command to start an OpenTelemetry Collector instance using Docker, with a mounted configuration file.

LANGUAGE: console
CODE:
docker run -p 4317:4317 -v $(pwd)/config.yaml:/etc/otelcol-contrib/config.yaml ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.86.0

----------------------------------------

TITLE: Total CPU Time Counter Configuration
DESCRIPTION: Example configuration for collecting total CPU time using the _Total instance.

LANGUAGE: yaml
CODE:
windowsperfcounters:
  metrics:
    processor.time.total:
      description: Total CPU active and idle time
      unit: "%"
      gauge:
  collection_interval: 30s
  perfcounters:
    - object: "Processor"
      instances:
          - "_Total"
      counters:
        - name: "% Processor Time"
          metric: processor.time.total

----------------------------------------

TITLE: Schema Processor Target Configuration
DESCRIPTION: Shows how to configure the schema processor with a specific target version for semantic convention translation.

LANGUAGE: yaml
CODE:
processors:
  schema:
    targets:
      - https://opentelemetry.io/schemas/1.26.0

----------------------------------------

TITLE: Configuring JSON Array Parser with Header
DESCRIPTION: YAML configuration for parsing the 'body' field containing a JSON array into attributes using a header, along with input and output examples.

LANGUAGE: yaml
CODE:
- type: json_array_parser
  parse_to: attributes
  header: origin,sev,message,isBool

LANGUAGE: json
CODE:
{
  "body": "[1,\"debug\",\"Debug Message\", true]"
}

LANGUAGE: json
CODE:
{
  "body": "[1,\"debug\",\"Debug Message\", true]",
  "attributes": {
    "origin":  1,
    "sev":     "debug",
    "message": "Debug Message",
    "isBool":  true
  }
}

----------------------------------------

TITLE: Disabling Nginx Metrics Configuration in YAML
DESCRIPTION: YAML configuration snippet showing how to disable specific Nginx metrics collection. The configuration allows selective disabling of individual metrics by setting their 'enabled' property to false.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Starting Services with Docker Compose (Bash)
DESCRIPTION: This command uses Docker Compose to start the Envoy and OpenTelemetry Collector services as defined in the docker-compose.yml file.

LANGUAGE: bash
CODE:
$ docker compose up

----------------------------------------

TITLE: Feature Gate Activation Command
DESCRIPTION: Shell command to enable the resource detection error propagation feature gate

LANGUAGE: shell
CODE:
$ otelcol --config=config.yaml --feature-gates=processor.resourcedetection.propagateerrors

----------------------------------------

TITLE: Checking ADX Streaming Ingestion Status
DESCRIPTION: KQL query to verify if streaming ingestion is enabled on the Azure Data Explorer database.

LANGUAGE: kql
CODE:
.show database <DB-Name> policy streamingingestion

----------------------------------------

TITLE: Multiple Filter Options Configuration
DESCRIPTION: Comprehensive example showing the combination of multiple filtering options including matches, units, and priority.

LANGUAGE: yaml
CODE:
- type: journald_input
  matches:
    - _SYSTEMD_UNIT: ssh
    - _SYSTEMD_UNIT: kubelet
      _UID: "1000"
  units:
    - kubelet
    - systemd
  priority: info

----------------------------------------

TITLE: Copying Nested Value within Body in YAML
DESCRIPTION: This configuration shows how to copy a nested value within the body using the 'copy' operator.

LANGUAGE: yaml
CODE:
- type: copy
  from: body.obj.nested
  to: body.newkey

----------------------------------------

TITLE: AWS X-Ray API Subsegment JSON Example
DESCRIPTION: JSON structure showing an AWS X-Ray subsegment that captures trace data for an API request. Includes trace identifiers, timing information, and HTTP request/response details for monitoring API calls.

LANGUAGE: json
CODE:
{
    "name": "api.example.com",
    "id": "53995c3f42cd8ad8",
    "start_time": 1478293361.271,
    "end_time": 1478293361.449,
    "type": "subsegment",
    "trace_id": "1-581cf771-a006649127e371903a2de979",
    "parent_id": "defdfd9912dc5a56",
    "namespace": "remote",
    "traced": true,
    "http": {
        "request": {
            "url": "https://api.example.com/health",
            "method": "POST"
        },
        "response": {
            "status": 200,
            "content_length": 861
        }
    }
}

----------------------------------------

TITLE: Configuring JSON Parser to Parse 'message' Field
DESCRIPTION: This YAML configuration sets up the json_parser to parse the 'message' field within the body as JSON.

LANGUAGE: yaml
CODE:
- type: json_parser
  parse_from: body.message

----------------------------------------

TITLE: Visualizing Sidecar Mode Architecture with ASCII Diagram
DESCRIPTION: ASCII diagram illustrating the architecture and data flow for the sidecar mode of the k8slogreceiver, showing how log files are found and read based on configuration.

LANGUAGE: plaintext
CODE:
            
  env      Poller      find files based on include from config
            
                 create
                
            
               Reader     
            
                 read files
                
               files

----------------------------------------

TITLE: Installing OpenTelemetry Collector as Deployment
DESCRIPTION: Command to install the OpenTelemetry Collector as a Deployment using the deployment-collector-dev.yaml configuration.

LANGUAGE: bash
CODE:
make kind-install-deployment

----------------------------------------

TITLE: Reading File Storage Contents with Strings Utility
DESCRIPTION: Shell command demonstrating how to use the strings utility to read the raw contents of files created by the File Storage extension for troubleshooting purposes.

LANGUAGE: shell
CODE:
$ strings /tmp/otelcol/file_storage/filelogreceiver/receiver_filelog_

----------------------------------------

TITLE: Complex Journald Filtering Configuration in YAML
DESCRIPTION: Advanced configuration example showing multiple filtering options including matches, units, priority, and identifiers.

LANGUAGE: yaml
CODE:
- type: journald_input
  matches:
    - _SYSTEMD_UNIT: ssh
    - _SYSTEMD_UNIT: kubelet
      _UID: "1000"
  units:
    - kubelet
    - systemd
  priority: info
  identifiers:
    - systemd

----------------------------------------

TITLE: File Structure Guidelines - Markdown
DESCRIPTION: Directory structure and naming conventions for adding new functions to the transform processor, including requirements for common and pipeline-specific functions.

LANGUAGE: markdown
CODE:
# Contributing\n\nThis guide is specific to the transform processor.  All guidelines in [Collector Contrib's CONTRIBUTING.MD](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/CONTRIBUTING.md) must also be followed.\n\n## New Functions\n\nIf a new function is not specific to the transform processor it should be added to the [OpenTelemetry Transformation Language](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/pkg/ottl) instead.\n\nAll new functions must be added via a new file.  Function files must start with `func_`.  Functions that are usable in multiple pipelines must be placed in `internal/common`.  Functions that are specific to a pipeline must be placed in `internal/<pipeline>`.\n\nNew functions must update the appropriate registry.  For common functions, update the registry in `internal/common/functions.go`.  For pipeline-specific functions, update the registry in `internal/<pipeline>/functions.go`\n\nUnit tests must be added for all new functions.  Unit test files must start with `func_` and end in `_test`.  Unit tests must be placed in the same directory as the function.  Functions that are not specific to a pipeline should be tested independently of any specific pipeline. Functions that are specific to a pipeline should be tests against that pipeline.\n\nAll new functions should have integration tests added to any usable pipeline's `processing_test.go` tests.  The purpose of these tests is not to test the function's logic, but its ability to be used within a specific pipeline.  \n\n## New Values\n\nWhen adding new values to the grammar you must update the [OpenTelemetry Transformation Language](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/pkg/ottl/CONTRIBUTING.md)

----------------------------------------

TITLE: Parsing and Recombining Multiline CRI Container Logs
DESCRIPTION: This configuration demonstrates how to parse and recombine multiline CRI container logs into a single log entry.

LANGUAGE: yaml
CODE:
- type: container

----------------------------------------

TITLE: Parsing Absolute URI with URI Parser in JSON
DESCRIPTION: This example demonstrates the input and output JSON for parsing an absolute URI using the uri_parser operator. It shows how the operator extracts various components of the URI into structured fields.

LANGUAGE: json
CODE:
{
  "timestamp": "",
  "body": {
    "message": "https://dev:pass@google.com/app?user_id=2&token=001"
  }
}

LANGUAGE: json
CODE:
{
  "timestamp": "",
  "body": {
    "host": "google.com",
    "path": "/app",
    "query": {
      "user_id": [
        "2"
      ],
      "token": [
        "001"
      ]
    },
    "scheme": "https",
    "user": "dev"
  }
}

----------------------------------------

TITLE: Defining Sigv4 Authenticator Configuration in Go
DESCRIPTION: Defines the Config struct for the Sigv4 Authenticator, including fields for AWS region, service, and role assumption. It also includes a validation method to check the configuration and set AWS credentials.

LANGUAGE: go
CODE:
type Config struct {
    Region string `mapstructure:"region,omitempty"`
    Service string `mapstructure:"service,omitempty"`
    AssumeRole AssumeRole `mapstructure:"assume_role"`
	credsProvider *aws.CredentialsProvider
}

type AssumeRole struct {
	ARN                  string `mapstructure:"arn,omitempty"`
	SessionName          string `mapstructure:"session_name,omitempty"`
}

func (cfg *Config) Validate() error {
	credsProvider, err := getCredsFromConfig(cfg)
	if err != nil {
		return fmt.Errorf("could not retrieve credential provider: %w", err)
	}
	if credsProvider == nil {
		return fmt.Errorf("credsProvider cannot be nil")
	}
	return nil
}

----------------------------------------

TITLE: Generated Log Entries in JSON Format
DESCRIPTION: Example JSON output showing the structure of log entries generated by the tcp_input operator, including timestamps and message bodies.

LANGUAGE: json
CODE:
{
  "timestamp": "2020-04-30T12:10:17.656726-04:00",
  "body": "message1"
},
{
  "timestamp": "2020-04-30T12:10:17.657143-04:00",
  "body": "message2"
}

----------------------------------------

TITLE: Enabling Optional Metrics in YAML Configuration
DESCRIPTION: This snippet demonstrates how to enable an optional metric in the YAML configuration. Replace <metric_name> with the specific metric you want to enable.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: true

----------------------------------------

TITLE: Adding an Object to Body in YAML Configuration
DESCRIPTION: This configuration demonstrates adding a nested object to the body of an entry. It creates a new key with a nested structure.

LANGUAGE: yaml
CODE:
- type: add
  field: body.key2
  value:
    nestedkey: nestedvalue

----------------------------------------

TITLE: Creating ConfigMap for OpenTelemetry Collector in Kubernetes
DESCRIPTION: Bash script to create a ConfigMap containing the configuration for the OpenTelemetry Collector, including the Kubernetes Events Receiver and OTLP Exporter.

LANGUAGE: bash
CODE:
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: ConfigMap
metadata:
  name: otelcontribcol
  labels:
    app: otelcontribcol
data:
  config.yaml: |
    receivers:
      k8s_events:
        namespaces: [default, my_namespace]
    exporters:
      otlp:
        endpoint: <OTLP_ENDPOINT>
        tls:
          insecure: true

    service:
      pipelines:
        logs:
          receivers: [k8s_events]
          exporters: [otlp]
EOF

----------------------------------------

TITLE: Uninstalling OpenTelemetry Collector DaemonSet
DESCRIPTION: Command to remove the OpenTelemetry Collector DaemonSet from the kind cluster.

LANGUAGE: bash
CODE:
make kind-uninstall-daemonset

----------------------------------------

TITLE: Configuring OpAMP Agent Extension in YAML
DESCRIPTION: Example YAML configuration for the OpAMP Agent Extension, demonstrating how to set up the server connection using WebSocket transport.

LANGUAGE: yaml
CODE:
extensions:
  opamp:
    server:
      ws:
        endpoint: wss://127.0.0.1:4320/v1/opamp

----------------------------------------

TITLE: Parsing RFC3164 Log Record in JSON
DESCRIPTION: Example of a simplified input log record in JSON format for RFC3164 syslog protocol. It shows the structure and attributes used by the Syslog exporter for the older RFC3164 format.

LANGUAGE: json
CODE:
{
  "body": "",
  "timeUnixNano": 1697062455000000000,
  "attributes":
  {
    "appname": "su",
    "hostname": "mymachine",
    "message": "'su root' failed for lonvick on /dev/pts/8",
    "priority": 34
  }
}

----------------------------------------

TITLE: Configuring Retain Operator for Resource Fields in YAML
DESCRIPTION: This example illustrates retaining specific fields from the resource section of a log entry. It keeps 'key1' and 'key2' from the resource, removing other resource fields while preserving the body and attributes.

LANGUAGE: yaml
CODE:
- type: retain
  fields:
    - resource.key1
    - resource.key2

----------------------------------------

TITLE: Generating Traces with Telemetrygen
DESCRIPTION: Commands to generate traces using telemetrygen, either for a specified duration or a specific number of traces.

LANGUAGE: console
CODE:
telemetrygen traces --otlp-insecure --duration 5s

LANGUAGE: console
CODE:
telemetrygen traces --otlp-insecure --traces 1

----------------------------------------

TITLE: Defining Redis Container in ECS Task Definition JSON
DESCRIPTION: This JSON snippet shows how to define a Redis container in an ECS task definition, including port mappings and Docker labels for use with the ECS Task Observer.

LANGUAGE: json
CODE:
{
  "containerDefinitions": [
    {
      "portMappings": [
        {
          "containerPort": 6379,
          "hostPort": 6379
        }
      ],
      "image": "redis",
      "dockerLabels": {
        "A_DOCKER_LABEL_CONTAINING_DESIRED_PORT": "6379",
        "SECRET": "my-redis-auth"
      },
      "name": "redis"
    }
  ]
}

----------------------------------------

TITLE: Adding a Value Using Expression in YAML Configuration
DESCRIPTION: This example shows how to add a value to the body using an expression. The expression concatenates an existing value with a suffix.

LANGUAGE: yaml
CODE:
- type: add
  field: body.key2
  value: EXPR(body.key1 + "_suffix")

----------------------------------------

TITLE: Configuring Kubernetes Events Receiver in YAML
DESCRIPTION: Example YAML configuration for the Kubernetes Events Receiver, specifying authentication type and namespaces to collect events from.

LANGUAGE: yaml
CODE:
  k8s_events:
    auth_type: kubeConfig
    namespaces: [default, my_namespace]

----------------------------------------

TITLE: Enabling Optional IIS Metrics in YAML Configuration
DESCRIPTION: YAML configuration snippet to enable an optional IIS metric. Replace <metric_name> with the specific metric to enable.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: true

----------------------------------------

TITLE: Configuring stdin Operator in YAML
DESCRIPTION: A simple YAML configuration for the stdin operator. This configuration doesn't specify any custom fields, using the default values.

LANGUAGE: yaml
CODE:
- type: stdin

----------------------------------------

TITLE: Configuring TCP Check Metrics in YAML
DESCRIPTION: Configuration example showing how to disable specific TCP check metrics in the collector configuration. Each metric can be individually disabled by setting enabled: false.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Output Entry Example - JSON Result
DESCRIPTION: Sample JSON output entry showing the structure after field operations are applied

LANGUAGE: json
CODE:
{
  "timestamp": "",
  "attributes": {
    "my_attribute": "my_attribute_value"
  },
  "body": {
    "key1": "value1",
    "key2": {
      "nested_key2": "nested_value2"
    },
    "key3": "value3"
  }
}

----------------------------------------

TITLE: Defining Wavefront Metric Format in OpenTelemetry
DESCRIPTION: Specifies the format for Wavefront metrics as received by the OpenTelemetry Collector. Each line represents a single metric data point with metricName, metricValue, optional timestamp, source, and optional pointTags.

LANGUAGE: plaintext
CODE:
<metricName> <metricValue> [<timestamp>] source=<source> [pointTags]

----------------------------------------

TITLE: Configuring Podman Stats Metrics in YAML
DESCRIPTION: Example configuration to disable specific metrics in the Podman stats receiver. The configuration allows disabling individual metrics by setting their 'enabled' property to false.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Creating a New Metric from Existing Metric in YAML
DESCRIPTION: Example of creating a new metric 'host.cpu.utilization' from 'host.cpu.usage' using the Metrics Transform Processor.

LANGUAGE: yaml
CODE:
include: host.cpu.usage
action: insert
new_name: host.cpu.utilization
operations:
  ...

----------------------------------------

TITLE: Disabling Default IIS Metrics in YAML Configuration
DESCRIPTION: YAML configuration snippet to disable a default IIS metric. Replace <metric_name> with the specific metric to disable.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Defining X-Ray Trace Data Structure in JSON
DESCRIPTION: This JSON structure defines an AWS X-Ray trace for a sample server request. It includes trace identifiers, timing information, HTTP request and response details, AWS-specific metadata (including X-Ray SDK, ECS, EC2, and Elastic Beanstalk information), and service compiler details.

LANGUAGE: json
CODE:
{
    "trace_id": "1-5f2aebcc-b475d14618c51eaa28753d37",
    "id": "bda182a644eee9b3",
    "name": "SampleServer",
    "start_time": 1596648396.6399446,
    "end_time": 1596648396.6401389,
    "http": {
        "request": {
            "method": "GET",
            "url": "http://localhost:8000/",
            "client_ip": "127.0.0.1",
            "user_agent": "Go-http-client/1.1",
            "x_forwarded_for": true
        },
        "response": {
            "status": 200
        }
    },
    "aws": {
        "xray": {
            "sdk_version": "1.1.0",
            "sdk": "X-Ray for Go"
        },
        "ecs": {
            "container": "containerId1234",
            "container_id": "d8453812a556",
            "availability_zone": "us-west-2c"
        },
        "ec2": {
            "availability_zone": "us-west-2c",
            "instance_id": "i-075ad396f12bc325a",
            "instance_size": "m5.xlarge",
            "ami_id": "ami-003634241a8fcdec0"
        },
        "elastic_beanstalk": {
            "environment_name": "scorekeep",
            "deployment_id": 32,
            "version_label": "app-5a56-170119_190650-stage-170119_190650"
        },
        "account_id": "000000000000"
    },
    "service": {
        "compiler_version": "go1.14.6",
        "compiler": "gc"
    },
    "Dummy": false
}

----------------------------------------

TITLE: Adding a String to Body in YAML Configuration
DESCRIPTION: This snippet demonstrates how to add a string value to the body of an entry using YAML configuration. It adds a new key-value pair to the body.

LANGUAGE: yaml
CODE:
- type: add
  field: body.key2
  value: val2

----------------------------------------

TITLE: Advanced Journald Matching Configuration in YAML
DESCRIPTION: Configuration example demonstrating complex matching rules for Journald input filtering based on systemd units and UID.

LANGUAGE: yaml
CODE:
- type: journald_input
  matches:
    - _SYSTEMD_UNIT: ssh
    - _SYSTEMD_UNIT: kubelet
      _UID: "1000"

----------------------------------------

TITLE: Generating Metrics with Telemetrygen
DESCRIPTION: Command to generate metrics using telemetrygen for a specified duration.

LANGUAGE: console
CODE:
telemetrygen metrics --duration 5s --otlp-insecure

----------------------------------------

TITLE: Setting AWS Credentials in Kubernetes Helm Chart
DESCRIPTION: Example YAML configuration for setting AWS credentials when using the OpenTelemetry Collector Helm Chart in Kubernetes.

LANGUAGE: yaml
CODE:
extraEnvs:
- name: AWS_ACCESS_KEY_ID
  value: "< YOUR AWS ACCESS KEY >"
- name: AWS_SECRET_ACCESS_KEY
  value: "< YOUR AWS SECRET ACCESS KEY >"

----------------------------------------

TITLE: Defining AWS ECS Task Metadata in JSON
DESCRIPTION: This JSON object defines metadata for an AWS ECS task, including cluster information, container details, networking configuration, and host information. It provides a comprehensive overview of the task's runtime environment and configuration.

LANGUAGE: json
CODE:
{
    "Cluster": "default",
    "ContainerInstanceARN": "arn:aws:ecs:us-west-50:012345678910:container-instance/default/1f73d099-b914-411c-a9ff-81633b7741dd",
    "TaskARN": "arn:aws:ecs:us-west-50:012345678910:task/default/2b88376d-aba3-4950-9ddf-bcb0f388a40c",
    "TaskDefinitionFamily": "console-sample-app-static",
    "TaskDefinitionRevision": "1",
    "ContainerID": "aec2557997f4eed9b280c2efd7afccdcedfda4ac399f7480cae870cfc7e163fd",
    "ContainerName": "simple-app",
    "DockerContainerName": "/ecs-console-sample-app-static-1-simple-app-e4e8e495e8baa5de1a00",
    "ImageID": "sha256:2ae34abc2ed0a22e280d17e13f9c01aaf725688b09b7a1525d1a2750e2c0d1de",
    "ImageName": "httpd:2.4",
    "PortMappings": [
        {
            "ContainerPort": 80,
            "HostPort": 80,
            "BindIp": "0.0.0.0",
            "Protocol": "tcp"
        }
    ],
    "Networks": [
        {
            "NetworkMode": "bridge",
            "IPv4Addresses": [
                "192.0.2.0"
            ]
        }
    ],
    "MetadataFileStatus": "READY",
    "AvailabilityZone": "us-east-1b",
    "HostPrivateIPv4Address": "192.0.2.0",
    "HostPublicIPv4Address": "203.0.113.0"
}

----------------------------------------

TITLE: Capturing X-Ray Segments with tcpdump
DESCRIPTION: Command to capture UDP packets containing X-Ray segments on port 2000 using tcpdump. The output is saved to a text file for analysis.

LANGUAGE: bash
CODE:
sudo tcpdump -i any -A -c100 -v -nn udp port 2000 > xray_instrumented_client.txt

----------------------------------------

TITLE: Configuring SAPM Receiver in YAML
DESCRIPTION: Example configuration for the SAPM receiver showing endpoint setup, access token passthrough, and TLS configuration options. Demonstrates basic receiver setup with optional TLS security.

LANGUAGE: yaml
CODE:
receivers:
  sapm:
    endpoint: localhost:7276
    access_token_passthrough: true
    tls:
      cert_file: /test.crt
      key_file: /test.key

----------------------------------------

TITLE: Defining AWS X-Ray Trace Segment JSON Structure
DESCRIPTION: This JSON structure defines the properties of an AWS X-Ray trace segment. It includes essential information such as trace and segment IDs, timing details, and error indicators. The structure is used to represent a single unit of work within a distributed application trace.

LANGUAGE: json
CODE:
{
    "trace_id": "1-5f187253-6a106696d56b1f4ef9eba2ed",
    "id": "5cc4a447f5d4d696",
    "name": "CauseIsExceptionID",
    "start_time": 1595437651.680097,
    "end_time": 1595437652.197392,
    "fault": true,
    "cause": "abcdefghijklmnop",
    "Dummy": false
}

----------------------------------------

TITLE: Assigning Keys to Nested Attributes List in YAML
DESCRIPTION: Configuration example demonstrating how to assign keys to a list within a nested attributes field. Maps two keys (foo, bar) to list values while preserving other fields.

LANGUAGE: yaml
CODE:
- type: assign_keys
  field: attributes.input
  keys: ["foo", "bar"]

LANGUAGE: json
CODE:
{
  "attributes": {
    "input": [1, "debug"],
    "field2": "unchanged"
  }
}

LANGUAGE: json
CODE:
{
  "attributes": {
    "input": {
      "foo": 1, 
      "bar": "debug"
    },
    "field2": "unchanged"
  }
}

----------------------------------------

TITLE: Basic Journald Receiver Configuration in YAML
DESCRIPTION: Example configuration showing basic setup of Journald receiver with unit filtering and priority settings.

LANGUAGE: yaml
CODE:
receivers:
  journald:
    directory: /run/log/journal
    units:
      - ssh
      - kubelet
      - docker
      - containerd
    priority: info

----------------------------------------

TITLE: Associating OpenTelemetry Spans with Sentry Errors in Python
DESCRIPTION: Example Python code demonstrating how to associate OpenTelemetry spans with Sentry errors by setting trace context on error events. This allows linking traces to errors that occurred during trace execution.

LANGUAGE: python
CODE:
from sentry_sdk import configure_scope

with start_otel_span("start") as span:
  ctx = span.get_context()
  with configure_scope() as scope:
    scope.set_context("trace", {"trace_id": ctx.trace_id})

  with start_otel_span("child"):
    # ...

----------------------------------------

TITLE: HAProxy Stats CSV Header Definition
DESCRIPTION: Complete list of column headers for HAProxy statistics CSV export format, including basic metrics, HTTP stats, health checks, session tracking, and protocol-specific counters.

LANGUAGE: csv
CODE:
pxname,svname,qcur,qmax,scur,smax,slim,stot,bin,bout,dreq,dresp,ereq,econ,eresp,wretr,wredis,status,weight,act,bck,chkfail,chkdown,lastchg,downtime,qlimit,pid,iid,sid,throttle,lbtot,tracked,type,rate,rate_lim,rate_max,check_status,check_code,check_duration,hrsp_1xx,hrsp_2xx,hrsp_3xx,hrsp_4xx,hrsp_5xx,hrsp_other,hanafail,req_rate,req_rate_max,req_tot,cli_abrt,srv_abrt,comp_in,comp_out,comp_byp,comp_rsp,lastsess,last_chk,last_agt,qtime,ctime,rtime,ttime,agent_status,agent_code,agent_duration,check_desc,agent_desc,check_rise,check_fall,check_health,agent_rise,agent_fall,agent_health,addr,cookie,mode,algo,conn_rate,conn_rate_max,conn_tot,intercepted,dcon,dses,wrew,connect,reuse,cache_lookups,cache_hits,srv_icur,src_ilim,qtime_max,ctime_max,rtime_max,ttime_max,eint,idle_conn_cur,safe_conn_cur,used_conn_cur,need_conn_est,uweight,agg_server_status,agg_server_check_status,agg_check_status,srid,sess_other,h1sess,h2sess,h3sess,req_other,h1req,h2req,h3req,proto,-,ssl_sess,ssl_reused_sess,ssl_failed_handshake,h2_headers_rcvd,h2_data_rcvd,h2_settings_rcvd,h2_rst_stream_rcvd,h2_goaway_rcvd,h2_detected_conn_protocol_errors,h2_detected_strm_protocol_errors,h2_rst_stream_resp,h2_goaway_resp,h2_open_connections,h2_backend_open_streams,h2_total_connections,h2_backend_total_streams,h1_open_connections,h1_open_streams,h1_total_connections,h1_total_streams,h1_bytes_in,h1_bytes_out

----------------------------------------

TITLE: Configuring Remote Tap Processor in YAML
DESCRIPTION: Example configuration for the Remote Tap processor showing how to set the WebSocket endpoint and rate limit. The endpoint parameter determines where the processor listens for WebSocket connections, while the limit parameter controls the message rate to prevent overload.

LANGUAGE: yaml
CODE:
processors:
  remotetap:
    endpoint: 0.0.0.0:12001
    limit: 1 # rate limit 1 msg/sec

----------------------------------------

TITLE: Adding Environment Variable Label in OpenTelemetry YAML Config
DESCRIPTION: Demonstrates how to add a new attribute field to telemetry data using an environment variable value through expressions. The example shows adding a 'stack' attribute using the STACK environment variable.

LANGUAGE: yaml
CODE:
- type: add
  field: attributes.stack
  value: 'EXPR(env("STACK"))'

----------------------------------------

TITLE: Describing OTel Arrow Admission In Flight Bytes Metric
DESCRIPTION: Documentation for a metric that tracks the number of bytes currently being processed but not yet finished in the OTel Arrow component.

LANGUAGE: markdown
CODE:
| Unit | Metric Type | Value Type | Monotonic |
| ---- | ----------- | ---------- | --------- |
| By | Sum | Int | false |

----------------------------------------

TITLE: Replace Body with Nested Value
DESCRIPTION: Shows how to replace the entire body with a nested value from within it

LANGUAGE: yaml
CODE:
- type: move
  from: body.log
  to: body

LANGUAGE: json
CODE:
{
  "resource": { },
  "attributes": { },
  "body": {
    "log": "The log line"
  }
}

----------------------------------------

TITLE: Configuring Huawei Cloud CES Receiver in YAML
DESCRIPTION: Example configuration for the Huawei Cloud CES receiver in YAML format. Includes settings for collection interval, region, authentication, and metric filtering.

LANGUAGE: yaml
CODE:
receivers:
  huaweicloudcesreceiver:
    collection_interval: 3h
    initial_delay: 5s
    region_id: eu-west-101
    access_key: ${env:HUAWEICLOUD_SDK_AK}
    secret_key: ${env:HUAWEICLOUD_SDK_SK}
    project_id: "project_1"
    period: 300
    filter: average
    no_verify_ssl: True

----------------------------------------

TITLE: Example Tracestate Format
DESCRIPTION: Example showing how 25% sampling is encoded in a tracing Span's tracestate.

LANGUAGE: text
CODE:
tracestate: ot=th:c

----------------------------------------

TITLE: Assigning Keys to Body List in YAML
DESCRIPTION: Configuration example showing how to assign keys to a list in the body field. Maps four keys (foo, bar, charlie, foxtrot) to corresponding list values.

LANGUAGE: yaml
CODE:
- type: assign_keys
  field: body
  keys: ["foo", "bar", "charlie", "foxtrot"]

LANGUAGE: json
CODE:
{
  "body": [1, "debug", "Debug Message", true]
}

LANGUAGE: json
CODE:
{
    "body": {
      "foo": 1,
      "bar": "debug",
      "charlie": "Debug Message",
      "foxtrot": true
    }
  }

----------------------------------------

TITLE: Configuring Root Path for Container-based Collection in YAML
DESCRIPTION: Configuration example for setting the root path when collecting host metrics from inside a container.

LANGUAGE: yaml
CODE:
receivers:
  hostmetrics:
    root_path: /hostfs

----------------------------------------

TITLE: Configuring Transform Processor for Resource Attribute Conversion
DESCRIPTION: Example of using the transform processor to copy resource attributes into metric labels for easier querying.

LANGUAGE: yaml
CODE:
processor:
  transform:
    metric_statements:
      - context: datapoint
        statements:
        - set(attributes["namespace"], resource.attributes["k8s.namespace.name"])
        - set(attributes["container"], resource.attributes["k8s.container.name"])
        - set(attributes["pod"], resource.attributes["k8s.pod.name"])

----------------------------------------

TITLE: Calculating Collection Interval for GitHub API Scraping
DESCRIPTION: Mathematical formula to calculate the ideal collection interval for the GitHub scraper based on the number of repositories and hourly rate limit. This helps in avoiding rate limiting issues.

LANGUAGE: math
CODE:
\text{collection\_interval (seconds)} = \frac{4n}{r/3600}

LANGUAGE: math
CODE:
\begin{aligned}
    \text{where:} \\
    n &= \text{number of repositories} \\
    r &= \text{hourly rate limit} \\
\end{aligned}

----------------------------------------

TITLE: Configuring SSH Check Receiver in YAML
DESCRIPTION: Example configuration for the SSH Check Receiver. It specifies the endpoint, username, password, and collection interval for connecting to an SSH server.

LANGUAGE: yaml
CODE:
receivers:
  sshcheck:
    endpoint: localhost:2222
    username: otelu
    password: $OTELP
    collection_interval: 60s

----------------------------------------

TITLE: Custom ID Configuration in YAML
DESCRIPTION: Shows how to use custom IDs in operator sequences while maintaining the same functionality. Demonstrates the flexibility of operator naming and relationships.

LANGUAGE: yaml
CODE:
receivers:
  filelog:
    include: my-log.json
    operators:
      - type: json_parser
        id: my_json_parser
        output: my_remove
      - type: remove
        id: my_remove
        field: attributes.foo
        output: my_add
      - type: add
        id: my_add
        key: attributes.bar
        value: baz

----------------------------------------

TITLE: Sending Logs to TCP Input Using Netcat
DESCRIPTION: A bash command demonstrating how to send log messages to the configured TCP input using netcat (nc).

LANGUAGE: bash
CODE:
$ nc localhost 54525 <<EOF
heredoc> message1
heredoc> message2
heredoc> EOF

----------------------------------------

TITLE: JSON Log Encoding with Inline Attributes Example
DESCRIPTION: Demonstrates the body_with_inline_attributes mode output format which combines log body, resource attributes, and log attributes into a single JSON array. Each log entry includes the body content along with any associated resource and log attributes as separate fields.

LANGUAGE: json
CODE:
[
  {
    "body": {
      "log": "test"
    },
    "resourceAttributes": {
      "test": "logs-test"
    },
    "logAttributes": {
      "foo": "bar"
    }
  },
  {
    "body": "log testing",
    "resource": {
      "test": "logs-test"
    }
  }
]

----------------------------------------

TITLE: Filtering Entries with Regex Pattern in YAML
DESCRIPTION: This snippet demonstrates how to configure the filter operator to drop entries based on a regular expression pattern matching the message body.

LANGUAGE: yaml
CODE:
- type: filter
  expr: 'body.message matches "^LOG: .* END$"'
  output: my_output

----------------------------------------

TITLE: Disabling a Specific Flink Metric in YAML Configuration
DESCRIPTION: This YAML configuration snippet demonstrates how to disable a specific metric in Flink. Replace <metric_name> with the name of the metric you want to disable.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Parsing RFC5424 Log Record with Structured Data in JSON
DESCRIPTION: Example of a more complex input log record in JSON format for RFC5424 syslog protocol. It includes structured data and additional attributes used by the Syslog exporter.

LANGUAGE: json
CODE:
{
  "body": "",
  "timeUnixNano": 1438811939693012000,
  "attributes":
  {
    "appname": "SecureAuth0",
    "hostname": "192.168.2.132",
    "message": "Found the user for retrieving user's profile",
    "msg_id": "ID52020",
    "priority": 86,
    "proc_id": "23108",
    "structured_data":
    {
      "SecureAuth@27389":
      {
        "UserHostAddress":"192.168.2.132",
        "Realm":"SecureAuth0",
        "UserID":"Tester2",
        "PEN":"27389"
      }
    },
    "version": 1
  }
}

----------------------------------------

TITLE: Configuring Attribute Hints for Loki Labels
DESCRIPTION: YAML configuration showing how to use attribute processors to set hints for converting OTLP attributes to Loki labels.

LANGUAGE: yaml
CODE:
processors:
  attributes:
    actions:
      - action: insert
        key: loki.attribute.labels
        value: event.domain, event.name

  resource:
    attributes:
      - action: insert
        key: loki.resource.labels
        value: service.name, service.namespace

----------------------------------------

TITLE: Debug Logging Configuration for OTTL
DESCRIPTION: YAML configuration to enable debug logging for OTTL troubleshooting in the collector.

LANGUAGE: yaml
CODE:
service:
  telemetry:
    logs:
      level: debug

----------------------------------------

TITLE: Configuring Trace Parser Operator
DESCRIPTION: Example configuration for the dedicated trace_parser operator that directly maps trace context fields from attributes without requiring regex patterns.

LANGUAGE: yaml
CODE:
- type: trace_parser
  trace_id:
    parse_from: attributes.trace_id
  span_id:
    parse_from: attributes.span_id
  trace_flags:
    parse_from: attributes.trace_flags

----------------------------------------

TITLE: Compiling and Running telemetrygen for Testing (Bash)
DESCRIPTION: These commands compile the telemetrygen tool, copy it to the secure-tracing directory, and run it to send a test trace. It uses TLS and client certificate authentication.

LANGUAGE: bash
CODE:
$ cd cmd/telemetrygen
$ go build . 
$ cp telemetrygen ../../examples/secure-tracing
$ cd examples/secure-tracing
$ chmod +x telemetrygen
$ ./telemetrygen traces --traces 1 --otlp-endpoint 127.0.0.1:10000 --ca-cert 'certs/ca.crt' --mtls --client-cert 'certs/tracing-client.crt' --client-key 'certs/tracing-client.key'

----------------------------------------

TITLE: Configuring Zookeeper Receiver in YAML
DESCRIPTION: Example configuration for setting up the Zookeeper receiver with custom endpoint, collection interval, and initial delay settings. The receiver connects to a Zookeeper instance to collect metrics using the mntr command.

LANGUAGE: yaml
CODE:
receivers:
  zookeeper:
    endpoint: "localhost:2181"
    collection_interval: 20s
    initial_delay: 1s

----------------------------------------

TITLE: Enabling Optional Elasticsearch Metrics in YAML
DESCRIPTION: YAML configuration snippet for enabling optional Elasticsearch metrics.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: true

----------------------------------------

TITLE: Redis Server Information Output
DESCRIPTION: Output from Redis INFO command showing server configuration, memory usage, persistence status, CPU stats, cluster status, keyspace metrics and command statistics.

LANGUAGE: redis
CODE:
# Server
redis_version:5.0.7
redis_git_sha1:00000000
redis_git_dirty:0
redis_build_id:825c96d6c798641
redis_mode:standalone
os:Linux 4.19.76-linuxkit x86_64
arch_bits:64
multiplexing_api:epoll
atomicvar_api:atomic-builtin
gcc_version:8.3.0
process_id:1
run_id:a3c8e3547fa3f13672342d4ce489e6061ff14c7d
tcp_port:6379
uptime_in_seconds:104946
uptime_in_days:1
hz:10
configured_hz:10
lru_clock:6474178
executable:/data/redis-server
config_file:

# Clients
connected_clients:1
client_recent_max_input_buffer:2
client_recent_max_output_buffer:0
blocked_clients:0

# Memory
used_memory:854160
used_memory_human:834.14K
used_memory_rss:5562368
used_memory_rss_human:5.30M
used_memory_peak:875064
used_memory_peak_human:854.55K
used_memory_peak_perc:97.61%
used_memory_overhead:840958
used_memory_startup:791264
used_memory_dataset:13202
used_memory_dataset_perc:20.99%
allocator_allocated:862792
allocator_active:1073152
allocator_resident:8687616
total_system_memory:2086154240
total_system_memory_human:1.94G
used_memory_lua:37888
used_memory_lua_human:37.00K
used_memory_scripts:0
used_memory_scripts_human:0B
number_of_cached_scripts:0
maxmemory:0
maxmemory_human:0B
maxmemory_policy:noeviction
allocator_frag_ratio:1.24
allocator_frag_bytes:210360
allocator_rss_ratio:8.10
allocator_rss_bytes:7614464
rss_overhead_ratio:0.64
rss_overhead_bytes:-3125248
mem_fragmentation_ratio:7.03
mem_fragmentation_bytes:4771088
mem_not_counted_for_evict:0
mem_replication_backlog:0
mem_clients_slaves:0
mem_clients_normal:49694
mem_aof_buffer:0
mem_allocator:jemalloc-5.1.0
active_defrag_running:0
lazyfree_pending_objects:0

# Persistence
loading:0
rdb_changes_since_last_save:0
rdb_bgsave_in_progress:0
rdb_last_save_time:1583427536
rdb_last_bgsave_status:ok
rdb_last_bgsave_time_sec:-1
rdb_current_bgsave_time_sec:-1
rdb_last_cow_size:0
aof_enabled:0
aof_rewrite_in_progress:0
aof_rewrite_scheduled:0
aof_last_rewrite_time_sec:-1
aof_current_rewrite_time_sec:-1
aof_last_bgrewrite_status:ok
aof_last_write_status:ok
aof_last_cow_size:0

# Stats
total_connections_received:28
total_commands_processed:30
instantaneous_ops_per_sec:0
total_net_input_bytes:8407
total_net_output_bytes:26604
instantaneous_input_kbps:0.00
instantaneous_output_kbps:0.00
rejected_connections:0
sync_full:0
sync_partial_ok:0
sync_partial_err:0
expired_keys:0
expired_stale_perc:0.00
expired_time_cap_reached_count:0
evicted_keys:0
keyspace_hits:0
keyspace_misses:0
pubsub_channels:0
pubsub_patterns:0
latest_fork_usec:0
migrate_cached_sockets:0
slave_expires_tracked_keys:0
active_defrag_hits:0
active_defrag_misses:0
active_defrag_key_hits:0
active_defrag_key_misses:0

# Replication
role:master
connected_slaves:0
master_replid:29fed19c4c45f24e289b2ac7917131fd4a9326e0
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:0
second_repl_offset:-1
repl_backlog_active:0
repl_backlog_size:1048576
repl_backlog_first_byte_offset:0
repl_backlog_histlen:0

# CPU
used_cpu_sys:185.649184
used_cpu_user:46.396430
used_cpu_sys_children:0.002354
used_cpu_user_children:0.001619
used_cpu_sys_main_thread:180.0
used_cpu_user_main_thread:42.39

# Cluster
cluster_enabled:0

# Keyspace
db0:keys=1,expires=2,avg_ttl=3
db1:keys=4,expires=5,avg_ttl=6
db3:keys=5,expires=10,avg_ttl=85

# Commandstats
cmdstat_ssubscribe:calls=0,usec=0,usec_per_call=0.00,rejected_calls=3,failed_calls=0
cmdstat_zrem:calls=641,usec=1884,usec_per_call=2.94,rejected_calls=0,failed_calls=0
cmdstat_incrbyfloat:calls=50340,usec=902409,usec_per_call=17.93,rejected_calls=0,failed_calls=0
cmdstat_lrange:calls=12495,usec=48886,usec_per_call=3.91,rejected_calls=0,failed_calls=14
cmdstat_mset:calls=4505,usec=65693,usec_per_call=14.58,rejected_calls=0,failed_calls=3

----------------------------------------

TITLE: Basic Field Renaming Example
DESCRIPTION: Demonstrates renaming a field within the body object from key1 to key3

LANGUAGE: yaml
CODE:
- type: move
  from: body.key1
  to: body.key3

LANGUAGE: json
CODE:
{
  "resource": { },
  "attributes": { },
  "body": {
    "key1": "val1",
    "key2": "val2"
  }
}

----------------------------------------

TITLE: Configuring Elasticsearch Metrics in YAML
DESCRIPTION: YAML configuration snippet for enabling or disabling specific Elasticsearch metrics.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Pipeline Configuration with SignalFx
DESCRIPTION: Example of setting up complete pipeline configuration with SignalFx components for metrics, logs and traces.

LANGUAGE: yaml
CODE:
service:
  pipelines:
    metrics:
      receivers: [signalfx]
      processors: [memory_limiter, batch]
      exporters: [signalfx]
    logs:
      receivers: [signalfx]
      processors: [memory_limiter, batch]
      exporters: [signalfx]
    traces:
      receivers: [zipkin]
      processors: []
      exporters: [signalfx]

----------------------------------------

TITLE: Configuring Metric Collection in YAML
DESCRIPTION: Example YAML configuration to disable a specific metric collection in vCenter monitoring

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Redis Receiver Configuration Schema
DESCRIPTION: Detailed markdown schema documentation that outlines all available configuration options for the Redis receiver, including TLS settings, metric configurations, and network connection parameters.

LANGUAGE: markdown
CODE:
# Redis Receiver Reference\n\nScraperControllerSettings defines common settings for a scraper controller\nconfiguration. Scraper controller receivers can embed this struct\nand extend it with more fields if needed.\n\n### redisreceiver-Config\n\n| Name | Field Info | Default | Docs |\n| ---- | --------- | ------- | ---- |\n| collection_interval |[time-Duration](#time-Duration)| 10s |  |\n| endpoint |string|  | Endpoint configures the address for this network connection... |

----------------------------------------

TITLE: Flattening Nested Object
DESCRIPTION: Example showing how to flatten an object nested within another object using the flatten operator. Demonstrates moving nested fields up one level while preserving the parent wrapper object.

LANGUAGE: yaml
CODE:
- type: flatten
  field: body.wrapper.key1

LANGUAGE: json
CODE:
{
  "resource": { },
  "attributes": { },
  "body": {
    "wrapper": {
      "key1": {
        "nested1": "nestedval1",
        "nested2": "nestedval2"
      },
      "key2": "val2"
    }
  }
}

LANGUAGE: json
CODE:
{
  "resource": { },
  "attributes": { },
  "body": {
    "wrapper": {
      "nested1": "nestedval1",
      "nested2": "nestedval2",
      "key2": "val2"
    }
  }
}

----------------------------------------

TITLE: Dynamic ECS Attribute Mapping Configuration
DESCRIPTION: Example transform processor configuration for setting dynamic document IDs

LANGUAGE: yaml
CODE:
processors:
  transform/es-doc-id:
    error_mode: ignore
    log_statements:
      - context: log
        condition: attributes["event_name"] != null && attributes["event_creation_time"] != null
        statements:
          - set(attributes["elasticsearch.document_id"], Concat(["log", attributes["event_name"], attributes["event_creation_time"], "-"]))

----------------------------------------

TITLE: Configuring Timestamp Parsing in Time Parser
DESCRIPTION: This snippet demonstrates how to configure timestamp parsing directly in a time_parser operator. It specifies the field to parse from, the layout type, and the timestamp format.

LANGUAGE: yaml
CODE:
- type: time_parser
  parse_from: body.timestamp_field
  layout_type: strptime
  layout: '%Y-%m-%d'

----------------------------------------

TITLE: Removing All Attributes using YAML Configuration
DESCRIPTION: This example demonstrates how to remove all attributes from a record using the 'remove' operator.

LANGUAGE: yaml
CODE:
- type: remove
  field: attributes

----------------------------------------

TITLE: Configuring Custom Chrony Receiver Settings in YAML
DESCRIPTION: Example of a custom Chrony receiver configuration specifying endpoint, timeout, collection interval, and specific metrics to enable. Shows how to selectively enable metrics like ntp.skew and ntp.stratum.

LANGUAGE: yaml
CODE:
receivers:
  chrony:
    endpoint: unix:///var/run/chrony/chronyd.sock
    timeout: 10s
    collection_interval: 30s
    metrics:
      ntp.skew:
        enabled: true
      ntp.stratum:
        enabled: true

----------------------------------------

TITLE: Configuring ECS Task Observer and Receiver Creator in YAML
DESCRIPTION: This snippet demonstrates how to configure the ECS Task Observer extension and use it with a Receiver Creator to detect and monitor Redis containers in an ECS task.

LANGUAGE: yaml
CODE:
extensions:
  ecs_task_observer:
    endpoint: http://my.task.metadata.endpoint
    port_labels: [A_DOCKER_LABEL_CONTAINING_DESIRED_PORT, ANOTHER_DOCKER_LABEL_CONTAINING_DESIRED_PORT]
    refresh_interval: 10s

receivers:
  receiver_creator:
    receivers:
      redis:
        rule: type == "container" && name matches "redis"
        config:
          password: `container.labels["SECRET"]`
    watch_observers: [ecs_task_observer]

----------------------------------------

TITLE: Configuring Process Metrics in YAML
DESCRIPTION: Configuration example showing how to disable specific process metrics in the OpenTelemetry Collector. The configuration allows individual metrics to be enabled or disabled using a boolean flag.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Configuring Sumo Logic Extension in YAML
DESCRIPTION: Example configuration for the Sumo Logic extension, including authentication setup and pipeline configuration for metrics collection and export.

LANGUAGE: yaml
CODE:
extensions:
  sumologic:
    installation_token: <token>
    collector_name: my_collector
    time_zone: Europe/Warsaw

receivers:
  hostmetrics:
    collection_interval: 30s
    scrapers:
      load:

processors:

exporters:
  sumologic:
    auth:
      authenticator: sumologic # Specify the name of the authenticator extension

service:
  extensions: [sumologic]
  pipelines:
    metrics:
      receivers: [hostmetrics]
      processors: []
      exporters: [sumologic]

----------------------------------------

TITLE: Sending UDP Log Messages with Netcat
DESCRIPTION: Example of sending log messages to the UDP input using netcat (nc) command.

LANGUAGE: bash
CODE:
$ nc -u localhost 54525 <<EOF
heredoc> message1
heredoc> message2
heredoc> EOF

----------------------------------------

TITLE: Visualizing Daemonset-stdout Mode Architecture with ASCII Diagram
DESCRIPTION: ASCII diagram showing the architecture and data flow for the daemonset-stdout mode of the k8slogreceiver, illustrating how metadata and log paths are obtained and processed.

LANGUAGE: plaintext
CODE:
 k8sapi         docker/cri-containerd
                                      
       Source    
  medatada                 logPath, env
            
                   assosiate
                  
            
               Reader     
            
                   read files from logPath
                  
                files

----------------------------------------

TITLE: Configuring Fault Tolerant Log Collection in OpenTelemetry Collector (YAML)
DESCRIPTION: This snippet references a YAML configuration file that demonstrates a full setup for fault-tolerant log collection. It uses the filestorage extension for offset tracking and the exporterhelper persistent-queue for ensuring log delivery across Collector restarts.

LANGUAGE: yaml
CODE:
./otel-col-config.yaml

----------------------------------------

TITLE: Configuring TCP Syslog Receiver in OpenTelemetry
DESCRIPTION: Basic configuration for receiving RFC5424 format syslogs over TCP connection on port 54526.

LANGUAGE: yaml
CODE:
receivers:
  syslog:
    tcp:
      listen_address: "0.0.0.0:54526"
    protocol: rfc5424

----------------------------------------

TITLE: Configuring Log DeDuplication Processor in YAML
DESCRIPTION: Example configuration for the log deduplication processor with a 60-second aggregation interval, 'America/Los_Angeles' timezone, and 'dedup_count' as the log count attribute.

LANGUAGE: yaml
CODE:
receivers:
    filelog:
        include: [./example/*.log]
processors:
    logdedup:
        interval: 60s
        log_count_attribute: dedup_count
        timezone: 'America/Los_Angeles'
exporters:
    googlecloud:

service:
    pipelines:
        logs:
            receivers: [filelog]
            processors: [logdedup]
            exporters: [googlecloud]

----------------------------------------

TITLE: Parsing SQL Server Database I/O Metrics JSON
DESCRIPTION: This JSON structure contains an array of objects, each representing I/O metrics for a specific database file in a SQL Server instance. It includes details such as database name, file type, read/write statistics, and latency information.

LANGUAGE: JSON
CODE:
[
    {
        "database_name": "master",
        "file_type": "ROWS",
        "logical_filename": "master",
        "measurement": "sqlserver_database_io",
        "physical_filename": "/var/opt/mssql/data/master.mdf",
        "read_bytes": "4022272",
        "read_latency_ms": "62",
        "reads": "73",
        "rg_read_stall_ms": "0",
        "rg_write_stall_ms": "0",
        "sql_instance": "8cac97ac9b8f",
        "write_bytes": "4096000",
        "write_latency_ms": "130",
        "writes": "329"
    },
    ...
]

----------------------------------------

TITLE: Removing an Object from Body using YAML Configuration
DESCRIPTION: This example shows how to remove an entire object from the body of a record using the 'remove' operator.

LANGUAGE: yaml
CODE:
- type: remove
  field: body.object

----------------------------------------

TITLE: Complete Pipeline Configuration with CloudWatch Metrics
DESCRIPTION: Full example showing how to configure a metrics pipeline using the CloudWatch Metrics receiver with debug exporter.

LANGUAGE: yaml
CODE:
receivers:
  awscloudwatchmetrics:
    region: eu-west-1
    poll_interval: 10m
    metrics:
      named:
        - namespace: "AWS/EC2"
          metric_name: "CPUUtilization"
          period: "5m"
          aws_aggregation: "Sum"
          dimensions:
            - Name: "InstanceId"
              Value: "i-035e091c31292427a"

processors:

exporters:
  debug:
    verbosity: detailed

service:
  pipelines:
    metrics:
      receivers: [awscloudwatchmetrics]
      processors: []
      exporters: [debug]

----------------------------------------

TITLE: Removing All Resource Fields using YAML Configuration
DESCRIPTION: This configuration shows how to remove all resource fields from a record using the 'remove' operator.

LANGUAGE: yaml
CODE:
- type: remove
  field: resource

----------------------------------------

TITLE: Running Tests with Make Commands
DESCRIPTION: Shell commands for executing the test suites using make targets. Shows both full test execution and running specific test directories.

LANGUAGE: bash
CODE:
make e2e-test

TESTS_DIR=correctnesstests/metrics make e2e-test

----------------------------------------

TITLE: Defining Configuration Fields for Severity Parser in Markdown
DESCRIPTION: A markdown table detailing the configuration fields for the severity_parser operator, including field names, default values, and descriptions.

LANGUAGE: markdown
CODE:
| Field            | Default           | Description |
| ---              | ---               | ---         |
| `id`             | `severity_parser` | A unique identifier for the operator. |
| `output`         | Next in pipeline  | The `id` for the operator to send parsed entries to. |
| `parse_from`     | required          | The [field](../types/field.md) from which the value will be parsed. |
| `on_error`       | `send`            | The behavior of the operator if it encounters an error. See [on_error](../types/on_error.md). |
| `preset`         | `default`         | A predefined set of values that should be interpreted at specific severity levels. |
| `mapping`        |                   | A formatted set of values that should be interpreted as severity levels. |
| `overwrite_text` | `false`           | If `true`, the severity text will be set to the [standard short name](https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/logs/data-model.md#displaying-severity) corresponding to the severity number. |
| `if`             |                   | An [expression](../types/expression.md) that, when set, will be evaluated to determine whether this operator should be used for the given entry. This allows you to do easy conditional parsing without branching logic with routers. |

----------------------------------------

TITLE: Generating Certificates using Make (Makefile)
DESCRIPTION: This Makefile command is used to generate self-signed certificates for Envoy, OpenTelemetry Collector receiver, and tracing client using OpenSSL. It cleans previous certificates and generates new ones.

LANGUAGE: makefile
CODE:
$ cd certs
$ make clean && make all

----------------------------------------

TITLE: HAProxy Stats Sample Data
DESCRIPTION: Example HAProxy statistics data showing frontend, backend and server metrics including connection stats, health status, traffic volumes and error counts.

LANGUAGE: csv
CODE:
stats,FRONTEND,,,0,1,524268,2,1444,47008,0,0,0,,,,,OPEN,,,,,,,,,1,2,0,,,,0,0,0,1,,,,0,2,0,0,0,0,,0,1,2,,,0,0,0,0,,,,,,,,,,,,,,,,,,,,,http,,0,1,2,2,0,0,0,,,0,0,,,,,,,0,,,,,,,,,-,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,1594,47052,0,0
myfrontend,FRONTEND,,,1,1,524268,1,85470,107711,0,0,0,,,,,OPEN,,,,,,,,,1,3,0,,,,0,0,0,1,,,,0,134,0,0,0,0,,0,11,134,,,0,0,0,0,,,,,,,,,,,,,,,,,,,,,http,,0,1,1,0,0,0,0,,,0,0,,,,,,,0,,,,,,,,,-,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,134,94712,107309,0,0

----------------------------------------

TITLE: Parsing Query String with URI Parser in JSON
DESCRIPTION: This example shows the input and output JSON for parsing a query string using the uri_parser operator. It demonstrates how the operator handles multiple values for the same query parameter.

LANGUAGE: json
CODE:
{
  "timestamp": "",
  "body": {
    "query": "?request=681e6fc4-3314-4ccc-933e-4f9c9f0efd24&env=stage&env=dev"
  }
}

LANGUAGE: json
CODE:
{
  "timestamp": "",
  "body": {
    "query": {
      "env": [
        "stage",
        "dev"
      ],
      "request": [
        "681e6fc4-3314-4ccc-933e-4f9c9f0efd24"
      ]
    }
  }
}

----------------------------------------

TITLE: Importing Kubernetes Test Helpers in Go
DESCRIPTION: This snippet demonstrates how to import and use the Kubernetes test helpers package in a Go test file. It references the k8sattributes processor's e2e test as an example of usage.

LANGUAGE: go
CODE:
import (
    "testing"
    "github.com/open-telemetry/opentelemetry-collector-contrib/testbed/testbed"
    k8stest "github.com/open-telemetry/opentelemetry-collector-contrib/internal/k8stest"
)

func TestK8sAttributesProcessor(t *testing.T) {
    // Example usage of k8stest package
    // Refer to ../../processor/k8sattributesprocessor/e2e_test.go for full implementation
}

----------------------------------------

TITLE: Collecting Database I/O Performance Metrics in SQL Server
DESCRIPTION: This SQL script collects I/O performance metrics for all database files in SQL Server. It checks for server compatibility, adapts to different SQL Server versions, and uses dynamic SQL to gather statistics on read/write operations, latency, and file details. The script is designed to work with SQL Server Standard, Enterprise, and Express editions.

LANGUAGE: SQL
CODE:
SET DEADLOCK_PRIORITY -10;
IF SERVERPROPERTY('EngineEdition') NOT IN (2,3,4) BEGIN /*NOT IN Standard,Enterprise,Express*/
	DECLARE @ErrorMessage AS nvarchar(500) = 'Connection string Server:'+ @@ServerName + ',Database:' + DB_NAME() +' is not a SQL Server Standard,Enterprise or Express. This query is only supported on these editions.';
	RAISERROR (@ErrorMessage,11,1)
	RETURN
END

DECLARE
	 @SqlStatement AS nvarchar(max)
	,@MajorMinorVersion AS int = CAST(PARSENAME(CAST(SERVERPROPERTY('ProductVersion') AS nvarchar),4) AS int) * 100 + CAST(PARSENAME(CAST(SERVERPROPERTY('ProductVersion') AS nvarchar),3) AS int)
	,@Columns AS nvarchar(max) = ''
	,@Tables AS nvarchar(max) = ''
IF @MajorMinorVersion > 1100 BEGIN
	SET @Columns += N'
	,vfs.[io_stall_queued_read_ms] AS [rg_read_stall_ms]
	,vfs.[io_stall_queued_write_ms] AS [rg_write_stall_ms]'
END

SET @SqlStatement = N'
SELECT
	''sqlserver_database_io'' AS [measurement]
	,REPLACE(@@SERVERNAME,''\''',''':'') AS [sql_instance]
	,HOST_NAME() AS [computer_name]
	,DB_NAME(vfs.[database_id]) AS [database_name]
	,COALESCE(mf.[physical_name],''RBPEX'') AS [physical_filename]	--RPBEX = Resilient Buffer Pool Extension
	,COALESCE(mf.[name],''RBPEX'') AS [logical_filename]	--RPBEX = Resilient Buffer Pool Extension
	,mf.[type_desc] AS [file_type]
	,vfs.[io_stall_read_ms] AS [read_latency_ms]
	,vfs.[num_of_reads] AS [reads]
	,vfs.[num_of_bytes_read] AS [read_bytes]
	,vfs.[io_stall_write_ms] AS [write_latency_ms]
	,vfs.[num_of_writes] AS [writes]
	,vfs.[num_of_bytes_written] AS [write_bytes]'
	+ @Columns + N'
FROM sys.dm_io_virtual_file_stats(NULL, NULL) AS vfs
INNER JOIN sys.master_files AS mf WITH (NOLOCK)
	ON vfs.[database_id] = mf.[database_id] AND vfs.[file_id] = mf.[file_id]
'
+ @Tables;

EXEC sp_executesql @SqlStatement

----------------------------------------

TITLE: Configuring Kafka Metrics in YAML
DESCRIPTION: Example YAML configuration for disabling a specific Kafka metric in the OpenTelemetry Collector.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Configuring Routing Connector in YAML
DESCRIPTION: Example configuration for the routing connector, which is the recommended replacement for the routing processor. It demonstrates routing traces based on a tenant header to different Jaeger exporters using OTTL conditions.

LANGUAGE: yaml
CODE:
connectors:
  routing:
    match_once: true
    default_pipelines: [traces/jaeger]
    table:
    - context: request
      condition: request["X-Tenant"] == "acme"
      pipelines: [traces/jaeger/acme]
exporters:
  jaeger:
    endpoint: localhost:14250
  jaeger/acme:
    endpoint: localhost:24250
service:
  pipelines:
    traces:
      receivers: [otlp]
      exporters: [routing]
    traces/jaeger:
      receivers: [routing]
      exporters: [jaeger]
    traces/jaeger/acme:
      receivers: [routing]
      exporters: [jaeger/acme]

----------------------------------------

TITLE: Visualizing K8slogreceiver Architecture with ASCII Diagram
DESCRIPTION: ASCII diagram illustrating the high-level architecture of the k8slogreceiver, showing the interaction between the Kubernetes API, Docker API, CRI API, Source, Poller, and Reader components.

LANGUAGE: plaintext
CODE:
   K8s
   API 
            
 Docker     
  API  
           
Cri        
API   
          
          
             
        Source       Poller  
             
                                 
                                  
                                 
                 
      Reader       
    

----------------------------------------

TITLE: Enabling Optional Kafka Metrics in YAML
DESCRIPTION: Example YAML configuration for enabling an optional Kafka metric in the OpenTelemetry Collector.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: true

----------------------------------------

TITLE: High Availability Solace Receiver Configuration
DESCRIPTION: Advanced configuration example demonstrating high availability setup with primary and backup brokers. Shows how to configure multiple Solace receivers with SASL plain authentication for redundancy.

LANGUAGE: yaml
CODE:
receivers:
  solace/primary:
    broker: [myHost-primary:5671]
    auth:
      sasl_plain:
        username: otel
        password: otel01$
    queue: queue://#telemetry-profile123

  solace/backup:
    broker: [myHost-backup:5671]
    auth:
      sasl_plain:
        username: otel
        password: otel01$
    queue: queue://#telemetry-profile123

service:
  pipelines:
    traces/solace:
      receivers: [solace/primary,solace/backup]

----------------------------------------

TITLE: Configuring Cumulative to Delta Processor with Regex and Metric Type Filtering in YAML
DESCRIPTION: This YAML configuration example demonstrates how to set up the Cumulative to Delta Processor to convert cumulative sum metrics to delta metrics using both a regular expression match and metric type filtering.

LANGUAGE: yaml
CODE:
processors:
    # processor name: cumulativetodelta
    cumulativetodelta:

        # Convert cumulative sum metrics to delta
        # if and only if 'metric' is in the name
        include:
            metrics:
                - ".*metric.*"
            match_type: regexp
            metric_types:
              - sum

----------------------------------------

TITLE: HAProxy Stats CSV Column Definition
DESCRIPTION: Header line defining all possible columns in HAProxy stats CSV output format. Includes metrics for queues, sessions, bytes, errors, health checks, HTTP responses, and more.

LANGUAGE: csv
CODE:
pxname,svname,qcur,qmax,scur,smax,slim,stot,bin,bout,dreq,dresp,ereq,econ,eresp,wretr,wredis,status,weight,act,bck,chkfail,chkdown,lastchg,downtime,qlimit,pid,iid,sid,throttle,lbtot,tracked,type,rate,rate_lim,rate_max,check_status,check_code,check_duration,hrsp_1xx,hrsp_2xx,hrsp_3xx,hrsp_4xx,hrsp_5xx,hrsp_other,hanafail,req_rate,req_rate_max,req_tot,cli_abrt,srv_abrt,comp_in,comp_out,comp_byp,comp_rsp,lastsess,last_chk,last_agt,qtime,ctime,rtime,ttime,agent_status,agent_code,agent_duration,check_desc,agent_desc,check_rise,check_fall,check_health,agent_rise,agent_fall,agent_health,addr,cookie,mode,algo,conn_rate,conn_rate_max,conn_tot,intercepted,dcon,dses,wrew,connect,reuse,cache_lookups,cache_hits,srv_icur,src_ilim,qtime_max,ctime_max,rtime_max,ttime_max,eint,idle_conn_cur,safe_conn_cur,used_conn_cur,need_conn_est,uweight,agg_server_status,agg_server_check_status,agg_check_status,-,ssl_sess,ssl_reused_sess,ssl_failed_handshake,h2_headers_rcvd,h2_data_rcvd,h2_settings_rcvd,h2_rst_stream_rcvd,h2_goaway_rcvd,h2_detected_conn_protocol_errors,h2_detected_strm_protocol_errors,h2_rst_stream_resp,h2_goaway_resp,h2_open_connections,h2_backend_open_streams,h2_total_connections,h2_backend_total_streams,h1_open_connections,h1_open_streams,h1_total_connections,h1_total_streams,h1_bytes_in,h1_bytes_out,h1_spliced_bytes_in,h1_spliced_bytes_out

----------------------------------------

TITLE: Configuring Linear Operator Sequence in YAML
DESCRIPTION: Basic example of a linear operator sequence that reads JSON logs, removes an attribute, and adds a new attribute. Shows the fundamental structure of operator configuration in a filelog receiver.

LANGUAGE: yaml
CODE:
receivers:
  filelog:
    include: my-log.json
    operators:
      - type: json_parser
      - type: remove
        field: attributes.foo
      - type: add
        key: attributes.bar
        value: baz

----------------------------------------

TITLE: Parsing Relative URI with URI Parser in JSON
DESCRIPTION: This example illustrates the input and output JSON for parsing a relative URI using the uri_parser operator. It demonstrates how the operator handles URIs without a scheme or host.

LANGUAGE: json
CODE:
{
  "timestamp": "",
  "body": {
    "message": "/app?user=admin"
  }
}

LANGUAGE: json
CODE:
{
  "timestamp": "",
  "body": {
    "path": "/app",
    "query": {
      "user": [
        "admin"
      ]
    }
  }
}

----------------------------------------

TITLE: Custom Collection Interval Configuration
DESCRIPTION: Configuration example showing how to set a custom 40-second collection interval for ECS metrics.

LANGUAGE: yaml
CODE:
receivers:
  awsecscontainermetrics:
      collection_interval: 40s
exporters:
  awsemf:
      namespace: 'ECS/ContainerMetrics/OpenTelemetry'
      log_group_name: '/ecs/containermetrics/opentelemetry'

service:
  pipelines:
      metrics:
          receivers: [awsecscontainermetrics]
          exporters: [awsemf]

----------------------------------------

TITLE: Configuring Azure Monitor Receiver with Managed Identity Authentication
DESCRIPTION: Example configuration for the Azure Monitor Receiver using Managed Identity authentication. It includes subscription ID and optional client ID.

LANGUAGE: yaml
CODE:
receivers:
  azuremonitor:
    subscription_id: "${subscription_id}"
    auth: "managed_identity"
    client_id: "${env:AZURE_CLIENT_ID}"

----------------------------------------

TITLE: AWS X-Ray Local Subsegment JSON Structure
DESCRIPTION: Defines the structure of a local namespace subsegment in AWS X-Ray tracing. Contains fields for identification (name, id, trace_id, parent_id), timing (start_time, end_time), and configuration (type, namespace, traced).

LANGUAGE: json
CODE:
{
    "name": "localNamespaceTest",
    "id": "53995c3f42cd8ad8",
    "start_time": 1478293361.271,
    "end_time": 1478293361.449,
    "type": "subsegment",
    "trace_id": "1-581cf771-a006649127e371903a2de979",
    "parent_id": "defdfd9912dc5a56",
    "namespace": "local",
    "traced": true
}

----------------------------------------

TITLE: Defining ECS Task Metadata in JSON
DESCRIPTION: This JSON object defines the metadata for an Amazon ECS task, including cluster information, container details, networking configuration, and host information. It provides a comprehensive overview of the task's runtime environment and configuration.

LANGUAGE: json
CODE:
{
    "Cluster": "default",
    "ContainerInstanceARN": "arn:aws:ecs:us-west-50:012345678910:container-instance/default/1f73d099-b914-411c-a9ff-81633b7741dd",
    "TaskARN": "invalid arn",
    "TaskDefinitionFamily": "console-sample-app-static",
    "TaskDefinitionRevision": "1",
    "ContainerID": "aec2557997f4eed9b280c2efd7afccdcedfda4ac399f7480cae870cfc7e163fd",
    "ContainerName": "simple-app",
    "DockerContainerName": "/ecs-console-sample-app-static-1-simple-app-e4e8e495e8baa5de1a00",
    "ImageID": "sha256:2ae34abc2ed0a22e280d17e13f9c01aaf725688b09b7a1525d1a2750e2c0d1de",
    "ImageName": "httpd:2.4",
    "PortMappings": [
        {
            "ContainerPort": 80,
            "HostPort": 80,
            "BindIp": "0.0.0.0",
            "Protocol": "tcp"
        }
    ],
    "Networks": [
        {
            "NetworkMode": "bridge",
            "IPv4Addresses": [
                "192.0.2.0"
            ]
        }
    ],
    "MetadataFileStatus": "READY",
    "AvailabilityZone": "us-east-1b",
    "HostPrivateIPv4Address": "192.0.2.0",
    "HostPublicIPv4Address": "203.0.113.0"
}

----------------------------------------

TITLE: Configuring AWS X-Ray Trace Data Structure in JSON
DESCRIPTION: Defines the structure of an AWS X-Ray trace including trace ID, span ID, timing, HTTP details, AWS SDK version, and service compiler information. The configuration captures both request and response data for HTTP transactions along with service metadata.

LANGUAGE: json
CODE:
{
    "trace_id": "1-5f2aebcc-b475d14618c51eaa28753d37",
    "id": "bda182a644eee9b3",
    "name": "SampleServer",
    "end_time": 1596648396.6401389,
    "http": {
        "request": {
            "method": "GET",
            "url": "http://localhost:8000/",
            "client_ip": "127.0.0.1",
            "user_agent": "Go-http-client/1.1",
            "x_forwarded_for": true
        },
        "response": {
            "status": 200
        }
    },
    "aws": {
        "xray": {
            "sdk_version": "1.1.0",
            "sdk": "X-Ray for Go"
        }
    },
    "service": {
        "compiler_version": "go1.14.6",
        "compiler": "gc"
    },
    "Dummy": false
}

----------------------------------------

TITLE: Configuring UDP Input Operator in YAML
DESCRIPTION: A simple configuration example for the udp_input operator, specifying the listen address.

LANGUAGE: yaml
CODE:
- type: udp_input
  listen_address: "0.0.0.0:54526"

----------------------------------------

TITLE: Running Load-Balancing Exporter Demo with Docker Compose
DESCRIPTION: This command starts the demo using Docker Compose. It should be run from the exporter/loadbalancingexporter/example directory.

LANGUAGE: shell
CODE:
docker-compose up

----------------------------------------

TITLE: Configuring Cloud Foundry Receiver in YAML
DESCRIPTION: Example configuration for the Cloud Foundry receiver showing how to set up RLP gateway and UAA authentication settings.

LANGUAGE: yaml
CODE:
receivers:
  cloudfoundry:
    rlp_gateway:
      endpoint: "https://log-stream.sys.example.internal"
      tls:
        insecure_skip_verify: false
      shard_id: "opentelemetry"
    uaa:
      endpoint: "https://uaa.sys.example.internal"
      tls:
        insecure_skip_verify: false
      username: "otelclient"
      password: "changeit"

----------------------------------------

TITLE: Required IAM Permissions
DESCRIPTION: YAML configuration showing the required IAM permissions for the CloudWatch Metrics receiver to function properly.

LANGUAGE: yaml
CODE:
"cloudwatch:GetMetricData",
"cloudwatch:GetMetricStatistics",
"cloudwatch:ListMetrics"

----------------------------------------

TITLE: Adding a Value to Resource Using Expression in YAML Configuration
DESCRIPTION: This example shows how to add a value to the resource using an expression. The expression concatenates an existing body value with a suffix.

LANGUAGE: yaml
CODE:
- type: add
  field: resource.key2
  value: EXPR(body.key1 + "_suffix")

----------------------------------------

TITLE: Configuring Windows Event Log Input in YAML
DESCRIPTION: Basic configuration example showing how to set up the windows_eventlog_input operator to monitor the application channel.

LANGUAGE: yaml
CODE:
- type: windows_eventlog_input
  channel: application

----------------------------------------

TITLE: Configuring Apache Web Server Receiver in YAML
DESCRIPTION: Basic configuration example for the Apache Web Server receiver showing how to specify the endpoint for collecting server statistics. The receiver requires Apache Web Server 2.4+ and the mod_status module enabled.

LANGUAGE: yaml
CODE:
receivers:
  apache:
    endpoint: "http://localhost:8080/server-status?auto"

----------------------------------------

TITLE: Permission Test Command for Journald Access
DESCRIPTION: Shell command to test if the OpenTelemetry Collector user has sufficient permissions to access journal logs.

LANGUAGE: sh
CODE:
sudo su -s /bin/bash -c 'journalctl --lines 5' otelcol-contrib

----------------------------------------

TITLE: Collecting SQL Server Performance Counters
DESCRIPTION: Complex T-SQL query that collects performance metrics from sys.dm_os_performance_counters. The script includes version checking, deadlock priority setting, and aggregates multiple performance counter categories into a standardized output format. Includes checks for SQL Server edition compatibility.

LANGUAGE: tsql
CODE:
SET DEADLOCK_PRIORITY -10;
IF SERVERPROPERTY('EngineEdition') NOT IN (2,3,4) BEGIN /*NOT IN Standard,Enterprise,Express*/
	DECLARE @ErrorMessage AS nvarchar(500) = 'Connection string Server:'+ @@ServerName + ',Database:' + DB_NAME() +' is not a SQL Server Standard, Enterprise or Express. This query is only supported on these editions.';
	RAISERROR (@ErrorMessage,11,1)
	RETURN
END

DECLARE
	 @SqlStatement AS nvarchar(max)
	,@MajorMinorVersion AS int = CAST(PARSENAME(CAST(SERVERPROPERTY('ProductVersion') AS nvarchar),4) AS int)*100 + CAST(PARSENAME(CAST(SERVERPROPERTY('ProductVersion') AS nvarchar),3) AS int)

DECLARE @PCounters TABLE
(
	 [object_name] nvarchar(128)
	,[counter_name] nvarchar(128)
	,[instance_name] nvarchar(128)
	,[cntr_value] bigint
	,[cntr_type] int
	PRIMARY KEY([object_name], [counter_name], [instance_name])
);

WITH PerfCounters AS (
SELECT DISTINCT
	 RTRIM(spi.[object_name]) [object_name]
	,RTRIM(spi.[counter_name]) [counter_name]
	,RTRIM(spi.[instance_name]) AS [instance_name]
	,CAST(spi.[cntr_value] AS bigint) AS [cntr_value]
	,spi.[cntr_type]
	FROM sys.dm_os_performance_counters AS spi
	WHERE
		counter_name IN (
			 'SQL Compilations/sec'
			,'SQL Re-Compilations/sec'
			,'User Connections'
			,'Batch Requests/sec'
			,'Logouts/sec'
			,'Logins/sec'
			,'Processes blocked'
			,'Latch Waits/sec'
			,'Average Latch Wait Time (ms)'
			,'Full Scans/sec'
			,'Index Searches/sec'
			,'Page Splits/sec'
			,'Page lookups/sec'
			,'Page reads/sec'
			,'Page writes/sec'
			,'Readahead pages/sec'
			,'Lazy writes/sec'
			,'Checkpoint pages/sec'
			,'Table Lock Escalations/sec'
			,'Page life expectancy'
			,'Log File(s) Size (KB)'
			,'Log File(s) Used Size (KB)'
			,'Data File(s) Size (KB)'
			,'Transactions/sec'
			,'Write Transactions/sec'
			,'Active Transactions'
			,'Log Growths'
			,'Active Temp Tables'
			,'Logical Connections'
			,'Temp Tables Creation Rate'
			,'Temp Tables For Destruction'
			,'Free Space in tempdb (KB)'
			,'Version Store Size (KB)'
			,'Memory Grants Pending'
			,'Memory Grants Outstanding'
			,'Free list stalls/sec'
			,'Buffer cache hit ratio'
			,'Buffer cache hit ratio base'
			,'Database Pages'
			,'Backup/Restore Throughput/sec'
			,'Total Server Memory (KB)'
			,'Target Server Memory (KB)'
			,'Log Flushes/sec'
			,'Log Flush Wait Time'
			,'Memory broker clerk size'
			,'Log Bytes Flushed/sec'
			,'Bytes Sent to Replica/sec'
			,'Log Send Queue'
			,'Bytes Sent to Transport/sec'
			,'Sends to Replica/sec'
			,'Bytes Sent to Transport/sec'
			,'Sends to Transport/sec'
			,'Bytes Received from Replica/sec'
			,'Receives from Replica/sec'
			,'Flow Control Time (ms/sec)'
			,'Flow Control/sec'
			,'Resent Messages/sec'
			,'Redone Bytes/sec'
			,'XTP Memory Used (KB)'
			,'Transaction Delay'
			,'Log Bytes Received/sec'
			,'Log Apply Pending Queue'
			,'Redone Bytes/sec'
			,'Recovery Queue'
			,'Log Apply Ready Queue'
			,'CPU usage %'
			,'CPU usage % base'
			,'Queued requests'
			,'Requests completed/sec'
			,'Blocked tasks'
			,'Active memory grant amount (KB)'
			,'Disk Read Bytes/sec'
			,'Disk Read IO Throttled/sec'
			,'Disk Read IO/sec'
			,'Disk Write Bytes/sec'
			,'Disk Write IO Throttled/sec'
			,'Disk Write IO/sec'
			,'Used memory (KB)'
			,'Forwarded Records/sec'
			,'Background Writer pages/sec'
			,'Percent Log Used'
			,'Log Send Queue KB'
			,'Redo Queue KB'
			,'Mirrored Write Transactions/sec'
			,'Group Commit Time'
			,'Group Commits/Sec'
			,'Workfiles Created/sec'
			,'Worktables Created/sec'
			,'Distributed Query'
			,'DTC calls'
			,'Query Store CPU usage'
			,'Query Store physical reads'
			,'Query Store logical reads'
			,'Query Store logical writes'
			,'Execution Errors'
		) OR (
			spi.[object_name] LIKE '%User Settable%'
			OR spi.[object_name] LIKE '%SQL Errors%'
			OR spi.[object_name] LIKE '%Batch Resp Statistics%'
		) OR (
			spi.[instance_name] IN ('_Total')
			AND spi.[counter_name] IN (
				 'Lock Timeouts/sec'
				,'Lock Timeouts (timeout > 0)/sec'
				,'Number of Deadlocks/sec'
				,'Lock Waits/sec'
				,'Latch Waits/sec'
			)
		)
)

INSERT INTO @PCounters SELECT * FROM PerfCounters;

SELECT
	 'sqlserver_performance' AS [measurement]
	,REPLACE(@@SERVERNAME,'\\',':') AS [sql_instance]
	,HOST_NAME() AS [computer_name]
	,pc.[object_name] AS [object]
	,pc.[counter_name] AS [counter]
	,CASE pc.[instance_name] WHEN '_Total' THEN 'Total' ELSE ISNULL(pc.[instance_name],'') END AS [instance]
	,CAST(CASE WHEN pc.[cntr_type] = 537003264 AND pc1.[cntr_value] > 0 THEN (pc.[cntr_value] * 1.0) / (pc1.[cntr_value] * 1.0) * 100 ELSE pc.[cntr_value] END AS float(10)) AS [value]
	,CAST(pc.[cntr_type] AS varchar(25)) AS [counter_type]
FROM @PCounters AS pc
LEFT OUTER JOIN @PCounters AS pc1
	ON (
		pc.[counter_name] = REPLACE(pc1.[counter_name],' base','')
		OR pc.[counter_name] = REPLACE(pc1.[counter_name],' base',' (ms)')
	)
	AND pc.[object_name] = pc1.[object_name]
	AND pc.[instance_name] = pc1.[instance_name]
	AND pc1.[counter_name] LIKE '%base'
WHERE
	pc.[counter_name] NOT LIKE '% base'

OPTION(RECOMPILE)

----------------------------------------

TITLE: Defining AWS X-Ray API Trace Subsegment Structure in JSON
DESCRIPTION: JSON structure defining an AWS X-Ray trace subsegment for an API request to api.example.com. Contains trace context information, timing details, and HTTP request/response data including URL, method, status code, and content length.

LANGUAGE: json
CODE:
{
    "name": "api.example.com",
    "id": "53995c3f42cd8ad8",
    "start_time": 14782323361.271,
    "end_time":   14789232374.449,
    "type": "subsegment",
    "trace_id": "1-581cf771-a006649127e371903a2de979",
    "parent_id": "defdfd9912dc5a56",
    "namespace": "remote",
    "traced": true,
    "http": {
        "request": {
            "url": "https://api.example.com/health",
            "method": "POST"
        },
        "response": {
            "status": 200,
            "content_length": "861"
        }
    }
}

----------------------------------------

TITLE: Pattern Matching with Group Replacement in YAML
DESCRIPTION: Configuration example demonstrating how to use regex groups to match and replace content within curly braces.

LANGUAGE: yaml
CODE:
- type: regex_replace
  regex: "{(.*)}"
  replace_with: "${1}"
  field: body

----------------------------------------

TITLE: Defining Metrics Data Structure in Go
DESCRIPTION: Example showing the structure of metrics data before grouping, demonstrating various metric types and their attributes.

LANGUAGE: go
CODE:
Resource {host.name="localhost",source="prom"}
  Metric "gauge-1" (GAUGE)
    DataPoint {host.name="host-A",id="eth0"}
    DataPoint {host.name="host-A",id="eth0"}
    DataPoint {host.name="host-B",id="eth0"}
  Metric "gauge-1" (GAUGE) // Identical to previous Metric
    DataPoint {host.name="host-A",id="eth0"}
    DataPoint {host.name="host-A",id="eth0"}
    DataPoint {host.name="host-B",id="eth0"}
  Metric "mixed-type" (GAUGE)
    DataPoint {host.name="host-A",id="eth0"}
    DataPoint {host.name="host-A",id="eth0"}
    DataPoint {host.name="host-B",id="eth0"}
  Metric "mixed-type" (SUM)
    DataPoint {host.name="host-A",id="eth0"}
    DataPoint {host.name="host-A",id="eth0"}
  Metric "dont-move" (Gauge)
    DataPoint {id="eth0"}

----------------------------------------

TITLE: Configuring AlibabaCloud LogService Exporter for Simple Trace Data in YAML
DESCRIPTION: This snippet demonstrates how to configure the AlibabaCloud LogService Exporter for exporting trace data. It includes the necessary parameters such as endpoint, project, logstore, and access credentials.

LANGUAGE: yaml
CODE:
receivers:
  examplereceiver:

exporters:
  alibabacloud_logservice:
    endpoint: "cn-hangzhou.log.aliyuncs.com"
    project: "demo-project"
    logstore: "traces-store"
    access_key_id: "access-key-id"
    access_key_secret: "access-key-secret"

service:
  pipelines:
    traces:
      receivers: [examplereceiver]
      exporters: [alibabacloud_logservice]

----------------------------------------

TITLE: Enabling Optional MongoDB Metrics
DESCRIPTION: Configuration to enable optional metrics that are not collected by default in MongoDB monitoring using YAML format.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: true

----------------------------------------

TITLE: Adding a Value to Resource in YAML Configuration
DESCRIPTION: This configuration demonstrates adding a value to the resource of an entry. It creates a new key-value pair in the resource section.

LANGUAGE: yaml
CODE:
- type: add
  field: resource.key2
  value: val2

----------------------------------------

TITLE: Defining AWS X-Ray Trace JSON Structure
DESCRIPTION: This JSON structure defines an AWS X-Ray trace for a sample server request. It includes trace identifiers, timing information, HTTP request and response details, AWS X-Ray SDK information, EKS (Elastic Kubernetes Service) metadata, and service compiler information.

LANGUAGE: json
CODE:
{
    "trace_id": "1-5f2aebcc-b475d14618c51eaa28753d37",
    "id": "bda182a644eee9b3",
    "name": "SampleServer",
    "start_time": 1596648396.6399446,
    "end_time": 1596648396.6401389,
    "http": {
        "request": {
            "method": "GET",
            "url": "http://localhost:8000/",
            "client_ip": "127.0.0.1",
            "user_agent": "Go-http-client/1.1",
            "x_forwarded_for": true
        },
        "response": {
            "status": 200
        }
    },
    "aws": {
        "xray": {
            "sdk_version": "1.1.0",
            "sdk": "X-Ray for Go"
        },
        "eks": {
            "cluster_name": "containerName",
            "pod": "podname",
            "container_id": "d8453812a556"
        }
    },
    "service": {
        "compiler_version": "go1.14.6",
        "compiler": "gc"
    },
    "Dummy": false
}

----------------------------------------

TITLE: Defining AWS X-Ray Trace JSON Structure
DESCRIPTION: This JSON structure defines an AWS X-Ray trace for a sample server request. It includes trace identifiers, timing information, HTTP request and response details, AWS X-Ray SDK information, EKS (Elastic Kubernetes Service) metadata, and service compiler information.

LANGUAGE: json
CODE:
{
    "trace_id": "1-5f2aebcc-b475d14618c51eaa28753d37",
    "id": "bda182a644eee9b3",
    "name": "SampleServer",
    "start_time": 1596648396.6399446,
    "end_time": 1596648396.6401389,
    "http": {
        "request": {
            "method": "GET",
            "url": "http://localhost:8000/",
            "client_ip": "127.0.0.1",
            "user_agent": "Go-http-client/1.1",
            "x_forwarded_for": true
        },
        "response": {
            "status": 200
        }
    },
    "aws": {
        "xray": {
            "sdk_version": "1.1.0",
            "sdk": "X-Ray for Go"
        },
        "eks": {
            "cluster_name": "containerName",
            "pod": "podname",
            "container_id": "d8453812a556"
        }
    },
    "service": {
        "compiler_version": "go1.14.6",
        "compiler": "gc"
    },
    "Dummy": false
}

----------------------------------------

TITLE: Resource Instrumentation Matrix Table
DESCRIPTION: Tabular data showing relationships between resources (VM, Kubernetes, FaaS, etc.), instrumentation libraries, and span configurations. The matrix demonstrates possible combinations in OpenTelemetry collector setups.

LANGUAGE: text
CODE:
Resource	InstrumentationLibrary	Spans
VMOnPrem	None	None
Nil	One	None
Exec	One	Several
Exec	None	All
Nil	Two	One
Empty	Two	Several
VMCloud	Two	All
K8sOnPrem	None	One
Empty	Two	None
Nil	None	Several
K8sOnPrem	One	None
K8sCloud	One	All
VMCloud	One	One
Nil	None	All
K8sOnPrem	Two	Several
K8sCloud	Two	One
Exec	Two	None
VMOnPrem	Two	One
K8sCloud	None	None
Faas	One	None
Faas	Two	Several
Exec	One	One
VMCloud	None	Several
Faas	None	All
Empty	One	One
K8sCloud	None	Several
VMOnPrem	One	All
VMOnPrem	One	Several
K8sOnPrem	Two	All
VMCloud	Two	None
Empty	None	All
Faas	One	One

----------------------------------------

TITLE: Conditional Regex Parsing in YAML
DESCRIPTION: Configuration for conditional parsing based on a field value. It only applies the regex parser if the 'type' field is 'hostname'.

LANGUAGE: yaml
CODE:
- type: regex_parser
  regex: '^Host=(?<host>)$'
  parse_from: body.message
  if: 'body.type == "hostname"'

----------------------------------------

TITLE: Disabling Default Metrics in YAML Configuration
DESCRIPTION: This snippet shows how to disable a default metric using YAML configuration. Replace <metric_name> with the specific metric you want to disable.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Configuring Service Graph Connector with Custom Buckets and Dimensions
DESCRIPTION: This YAML configuration demonstrates how to set up the Service Graph Connector with custom latency histogram buckets and additional dimensions. It also includes settings for the in-memory store and exports metrics to Prometheus.

LANGUAGE: yaml
CODE:
receivers:
  otlp:
    protocols:
      grpc:

connectors:
  servicegraph:
    latency_histogram_buckets: [100ms, 250ms, 1s, 5s, 10s]
    dimensions:
      - dimension-1
      - dimension-2
    store:
      ttl: 1s
      max_items: 10

exporters:
  prometheus/servicegraph:
    endpoint: localhost:9090
    namespace: servicegraph

service:
  pipelines:
    traces:
      receivers: [otlp]
      exporters: [servicegraph]
    metrics/servicegraph:
      receivers: [servicegraph]
      exporters: [prometheus/servicegraph]

----------------------------------------

TITLE: Configuring NSX-T Receiver in YAML
DESCRIPTION: Example configuration for the NSX-T receiver in the OpenTelemetry Collector. It demonstrates how to set up the receiver with basic authentication, custom timeout, and metric filtering.

LANGUAGE: yaml
CODE:
receivers:
  nsxt:
    endpoint: https://nsx-manager
    username: admin
    password: password
    timeout: 60s
    metrics:
      nsxt.node.cpu.utilization:
        enabled: false

exporters:
  file:
    path: "./content.json"

service:
  pipelines:
    metrics:
      receivers: [nsxt]
      exporters: [file]

----------------------------------------

TITLE: Installing OpenTelemetry Collector as DaemonSet
DESCRIPTION: Command to install the OpenTelemetry Collector as a DaemonSet using the daemonset-collector-dev.yaml configuration.

LANGUAGE: bash
CODE:
make kind-install-daemonset

----------------------------------------

TITLE: Viewing OpenTelemetry Collector Logs
DESCRIPTION: Command to view the metrics data being collected and processed by the OpenTelemetry Collector through Docker logs.

LANGUAGE: bash
CODE:
docker logs otelcollector

----------------------------------------

TITLE: Customizing Expvar Receiver Configuration in YAML
DESCRIPTION: An example of a customized Expvar receiver configuration, including a custom endpoint, timeout, collection interval, and metric filtering.

LANGUAGE: yaml
CODE:
receivers:
  expvar:
    endpoint: "http://localhost:8000/custom/path"
    timeout: 1s
    collection_interval: 30s
    metrics:
      process.runtime.memstats.total_alloc:
        enabled: true
      process.runtime.memstats.mallocs:
        enabled: false

----------------------------------------

TITLE: Prometheus Metrics Example
DESCRIPTION: Example of Prometheus text format metrics showing grouping and type hints

LANGUAGE: prometheus
CODE:
# HELP container_cpu_load_average_10s Value of container cpu load average over the last 10 seconds.
# TYPE container_cpu_load_average_10s gauge
container_cpu_load_average_10s{id="/",image="",name=""} 0
container_cpu_load_average_10s{id="/000-metadata",image="",name=""} 0
container_cpu_load_average_10s{id="/001-sysfs",image="",name=""} 0

----------------------------------------

TITLE: Configuring AWS X-Ray Trace Subsegment JSON
DESCRIPTION: Defines the structure of an AWS X-Ray trace subsegment with required fields including trace identifiers, timing information, resource details, and trace relationships. Contains standard X-Ray fields like trace_id, start_time, end_time along with AWS-specific fields like resource_arn and origin.

LANGUAGE: json
CODE:
{
    "trace_id": "1-5f187253-6a106696d56b1f4ef9eba2ed",
    "id": "5cc4a447f5d4d696",
    "name": "OtherTopLevelFields",
    "start_time": 1595437651.680097,
    "end_time": 1595437652.197392,
    "error": false,
    "throttle": true,
    "resource_arn": "chicken",
    "origin": "AWS::EC2::Instance",
    "parent_id": "defdfd9912dc5a56",
    "type": "subsegment",
    "Dummy": false
}

----------------------------------------

TITLE: Configuring AWS X-Ray Trace Subsegment JSON
DESCRIPTION: Defines the structure of an AWS X-Ray trace subsegment with required fields including trace identifiers, timing information, resource details, and trace relationships. Contains standard X-Ray fields like trace_id, start_time, end_time along with AWS-specific fields like resource_arn and origin.

LANGUAGE: json
CODE:
{
    "trace_id": "1-5f187253-6a106696d56b1f4ef9eba2ed",
    "id": "5cc4a447f5d4d696",
    "name": "OtherTopLevelFields",
    "start_time": 1595437651.680097,
    "end_time": 1595437652.197392,
    "error": false,
    "throttle": true,
    "resource_arn": "chicken",
    "origin": "AWS::EC2::Instance",
    "parent_id": "defdfd9912dc5a56",
    "type": "subsegment",
    "Dummy": false
}

----------------------------------------

TITLE: Enabling Optional Metrics in RabbitMQ Collector Configuration (YAML)
DESCRIPTION: This YAML configuration snippet demonstrates how to enable an optional metric in the RabbitMQ collector. Replace <metric_name> with the specific optional metric to be enabled.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: true

----------------------------------------

TITLE: Configuring NoOp Operator with Router in OpenTelemetry YAML
DESCRIPTION: Example configuration showing how to use the noop operator as a terminal node in a non-linear pipeline. The configuration demonstrates routing logs to different parsers and using noop as a final destination.

LANGUAGE: yaml
CODE:
operators:
  - type: router
    routes:
      - output: json_parser
        expr: 'body.format == "json"'
      - output: syslog_parser
        expr: 'body.format == "syslog"'
  - type: json_parser
    output: noop  # If this were not set, logs would implicitly pass to the next operator
  - type: syslog_parser
  - type: noop

----------------------------------------

TITLE: Configuring Envoy for Client Authentication with TLS (YAML)
DESCRIPTION: This configuration snippet for Envoy sets up client authentication using TLS. It requires client certificates and specifies validation context for more granular control, including matching tenant information in the certificate.

LANGUAGE: yaml
CODE:
typed_config:
    "@type": type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.DownstreamTlsContext
    require_client_certificate: true
    common_tls_context:
    alpn_protocols: "h2"
    tls_certificates:
    - certificate_chain: 
        filename: "/etc/envoy.crt"
        private_key: 
        filename: "/etc/envoy.key"
    validation_context:
        match_typed_subject_alt_names:
        - san_type: URI
        matcher:
            exact: "aprn:trace-client:certmgr:::group-x:/ig/5003178/uv/tenant-a"
        trusted_ca:
        filename: "/etc/ca.crt"

----------------------------------------

TITLE: Configuring URI Parser for Relative URI Parsing in YAML
DESCRIPTION: This configuration snippet shows how to set up the uri_parser operator to parse a relative URI from the body.message field. The configuration is identical to the absolute URI parsing setup.

LANGUAGE: yaml
CODE:
- type: uri_parser
  parse_from: body.message

----------------------------------------

TITLE: Delta to Cumulative Internal Telemetry Metrics Table
DESCRIPTION: Defines the structure and properties of internal telemetry metrics used for monitoring the deltatocumulative component's performance and state.

LANGUAGE: markdown
CODE:
| Unit | Metric Type | Value Type | Monotonic |
| ---- | ----------- | ---------- | --------- |
| {datapoint} | Sum | Int | true |

| Unit | Metric Type | Value Type |
| ---- | ----------- | ---------- |
| {stream} | Gauge | Int |

| Unit | Metric Type | Value Type |
| ---- | ----------- | ---------- |
| s | Gauge | Int |

| Unit | Metric Type | Value Type | Monotonic |
| ---- | ----------- | ---------- | --------- |
| {dps} | Sum | Int | false |

----------------------------------------

TITLE: Configuring HTTP Check Metrics in YAML
DESCRIPTION: Configuration example showing how to disable specific metrics in the httpcheck component. This can be applied to any of the default metrics to disable their collection.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Explicit ID and Output Configuration in YAML
DESCRIPTION: Demonstrates the same linear sequence with explicit ID and output fields. Shows how operator relationships are defined using default values for ID and output fields.

LANGUAGE: yaml
CODE:
receivers:
  filelog:
    include: my-log.json
    operators:
      - type: json_parser
        id: json_parser
        output: remove
      - type: remove
        id: remove
        field: attributes.foo
        output: add
      - type: add
        id: add
        key: attributes.bar
        value: baz

----------------------------------------

TITLE: Disabling Default Metrics in RabbitMQ Collector Configuration (YAML)
DESCRIPTION: This YAML configuration snippet shows how to disable a default metric in the RabbitMQ collector. Replace <metric_name> with the specific metric to be disabled.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Remove Wrapper Layer
DESCRIPTION: Demonstrates removing a wrapper layer from the body structure

LANGUAGE: yaml
CODE:
- type: move
  from: body.wrapper
  to: body

LANGUAGE: json
CODE:
{
  "resource": { },
  "attributes": { },
  "body": {
    "wrapper": {
      "key1": "val1",
      "key2": "val2",
      "key3": "val3"
    }
  }
}

----------------------------------------

TITLE: Initializing SQL Server Database I/O Performance Monitoring in TSQL
DESCRIPTION: Sets up variables and conditions for collecting I/O performance metrics. Checks SQL Server edition compatibility and adjusts columns based on the server version.

LANGUAGE: TSQL
CODE:
SET DEADLOCK_PRIORITY -10;
IF SERVERPROPERTY('EngineEdition') NOT IN (2,3,4) BEGIN /*NOT IN Standard,Enterprise,Express*/
	DECLARE @ErrorMessage AS nvarchar(500) = 'Connection string Server:'+ @@ServerName + ',Database:' + DB_NAME() +' is not a SQL Server Standard,Enterprise or Express. This query is only supported on these editions.';
	RAISERROW (@ErrorMessage,11,1)
	RETURN
END

DECLARE
	 @SqlStatement AS nvarchar(max)
	,@MajorMinorVersion AS int = CAST(PARSENAME(CAST(SERVERPROPERTY('ProductVersion') AS nvarchar),4) AS int) * 100 + CAST(PARSENAME(CAST(SERVERPROPERTY('ProductVersion') AS nvarchar),3) AS int)
	,@Columns AS nvarchar(max) = ''
	,@Tables AS nvarchar(max) = ''
IF @MajorMinorVersion > 1100 BEGIN
	SET @Columns += N'
	,vfs.[io_stall_queued_read_ms] AS [rg_read_stall_ms]
	,vfs.[io_stall_queued_write_ms] AS [rg_write_stall_ms]'
END

----------------------------------------

TITLE: Running mitmproxy for API Interaction Recording
DESCRIPTION: Shell command to run mitmproxy as a reverse proxy for recording API interactions with the vCenter server. This is used to capture the behavior of the real server for mock implementation.

LANGUAGE: sh
CODE:
mitmproxy -p 55626 --mode=reverse:https://<vcenter-hostname>

----------------------------------------

TITLE: Disabling Default Metrics in YAML Configuration
DESCRIPTION: YAML configuration snippet to disable a default metric. Replace <metric_name> with the specific metric to disable.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Unquoting Attribute Field Configuration - YAML
DESCRIPTION: Configuration example demonstrating how to unquote an attribute field using the unquote operator.

LANGUAGE: yaml
CODE:
- type: unquote
  field: attributes.foo

LANGUAGE: json
CODE:
{
  "resource": { },
  "attributes": {
    "foo": "`bar`"
  },
}

LANGUAGE: json
CODE:
{
  "resource": { },
  "attributes": {
    "foo": "bar"
  },
}

----------------------------------------

TITLE: Enabling Optional Metrics in YAML
DESCRIPTION: Example YAML configuration to enable optional metrics that are not collected by default

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: true

----------------------------------------

TITLE: Configuring TCP Receiver in YAML
DESCRIPTION: A simple configuration example for the TCP Receiver, specifying the listen address.

LANGUAGE: yaml
CODE:
receivers:
  tcplog:
    listen_address: "0.0.0.0:54525"

----------------------------------------

TITLE: Configuring Ordering for Google Cloud Pubsub Exporter
DESCRIPTION: Example configuration for enabling ordering using a specific resource attribute as the ordering key.

LANGUAGE: yaml
CODE:
exporters:
  googlecloudpubsub:
    project: my-project
    topic: projects/my-project/topics/otlp-traces
    ordering:
      enabled: true
      from_resource_attribute: some.resource.attribute.key
      remove_resource_attribute: true

----------------------------------------

TITLE: Installing OpenTelemetry Operator in Kubernetes
DESCRIPTION: This command applies the latest OpenTelemetry Operator manifest to the Kubernetes cluster, which is a prerequisite for the demo setup.

LANGUAGE: shell
CODE:
kubectl apply -f https://github.com/open-telemetry/opentelemetry-operator/releases/latest/download/opentelemetry-operator.yaml

----------------------------------------

TITLE: Configuring Oracle DB Receiver with Secondary Connection Option
DESCRIPTION: Example configuration using the secondary connection option with separate parameters for endpoint, credentials, and service name.

LANGUAGE: yaml
CODE:
receivers:
  oracledb:
    endpoint: localhost:51521
    password: p@sswo%d
    service: XE
    username: otel

----------------------------------------

TITLE: Sample Output Entry
DESCRIPTION: Example of the JSON output structure produced by the journald_input operator.

LANGUAGE: json
CODE:
"entry": {
  "timestamp": "2020-04-16T11:05:49.516168-04:00",
  "body": {
    "CODE_FILE": "../src/core/unit.c",
    "CODE_FUNC": "unit_log_success",
    "CODE_LINE": "5487",
    "MESSAGE": "var-lib-docker-overlay2-bff8130ef3f66eeb81ce2102f1ac34cfa7a10fcbd1b8ae27c6c5a1543f64ddb7-merged.mount: Succeeded.",
    "MESSAGE_ID": "7ad2d189f7e94e70a38c781354912448",
    "PRIORITY": "6",
    "SYSLOG_FACILITY": "3",
    "SYSLOG_IDENTIFIER": "systemd",
    "USER_INVOCATION_ID": "de9283b4fd634213a50f5abe71b4d951",
    "USER_UNIT": "var-lib-docker-overlay2-bff8130ef3f66eeb81ce2102f1ac34cfa7a10fcbd1b8ae27c6c5a1543f64ddb7-merged.mount",
    "_AUDIT_LOGINUID": "1000",
    "_AUDIT_SESSION": "299",
    "_BOOT_ID": "c4fa36de06824d21835c05ff80c54468",
    "_CAP_EFFECTIVE": "0",
    "_CMDLINE": "/lib/systemd/systemd --user",
    "_COMM": "systemd",
    "_EXE": "/usr/lib/systemd/systemd",
    "_GID": "1000",
    "_HOSTNAME": "testhost",
    "_MACHINE_ID": "d777d00e7caf45fbadedceba3975520d",
    "_PID": "18667",
    "_SELINUX_CONTEXT": "unconfined\n",
    "_SOURCE_REALTIME_TIMESTAMP": "1587049549515868",
    "_SYSTEMD_CGROUP": "/user.slice/user-1000.slice/user@1000.service/init.scope",
    "_SYSTEMD_INVOCATION_ID": "da8b20bdc65e4f6f9ca35d6352199b56",
    "_SYSTEMD_OWNER_UID": "1000",
    "_SYSTEMD_SLICE": "user-1000.slice",
    "_SYSTEMD_UNIT": "user@1000.service",
    "_SYSTEMD_USER_SLICE": "-.slice",
    "_SYSTEMD_USER_UNIT": "init.scope",
    "_TRANSPORT": "journal",
    "_UID": "1000",
    "__CURSOR": "s=b1e713b587ae4001a9ca482c4b12c005;i=1efec9;b=c4fa36de06824d21835c05ff80c54468;m=a001b7ec5a;t=5a369c4a3cd88;x=f9717e0b5608807b",
    "__MONOTONIC_TIMESTAMP": "687223598170"
  }
}

----------------------------------------

TITLE: Complex Matching Configuration
DESCRIPTION: Advanced configuration example demonstrating the use of matches for filtering specific systemd units and UIDs.

LANGUAGE: yaml
CODE:
- type: journald_input
  matches:
    - _SYSTEMD_UNIT: ssh
    - _SYSTEMD_UNIT: kubelet
      _UID: "1000"

----------------------------------------

TITLE: Configuring Timestamp Parsing in Regex Parser
DESCRIPTION: This snippet shows how to configure timestamp parsing in a regex_parser operator. It extracts a timestamp field from a log entry and parses it using the strptime layout.

LANGUAGE: yaml
CODE:
- type: regex_parser
  regex: '^Time=(?P<timestamp_field>\d{4}-\d{2}-\d{2}), Host=(?P<host>[^,]+)'
  timestamp:
    parse_from: attributes.timestamp_field
    layout_type: strptime
    layout: '%Y-%m-%d'

----------------------------------------

TITLE: InfluxDB Line Protocol Example - Prometheus v2 Format
DESCRIPTION: Example of metrics data in Prometheus v2 format using InfluxDB Line Protocol, demonstrating the same metrics in an alternative format with explicit prometheus measurement.

LANGUAGE: plaintext
CODE:
prometheus,foo=bar cpu_temp=87.332\nprometheus,method=post,code=200 http_requests_total=1027\nprometheus,method=post,code=400 http_requests_total=3\nprometheus,le=0.05 http_request_duration_seconds_bucket=24054\nprometheus,le=0.1  http_request_duration_seconds_bucket=33444\nprometheus,le=0.2  http_request_duration_seconds_bucket=100392\nprometheus,le=0.5  http_request_duration_seconds_bucket=129389\nprometheus,le=1    http_request_duration_seconds_bucket=133988\nprometheus         http_request_duration_seconds_count=144320,http_request_duration_seconds_sum=53423\nprometheus,quantile=0.01 rpc_duration_seconds=3102\nprometheus,quantile=0.05 rpc_duration_seconds=3272\nprometheus,quantile=0.5  rpc_duration_seconds=4773\nprometheus,quantile=0.9  rpc_duration_seconds=9001\nprometheus,quantile=0.99 rpc_duration_seconds=76656\nprometheus               rpc_duration_seconds_count=1.7560473e+07,rpc_duration_seconds_sum=2693

----------------------------------------

TITLE: Building OpenTelemetry Collector Docker Image
DESCRIPTION: Command to build the OpenTelemetry Collector Docker image from the root of the repository.

LANGUAGE: sh
CODE:
make docker-otelcontribcol

----------------------------------------

TITLE: Disabling Default Metrics in YAML Configuration for NSX-T
DESCRIPTION: This YAML configuration snippet demonstrates how to disable specific default metrics in the NSX-T collector. It allows users to selectively turn off individual metrics by setting the 'enabled' flag to false.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Priority Range Configuration
DESCRIPTION: Example showing how to configure journald_input with a priority range filter.

LANGUAGE: yaml
CODE:
- type: journald_input
  priority: emerg..err

----------------------------------------

TITLE: Querying Global Status in MySQL/MariaDB
DESCRIPTION: SQL command to display global status variables in a database system, typically used for monitoring and diagnostics.

LANGUAGE: sql
CODE:
SHOW GLOBAL STATUS

----------------------------------------

TITLE: Defining Sampling Strategies in JSON
DESCRIPTION: Example JSON configuration for defining sampling strategies, including service-specific and default strategies with probabilistic and rate-limiting sampling types.

LANGUAGE: json
CODE:
{
  "service_strategies": [
    {
      "service": "foo",
      "type": "probabilistic",
      "param": 0.8,
      "operation_strategies": [
        {
          "operation": "op1",
          "type": "probabilistic",
          "param": 0.2
        },
        {
          "operation": "op2",
          "type": "probabilistic",
          "param": 0.4
        }
      ]
    },
    {
      "service": "bar",
      "type": "ratelimiting",
      "param": 5
    }
  ],
  "default_strategy": {
    "type": "probabilistic",
    "param": 0.5,
    "operation_strategies": [
      {
        "operation": "/health",
        "type": "probabilistic",
        "param": 0.0
      },
      {
        "operation": "/metrics",
        "type": "probabilistic",
        "param": 0.0
      }
    ]
  }
}

----------------------------------------

TITLE: Prometheus Storage Appender Interface
DESCRIPTION: Interface definition for implementing storage appender in Prometheus receiver

LANGUAGE: go
CODE:
type Appender interface {
  Append(ref uint64, l labels.Labels, t int64, v float64) (uint64, error)

  // Commit submits the collected samples and purges the batch.
  Commit() error

  Rollback() error

  ExemplarAppender
}

type ExemplarAppender interface {
	AppendExemplar(ref uint64, l labels.Labels, e exemplar.Exemplar) (uint64, error)
}

----------------------------------------

TITLE: Removing a Value from Body using YAML Configuration
DESCRIPTION: This snippet demonstrates how to configure the 'remove' operator to remove a specific key from the body of a record.

LANGUAGE: yaml
CODE:
- type: remove
  field: body.key1

----------------------------------------

TITLE: Metric Flag and Temporality Enum Values
DESCRIPTION: Definition of enum values for metric flags and aggregation temporality types

LANGUAGE: protobuf
CODE:
FLAG_NONE = 0
FLAG_NO_RECORDED_VALUE = 1
AGGREGATION_TEMPORALITY_UNSPECIFIED = 0
AGGREGATION_TEMPORALITY_DELTA = 1
AGGREGATION_TEMPORALITY_CUMULATIVE = 2

----------------------------------------

TITLE: Configuring NTP Receiver in YAML for OpenTelemetry Collector
DESCRIPTION: Example configuration for the NTP receiver, specifying the endpoint, collection interval, and initial delay.

LANGUAGE: yaml
CODE:
receivers:
  ntp:
    endpoint: pool.ntp.org:123
    collection_interval: 1h
    initial_delay: 5m

----------------------------------------

TITLE: Configuring Basic Sum Connector in YAML
DESCRIPTION: This snippet demonstrates a basic configuration for the Sum Connector. It sums numerical values from the 'attribute.with.numerical.value' attribute of span telemetry and outputs a metric named 'my.example.metric.name'.

LANGUAGE: yaml
CODE:
receivers:
  foo:
connectors:
  sum:
    spans:
      my.example.metric.name:
        source_attribute: attribute.with.numerical.value
exporters:
  bar:

service:
  pipelines:
    metrics/sum:
       receivers: [sum]
       exporters: [bar]
    traces:
       receivers: [foo]
       exporters: [sum]

----------------------------------------

TITLE: Launching Couchbase Environment with Docker Compose
DESCRIPTION: Docker Compose command to start Couchbase, the collector, and Prometheus server with clean deployment options.

LANGUAGE: sh
CODE:
docker-compose up -d --remove-orphans --build --force-recreate

----------------------------------------

TITLE: Regex Parser with Severity Configuration
DESCRIPTION: Configuration example for regex_parser with severity parsing from HTTP status codes.

LANGUAGE: yaml
CODE:
- type: regex_parser
  regexp: '^StatusCode=(?P<severity_field>\d{3}), Host=(?P<host>[^,]+)'
  severity:
    parse_from: body.severity_field
    mapping:
      warn: 5xx
      error: 4xx
      info: 3xx
      debug: 2xx

----------------------------------------

TITLE: Breaking Change: ParserCollection Context Support
DESCRIPTION: Modify OTTL ParserCollection to support parsing conditions and require converters to be configured using statement and condition converter options

LANGUAGE: go
CODE:
ottl.WithParserCollectionContext // Now requires separate converters for statements and conditions

----------------------------------------

TITLE: Configuring Log Include/Exclude Paths in OpenTelemetry Collector
DESCRIPTION: YAML configuration example showing how to include logs from the 'default' namespace in Kubernetes using path patterns. This configuration demonstrates filtering logs based on their location in /var/log/pods.

LANGUAGE: yaml
CODE:
include:\n    - /var/log/pods/default_*/*/*.log\nexclude: []

----------------------------------------

TITLE: Disabling a Metric in YAML Configuration
DESCRIPTION: Example of how to disable a specific metric using YAML configuration in the OpenTelemetry Collector.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Configuring vCenter Receiver for Testing
DESCRIPTION: YAML configuration for the vCenter receiver to use the mitmproxy for testing. It includes endpoint, credentials, and TLS settings to connect to the mock server.

LANGUAGE: yaml
CODE:
receivers:
  vcenter:
    endpoint: http://localhost:55626
    username: "otelu"
    password: "otelp"
    tls:
      insecure: false
      insecure_skip_verify: true

service:
  pipelines:
    metrics:
      receivers: [vcenter]

----------------------------------------

TITLE: Initializing Couchbase Configuration
DESCRIPTION: Script execution to initialize Couchbase and create required buckets.

LANGUAGE: sh
CODE:
./scripts/setup.sh

----------------------------------------

TITLE: Enabling Optional Metrics in YAML Configuration
DESCRIPTION: YAML configuration snippet to enable an optional metric in the k8s_cluster collector.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: true

----------------------------------------

TITLE: Non-Linear Operator Sequence with Router in YAML
DESCRIPTION: Complex example showing how to handle multiple log formats using a router operator. Demonstrates branching logic in operator sequences.

LANGUAGE: yaml
CODE:
receivers:
  filelog:
    include: my-log.json
    operators:
      - type: router
        routes:
          - expr: 'body matches "^{.*}$"'
            output: json_parser
          - expr: 'body startsWith "ERROR"'
            output: error_parser
      - type: json_parser
        output: remove
      - type: regex_parser
        id: error_parser
        regex: ...
      - type: remove
        field: attributes.foo
      - type: add
        key: attributes.bar
        value: baz

----------------------------------------

TITLE: ADX Database Table Creation Scripts
DESCRIPTION: KQL scripts to create the required tables for storing OpenTelemetry data in Azure Data Explorer.

LANGUAGE: kql
CODE:
.create-merge table <Logs-Table-Name> (Timestamp:datetime, ObservedTimestamp:datetime, TraceID:string, SpanID:string, SeverityText:string, SeverityNumber:int, Body:string, ResourceAttributes:dynamic, LogsAttributes:dynamic)

.create-merge table <Metrics-Table-Name> (Timestamp:datetime, MetricName:string, MetricType:string, MetricUnit:string, MetricDescription:string, MetricValue:real, Host:string, ResourceAttributes:dynamic,MetricAttributes:dynamic)

.create-merge table <Traces-Table-Name> (TraceID:string, SpanID:string, ParentID:string, SpanName:string, SpanStatus:string, SpanKind:string, StartTime:datetime, EndTime:datetime, ResourceAttributes:dynamic, TraceAttributes:dynamic, Events:dynamic, Links:dynamic)

----------------------------------------

TITLE: Setting Node Name via Kubernetes Downward API
DESCRIPTION: Example showing how to set the node name using Kubernetes downward API in a pod specification.

LANGUAGE: yaml
CODE:
env:
  - name: K8S_NODE_NAME
    valueFrom:
      fieldRef:
        fieldPath: spec.nodeName

----------------------------------------

TITLE: Enabling Optional Metrics in Kubelet Stats
DESCRIPTION: YAML configuration template for enabling optional metrics that are not collected by default in the kubeletstats receiver.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: true

----------------------------------------

TITLE: Enhancement: dbstorage.Batch Performance Optimization
DESCRIPTION: Optimize performance of dbstorage.Batch() method for Operations with a single type



----------------------------------------

TITLE: Calculating New Metrics from Existing Metrics
DESCRIPTION: Example configuration showing how to create a new CPU utilization metric by dividing pod CPU usage by node CPU limit.

LANGUAGE: yaml
CODE:
rules:
    - name: pod.cpu.utilized
      type: calculate
      metric1: pod.cpu.usage
      metric2: node.cpu.limit
      operation: divide

----------------------------------------

TITLE: Configuring MongoDB Atlas Access Log Polling in YAML
DESCRIPTION: Configuration for polling access logs from MongoDB Atlas API, including project and cluster specifications, pagination settings, and poll interval.

LANGUAGE: yaml
CODE:
receivers:
  mongodbatlas:
    public_key: <redacted>
    private_key: <redacted>
    logs:
      enabled: true
      projects:
      - name: Project 0
        include_clusters: [Cluster0]
        access_logs:
          page_size: 20000
          max_pages: 10
          poll_interval: 5m
    storage: file_storage

----------------------------------------

TITLE: Configuring Docker Stats Receiver in YAML
DESCRIPTION: Example configuration showing how to set up the Docker Stats receiver with custom endpoints, intervals, labels, and metric filters.

LANGUAGE: yaml
CODE:
receivers:
  docker_stats:
    endpoint: http://example.com/
    collection_interval: 2s
    timeout: 20s
    api_version: "1.24"
    container_labels_to_metric_labels:
      my.container.label: my-metric-label
      my.other.container.label: my-other-metric-label
    env_vars_to_metric_labels:
      MY_ENVIRONMENT_VARIABLE: my-metric-label
      MY_OTHER_ENVIRONMENT_VARIABLE: my-other-metric-label
    excluded_images:
      - undesired-container
      - /.*undesired.*/
      - another-*-container
    metrics: 
      container.cpu.usage.percpu:
        enabled: true
      container.network.io.usage.tx_dropped:
        enabled: false

----------------------------------------

TITLE: Reporting Uncompressed Size in Exporter with Network Statistics in Go
DESCRIPTION: This code shows how to report the uncompressed size of data in an exporter using the Network Statistics package. It creates a SizesStruct, sets the method and uncompressed length, and calls CountSend on the network reporter.

LANGUAGE: go
CODE:
var sized netstats.SizesStruct
sized.Method = s.method
sized.Length = int64(uncompressedSize)
netReporter.CountSend(ctx, sized)

----------------------------------------

TITLE: Configuring Process Metrics in YAML
DESCRIPTION: Configuration example for enabling/disabling specific process metrics in OpenTelemetry Collector.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Specifying ByteSize in YAML Configuration
DESCRIPTION: Illustrates four different ways to specify 5000 bytes in a YAML configuration using the ByteSize type. The examples show direct numeric value, kilobytes (KB), kibibytes (KiB), and scientific notation.

LANGUAGE: yaml
CODE:
- type: some_operator
  bytes: 5000

LANGUAGE: yaml
CODE:
- type: some_operator
  bytes: 5kb

LANGUAGE: yaml
CODE:
- type: some_operator
  bytes: 4.88KiB

LANGUAGE: yaml
CODE:
- type: some_operator
  bytes: 5e3

----------------------------------------

TITLE: Configuring Zipkin Encoding Extension in YAML
DESCRIPTION: Default configuration for the Zipkin encoding extension. It specifies the protocol as 'zipkin_proto' and the version as 'v2'. The extension supports marshaling and unmarshaling Zipkin data for traces.

LANGUAGE: yaml
CODE:
extensions:
  zipkin_encoding:
    protocol: zipkin_proto
    version: v2

----------------------------------------

TITLE: Configuring Spark Metrics Collection in YAML
DESCRIPTION: Example YAML configuration to disable specific metrics collection in Apache Spark.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Configuring Aerospike Receiver in YAML for OpenTelemetry Collector
DESCRIPTION: Example YAML configuration for the Aerospike receiver. It specifies the endpoint, collection interval, and other optional parameters for connecting to and collecting metrics from Aerospike nodes.

LANGUAGE: yaml
CODE:
receivers:
    aerospike:
        endpoint: "localhost:3000"
        tlsname: ""
        collect_cluster_metrics: false
        collection_interval: 30s

----------------------------------------

TITLE: Registering Network Reporter with gRPC in Go
DESCRIPTION: This snippet demonstrates how to create a network reporter and register it with gRPC. It appends a new dial option to use the network reporter's handler.

LANGUAGE: go
CODE:
dialOpts = append(dialOpts, grpc.WithStatsHandler(netReporter.Handler()))

----------------------------------------

TITLE: Disabling Default Metrics in YAML Configuration
DESCRIPTION: YAML configuration snippet to disable a specific default metric in the OpenTelemetry Collector.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Configuring AWS X-Ray SQL Database Subsegment in JSON
DESCRIPTION: This JSON object configures an AWS X-Ray subsegment for a SQL database query. It includes identifiers, timing information, and details about the SQL operation such as the database type, version, and sanitized query.

LANGUAGE: json
CODE:
{
  "name": "ebdb@aawijb5u25wdoy.cpamxznpdoq8.us-west-2.rds.amazonaws.com",
  "id": "3fd8634e78ca9560",
  "start_time": 1484872218.696,
  "end_time": 1484872218.697,
  "namespace": "remote",
  "type" : "subsegment",
  "trace_id" : "1-581cf771-a006649127e371903a2de979",
  "parent_id" : "defdfd9912dc5a56",
  "sql" : {
    "url": "//aawijb5u25wdoy.cpamxznpdoq8.us-west-2.rds.amazonaws.com:5432/ebdb",
    "preparation": "statement",
    "database_type": "PostgreSQL",
    "database_version": "9.5.4",
    "driver_version": "PostgreSQL 9.4.1211.jre7",
    "user" : "dbuser",
    "sanitized_query" : "SELECT  *  FROM  customers  WHERE  customer_id=?;"
  }
}

----------------------------------------

TITLE: Configuring Watermark Behavior for Google Cloud Pubsub Exporter
DESCRIPTION: Configuration example for setting the watermark behavior to 'earliest' with a 1-hour drift allowance.

LANGUAGE: yaml
CODE:
exporters:
  googlecloudpubsub:
    project: my-project
    topic: projects/my-project/topics/otlp-traces
    watermark: 
      behavior: earliest
      allow_drift: 1h

----------------------------------------

TITLE: Configuring Pure Storage FlashArray Receiver in YAML
DESCRIPTION: Example configuration showing how to set up Pure Storage FlashArray receiver for two arrays - one using the OpenMetrics exporter and another using native on-box metrics from Purity//FA v6.6.11+. Includes bearer token authentication, endpoint configuration, and various collection settings.

LANGUAGE: yaml
CODE:
extensions:
  bearertokenauth/array01:
    token: "..."
  bearertokenauth/array02:
    token: "..."

receivers:
  purefa/array01:
    fa_array_name: foobar01
    endpoint: http://127.0.0.1:9490/metrics
    array:
      - address: array01
        auth:
          authenticator: bearertokenauth/array01
    hosts:
      - address: array01
        auth:
          authenticator: bearertokenauth/array01
    directories:
      - address: array01
        auth:
          authenticator: bearertokenauth/array01
    pods:
      - address: array01
        auth:
          authenticator: bearertokenauth/array01
    volumes:
      - address: array01
        auth:
          authenticator: bearertokenauth/array01
    env: dev
    settings:
      reload_intervals:
        array: 20s
        hosts: 60s
        directories: 60s
        pods: 60s
        volumes: 60s

  purefa/array02:
    fa_array_name: foobar02
    endpoint: https://127.0.0.1/metrics
    tls:
      insecure_skip_verify: true
    array:
      - address: array02
        auth:
          authenticator: bearertokenauth/array02
    hosts:
      - address: array02
        auth:
          authenticator: bearertokenauth/array02
    directories:
      - address: array02
        auth:
          authenticator: bearertokenauth/array02
    pods:
      - address: array02
        auth:
          authenticator: bearertokenauth/array02
    volumes:
      - address: array02
        auth:
          authenticator: bearertokenauth/array02
    env: production
    settings:
      reload_intervals:
        array: 20s
        hosts: 60s
        directories: 60s
        pods: 60s
        volumes: 60s

service:
  extensions: [bearertokenauth/array01,bearertokenauth/array02]
  pipelines:
    metrics:
      receivers: [purefa/array01,purefa/array02]

----------------------------------------

TITLE: Setting Huawei Cloud SDK Authentication Environment Variables
DESCRIPTION: Commands to set and verify the environment variables for Huawei Cloud SDK authentication using Access Key and Secret Key.

LANGUAGE: sh
CODE:
export HUAWEICLOUD_SDK_AK=your-access-key
export HUAWEICLOUD_SDK_SK=your-secret-key

echo $HUAWEICLOUD_SDK_AK
echo $HUAWEICLOUD_SDK_SK

----------------------------------------

TITLE: Implementing Sigv4 Authenticator Extension in Go
DESCRIPTION: Implements the sigv4Auth struct and methods to satisfy the ClientAuthenticator interface, including RoundTripper and PerRPCCredentials methods. It also includes helper functions for creating the extension and retrieving AWS credentials.

LANGUAGE: go
CODE:
type sigv4Auth struct {
    cfg *Config
    logger *zap.logger
    awsSDKInfo string
    componenthelper.StartFunc
    componenthelper.ShutdownFunc
}

func (sa *sigv4Auth) RoundTripper(base http.RoundTripper) (http.RoundTripper, error) {
    rt := signingRoundTripper {
        transport: base,
        signer: // Initialize signer,
        region: // Set region,
        service: // Set service,
        credsProvider: // Set credentials provider,
        awsSDKInfo: sa.awsSDKInfo,
        logger: sa.logger,
    }
    return &rt, nil
}

func (sa *sigv4Auth) PerRPCCredentials() (credentials.PerRPCCredentials, error) {
    return nil, errors.New("Not Implemented")
}

func newSigv4Extension(cfg *Config, awsSDKInfo string, logger *zap.logger) (*sigv4Auth, error) {
    return &sigv4Auth{
        cfg: cfg,
        logger: logger,
        awsSDKInfo: awsSDKInfo,
    }, nil
}

func getCredsFromConfig(cfg *Config) (*aws.Credentials, error) {
	// Implementation details omitted for brevity
}

----------------------------------------

TITLE: Basic AWS CloudWatch Logs Exporter Configuration
DESCRIPTION: Demonstrates the minimal required configuration for the AWS CloudWatch Logs exporter, specifying only the mandatory log group and stream names.

LANGUAGE: yaml
CODE:
exporters:
  awscloudwatchlogs:
    log_group_name: "testing-logs"
    log_stream_name: "testing-integrations-stream"

----------------------------------------

TITLE: Configuring OpenTelemetry Protocol with Apache Arrow Receiver in YAML
DESCRIPTION: Basic configuration to enable the OpenTelemetry Protocol with Apache Arrow receiver in a pipeline. This snippet demonstrates how to include the receiver with default settings.

LANGUAGE: yaml
CODE:
receivers:
  otelarrow:

----------------------------------------

TITLE: Disabling Default Metrics in OpenTelemetry Collector Contrib YAML Configuration
DESCRIPTION: This YAML configuration snippet demonstrates how to disable a default metric in the OpenTelemetry Collector Contrib project. Replace <metric_name> with the specific metric you want to disable.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Configuring JSON Format for AWS CloudWatch Metric Streams
DESCRIPTION: YAML configuration example for setting up the AWS CloudWatch Metric Streams encoding extension using JSON format.

LANGUAGE: yaml
CODE:
extensions:
  awscloudwatchmetricstreams_encoding:
    format: json

----------------------------------------

TITLE: gRPC Server Keepalive Configuration
DESCRIPTION: Configuration for gRPC server keepalive settings, including connection idle time, max age, and enforcement policies.

LANGUAGE: yaml
CODE:
keepalive:
  server_parameters:
    max_connection_idle: "1h"
    max_connection_age: "24h"
    time: "2h"
    timeout: "20s"
  enforcement_policy:
    min_time: "5m"
    permit_without_stream: true

----------------------------------------

TITLE: Disabling Default Redis Metrics in YAML Configuration
DESCRIPTION: This snippet shows how to disable a default metric in the YAML configuration file. Replace <metric_name> with the specific metric you want to disable.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Querying Log Severity Count Time Series in ClickHouse
DESCRIPTION: SQL query to get log severity count time series from the otel_logs table in ClickHouse. Groups logs by severity and 60-second intervals over the last hour.

LANGUAGE: sql
CODE:
SELECT toDateTime(toStartOfInterval(TimestampTime, INTERVAL 60 second)) as time, SeverityText, count() as count
FROM otel_logs
WHERE time >= NOW() - INTERVAL 1 HOUR
GROUP BY SeverityText, time
ORDER BY time;

----------------------------------------

TITLE: Configuring OpenTelemetry Protocol with Apache Arrow Exporter
DESCRIPTION: Example configuration for the OpenTelemetry Protocol with Apache Arrow exporter, demonstrating how to set timeout, max stream lifetime, and other related settings.

LANGUAGE: yaml
CODE:
exporters:
  otelarrow:
    timeout: 30s
    arrow:
      max_stream_lifetime: 9m30s
    endpoint: ...
    tls: ...

----------------------------------------

TITLE: Disabling Default CPU Metrics in YAML Configuration
DESCRIPTION: YAML configuration snippet to disable a default CPU metric in the OpenTelemetry Collector. Replace <metric_name> with the specific metric to disable.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Configuring OpenTelemetry 1.0.0 Format for AWS CloudWatch Metric Streams
DESCRIPTION: YAML configuration example for setting up the AWS CloudWatch Metric Streams encoding extension using OpenTelemetry 1.0.0 format.

LANGUAGE: yaml
CODE:
extensions:
  awscloudwatchmetricstreams_encoding:
    format: opentelemetry1.0

----------------------------------------

TITLE: Webhook Event Receiver Configuration
DESCRIPTION: Example configuration for the webhook event receiver showing endpoint, timeout, path, and header settings.

LANGUAGE: yaml
CODE:
receivers:
    webhookevent:
        endpoint: localhost:8088
        read_timeout: "500ms"
        path: "eventsource/receiver"
        health_path: "eventreceiver/healthcheck"
        required_header:
            key: "required-header-key"
            value: "required-header-value"
        split_logs_at_newline: false

----------------------------------------

TITLE: Configuring SQL Server Receiver with Named Instance
DESCRIPTION: Configuration example for monitoring a named SQL Server instance on Windows, including computer name and instance name specifications with resource attributes.

LANGUAGE: yaml
CODE:
    receivers:
      sqlserver:
        collection_interval: 10s
        computer_name: CustomServer
        instance_name: CustomInstance
        resource_attributes:
          sqlserver.computer.name:
            enabled: true
          sqlserver.instance.name:
            enabled: true

----------------------------------------

TITLE: Creating Kubernetes Service Account for OpenTelemetry Collector
DESCRIPTION: YAML configuration to create a Kubernetes Service Account for the OpenTelemetry Collector.

LANGUAGE: yaml
CODE:
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app: otelcontribcol
  name: otelcontribcol

----------------------------------------

TITLE: Configuring MongoDB Atlas Event Collection in YAML
DESCRIPTION: Setup for receiving events from MongoDB Atlas, including project and organization-level configurations, polling intervals, and pagination settings.

LANGUAGE: yaml
CODE:
receivers:
  mongodbatlas:
    events:
      projects:
        - name: "project 1"
      organizations:
        - id: "5b478b3afc4625789ce616a3"
      poll_interval: 1m
      page_size: 100
      max_pages: 25
    storage: file_storage

----------------------------------------

TITLE: Invalid Cross-Signal OTTL Example
DESCRIPTION: Shows an unsupported cross-signal interaction example that attempts to set a span attribute using log data.

LANGUAGE: ottl
CODE:
set(span.attributes["log body"], log.body)

----------------------------------------

TITLE: Enabling Optional Metrics in YAML
DESCRIPTION: YAML configuration snippet showing how to enable optional metrics in the OpenTelemetry Collector.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: true

----------------------------------------

TITLE: Installing Go and GCC Dependencies
DESCRIPTION: Installs required dependencies including Go runtime and GCC compiler for running integration tests. Example shows installation for Go 1.23.4 on AMD64.

LANGUAGE: bash
CODE:
apt update && apt install -y wget sudo gcc && wget https://go.dev/dl/go1.23.4.linux-amd64.tar.gz && tar -C /usr/local -xzf go1.23.4.linux-amd64.tar.gz && export PATH=$PATH:/usr/local/go/bin && go version && rm go1.23.4.linux-amd64.tar.gz

----------------------------------------

TITLE: Defining RBAC Role for Leader Elector in YAML
DESCRIPTION: This YAML snippet defines a Role for the Leader Elector extension, granting necessary permissions to manage leases in the coordination.k8s.io API group.

LANGUAGE: yaml
CODE:
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: my-lease
  namespace: default
rules:
- apiGroups:
  - coordination.k8s.io
  resources:
  - leases
  verbs:
  - get
  - list
  - watch
  - create
  - update
  - patch
  - delete

----------------------------------------

TITLE: Generated Log Entry in JSON Format
DESCRIPTION: Example of the JSON output generated by the UDP input operator for the received log messages.

LANGUAGE: json
CODE:
{
  "timestamp": "2020-04-30T12:10:17.656726-04:00",
  "body": "message1\nmessage2\n"
}

----------------------------------------

TITLE: Configuring Envoy ALS Receiver in YAML
DESCRIPTION: Basic configuration example for setting up the Envoy ALS receiver with a custom endpoint. The receiver listens for gRPC access log data from Envoy proxy instances.

LANGUAGE: yaml
CODE:
receivers:
  envoyals:
    endpoint: 0.0.0.0:3500

----------------------------------------

TITLE: Configuring ASAP Client Authentication with OTLP Exporters
DESCRIPTION: Example configuration showing how to set up ASAP client authentication with both HTTP and gRPC OTLP exporters. Includes settings for key ID, issuer, audience, private key, and token TTL along with corresponding exporter configurations.

LANGUAGE: yaml
CODE:
extensions:
  asapclient:
    # The `kid` as specified by the asap specification.
    key_id: somekeyid
    # The `iss` as specified by the asap specification.
    issuer: someissuer
    # The `aud` as specified by the asap specification.
    audience:
      - someservice
      - someotherservice
    # The private key of the client, used to sign the token. For an example, see `testdata/config.yaml`.
    private_key: ${env:ASAP_PRIVATE_KEY}
    # The time until expiry of each given token. The token will be cached and then re-provisioned upon expiry. 
    # For more info see the "exp" claim in the asap specification: https://s2sauth.bitbucket.io/spec/#access-token-generation
    ttl: 60s
    
exporters:
  otlphttp/withauth:
    endpoint: http://localhost:9000
    auth:
      authenticator: asapclient

  otlp/withauth:
    endpoint: 0.0.0.0:5000
    ca_file: /tmp/certs/ca.pem
    auth:
      authenticator: asapclient

----------------------------------------

TITLE: HTTP Check Receiver Configuration
DESCRIPTION: Complete example configuration showing how to set up the HTTP Check Receiver with multiple targets, custom headers, and pipeline configuration. Includes collection interval, batch processing, and debug export settings.

LANGUAGE: yaml
CODE:
receivers:
  httpcheck:
    collection_interval: 30s
    targets:
      - method: "GET"
        endpoints:
          - "https://opentelemetry.io"
      - method: "GET"
        endpoints: 
          - "http://localhost:8080/hello1"
          - "http://localhost:8080/hello2"
        headers:
          Authorization: "Bearer <your_bearer_token>"
      - method: "GET"
        endpoint: "http://localhost:8080/hello"
        headers:
          Authorization: "Bearer <your_bearer_token>"
processors:
  batch:
    send_batch_max_size: 1000
    send_batch_size: 100
    timeout: 10s
exporters:
  debug:
    verbosity: detailed
service:
  pipelines:
    metrics:
      receivers: [httpcheck]
      processors: [batch]
      exporters: [debug]

----------------------------------------

TITLE: Configuring Oracle DB Receiver with Primary Connection Option
DESCRIPTION: Example configuration using the primary datasource option to connect to an Oracle database. Uses a direct connection string format.

LANGUAGE: yaml
CODE:
receivers:
  oracledb:
    datasource: "oracle://otel:password@localhost:51521/XE"

----------------------------------------

TITLE: Configuring Remote Windows Event Log Receiver in YAML
DESCRIPTION: YAML configuration for the Windows Event Log Receiver to collect logs from a remote server, including server address, username, password, and domain.

LANGUAGE: yaml
CODE:
receivers:
    windowseventlog:
        channel: application
        remote:
            server:   "remote-server"
            username: "user"
            password: "password"
            domain:   "domain"

----------------------------------------

TITLE: Disabling Default Metrics in YAML Configuration
DESCRIPTION: This snippet shows how to disable a default metric in the YAML configuration. Replace <metric_name> with the specific metric you want to disable.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Shutting Down Services with Docker Compose (Bash)
DESCRIPTION: This command stops and removes the Docker containers started by Docker Compose for the secure tracing setup.

LANGUAGE: bash
CODE:
$ docker compose down

----------------------------------------

TITLE: Configuring Azure Monitor Receiver with Workload Identity Authentication
DESCRIPTION: Example configuration for the Azure Monitor Receiver using Azure Workload Identity authentication. It includes subscription ID, tenant ID, client ID, and federated token file path.

LANGUAGE: yaml
CODE:
receivers:
  azuremonitor:
    subscription_id: "${subscription_id}"
    auth: "workload_identity"
    tenant_id: "${env:AZURE_TENANT_ID}"
    client_id: "${env:AZURE_CLIENT_ID}"
    federated_token_file: "${env:AZURE_FEDERATED_TOKEN_FILE}"

----------------------------------------

TITLE: Metadata Exporter Interface Definition
DESCRIPTION: Go interface definition for metadata exporters that can consume metadata updates from the receiver.

LANGUAGE: go
CODE:
type MetadataExporter interface {
  ConsumeMetadata(metadata []*MetadataUpdate) error
}

type MetadataUpdate struct {
  ResourceIDKey string
  ResourceID    ResourceID
  MetadataDelta
}

type MetadataDelta struct {
  MetadataToAdd    map[string]string
  MetadataToRemove map[string]string
  MetadataToUpdate map[string]string
}

----------------------------------------

TITLE: CloudWatch Logs JSON Format Example
DESCRIPTION: Example of the expected JSON format for CloudWatch logs encoding, showing the structure of a log message including metadata and log events.

LANGUAGE: json
CODE:
{
  "messageType": "DATA_MESSAGE",
  "owner": "111122223333",
  "logGroup": "my-log-group",
  "logStream": "my-log-stream",
  "subscriptionFilters": ["my-subscription-filter"],
  "logEvents": [
    {
      "id": "123",
      "timestamp": 1725544035523,
      "message": "My log message."
    }
  ]
}

----------------------------------------

TITLE: Configuring TencentCloud LogService Exporter in YAML
DESCRIPTION: This YAML configuration sets up an OTLP receiver and a TencentCloud LogService exporter. It specifies the required region, logset, and topic, along with optional secret credentials for authentication.

LANGUAGE: yaml
CODE:
receivers:
  otlp:
    protocols:
      grpc:
        endpoint: ":4317"

exporters:
  tencentcloud_logservice:
      # LogService's Region, https://cloud.tencent.com/document/product/614/18940
      # set cls.{region}.tencentcloudapi.com, eg cls.ap-beijing.tencentcloudapi.com;
    region: "ap-beijing"
    # LogService's LogSet ID
    logset: "demo-logset"
    # LogService's Topic ID
    topic: "demo-topic"
    # TencentCloud secret id
    secret_id: "demo-secret-id"
    # TencentCloud secret key
    secret_key: "demo-secret-key"

service:
  pipelines:
    logs:
      receivers: [otlp]
      exporters: [tencentcloud_logservice]

----------------------------------------

TITLE: EMF Log Format Example
DESCRIPTION: Illustrates the structure of an EMF log with custom log group and stream names, including AWS metadata and metrics configuration.

LANGUAGE: json
CODE:
{
  "_aws": {
    "Timestamp": 1574109732004,
    "LogGroupName": "Foo",
    "LogStreamName": "Bar",
    "CloudWatchMetrics": [
      {
        "Namespace": "MyApp",
        "Dimensions": [["Operation"]],
        "Metrics": [
          {
            "Name": "ProcessingLatency",
            "Unit": "Milliseconds",
            "StorageResolution": 60
          }
        ]
      }
    ]
  },
  "Operation": "Aggregator",
  "ProcessingLatency": 100
}

----------------------------------------

TITLE: Enhancement: Multiple Bearer Token Support
DESCRIPTION: Add ability to configure multiple bearer tokens for the same endpoint in the bearer token auth extension



----------------------------------------

TITLE: Enabling ZSTD Compression for STEF Exporter in YAML
DESCRIPTION: Configuration example showing how to enable ZSTD compression for the STEF exporter. This is the only supported compression method.

LANGUAGE: yaml
CODE:
exporters:
  otlp:
    ...
    compression: zstd

----------------------------------------

TITLE: Sample Configuration for Container Insights on ECS
DESCRIPTION: A configuration example for using AWS Container Insights with the awscontainerinsightreceiver and awsemfexporter on an ECS cluster to collect instance-level metrics.

LANGUAGE: yaml
CODE:
receivers:
  awscontainerinsightreceiver:
    collection_interval: 10s
    container_orchestrator: ecs

processors:
  batch/metrics:
    timeout: 60s

exporters:
  awsemf:
    namespace: ContainerInsightsEC2Instance
    log_group_name: '/aws/ecs/containerinsights/{ClusterName}/performance'
    log_stream_name: 'instanceTelemetry/{ContainerInstanceId}'
    resource_to_telemetry_conversion:
      enabled: true
    dimension_rollup_option: NoDimensionRollup
    parse_json_encoded_attr_values: [Sources]
    metric_declarations:
      # instance metrics
      - dimensions: [ [ ContainerInstanceId, InstanceId, ClusterName] ]
        metric_name_selectors:
          - instance_cpu_utilization
          - instance_memory_utilization
          - instance_network_total_bytes
          - instance_cpu_reserved_capacity
          - instance_memory_reserved_capacity
          - instance_number_of_running_tasks
          - instance_filesystem_utilization
      - dimensions: [ [ClusterName] ]
        metric_name_selectors:
          - instance_cpu_utilization
          - instance_memory_utilization
          - instance_network_total_bytes
          - instance_cpu_reserved_capacity
          - instance_memory_reserved_capacity
          - instance_number_of_running_tasks
          - instance_cpu_usage_total
          - instance_cpu_limit
          - instance_memory_working_set
          - instance_memory_limit
  debug:
    verbosity: detailed
service:
  pipelines:
    metrics:
      receivers: [awscontainerinsightreceiver]
      processors: [batch/metrics]
      exporters: [awsemf,debug]

----------------------------------------

TITLE: Running Docker Compose Demo for OpenTelemetry-Splunk Integration
DESCRIPTION: Command to start the Docker Compose environment that launches both the OpenTelemetry Collector and Splunk instance. This sets up the complete demo environment for metrics collection and visualization.

LANGUAGE: bash
CODE:
docker-compose up

----------------------------------------

TITLE: Configuring Azure Monitor Exporter with Connection String in YAML
DESCRIPTION: Example YAML configuration for the Azure Monitor Exporter using the recommended connection string method. This configuration includes the InstrumentationKey and IngestionEndpoint.

LANGUAGE: yaml
CODE:
exporters:
  azuremonitor:
    connection_string: "InstrumentationKey=00000000-0000-0000-0000-000000000000;IngestionEndpoint=https://ingestion.azuremonitor.com/"

----------------------------------------

TITLE: InfluxDB Line Protocol Example - Prometheus v1 Format
DESCRIPTION: Example of metrics data in Prometheus v1 format using InfluxDB Line Protocol, showing various metric types including gauges, counters, and histograms.

LANGUAGE: plaintext
CODE:
cpu_temp,foo=bar gauge=87.332\nhttp_requests_total,method=post,code=200 counter=1027\nhttp_requests_total,method=post,code=400 counter=3\nhttp_request_duration_seconds 0.05=24054,0.1=33444,0.2=100392,0.5=129389,1=133988,sum=53423,count=144320\nrpc_duration_seconds 0.01=3102,0.05=3272,0.5=4773,0.9=9001,0.99=76656,sum=1.7560473e+07,count=2693

----------------------------------------

TITLE: Disabling Specific Aerospike Metrics in YAML Configuration
DESCRIPTION: This YAML configuration snippet demonstrates how to disable specific metrics in the Aerospike collector. Each metric can be individually disabled by setting its 'enabled' property to false.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Transform Processor Configuration for Resource Attributes
DESCRIPTION: Configuration example showing how to copy resource attributes into metric labels using the transform processor.

LANGUAGE: yaml
CODE:
processor:
  transform:
    metric_statements:
      - context: datapoint
        statements:
        - set(attributes["namespace"], resource.attributes["k8s.namespace.name"])
        - set(attributes["container"], resource.attributes["k8s.container.name"])
        - set(attributes["pod"], resource.attributes["k8s.pod.name"])

----------------------------------------

TITLE: Configuring Azure Monitor Exporter with Instrumentation Key in YAML
DESCRIPTION: Legacy YAML configuration for the Azure Monitor Exporter using the instrumentation key. This method is not recommended and will be deprecated in the future.

LANGUAGE: yaml
CODE:
exporters:
  azuremonitor:
    instrumentation_key: b1cd0778-85fc-4677-a3fa-79d3c23e0efd

----------------------------------------

TITLE: Configuring Retain Operator for Object in Body in YAML
DESCRIPTION: This configuration shows how to retain an entire object within the body of a log entry. It keeps the 'object' field and its nested contents, while removing other top-level fields in the body.

LANGUAGE: yaml
CODE:
- type: retain
  fields:
    - body.object

----------------------------------------

TITLE: Creating Deployment for OpenTelemetry Collector in Kubernetes
DESCRIPTION: Bash script to create a Kubernetes Deployment for the OpenTelemetry Collector, specifying the container image, configuration, and volume mounts.

LANGUAGE: bash
CODE:
<<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: otelcontribcol
  labels:
    app: otelcontribcol
spec:
  replicas: 1
  selector:
    matchLabels:
      app: otelcontribcol
  template:
    metadata:
      labels:
        app: otelcontribcol
    spec:
      serviceAccountName: otelcontribcol
      containers:
      - name: otelcontribcol
        # This image is created by running `make docker-otelcontribcol`.
        # If you are not building the collector locally, specify a published image: `otel/opentelemetry-collector-contrib`
        image: otelcontribcol:latest
        args: ["--config", "/etc/config/config.yaml"]
        volumeMounts:
        - name: config
          mountPath: /etc/config
        imagePullPolicy: IfNotPresent
      volumes:
        - name: config
          configMap:
            name: otelcontribcol
EOF

----------------------------------------

TITLE: DirectoryServices Performance Counter Paths
DESCRIPTION: Collection of Windows performance counter paths under the DirectoryServices namespace that monitor various aspects of directory service operations including replication, LDAP operations, security, and thread management

LANGUAGE: plaintext
CODE:
\DirectoryServices(*)\DRA Inbound Properties Total/sec
\DirectoryServices(*)\AB Browses/sec
\DirectoryServices(*)\DRA Inbound Objects Applied/sec
[...additional counter paths...]

----------------------------------------

TITLE: Configuring OpenTelemetry Protocol with Apache Arrow Exporter in YAML
DESCRIPTION: Example YAML configuration for setting up secure and insecure OpenTelemetry Protocol with Apache Arrow exporters. Demonstrates endpoint configuration and TLS settings.

LANGUAGE: yaml
CODE:
exporters:
  otelarrow/secure:
    endpoint: external-collector:4317
    tls:
      cert_file: file.cert
      key_file: file.key
  otelarrow/insecure:
    endpoint: internal-collector:4317
    tls:
      insecure: true

----------------------------------------

TITLE: Configuring BMC Helix Exporter in YAML
DESCRIPTION: Basic YAML configuration for the BMC Helix Exporter, specifying the required endpoint and API key settings.

LANGUAGE: yaml
CODE:
exporters:
  bmchelix/helix1:
    endpoint: https://company.onbmc.com
    api_key: <api-key>

----------------------------------------

TITLE: Configuring Azure Monitor Receiver with Service Principal Authentication
DESCRIPTION: Example configuration for the Azure Monitor Receiver using Service Principal authentication. It includes subscription ID, tenant ID, client ID, client secret, and other optional settings like resource groups and services to monitor.

LANGUAGE: yaml
CODE:
receivers:
  azuremonitor:
    subscription_id: "${subscription_id}"
    tenant_id: "${tenant_id}"
    client_id: "${client_id}"
    client_secret: "${env:CLIENT_SECRET}"
    cloud: AzureUSGovernment
    resource_groups:
      - "${resource_group1}"
      - "${resource_group2}"
    services:
      - "${service1}"
      - "${service2}"
    collection_interval: 60s
    initial_delay: 1s

----------------------------------------

TITLE: Scaling Existing Metrics
DESCRIPTION: Example configuration demonstrating how to create a new memory usage metric in bytes by scaling an existing metric in megabytes.

LANGUAGE: yaml
CODE:
rules:
    - name: pod.memory.usage.bytes
      unit: Bytes
      type: scale
      metric1: pod.memory.usage.megabytes
      operation: multiply
      scale_by: 1048576

----------------------------------------

TITLE: Configuring Loki Exporter in OpenTelemetry Collector
DESCRIPTION: Example YAML configuration for the Loki exporter in the OpenTelemetry Collector, showing basic setup with endpoint and label settings.

LANGUAGE: yaml
CODE:
exporters:
  loki:
    endpoint: https://loki.example.com:3100/loki/api/v1/push
    default_labels_enabled:
      exporter: false
      job: true

----------------------------------------

TITLE: Kubernetes Attribute Mapping for Coralogix Exporter
DESCRIPTION: Configuration example showing how to map Kubernetes attributes to Coralogix application and subsystem names.

LANGUAGE: yaml
CODE:
exporters:
  coralogix:
    domain: "coralogix.com"
    application_name_attributes:
      - "k8s.namespace.name" 
      - "service.namespace"
    subsystem_name_attributes:
      - "k8s.deployment.name"
      - "k8s.statefulset.name"
      - "k8s.daemonset.name"
      - "k8s.cronjob.name"
      - "service.name"

----------------------------------------

TITLE: Configuring AlibabaCloud LogService Exporter for All Telemetry Data in YAML
DESCRIPTION: This snippet shows how to configure the AlibabaCloud LogService Exporter for exporting all types of telemetry data (logs, metrics, and traces) to different LogService stores. It includes separate configurations for each data type.

LANGUAGE: yaml
CODE:
receivers:
  examplereceiver:

exporters:
  alibabacloud_logservice/logs:
    endpoint: "cn-hangzhou.log.aliyuncs.com"
    project: "demo-project"
    logstore: "logs-store"
    access_key_id: "access-key-id"
    access_key_secret: "access-key-secret"
  alibabacloud_logservice/metrics:
    endpoint: "cn-hangzhou.log.aliyuncs.com"
    project: "demo-project"
    logstore: "metrics-store"
    access_key_id: "access-key-id"
    access_key_secret: "access-key-secret"
  alibabacloud_logservice/traces:
    endpoint: "cn-hangzhou.log.aliyuncs.com"
    project: "demo-project"
    logstore: "traces-store"
    access_key_id: "access-key-id"
    access_key_secret: "access-key-secret"

service:
  pipelines:
    traces:
      receivers: [examplereceiver]
      exporters: [alibabacloud_logservice/traces]
    logs:
      receivers: [examplereceiver]
      exporters: [alibabacloud_logservice/logs]
    metrics:
      receivers: [examplereceiver]
      exporters: [alibabacloud_logservice/metrics]

----------------------------------------

TITLE: Configuring Logging for Kinetica Exporter
DESCRIPTION: YAML configuration for setting up logging using Uber zap package and lumberjack for log rotation.

LANGUAGE: YAML
CODE:
level: 'info'
development: true
disableCaller: false
disableStacktrace: false
encoding: 'console'
encoderConfig:
  messageKey: 'msg'
  levelKey: 'level'
  timeKey: 'ts'
  nameKey: 'logger'
  callerKey: 'caller'
  functionKey: 'function'
  stacktraceKey: 'stacktrace'
  skipLineEnding: false
  lineEnding: "\n"
  levelEncoder: 'capital'
  timeEncoder: 'iso8601'
  durationEncoder: 'string'
  callerEncoder: 'full'
  nameEncoder: 'full'
  consoleSeparator: ' | '
outputPaths:
  - 'stdout'
  - 'lumberjack://localhost/logs/kinetica-exporter.log?maxSize=10&maxBackups=5&maxAge=10'
errorOutputPaths:
  - 'stderr'
  - './logs/error_logs'
initialFields:
  app: 'kinetica-exporter'

----------------------------------------

TITLE: Setting Custom Log Source in Datadog
DESCRIPTION: Configuration example showing how to add a custom source to OTLP logs using resource attribute transformation. Requires the UseLogsAgentExporter feature flag to be enabled.

LANGUAGE: yaml
CODE:
processors:
  transform/logs:
    log_statements:
      - context: resource
        statements:
          - set(attributes["datadog.log.source"], "otel")

----------------------------------------

TITLE: Configuring Detailed Metrics for OpenTelemetry Protocol with Apache Arrow Receiver
DESCRIPTION: Configuration snippet to enable detailed metrics for the OpenTelemetry Protocol with Apache Arrow receiver, which provides more in-depth performance and diagnostic information.

LANGUAGE: yaml
CODE:
service
  ...
  telemetry:
    ...
    metrics:
      ...
      level: detailed

----------------------------------------

TITLE: OTTL Function Example - SHA256
DESCRIPTION: Example showing how to hash a string value using SHA256

LANGUAGE: ottl
CODE:
SHA256(resource.attributes["device.name"])

----------------------------------------

TITLE: Finding Spans with Specific Attributes in ClickHouse
DESCRIPTION: SQL query to find spans with specific attributes from the otel_traces table in ClickHouse. Filters by service name and span attribute, limiting results to the last hour.

LANGUAGE: sql
CODE:
SELECT Timestamp,
       TraceId,
       SpanId,
       ParentSpanId,
       SpanName,
       SpanKind,
       ServiceName,
       Duration,
       StatusCode,
       StatusMessage,
       toString(SpanAttributes),
       toString(ResourceAttributes),
       toString(Events.Name),
       toString(Links.TraceId)
FROM otel_traces
WHERE ServiceName = 'clickhouse-exporter'
  AND SpanAttributes['peer.service'] = 'telemetrygen-server'
  AND Timestamp >= NOW() - INTERVAL 1 HOUR
Limit 100;

----------------------------------------

TITLE: TLS Configuration for Faro Exporter in YAML
DESCRIPTION: Example showing how to configure the Faro exporter with HTTPS and TLS settings, including an option to skip TLS verification.

LANGUAGE: yaml
CODE:
exporters:
  faro:
    endpoint: "https://faro.example.com/collect"

  faro/tlsnoverify:
    endpoint: "https://faro.example.com/collect"
    tls:
      insecure_skip_verify: true

----------------------------------------

TITLE: Configuring Skywalking Encoding Extension in YAML
DESCRIPTION: This snippet demonstrates how to configure the Skywalking encoding extension in the OpenTelemetry Collector. It shows the extension declaration and its usage with a Kafka receiver.

LANGUAGE: yaml
CODE:
extensions:
  skywalking_encoding:

receivers:
  kafka:
    encoding: skywalking_encoding

----------------------------------------

TITLE: Configuring Wavefront Receiver in YAML for OpenTelemetry Collector
DESCRIPTION: Demonstrates how to configure the Wavefront receiver in the OpenTelemetry Collector's YAML configuration. It shows both default and custom settings for the receiver, including endpoint, TCP idle timeout, and CollectD tag extraction option.

LANGUAGE: yaml
CODE:
receivers:
  wavefront:
  wavefront/allsettings:
    endpoint: localhost:8080
    tcp_idle_timeout: 5s
    extract_collectd_tags: true

----------------------------------------

TITLE: OTTL Converter Example - ParseJSON
DESCRIPTION: Example showing how to parse a JSON string into a pcommon.Map

LANGUAGE: ottl
CODE:
ParseJSON("{\"attr\":true}")

----------------------------------------

TITLE: Basic Windows Performance Counter Configuration
DESCRIPTION: Base configuration structure for the Windows Performance Counters receiver showing metric definition and counter collection setup.

LANGUAGE: yaml
CODE:
windowsperfcounters:
  collection_interval: <duration> # default = "1m"
  initial_delay: <duration> # default = "1s"
  metrics:
    <metric name>:
      description: <description>
      unit: <unit type>
      gauge:
    <metric name>:
      description: <description>
      unit: <unit type>
      sum:
        aggregation: <cumulative or delta>
        monotonic: <true or false>
  perfcounters:
    - object: <object name>
      instances: [<instance name>]*
      counters:
        - name: <counter name>
          metric: <metric name>
          attributes:
            <key>: <value>
          recreate_query: <true or false>

----------------------------------------

TITLE: Configuring Compression for Google Cloud Pubsub Exporter
DESCRIPTION: Example configuration enabling gzip compression for Pubsub messages to reduce costs.

LANGUAGE: yaml
CODE:
exporters:
  googlecloudpubsub:
    project: my-project
    topic: projects/my-project/topics/otlp-traces
    compression: gzip

----------------------------------------

TITLE: Configuring BMC Helix Exporter with Optional Settings
DESCRIPTION: Extended YAML configuration for the BMC Helix Exporter, including optional settings like timeout and retry configuration.

LANGUAGE: yaml
CODE:
exporters:
  bmchelix/helix2:
    endpoint: https://company.onbmc.com
    api_key: <api-key>
    timeout: 20s
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 1m
      max_elapsed_time: 8m

----------------------------------------

TITLE: Metric Data Type Enum Values
DESCRIPTION: Definition of enum values for different metric data types as defined in pdata metrics

LANGUAGE: protobuf
CODE:
METRIC_DATA_TYPE_NONE = 0
METRIC_DATA_TYPE_GAUGE = 1
METRIC_DATA_TYPE_SUM = 2
METRIC_DATA_TYPE_HISTOGRAM = 3
METRIC_DATA_TYPE_EXPONENTIAL_HISTOGRAM = 4
METRIC_DATA_TYPE_SUMMARY = 5

----------------------------------------

TITLE: Sample JSON Output from Windows Event Log Receiver
DESCRIPTION: An example of the JSON output structure produced by the Windows Event Log Receiver, showing various fields captured from an event log entry.

LANGUAGE: json
CODE:
{
    "channel": "Application",
    "computer": "computer name",
    "event_id":
    {
        "id": 10,
        "qualifiers": 0
    },
    "keywords": "[Classic]",
    "level": "Information",
    "message": "Test log",
    "opcode": "Info",
    "provider":
    {
        "event_source": "",
        "guid": "",
        "name": "otel"
    },
    "record_id": 12345,
    "system_time": "2022-04-15T15:28:08.898974100Z",
    "task": ""
}

----------------------------------------

TITLE: Configuring OpenTelemetry Collector Builder
DESCRIPTION: YAML configuration for building the OpenTelemetry collector binary with Kinetica exporter support.

LANGUAGE: YAML
CODE:
dist:
  name: otelcol-kinetica
  description: Otel collector with Kinetica exporter
  output_path: /home/kinetica/otelexporter_utils/collector-binary
  otelcol_version: 0.78.2

exporters:
  - gomod:
      github.com/open-telemetry/opentelemetry-collector-contrib/exporter/fileexporter v0.78.0

processors:
  - gomod:
      go.opentelemetry.io/collector/processor/batchprocessor v0.78.2

receivers:
  - gomod:
      go.opentelemetry.io/collector/receiver/otlpreceiver v0.78.2
  - gomod:
      github.com/open-telemetry/opentelemetry-collector-contrib/receiver/prometheusreceiver v0.78.0

----------------------------------------

TITLE: Configuring Default Metrics in YAML
DESCRIPTION: YAML configuration snippet showing how to disable default metrics in the OpenTelemetry Collector.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Creating Kubernetes RBAC Resources
DESCRIPTION: Series of Kubernetes commands to set up necessary RBAC permissions including ServiceAccount, ClusterRole, and ClusterRoleBinding for the k8s_observer.

LANGUAGE: bash
CODE:
<<EOF | kubectl apply -f -
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app: otelcontribcol
  name: otelcontribcol
EOF

LANGUAGE: bash
CODE:
<<EOF | kubectl apply -f -
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: otelcontribcol
  labels:
    app: otelcontribcol
rules:
- apiGroups:
  - ""
  resources:
  - nodes
  - services
  - pods
  verbs:
  - get
  - list
  - watch
- apiGroups: 
  - "networking.k8s.io"
  resources:
  - ingresses
  verbs:
  - get
  - watch
  - list
EOF

LANGUAGE: bash
CODE:
<<EOF | kubectl apply -f -
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: otelcontribcol
  labels:
    app: otelcontribcol
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: otelcontribcol
subjects:
- kind: ServiceAccount
  name: otelcontribcol
  namespace: default
EOF

----------------------------------------

TITLE: Visualizing Issue State Workflow with Mermaid Diagram
DESCRIPTION: This Mermaid flowchart illustrates the potential issue states and how issues move through different stages in the OpenTelemetry Collector Contrib project. It shows the workflow from a new issue being opened, through triage, assignment, and resolution.

LANGUAGE: mermaid
CODE:
flowchart TD
    n0(["New issue has been opened"]) --> n1
    n1(["Needs Triage"]) --> n2["Has good repro steps <br>and/or description?"]
  subgraph graph2["**waiting-for-codeowners**"]
        n3["Waiting for Codeowners<br>to further validate the issue"]
  end
  subgraph graph3["**waiting-for-author**"]
        n4["Waiting for author to provide more details"]
  end
  subgraph graph4["**help-wanted**"]
        n8["Waiting on community"]
  end
  subgraph graph5["**closed**"]
        n10(["Close the issue and provide details as needed"])
  end
    n2 -- Yes --> n3
    n2 -- No/Need more details --> n4
    n2 -- Invalid configuration/alternative available --> n10
    n3 -- Invalid Issue --> n10
    n3 -- Valid Issue -->  n6["Codeowner has time<br>to fix it?"]
    n6 -- Assign it to codeowner --> n7["Issue in being worked upon"]
    n6 -- No --> n8
    n7 -- Once PR is merged --> n10
    n8 -- When someone volunteers to provide a fix --> n11["Assign it to the person"]
    n12 -- Any activity on the issue --> n8
    n8 -. Issue becomes stale due to lack of activity .-> n12["Issue is inactive"]
    n11 --> n7
    n12 -- Closed automatically after 120 days due to lack of activity --> n10
    n4 -- Once enough details are available --> n2

    n3@{ shape: rect}
    n4@{ shape: rect}
    n2@{ shape: diam}
    n6@{ shape: diam}

     n1:::Aqua
     n3:::Ash
     n4:::Ash
     n8:::Ash
     n2:::Ash
     n2:::Peach
     n6:::Peach
     n7:::Ash
     n10:::Rose
    classDef Rose stroke-width:1px, stroke-dasharray:none, stroke:#FF5978, fill:#FFDFE5, color:#8E2236
    classDef Aqua stroke-width:1px, stroke-dasharray:none, stroke:#46EDC8, fill:#DEFFF8, color:#378E7A
    classDef Peach stroke-width:1px, stroke-dasharray:none, stroke:#FBB35A, fill:#FFEFDB, color:#8F632D
    classDef Ash stroke-width:1px, stroke-dasharray:none, stroke:#999999, fill:#EEEEEE, color:#000000

----------------------------------------

TITLE: Webhook Event JSON Body Example - Single Log
DESCRIPTION: Example of webhook body format when split_logs_at_newline is set to false, resulting in a single log record.

LANGUAGE: yaml
CODE:
{
"name": "francis",
"city": "newyork"
}
a fifth line

----------------------------------------

TITLE: Starting Local Loki Instance in Bash
DESCRIPTION: Command to start a local Loki instance using a Linux binary. Assumes the configuration file is in the current directory.

LANGUAGE: bash
CODE:
$ loki-linux-amd64

----------------------------------------

TITLE: Disabling ZooKeeper Metrics in YAML Configuration
DESCRIPTION: Shows how to disable specific metrics in the ZooKeeper configuration using YAML. This snippet demonstrates the structure for disabling individual metrics.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Defining Circular Dependencies for OpenTelemetry Collector Contrib Modules
DESCRIPTION: This configuration specifies two sets of modules with circular dependencies: the Datadog exporter and connector, and the OTel Arrow receiver, exporter, and internal module. It's used to maintain awareness of these dependencies and prevent accidental changes.

LANGUAGE: plaintext
CODE:
# exporter/datadog <-> connector/datadog
exporter/datadogexporter
connector/datadogconnector

# receiver/otelarrow <-> internal/otelarrow <-> exporter/otelarrow
receiver/otelarrowreceiver
exporter/otelarrowexporter
internal/otelarrow

----------------------------------------

TITLE: Full Sample Collector Configuration
DESCRIPTION: Complete configuration example showing StatsD receiver setup with file exporter and metrics pipeline.

LANGUAGE: yaml
CODE:
receivers:
  statsd:
    endpoint: "localhost:8125" # default
    aggregation_interval: 60s  # default
    enable_metric_type: false   # default
    is_monotonic_counter: false # default
    timer_histogram_mapping:
      - statsd_type: "histogram"
        observer_type: "histogram"
        histogram:
          max_size: 50
      - statsd_type: "distribution"
        observer_type: "histogram"
        histogram: 
          max_size: 50    
      - statsd_type: "timing"
        observer_type: "summary"

exporters:
  file:
    path: ./test.json

service:
  pipelines:
    metrics:
     receivers: [statsd]
     exporters: [file]

----------------------------------------

TITLE: Configuring Solarwinds APM Settings Extension in YAML
DESCRIPTION: This snippet demonstrates how to configure the Solarwinds APM Settings extension in the YAML configuration file. It includes the required 'endpoint' and 'key' parameters, as well as the optional 'interval' setting.

LANGUAGE: yaml
CODE:
extensions:
  solarwindsapmsettings:
    endpoint: "<endpoint>"
    key: "<token>:<name>"
    interval: 10s

----------------------------------------

TITLE: Using AES Encrypted Value in YAML Configuration
DESCRIPTION: This YAML snippet demonstrates how to use an AES encrypted value in a configuration file using the ${aes:...} placeholder pattern.

LANGUAGE: yaml
CODE:
password: ${aes:RsEf6cTWrssi8tlssfs1AJs2bRMrVm2Ce5TaWPY=}

----------------------------------------

TITLE: Configuring Ack Extension in OpenTelemetry Collector YAML
DESCRIPTION: This YAML configuration snippet demonstrates how to set up the Ack extension in the OpenTelemetry Collector. It includes settings for storage, partition limits, and integration with the Splunk HEC receiver.

LANGUAGE: yaml
CODE:
extensions:
  ack:
    storage:
    max_number_of_partition: 1000000
    max_number_of_pending_acks_per_partition: 1000000

receivers:
  splunk_hec:
    ack_extension: ack

service:
  extensions: [ack]
  pipelines:
    logs:
      receivers: [splunk_hec]

----------------------------------------

TITLE: Configuring Cgroup Runtime Extension in YAML
DESCRIPTION: This YAML snippet demonstrates how to configure the cgroupruntime extension in the OpenTelemetry Collector. It shows settings for enabling and configuring GOMAXPROCS and GOMEMLIMIT, including the memory ratio allocation.

LANGUAGE: yaml
CODE:
extension:
    # processor name: cgroupruntime
    cgroupruntime:
      gomaxprocs:
        enabled: true
      gomemlimit:
        enabled: true
        ratio: 0.8

----------------------------------------

TITLE: Parsing SQL Server Metrics JSON in Any Language
DESCRIPTION: This JSON object contains key-value pairs representing various SQL Server metrics and properties. It includes information about server configuration, resource utilization, database states, and version details. This data can be parsed and used for monitoring or reporting purposes.

LANGUAGE: json
CODE:
[{"ForceEncryption":"0","Port":"1433","PortType":"Static","available_server_memory":"4517288","cpu_count":"16","db_offline":"0","db_online":"4","db_recovering":"0","db_recoveryPending":"0","db_restoring":"0","db_suspect":"0","engine_edition":"3","hardware_type":"HYPERVISOR","instance_type":"0","is_hadr_enabled":"0","measurement":"sqlserver_server_properties","server_memory":"6421504","service_name":"MSSQLSERVER","sku":"Developer Edition (64-bit)","sql_instance":"ad8fb2b53dce","computer_name":"abcde","sql_version":"16.0.4105.2","sql_version_desc":"Microsoft SQL Server 2022 (RTM-CU11) (KB5032679) ","uptime":"17393"}]

----------------------------------------

TITLE: Configuring Database Storage Extension with PostgreSQL Key/Value in YAML
DESCRIPTION: Example configuration for the Database Storage extension using PostgreSQL driver with a key/value-formatted datasource.

LANGUAGE: yaml
CODE:
extensions:
  db_storage:
    driver: "pgx"
    datasource: "host=127.0.0.1 port=5432 user=otel password=otel_password database=otlp sslmode=disable"

----------------------------------------

TITLE: Configuring Mezmo Log Exporter with OpenTelemetry Collector
DESCRIPTION: Example configuration for setting up the Mezmo exporter with OTLP receiver and resource detection processor. Includes hostname detection which is required for Mezmo log ingestion. The configuration demonstrates proper pipeline setup for logs processing and export.

LANGUAGE: yaml
CODE:
receivers:
  otlp:
    protocols:
      grpc:
        endpoint: ":4317"

processors:
  resourcedetection:
    detectors:
      - system
    system:
      hostname_sources:
        - os

exporters:
  mezmo:
    ingest_url: "https://logs.mezmo.com/otel/ingest/rest"
    ingest_key: "00000000000000000000000000000000"

service:
  pipelines:
    logs:
      receivers: [ otlp ]
      processors: [ resourcedetection ]
      exporters: [ mezmo ]

----------------------------------------

TITLE: Uninstalling OpenTelemetry Collector Deployment
DESCRIPTION: Command to remove the OpenTelemetry Collector Deployment from the kind cluster.

LANGUAGE: bash
CODE:
make kind-uninstall-deployment

----------------------------------------

TITLE: Enabling Optional SQL Server Metrics in YAML
DESCRIPTION: YAML configuration to enable an optional metric in the SQL Server collector.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: true

----------------------------------------

TITLE: Testing Scraper with Golden File Comparison in Go
DESCRIPTION: This snippet demonstrates how to test a scraper by comparing its output to a golden file. It shows the process of writing metrics to a golden file, reading expected metrics, and comparing them with actual metrics.

LANGUAGE: go
CODE:
func TestScraper(t *testing.T) {
	cfg := createDefaultConfig().(*Config)
	require.NoError(t, xconfmap.Validate(cfg))

	scraper := newScraper(componenttest.NewNopReceiverCreateSettings(), cfg)

	err := scraper.start(context.Background(), componenttest.NewNopHost())
	require.NoError(t, err)

	actualMetrics, err := scraper.scrape(context.Background())
	require.NoError(t, err)

	expectedFile := filepath.Join("testdata", "scraper", "expected.yaml")

	golden.WriteMetrics(t, expectedFile, actualMetrics) // This line is temporary! TODO remove this!!

	expectedMetrics, err := golden.ReadMetrics(expectedFile)
	require.NoError(t, err)

	require.NoError(t, pmetrictest.CompareMetrics(expectedMetrics, actualMetrics))
}

----------------------------------------

TITLE: Advanced UDP Protocol Configuration with YAML
DESCRIPTION: Advanced configuration example demonstrating UDP protocol settings including queue size, packet size, workers, and socket buffer configuration.

LANGUAGE: yaml
CODE:
protocols:
  thrift_binary:
    endpoint: 0.0.0.0:6832
    queue_size: 5_000
    max_packet_size: 131_072
    workers: 50
    socket_buffer_size: 8_388_608

----------------------------------------

TITLE: Configuring Azure Monitor Exporter for AAD Authentication Proxy in YAML
DESCRIPTION: This snippet illustrates how to configure the Azure Monitor Exporter to use the AAD Authentication Proxy by modifying the ingestion endpoint in the YAML configuration file.

LANGUAGE: yaml
CODE:
exporters:
   azuremonitor:
      connection_string: "InstrumentationKey=00000000-0000-0000-0000-000000000000;IngestionEndpoint=http://localhost:8081"

----------------------------------------

TITLE: Stopping Couchbase Environment
DESCRIPTION: Docker Compose command to shut down the entire environment.

LANGUAGE: sh
CODE:
docker-compose down

----------------------------------------

TITLE: SignalFx Pipeline Configuration
DESCRIPTION: Complete pipeline configuration example showing how to set up both metrics and logs pipelines with the SignalFx receiver, including necessary processors and exporters.

LANGUAGE: yaml
CODE:
service:
  pipelines:
    metrics:
      receivers: [signalfx]
      processors: [memory_limiter, batch]
      exporters: [signalfx]
    logs:
      receivers: [signalfx]
      processors: [memory_limiter, batch]
      exporters: [signalfx]

----------------------------------------

TITLE: Configuring Multiline File Input in YAML
DESCRIPTION: Configuration example demonstrating how to set up file input with multiline support using a line start pattern

LANGUAGE: yaml
CODE:
- type: file_input
  include:
    - ./test.log
  multiline:
    line_start_pattern: 'START '

----------------------------------------

TITLE: Creating HTTP Client with Timeout in Factory for Prometheus Remote Write Exporter in Go
DESCRIPTION: This code snippet shows how to create an HTTP client with a configurable timeout in the Factory's CreateNewExporter method for the Prometheus Remote Write/Cortex exporter.

LANGUAGE: go
CODE:
func (f *Factory) CreateNewExporter (config) {
...
    client := &http.Client{
            Timeout: config.requestTimeout
    }
...
}

----------------------------------------

TITLE: Implementing PushMetrics Function in Go
DESCRIPTION: This code snippet demonstrates the basic structure of the PushMetrics function for the Prometheus Remote Write/Cortex exporter. It creates a map to store distinct TimeSeries, processes incoming metrics, and exports them to the backend.

LANGUAGE: go
CODE:
func PushMetrics(metricsData) {

 // Create a map that stores distinct TimeSeries
 map := make(map[String][]TimeSeries)

 for metric in metricsData:
	 for point in metric:
	   // Generate signature string
	   sig := pointSignature(metric, point)

	   // Find corresponding TimeSeries in map
	   // Add to TimeSeries

  // Sends TimeSeries to backend
  export(map)
}

----------------------------------------

TITLE: OpenCensus Receiver CORS Configuration in YAML
DESCRIPTION: Configuration example showing how to enable CORS for the HTTP/JSON endpoint. Demonstrates setting allowed origins including wildcard patterns.

LANGUAGE: yaml
CODE:
receivers:
  opencensus:
    cors_allowed_origins:
    - http://test.com
    # Origins can have wildcards with *, use * by itself to match any origin.
    - https://*.example.com

----------------------------------------

TITLE: Configuring File Log Receiver for JSON Logs
DESCRIPTION: Example configuration for tailing a simple JSON log file using the File Log Receiver. It includes file path specification and JSON parsing with timestamp extraction.

LANGUAGE: yaml
CODE:
receivers:
  filelog:
    include: [ /var/log/myservice/*.json ]
    operators:
      - type: json_parser
        timestamp:
          parse_from: attributes.time
          layout: '%Y-%m-%d %H:%M:%S'

----------------------------------------

TITLE: Configuring Azure Blob Exporter in YAML for OpenTelemetry Collector
DESCRIPTION: This YAML snippet demonstrates how to configure the Azure Blob Exporter for the OpenTelemetry Collector. It includes extensions setup, exporter configuration with authentication, and container settings for different telemetry types.

LANGUAGE: yaml
CODE:
extensions:
  zpages:
    endpoint: localhost:55679
  text_encoding:
    encoding: utf8
    marshaling_separator: "\n"
    unmarshaling_separator: "\r?\n"

exporter:
  azureblob/1:
    url: "https://<your-account>.blob.core.windows.net/"
    container:
      logs: "logs"
      metrics: "metrics"
      traces: "traces"
    auth:
      type: "connection_string"
      connection_string: "DefaultEndpointsProtocol=https;AccountName=<your-acount>;AccountKey=<account-key>;EndpointSuffix=core.windows.net"
          traces: "test"
    encodings:
      logs: text_encoding

----------------------------------------

TITLE: Testing Logs Receiver in Go
DESCRIPTION: This code snippet shows how to test a logs receiver using pmetrictest.CompareLogs. It sets up a receiver, processes logs, and compares the results with expected logs from a JSON file.

LANGUAGE: go
CODE:
func TestLogsReceiver(t *testing.T) {
	sink := &consumertest.LogsSink{}
	rcvr := newLogsReceiver(createDefaultConfig().(*Config), zap.NewNop(), sink)
	rcvr.client = defaultMockClient()
	require.NoError(t,  rcvr.Start(context.Background(), componenttest.NewNopHost()))
	require.Eventually(t, func() bool {
		return sink.LogRecordCount() > 0
	}, 2*time.Second, 10*time.Millisecond)
	err = rcvr.Shutdown(context.Background())
	require.NoError(t, err)
	actualLogs := sink.AllLogs()[0]

	expectedLogs, err := readLogs(filepath.Join("testdata", "logs", "expected.json"))
	require.NoError(t, err)

	require.NoError(t, pmetrictest.CompareLogs(expectedLogs, actualLogs))
}

----------------------------------------

TITLE: Building OpenTelemetry Collector Contrib Docker Image
DESCRIPTION: This command builds a Docker image for the OpenTelemetry Collector Contrib project. It should be run from the root of the project.

LANGUAGE: shell
CODE:
docker build -t otelcontribcol .

----------------------------------------

TITLE: Basic OpenCensus Receiver Configuration in YAML
DESCRIPTION: Minimal configuration required to enable the OpenCensus receiver with default settings. By default, it will listen on localhost:55678.

LANGUAGE: yaml
CODE:
receivers:
  opencensus:

----------------------------------------

TITLE: Configuring FlinkMetrics Receiver in YAML
DESCRIPTION: Example configuration showing how to set up the FlinkMetrics receiver with basic settings including endpoint and collection interval configuration.

LANGUAGE: yaml
CODE:
receivers:
  flinkmetrics:
    endpoint: http://localhost:8081
    collection_interval: 10s

----------------------------------------

TITLE: Configuring Headers Setter Extension in YAML
DESCRIPTION: This snippet demonstrates how to configure the headers_setter extension, along with receivers, processors, and exporters in the OpenTelemetry Collector. It shows various header actions and value sources, including context and static values.

LANGUAGE: yaml
CODE:
extensions:
  headers_setter:
    headers:
      - action: insert
        key: X-Scope-OrgID
        from_context: tenant_id
        default_value: Org-ID
      - action: upsert
        key: User-ID
        value: user_id
      - action: update
        key: User-ID
        value: user_id
      - action: delete
        key: Some-Header

receivers:
  otlp:
    protocols:
      http:
        include_metadata: true

processors:
  batch:
    # Preserve the tenant-id metadata.
    metadata_keys:
    - tenant_id

exporters:
  loki:
    labels:
      resource:
        container_id: ""
        container_name: ""
    endpoint: https://localhost:<port>/loki/api/v1/push
    auth:
      authenticator: headers_setter

service:
  extensions: [ headers_setter ]
  pipelines:
    traces:
      receivers: [ otlp ]
      processors: [ batch ]
      exporters: [ loki ]

----------------------------------------

TITLE: Setting AWS Log Group Names via Environment Variable
DESCRIPTION: Example showing how to set multiple AWS log group names using the OTEL_RESOURCE_ATTRIBUTES environment variable. Multiple log groups are separated using the & character.

LANGUAGE: shell
CODE:
export OTEL_RESOURCE_ATTRIBUTES="aws.log.group.names=log-group1&log-group2&log-group3"

----------------------------------------

TITLE: Configuring Named Pipe Receiver in OpenTelemetry YAML
DESCRIPTION: Example configuration for setting up a Named Pipe receiver. Demonstrates how to specify the pipe path and optional mode bits for file permissions.

LANGUAGE: yaml
CODE:
receivers:
  namedpipe:
    path: /tmp/pipe
    mode: 0600

----------------------------------------

TITLE: Configuring Redis Storage Extension in YAML
DESCRIPTION: Example YAML configuration for the Redis Storage extension in OpenTelemetry Collector. It demonstrates both default and custom settings, including endpoint, password, database selection, expiration time, and key prefix.

LANGUAGE: yaml
CODE:
extensions:
  redis_storage:
  redis_storage/all_settings:
    endpoint: localhost:6379
    password: ""
    db: 0
    expiration: 5m
    prefix: test_

service:
  extensions: [redis_storage, redis_storage/all_settings]
  pipelines:
    traces:
      receivers: [nop]
      exporters: [nop]

# Data pipeline is required to load the config.
receivers:
  nop:
exporters:
  nop:

----------------------------------------

TITLE: Testing Trace Processor in Go
DESCRIPTION: This example demonstrates how to test a trace processor using ptracetest.CompareTraces. It sets up a processor, processes traces, and compares them with expected traces from a JSON file, ignoring start and end timestamps.

LANGUAGE: go
CODE:
func TestTraceProcessor(t *testing.T) {
	nextTrace := new(consumertest.TracesSink)
	tp, err := newTracesProcessor(NewFactory().CreateDefaultConfig(), nextTrace)
	traces := generateTraces()
	tp.ConsumeTraces(ctx, traces)
	actualTraces := nextTrace.AllTraces()[0]

	expectedTraces, err := readTraces(filepath.Join("testdata", "traces", "expected.json"))
	require.NoError(t, err)
	
	require.NoError(t, ptracetest.CompareTraces(expectedTraces, actualTraces, ptracetest.IgnoreStartTimestamp(), 
		ptracetest.IgnoreEndTimestamp()))
}

----------------------------------------

TITLE: Advanced AWS CloudWatch Logs EMF Configuration
DESCRIPTION: Shows a complete configuration example for EMF logs with additional optional parameters including region, endpoint, retention period, and tags.

LANGUAGE: yaml
CODE:
exporters:
  awscloudwatchlogs:
    log_group_name: "testing-logs-emf"
    log_stream_name: "testing-integrations-stream-emf"
    raw_log: true
    region: "us-east-1"
    endpoint: "logs.us-east-1.amazonaws.com"
    log_retention: 365
    tags: { "sampleKey": "sampleValue" }

----------------------------------------

TITLE: Configuring Netflow and SFlow Receivers in OpenTelemetry Collector YAML
DESCRIPTION: This YAML configuration sets up two Netflow receivers, one for standard Netflow/IPFIX on port 2055 and another for SFlow on port 6343. It also configures a batch processor and a debug exporter, demonstrating a complete pipeline setup.

LANGUAGE: yaml
CODE:
receivers:
  netflow:
    - scheme: netflow
      port: 2055
      sockets: 16
      workers: 32
  netflow/sflow:
    - scheme: sflow
      port: 6343
      sockets: 16
      workers: 32

processors:
  batch:
    send_batch_size: 2000
    timeout: 30s

exporters:
  debug:
    verbosity: detailed

service:
  pipelines:
    logs:
      receivers: [netflow, netflow/sflow]
      processors: [batch]
      exporters: [debug]
  telemetry:
    logs:
      level: debug

----------------------------------------

TITLE: Configuring Google Cloud Spanner Receiver in YAML
DESCRIPTION: Example YAML configuration for the Google Cloud Spanner Receiver, including collection interval, initial delay, project details, and instance configurations.

LANGUAGE: yaml
CODE:
receivers:
  googlecloudspanner:
    collection_interval: 60s
    initial_delay: 1s
    top_metrics_query_max_rows: 100
    backfill_enabled: true
    cardinality_total_limit: 200000
    hide_topn_lockstats_rowrangestartkey: false
    truncate_text: false
    projects:
      - project_id: "spanner project 1"
        service_account_key: "path to spanner project 1 service account json key"
        instances:
          - instance_id: "id1"
            databases:
              - "db11"
              - "db12"
          - instance_id: "id2"
            databases:
              - "db21"
              - "db22"
      - project_id: "spanner project 2"
        service_account_key: "path to spanner project 2 service account json key"
        instances:
          - instance_id: "id3"
            databases:
              - "db31"
              - "db32"
          - instance_id: "id4"
            databases:
              - "db41"
              - "db42"

----------------------------------------

TITLE: Analyzing AWS X-Ray Trace Segment for DynamoDB Operation
DESCRIPTION: This JSON structure represents an AWS X-Ray trace segment for a DynamoDB operation. It includes details about the operation, error encountered, and nested subsegments for various stages of the request lifecycle.

LANGUAGE: json
CODE:
{
    "trace_id": "1-5f29ab21-d4ebf299219a65bd5c31d6da",
    "id": "88ad1df59cd7a7be",
    "name": "DDB",
    "start_time": 1596566305.535414,
    "end_time": 1596566305.5928545,
    "fault": true,
    "cause": {
        "working_directory": "/home/ubuntu/opentelemetry-collector-contrib/receiver/awsxrayreceiver/testdata/rawsegment/sampleapp",
        "exceptions": [
            {
                "id": "3e9e11e3ab3fba60",
                "type": "dynamodb.ResourceNotFoundException",
                "message": "ResourceNotFoundException: Requested resource not found",
                "stack": [
                    {
                        "path": "runtime/proc.go",
                        "line": 203,
                        "label": "main"
                    },
                    {
                        "path": "runtime/asm_amd64.s",
                        "line": 1373,
                        "label": "goexit"
                    }
                ],
                "remote": true
            }
        ]
    },
    "user": "xraysegmentdump",
    "aws": {
        "xray": {
            "sdk_version": "1.1.0",
            "sdk": "X-Ray for Go"
        }
    },
    "service": {
        "compiler_version": "go1.14.6",
        "compiler": "gc"
    },
    "subsegments": [
        {
            "id": "7df694142c905d8d",
            "name": "DDB.DescribeExistingTableAndPutToMissingTable",
            "start_time": 1596566305.5354965,
            "end_time": 1596566305.5928457,
            "fault": true,
            "cause": {
                "working_directory": "/home/ubuntu/opentelemetry-collector-contrib/receiver/awsxrayreceiver/testdata/rawsegment/sampleapp",
                "exceptions": [
                    {
                        "id": "e2ba8a2109451f5b",
                        "type": "dynamodb.ResourceNotFoundException",
                        "message": "ResourceNotFoundException: Requested resource not found",
                        "stack": [
                            {
                                "path": "github.com/aws/aws-xray-sdk-go@v1.1.0/xray/capture.go",
                                "line": 48,
                                "label": "Capture"
                            },
                            {
                                "path": "sampleapp/sample.go",
                                "line": 41,
                                "label": "ddbExpectedFailure"
                            },
                            {
                                "path": "sampleapp/sample.go",
                                "line": 36,
                                "label": "main"
                            },
                            {
                                "path": "runtime/proc.go",
                                "line": 203,
                                "label": "main"
                            },
                            {
                                "path": "runtime/asm_amd64.s",
                                "line": 1373,
                                "label": "goexit"
                            }
                        ],
                        "remote": true
                    }
                ]
            },
            "annotations": {
                "DDB.DescribeExistingTableAndPutToMissingTable.Annotation": "anno"
            },
            "metadata": {
                "default": {
                    "DDB.DescribeExistingTableAndPutToMissingTable.AddMetadata": "meta"
                }
            },
            "subsegments": [
                {
                    "id": "7318c46a385557f5",
                    "name": "dynamodb",
                    "start_time": 1596566305.5355225,
                    "end_time": 1596566305.5873947,
                    "namespace": "aws",
                    "http": {
                        "response": {
                            "status": 200,
                            "content_length": 713
                        }
                    },
                    "aws": {
                        "operation": "DescribeTable",
                        "region": "us-west-2",
                        "request_id": "29P5V7QSAKHS4LNL56ECAJFF3BVV4KQNSO5AEMVJF66Q9ASUAAJG",
                        "retries": 0,
                        "table_name": "xray_sample_table"
                    },
                    "subsegments": [
                        {
                            "id": "0239834271dbee25",
                            "name": "marshal",
                            "start_time": 1596566305.5355248,
                            "end_time": 1596566305.5355635,
                            "Dummy": false
                        },
                        {
                            "id": "23cf5bb60e4f66b1",
                            "name": "attempt",
                            "start_time": 1596566305.5355663,
                            "end_time": 1596566305.5873196,
                            "subsegments": [
                                {
                                    "id": "417b81b977b9563b",
                                    "name": "connect",
                                    "start_time": 1596566305.5357504,
                                    "end_time": 1596566305.575329,
                                    "metadata": {
                                        "http": {
                                            "connection": {
                                                "reused": false,
                                                "was_idle": false
                                            }
                                        }
                                    },
                                    "subsegments": [
                                        {
                                            "id": "0cab02b318413eb1",
                                            "name": "dns",
                                            "start_time": 1596566305.5357957,
                                            "end_time": 1596566305.5373216,
                                            "metadata": {
                                                "http": {
                                                    "dns": {
                                                        "addresses": [
                                                            {
                                                                "IP": "52.94.10.94",
                                                                "Zone": ""
                                                            }
                                                        ],
                                                        "coalesced": false
                                                    }
                                                }
                                            },
                                            "Dummy": false
                                        },
                                        {
                                            "id": "f8dbc5c6b291017e",
                                            "name": "dial",
                                            "start_time": 1596566305.5373297,
                                            "end_time": 1596566305.537964,
                                            "metadata": {
                                                "http": {
                                                    "connect": {
                                                        "network": "tcp"
                                                    }
                                                }
                                            },
                                            "Dummy": false
                                        },
                                        {
                                            "id": "e2deb66ecaa769a5",
                                            "name": "tls",
                                            "start_time": 1596566305.5380135,
                                            "end_time": 1596566305.5753162,
                                            "metadata": {
                                                "http": {
                                                    "tls": {
                                                        "cipher_suite": 49199,
                                                        "did_resume": false,
                                                        "negotiated_protocol": "http/1.1",
                                                        "negotiated_protocol_is_mutual": true
                                                    }
                                                }
                                            },
                                            "Dummy": false
                                        }
                                    ],
                                    "Dummy": false
                                },
                                {
                                    "id": "a70bfab91597c7a2",
                                    "name": "request",
                                    "start_time": 1596566305.5753367,
                                    "end_time": 1596566305.5754144,
                                    "Dummy": false
                                },
                                {
                                    "id": "c05331c26d3e8a7f",
                                    "name": "response",
                                    "start_time": 1596566305.5754204,
                                    "end_time": 1596566305.5872962,
                                    "Dummy": false
                                }
                            ],
                            "Dummy": false
                        },
                        {
                            "id": "5fca2dfc9de81f4c",
                            "name": "unmarshal",
                            "start_time": 1596566305.5873249,
                            "end_time": 1596566305.587389,
                            "Dummy": false
                        }
                    ],
                    "Dummy": false
                },
                {
                    "id": "71631df3f58bdfc5",
                    "name": "dynamodb",
                    "start_time": 1596566305.5874245,
                    "end_time": 1596566305.5928326,
                    "fault": true,
                    "cause": {
                        "working_directory": "/home/ubuntu/opentelemetry-collector-contrib/receiver/awsxrayreceiver/testdata/rawsegment/sampleapp",
                        "exceptions": [
                            {
                                "id": "7121b882a0ef44da",
                                "type": "dynamodb.ResourceNotFoundException",
                                "message": "ResourceNotFoundException: Requested resource not found",
                                "stack": [
                                    {
                                        "path": "github.com/aws/aws-sdk-go@v1.33.9/aws/request/handlers.go",
                                        "line": 267,
                                        "label": "(*HandlerList).Run"
                                    },
                                    {
                                        "path": "github.com/aws/aws-sdk-go@v1.33.9/aws/request/request.go",
                                        "line": 515,
                                        "label": "(*Request).Send.func1"
                                    },
                                    {
                                        "path": "github.com/aws/aws-sdk-go@v1.33.9/aws/request/request.go",
                                        "line": 538,
                                        "label": "(*Request).Send"
                                    },
                                    {
                                        "path": "github.com/aws/aws-sdk-go@v1.33.9/service/dynamodb/api.go",
                                        "line": 3414,
                                        "label": "(*DynamoDB).PutItemWithContext"
                                    },
                                    {
                                        "path": "sampleapp/sample.go",
                                        "line": 62,
                                        "label": "ddbExpectedFailure.func1"
                                    },
                                    {
                                        "path": "github.com/aws/aws-xray-sdk-go@v1.1.0/xray/capture.go",
                                        "line": 45,
                                        "label": "Capture"
                                    },
                                    {
                                        "path": "sampleapp/sample.go",
                                        "line": 41,
                                        "label": "ddbExpectedFailure"
                                    },
                                    {
                                        "path": "sampleapp/sample.go",
                                        "line": 36,
                                        "label": "main"
                                    },
                                    {
                                        "path": "runtime/proc.go",
                                        "line": 203,
                                        "label": "main"
                                    },
                                    {
                                        "path": "runtime/asm_amd64.s",
                                        "line": 1373,
                                        "label": "goexit"
                                    }
                                ],
                                "remote": true
                            }
                        ]
                    },
                    "namespace": "aws",
                    "http": {
                        "response": {
                            "status": 400,
                            "content_length": 112
                        }
                    },
                    "aws": {
                        "consumed_capacity": null,
                        "item_collection_metrics": null,
                        "operation": "PutItem",
                        "region": "us-west-2",
                        "request_id": "TJUJNR0JV84CFHJL93D3GIA0LBVV4KQNSO5AEMVJF66Q9ASUAAJG",
                        "retries": 0,
                        "table_name": "does_not_exist"
                    },
                    "subsegments": [
                        {
                            "id": "9da02fcbb9711b47",
                            "name": "marshal",
                            "start_time": 1596566305.5874267,
                            "end_time": 1596566305.58745,
                            "Dummy": false
                        },
                        {
                            "id": "56b1cb185cbdb378",
                            "name": "attempt",
                            "start_time": 1596566305.587453,
                            "end_time": 1596566305.592767,
                            "fault": true,
                            "cause": {
                                "working_directory": "/home/ubuntu/opentelemetry-collector-contrib/receiver/awsxrayreceiver/testdata/rawsegment/sampleapp",
                                "exceptions": [
                                    {
                                        "id": "59de8ae27660d21d",
                                        "type": "dynamodb.ResourceNotFoundException",
                                        "message": "ResourceNotFoundException: Requested resource not found",
                                        "stack": [
                                            {
                                                "path": "github.com/aws/aws-xray-sdk-go@v1.1.0/xray/aws.go",
                                                "line": 139,
                                                "label": "glob..func7"
                                            },
                                            {
                                                "path": "github.com/aws/aws-sdk-go@v1.33.9/aws/request/handlers.go",
                                                "line": 267,
                                                "label": "(*HandlerList).Run"
                                            },
                                            {
                                                "path": "github.com/aws/aws-sdk-go@v1.33.9/aws/request/request.go",
                                                "line": 534,
                                                "label": "(*Request).Send"
                                            },
                                            {
                                                "path": "github.com/aws/aws-sdk-go@v1.33.9/service/dynamodb/api.go",
                                                "line": 3414,
                                                "label": "(*DynamoDB).PutItemWithContext"
                                            },
                                            {
                                                "path": "sampleapp/sample.go",
                                                "line": 62,
                                                "label": "ddbExpectedFailure.func1"
                                            },
                                            {
                                                "path": "github.com/aws/aws-xray-sdk-go@v1.1.0/xray/capture.go",
                                                "line": 45,
                                                "label": "Capture"
                                            },
                                            {
                                                "path": "sampleapp/sample.go",
                                                "line": 41,
                                                "label": "ddbExpectedFailure"
                                            },
                                            {
                                                "path": "sampleapp/sample.go",
                                                "line": 36,
                                                "label": "main"
                                            },
                                            {
                                                "path": "runtime/proc.go",
                                                "line": 203,
                                                "label": "main"
                                            },
                                            {
                                                "path": "runtime/asm_amd64.s",
                                                "line": 1373,
                                                "label": "goexit"
                                            }
                                        ],
                                        "remote": true
                                    }
                                ]
                            },
                            "subsegments": [
                                {
                                    "id": "6f908a1d3ec70abe",
                                    "name": "request",
                                    "start_time": 1596566305.5875077,
                                    "end_time": 1596566305.587543,
                                    "Dummy": false
                                },
                                {
                                    "id": "acfaa7e3fe3aab03",
                                    "name": "response",
                                    "start_time": 1596566305.5875454,
                                    "end_time": 1596566305.592695,
                                    "Dummy": false
                                }
                            ],
                            "Dummy": false
                        },
                        {
                            "id": "ba8d350c0e8cdc4b",
                            "name": "wait",
                            "start_time": 1596566305.592807,
                            "end_time": 1596566305.5928102,
                            "fault": true,
                            "cause": {
                                "working_directory": "/home/ubuntu/opentelemetry-collector-contrib/receiver/awsxrayreceiver/testdata/rawsegment/sampleapp",
                                "exceptions": [
                                    {
                                        "id": "5a07f08a8c260405",
                                        "type": "dynamodb.ResourceNotFoundException",
                                        "message": "ResourceNotFoundException: Requested resource not found",
                                        "stack": [
                                            {
                                                "path": "github.com/aws/aws-xray-sdk-go@v1.1.0/xray/aws.go",
                                                "line": 149,
                                                "label": "glob..func8"
                                            },
                                            {
                                                "path": "github.com/aws/aws-sdk-go@v1.33.9/aws/request/handlers.go",
                                                "line": 267,
                                                "label": "(*HandlerList).Run"
                                            },
                                            {
                                                "path": "github.com/aws/aws-sdk-go@v1.33.9/aws/request/request.go",
                                                "line": 535,
                                                "label": "(*Request).Send"
                                            },
                                            {
                                                "path": "github.com/aws/aws-sdk-go@v1.33.9/service/dynamodb/api.go",
                                                "line": 3414,
                                                "label": "(*DynamoDB).PutItemWithContext"
                                            },
                                            {
                                                "path": "sampleapp/sample.go",
                                                "line": 62,
                                                "label": "ddbExpectedFailure.func1"
                                            },
                                            {
                                                "path": "github.com/aws/aws-xray-sdk-go@v1.1.0/xray/capture.go",
                                                "line": 45,
                                                "label": "Capture"
                                            },
                                            {
                                                "path": "sampleapp/sample.go",
                                                "line": 41,
                                                "label": "ddbExpectedFailure"
                                            },
                                            {
                                                "path": "sampleapp/sample.go",
                                                "line": 36,
                                                "label": "main"
                                            },
                                            {
                                                "path": "runtime/proc.go",
                                                "line": 203,
                                                "label": "main"
                                            },
                                            {
                                                "path": "runtime/asm_amd64.s",
                                                "line": 1373,
                                                "label": "goexit"
                                            }
                                        ],
                                        "remote": true
                                    }
                                ]
                            },
                            "Dummy": false
                        }
                    ],
                    "Dummy": false
                }
            ],
            "Dummy": false
        }
    ],
    "Dummy": false
}

----------------------------------------

TITLE: Configuring Azure Monitor Exporter with Environment Variable in YAML
DESCRIPTION: YAML configuration for the Azure Monitor Exporter when using the APPLICATIONINSIGHTS_CONNECTION_STRING environment variable. This method is useful for cloud or containerized environments.

LANGUAGE: yaml
CODE:
exporters:
  azuremonitor:

----------------------------------------

TITLE: Kafka Receiver Configuration with SASL and TLS in YAML
DESCRIPTION: An example configuration for connecting to Kafka using SASL authentication and TLS encryption.

LANGUAGE: yaml
CODE:
receivers:
  kafka:
    auth:
      sasl:
        username: "user"
        password: "secret"
        mechanism: "SCRAM-SHA-512"
      tls:
        insecure: false

----------------------------------------

TITLE: Prometheus API Server Configuration
DESCRIPTION: YAML configuration for enabling and configuring the Prometheus API server functionality within the receiver.

LANGUAGE: yaml
CODE:
receivers:
  prometheus:
    api_server:
      enabled: true
      server_config:
        endpoint: "localhost:9090"

----------------------------------------

TITLE: Configuring Attribute Extraction from Span Names in YAML
DESCRIPTION: This snippet demonstrates how to configure the span processor to extract attributes from span names using regular expressions. It shows the structure for specifying rules, break_after_match, and keep_original_name options.

LANGUAGE: yaml
CODE:
span/to_attributes:
  name:
    to_attributes:
      rules:
        - regexp-rule1
        - regexp-rule2
        - regexp-rule3
      break_after_match: <true|false>
      keep_original_name: <true|false>

----------------------------------------

TITLE: Creating OpenTelemetry Schema Tables in Kinetica
DESCRIPTION: SQL statements to create the necessary tables in Kinetica for storing OpenTelemetry data, including logs, traces, and metrics.

LANGUAGE: SQL
CODE:
CREATE TABLE otel.log
(
        log_id                   VARCHAR (uuid),            -- generated
        trace_id                 VARCHAR(32),
        span_id                  VARCHAR(16),
        time_unix_nano           TIMESTAMP,
        observed_time_unix_nano  TIMESTAMP,
        severity_id              TINYINT,
        severity_text            VARCHAR(8),
        body                     VARCHAR,
        flags                    INT,
        PRIMARY KEY (log_id)
) USING TABLE PROPERTIES (NO_ERROR_IF_EXISTS = TRUE);

-- Additional table creation statements omitted for brevity

----------------------------------------

TITLE: Generating AES-256 Key using OpenSSL in Shell
DESCRIPTION: This command generates a 32-byte (AES-256) key using OpenSSL and encodes it in base64 format.

LANGUAGE: shell
CODE:
openssl rand -base64 32

----------------------------------------

TITLE: Configuring CollectD Receiver in YAML
DESCRIPTION: Example YAML configuration for the CollectD receiver. It demonstrates setting up multiple instances with different configurations, including custom attributes prefix, endpoint, and timeout.

LANGUAGE: yaml
CODE:
receivers:
  collectd:
  collectd/one:
    attributes_prefix: "dap_"
    endpoint: "localhost:12345"
    timeout: "50s"

----------------------------------------

TITLE: Configuring Simple Windows Event Log Receiver in YAML
DESCRIPTION: A basic YAML configuration for the Windows Event Log Receiver, specifying the application channel to monitor.

LANGUAGE: yaml
CODE:
receivers:
    windowseventlog:
        channel: application

----------------------------------------

TITLE: Database Metrics Log Entry
DESCRIPTION: A single line of log data containing database metrics with fields separated by tabs. The values appear to represent schema name, table name, followed by numeric metrics.

LANGUAGE: plaintext
CODE:
a_schema	a_table	123	38	734976	0

----------------------------------------

TITLE: OpenTelemetry Collector Configuration
DESCRIPTION: YAML configuration for setting up an OpenTelemetry Collector to receive telemetry data from telemetrygen.

LANGUAGE: yaml
CODE:
receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317

processors:
  batch:

exporters:
  debug:
    verbosity: detailed

service:
  pipelines:
    logs:
      receivers: [otlp]
      processors: [batch]
      exporters: [debug]
    metrics:
      receivers: [otlp]
      processors: [batch]
      exporters: [debug]
    traces:
      receivers: [otlp]
      processors: [batch]
      exporters: [debug]

----------------------------------------

TITLE: Configuring Azure Event Hub Receiver in YAML
DESCRIPTION: Example configuration for setting up the Azure Event Hub receiver with connection details, partition settings, consumer group, offset, and format options. Includes optional time format configurations for logs and metrics parsing.

LANGUAGE: yaml
CODE:
receivers:
  azureeventhub:
    connection: Endpoint=sb://namespace.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=superSecret1234=;EntityPath=hubName
    partition: foo
    group: bar
    offset: "1234-5566"
    format: "azure"
    # optional
    time_formats:
      # All supported time format. Default is empty string array, which means using the current iso8601 parser. The format is based on https://pkg.go.dev/time#Layout. If no time-zone info, will use UTC time.
      logs: ["01/02/2006 15:04:05","2006-01-02 15:04:05","2006-01-02T15:04:05Z07:00"]
      metrics: ["01/02/2006 15:04:05"]

----------------------------------------

TITLE: AWS X-Ray Segment Data Structure for DynamoDB Operations
DESCRIPTION: This JSON structure represents an AWS X-Ray segment for DynamoDB operations. It includes details about the trace, subsegments for different operations, error information, and metadata about AWS services and HTTP requests.

LANGUAGE: json
CODE:
{
    "trace_id": "1-5f29ab21-d4ebf299219a65bd5c31d6da",
    "id": "88ad1df59cd7a7be",
    "name": "DDB",
    "start_time": 1596566305.535414,
    "end_time": 1596566305.5928545,
    "fault": true,
    "cause": {
        "working_directory": "/home/ubuntu/opentelemetry-collector-contrib/receiver/awsxrayreceiver/testdata/rawsegment/sampleapp",
        "exceptions": [
            {
                "id": "3e9e11e3ab3fba60",
                "type": "dynamodb.ResourceNotFoundException",
                "message": "ResourceNotFoundException: Requested resource not found",
                "stack": [
                    {
                        "path": "runtime/proc.go",
                        "line": 203,
                        "label": "main"
                    },
                    {
                        "path": "runtime/asm_amd64.s",
                        "line": 1373,
                        "label": "goexit"
                    }
                ],
                "remote": true
            }
        ]
    },
    "user": "xraysegmentdump",
    "aws": {
        "xray": {
            "sdk_version": "1.1.0",
            "sdk": "X-Ray for Go"
        }
    },
    "service": {
        "compiler_version": "go1.14.6",
        "compiler": "gc"
    },
    "subsegments": [
        {
            "id": "7df694142c905d8d",
            "name": "DDB.DescribeExistingTableAndPutToMissingTable",
            "start_time": 1596566305.5354965,
            "end_time": 1596566305.5928457,
            "fault": true,
            "cause": {
                "working_directory": "/home/ubuntu/opentelemetry-collector-contrib/receiver/awsxrayreceiver/testdata/rawsegment/sampleapp",
                "exceptions": [
                    {
                        "id": "e2ba8a2109451f5b",
                        "type": "dynamodb.ResourceNotFoundException",
                        "message": "ResourceNotFoundException: Requested resource not found",
                        "stack": [
                            {
                                "path": "github.com/aws/aws-xray-sdk-go@v1.1.0/xray/capture.go",
                                "line": 48,
                                "label": "Capture"
                            },
                            {
                                "path": "sampleapp/sample.go",
                                "line": 41,
                                "label": "ddbExpectedFailure"
                            },
                            {
                                "path": "sampleapp/sample.go",
                                "line": 36,
                                "label": "main"
                            },
                            {
                                "path": "runtime/proc.go",
                                "line": 203,
                                "label": "main"
                            },
                            {
                                "path": "runtime/asm_amd64.s",
                                "line": 1373,
                                "label": "goexit"
                            }
                        ],
                        "remote": true
                    }
                ]
            },
            "annotations": {
                "DDB.DescribeExistingTableAndPutToMissingTable.Annotation": "anno"
            },
            "metadata": {
                "default": {
                    "DDB.DescribeExistingTableAndPutToMissingTable.AddMetadata": "meta"
                }
            },
            "subsegments": [
                {
                    "id": "7318c46a385557f5",
                    "name": "dynamodb",
                    "start_time": 1596566305.5355225,
                    "end_time": 1596566305.5873947,
                    "namespace": "invalidNs",
                    "http": {
                        "response": {
                            "status": 200,
                            "content_length": 713
                        }
                    },
                    "aws": {
                        "operation": "DescribeTable",
                        "region": "us-west-2",
                        "request_id": "29P5V7QSAKHS4LNL56ECAJFF3BVV4KQNSO5AEMVJF66Q9ASUAAJG",
                        "retries": 0,
                        "table_name": "xray_sample_table"
                    },
                    "subsegments": [
                        {
                            "id": "0239834271dbee25",
                            "name": "marshal",
                            "start_time": 1596566305.5355248,
                            "end_time": 1596566305.5355635,
                            "Dummy": false
                        },
                        {
                            "id": "23cf5bb60e4f66b1",
                            "name": "attempt",
                            "start_time": 1596566305.5355663,
                            "end_time": 1596566305.5873196,
                            "subsegments": [
                                {
                                    "id": "417b81b977b9563b",
                                    "name": "connect",
                                    "start_time": 1596566305.5357504,
                                    "end_time": 1596566305.575329,
                                    "metadata": {
                                        "http": {
                                            "connection": {
                                                "reused": false,
                                                "was_idle": false
                                            }
                                        }
                                    },
                                    "subsegments": [
                                        {
                                            "id": "0cab02b318413eb1",
                                            "name": "dns",
                                            "start_time": 1596566305.5357957,
                                            "end_time": 1596566305.5373216,
                                            "metadata": {
                                                "http": {
                                                    "dns": {
                                                        "addresses": [
                                                            {
                                                                "IP": "52.94.10.94",
                                                                "Zone": ""
                                                            }
                                                        ],
                                                        "coalesced": false
                                                    }
                                                }
                                            },
                                            "Dummy": false
                                        },
                                        {
                                            "id": "f8dbc5c6b291017e",
                                            "name": "dial",
                                            "start_time": 1596566305.5373297,
                                            "end_time": 1596566305.537964,
                                            "metadata": {
                                                "http": {
                                                    "connect": {
                                                        "network": "tcp"
                                                    }
                                                }
                                            },
                                            "Dummy": false
                                        },
                                        {
                                            "id": "e2deb66ecaa769a5",
                                            "name": "tls",
                                            "start_time": 1596566305.5380135,
                                            "end_time": 1596566305.5753162,
                                            "metadata": {
                                                "http": {
                                                    "tls": {
                                                        "cipher_suite": 49199,
                                                        "did_resume": false,
                                                        "negotiated_protocol": "http/1.1",
                                                        "negotiated_protocol_is_mutual": true
                                                    }
                                                }
                                            },
                                            "Dummy": false
                                        }
                                    ],
                                    "Dummy": false
                                },
                                {
                                    "id": "a70bfab91597c7a2",
                                    "name": "request",
                                    "start_time": 1596566305.5753367,
                                    "end_time": 1596566305.5754144,
                                    "Dummy": false
                                },
                                {
                                    "id": "c05331c26d3e8a7f",
                                    "name": "response",
                                    "start_time": 1596566305.5754204,
                                    "end_time": 1596566305.5872962,
                                    "Dummy": false
                                }
                            ],
                            "Dummy": false
                        },
                        {
                            "id": "5fca2dfc9de81f4c",
                            "name": "unmarshal",
                            "start_time": 1596566305.5873249,
                            "end_time": 1596566305.587389,
                            "Dummy": false
                        }
                    ],
                    "Dummy": false
                },
                {
                    "id": "71631df3f58bdfc5",
                    "name": "dynamodb",
                    "start_time": 1596566305.5874245,
                    "end_time": 1596566305.5928326,
                    "fault": true,
                    "cause": {
                        "working_directory": "/home/ubuntu/opentelemetry-collector-contrib/receiver/awsxrayreceiver/testdata/rawsegment/sampleapp",
                        "exceptions": [
                            {
                                "id": "7121b882a0ef44da",
                                "type": "dynamodb.ResourceNotFoundException",
                                "message": "ResourceNotFoundException: Requested resource not found",
                                "stack": [
                                    {
                                        "path": "github.com/aws/aws-sdk-go@v1.33.9/aws/request/handlers.go",
                                        "line": 267,
                                        "label": "(*HandlerList).Run"
                                    },
                                    {
                                        "path": "github.com/aws/aws-sdk-go@v1.33.9/aws/request/request.go",
                                        "line": 515,
                                        "label": "(*Request).Send.func1"
                                    },
                                    {
                                        "path": "github.com/aws/aws-sdk-go@v1.33.9/aws/request/request.go",
                                        "line": 538,
                                        "label": "(*Request).Send"
                                    },
                                    {
                                        "path": "github.com/aws/aws-sdk-go@v1.33.9/service/dynamodb/api.go",
                                        "line": 3414,
                                        "label": "(*DynamoDB).PutItemWithContext"
                                    },
                                    {
                                        "path": "sampleapp/sample.go",
                                        "line": 62,
                                        "label": "ddbExpectedFailure.func1"
                                    },
                                    {
                                        "path": "github.com/aws/aws-xray-sdk-go@v1.1.0/xray/capture.go",
                                        "line": 45,
                                        "label": "Capture"
                                    },
                                    {
                                        "path": "sampleapp/sample.go",
                                        "line": 41,
                                        "label": "ddbExpectedFailure"
                                    },
                                    {
                                        "path": "sampleapp/sample.go",
                                        "line": 36,
                                        "label": "main"
                                    },
                                    {
                                        "path": "runtime/proc.go",
                                        "line": 203,
                                        "label": "main"
                                    },
                                    {
                                        "path": "runtime/asm_amd64.s",
                                        "line": 1373,
                                        "label": "goexit"
                                    }
                                ],
                                "remote": true
                            }
                        ]
                    },
                    "namespace": "aws",
                    "http": {
                        "response": {
                            "status": 400,
                            "content_length": 112
                        }
                    },
                    "aws": {
                        "consumed_capacity": null,
                        "item_collection_metrics": null,
                        "operation": "PutItem",
                        "region": "us-west-2",
                        "request_id": "TJUJNR0JV84CFHJL93D3GIA0LBVV4KQNSO5AEMVJF66Q9ASUAAJG",
                        "retries": 0,
                        "table_name": "does_not_exist"
                    },
                    "subsegments": [
                        {
                            "id": "9da02fcbb9711b47",
                            "name": "marshal",
                            "start_time": 1596566305.5874267,
                            "end_time": 1596566305.58745,
                            "Dummy": false
                        },
                        {
                            "id": "56b1cb185cbdb378",
                            "name": "attempt",
                            "start_time": 1596566305.587453,
                            "end_time": 1596566305.592767,
                            "fault": true,
                            "cause": {
                                "working_directory": "/home/ubuntu/opentelemetry-collector-contrib/receiver/awsxrayreceiver/testdata/rawsegment/sampleapp",
                                "exceptions": [
                                    {
                                        "id": "59de8ae27660d21d",
                                        "type": "dynamodb.ResourceNotFoundException",
                                        "message": "ResourceNotFoundException: Requested resource not found",
                                        "stack": [
                                            {
                                                "path": "github.com/aws/aws-xray-sdk-go@v1.1.0/xray/aws.go",
                                                "line": 139,
                                                "label": "glob..func7"
                                            },
                                            {
                                                "path": "github.com/aws/aws-sdk-go@v1.33.9/aws/request/handlers.go",
                                                "line": 267,
                                                "label": "(*HandlerList).Run"
                                            },
                                            {
                                                "path": "github.com/aws/aws-sdk-go@v1.33.9/aws/request/request.go",
                                                "line": 534,
                                                "label": "(*Request).Send"
                                            },
                                            {
                                                "path": "github.com/aws/aws-sdk-go@v1.33.9/service/dynamodb/api.go",
                                                "line": 3414,
                                                "label": "(*DynamoDB).PutItemWithContext"
                                            },
                                            {
                                                "path": "sampleapp/sample.go",
                                                "line": 62,
                                                "label": "ddbExpectedFailure.func1"
                                            },
                                            {
                                                "path": "github.com/aws/aws-xray-sdk-go@v1.1.0/xray/capture.go",
                                                "line": 45,
                                                "label": "Capture"
                                            },
                                            {
                                                "path": "sampleapp/sample.go",
                                                "line": 41,
                                                "label": "ddbExpectedFailure"
                                            },
                                            {
                                                "path": "sampleapp/sample.go",
                                                "line": 36,
                                                "label": "main"
                                            },
                                            {
                                                "path": "runtime/proc.go",
                                                "line": 203,
                                                "label": "main"
                                            },
                                            {
                                                "path": "runtime/asm_amd64.s",
                                                "line": 1373,
                                                "label": "goexit"
                                            }
                                        ],
                                        "remote": true
                                    }
                                ]
                            },
                            "subsegments": [
                                {
                                    "id": "6f908a1d3ec70abe",
                                    "name": "request",
                                    "start_time": 1596566305.5875077,
                                    "end_time": 1596566305.587543,
                                    "Dummy": false
                                },
                                {
                                    "id": "acfaa7e3fe3aab03",
                                    "name": "response",
                                    "start_time": 1596566305.5875454,
                                    "end_time": 1596566305.592695,
                                    "Dummy": false
                                }
                            ],
                            "Dummy": false
                        },
                        {
                            "id": "ba8d350c0e8cdc4b",
                            "name": "wait",
                            "start_time": 1596566305.592807,
                            "end_time": 1596566305.5928102,
                            "fault": true,
                            "cause": {
                                "working_directory": "/home/ubuntu/opentelemetry-collector-contrib/receiver/awsxrayreceiver/testdata/rawsegment/sampleapp",
                                "exceptions": [
                                    {
                                        "id": "5a07f08a8c260405",
                                        "type": "dynamodb.ResourceNotFoundException",
                                        "message": "ResourceNotFoundException: Requested resource not found",
                                        "stack": [
                                            {
                                                "path": "github.com/aws/aws-xray-sdk-go@v1.1.0/xray/aws.go",
                                                "line": 149,
                                                "label": "glob..func8"
                                            },
                                            {
                                                "path": "github.com/aws/aws-sdk-go@v1.33.9/aws/request/handlers.go",
                                                "line": 267,
                                                "label": "(*HandlerList).Run"
                                            },
                                            {
                                                "path": "github.com/aws/aws-sdk-go@v1.33.9/aws/request/request.go",
                                                "line": 535,
                                                "label": "(*Request).Send"
                                            },
                                            {
                                                "path": "github.com/aws/aws-sdk-go@v1.33.9/service/dynamodb/api.go",
                                                "line": 3414,
                                                "label": "(*DynamoDB).PutItemWithContext"
                                            },
                                            {
                                                "path": "sampleapp/sample.go",
                                                "line": 62,
                                                "label": "ddbExpectedFailure.func1"
                                            },
                                            {
                                                "path": "github.com/aws/aws-xray-sdk-go@v1.1.0/xray/capture.go",
                                                "line": 45,
                                                "label": "Capture"
                                            },
                                            {
                                                "path": "sampleapp/sample.go",
                                                "line": 41,
                                                "label": "ddbExpectedFailure"
                                            },
                                            {
                                                "path": "sampleapp/sample.go",
                                                "line": 36,
                                                "label": "main"
                                            },
                                            {
                                                "path": "runtime/proc.go",
                                                "line": 203,
                                                "label": "main"
                                            },
                                            {
                                                "path": "runtime/asm_amd64.s",
                                                "line": 1373,
                                                "label": "goexit"
                                            }
                                        ],
                                        "remote": true
                                    }
                                ]
                            },
                            "Dummy": false
                        }
                    ],
                    "Dummy": false
                }
            ],
            "Dummy": false
        }
    ],
    "Dummy": false
}

----------------------------------------

TITLE: Example Portable File Path Go Code
DESCRIPTION: Shows a comparison between non-portable hard-coded file paths and portable solutions using environment variables or configuration files.

LANGUAGE: go
CODE:
filePath := "C:\Users\Bob\Documents\sampleData.csv"

// Better portable alternatives:
filePath := os.Getenv("DATA_FILE_PATH")
// or
filePath := Configuration.Get("data_file_path")

----------------------------------------

TITLE: Host Observer Configuration Parameters
DESCRIPTION: Configuration options for the host_observer extension. The refresh_interval parameter determines the frequency of endpoint checks with a default value of 10 seconds.



----------------------------------------

TITLE: Building OpenTelemetry Collector - Shell Command
DESCRIPTION: Command to build the OpenTelemetry Collector from the contrib repository root.

LANGUAGE: shell
CODE:
make otelcontribcol

----------------------------------------

TITLE: Telemetry Metrics Table Format in Markdown
DESCRIPTION: Table structure showing metric attributes including unit, metric type, value type, and monotonic property

LANGUAGE: markdown
CODE:
| Unit | Metric Type | Value Type | Monotonic |
| ---- | ----------- | ---------- | --------- |
| {spans} | Sum | Int | true |

----------------------------------------

TITLE: Deploying OpenTelemetry Collector with Docker Compose
DESCRIPTION: Command to build and start the Docker Compose deployment that sets up the Prometheus federation endpoint with OpenTelemetry Collector.

LANGUAGE: bash
CODE:
$> docker-compose up --build

----------------------------------------

TITLE: Go Package Documentation Template
DESCRIPTION: Template for creating a doc.go file with generation pragma for a new component.

LANGUAGE: go
CODE:
// Copyright The OpenTelemetry Authors
// SPDX-License-Identifier: Apache-2.0

//go:generate mdatagen metadata.yaml

// Package fooreceiver bars.
package fooreceiver // import "github.com/open-telemetry/opentelemetry-collector-contrib/receiver/fooreceiver"

----------------------------------------

TITLE: Implementing Trace Tests in Go
DESCRIPTION: Example implementation of a trace test case that demonstrates how to set up tests for new exporters and receivers. Shows configuration of test parameters including data senders, receivers, and resource specifications.

LANGUAGE: go
CODE:
func TestTrace10kSPS(t *testing.T) {
	tests := []struct {
		name         string
		sender       testbed.DataSender
		receiver     testbed.DataReceiver
		resourceSpec testbed.ResourceSpec
	}{
		{
			"NewExporterOrReceiver",
			testbed.NewXXXDataSender(testbed.DefaultHost, testutil.GetAvailablePort(t)),
			testbed.NewXXXDataReceiver(testutil.GetAvailablePort(t)),
			testbed.ResourceSpec{
				ExpectedMaxCPU: XX,
				ExpectedMaxRAM: XX,
			},
		},
		...
	}
	processors := []ProcessorNameAndConfigBody{
		{
			Name: "batch",
			Body: `
	  batch:
    `,
		},
	}
	for _, test := range tests {
		t.Run(test.name, func(t *testing.T) {
			Scenario10kItemsPerSecond(
				t,
				test.sender,
				test.receiver,
				test.resourceSpec,
				performanceResultsSummary,
				processors,
			)
		})
	}
}

----------------------------------------

TITLE: Configuring Cumulative to Delta Processor with Default Settings in YAML
DESCRIPTION: This YAML configuration example shows the default setup for the Cumulative to Delta Processor, which converts all cumulative sum or histogram metrics to delta metrics when include/exclude are not specified.

LANGUAGE: yaml
CODE:
processors:
    # processor name: cumulativetodelta
    cumulativetodelta:
        # If include/exclude are not specified
        # convert all cumulative sum or histogram metrics to delta

----------------------------------------

TITLE: GeoIP Processor Configuration Example
DESCRIPTION: Example YAML configuration for the GeoIP processor showing how to specify the MaxMind provider, context settings, and custom IP address attributes to process.

LANGUAGE: yaml
CODE:
processors:
    # processor name: geoip
    geoip:
      providers:
        maxmind:
          database_path: /tmp/mygeodb
      context: record
      attributes: [client.address, source.address, custom.address]

----------------------------------------

TITLE: Querying Loki Using logcli in Bash
DESCRIPTION: Example command to query Loki using the logcli tool. This query filters logs with the exporter label set to 'OTLP'.

LANGUAGE: bash
CODE:
logcli-linux-amd64 query '{exporter="OTLP"}'

----------------------------------------

TITLE: Querying SQL Server Instance Properties and Metrics
DESCRIPTION: This SQL script gathers comprehensive information about a SQL Server instance, including hardware details, version information, configuration settings, and database states. It uses system views and registry reads to compile the data.

LANGUAGE: SQL
CODE:
SET DEADLOCK_PRIORITY -10;
IF SERVERPROPERTY('EngineEdition') NOT IN (2,3,4) BEGIN /*NOT IN Standard, Enterprise, Express*/
	DECLARE @ErrorMessage AS nvarchar(500) = 'Connection string Server:'+ @@ServerName + ',Database:' + DB_NAME() +' is not a SQL Server Standard, Enterprise or Express. This query is only supported on these editions.';
	RAISERROR (@ErrorMessage,11,1)
	RETURN
END

DECLARE
	 @SqlStatement AS nvarchar(max) = ''
	,@MajorMinorVersion AS int = CAST(PARSENAME(CAST(SERVERPROPERTY('ProductVersion') AS nvarchar),4) AS int)*100 + CAST(PARSENAME(CAST(SERVERPROPERTY('ProductVersion') AS nvarchar),3) AS int)
	,@Columns AS nvarchar(MAX) = ''

IF CAST(SERVERPROPERTY('ProductVersion') AS varchar(50)) >= '10.50.2500.0'
	SET @Columns = N'
	,CASE [virtual_machine_type_desc]
		WHEN ''NONE'' THEN ''PHYSICAL Machine''
		ELSE [virtual_machine_type_desc]
	END AS [hardware_type]'

SET @SqlStatement = '
DECLARE @ForceEncryption INT
DECLARE @DynamicportNo NVARCHAR(50);
DECLARE @StaticportNo NVARCHAR(50);

EXEC [xp_instance_regread]
	 @rootkey = ''HKEY_LOCAL_MACHINE''
	,@key = ''SOFTWARE\Microsoft\Microsoft SQL Server\MSSQLServer\SuperSocketNetLib''
	,@value_name = ''ForceEncryption''
	,@value = @ForceEncryption OUTPUT;

EXEC [xp_instance_regread]
	 @rootkey = ''HKEY_LOCAL_MACHINE''
	,@key = ''Software\Microsoft\Microsoft SQL Server\MSSQLServer\SuperSocketNetLib\Tcp\IpAll''
	,@value_name = ''TcpDynamicPorts''
	,@value = @DynamicportNo OUTPUT

EXEC [xp_instance_regread]
	  @rootkey = ''HKEY_LOCAL_MACHINE''
     ,@key = ''Software\Microsoft\Microsoft SQL Server\MSSQLServer\SuperSocketNetLib\Tcp\IpAll''
     ,@value_name = ''TcpPort''
     ,@value = @StaticportNo OUTPUT

SELECT
	 ''sqlserver_server_properties'' AS [measurement]
	,REPLACE(@@SERVERNAME,''\','':'') AS [sql_instance]
	,HOST_NAME() AS [computer_name]
	,@@SERVICENAME AS [service_name]
	,si.[cpu_count]
	,(SELECT [total_physical_memory_kb] FROM sys.[dm_os_sys_memory]) AS [server_memory]
	,(SELECT [available_physical_memory_kb] FROM sys.[dm_os_sys_memory]) AS [available_server_memory]
	,SERVERPROPERTY(''Edition'') AS [sku]
	,CAST(SERVERPROPERTY(''EngineEdition'') AS int) AS [engine_edition]
	,DATEDIFF(MINUTE,si.[sqlserver_start_time],GETDATE()) AS [uptime]
	,SERVERPROPERTY(''ProductVersion'') AS [sql_version]
	,SERVERPROPERTY(''IsClustered'') AS [instance_type]
	,SERVERPROPERTY(''IsHadrEnabled'') AS [is_hadr_enabled]
	,LEFT(@@VERSION,CHARINDEX('' - '',@@VERSION)) AS [sql_version_desc]
	,@ForceEncryption AS [ForceEncryption]
	,COALESCE(@DynamicportNo,@StaticportNo) AS [Port]
	,IIF(@DynamicportNo IS NULL, ''Static'', ''Dynamic'') AS [PortType]
	,dbs.[db_online]
	,dbs.[db_restoring]
	,dbs.[db_recovering]
	,dbs.[db_recoveryPending]
	,dbs.[db_suspect]
	,dbs.[db_offline]'
	+ @Columns + N'
	FROM sys.[dm_os_sys_info] AS si
	CROSS APPLY (
		SELECT
			 SUM(CASE WHEN [state] = 0 THEN 1 ELSE 0 END) AS [db_online]
			,SUM(CASE WHEN [state] = 1 THEN 1 ELSE 0 END) AS [db_restoring]
			,SUM(CASE WHEN [state] = 2 THEN 1 ELSE 0 END) AS [db_recovering]
			,SUM(CASE WHEN [state] = 3 THEN 1 ELSE 0 END) AS [db_recoveryPending]
			,SUM(CASE WHEN [state] = 4 THEN 1 ELSE 0 END) AS [db_suspect]
			,SUM(CASE WHEN [state] IN (6,10) THEN 1 ELSE 0 END) AS [db_offline]
		FROM sys.databases
	) AS dbs
'

EXEC sp_executesql @SqlStatement

----------------------------------------

TITLE: Configuring Coralogix Processor with Sampling in YAML
DESCRIPTION: Configuration for the Coralogix processor with sampling enabled. This setup includes cache configuration for storing blueprint hashes and adds sampling priority attributes to spans with new blueprints.

LANGUAGE: yaml
CODE:
processors:
  coralogix:
    db_statement_blueprints:
      sampling:
        enabled: true
        max_cache_size_mib: 1024 #1GiB

----------------------------------------

TITLE: Schema URL Format Example
DESCRIPTION: Demonstrates the structure of a schema URL, showing how it's composed of a Schema Family and Schema Version components.

LANGUAGE: text
CODE:
|                       Schema URL                           |
| https://example.com/telemetry/schemas/ |  |      1.0.1     |
|             Schema Family              |  | Schema Version |

----------------------------------------

TITLE: Basic Google Pubsub Receiver Configuration
DESCRIPTION: Basic YAML configuration for setting up the Google Pubsub receiver with project and subscription details.

LANGUAGE: yaml
CODE:
receivers:
  googlecloudpubsub:
    project: otel-project
    subscription: projects/otel-project/subscriptions/otlp-logs
    encoding: raw_json

----------------------------------------

TITLE: Advanced Prometheus Receiver Configuration
DESCRIPTION: YAML configuration showing advanced options including trim_metric_suffixes, use_start_time_metric, and custom start time metric regex settings.

LANGUAGE: yaml
CODE:
receivers:
    prometheus:
      trim_metric_suffixes: true
      use_start_time_metric: true
      start_time_metric_regex: foo_bar_.*
      config:
        scrape_configs:
          - job_name: 'otel-collector'
            scrape_interval: 5s
            static_configs:
              - targets: ['0.0.0.0:8888']

----------------------------------------

TITLE: Testing Metrics Scraper in Go
DESCRIPTION: This snippet demonstrates how to use pmetrictest.CompareMetrics to test a metrics scraper. It sets up a scraper, scrapes metrics, and compares them with expected results from a JSON file.

LANGUAGE: go
CODE:
func TestMetricsScraper(t *testing.T) {
	scraper := newScraper(componenttest.NewNopReceiverCreateSettings(), createDefaultConfig().(*Config))
	require.NoError(t, scraper.start(context.Background(), componenttest.NewNopHost()))
	actualMetrics, err := require.NoError(t, scraper.scrape(context.Background()))
	require.NoError(t, err)

	expectedFile, err := readMetrics(filepath.Join("testdata", "expected.json"))
	require.NoError(err)

	require.NoError(t, pmetrictest.CompareMetrics(expectedMetrics, actualMetrics, pmetrictest.IgnoreStartTimestamp(), 
		pmetrictest.IgnoreTimestamp()))
}

----------------------------------------

TITLE: Configuring Span Name Modification in YAML
DESCRIPTION: This snippet shows how to configure the span processor to modify span names based on attributes. It demonstrates setting the 'from_attributes' and 'separator' fields.

LANGUAGE: yaml
CODE:
span:
  name:
    from_attributes: ["db.svc", "operation"]
    separator: "::"

----------------------------------------

TITLE: Configuring CouchDB Metric Collection in YAML
DESCRIPTION: Configuration template for disabling specific CouchDB metrics collection. Used to customize which metrics are collected by setting the 'enabled' flag to false for individual metric names.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Pubsub Subscription Filter Configuration
DESCRIPTION: Example of a Pubsub subscription filter expression to filter only trace messages based on message attributes.

LANGUAGE: text
CODE:
attributes.ce-type = "org.opentelemetry.otlp.traces.v1"
AND
attributes.content-type = "application/protobuf"

----------------------------------------

TITLE: OTTL Editor Example - append
DESCRIPTION: Example showing how to append string values to a target field

LANGUAGE: ottl
CODE:
append(log.attributes["tags"], "prod")

----------------------------------------

TITLE: Configuring Log Transform Processor in YAML
DESCRIPTION: This snippet demonstrates how to configure a transform processor to parse JSON payloads from log bodies into attributes, which can then be used by the Sum Connector.

LANGUAGE: yaml
CODE:
processors:
  transform/logs:
    log_statements:
      - context: log
        statements:
          - merge_maps(attributes, ParseJSON(body), "upsert")

----------------------------------------

TITLE: Enum Values Table for Metric Context in Markdown
DESCRIPTION: A markdown table listing the supported enum values for aggregation temporality and metric data types, along with their corresponding numeric values.

LANGUAGE: markdown
CODE:
| Enum Symbol                            | Value |
|----------------------------------------|-------|
| AGGREGATION_TEMPORALITY_UNSPECIFIED    | 0     |
| AGGREGATION_TEMPORALITY_DELTA          | 1     |
| AGGREGATION_TEMPORALITY_CUMULATIVE     | 2     |
| METRIC_DATA_TYPE_NONE                  | 0     |
| METRIC_DATA_TYPE_GAUGE                 | 1     |
| METRIC_DATA_TYPE_SUM                   | 2     |
| METRIC_DATA_TYPE_HISTOGRAM             | 3     |
| METRIC_DATA_TYPE_EXPONENTIAL_HISTOGRAM | 4     |
| METRIC_DATA_TYPE_SUMMARY               | 5     |

----------------------------------------

TITLE: Configuring Google Cloud LogEntry Encoding Extension in YAML
DESCRIPTION: Example configuration for setting up the Google Cloud LogEntry encoding extension with a Google Cloud Pub/Sub receiver. This configuration demonstrates how to parse LogEntry messages from a Pub/Sub topic.

LANGUAGE: yaml
CODE:
extensions:
  googlecloudlogentry_encoding:
    handle_json_payload_as: "json"
    handle_proto_payload_as: "json"

receivers:
  googlecloudpubsub:
    project: otel-project
    subscription: projects/otel-project/subscriptions/otlp-logs
    encoding: googlecloudlogentry_encoding

----------------------------------------

TITLE: Configuring Attributes for Metrics in YAML
DESCRIPTION: Example of how to configure attributes for metrics, including default values.

LANGUAGE: yaml
CODE:
attributes:
  - key: datapoint.foo
  - key: datapoint.bar
    default_value: bar

----------------------------------------

TITLE: Basic Round-Robin Connector Configuration in YAML
DESCRIPTION: Demonstrates minimal configuration setup for the round-robin connector with OTLP receiver and multiple Prometheus remote write exporters.

LANGUAGE: yaml
CODE:
receivers:
  otlp:
exporters:
  prometheusremotewrite/1:
  prometheusremotewrite/2:
connectors:
  roundrobin:

----------------------------------------

TITLE: Configuring Text Encoding Extension in YAML
DESCRIPTION: Default configuration for the text_encoding extension showing encoding and separator settings. The extension uses UTF-8 encoding by default with newline characters as separators. The unmarshaling separator supports regular expressions.

LANGUAGE: yaml
CODE:
extensions:
  text_encoding:
    encoding: utf8
    marshaling_separator: "\n"
    unmarshaling_separator: "\r?\n"

----------------------------------------

TITLE: Configuring Supervisor for OpenTelemetry Collector with OpAMP
DESCRIPTION: This YAML configuration file defines the settings for the Supervisor process that manages the OpenTelemetry Collector using OpAMP. It includes server settings, capabilities, storage configuration, and agent-specific settings.

LANGUAGE: yaml
CODE:
server:
  endpoint: wss://example.com/opamp

capabilities:
  accepts_remote_config:
  reports_effective_config:
  accepts_packages:
  reports_own_metrics:
  reports_own_logs:
  reports_own_traces:
  accepts_other_connection_settings:
  accepts_restart_command:
  reports_health:

storage:
  directory: /path/to/dir

agent:
  executable: /opt/otelcol/bin/otelcol
  orphan_detection_interval: 5s
  bootstrap_timeout: 3s
  args:
  env:
  run_as: myuser
  config_files: 
    - /etc/otelcol/config.yaml
  access_dirs:
    read:
      allow: [/var/log]
      deny: [/var/log/secret_logs]
    write:
      allow: [/var/otelcol]
  description:
    identifying_attributes:
      client.id: "01HWWSK84BMT7J45663MBJMTPJ"
    non_identifying_attributes:
      custom.attribute: "custom-value"
  health_check_port:
  opamp_server_port:

----------------------------------------

TITLE: Complete Pipeline Configuration Examples
DESCRIPTION: Multiple configuration examples showing different pipeline setups for counting various telemetry data types.

LANGUAGE: yaml
CODE:
receivers:
  foo/traces:
  foo/metrics:
  foo/logs:
exporters:
  bar/all_types:
  bar/counts_only:
connectors:
  count:
    metrics:
      my.prod.metric.count:
        conditions:
         - `attributes["env"] == "prod"
      my.test.metric.count:
        conditions:
         - `attributes["env"] == "test"
    datapoints:
      my.prod.datapoint.count:
        conditions:
         - `attributes["env"] == "prod"
      my.test.datapoint.count:
        conditions:
         - `attributes["env"] == "test"
service:
  pipelines:
    traces:
      receivers: [foo/traces]
      exporters: [bar/all_types, count]
    metrics:
      receivers: [foo/metrics]
      exporters: [bar/all_types, count]
    metrics/counts:
      receivers: [count]
      exporters: [bar/counts_only]

----------------------------------------

TITLE: Configuring Histogram Metrics in YAML
DESCRIPTION: Example configuration for histogram metrics, showing bucket, count, and value settings.

LANGUAGE: yaml
CODE:
histogram:
  buckets: []float64
  count: <ottl_value_expression>
  value: <ottl_value_expression>

----------------------------------------

TITLE: Configuring Conditions for Metrics in YAML
DESCRIPTION: Example of using OTTL conditions to filter metrics based on resource attributes.

LANGUAGE: yaml
CODE:
signaltometrics:
  datapoints:
    - name: datapoint.bar.sum
      description: Count total number of datapoints as per datapoint.bar attribute
      conditions:
        - resource.attributes["foo"] != nil
        - resource.attributes["bar"] != nil
      sum:
        value: "1"

----------------------------------------

TITLE: Configuring Basic File Input in YAML
DESCRIPTION: Simple configuration example showing how to set up file input to read from a single log file

LANGUAGE: yaml
CODE:
- type: file_input
  include:
    - ./test.log

----------------------------------------

TITLE: Configuring Simple File Output in YAML for OpenTelemetry Collector
DESCRIPTION: A basic configuration for the file_output operator that writes JSON-formatted log entries to a specified file path.

LANGUAGE: yaml
CODE:
- type: file_output
  path: /tmp/output.json

----------------------------------------

TITLE: Basic Journald Input Configuration with Units
DESCRIPTION: Configuration example showing how to set up journald_input with specific units and priority filtering.

LANGUAGE: yaml
CODE:
- type: journald_input
  units:
    - ssh
    - kubelet
  priority: info

----------------------------------------

TITLE: Sample JSON Output from stdin Operator
DESCRIPTION: An example of the JSON output produced by the stdin operator. It includes a timestamp, severity level, and the input body.

LANGUAGE: json
CODE:
{
  "timestamp": "2020-11-10T11:09:56.505467-05:00",
  "severity": 0,
  "body": "test"
}

----------------------------------------

TITLE: Parsing Docker Container Log with Metadata Extraction
DESCRIPTION: This example shows the input and output JSON for parsing a Docker container log, including metadata extraction from the file path.

LANGUAGE: json
CODE:
{
  "timestamp": "",
  "body": "{\"log\":\"INFO: log line here\",\"stream\":\"stdout\",\"time\":\"2024-03-30T08:31:20.545192187Z\"}",
  "log.file.path": "/var/log/pods/some_kube-controller-kind-control-plane_49cc7c1fd3702c40b2686ea7486091d6/kube-controller/1.log"
}

LANGUAGE: json
CODE:
{
  "timestamp": "2024-03-30 08:31:20.545192187 +0000 UTC",
  "body": "INFO: log line here",
  "attributes": {
    "time": "2024-03-30T08:31:20.545192187Z", 
    "log.iostream":                "stdout",
    "log.file.path": "/var/log/pods/some_kube-controller-kind-control-plane_49cc7c1fd3702c40b2686ea7486091d6/kube-controller/1.log"
  },
  "resource": {
    "attributes": {
      "k8s.pod.name":                "kube-controller-kind-control-plane",
      "k8s.pod.uid":                 "49cc7c1fd3702c40b2686ea7486091d6",
      "k8s.container.name":          "kube-controller",
      "k8s.container.restart_count": "1",
      "k8s.namespace.name":          "some"
    }
  }
}

----------------------------------------

TITLE: Syslog Parsing Input and Output Example in JSON
DESCRIPTION: Demonstrates the input and output JSON for the syslog_parser operator when parsing an RFC3164 syslog message.

LANGUAGE: json
CODE:
{
  "timestamp": "",
  "body": "<34>Jan 12 06:30:00 1.2.3.4 apache_server: test message"
}

LANGUAGE: json
CODE:
{
  "timestamp": "2020-01-12T06:30:00Z",
  "body": {
    "appname": "apache_server",
    "facility": 4,
    "hostname": "1.2.3.4",
    "message": "test message",
    "msg_id": null,
    "priority": 34,
    "proc_id": null,
    "severity": 2
  }
}

----------------------------------------

TITLE: Sample Windows Event Log Output Format in JSON
DESCRIPTION: Example of the JSON output structure produced by the windows_eventlog_input operator, showing timestamp, severity, and detailed event information in the body.

LANGUAGE: json
CODE:
{
  "timestamp": "2020-04-30T12:10:17.656726-04:00",
  "severity": 30,
  "body": {
		"event_id": {
			"qualifiers": 0,
			"id": 1000
		},
		"provider": {
			"name": "provider name",
			"guid": "provider guid",
			"event_source": "event source"
		},
		"system_time": "2020-04-30T12:10:17.656726789Z",
		"computer": "example computer",
		"channel": "application",
		"record_id": 1,
		"level": "Information",
		"message": "example message",
		"task": "example task",
		"opcode": "example opcode",
		"keywords": ["example keyword"]
	}
}

----------------------------------------

TITLE: Field Usage with Add and Remove Operators - YAML Configuration
DESCRIPTION: Example showing how to configure add and remove operators using field references to modify log entries

LANGUAGE: yaml
CODE:
- type: add
  field: body.key3
  value: val3
- type: remove
  field: body.key2.nested_key1
- type: add
  field: attributes.my_attribute
  value: my_attribute_value

----------------------------------------

TITLE: Parsing Timestamps from Plain Text Logs
DESCRIPTION: This configuration example shows how to parse timestamps from plain text logs using a regex_parser operator. It extracts the timestamp from the log body and removes the temporary attribute.

LANGUAGE: yaml
CODE:
exporters:
  debug:
    verbosity: detailed
receivers:
  filelog:
    include:
    - my-app.log
    start_at: beginning
    operators:
    - type: regex_parser
      regex: (?P<timestamp_field>^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3} (\+|\-)\d{2}\d{2})
      timestamp:
        layout: "%Y-%m-%d %H:%M:%S.%f %z"
        parse_from: attributes.timestamp_field
    - type: remove
      field: attributes.timestamp_field
service:
  pipelines:
    logs:
      receivers:
      - filelog
      exporters:
      - debug

----------------------------------------

TITLE: Simple Severity Parser Configuration
DESCRIPTION: Basic severity parser configuration that uses default preset mappings.

LANGUAGE: yaml
CODE:
- type: severity_parser
  parse_from: body.severity_field
  mapping:
    error: nooo!

----------------------------------------

TITLE: Input/Output JSON Examples for Space Collapse
DESCRIPTION: Example JSON showing the transformation of text with multiple spaces.

LANGUAGE: json
CODE:
{
  "resource": { },
  "attributes": { },
  "body": "Hello  World"
}

----------------------------------------

TITLE: Input/Output JSON Examples for Group Replacement
DESCRIPTION: Example JSON showing the transformation of text using regex group replacement.

LANGUAGE: json
CODE:
{
  "resource": { },
  "attributes": { },
  "body": "{a}{bb}{ccc}"
}

----------------------------------------

TITLE: No-op Operator Usage in YAML
DESCRIPTION: Shows how to use the no-op operator to control where logs are emitted from the receiver in non-linear sequences.

LANGUAGE: yaml
CODE:
receivers:
  filelog:
    include: my-log.json
    operators:
      - type: router
        routes:
          - expr: 'body matches "^{.*}$"'
            output: json_parser
          - expr: 'body startsWith "ERROR"'
            output: error_parser
      - type: json_parser
        output: noop
      - type: regex_parser
        id: error_parser
        regex: ...
      - type: noop

----------------------------------------

TITLE: Running Integration Tests
DESCRIPTION: Executes integration tests with CGO enabled, race detection, and sudo privileges. Sets appropriate timeout and parallel execution parameters.

LANGUAGE: bash
CODE:
CGO_ENABLED=1 go test -v -exec sudo -race -timeout 360s -parallel 4 -tags=integration,""

----------------------------------------

TITLE: Setting Up Docker Environment for Cgroup Testing
DESCRIPTION: Starts a privileged Docker container with cgroupns host access and mounts the current workspace for testing.

LANGUAGE: bash
CODE:
cd extension/cgroupruntimeextension
docker run -ti --privileged --cgroupns=host -v $(pwd):/workspace -w /workspace debian:bookworm-slim

----------------------------------------

TITLE: Deleting Lease Object in Kubernetes
DESCRIPTION: This shell command demonstrates how to delete the lease object in Kubernetes. It requires specifying the namespace and lease name.

LANGUAGE: shell
CODE:
kubectl delete leases.coordination.k8s.io -n <namespace> <lease_name>

----------------------------------------

TITLE: Configuring Zipkin Encoding Extension for Kafka Receiver
DESCRIPTION: Example YAML configuration showing how to set up a Zipkin encoding extension and use it with a Kafka receiver. The configuration demonstrates defining the encoding protocol, version, and referencing it in the receiver settings.

LANGUAGE: yaml
CODE:
extensions:
  zipkin_encoding:
    protocol: zipkin_proto
    version: v2

receivers:
  kafka:
    encoding: zipkin_encoding
    # ... other configuration values

----------------------------------------

TITLE: Building OpenTelemetry Collector for Kubernetes
DESCRIPTION: Command to build the OpenTelemetry Collector from source for deployment on a kind cluster.

LANGUAGE: bash
CODE:
make kind-build

----------------------------------------

TITLE: Configuring Concurrent Batch Processor for OpenTelemetry Protocol with Apache Arrow Exporter
DESCRIPTION: YAML configuration example for using the Concurrent Batch Processor with the OpenTelemetry Protocol with Apache Arrow exporter, providing simultaneous back-pressure, concurrency, and batching functionality.

LANGUAGE: yaml
CODE:
exporters:
  otelarrow:
    batcher:
      enabled: false
    sending_queue:
      enabled: false
processors:
  concurrentbatch:
    send_batch_max_size: 1500
    send_batch_size: 1000
    timeout: 1s

----------------------------------------

TITLE: Setting Stream Lifetime for OpenTelemetry Protocol with Apache Arrow Exporter
DESCRIPTION: YAML configuration showing how to set the maximum stream lifetime and export timeout for the OpenTelemetry Protocol with Apache Arrow exporter.

LANGUAGE: yaml
CODE:
exporters:
  otelarrow:
    timeout: 30s
    arrow:
      max_stream_lifetime: 9m30s
    endpoint: ...
    tls: ...

----------------------------------------

TITLE: Component Metadata Configuration
DESCRIPTION: Template for creating a component metadata.yaml file with required fields including type, status, stability and code owners.

LANGUAGE: yaml
CODE:
type: <name of your component, such as apache, http, haproxy, postgresql>

status:
  class: <class of component, one of cmd, connector, exporter, extension, processor or receiver>
  stability:
    development: [<pick the signals supported: logs, metrics, traces. For extension, use "extension">]
  codeowners:
    active: [<github account of the sponsor, such as alice>, <your GitHub account if you are already an OpenTelemetry member>]

----------------------------------------

TITLE: Metric Inclusion Configuration
DESCRIPTION: Example showing how to configure metric inclusion filters to override default exclusions.

LANGUAGE: yaml
CODE:
exporters:
  signalfx:
    include_metrics:
      - metric_names: [cpu.interrupt, cpu.user, cpu.system]
      - metric_name: system.cpu.time
        dimensions:
          state: [interrupt, user, system]

----------------------------------------

TITLE: Webhook Event Multi-line Example - Split Logs
DESCRIPTION: Example of webhook body format when split_logs_at_newline is set to true, resulting in multiple log records.

LANGUAGE: yaml
CODE:
{ "name": "francis", "city": "newyork" }
{ "name": "john", "city": "paris" }
a third line

----------------------------------------

TITLE: Webhook Event Multi-line Example - Split Logs
DESCRIPTION: Example of webhook body format when split_logs_at_newline is set to true, resulting in multiple log records.

LANGUAGE: yaml
CODE:
{ "name": "francis", "city": "newyork" }
{ "name": "john", "city": "paris" }
a third line

----------------------------------------

TITLE: Configuring TLS Check Metrics in YAML
DESCRIPTION: Example configuration for disabling specific TLS check metrics in the OpenTelemetry Collector. Shows the YAML structure for metric enablement configuration.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Enabling Optional Snowflake Metrics in YAML Configuration
DESCRIPTION: Example YAML configuration to enable an optional Snowflake metric. This can be applied to any of the optional metrics listed in the document.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: true

----------------------------------------

TITLE: Enabling Optional Redis Metrics in YAML Configuration
DESCRIPTION: This snippet demonstrates how to enable an optional metric in the YAML configuration file. Replace <metric_name> with the specific optional metric you want to enable.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: true

----------------------------------------

TITLE: Configuring OracleDB Metric Collection in YAML
DESCRIPTION: YAML configuration snippet showing how to disable specific metrics in the OracleDB collector. Each metric can be individually enabled or disabled using the enabled flag.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Enabling Optional MySQL Metrics in YAML Configuration
DESCRIPTION: Example YAML configuration to enable a specific optional metric in the MySQL receiver.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: true

----------------------------------------

TITLE: Configuring MongoDB Atlas Metrics in YAML
DESCRIPTION: Example YAML configuration to enable or disable specific MongoDB Atlas metrics.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Disabling Memcached Metrics in YAML Configuration
DESCRIPTION: This YAML configuration snippet demonstrates how to disable specific metrics in the Memcached collector. Each metric can be individually disabled by setting its 'enabled' property to false.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: HTTP Status Metrics Example
DESCRIPTION: Example of metrics generated by the HTTP Check Receiver when an endpoint returns a 200 status code. Shows the status class labels and their corresponding values.

LANGUAGE: text
CODE:
httpcheck.status{http.status_class:1xx, http.status_code:200,...} = 0
httpcheck.status{http.status_class:2xx, http.status_code:200,...} = 1
httpcheck.status{http.status_class:3xx, http.status_code:200,...} = 0
httpcheck.status{http.status_class:4xx, http.status_code:200,...} = 0
httpcheck.status{http.status_class:5xx, http.status_code:200,...} = 0

----------------------------------------

TITLE: Enabling Optional HAProxy Metrics in YAML
DESCRIPTION: Configuration example showing how to enable optional metrics that are not emitted by default in the HAProxy collector.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: true

----------------------------------------

TITLE: Disabling Default Metrics in YAML Configuration
DESCRIPTION: This snippet shows how to disable a default metric in the YAML configuration. Replace <metric_name> with the specific metric you want to disable.

LANGUAGE: yaml
CODE:
metrics:
  <metric_name>:
    enabled: false

----------------------------------------

TITLE: Environment Variable Detector Configuration
DESCRIPTION: YAML configuration for the environment variable detector which reads resource information from OTEL_RESOURCE_ATTRIBUTES

LANGUAGE: yaml
CODE:
processors:
  resourcedetection/env:
    detectors: [env]
    timeout: 2s
    override: false

----------------------------------------

TITLE: OpenTelemetry Span Event Enum Definitions
DESCRIPTION: Enum definitions for Span Kinds and Status Codes used in the OpenTelemetry traces proto. These enums represent different types of spans and their status states.

LANGUAGE: proto
CODE:
SPAN_KIND_UNSPECIFIED = 0
SPAN_KIND_INTERNAL = 1
SPAN_KIND_SERVER = 2
SPAN_KIND_CLIENT = 3
SPAN_KIND_PRODUCER = 4
SPAN_KIND_CONSUMER = 5
STATUS_CODE_UNSET = 0
STATUS_CODE_OK = 1
STATUS_CODE_ERROR = 2

----------------------------------------

TITLE: Running X-Ray Sample Server Application
DESCRIPTION: Command to start the sample server with X-Ray instrumented handler.

LANGUAGE: shell
CODE:
go run sampleserver/sample.go

----------------------------------------

TITLE: Running X-Ray Sample Server Application
DESCRIPTION: Command to start the sample server with X-Ray instrumented handler.

LANGUAGE: shell
CODE:
go run sampleserver/sample.go

----------------------------------------

TITLE: Collecting SQL Server Performance Metrics
DESCRIPTION: This SQL script collects a wide range of performance metrics from SQL Server. It checks for server compatibility, declares variables and temporary tables, and then queries system views to gather performance counter data. The script covers various aspects of SQL Server performance including CPU usage, memory utilization, I/O operations, and specific SQL Server counters.

LANGUAGE: SQL
CODE:
SET DEADLOCK_PRIORITY -10;
IF SERVERPROPERTY('EngineEdition') NOT IN (2,3,4) BEGIN /*NOT IN Standard,Enterprise,Express*/
	DECLARE @ErrorMessage AS nvarchar(500) = 'Connection string Server:'+ @@ServerName + ',Database:' + DB_NAME() +' is not a SQL Server Standard, Enterprise or Express. This query is only supported on these editions.';
	RAISERROR (@ErrorMessage,11,1)
	RETURN
END

DECLARE
	 @SqlStatement AS nvarchar(max)
	,@MajorMinorVersion AS int = CAST(PARSENAME(CAST(SERVERPROPERTY('ProductVersion') AS nvarchar),4) AS int)*100 + CAST(PARSENAME(CAST(SERVERPROPERTY('ProductVersion') AS nvarchar),3) AS int)

DECLARE @PCounters TABLE
(
	 [object_name] nvarchar(128)
	,[counter_name] nvarchar(128)
	,[instance_name] nvarchar(128)
	,[cntr_value] bigint
	,[cntr_type] int
	PRIMARY KEY([object_name], [counter_name], [instance_name])
);

WITH PerfCounters AS (
SELECT DISTINCT
	 RTRIM(spi.[object_name]) [object_name]
	,RTRIM(spi.[counter_name]) [counter_name]
	,RTRIM(spi.[instance_name]) AS [instance_name]
	,CAST(spi.[cntr_value] AS bigint) AS [cntr_value]
	,spi.[cntr_type]
	FROM sys.dm_os_performance_counters AS spi
	WHERE
		counter_name IN (
			 'SQL Compilations/sec'
			,'SQL Re-Compilations/sec'
			,'User Connections'
			,'Batch Requests/sec'
			,'Logouts/sec'
			,'Logins/sec'
			,'Processes blocked'
			,'Latch Waits/sec'
			,'Average Latch Wait Time (ms)'
			,'Full Scans/sec'
			,'Index Searches/sec'
			,'Page Splits/sec'
			,'Page lookups/sec'
			,'Page reads/sec'
			,'Page writes/sec'
			,'Readahead pages/sec'
			,'Lazy writes/sec'
			,'Checkpoint pages/sec'
			,'Table Lock Escalations/sec'
			,'Page life expectancy'
			,'Log File(s) Size (KB)'
			,'Log File(s) Used Size (KB)'
			,'Data File(s) Size (KB)'
			,'Transactions/sec'
			,'Write Transactions/sec'
			,'Active Transactions'
			,'Log Growths'
			,'Active Temp Tables'
			,'Logical Connections'
			,'Temp Tables Creation Rate'
			,'Temp Tables For Destruction'
			,'Free Space in tempdb (KB)'
			,'Version Store Size (KB)'
			,'Memory Grants Pending'
			,'Memory Grants Outstanding'
			,'Free list stalls/sec'
			,'Buffer cache hit ratio'
			,'Buffer cache hit ratio base'
			,'Database Pages'
			,'Backup/Restore Throughput/sec'
			,'Total Server Memory (KB)'
			,'Target Server Memory (KB)'
			,'Log Flushes/sec'
			,'Log Flush Wait Time'
			,'Memory broker clerk size'
			,'Log Bytes Flushed/sec'
			,'Bytes Sent to Replica/sec'
			,'Log Send Queue'
			,'Bytes Sent to Transport/sec'
			,'Sends to Replica/sec'
			,'Bytes Sent to Transport/sec'
			,'Sends to Transport/sec'
			,'Bytes Received from Replica/sec'
			,'Receives from Replica/sec'
			,'Flow Control Time (ms/sec)'
			,'Flow Control/sec'
			,'Resent Messages/sec'
			,'Redone Bytes/sec'
			,'XTP Memory Used (KB)'
			,'Transaction Delay'
			,'Log Bytes Received/sec'
			,'Log Apply Pending Queue'
			,'Redone Bytes/sec'
			,'Recovery Queue'
			,'Log Apply Ready Queue'
			,'CPU usage %'
			,'CPU usage % base'
			,'Queued requests'
			,'Requests completed/sec'
			,'Blocked tasks'
			,'Active memory grant amount (KB)'
			,'Disk Read Bytes/sec'
			,'Disk Read IO Throttled/sec'
			,'Disk Read IO/sec'
			,'Disk Write Bytes/sec'
			,'Disk Write IO Throttled/sec'
			,'Disk Write IO/sec'
			,'Used memory (KB)'
			,'Forwarded Records/sec'
			,'Background Writer pages/sec'
			,'Percent Log Used'
			,'Log Send Queue KB'
			,'Redo Queue KB'
			,'Mirrored Write Transactions/sec'
			,'Group Commit Time'
			,'Group Commits/Sec'
			,'Workfiles Created/sec'
			,'Worktables Created/sec'
			,'Distributed Query'
			,'DTC calls'
			,'Query Store CPU usage'
			,'Query Store physical reads'
			,'Query Store logical reads'
			,'Query Store logical writes'
			,'Execution Errors'
		) OR (
			spi.[object_name] LIKE '%User Settable%'
			OR spi.[object_name] LIKE '%SQL Errors%'
			OR spi.[object_name] LIKE '%Batch Resp Statistics%'
		) OR (
			spi.[instance_name] IN ('_Total')
			AND spi.[counter_name] IN (
				 'Lock Timeouts/sec'
				,'Lock Timeouts (timeout > 0)/sec'
				,'Number of Deadlocks/sec'
				,'Lock Waits/sec'
				,'Latch Waits/sec'
			)
		)
)

INSERT INTO @PCounters SELECT * FROM PerfCounters;

SELECT
	 'sqlserver_performance' AS [measurement]
	,REPLACE(@@SERVERNAME,'\',':') AS [sql_instance]
	,HOST_NAME() AS [computer_name]
	,pc.[object_name] AS [object]
	,pc.[counter_name] AS [counter]
	,CASE pc.[instance_name] WHEN '_Total' THEN 'Total' ELSE ISNULL(pc.[instance_name],'') END AS [instance]
	,CAST(CASE WHEN pc.[cntr_type] = 537003264 AND pc1.[cntr_value] > 0 THEN (pc.[cntr_value] * 1.0) / (pc1.[cntr_value] * 1.0) * 100 ELSE pc.[cntr_value] END AS float(10)) AS [value]
	,CAST(pc.[cntr_type] AS varchar(25)) AS [counter_type]
FROM @PCounters AS pc
LEFT OUTER JOIN @PCounters AS pc1
	ON (
		pc.[counter_name] = REPLACE(pc1.[counter_name],' base','')
		OR pc.[counter_name] = REPLACE(pc1.[counter_name],' base',' (ms)')
	)
	AND pc.[object_name] = pc1.[object_name]
	AND pc.[instance_name] = pc1.[instance_name]
	AND pc1.[counter_name] LIKE '%base'
WHERE
	pc.[counter_name] NOT LIKE '% base'
	AND @@SERVERNAME = 'instanceName'
OPTION(RECOMPILE)

----------------------------------------

TITLE: Parsing SQL Server Performance Metrics in JSON
DESCRIPTION: This JSON structure represents various SQL Server performance metrics. Each object in the array contains information about a specific performance counter, including its name, type, instance, measurement, object, SQL instance, computer name, and value.

LANGUAGE: JSON
CODE:
[
  {
    "counter": "Forwarded Records/sec",
    "counter_type": "272696576",
    "instance": "",
    "measurement": "sqlserver_performance",
    "object": "SQLServer:Access Methods",
    "sql_instance": "8cac97ac9b8f",
    "computer_name": "abcde",
    "value": "0"
  },
  // ... more entries
]

----------------------------------------

TITLE: Parsing CloudFlare HTTP Request Log JSON
DESCRIPTION: A complete CloudFlare HTTP request log entry containing detailed information about the request, including client details, edge server information, security settings, and performance metrics. The log includes timing data, cache status, client identification, and various CloudFlare-specific attributes.

LANGUAGE: json
CODE:
{
  "RayID": "7a1f7ad4df2f870a",
  "EdgeStartTimestamp": "2023-03-03T05:29:06Z",
  "CacheCacheStatus": "dynamic",
  "CacheReserveUsed": false,
  "CacheResponseBytes": 9247,
  "CacheResponseStatus": 200,
  "CacheTieredFill": false,
  "ClientASN": 20115,
  "ClientCountry": "us",
  "ClientDeviceType": "desktop",
  "ClientIP": "47.35.104.49",
  "ClientIPClass": "noRecord",
  "ClientMTLSAuthCertFingerprint": "",
  "ClientMTLSAuthStatus": "unknown",
  "ClientRegionCode": "MI",
  "ClientRequestBytes": 2667,
  "ClientRequestHost": "www.theburritobot2.com",
  "ClientRequestMethod": "GET",
  "ClientRequestPath": "/product/66VCHSJNUP",
  "ClientRequestProtocol": "HTTP/2",
  "ClientRequestReferer": "https://www.theburritobot2.com/",
  "ClientRequestScheme": "https",
  "ClientRequestSource": "eyeball",
  "ClientRequestURI": "/product/66VCHSJNUP",
  "ClientRequestUserAgent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36",
  "ClientSSLCipher": "AEAD-AES128-GCM-SHA256",
  "ClientSSLProtocol": "TLSv1.3",
  "ClientSrcPort": 49358,
  "ClientTCPRTTMs": 18,
  "ClientXRequestedWith": "",
  "ContentScanObjResults": [],
  "ContentScanObjTypes": [],
  "Cookies": {},
  "EdgeCFConnectingO2O": false,
  "EdgeColoCode": "ORD",
  "EdgeColoID": 398,
  "EdgeEndTimestamp": "2023-03-03T05:29:06Z",
  "EdgePathingOp": "wl",
  "EdgePathingSrc": "macro",
  "EdgePathingStatus": "nr",
  "EdgeRateLimitAction": "",
  "EdgeRateLimitID": 0,
  "EdgeRequestHost": "www.theburritobot2.com",
  "EdgeResponseBodyBytes": 1963,
  "EdgeResponseBytes": 2301,
  "EdgeResponseCompressionRatio": 2.54,
  "EdgeResponseContentType": "text/html",
  "EdgeResponseStatus": 200,
  "EdgeServerIP": "172.70.131.84",
  "EdgeTimeToFirstByteMs": 28,
  "FirewallMatchesActions": [],
  "FirewallMatchesRuleIDs": [],
  "FirewallMatchesSources": [],
  "OriginDNSResponseTimeMs": 0,
  "OriginIP": "35.223.103.128",
  "OriginRequestHeaderSendDurationMs": 0,
  "OriginResponseBytes": 0,
  "OriginResponseDurationMs": 22,
  "OriginResponseHTTPExpires": "",
  "OriginResponseHTTPLastModified": "",
  "OriginResponseHeaderReceiveDurationMs": 21,
  "OriginResponseStatus": 200,
  "OriginResponseTime": 22000000,
  "OriginSSLProtocol": "none",
  "OriginTCPHandshakeDurationMs": 0,
  "OriginTLSHandshakeDurationMs": 0,
  "ParentRayID": "00",
  "RequestHeaders": {},
  "ResponseHeaders": {},
  "SecurityLevel": "med",
  "SmartRouteColoID": 0,
  "UpperTierColoID": 0,
  "WAFAction": "unknown",
  "WAFAttackScore": 0,
  "WAFFlags": "0",
  "WAFMatchedVar": "",
  "WAFProfile": "unknown",
  "WAFRCEAttackScore": 0,
  "WAFRuleID": "",
  "WAFRuleMessage": "",
  "WAFSQLiAttackScore": 0,
  "WAFXSSAttackScore": 0,
  "WorkerCPUTime": 0,
  "WorkerStatus": "unknown",
  "WorkerSubrequest": false,
  "WorkerSubrequestCount": 0,
  "WorkerWallTimeUs": 0,
  "ZoneName": "otlpdev.net"
}

----------------------------------------

TITLE: Creating ClusterRole for OpenTelemetry Collector in Kubernetes
DESCRIPTION: Bash script to create a Kubernetes ClusterRole with necessary permissions for the OpenTelemetry Collector.

LANGUAGE: bash
CODE:
<<EOF | kubectl apply -f -
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: otelcontribcol
  labels:
    app: otelcontribcol
rules:
- apiGroups:
  - ""
  resources:
  - events
  - namespaces
  - namespaces/status
  - nodes
  - nodes/spec
  - pods
  - pods/status
  - replicationcontrollers
  - replicationcontrollers/status
  - resourcequotas
  - services
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - apps
  resources:
  - daemonsets
  - deployments
  - replicasets
  - statefulsets
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - extensions
  resources:
  - daemonsets
  - deployments
  - replicasets
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - batch
  resources:
  - jobs
  - cronjobs
  verbs:
  - get
  - list
  - watch
- apiGroups:
    - autoscaling
  resources:
    - horizontalpodautoscalers
  verbs:
    - get
    - list
    - watch
EOF

----------------------------------------

TITLE: Defining AWS X-Ray Trace Segment in JSON
DESCRIPTION: This JSON object represents a single trace segment in AWS X-Ray. It includes essential fields for identifying and timing the trace, as well as status indicators. The trace is identified by a unique trace_id and segment id, with a descriptive name and start timestamp.

LANGUAGE: json
CODE:
{
    "trace_id": "1-5f187253-6a106696d56b1f4ef9eba2ed",
    "id": "5cc4a447f5d4d696",
    "name": "LongOperation",
    "start_time": 1595437651.680097,
    "in_progress": true,
    "Dummy": false
}

----------------------------------------

TITLE: Defining AWS X-Ray Trace Segment in JSON
DESCRIPTION: This JSON object represents a single trace segment in AWS X-Ray. It includes essential fields for identifying and timing the trace, as well as status indicators. The trace is identified by a unique trace_id and segment id, with a descriptive name and start timestamp.

LANGUAGE: json
CODE:
{
    "trace_id": "1-5f187253-6a106696d56b1f4ef9eba2ed",
    "id": "5cc4a447f5d4d696",
    "name": "LongOperation",
    "start_time": 1595437651.680097,
    "in_progress": true,
    "Dummy": false
}

----------------------------------------

TITLE: Defining AWS X-Ray Trace Segment in JSON
DESCRIPTION: This JSON object defines the structure of an AWS X-Ray trace segment. It includes essential fields such as trace_id, segment id, name, start and end times, fault status, and cause. The structure is used to represent distributed tracing data in AWS X-Ray.

LANGUAGE: json
CODE:
{
    "trace_id": "1-5f187253-6a106696d56b1f4ef9eba2ed",
    "id": "5cc4a447f5d4d696",
    "name": "CauseIsExceptionID",
    "start_time": 1595437651.680097,
    "end_time": 1595437652.197392,
    "fault": true,
    "cause": 200,
    "Dummy": false
}

----------------------------------------

TITLE: Defining AWS X-Ray Trace Segment in JSON
DESCRIPTION: This JSON object defines the structure of an AWS X-Ray trace segment. It includes essential fields such as trace_id, segment id, name, start and end times, fault status, and cause. The structure is used to represent distributed tracing data in AWS X-Ray.

LANGUAGE: json
CODE:
{
    "trace_id": "1-5f187253-6a106696d56b1f4ef9eba2ed",
    "id": "5cc4a447f5d4d696",
    "name": "CauseIsExceptionID",
    "start_time": 1595437651.680097,
    "end_time": 1595437652.197392,
    "fault": true,
    "cause": 200,
    "Dummy": false
}

----------------------------------------

TITLE: Defining vCenter Server Product Information in JSON
DESCRIPTION: JSON object containing detailed product information for the emulated VMware vCenter Server, including version, build, and API details.

LANGUAGE: json
CODE:
{
      "name": "VMware vCenter Server",
      "fullName": "VMware vCenter Server 7.0.2 build-19272235",
      "vendor": "VMware, Inc.",
      "version": "7.0.2",
      "build": "19272235",
      "localeVersion": "INTL",
      "localeBuild": "000",
      "osType": "linux-x64",
      "productLineId": "vpx",
      "apiType": "VirtualCenter",
      "apiVersion": "7.0.2.0",
      "licenseProductName": "VMware VirtualCenter Server",
      "licenseProductVersion": "7.0"
}