TITLE: Windows Installation Commands
DESCRIPTION: PowerShell commands to install OpenSearch and set custom admin password on Windows

LANGUAGE: powershell
CODE:
.\opensearch-windows-install.bat

LANGUAGE: powershell
CODE:
set OPENSEARCH_INITIAL_ADMIN_PASSWORD=<custom-admin-password>

----------------------------------------

TITLE: Basic Cluster Health Check using cURL
DESCRIPTION: Examples of making basic HTTP GET requests to check cluster health, both with and without security plugin enabled.

LANGUAGE: bash
CODE:
curl -X GET "http://localhost:9200/_cluster/health"

LANGUAGE: bash
CODE:
curl -X GET "https://localhost:9200/_cluster/health" -ku admin:<custom-admin-password>"

----------------------------------------

TITLE: Document Indexing Operations
DESCRIPTION: Examples of indexing a document with specific fields into OpenSearch.

LANGUAGE: json
CODE:
PUT /students/_doc/1
{
  "name": "John Doe",
  "gpa": 3.89,
  "grad_year": 2022
}

----------------------------------------

TITLE: Performing Vector Search in OpenSearch
DESCRIPTION: Executes a k-nearest neighbor (kNN) search on the 'hotels-index' to find the top 3 closest hotels to the location [5, 4].

LANGUAGE: json
CODE:
POST /hotels-index/_search
{
  "size": 3,
  "query": {
    "knn": {
      "location": {
        "vector": [5, 4],
        "k": 3
      }
    }
  }
}

----------------------------------------

TITLE: Testing reranking with Amazon Bedrock model in OpenSearch
DESCRIPTION: This JSON request demonstrates how to use the created reranking pipeline to improve search results relevance using the Amazon Bedrock Rerank model.

LANGUAGE: json
CODE:
POST my-test-data/_search?search_pipeline=rerank_pipeline_bedrock
{
  "query": {
    "match": {
      "passage_text": "What is the capital city of America?"
    }
  },
  "ext": {
    "rerank": {
      "query_context": {
         "query_text": "What is the capital city of America?"
      }
    }
  },
  "highlight": {
    "pre_tags": ["<strong>"],
    "post_tags": ["</strong>"],
    "fields": {"passage_text": {}}
  },
  "_source": false,
  "fields": ["passage_text"]
}

----------------------------------------

TITLE: Docker Volume Configuration for Custom OpenSearch Dashboards Settings
DESCRIPTION: Docker compose configuration to mount a custom opensearch_dashboards.yml file for branding customization.

LANGUAGE: yaml
CODE:
volumes:
  - ./opensearch_dashboards.yml:/usr/share/opensearch-dashboards/config/opensearch_dashboards.yml

----------------------------------------

TITLE: Configuring RAG Pipeline for Conversational Search in OpenSearch
DESCRIPTION: This snippet shows how to create a search pipeline with a Retrieval Augmented Generation (RAG) processor in OpenSearch. It specifies the model ID, context fields, and prompts for the conversational search.

LANGUAGE: json
CODE:
PUT /_search/pipeline/my-conversation-search-pipeline-openai
{
  "response_processors": [
    {
      "retrieval_augmented_generation": {
        "tag": "Demo pipeline",
        "description": "Demo pipeline Using Cohere",
        "model_id": "your_model_id_created_in_step1",
        "context_field_list": [
          "text"
        ],
        "system_prompt": "You are a helpful assistant",
        "user_instructions": "Generate a concise and informative answer in less than 100 words for the given question"
      }
    }
  ]
}

----------------------------------------

TITLE: Creating Multimodal Search Workflow in OpenSearch
DESCRIPTION: POST request to create a default multimodal search workflow using the Flow Framework. This automatically sets up an ingest pipeline and index.

LANGUAGE: json
CODE:
POST /_plugins/_flow_framework/workflow?use_case=multimodal_search&provision=true
{
"create_ingest_pipeline.model_id": "mBGzipQB2gmRjlv_dOoB"
}

----------------------------------------

TITLE: Training k-NN Model
DESCRIPTION: Initiates the training of a k-NN model using the training data index and specified parameters for the Faiss engine.

LANGUAGE: json
CODE:
POST /_plugins/_knn/models/my-model/_train
{
  "training_index": "train-index",
  "training_field": "train-field",
  "dimension": 4,
  "description": "My model description",
  "space_type": "l2",
  "method": {
    "name": "ivf",
    "engine": "faiss",
    "parameters": {
      "nlist": 4,
      "nprobes": 2
    }
  }
}

----------------------------------------

TITLE: Executing a Range Query in OpenSearch
DESCRIPTION: This snippet demonstrates how to search for documents where the 'line_id' field value is between 10 and 20 (inclusive) using a range query.

LANGUAGE: json
CODE:
GET shakespeare/_search
{
  "query": {
    "range": {
      "line_id": {
        "gte": 10,
        "lte": 20
      }
    }
  }
}

----------------------------------------

TITLE: Registering a Conversational Agent with RAG Capabilities
DESCRIPTION: Creates a conversational agent with two vector database tools for population data and tech news, using an LLM for processing and responding to queries.

LANGUAGE: json
CODE:
POST _plugins/_ml/agents/_register
{
  "name": "Chat Agent with RAG",
  "type": "conversational",
  "description": "this is a test agent",
  "llm": {
    "model_id": "your_llm_model_id",
    "parameters": {
      "max_iteration": 5,
      "response_filter": "$.completion"
    }
  },
  "memory": {
    "type": "conversation_index"
  },
  "tools": [
    {
      "type": "VectorDBTool",
      "name": "population_data_knowledge_base",
      "description": "This tool provides population data of US cities.",
      "parameters": {
        "input": "${parameters.question}",
        "index": "test_population_data",
        "source_field": [
          "population_description"
        ],
        "model_id": "your_text_embedding_model_id",
        "embedding_field": "population_description_embedding",
        "doc_size": 3
      }
    },
    {
      "type": "VectorDBTool",
      "name": "tech_news_knowledge_base",
      "description": "This tool provides recent tech news.",
      "parameters": {
        "input": "${parameters.question}",
        "index": "test_tech_news",
        "source_field": [
          "passage"
        ],
        "model_id": "your_text_embedding_model_id",
        "embedding_field": "passage_embedding",
        "doc_size": 2
      }
    }
  ],
  "app_type": "chat_with_rag"
}

----------------------------------------

TITLE: Basic PPL Query Syntax in OpenSearch
DESCRIPTION: Demonstrates the fundamental syntax structure of a PPL query using pipe operators to chain commands. The query starts with a search command followed by optional processing commands.

LANGUAGE: sql
CODE:
search source=<index-name> | <command_1> | <command_2> | ... | <command_n>

----------------------------------------

TITLE: Configuring Security Settings for Multi-tenancy
DESCRIPTION: Core security configuration settings for OpenSearch Dashboards multi-tenancy including tenant enablement and default settings.

LANGUAGE: yaml
CODE:
config:
  dynamic:
    kibana:
      multitenancy_enabled: true
      private_tenant_enabled: true
      default_tenant: global tenant
      server_username: kibanaserver
      index: '.kibana'
    do_not_fail_on_forbidden: false

----------------------------------------

TITLE: Complete SQL Query Syntax in OpenSearch
DESCRIPTION: The complete syntax for searching and aggregating data in OpenSearch using SQL. It includes all optional clauses such as WHERE, GROUP BY, HAVING, ORDER BY, and LIMIT.

LANGUAGE: sql
CODE:
SELECT [DISTINCT] (* | expression) [[AS] alias] [, ...]
FROM index_name
[WHERE predicates]
[GROUP BY expression [, ...]
 [HAVING predicates]]
[ORDER BY expression [IS [NOT] NULL] [ASC | DESC] [, ...]]
[LIMIT [offset, ] size]

----------------------------------------

TITLE: Upgrading OpenSearch with YUM
DESCRIPTION: Upgrade OpenSearch to the latest version using YUM package manager.

LANGUAGE: bash
CODE:
sudo yum update opensearch

----------------------------------------

TITLE: Creating OpenAI Connector for Batch Prediction
DESCRIPTION: Example of creating a connector to OpenAI's text-embedding-ada-002 model with batch prediction capabilities. Includes configuration for predict, batch_predict, batch_predict_status, and cancel_batch_predict actions.

LANGUAGE: json
CODE:
{
  "name": "OpenAI Embedding model",
  "description": "OpenAI embedding model for testing offline batch",
  "version": "1",
  "protocol": "http",
  "parameters": {
    "model": "text-embedding-ada-002",
    "input_file_id": "<your input file id in OpenAI>",
    "endpoint": "/v1/embeddings"
  },
  "credential": {
    "openAI_key": "<your openAI key>"
  },
  "actions": [
    {
      "action_type": "predict",
      "method": "POST",
      "url": "https://api.openai.com/v1/embeddings",
      "headers": {
        "Authorization": "Bearer ${credential.openAI_key}"
      },
      "request_body": "{ \"input\": ${parameters.input}, \"model\": \"${parameters.model}\" }",
      "pre_process_function": "connector.pre_process.openai.embedding",
      "post_process_function": "connector.post_process.openai.embedding"
    },
    {
      "action_type": "batch_predict",
      "method": "POST",
      "url": "https://api.openai.com/v1/batches",
      "headers": {
        "Authorization": "Bearer ${credential.openAI_key}"
      },
      "request_body": "{ \"input_file_id\": \"${parameters.input_file_id}\", \"endpoint\": \"${parameters.endpoint}\", \"completion_window\": \"24h\" }"
    },
    {
      "action_type": "batch_predict_status",
      "method": "GET",
      "url": "https://api.openai.com/v1/batches/${parameters.id}",
      "headers": {
        "Authorization": "Bearer ${credential.openAI_key}"
      }
    },
    {
      "action_type": "cancel_batch_predict",
      "method": "POST",
      "url": "https://api.openai.com/v1/batches/${parameters.id}/cancel",
      "headers": {
        "Authorization": "Bearer ${credential.openAI_key}"
      }
    }
  ]
}

----------------------------------------

TITLE: Searching Indexes in OpenSearch
DESCRIPTION: These HTTP GET requests demonstrate how to search a specific index or multiple indexes matching a pattern in OpenSearch using a query parameter.

LANGUAGE: http
CODE:
GET my-logs/_search?q=test
GET my-logs*/_search?q=test

----------------------------------------

TITLE: Registering and Deploying an LLM Model
DESCRIPTION: These requests show how to register an LLM model with OpenSearch and then deploy it for use.

LANGUAGE: json
CODE:
POST /_plugins/_ml/models/_register
{
  "name": "openAI-gpt-3.5-turbo",
  "function_name": "remote",
  "description": "test model",
  "connector_id": "u3DEbI0BfUsSoeNTti-1"
}

LANGUAGE: json
CODE:
POST /_plugins/_ml/models/gnDIbI0BfUsSoeNT_jAw/_deploy

----------------------------------------

TITLE: Registering a Flow Agent with RAGTool in OpenSearch
DESCRIPTION: This snippet demonstrates how to register a flow agent that uses the RAGTool in OpenSearch. It includes parameters for embedding and inference models, index configuration, and prompt settings.

LANGUAGE: json
CODE:
POST /_plugins/_ml/agents/_register
{
  "name": "Test_Agent_For_RagTool",
  "type": "flow",
  "description": "this is a test flow agent",
  "tools": [
  {
    "type": "RAGTool",
    "description": "A description of the tool",
    "parameters": {
      "embedding_model_id": "Hv_PY40Bk4MTqircAVmm",
      "inference_model_id": "SNzSY40B_1JGmyB0WbfI",
      "index": "my_test_data",
      "embedding_field": "embedding",
      "query_type": "neural",
      "source_field": [
        "text"
      ],
      "input": "${parameters.question}",
      "prompt": "\n\nHuman:You are a professional data analyst. You will always answer question based on the given context first. If the answer is not directly shown in the context, you will analyze the data and find the answer. If you don't know the answer, just say don't know. \n\n Context:\n${parameters.output_field}\n\nHuman:${parameters.question}\n\nAssistant:"
    }
  }
]
}

----------------------------------------

TITLE: Sample OpenSearch Configuration with Security Settings
DESCRIPTION: An example opensearch.yml file that configures TLS certificates, permissions, and audit logging.

LANGUAGE: yaml
CODE:
plugins.security.ssl.transport.pemcert_filepath: node1.pem
plugins.security.ssl.transport.pemkey_filepath: node1-key.pem
plugins.security.ssl.transport.pemtrustedcas_filepath: root-ca.pem
plugins.security.ssl.transport.enforce_hostname_verification: false
plugins.security.ssl.http.enabled: true
plugins.security.ssl.http.pemcert_filepath: node1.pem
plugins.security.ssl.http.pemkey_filepath: node1-key.pem
plugins.security.ssl.http.pemtrustedcas_filepath: root-ca.pem
plugins.security.allow_default_init_securityindex: true
plugins.security.authcz.admin_dn:
  - CN=A,OU=UNIT,O=ORG,L=TORONTO,ST=ONTARIO,C=CA
plugins.security.nodes_dn:
  - 'CN=N,OU=UNIT,O=ORG,L=TORONTO,ST=ONTARIO,C=CA'
plugins.security.audit.type: internal_opensearch
plugins.security.enable_snapshot_restore_privilege: true
plugins.security.check_snapshot_restore_write_privileges: true
plugins.security.restapi.roles_enabled: ["all_access", "security_rest_api_access"]
cluster.routing.allocation.disk.threshold_enabled: false
opendistro_security.audit.config.disabled_rest_categories: NONE
opendistro_security.audit.config.disabled_transport_categories: NONE

----------------------------------------

TITLE: Performing Query String Search with SQL and PPL in OpenSearch
DESCRIPTION: Examples of using the QUERY_STRING function in SQL and PPL to perform complex searches with operators, wildcards, and regex. Shows syntax and usage with multiple fields and options.

LANGUAGE: sql
CODE:
SELECT account_number, address
FROM accounts
WHERE query_string(['address'], 'Lane Street', default_operator='OR')

LANGUAGE: ppl
CODE:
SOURCE=accounts | WHERE query_string(['address'], 'Lane Street', default_operator='OR') | fields account_number, address

----------------------------------------

TITLE: Running RAG Search with Conversation Memory
DESCRIPTION: Executes a RAG search using the configured pipeline and stores the conversation in memory.

LANGUAGE: JSON
CODE:
GET /qa_demo/_search?search_pipeline=my-conversation-search-pipeline-claude
{
"query": {
    "match": {
    "text": "What's the population increase of New York City from 2021 to 2023?"
    }
},
"size": 1,
"_source": [
    "text"
],
"ext": {
    "generative_qa_parameters": {
    "llm_model": "bedrock-converse/anthropic.claude-3-sonnet-20240229-v1:0",
    "llm_question": "What's the population increase of New York City from 2021 to 2023?",
    "context_size": 5,
    "memory_id": "sBAqY5UBSzdNxlHvrSJK"
    }
}
}

----------------------------------------

TITLE: Creating a basic vector index in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a basic vector index in OpenSearch by enabling k-NN search and defining a vector field with specified dimensions and other optional parameters.

LANGUAGE: json
CODE:
PUT /test-index
{
  "settings": {
    "index.knn": true
  },
  "mappings": {
    "properties": {
      "my_vector": {
        "type": "knn_vector",
        "dimension": 3,
        "space_type": "l2",
        "mode": "on_disk",
        "method": {
          "name": "hnsw"
        }     
      }
    }
  }
}

----------------------------------------

TITLE: Configuring TLS Certificates in opensearch.yml (YAML)
DESCRIPTION: This snippet shows how to set the correct paths for custom certificates and keys in the opensearch.yml configuration file. It includes settings for both transport and HTTP layers.

LANGUAGE: yaml
CODE:
plugins.security.ssl.transport.pemcert_filepath: /path/to/your/cert.pem
plugins.security.ssl.transport.pemkey_filepath: /path/to/your/key.pem
plugins.security.ssl.transport.pemtrustedcas_filepath: /path/to/your/ca.pem
plugins.security.ssl.http.enabled: true
plugins.security.ssl.http.pemcert_filepath: /path/to/your/cert.pem
plugins.security.ssl.http.pemkey_filepath: /path/to/your/key.pem
plugins.security.ssl.http.pemtrustedcas_filepath: /path/to/your/ca.pem

----------------------------------------

TITLE: Performing Semantic Search Query in OpenSearch
DESCRIPTION: This snippet demonstrates a complex search query combining neural search with traditional text matching and custom scoring in OpenSearch.

LANGUAGE: json
CODE:
GET /my-nlp-index/_search
{
  "_source": {
    "excludes": [
      "passage_embedding"
    ]
  },
  "query": {
    "bool": {
      "filter": {
         "wildcard":  { "id": "*1" }
      },
      "should": [
        {
          "script_score": {
            "query": {
              "neural": {
                "passage_embedding": {
                  "query_text": "Hi world",
                  "model_id": "bQ1J8ooBpBj3wT4HVUsb",
                  "k": 100
                }
              }
            },
            "script": {
              "source": "_score * 1.5"
            }
          }
        },
        {
          "script_score": {
            "query": {
              "match": {
                "passage_text": "Hi world"
              }
            },
            "script": {
              "source": "_score * 1.7"
            }
          }
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Creating Vector Index for OpenAI Embeddings
DESCRIPTION: JSON configuration for creating a vector index with KNN settings for storing embeddings.

LANGUAGE: json
CODE:
{
  "settings": {
    "index": {
      "knn.space_type": "cosinesimil",
      "default_pipeline": "my_openai_embedding_pipeline",
      "knn": "true"
    }
  },
  "mappings": {
    "properties": {
      "text_knn": {
        "type": "knn_vector",
        "dimension": 1536
      }
    }
  }
}

----------------------------------------

TITLE: Creating an Automated Conversational Search Workflow
DESCRIPTION: This request creates a default conversational search workflow, which sets up a connector, registers and deploys a model, and configures a search pipeline.

LANGUAGE: json
CODE:
POST /_plugins/_flow_framework/workflow?use_case=conversational_search_with_llm_deploy&provision=true
{
"create_connector.credential.key": "<YOUR_API_KEY>"
}

----------------------------------------

TITLE: Ingesting Text Data for Embedding Generation in OpenSearch
DESCRIPTION: Illustrates how to ingest text data into an OpenSearch index with a configured ingest pipeline that automatically generates embeddings. The pipeline stores the generated embeddings in the 'output_embedding' field.

LANGUAGE: json
CODE:
PUT /my-ai-search-index/_doc/1
{
  "input_text": "Example: AI search description"
}

----------------------------------------

TITLE: Register Conversational Agent - Example Request
DESCRIPTION: Example request body for registering a conversational agent with LLM integration and multiple tools including vector database and index metadata retrieval.

LANGUAGE: json
CODE:
{
  "name": "Test_Agent_For_ReAct_ClaudeV2",
  "type": "conversational",
  "description": "this is a test agent",
  "app_type": "my chatbot",
  "llm": {
    "model_id": "<llm_model_id>",
    "parameters": {
      "max_iteration": 5,
      "stop_when_no_tool_found": true,
      "response_filter": "$.completion"
    }
  },
  "memory": {
    "type": "conversation_index"
  },
  "tools": [
    {
      "type": "VectorDBTool",
      "name": "VectorDBTool",
      "description": "A tool to search opensearch index with natural language question. If you don't know answer for some question, you should always try to search data with this tool. Action Input: <natural language question>",
      "parameters": {
        "model_id": "<embedding_model_id>",
        "index": "<your_knn_index>",
        "embedding_field": "<embedding_filed_name>",
        "source_field": [
          "<source_filed>"
        ],
        "input": "${parameters.question}"
      }
    },
    {
      "type": "CatIndexTool",
      "name": "RetrieveIndexMetaTool",
      "description": "Use this tool to get OpenSearch index information: (health, status, index, uuid, primary count, replica count, docs.count, docs.deleted, store.size, primary.store.size)."
    }
  ]
}

----------------------------------------

TITLE: Performing Semantic Search with Default Model in OpenSearch
DESCRIPTION: This snippet shows how to perform a semantic search query in OpenSearch using a default model, eliminating the need to specify the model ID in the query.

LANGUAGE: json
CODE:
GET /my-nlp-index/_search
{
  "_source": {
    "excludes": [
      "passage_embedding"
    ]
  },
  "query": {
    "neural": {
      "passage_embedding": {
        "query_text": "Hi world",
        "k": 100
      }
    }
  }
}

----------------------------------------

TITLE: Indexing Student Data with Bulk API
DESCRIPTION: Creates sample student records in the 'students' index using the bulk API endpoint

LANGUAGE: json
CODE:
POST _bulk
{ "create": { "_index": "students", "_id": "1" } }
{ "name": "John Doe", "gpa": 3.89, "grad_year": 2022}
{ "create": { "_index": "students", "_id": "2" } }
{ "name": "Jonathan Powers", "gpa": 3.85, "grad_year": 2025 }
{ "create": { "_index": "students", "_id": "3" } }
{ "name": "Jane Doe", "gpa": 3.52, "grad_year": 2024 }

----------------------------------------

TITLE: Creating Vector Index for Semantic Search in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a vector index in OpenSearch for semantic search, including setting up the default ingest pipeline and mapping vector fields.

LANGUAGE: json
CODE:
PUT /my-nlp-index
{
  "settings": {
    "index.knn": true,
    "default_pipeline": "nlp-ingest-pipeline"
  },
  "mappings": {
    "properties": {
      "id": {
        "type": "text"
      },
      "passage_embedding": {
        "type": "knn_vector",
        "dimension": 768,
        "method": {
          "engine": "lucene",
          "space_type": "l2",
          "name": "hnsw",
          "parameters": {}
        }
      },
      "passage_text": {
        "type": "text"
      }
    }
  }
}

----------------------------------------

TITLE: Basic OpenSearch Security Configuration Structure
DESCRIPTION: Main configuration structure showing the three primary sections of the security configuration file: http, authc, and authz.

LANGUAGE: yaml
CODE:
config:
  dynamic:
    http:
      ...
    authc:
      ...
    authz:
      ...

----------------------------------------

TITLE: OpenSearch Security Plugin Configuration Example
DESCRIPTION: Example YAML configuration showing common security settings including node certificates, admin DNs, role mappings, audit logging, and advanced SSL options

LANGUAGE: yaml
CODE:
# Common configuration settings
plugins.security.nodes_dn:
  - "CN=*.example.com, OU=SSL, O=Test, L=Test, C=DE"
  - "CN=node.other.com, OU=SSL, O=Test, L=Test, C=DE"
  - "CN=node.example.com, OU=SSL\, Inc., L=Test, C=DE" # escape additional comma with `\`
plugins.security.authcz.admin_dn:
  - CN=kirk,OU=client,O=client,L=test, C=de
plugins.security.roles_mapping_resolution: MAPPING_ONLY
plugins.security.ssl.transport.pemcert_filepath: esnode.pem
plugins.security.ssl.transport.pemkey_filepath: esnode-key.pem
plugins.security.ssl.transport.pemtrustedcas_filepath: root-ca.pem
plugins.security.ssl.transport.enforce_hostname_verification: false
plugins.security.ssl.http.enabled: true
plugins.security.ssl.http.pemcert_filepath: esnode.pem
plugins.security.ssl.http.pemkey_filepath: esnode-key.pem
plugins.security.ssl.http.pemtrustedcas_filepath: root-ca.pem
plugins.security.allow_unsafe_democertificates: true
plugins.security.allow_default_init_securityindex: true
plugins.security.nodes_dn_dynamic_config_enabled: false
plugins.security.cert.intercluster_request_evaluator_class: # need example value for this.
plugins.security.audit.type: internal_opensearch
plugins.security.enable_snapshot_restore_privilege: true
plugins.security.check_snapshot_restore_write_privileges: true
plugins.security.cache.ttl_minutes: 60
plugins.security.restapi.roles_enabled: ["all_access", "security_rest_api_access"]
plugins.security.system_indices.enabled: true
plugins.security.system_indices.indices: [".opendistro-alerting-config", ".opendistro-alerting-alert*", ".opendistro-anomaly-results*", ".opendistro-anomaly-detector*", ".opendistro-anomaly-checkpoints", ".opendistro-anomaly-detection-state", ".opendistro-reports-*", ".opendistro-notifications-*", ".opendistro-notebooks", ".opendistro-asynchronous-search-response*"]
node.max_local_storage_nodes: 3

----------------------------------------

TITLE: Setting Default Model for Semantic Search in OpenSearch
DESCRIPTION: This snippet shows how to set a default model for semantic search on an index or field level using a search pipeline in OpenSearch.

LANGUAGE: json
CODE:
PUT /_search/pipeline/default_model_pipeline 
{
  "request_processors": [
    {
      "neural_query_enricher" : {
        "default_model_id": "bQ1J8ooBpBj3wT4HVUsb",
        "neural_field_default_id": {
           "my_field_1": "uZj0qYoBMtvQlfhaYeud",
           "my_field_2": "upj0qYoBMtvQlfhaZOuM"
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Index Creation with Mappings and Settings
DESCRIPTION: Example of creating an index with custom mappings and settings configuration.

LANGUAGE: json
CODE:
PUT /students
{
  "settings": {
    "index.number_of_shards": 1
  }, 
  "mappings": {
    "properties": {
      "name": {
        "type": "text"
      },
      "grad_year": {
        "type": "date"
      }
    }
  }
}

----------------------------------------

TITLE: Bulk Indexing Documents in OpenSearch
DESCRIPTION: This snippet demonstrates how to use the Bulk API to index multiple documents into the 'students' index in OpenSearch. It shows the JSON structure for creating two student records with their respective details.

LANGUAGE: json
CODE:
POST _bulk
{ "create": { "_index": "students", "_id": "2" } }
{ "name": "Jonathan Powers", "gpa": 3.85, "grad_year": 2025 }
{ "create": { "_index": "students", "_id": "3" } }
{ "name": "Jane Doe", "gpa": 3.52, "grad_year": 2024 }

----------------------------------------

TITLE: Configuring Text Embedding Pipeline in OpenSearch
DESCRIPTION: Creates an ingest pipeline for text embedding using a specified model to process fields in the knowledge base.

LANGUAGE: json
CODE:
PUT /_ingest/pipeline/test_stock_price_data_pipeline
{
  "description": "text embedding pipeline",
  "processors": [
    {
      "text_embedding": {
        "model_id": "your_text_embedding_model_id",
        "field_map": {
          "stock_price_history": "stock_price_history_embedding"
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Creating Vector Index with Default Ingest Pipeline in OpenSearch
DESCRIPTION: PUT request to create a vector index configured with a default ingest pipeline and appropriate field mappings for text and image data.

LANGUAGE: json
CODE:
PUT /my-nlp-index
{
  "settings": {
    "index.knn": true,
    "default_pipeline": "nlp-ingest-pipeline",
    "number_of_shards": 2
  },
  "mappings": {
    "properties": {
      "vector_embedding": {
        "type": "knn_vector",
        "dimension": 1024,
        "method": {
          "name": "hnsw",
          "engine": "lucene",
          "parameters": {}
        }
      },
      "image_description": {
        "type": "text"
      },
      "image_binary": {
        "type": "binary"
      }
    }
  }
}

----------------------------------------

TITLE: Bulk Indexing Vector Data
DESCRIPTION: Demonstrates bulk indexing of vector data into the k-NN index, including both vector fields and additional metadata like price.

LANGUAGE: json
CODE:
POST _bulk
{ "index": { "_index": "my-knn-index-1", "_id": "1" } }
{ "my_vector1": [1.5, 2.5], "price": 12.2 }
{ "index": { "_index": "my-knn-index-1", "_id": "2" } }
{ "my_vector1": [2.5, 3.5], "price": 7.1 }
{ "index": { "_index": "my-knn-index-1", "_id": "3" } }
{ "my_vector1": [3.5, 4.5], "price": 12.9 }

----------------------------------------

TITLE: Creating an index with automatic embedding generation in OpenSearch
DESCRIPTION: This snippet shows how to create an index in OpenSearch that uses an ingest pipeline for automatic embedding generation. It configures the index settings, mappings, and specifies the default pipeline.

LANGUAGE: json
CODE:
PUT /my-ai-search-index
{
  "settings": {
    "index.knn": true,
    "default_pipeline": "auto-embed-pipeline"
  },
  "mappings": {
    "properties": {
      "input_text": {
        "type": "text"
      },
      "output_embedding": {
        "type": "knn_vector",
        "dimension": 768
      }
    }
  }
}

----------------------------------------

TITLE: Sample Docker Compose File for OpenSearch Cluster
DESCRIPTION: A sample docker-compose.yml file that creates a cluster with two OpenSearch nodes and one OpenSearch Dashboards node. This configuration enables the demo security settings.

LANGUAGE: yaml
CODE:
services:
  opensearch-node1: # This is also the hostname of the container within the Docker network (i.e. https://opensearch-node1/)
    image: opensearchproject/opensearch:latest # Specifying the latest available image - modify if you want a specific version
    container_name: opensearch-node1
    environment:
      - cluster.name=opensearch-cluster # Name the cluster
      - node.name=opensearch-node1 # Name the node that will run in this container
      - discovery.seed_hosts=opensearch-node1,opensearch-node2 # Nodes to look for when discovering the cluster
      - cluster.initial_cluster_manager_nodes=opensearch-node1,opensearch-node2 # Nodes eligible to serve as cluster manager
      - bootstrap.memory_lock=true # Disable JVM heap memory swapping
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m" # Set min and max JVM heap sizes to at least 50% of system RAM
      - OPENSEARCH_INITIAL_ADMIN_PASSWORD=${OPENSEARCH_INITIAL_ADMIN_PASSWORD}    # Sets the demo admin user password when using demo configuration, required for OpenSearch 2.12 and later
    ulimits:
      memlock:
        soft: -1 # Set memlock to unlimited (no soft or hard limit)
        hard: -1
      nofile:
        soft: 65536 # Maximum number of open files for the opensearch user - set to at least 65536
        hard: 65536
    volumes:
      - opensearch-data1:/usr/share/opensearch/data # Creates volume called opensearch-data1 and mounts it to the container
    ports:
      - 9200:9200 # REST API
      - 9600:9600 # Performance Analyzer
    networks:
      - opensearch-net # All of the containers will join the same Docker bridge network
  opensearch-node2:
    image: opensearchproject/opensearch:latest # This should be the same image used for opensearch-node1 to avoid issues
    container_name: opensearch-node2
    environment:
      - cluster.name=opensearch-cluster
      - node.name=opensearch-node2
      - discovery.seed_hosts=opensearch-node1,opensearch-node2
      - cluster.initial_cluster_manager_nodes=opensearch-node1,opensearch-node2
      - bootstrap.memory_lock=true
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m"
      - OPENSEARCH_INITIAL_ADMIN_PASSWORD=${OPENSEARCH_INITIAL_ADMIN_PASSWORD}
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - opensearch-data2:/usr/share/opensearch/data
    networks:
      - opensearch-net
  opensearch-dashboards:
    image: opensearchproject/opensearch-dashboards:latest # Make sure the version of opensearch-dashboards matches the version of opensearch installed on other nodes
    container_name: opensearch-dashboards
    ports:
      - 5601:5601 # Map host port 5601 to container port 5601
    expose:
      - "5601" # Expose port 5601 for web access to OpenSearch Dashboards
    environment:
      OPENSEARCH_HOSTS: '["https://opensearch-node1:9200","https://opensearch-node2:9200"]' # Define the OpenSearch nodes that OpenSearch Dashboards will query
    networks:
      - opensearch-net

volumes:
  opensearch-data1:
  opensearch-data2:

networks:
  opensearch-net:

----------------------------------------

TITLE: Basic OpenSearch Operations
DESCRIPTION: Examples of basic operations including creating an index, indexing data, searching, and deleting documents.

LANGUAGE: java
CODE:
// Create index
String index = "sample-index";
CreateIndexRequest createIndexRequest = new CreateIndexRequest.Builder().index(index).build();
client.indices().create(createIndexRequest);

// Index data
IndexData indexData = new IndexData("first_name", "Bruce");
IndexRequest<IndexData> indexRequest = new IndexRequest.Builder<IndexData>().index(index).id("1").document(indexData).build();
client.index(indexRequest);

// Search
SearchResponse<IndexData> searchResponse = client.search(s -> s.index(index), IndexData.class);

// Delete document
client.delete(b -> b.index(index).id("1"));

// Delete index
DeleteIndexRequest deleteIndexRequest = new DeleteIndexRequest.Builder().index(index).build();
DeleteIndexResponse deleteIndexResponse = client.indices().delete(deleteIndexRequest);

----------------------------------------

TITLE: Querying OpenSearch Server with Security Enabled
DESCRIPTION: These cURL commands send requests to the OpenSearch server to verify its operation with security enabled, using HTTPS and basic authentication.

LANGUAGE: batch
CODE:
curl.exe -X GET https://localhost:9200 -u "admin:<custom-admin-password>" --insecure

LANGUAGE: batch
CODE:
curl.exe -X GET https://localhost:9200/_cat/plugins?v -u "admin:<custom-admin-password>" --insecure

----------------------------------------

TITLE: Configuring Search Pipeline with Rerank Processor
DESCRIPTION: Creates a search pipeline that uses a cross-encoder model for reranking. Specifies the model ID and document fields to use as context.

LANGUAGE: json
CODE:
PUT /_search/pipeline/my_pipeline
{
  "description": "Pipeline for reranking with a cross-encoder",
  "response_processors": [
    {
      "rerank": {
        "ml_opensearch": {
          "model_id": "gnDIbI0BfUsSoeNT_jAw"
        },
        "context": {
          "document_fields": [
            "passage_text"
          ]
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Ingesting Documents via Bulk API
DESCRIPTION: Bulk request to ingest sample documents containing passage_text fields into the created index.

LANGUAGE: json
CODE:
POST /_bulk
{ "index": { "_index": "my-index" } }
{ "passage_text" : "I said welcome to them and we entered the house" }
{ "index": { "_index": "my-index" } }
{ "passage_text" : "I feel welcomed in their family" }
{ "index": { "_index": "my-index" } }
{ "passage_text" : "Welcoming gifts are great" }


----------------------------------------

TITLE: Bulk Uploading Documents to OpenSearch
DESCRIPTION: This bash command demonstrates how to use cURL to bulk upload documents to the 'ecommerce' index in OpenSearch using the Bulk API and the previously downloaded NDJSON file.

LANGUAGE: bash
CODE:
curl -H "Content-Type: application/x-ndjson" -X PUT "https://localhost:9200/ecommerce/_bulk" -ku admin:<custom-admin-password> --data-binary "@ecommerce.ndjson"

----------------------------------------

TITLE: Document-Specific Explain Query
DESCRIPTION: Demonstrates how to use the explain parameter for a specific document ID to get low-level scoring information.

LANGUAGE: json
CODE:
GET <index>/_explain/<id>
POST <index>/_explain/<id>

----------------------------------------

TITLE: Configuring AWS Temporary Credentials
DESCRIPTION: INI configuration for storing AWS temporary credentials in the credentials file.

LANGUAGE: ini
CODE:
[default]
AWS_ACCESS_KEY_ID=your_access_key_of_role_created_in_step3.1
AWS_SECRET_ACCESS_KEY=your_secret_key_of_role_created_in_step3.1
AWS_SESSION_TOKEN=your_session_token_of_role_created_in_step3.1

----------------------------------------

TITLE: Creating Vector Index for Semantic Search
DESCRIPTION: This JSON request creates a vector index in OpenSearch for storing input text and generated embeddings, enabling semantic search.

LANGUAGE: json
CODE:
PUT my_index
{
  "settings": {
    "index": {
      "knn.space_type": "cosinesimil",
      "default_pipeline": "my_bedrock_cohere_embedding_pipeline",
      "knn": "true"
    }
  },
  "mappings": {
    "properties": {
      "text_knn": {
        "type": "knn_vector",
        "dimension": 1024
      }
    }
  }
}

----------------------------------------

TITLE: Continuing a Conversation with the Agent
DESCRIPTION: Demonstrates how to continue a previous conversation by providing a memory_id, asking for a comparison between Austin and Seattle populations.

LANGUAGE: json
CODE:
POST _plugins/_ml/agents/your_agent_id/_execute
{
  "parameters": {
    "question": "What's the population of Austin 2023, compared with Seattle",
    "memory_id": "l7VUxI0B8vrNLhb9sRuQ",
    "verbose": true
  }
}

----------------------------------------

TITLE: Indexing Documents with Bulk Helper in OpenSearch JavaScript Client
DESCRIPTION: Demonstrates how to use the bulk helper to index documents into an OpenSearch index. This operation creates new documents or recreates existing ones.

LANGUAGE: javascript
CODE:
client.helpers.bulk({
  datasource: arrayOfDocuments,
  onDocument (doc) {
    return {
      index: { _index: 'example-index' }
    }
  }
})

----------------------------------------

TITLE: Creating Search Pipeline and Running Semantic Search Query
DESCRIPTION: JSON requests to create a search pipeline for query embedding and perform a semantic search query.

LANGUAGE: json
CODE:
PUT /_search/pipeline/asymmetric_embedding_search_pipeline
{
   "description": "ingest passage text and generate a embedding using an asymmetric model",
   "request_processors": [
      {
        "ml_inference": {
            "query_template": "{\"size\": 3,\"query\": {\"knn\": {\"fact_embedding\": {\"vector\": ${query_embedding},\"k\": 4}}}}",
            "function_name": "text_embedding",
            "model_id": "{{ _.model_id }}",
            "model_input": "{ \"text_docs\": [\"${input_map.query}\"], \"target_response\": [\"sentence_embedding\"], \"parameters\" : {\"content_type\" : \"query\" } }",
            "input_map": [
               {
                  "query": "query.term.fact_embedding.value"
               }
            ],
            "output_map": [
               {
                  "query_embedding": "$.inference_results[0].output[0].data",
                  "embedding_size": "$.inference_results.*.output.*.shape[0]"
               }
            ]
         }
      }
   ]
}

GET /nyc_facts/_search?search_pipeline=asymmetric_embedding_search_pipeline
{
  "query": {
    "term": {
      "fact_embedding": {
        "value": "What are some places for sports in NYC?",
       "boost": 1 
      }
    }
  }
}

----------------------------------------

TITLE: Performing Semantic Search Query
DESCRIPTION: This JSON request performs a semantic search query using the Bedrock Cohere embedding model to find relevant documents.

LANGUAGE: json
CODE:
POST /my_index/_search
{
  "query": {
    "neural": {
      "text_knn": {
        "query_text": "hello",
        "model_id": "your_embedding_model_id_created_in_step4",
        "k": 100
      }
    }
  },
  "size": "1",
  "_source": ["text"]
}

----------------------------------------

TITLE: Complete OpenSearch .NET Sample Program
DESCRIPTION: A comprehensive example demonstrating indexing, searching, and working with both high-level and low-level clients in OpenSearch.

LANGUAGE: csharp
CODE:
using OpenSearch.Client;
using OpenSearch.Net;

namespace NetClientProgram;

internal class Program
{
    private static IOpenSearchClient osClient = new OpenSearchClient();

    public static void Main(string[] args)
    {       
        Console.WriteLine("Indexing one student......");
        var student = new Student { Id = 100, 
                                    FirstName = "Paulo", 
                                    LastName = "Santos", 
                                    Gpa = 3.93, 
                                    GradYear = 2021 };
        var response =  osClient.Index(student, i => i.Index("students"));
        Console.WriteLine(response.IsValid ? "Response received" : "Error");

        Console.WriteLine("Searching for one student......");
        SearchForOneStudent();

        Console.WriteLine("Searching using low-level client......");
        SearchLowLevel();

        Console.WriteLine("Indexing an array of Student objects......");
        var studentArray = new Student[]
        {
            new() { Id = 200, 
                    FirstName = "Shirley", 
                    LastName = "Rodriguez", 
                    Gpa = 3.91, 
                    GradYear = 2019},
            new() { Id = 300, 
                    FirstName = "Nikki", 
                    LastName = "Wolf", 
                    Gpa = 3.87, 
                    GradYear = 2020}
        };
        var manyResponse = osClient.IndexMany(studentArray, "students");
        Console.WriteLine(manyResponse.IsValid ? "Response received" : "Error");
    }

    private static void SearchForOneStudent()
    {
        var searchResponse = osClient.Search<Student>(s => s
                                .Index("students")
                                .Query(q => q
                                    .Match(m => m
                                        .Field(fld => fld.LastName)
                                        .Query("Santos"))));

        PrintResponse(searchResponse);
    }

    private static void SearchForAllStudentsWithANonEmptyLastName()
    {
        var searchResponse = osClient.Search<Student>(s => s
                                .Index("students")
                                .Query(q => q
                        						.Bool(b => b
                        							.Must(m => m.Exists(fld => fld.LastName))
                        							.MustNot(m => m.Term(t => t.Verbatim().Field(fld => fld.LastName).Value(string.Empty)))
                        						)));

        PrintResponse(searchResponse);
    }

    private static void SearchLowLevel()
    {
        // Search for the student using the low-level client
        var lowLevelClient = osClient.LowLevel;

        var searchResponseLow = lowLevelClient.Search<SearchResponse<Student>>
            ("students",
            PostData.Serializable(
                new
                {
                    query = new
                    {
                        match = new
                        {
                            lastName = new
                            {
                                query = "Santos"
                            }
                        }
                    }
                }));

        PrintResponse(searchResponseLow);
    }

    private static void PrintResponse(ISearchResponse<Student> response)
    {
        if (response.IsValid)
        {
            foreach (var s in response.Documents)
            {
                Console.WriteLine($"{s.Id} {s.LastName} " +
                    $"{s.FirstName} {s.Gpa} {s.GradYear}");
            }
        }
        else
        {
            Console.WriteLine("Student not found.");
        }
    }
}

----------------------------------------

TITLE: Disable Shard Allocation API Call
DESCRIPTION: JSON API request to disable shard allocation before removing the Security plugin.

LANGUAGE: json
CODE:
curl -XPUT "https://localhost:9200/_cluster/settings" -u "admin:<password>" -H 'Content-Type: application/json' -d '{
   "transient": {
      "cluster.routing.allocation.enable": "none"
   }
}'

----------------------------------------

TITLE: Configuring Comprehensive Data Prepper Pipeline in YAML
DESCRIPTION: This snippet shows a comprehensive Data Prepper pipeline configuration using both required and optional components. It includes worker settings, a bounded blocking buffer, a string converter processor, and file source and sink configurations.

LANGUAGE: yaml
CODE:
sample-pipeline:
  workers: 4 # Number of workers
  delay: 100 # in milliseconds, how often the workers should run
  source:
    file:
        path: <path/to/input-file>
  buffer:
    bounded_blocking:
      buffer_size: 1024 # max number of events the buffer will accept
      batch_size: 256 # max number of events the buffer will drain for each read
  processor:
    - string_converter:
       upper_case: true
  sink:
    - file:
       path: <path/to/output-file>

----------------------------------------

TITLE: Configuring OpenSearch Cluster Settings for Local Models
DESCRIPTION: JSON request to configure OpenSearch cluster settings for running local models without dedicated ML nodes.

LANGUAGE: json
CODE:
PUT _cluster/settings
{
  "persistent": {
    "plugins.ml_commons.allow_registering_model_via_url": "true",
    "plugins.ml_commons.only_run_on_ml_node": "false",
    "plugins.ml_commons.model_access_control_enabled": "true",
    "plugins.ml_commons.native_memory_threshold": "99"
  }
}

----------------------------------------

TITLE: Using RAG Search Pipeline in OpenSearch Query
DESCRIPTION: This example shows how to use a search pipeline with the retrieval_augmented_generation processor in an OpenSearch query. It includes both the OpenSearch query and the generative question answering parameters for the LLM.

LANGUAGE: json
CODE:
GET /my_rag_test_data/_search?search_pipeline=rag_pipeline
{
  "query": {
    "match": {
      "text": "Abraham Lincoln"
    }
  },
  "ext": {
    "generative_qa_parameters": {
      "llm_model": "gpt-3.5-turbo",
      "llm_question": "Was Abraham Lincoln a good politician",
      "memory_id": "iXC4bI0BfUsSoeNTjS30",
      "context_size": 5,
      "message_size": 5,
      "timeout": 15
    }
  }
}

----------------------------------------

TITLE: Creating RAG Search Pipeline
DESCRIPTION: JSON configuration for creating a search pipeline with RAG processor using the DeepSeek model.

LANGUAGE: json
CODE:
{
  "response_processors": [
    {
      "retrieval_augmented_generation": {
        "tag": "Demo pipeline",
        "description": "Demo pipeline Using DeepSeek R1",
        "model_id": "Sym9sJQBts7fa6byEh1-",
        "context_field_list": [
          "text"
        ],
        "system_prompt": "You are a helpful assistant.",
        "user_instructions": "Generate a concise and informative answer in less than 100 words for the given question"
      }
    }
  ]
}

----------------------------------------

TITLE: Bulk API Format in OpenSearch
DESCRIPTION: Shows the structure for bulk indexing operations, including how to specify the index and document ID in the bulk data format. Each line must end with a newline character.

LANGUAGE: json
CODE:
POST _bulk
{ "index": { "_index": "<index>", "_id": "<id>" } }
{ "A JSON": "document" }

----------------------------------------

TITLE: Example Amazon SageMaker Connector Blueprint in JSON
DESCRIPTION: This snippet demonstrates a blueprint for creating an Amazon SageMaker connector in OpenSearch. It includes fields for connector name, description, version, protocol, AWS credentials, region, and action specifications.

LANGUAGE: json
CODE:
{
  "name": "<YOUR CONNECTOR NAME>",
  "description": "<YOUR CONNECTOR DESCRIPTION>",
  "version": "<YOUR CONNECTOR VERSION>",
  "protocol": "aws_sigv4",
  "credential": {
    "access_key": "<YOUR AWS ACCESS KEY>",
    "secret_key": "<YOUR AWS SECRET KEY>",
    "session_token": "<YOUR AWS SECURITY TOKEN>"
  },
  "parameters": {
    "region": "<YOUR AWS REGION>",
    "service_name": "sagemaker"
  },
  "actions": [
    {
      "action_type": "predict",
      "method": "POST",
      "headers": {
        "content-type": "application/json"
      },
      "url": "<YOUR SAGEMAKER MODEL ENDPOINT URL>",
      "request_body": "<YOUR REQUEST BODY. Example: ${parameters.inputs}>"
    }
  ]
}

----------------------------------------

TITLE: Inserting Vector and Keyword Data into OpenSearch Index
DESCRIPTION: This snippet shows how to insert documents containing both vector data and keyword data into the OpenSearch index using the bulk API.

LANGUAGE: json
CODE:
POST _bulk
{ "index": { "_index": "my-knn-index-2", "_id": "1" } }
{ "my_vector": [1, 1], "color" : "RED" }
{ "index": { "_index": "my-knn-index-2", "_id": "2" } }
{ "my_vector": [2, 2], "color" : "RED" }
{ "index": { "_index": "my-knn-index-2", "_id": "3" } }
{ "my_vector": [3, 3], "color" : "RED" }
{ "index": { "_index": "my-knn-index-2", "_id": "4" } }
{ "my_vector": [10, 10], "color" : "BLUE" }
{ "index": { "_index": "my-knn-index-2", "_id": "5" } }
{ "my_vector": [20, 20], "color" : "BLUE" }
{ "index": { "_index": "my-knn-index-2", "_id": "6" } }
{ "my_vector": [30, 30], "color" : "BLUE" }

----------------------------------------

TITLE: Bulk Indexing in OpenSearch
DESCRIPTION: This code shows how to perform bulk indexing in OpenSearch, inserting multiple documents with vector fields in a single request.

LANGUAGE: json
CODE:
POST _bulk
{ "index": { "_index": "test-index", "_id": "1" } }
{ "my_vector1": [1.5, 2.5], "price": 12.2 }
{ "index": { "_index": "test-index", "_id": "2" } }
{ "my_vector1": [2.5, 3.5], "price": 7.1 }

----------------------------------------

TITLE: Basic Boolean Query Structure in OpenSearch
DESCRIPTION: Shows the basic structure of a Boolean query with all possible clauses (must, must_not, should, filter).

LANGUAGE: json
CODE:
GET _search
{
  "query": {
    "bool": {
      "must": [
        {}
      ],
      "must_not": [
        {}
      ],
      "should": [
        {}
      ],
      "filter": {}
    }
  }
}

----------------------------------------

TITLE: Connecting to OpenSearch with SSL
DESCRIPTION: Create an OpenSearch client with SSL enabled, using default credentials for testing purposes. This configuration is suitable when using the Security plugin.

LANGUAGE: python
CODE:
host = 'localhost'
port = 9200
auth = ('admin', 'admin') # For testing only. Don't store credentials in code.
ca_certs_path = '/full/path/to/root-ca.pem' # Provide a CA bundle if you use intermediate CAs with your root CA.

# Create the client with SSL/TLS enabled, but hostname verification disabled.
client = OpenSearch(
    hosts = [{'host': host, 'port': port}],
    http_compress = True, # enables gzip compression for request bodies
    http_auth = auth,
    use_ssl = True,
    verify_certs = True,
    ssl_assert_hostname = False,
    ssl_show_warn = False,
    ca_certs = ca_certs_path
)

----------------------------------------

TITLE: Creating a Composable Index Template in OpenSearch
DESCRIPTION: This snippet shows how to create a composable index template that incorporates two component templates. It sets up patterns, aliases, settings, mappings, and includes metadata and versioning.

LANGUAGE: json
CODE:
PUT _index_template/daily_logs
{
  "index_patterns": [
    "logs-2020-01-*"
  ],
  "template": {
    "aliases": {
      "my_logs": {}
    },
    "settings": {
      "number_of_shards": 2,
      "number_of_replicas": 1
    },
    "mappings": {
      "properties": {
        "timestamp": {
          "type": "date",
          "format": "yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis"
        },
        "value": {
          "type": "double"
        }
      }
    }
  },
  "priority": 200,
  "composed_of": [
    "component_template_1",
    "component_template_2"
  ],
  "version": 3,
  "_meta": {
    "description": "using component templates"
  }
}

----------------------------------------

TITLE: Inner Join SQL Query Example
DESCRIPTION: Demonstrates an inner join between accounts and employees_nested tables matching on account_number and id fields

LANGUAGE: sql
CODE:
SELECT
  a.account_number, a.firstname, a.lastname,
  e.id, e.name
FROM accounts a
JOIN employees_nested e
 ON a.account_number = e.id

----------------------------------------

TITLE: JWT Payload Structure Example
DESCRIPTION: Example of a JWT payload containing standard claims including issuer, expiration, name, and roles.

LANGUAGE: json
CODE:
{
  "iss": "example.com",
  "exp": 1300819380,
  "name": "John Doe",
  "roles": "admin, devops"
}

----------------------------------------

TITLE: Defining Date Type in SQL for OpenSearch
DESCRIPTION: Specifies the syntax and range for the 'date' type in SQL for OpenSearch. The date type represents a calendar date without time zone information.

LANGUAGE: sql
CODE:
date | yyyy-MM-dd | 0001-01-01 to 9999-12-31

----------------------------------------

TITLE: Executing a RAGTool Agent in OpenSearch
DESCRIPTION: This snippet shows how to execute a previously registered RAGTool agent in OpenSearch. It includes a sample question parameter for the agent to process.

LANGUAGE: json
CODE:
POST /_plugins/_ml/agents/9X7xWI0Bpc3sThaJdY9i/_execute
{
  "parameters": {
    "question": "what's the population increase of Seattle from 2021 to 2023"
  }
}

----------------------------------------

TITLE: PPL Query Explain Request
DESCRIPTION: Example of using the explain API with a PPL query to show execution details.

LANGUAGE: json
CODE:
{
  "query" : "source=accounts | fields firstname, lastname"
}

----------------------------------------

TITLE: Searching for OpenSearch Helm Charts
DESCRIPTION: Command to search for OpenSearch-related Helm charts in the repository.

LANGUAGE: bash
CODE:
helm search repo opensearch

----------------------------------------

TITLE: Performing RAG Search with DeepSeek-R1 Model
DESCRIPTION: JSON request to perform a vector search and use the DeepSeek-R1 model for RAG, comparing population trends between New York City and Miami.

LANGUAGE: json
CODE:
GET /my-nlp-index/_search?search_pipeline=my-conversation-search-pipeline-deepseek
{
  "query": {
    "neural": {
      "passage_embedding": {
        "query_text": "What's the population increase of New York City from 2021 to 2023? How is the trending comparing with Miami?",
        "model_id": "heS7s5QBFSAM-Wczv7Kb",
        "k": 5
      }
    }
  },
  "size": 2,
  "_source": [
    "text"
  ],
  "ext": {
    "generative_qa_parameters": {
      "llm_model": "bedrock/claude",
      "llm_question": "What's the population increase of New York City from 2021 to 2023? How is the trending comparing with Miami?",
      "context_size": 5,
      "timeout": 15
    }
  }
}

----------------------------------------

TITLE: Creating RAG Search Pipeline
DESCRIPTION: Configures a search pipeline with a RAG processor for conversational search functionality.

LANGUAGE: json
CODE:
PUT /_search/pipeline/my-conversation-search-pipeline-cohere
{
  "response_processors": [
    {
      "retrieval_augmented_generation": {
        "tag": "Demo pipeline",
        "description": "Demo pipeline Using Cohere",
        "model_id": "your_model_id_created_in_step1",
        "context_field_list": [
          "text"
        ],
        "system_prompt": "You are a helpful assistant",
        "user_instructions": "Generate a concise and informative answer in less than 100 words for the given question"
      }
    }
  ]
}

----------------------------------------

TITLE: Complete OpenSearch JavaScript Client Sample Program
DESCRIPTION: A comprehensive JavaScript program demonstrating various operations with the OpenSearch client, including creating an index, adding a document, searching, updating, deleting a document, and deleting the index.

LANGUAGE: javascript
CODE:
"use strict";

var host = "localhost";
var protocol = "https";
var port = 9200;
var auth = "admin:<custom-admin-password>";
var ca_certs_path = "/full/path/to/root-ca.pem";

var { Client } = require("@opensearch-project/opensearch");
var fs = require("fs");
var client = new Client({
  node: protocol + "://" + auth + "@" + host + ":" + port,
  ssl: {
    ca: fs.readFileSync(ca_certs_path),
  },
});

async function search() {
  var index_name = "books";
  
  var settings = {
    settings: {
      index: {
        number_of_shards: 4,
        number_of_replicas: 3,
      },
    },
  };

  var response = await client.indices.create({
    index: index_name,
    body: settings,
  });

  console.log("Creating index:");
  console.log(response.body);

  var document = {
    title: "The Outsider",
    author: "Stephen King",
    year: "2018",
    genre: "Crime fiction",
  };

  var id = "1";

  var response = await client.index({
    id: id,
    index: index_name,
    body: document,
    refresh: true,
  });

  console.log("Adding document:");
  console.log(response.body);

  var query = {
    query: {
      match: {
        title: {
          query: "The Outsider",
        },
      },
    },
  };

  var response = await client.search({
    index: index_name,
    body: query,
  });

  console.log("Search results:");
  console.log(JSON.stringify(response.body.hits, null, "  "));

  var response = await client.update({
    index: index_name,
    id: id,
    body: {
      doc: {
        genre: "Detective fiction",
        tv_adapted: true
      }
    },
    refresh: true
  });

  var query = {
    query: {
      match: {
        title: {
          query: "The Outsider",
        },
      },
    },
  };

  var response = await client.search({
    index: index_name,
    body: query,
  });

  console.log("Search results:");
  console.log(JSON.stringify(response.body.hits, null, "  "));

  var response = await client.delete({
    index: index_name,
    id: id,
  });

  console.log("Deleting document:");
  console.log(response.body);

  var response = await client.indices.delete({
    index: index_name,
  });

  console.log("Deleting index:");
  console.log(response.body);
}

search().catch(console.log);

----------------------------------------

TITLE: Configuring Client Certificate Authentication in config.yml
DESCRIPTION: Configuration block for enabling client certificate authentication in the config.yml file, specifying the authentication domain, HTTP authenticator, and authentication backend.

LANGUAGE: yaml
CODE:
clientcert_auth_domain:
  description: "Authenticate via SSL client certificates"
  http_enabled: true
  transport_enabled: true
  order: 1
  http_authenticator:
    type: clientcert
    config:
      username_attribute: cn #optional, if omitted DN becomes username
    challenge: false
  authentication_backend:
    type: noop

----------------------------------------

TITLE: Adding Hotel Data to Vector Index in OpenSearch
DESCRIPTION: Adds sample hotel data to the 'hotels-index' using bulk indexing. Each document represents a hotel with a 2D vector location.

LANGUAGE: json
CODE:
POST /_bulk
{ "index": { "_index": "hotels-index", "_id": "1" } }
{ "location": [5.2, 4.4] }
{ "index": { "_index": "hotels-index", "_id": "2" } }
{ "location": [5.2, 3.9] }
{ "index": { "_index": "hotels-index", "_id": "3" } }
{ "location": [4.9, 3.4] }
{ "index": { "_index": "hotels-index", "_id": "4" } }
{ "location": [4.2, 4.6] }
{ "index": { "_index": "hotels-index", "_id": "5" } }
{ "location": [3.3, 4.5] }

----------------------------------------

TITLE: Creating a Vector Index in OpenSearch
DESCRIPTION: Creates an index named 'hotels-index' with vector search capabilities. The index is configured to store 2D vectors in the 'location' field using the Euclidean (l2) similarity metric.

LANGUAGE: json
CODE:
PUT /hotels-index
{
  "settings": {
    "index.knn": true
  },
  "mappings": {
    "properties": {
      "location": {
        "type": "knn_vector",
        "dimension": 2,
        "space_type": "l2"
      }
    }
  }
}

----------------------------------------

TITLE: HNSW Method Definition with Faiss Engine
DESCRIPTION: Example of configuring an HNSW method using the Faiss engine with L2 space type and custom parameters for vector search indexing.

LANGUAGE: json
CODE:
PUT test-index
{
  "settings": {
    "index": {
      "knn": true,
      "knn.algo_param.ef_search": 100
    }
  },
  "mappings": {
    "properties": {
      "my_vector1": {
        "type": "knn_vector",
        "dimension": 1024,
        "method": {
          "name": "hnsw",
          "space_type": "l2",
          "engine": "faiss",
          "parameters": {
            "ef_construction": 128,
            "m": 24
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating an Ingest Pipeline for Text Embedding in OpenSearch
DESCRIPTION: This request creates an ingest pipeline with a text_embedding processor to generate vector embeddings from text during document ingestion.

LANGUAGE: json
CODE:
PUT /_ingest/pipeline/nlp-ingest-pipeline
{
  "description": "An NLP ingest pipeline",
  "processors": [
    {
      "text_embedding": {
        "model_id": "aVeif4oB5Vm0Tdw8zYO2",
        "field_map": {
          "text": "passage_embedding"
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Registering a Conversational Agent with ReAct Capabilities in OpenSearch
DESCRIPTION: This snippet demonstrates how to register a conversational agent with ReAct capabilities. It configures an LLM with VectorDBTool and CATIndexTool, allowing the agent to reason and decide which tool to use for answering questions.

LANGUAGE: json
CODE:
{
  "name": "Test_Agent_For_ReAct_ClaudeV2",
  "type": "conversational",
  "description": "this is a test agent",
  "llm": {
    "model_id": "YOUR_LLM_MODEL_ID",
    "parameters": {
      "max_iteration": 5,
      "stop_when_no_tool_found": true,
      "response_filter": "$.completion"
    }
  },
  "memory": {
    "type": "conversation_index"
  },
  "tools": [
    {
      "type": "VectorDBTool",
      "name": "VectorDBTool",
      "description": "A tool to search opensearch index with natural language question. If you don't know answer for some question, you should always try to search data with this tool. Action Input: <natural language question>",
      "parameters": {
        "model_id": "YOUR_TEXT_EMBEDDING_MODEL_ID",
        "index": "my_test_data",
        "embedding_field": "embedding",
        "source_field": [ "text" ],
        "input": "${parameters.question}"
      }
    },
    {
      "type": "CatIndexTool",
      "name": "RetrieveIndexMetaTool",
      "description": "Use this tool to get OpenSearch index information: (health, status, index, uuid, primary count, replica count, docs.count, docs.deleted, store.size, primary.store.size)."
    }
  ],
  "app_type": "my app"
}

----------------------------------------

TITLE: Warming Up OpenSearch K-NN Indexes
DESCRIPTION: Demonstrates how to use the warmup API operation to preload native library indexes into memory cache for multiple indices. This operation helps avoid initial search latency by loading all native library indexes for all shards into cache before performing searches.

LANGUAGE: json
CODE:
GET /_plugins/_knn/warmup/index1,index2,index3?pretty
{
    "_shards" : {
    "total" : 6,
    "successful" : 6,
    "failed" : 0
    }
}

----------------------------------------

TITLE: Using the RAG Pipeline for Querying
DESCRIPTION: This request demonstrates how to use the RAG pipeline to query the index and get a response from the LLM.

LANGUAGE: json
CODE:
GET /my_rag_test_data/_search
{
  "query": {
    "match": {
      "text": "What's the population of NYC metro area in 2023"
    }
  },
  "ext": {
    "generative_qa_parameters": {
      "llm_model": "gpt-3.5-turbo",
      "llm_question": "What's the population of NYC metro area in 2023",
      "memory_id": "znCqcI0BfUsSoeNTntd7",
      "context_size": 5,
      "message_size": 5,
      "timeout": 15
    }
  }
}

----------------------------------------

TITLE: Creating Hybrid Search Workflow
DESCRIPTION: Creates a workflow that automatically sets up an ingest pipeline, index, and search pipeline for hybrid search

LANGUAGE: json
CODE:
POST /_plugins/_flow_framework/workflow?use_case=hybrid_search&provision=true
{
"create_ingest_pipeline.model_id": "mBGzipQB2gmRjlv_dOoB"
}

----------------------------------------

TITLE: Sample Java Program Using OpenSearch High-Level REST Client
DESCRIPTION: This comprehensive Java example demonstrates how to use the OpenSearch high-level REST client. It covers creating a secure connection, creating an index with custom settings, adding data, retrieving documents, and deleting both documents and indexes.

LANGUAGE: java
CODE:
import org.apache.http.HttpHost;
import org.apache.http.auth.AuthScope;
import org.apache.http.auth.UsernamePasswordCredentials;
import org.apache.http.client.CredentialsProvider;
import org.apache.http.impl.client.BasicCredentialsProvider;
import org.apache.http.impl.nio.client.HttpAsyncClientBuilder;
import org.opensearch.action.admin.indices.delete.DeleteIndexRequest;
import org.opensearch.action.delete.DeleteRequest;
import org.opensearch.action.delete.DeleteResponse;
import org.opensearch.action.get.GetRequest;
import org.opensearch.action.get.GetResponse;
import org.opensearch.action.index.IndexRequest;
import org.opensearch.action.index.IndexResponse;
import org.opensearch.action.support.master.AcknowledgedResponse;
import org.opensearch.client.RequestOptions;
import org.opensearch.client.RestClient;
import org.opensearch.client.RestClientBuilder;
import org.opensearch.client.RestHighLevelClient;
import org.opensearch.client.indices.CreateIndexRequest;
import org.opensearch.client.indices.CreateIndexResponse;
import org.opensearch.common.settings.Settings;

import java.io.IOException;
import java.util.HashMap;

public class RESTClientSample {

  public static void main(String[] args) throws IOException {

    //Point to keystore with appropriate certificates for security.
    System.setProperty("javax.net.ssl.trustStore", "/full/path/to/keystore");
    System.setProperty("javax.net.ssl.trustStorePassword", "password-to-keystore");

    //Establish credentials to use basic authentication.
    //Only for demo purposes. Don't specify your credentials in code.
    final CredentialsProvider credentialsProvider = new BasicCredentialsProvider();

    credentialsProvider.setCredentials(AuthScope.ANY,
      new UsernamePasswordCredentials("admin", "admin"));

    //Create a client.
    RestClientBuilder builder = RestClient.builder(new HttpHost("localhost", 9200, "https"))
      .setHttpClientConfigCallback(new RestClientBuilder.HttpClientConfigCallback() {
        @Override
        public HttpAsyncClientBuilder customizeHttpClient(HttpAsyncClientBuilder httpClientBuilder) {
          return httpClientBuilder.setDefaultCredentialsProvider(credentialsProvider);
            }
          });
    RestHighLevelClient client = new RestHighLevelClient(builder);

    //Create a non-default index with custom settings and mappings.
    CreateIndexRequest createIndexRequest = new CreateIndexRequest("custom-index");

    createIndexRequest.settings(Settings.builder() //Specify in the settings how many shards you want in the index.
      .put("index.number_of_shards", 4)
      .put("index.number_of_replicas", 3)
      );
    //Create a set of maps for the index's mappings.
    HashMap<String, String> typeMapping = new HashMap<String,String>();
    typeMapping.put("type", "integer");
    HashMap<String, Object> ageMapping = new HashMap<String, Object>();
    ageMapping.put("age", typeMapping);
    HashMap<String, Object> mapping = new HashMap<String, Object>();
    mapping.put("properties", ageMapping);
    createIndexRequest.mapping(mapping);
    CreateIndexResponse createIndexResponse = client.indices().create(createIndexRequest, RequestOptions.DEFAULT);

    //Adding data to the index.
    IndexRequest request = new IndexRequest("custom-index"); //Add a document to the custom-index we created.
    request.id("1"); //Assign an ID to the document.

    HashMap<String, String> stringMapping = new HashMap<String, String>();
    stringMapping.put("message:", "Testing Java REST client");
    request.source(stringMapping); //Place your content into the index's source.
    IndexResponse indexResponse = client.index(request, RequestOptions.DEFAULT);

    //Getting back the document
    GetRequest getRequest = new GetRequest("custom-index", "1");
    GetResponse response = client.get(getRequest, RequestOptions.DEFAULT);

    System.out.println(response.getSourceAsString());

    //Delete the document
    DeleteRequest deleteDocumentRequest = new DeleteRequest("custom-index", "1"); //Index name followed by the ID.
    DeleteResponse deleteResponse = client.delete(deleteDocumentRequest, RequestOptions.DEFAULT);

    //Delete the index
    DeleteIndexRequest deleteIndexRequest = new DeleteIndexRequest("custom-index"); //Index name.
    AcknowledgedResponse deleteIndexResponse = client.indices().delete(deleteIndexRequest, RequestOptions.DEFAULT);

    client.close();
  }
}

----------------------------------------

TITLE: Creating Reranking Pipeline with Cohere Rerank in OpenSearch
DESCRIPTION: Creates a reranking pipeline that uses the previously registered Cohere Rerank model to rerank search results.

LANGUAGE: json
CODE:
PUT /_search/pipeline/rerank_pipeline_cohere
{
    "description": "Pipeline for reranking with Cohere Rerank model",
    "response_processors": [
        {
            "rerank": {
                "ml_opensearch": {
                    "model_id": "your_model_id_created_in_step1"
                },
                "context": {
                    "document_fields": ["passage_text"]
                }
            }
        }
    ]
}

----------------------------------------

TITLE: Creating an Index with knn_vector Fields in OpenSearch
DESCRIPTION: This snippet demonstrates how to create an index with two knn_vector fields in OpenSearch. It sets up the mappings for vector search capabilities.

LANGUAGE: json
CODE:
PUT my-knn-index-1
{
  "mappings": {
    "properties": {
      "my_vector1": {
        "type": "knn_vector",
        "dimension": 2
      },
      "my_vector2": {
        "type": "knn_vector",
        "dimension": 4
      }
    }
  }
}

----------------------------------------

TITLE: Setting IAM Role Permissions for Connector Requests
DESCRIPTION: JSON policy granting permissions to pass roles and make API requests to Amazon OpenSearch Service.

LANGUAGE: json
CODE:
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": "iam:PassRole",
      "Resource": "your_iam_role_arn_created_in_step1"
    },
    {
      "Effect": "Allow",
      "Action": "es:ESHttpPost",
      "Resource": "your_opensearch_domain_arn"
    }
  ]
}

----------------------------------------

TITLE: Creating K-means Clustering Model in OpenSearch
DESCRIPTION: Example of using the OpenSearch API to train a k-means clustering model on the Iris dataset.

LANGUAGE: JSON
CODE:
POST /_plugins/_ml/_train/kmeans
{
    "parameters": {
        "centroids": 3,
        "iterations": 10,
        "distance_type": "COSINE"
    },
    "input_query": {
        "_source": ["petal_length_in_cm", "petal_width_in_cm"],
        "size": 10000
    },
    "input_index": [
        "iris_data"
    ]
}

----------------------------------------

TITLE: Multiple Filter Constructions for k-NN Search in OpenSearch
DESCRIPTION: This snippet demonstrates various ways to construct filters for the same condition in a k-NN search, including term, wildcard, regexp, and must_not clauses.

LANGUAGE: json
CODE:
POST /hotels-index/_search
{
  "size": 3,
  "query": {
    "knn": {
      "location": {
        "vector": [ 5.0, 4.0 ],
        "k": 3,
        "filter": {
          "bool": {
            "must": {
              "range": {
                "rating": {
                  "gte": 1,
                  "lte": 6
                }
              }
            },
            "should": [
            {
              "term": {
                "parking": "true"
              }
            },
            {
              "wildcard": {
                "parking": {
                  "value": "t*e"
                }
              }
            },
            {
              "regexp": {
                "parking": "[a-zA-Z]rue"
              }
            }
            ],
            "must_not": [
            {
              "term": {
                  "parking": "false"
              }
            }
            ],
            "minimum_should_match": 1
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Enabling Assistant Features in YAML
DESCRIPTION: YAML configuration settings to enable the chat assistant and query assist features in OpenSearch Assistant.

LANGUAGE: yaml
CODE:
assistant.chat.enabled: true
observability.query_assist.enabled: true

----------------------------------------

TITLE: Bulk Indexing with Pipeline in OpenSearch
DESCRIPTION: Demonstrates bulk document indexing using the created pipeline for batch processing.

LANGUAGE: json
CODE:
POST _bulk?batch_size=5&pipeline=nlp-ingest-pipeline
{ "create": { "_index": "testindex1", "_id": "2" } }
{ "passage_text": "hello world" }
{ "create": { "_index": "testindex1", "_id": "3" } }
{ "passage_text": "big apple" }
{ "create": { "_index": "testindex1", "_id": "4" } }
{ "passage_text": "golden gate bridge" }
{ "create": { "_index": "testindex1", "_id": "5" } }
{ "passage_text": "fine tune" }
{ "create": { "_index": "testindex1", "_id": "6" } }
{ "passage_text": "random test" }
{ "create": { "_index": "testindex1", "_id": "7" } }
{ "passage_text": "sun and moon" }
{ "create": { "_index": "testindex1", "_id": "8" } }
{ "passage_text": "windy" }
{ "create": { "_index": "testindex1", "_id": "9" } }
{ "passage_text": "new york" }
{ "create": { "_index": "testindex1", "_id": "10" } }
{ "passage_text": "fantastic" }


----------------------------------------

TITLE: Creating ISM Policy with Auto-attachment Template in OpenSearch
DESCRIPTION: JSON configuration for creating an ISM policy that automatically attaches to indexes matching a specific pattern. The policy includes template patterns and priority settings for automatic application.

LANGUAGE: json
CODE:
PUT _plugins/_ism/policies/policy_id
{
  "policy": {
    "description": "Example policy.",
    "default_state": "...",
    "states": [...],
    "ism_template": {
      "index_patterns": ["index_name-*"],
      "priority": 100
    }
  }
}

----------------------------------------

TITLE: Updating ML-related Cluster Settings in OpenSearch
DESCRIPTION: This request updates cluster settings to enable a basic local setup for running ML models without dedicated ML nodes.

LANGUAGE: json
CODE:
PUT _cluster/settings
{
  "persistent": {
    "plugins.ml_commons.only_run_on_ml_node": "false",
    "plugins.ml_commons.model_access_control_enabled": "true",
    "plugins.ml_commons.native_memory_threshold": "99"
  }
}

----------------------------------------

TITLE: Creating Basic Search Pipeline in OpenSearch
DESCRIPTION: Creates a search pipeline with a filter_query request processor to filter public messages and a response processor to rename fields.

LANGUAGE: json
CODE:
PUT /_search/pipeline/my_pipeline 
{
  "request_processors": [
    {
      "filter_query" : {
        "tag" : "tag1",
        "description" : "This processor is going to restrict to publicly visible documents",
        "query" : {
          "term": {
            "visibility": "public"
          }
        }
      }
    }
  ],
  "response_processors": [
    {
      "rename_field": {
        "field": "message",
        "target_field": "notification"
      }
    }
  ]
}

----------------------------------------

TITLE: Creating an Index with Dynamic Template for String Fields in OpenSearch
DESCRIPTION: This snippet demonstrates how to create an index named 'movies1' with a dynamic template. The template maps all string fields to both 'text' and 'keyword' types, allowing for full-text search and aggregations on the same field.

LANGUAGE: json
CODE:
PUT movies1
{
  "mappings": {
    "dynamic_templates": [
      {
        "strings": {
          "match_mapping_type": "string",
          "mapping": {
            "type": "text",
            "fields": {
              "keyword": {
                "type":  "keyword",
                "ignore_above": 256
              }
            }
          }
        }
      }
    ]
  }
}

----------------------------------------

TITLE: Installing OpenSearch JavaScript Client
DESCRIPTION: Instructions for installing the OpenSearch JavaScript client using npm. Includes commands for installing the latest version or a specific major version.

LANGUAGE: bash
CODE:
npm install @opensearch-project/opensearch

LANGUAGE: bash
CODE:
npm install @opensearch-project/opensearch@<version>

----------------------------------------

TITLE: Performance Degradation Control Settings
DESCRIPTION: Settings that define thresholds and factors for monitoring and controlling performance degradation. Includes parameters for request sampling, degradation detection, and request management.

LANGUAGE: yaml
CODE:
shard_indexing_pressure.secondary_parameter.throughput.request_size_window: 2000
shard_indexing_pressure.secondary_parameter.throughput.degradation_factor: 5
shard_indexing_pressure.secondary_parameter.successful_request.elapsed_timeout: 300000
shard_indexing_pressure.secondary_parameter.successful_request.max_outstanding_requests: 100

----------------------------------------

TITLE: Completion Suggester Query in OpenSearch
DESCRIPTION: Illustrates how to use the completion suggester for autocomplete. This method uses a finite-state transducer (FST) data structure for fast prefix lookups.

LANGUAGE: json
CODE:
GET shakespeare/_search
{
  "suggest": {
    "autocomplete": {
      "prefix": "To be",
      "completion": {
        "field": "text_entry"
      }
    }
  }
}

----------------------------------------

TITLE: Register Pretrained Text Embedding Model
DESCRIPTION: Example request to register a pretrained text embedding model from Hugging Face with required name, version and model format parameters.

LANGUAGE: json
CODE:
POST /_plugins/_ml/models/_register
{
  "name": "huggingface/sentence-transformers/msmarco-distilbert-base-tas-b",
  "version": "1.0.1",
  "model_group_id": "Z1eQf4oB5Vm0Tdw8EIP2",
  "model_format": "TORCH_SCRIPT"
}

----------------------------------------

TITLE: Creating a Semantic Search Workflow in OpenSearch
DESCRIPTION: This request creates and provisions a semantic search workflow using automated workflows, specifying the model ID and custom parameters.

LANGUAGE: json
CODE:
POST /_plugins/_flow_framework/workflow?use_case=semantic_search&provision=true
{
    "create_ingest_pipeline.model_id" : "mBGzipQB2gmRjlv_dOoB",
    "text_embedding.field_map.output.dimension": "768",
    "text_embedding.field_map.input": "text"
}

----------------------------------------

TITLE: Creating a Standalone Amazon SageMaker Connector in OpenSearch
DESCRIPTION: Example request to create a standalone Amazon SageMaker connector using the _plugins/_ml/connectors/_create endpoint. This connector uses AWS SigV4 authentication to access a SageMaker endpoint for embedding models.

LANGUAGE: json
CODE:
POST /_plugins/_ml/connectors/_create
{
    "name": "sagemaker: embedding",
    "description": "Test connector for Sagemaker embedding model",
    "version": 1,
    "protocol": "aws_sigv4",
    "credential": {
        "access_key": "...",
        "secret_key": "...",
        "session_token": "..."
    },
    "parameters": {
        "region": "us-west-2",
        "service_name": "sagemaker"
    },
    "actions": [
        {
            "action_type": "predict",
            "method": "POST",
            "headers": {
                "content-type": "application/json"
            },
            "url": "https://runtime.sagemaker.${parameters.region}.amazonaws.com/endpoints/lmi-model-2023-06-24-01-35-32-275/invocations",
            "request_body": "[\"${parameters.inputs}\"]"
        }
    ]
}

----------------------------------------

TITLE: Creating or Updating an Index Rollup Job in OpenSearch
DESCRIPTION: This snippet demonstrates how to create or update an index rollup job using a PUT request. It includes various configuration options such as source and target indices, scheduling, dimensions, and metrics.

LANGUAGE: json
CODE:
PUT _plugins/_rollup/jobs/<rollup_id> // Create
PUT _plugins/_rollup/jobs/<rollup_id>?if_seq_no=1&if_primary_term=1 // Update
{
  "rollup": {
    "source_index": "nyc-taxi-data",
    "target_index": "rollup-nyc-taxi-data",
    "target_index_settings":{
      "index.number_of_shards": 1,
      "index.number_of_replicas": 1,
      "index.codec": "best_compression"
    },
    "schedule": {
      "interval": {
        "period": 1,
        "unit": "Days"
      }
    },
    "description": "Example rollup job",
    "enabled": true,
    "page_size": 200,
    "delay": 0,
    "roles": [
      "rollup_all",
      "nyc_taxi_all",
      "example_rollup_index_all"
    ],
    "continuous": false,
    "dimensions": [
      {
        "date_histogram": {
          "source_field": "tpep_pickup_datetime",
          "fixed_interval": "1h",
          "timezone": "America/Los_Angeles"
        }
      },
      {
        "terms": {
          "source_field": "PULocationID"
        }
      }
    ],
    "metrics": [
      {
        "source_field": "passenger_count",
        "metrics": [
          {
            "avg": {}
          },
          {
            "sum": {}
          },
          {
            "max": {}
          },
          {
            "min": {}
          },
          {
            "value_count": {}
          }
        ]
      }
    ]
  }
}

----------------------------------------

TITLE: Configuring Hybrid Query Pagination in OpenSearch
DESCRIPTION: This snippet demonstrates how to configure a hybrid query with pagination using the pagination_depth, from, and size parameters. It retrieves up to 10 search results per shard for both bool and term queries before applying pagination.

LANGUAGE: json
CODE:
GET /my-nlp-index/_search?search_pipeline=nlp-search-pipeline
{
  "size": 5,      
  "query": {
    "hybrid": {
      "pagination_depth":10,  
      "queries": [
        {
          "term": {
            "category": "permission"
          }
        },
        {
          "bool": {
            "should": [
              {
                "term": {
                  "category": "editor"
                }
              },
              {
                "term": {
                  "category": "statement"
                }
              }
            ]
          }
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Testing Embedding Model in OpenSearch
DESCRIPTION: Tests a registered Amazon Titan Text Embeddings model by generating embeddings for sample text.

LANGUAGE: json
CODE:
POST /_plugins/_ml/models/your_embedding_model_id/_predict
{
    "parameters": {
        "inputText": "hello world"
    }
}

----------------------------------------

TITLE: Basic Search Highlighting Query
DESCRIPTION: Example of a basic search query with highlighting enabled for text matches

LANGUAGE: json
CODE:
{
  "query": {
    "match": {
      "text_entry": "life"
    }
  },
  "size": 3,
  "highlight": {
    "fields": {
      "text_entry": {}
    }
  }
}

----------------------------------------

TITLE: Configuring Remote-backed Storage in OpenSearch YAML
DESCRIPTION: YAML configuration example showing how to set up remote-backed storage repositories for segments and translog in opensearch.yml. Includes settings for repository names, types, bucket names, paths and regions.

LANGUAGE: yaml
CODE:
# Repository name
node.attr.remote_store.segment.repository: my-repo-1
node.attr.remote_store.translog.repository: my-repo-2

# Segment repository settings
node.attr.remote_store.repository.my-repo-1.type: s3
node.attr.remote_store.repository.my-repo-1.settings.bucket: <Bucket Name 1>
node.attr.remote_store.repository.my-repo-1.settings.base_path: <Bucket Base Path 1>
node.attr.remote_store.repository.my-repo-1.settings.region: us-east-1

# Translog repository settings
node.attr.remote_store.repository.my-repo-2.type: s3
node.attr.remote_store.repository.my-repo-2.settings.bucket: <Bucket Name 2>
node.attr.remote_store.repository.my-repo-2.settings.base_path: <Bucket Base Path 2>
node.attr.remote_store.repository.my-repo-2.settings.region: us-east-1

----------------------------------------

TITLE: Edge N-Gram Analyzer Configuration in OpenSearch
DESCRIPTION: Shows how to configure an edge n-gram analyzer for autocomplete. This method splits words into a sequence of n characters during indexing to support faster lookup of partial search terms.

LANGUAGE: json
CODE:
PUT shakespeare
{
  "mappings": {
    "properties": {
      "text_entry": {
        "type": "text",
        "analyzer": "autocomplete"
      }
    }
  },
  "settings": {
    "analysis": {
      "filter": {
        "edge_ngram_filter": {
          "type": "edge_ngram",
          "min_gram": 1,
          "max_gram": 20
        }
      },
      "analyzer": {
        "autocomplete": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "edge_ngram_filter"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Defining ML Inference Processor Syntax
DESCRIPTION: Base syntax structure for configuring the ml_inference search request processor with all possible parameters.

LANGUAGE: json
CODE:
{
  "ml_inference": {
    "model_id": "<model_id>",
    "function_name": "<function_name>",
    "full_response_path": "<full_response_path>",
    "query_template": "<query_template>",
    "model_config": {
      "<model_config_field>": "<config_value>"
    },
    "model_input": "<model_input>",
    "input_map": [
      {
        "<model_input_field>": "<query_input_field>"
      }
    ],
    "output_map": [
      {
        "<query_output_field>": "<model_output_field>"
      }
    ]
  }
}

----------------------------------------

TITLE: Creating a search pipeline for neural sparse search
DESCRIPTION: Defines a search pipeline that includes processors for accelerating neural sparse search and setting default model IDs.

LANGUAGE: json
CODE:
PUT /_search/pipeline/neural_search_pipeline
{
  "request_processors": [
    {
      "neural_sparse_two_phase_processor": {
        "tag": "neural-sparse",
        "description": "Creates a two-phase processor for neural sparse search."
      }
    },
    {
      "neural_query_enricher" : {
        "default_model_id": "<model ID>"
      }
    }
  ]
}

----------------------------------------

TITLE: Creating an Index for Tech News with KNN Vector Mapping
DESCRIPTION: Sets up an OpenSearch index named 'test_tech_news' with KNN vector mapping for passage embeddings and configures the default pipeline.

LANGUAGE: json
CODE:
PUT test_tech_news
{
  "mappings": {
    "properties": {
      "passage": {
        "type": "text"
      },
      "passage_embedding": {
        "type": "knn_vector",
        "dimension": 384
      }
    }
  },
  "settings": {
    "index": {
      "knn.space_type": "cosinesimil",
      "default_pipeline": "test_tech_news_pipeline",
      "knn": "true"
    }
  }
}

----------------------------------------

TITLE: Ingesting Document with Text Chunking Pipeline in OpenSearch
DESCRIPTION: This snippet demonstrates how to ingest a document into the vector index using the text chunking and embedding pipeline. It sends a POST request with the document content to be processed.

LANGUAGE: json
CODE:
POST testindex/_doc?pipeline=text-chunking-embedding-ingest-pipeline
{
  "passage_text": "This is an example document to be chunked. The document contains a single paragraph, two sentences and 24 tokens by standard tokenizer in OpenSearch."
}

----------------------------------------

TITLE: Pipeline Test Response
DESCRIPTION: Example response showing the generated vector embeddings alongside the original text input.

LANGUAGE: json
CODE:
{
  "docs": [
    {
      "doc": {
        "_index": "testindex1",
        "_id": "1",
        "_source": {
          "passage_embedding": [
            -0.048237972,
            -0.07612712,
            0.3262124,
            ...
            -0.16352308
          ],
          "passage_text": "hello world"
        },
        "_ingest": {
          "timestamp": "2023-10-05T15:15:19.691345393Z"
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Connecting to Amazon OpenSearch Service
DESCRIPTION: Establishes connection to Amazon OpenSearch Service using AWS credentials and request signing

LANGUAGE: go
CODE:
package main

import (
	"context"
	"log"

	"github.com/aws/aws-sdk-go-v4/aws"
	"github.com/aws/aws-sdk-go-v4/config"
	opensearch "github.com/opensearch-project/opensearch-go/v4"
	opensearchapi "github.com/opensearch-project/opensearch-go/v4@v4.3.0/opensearchapi"
	requestsigner "github.com/opensearch-project/opensearch-go/v4@v4.3.0/signer/awsv2"
)

const endpoint = ""

func main() {
	ctx := context.Background()

	awsCfg, err := config.LoadDefaultConfig(ctx,
		config.WithRegion("<AWS_REGION>"),
		config.WithCredentialsProvider(
			getCredentialProvider("<AWS_ACCESS_KEY>", "<AWS_SECRET_ACCESS_KEY>", "<AWS_SESSION_TOKEN>"),
		),
	)
	if err != nil {
		log.Fatal(err)
	}

	signer, err := requestsigner.NewSignerWithService(awsCfg, "es")
	if err != nil {
		log.Fatal(err)
	}

	client, err := opensearch.NewClient(opensearch.Config{
		Addresses: []string{endpoint},
		Signer:    signer,
	})
	if err != nil {
		log.Fatal("client creation err", err)
	}
}

func getCredentialProvider(accessKey, secretAccessKey, token string) aws.CredentialsProviderFunc {
	return func(ctx context.Context) (aws.Credentials, error) {
		c := &aws.Credentials{
			AccessKeyID:     accessKey,
			SecretAccessKey: secretAccessKey,
			SessionToken:    token,
		}
		return *c, nil
	}
}

----------------------------------------

TITLE: Creating a Search Pipeline with RAG Processor in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a search pipeline containing a retrieval_augmented_generation processor for an OpenAI model. It specifies the model ID, context fields, system prompt, and user instructions.

LANGUAGE: json
CODE:
PUT /_search/pipeline/rag_pipeline
{
  "response_processors": [
    {
      "retrieval_augmented_generation": {
        "tag": "openai_pipeline_demo",
        "description": "Demo pipeline Using OpenAI Connector",
        "model_id": "gnDIbI0BfUsSoeNT_jAw",
        "context_field_list": ["text"],
        "system_prompt": "You are a helpful assistant",
        "user_instructions": "Generate a concise and informative answer in less than 100 words for the given question"
      }
    }
  ]
}

----------------------------------------

TITLE: Generating Root Certificate for OpenSearch
DESCRIPTION: Generate a self-signed root certificate for OpenSearch TLS configuration.

LANGUAGE: bash
CODE:
sudo openssl genrsa -out root-ca-key.pem 2048
sudo openssl req -new -x509 -sha256 -key root-ca-key.pem -subj "/C=CA/ST=ONTARIO/L=TORONTO/O=ORG/OU=UNIT/CN=ROOT" -out root-ca.pem -days 730

----------------------------------------

TITLE: Creating Vector Index for Radial Search in OpenSearch
DESCRIPTION: Creates an OpenSearch index with KNN vector capabilities using the FAISS engine. Configures a 2-dimensional vector field with L2 space type and HNSW method parameters.

LANGUAGE: json
CODE:
PUT knn-index-test
{
  "settings": {
    "number_of_shards": 1,
    "number_of_replicas": 1,
    "index.knn": true
  },
  "mappings": {
    "properties": {
      "my_vector": {
        "type": "knn_vector",
        "dimension": 2,
        "space_type": "l2",
        "method": {
            "name": "hnsw",
            "engine": "faiss",
            "parameters": {
              "ef_construction": 100,
              "m": 16,
              "ef_search": 100
            }
          }
      }
    }
  }
}

----------------------------------------

TITLE: Creating a Connector for OpenAI GPT 3.5 Model
DESCRIPTION: This request creates a connector for the OpenAI GPT 3.5 model, which is required for RAG functionality.

LANGUAGE: json
CODE:
POST /_plugins/_ml/connectors/_create
{
  "name": "OpenAI Chat Connector",
  "description": "The connector to public OpenAI model service for GPT 3.5",
  "version": 2,
  "protocol": "http",
  "parameters": {
    "endpoint": "api.openai.com",
    "model": "gpt-3.5-turbo",
    "temperature": 0
  },
  "credential": {
    "openAI_key": "<YOUR_OPENAI_KEY>"
  },
  "actions": [
    {
      "action_type": "predict",
      "method": "POST",
      "url": "https://${parameters.endpoint}/v1/chat/completions",
      "headers": {
        "Authorization": "Bearer ${credential.openAI_key}"
      },
      "request_body": "{ \"model\": \"${parameters.model}\", \"messages\": ${parameters.messages}, \"temperature\": ${parameters.temperature} }"
    }
  ]
}

----------------------------------------

TITLE: Configuring Trace-Based Anomaly Detection Pipeline in OpenSearch
DESCRIPTION: Pipeline configuration that processes OpenTelemetry traces, converts them to metrics, and performs anomaly detection. The pipeline extracts spans, creates service maps, and uses the Random Cut Forest algorithm for detecting anomalies in trace durations.

LANGUAGE: json
CODE:
{
"entry-pipeline": {
  "source": {
    "otel_trace_source": {}
  },
  "processor": [
    {
      "trace_peer_forwarder": {}
    }
  ],
  "sink": [
    {
      "pipeline": {
        "name": "span-pipeline"
      }
    },
    {
      "pipeline": {
        "name": "service-map-pipeline"
      }
    },
    {
      "pipeline": {
        "name": "trace-to-metrics-pipeline"
      }
    }
  ]
}}

----------------------------------------

TITLE: Ingesting Raw Vector Data in OpenSearch
DESCRIPTION: Demonstrates how to ingest a single raw vector directly into the 'knn_vector' field of an OpenSearch index. This method is used when working with pre-generated vectors or embeddings.

LANGUAGE: json
CODE:
PUT /my-raw-vector-index/_doc/1
{
  "my_vector": [0.1, 0.2, 0.3],
  "metadata": "Optional additional information"
}

----------------------------------------

TITLE: Creating Ingest Pipeline for Text Embedding in OpenSearch
DESCRIPTION: This snippet shows how to create an ingest pipeline with a text embedding processor to generate vector embeddings from text fields in OpenSearch.

LANGUAGE: json
CODE:
PUT /_ingest/pipeline/nlp-ingest-pipeline
{
  "description": "A text embedding pipeline",
  "processors": [
    {
      "text_embedding": {
        "model_id": "bQ1J8ooBpBj3wT4HVUsb",
        "field_map": {
          "passage_text": "passage_embedding"
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Sorting hybrid query results by document ID in OpenSearch
DESCRIPTION: This snippet shows how to sort the results of a hybrid query by document ID in descending order. It uses the same hybrid query structure as the previous example but applies sorting on the '_id' field.

LANGUAGE: json
CODE:
GET /my-nlp-index/_search?search_pipeline=nlp-search-pipeline
{
  "query": {
    "hybrid": {
      "queries": [
        {
          "term": {
            "category": "permission"
          }
        },
        {
          "bool": {
            "should": [
              {
                "term": {
                  "category": "editor"
                }
              },
              {
                "term": {
                  "category": "statement"
                }
              }
            ]
          }
        }
      ]
    }
  },
  "sort":[
     {
        "_id": {
          "order": "desc"   
        }
     } 
  ]
}

----------------------------------------

TITLE: Setting Up an Ingest Pipeline for Text Embedding in OpenSearch
DESCRIPTION: This code creates an ingest pipeline that uses the previously registered model to encode documents with text embeddings.

LANGUAGE: json
CODE:
PUT /_ingest/pipeline/test-pipeline-local-model
{
  "description": "text embedding pipeline",
  "processors": [
    {
      "text_embedding": {
        "model_id": "Hv_PY40Bk4MTqircAVmm",
        "field_map": {
          "text": "embedding"
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Configuring LDAP Authentication in config.yml (YAML)
DESCRIPTION: This snippet demonstrates how to configure LDAP as the authentication backend in the config.yml file. It includes settings for basic internal authentication with HTTP and transport layer enabled.

LANGUAGE: yaml
CODE:
authc:
  basic_internal_auth:
    http_enabled: true
    transport_enabled: true
    order: 1
    http_authenticator:
      type: basic
      challenge: true
    authentication_backend:
      type: internal

----------------------------------------

TITLE: Performing k-NN Search Query
DESCRIPTION: Executes an approximate k-NN search query specifying the vector to search for and the number of nearest neighbors to return.

LANGUAGE: json
CODE:
GET my-knn-index-1/_search
{
  "size": 2,
  "query": {
    "knn": {
      "my_vector2": {
        "vector": [2, 3, 5, 6],
        "k": 2
      }
    }
  }
}

----------------------------------------

TITLE: Creating an Index for Faiss k-NN Filtering in OpenSearch
DESCRIPTION: This snippet shows how to create an index with a knn_vector field using the Faiss engine and HNSW method for efficient k-NN filtering.

LANGUAGE: json
CODE:
PUT /products-shirts
{
  "settings": {
    "index": {
      "knn": true
    }
  },
  "mappings": {
    "properties": {
      "item_vector": {
        "type": "knn_vector",
        "dimension": 3,
        "method": {
          "name": "hnsw",
          "space_type": "l2",
          "engine": "faiss"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Defining Roles in roles.yml
DESCRIPTION: Specifies roles with their permissions for cluster, index, and tenant access. This example defines a complex role with various permissions.

LANGUAGE: yaml
CODE:
---
complex-role:
  reserved: false
  hidden: false
  cluster_permissions:
  - "read"
  - "cluster:monitor/nodes/stats"
  - "cluster:monitor/task/get"
  index_permissions:
  - index_patterns:
    - "opensearch_dashboards_sample_data_*"
    dls: "{\"match\": {\"FlightDelay\": true}}"
    fls:
    - "~FlightNum"
    masked_fields:
    - "Carrier"
    allowed_actions:
    - "read"
  tenant_permissions:
  - tenant_patterns:
    - "analyst_*"
    allowed_actions:
    - "kibana_all_write"
  static: false
_meta:
  type: "roles"
  config_version: 2

----------------------------------------

TITLE: Adding Data for Lucene k-NN Filtering in OpenSearch
DESCRIPTION: This snippet shows how to add multiple documents with hotel information to the index for k-NN filtering using the bulk API.

LANGUAGE: json
CODE:
POST /_bulk
{ "index": { "_index": "hotels-index", "_id": "1" } }
{ "location": [5.2, 4.4], "parking" : "true", "rating" : 5 }
{ "index": { "_index": "hotels-index", "_id": "2" } }
{ "location": [5.2, 3.9], "parking" : "false", "rating" : 4 }
{ "index": { "_index": "hotels-index", "_id": "3" } }
{ "location": [4.9, 3.4], "parking" : "true", "rating" : 9 }
{ "index": { "_index": "hotels-index", "_id": "4" } }
{ "location": [4.2, 4.6], "parking" : "false", "rating" : 6}
{ "index": { "_index": "hotels-index", "_id": "5" } }
{ "location": [3.3, 4.5], "parking" : "true", "rating" : 8 }
{ "index": { "_index": "hotels-index", "_id": "6" } }
{ "location": [6.4, 3.4], "parking" : "true", "rating" : 9 }
{ "index": { "_index": "hotels-index", "_id": "7" } }
{ "location": [4.2, 6.2], "parking" : "true", "rating" : 5 }
{ "index": { "_index": "hotels-index", "_id": "8" } }
{ "location": [2.4, 4.0], "parking" : "true", "rating" : 8 }
{ "index": { "_index": "hotels-index", "_id": "9" } }
{ "location": [1.4, 3.2], "parking" : "false", "rating" : 5 }
{ "index": { "_index": "hotels-index", "_id": "10" } }
{ "location": [7.0, 9.9], "parking" : "true", "rating" : 9 }
{ "index": { "_index": "hotels-index", "_id": "11" } }
{ "location": [3.0, 2.3], "parking" : "false", "rating" : 6 }
{ "index": { "_index": "hotels-index", "_id": "12" } }
{ "location": [5.0, 1.0], "parking" : "true", "rating" : 3 }

----------------------------------------

TITLE: Ingesting Document with Text and Image Data in OpenSearch
DESCRIPTION: PUT request to ingest a document containing text description and binary image data into the created index.

LANGUAGE: json
CODE:
PUT /nlp-index/_doc/1
{
 "image_description": "Orange table",
 "image_binary": "iVBORw0KGgoAAAANSUI..."
}

----------------------------------------

TITLE: Enabling and Starting OpenSearch Service
DESCRIPTION: Enable OpenSearch as a service and start it using systemctl commands.

LANGUAGE: bash
CODE:
sudo systemctl enable opensearch
sudo systemctl start opensearch

----------------------------------------

TITLE: Querying Significant Terms in OpenSearch Logs
DESCRIPTION: Demonstrates how to use significant_terms aggregation to analyze user agent patterns in iOS requests. The query filters for iOS operating system documents and aggregates significant terms from the agent field.

LANGUAGE: json
CODE:
{
  "size": 0,
  "query": {
    "terms": {
      "machine.os.keyword": [
        "ios"
      ]
    }
  },
  "aggs": {
    "significant_response_codes": {
      "significant_terms": {
        "field": "agent.keyword"
      }
    }
  }
}

----------------------------------------

TITLE: Creating a Vector Index with Nested Fields in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a vector index with nested fields in OpenSearch, setting up the index structure and vector search parameters.

LANGUAGE: json
CODE:
PUT my-knn-index-1
{
  "settings": {
    "index": {
      "knn": true
    }
  },
  "mappings": {
    "properties": {
      "nested_field": {
        "type": "nested",
        "properties": {
          "my_vector": {
            "type": "knn_vector",
            "dimension": 3,
            "space_type": "l2",
            "method": {
              "name": "hnsw",
              "engine": "lucene",
              "parameters": {
                "ef_construction": 100,
                "m": 16
              }
            }
          },
          "color": {
            "type": "text",
            "index": false
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Installing OpenSearch CLI
DESCRIPTION: This snippet shows the steps to install OpenSearch CLI, including making the file executable and adding it to the system PATH.

LANGUAGE: bash
CODE:
chmod +x ./opensearch-cli
export PATH=$PATH:$(pwd)
opensearch-cli --version

----------------------------------------

TITLE: Complete OpenSearch Python Client Sample Program
DESCRIPTION: A comprehensive example demonstrating client creation, index management, document operations, searching, and cleanup using the OpenSearch high-level Python client.

LANGUAGE: python
CODE:
from opensearchpy import OpenSearch
from opensearch_dsl import Search, Document, Text, Keyword

host = 'localhost'
port = 9200

auth = ('admin', 'admin')  # For testing only. Don't store credentials in code.
ca_certs_path = 'root-ca.pem'

# Create the client with SSL/TLS enabled, but hostname verification disabled.
client = OpenSearch(
    hosts=[{'host': host, 'port': port}],
    http_compress=True,  # enables gzip compression for request bodies
    # http_auth=auth,
    use_ssl=False,
    verify_certs=False,
    ssl_assert_hostname=False,
    ssl_show_warn=False,
    # ca_certs=ca_certs_path
)
index_name = 'my-dsl-index'

index_body = {
  'settings': {
    'index': {
      'number_of_shards': 4
    }
  }
}

response = client.indices.create(index_name, index_body)
print('\nCreating index:')
print(response)

# Create the structure of the document
class Movie(Document):
    title = Text(fields={'raw': Keyword()})
    director = Text()
    year = Text()

    class Index:
        name = index_name

    def save(self, ** kwargs):
        return super(Movie, self).save(** kwargs)

# Set up the opensearch-py version of the document
Movie.init(using=client)
doc = Movie(meta={'id': 1}, title='Moneyball', director='Bennett Miller', year='2011')
response = doc.save(using=client)

print('\nAdding document:')
print(response)

# Perform bulk operations

movies = '{ "index" : { "_index" : "my-dsl-index", "_id" : "2" } } \n { "title" : "Interstellar", "director" : "Christopher Nolan", "year" : "2014"} \n { "create" : { "_index" : "my-dsl-index", "_id" : "3" } } \n { "title" : "Star Trek Beyond", "director" : "Justin Lin", "year" : "2015"} \n { "update" : {"_id" : "3", "_index" : "my-dsl-index" } } \n { "doc" : {"year" : "2016"} }'

client.bulk(movies)

# Search for the document.
s = Search(using=client, index=index_name) \
    .filter('term', year='2011') \
    .query('match', title='Moneyball')

response = s.execute()

print('\nSearch results:')
for hit in response:
    print(hit.meta.score, hit.title)
    
# Delete the document.
print('\nDeleting document:')
print(response)

# Delete the index.
response = client.indices.delete(
    index = index_name
)

print('\nDeleting index:')
print(response)

----------------------------------------

TITLE: Creating an Ingest Pipeline for Text Embedding
DESCRIPTION: Creates an ingest pipeline to generate text embeddings for tech news data using a specified embedding model.

LANGUAGE: json
CODE:
PUT /_ingest/pipeline/test_tech_news_pipeline
{
    "description": "text embedding pipeline for tech news",
    "processors": [
        {
            "text_embedding": {
                "model_id": "your_text_embedding_model_id",
                "field_map": {
                    "passage": "passage_embedding"
                }
            }
        }
    ]
}

----------------------------------------

TITLE: Configuring Multiple Authentication Domains in OpenSearch
DESCRIPTION: This YAML snippet demonstrates how to set up multiple authentication domains in OpenSearch, including a basic internal auth domain and a SAML auth domain.

LANGUAGE: yaml
CODE:
_meta:
  type: "config"
  config_version: 2

config:
  dynamic:
    authc:
      basic_internal_auth_domain:
        http_enabled: true
        transport_enabled: true
        order: 0
        http_authenticator:
          type: basic
          challenge: false
        authentication_backend:
          type: internal
      saml_auth_domain:
        http_enabled: true
        transport_enabled: false
        order: 1
        http_authenticator:
          type: saml
          challenge: true
          config:
            ...
        authentication_backend:
          type: noop

----------------------------------------

TITLE: Match Query with AND Operator in OpenSearch
DESCRIPTION: A Match query using the 'AND' operator to require all terms to match.

LANGUAGE: json
CODE:
GET testindex/_search
{
  "query": {
    "match": {
      "title": {
        "query": "wind rise",
        "operator": "and"
      }
    }
  }
}

----------------------------------------

TITLE: Complex Rollup Search Query
DESCRIPTION: Example of a more complex search query against a rollup index with multiple aggregations

LANGUAGE: json
CODE:
{
  "size": 0,
  "query": {
    "bool": {
      "must": {"term": { "geoip.region_name": "California" } }
    }
  },
  "aggregations": {
    "daily_numbers": {
      "terms": {
        "field": "day_of_week"
      },
      "aggs": {
        "per_city": {
          "terms": {
            "field": "geoip.city_name"
          },
          "aggregations": {
            "average quantity": {
               "avg": {
                  "field": "total_quantity"
                }
              }
            }
          }
        }
      }
    }
  }

----------------------------------------

TITLE: Basic Missing Aggregation Query in OpenSearch
DESCRIPTION: Demonstrates how to use the 'missing' parameter to place documents with missing values into a named bucket 'N/A'. This query aggregates response codes from log data.

LANGUAGE: json
CODE:
GET opensearch_dashboards_sample_data_logs/_search
{
  "size": 0,
  "aggs": {
    "response_codes": {
      "terms": {
        "field": "response.keyword",
        "size": 10,
        "missing": "N/A"
      }
    }
  }
}

----------------------------------------

TITLE: Testing a Built-in Analyzer in OpenSearch
DESCRIPTION: This snippet demonstrates how to use the Analyze API to test a built-in analyzer and view the tokens it generates. It applies the 'standard' analyzer to the text 'Let's contribute to OpenSearch!'.

LANGUAGE: json
CODE:
GET /_analyze
{
  "analyzer" : "standard",
  "text" : "Let's contribute to OpenSearch!"
}

----------------------------------------

TITLE: Testing Bedrock Cohere Model in OpenSearch
DESCRIPTION: This JSON request tests the deployed Bedrock Cohere embedding model by generating embeddings for a sample text.

LANGUAGE: json
CODE:
POST /_plugins/_ml/models/VRUu8o0BTaDH9c7t9xet/_predict
{
  "parameters": {
    "texts": ["hello world"]
  }
}

----------------------------------------

TITLE: Indexing a Document in OpenSearch
DESCRIPTION: JavaScript code for indexing a document into OpenSearch using the client's index method.

LANGUAGE: javascript
CODE:
var document = {
  title: "The Outsider",
  author: "Stephen King",
  year: "2018",
  genre: "Crime fiction",
};

var id = "1";

var response = await client.index({
  id: id,
  index: index_name,
  body: document,
  refresh: true,
});

----------------------------------------

TITLE: Executing Reindex Operation in OpenSearch
DESCRIPTION: This snippet demonstrates how to use the reindex API to copy documents from a source index to a destination index. It shows the basic structure of the request body, specifying the source and destination indices.

LANGUAGE: json
CODE:
POST /_reindex
{
   "source":{
      "index":"my-source-index"
   },
   "dest":{
      "index":"my-destination-index"
   }
}

----------------------------------------

TITLE: Configuring TLS Settings in OpenSearch Dashboards YAML
DESCRIPTION: Example configuration for enabling TLS in OpenSearch Dashboards with demo settings. Shows settings for server SSL, OpenSearch cluster communication, security features, and multitenancy configuration. Assumes OpenSearch and OpenSearch Dashboards are running on the same machine.

LANGUAGE: yaml
CODE:
server.host: '0.0.0.0'
server.ssl.enabled: true
server.ssl.certificate: /usr/share/opensearch-dashboards/config/client-cert.pem
server.ssl.key: /usr/share/opensearch-dashboards/config/client-cert-key.pem
opensearch.hosts: ["https://localhost:9200"]
opensearch.ssl.verificationMode: full
opensearch.ssl.certificateAuthorities: [ "/usr/share/opensearch-dashboards/config/root-ca.pem", "/usr/share/opensearch-dashboards/config/intermediate-ca.pem" ]
opensearch.username: "kibanaserver"
opensearch.password: "kibanaserver"
opensearch.requestHeadersAllowlist: [ authorization,securitytenant ]
opensearch_security.multitenancy.enabled: true
opensearch_security.multitenancy.tenants.preferred: ["Private", "Global"]
opensearch_security.readonly_mode.roles: ["kibana_read_only"]
opensearch_security.cookie.secure: true

----------------------------------------

TITLE: Training a k-NN Model in OpenSearch
DESCRIPTION: Demonstrates how to initiate the training process for a k-NN model, specifying training data, dimensions, and method parameters.

LANGUAGE: json
CODE:
POST /_plugins/_knn/models/{model_id}/_train?preference={node_id}
{
    "training_index": "train-index-name",
    "training_field": "train-field-name",
    "dimension": 16,
    "max_training_vector_count": 1200,
    "search_size": 100,
    "description": "My model",
    "space_type": "l2",
    "method": {
        "name":"ivf",
        "engine":"faiss",
        "parameters":{
            "nlist":128,
            "encoder":{
                "name":"pq",
                "parameters":{
                    "code_size":8
                }
            }
        }
    }
}

----------------------------------------

TITLE: Verifying OpenSearch Installation
DESCRIPTION: Sends a curl request to check if OpenSearch is running on localhost:9200.

LANGUAGE: bash
CODE:
curl https://localhost:9200

----------------------------------------

TITLE: Complex Boolean Query with Multiple Conditions
DESCRIPTION: Example of a Boolean query searching for 'love' in text_entry with additional conditions for 'life' or 'grace', excluding ROMEO as speaker, and filtering for 'Romeo and Juliet'.

LANGUAGE: json
CODE:
GET shakespeare/_search
{
  "query": {
    "bool": {
      "must": [
        {
          "match": {
            "text_entry": "love"
          }
        }
      ],
      "should": [
        {
          "match": {
            "text_entry": "life"
          }
        },
        {
          "match": {
            "text_entry": "grace"
          }
        }
      ],
      "minimum_should_match": 1,
      "must_not": [
        {
          "match": {
            "speaker": "ROMEO"
          }
        }
      ],
      "filter": {
        "term": {
          "play_name": "Romeo and Juliet"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating an OpenAI GPT-4o Connector in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a connector for the OpenAI GPT-4o model in OpenSearch. It includes the necessary configuration for the endpoint, model, and authentication.

LANGUAGE: json
CODE:
POST _plugins/_ml/connectors/_create
{
  "name": "OpenAI GPT-4o",
  "description": "Connector of OpenAI GPT-4o",
  "version": "1.0",
  "protocol": "http",
  "parameters": {
    "endpoint": "api.openai.com",
    "model": "gpt-4o"
  },
  "credential": {
    "openAI_key": "your_openai_key"
  },
  "actions": [
    {
      "action_type": "predict",
      "method": "POST",
      "url": "https://${parameters.endpoint}/v1/chat/completions",
      "headers": {
        "Authorization": "Bearer ${credential.openAI_key}"
      },
      "request_body": "{ \"model\": \"${parameters.model}\", \"messages\": ${parameters.messages} }"
    }
  ]
}

----------------------------------------

TITLE: Retrieving Cluster Health in OpenSearch
DESCRIPTION: This HTTP GET request retrieves the current health status of the OpenSearch cluster.

LANGUAGE: http
CODE:
GET _cluster/health

----------------------------------------

TITLE: OpenSearch YAML Configuration Examples
DESCRIPTION: Examples of configuration settings in opensearch.yml file including basic cluster settings and CORS configuration.

LANGUAGE: yaml
CODE:
cluster.name: my-application
action.auto_create_index: true
compatibility.override_main_response_version: true

LANGUAGE: yaml
CODE:
- http.host:0.0.0.0
- http.port:9200
- http.cors.allow-origin:"http://localhost"
- http.cors.enabled:true
- http.cors.allow-headers:X-Requested-With,X-Auth-Token,Content-Type,Content-Length,Authorization
- http.cors.allow-credentials:true

----------------------------------------

TITLE: Deploying Bedrock Cohere Model in OpenSearch
DESCRIPTION: This JSON request deploys the registered Bedrock Cohere embedding model in OpenSearch.

LANGUAGE: json
CODE:
POST /_plugins/_ml/models/VRUu8o0BTaDH9c7t9xet/_deploy

----------------------------------------

TITLE: Configuring System Memory Settings
DESCRIPTION: Commands to disable memory paging and set the virtual memory map count for optimal OpenSearch performance.

LANGUAGE: bash
CODE:
sudo swapoff -a

LANGUAGE: bash
CODE:
sudo vi /etc/sysctl.conf

LANGUAGE: bash
CODE:
vm.max_map_count=262144

LANGUAGE: bash
CODE:
sudo sysctl -p

----------------------------------------

TITLE: Setting NODE_HOME Environment Variable on UNIX
DESCRIPTION: Commands to set the NODE_HOME environment variable on UNIX systems to specify a custom Node.js installation path

LANGUAGE: bash
CODE:
export NODE_HOME=/usr/local/nodejs

----------------------------------------

TITLE: Creating Index with Special Field Types for Aggregations
DESCRIPTION: Creates an OpenSearch index with specialized field types (integer and keyword) that are optimized for aggregations. The index includes fields for doc_index, doc_keyword, and category.

LANGUAGE: json
CODE:
PUT /my-nlp-index
{
  "settings": {
    "number_of_shards": 2
  },
  "mappings": {
    "properties": {
      "doc_index": {
        "type": "integer"
      },
      "doc_keyword": {
        "type": "keyword"
      },
      "category": {
        "type": "keyword"
      }
    }
  }
}

----------------------------------------

TITLE: Analyzing Text with Index Default Analyzer in OpenSearch
DESCRIPTION: This example shows how to analyze text using the default analyzer associated with a specific index in OpenSearch.

LANGUAGE: json
CODE:
GET /books/_analyze
{
  "text" : "OpenSearch analyze test"
}

----------------------------------------

TITLE: Executing Hybrid Search with Post-Filtering in OpenSearch
DESCRIPTION: This example demonstrates a hybrid search query combining 'term' and 'match' clauses with a post-filter. The search is performed on the 'my-nlp-index' using the 'nlp-search-pipeline'. The post-filter applies an additional 'match' condition on the 'passage_text' field.

LANGUAGE: json
CODE:
GET /my-nlp-index/_search?search_pipeline=nlp-search-pipeline
{
  "query": {
    "hybrid":{
      "queries":[
        {
          "match":{
            "passage_text": "hello"
          }
        },
        {
          "term":{
            "passage_text":{
              "value":"planet"
            }
          }
        }
      ]
    }

  },
  "post_filter":{
    "match": { "passage_text": "world" }
  }
}

----------------------------------------

TITLE: Creating Text Embedding Pipeline
DESCRIPTION: Defines an ingest pipeline that generates vector embeddings from text fields using the embedding model

LANGUAGE: json
CODE:
{
    "description": "text embedding pipeline",
    "processors": [
        {
            "text_embedding": {
                "model_id": "your_text_embedding_model_id",
                "field_map": {
                    "population_description": "population_description_embedding"
                }
            }
        }
    ]
}

----------------------------------------

TITLE: Performing Neural Query Search on Text and Image in OpenSearch
DESCRIPTION: GET request to perform a neural query search on the index using both text and image data.

LANGUAGE: json
CODE:
GET /my-nlp-index/_search
{
  "size": 10,
  "query": {
    "neural": {
      "vector_embedding": {
        "query_text": "Orange table",
        "query_image": "iVBORw0KGgoAAAANSUI...",
        "model_id": "-fYQAosBQkdnhhBsK593",
        "k": 5
      }
    }
  }
}

----------------------------------------

TITLE: Mapping a k-NN Vector Field in OpenSearch
DESCRIPTION: This example demonstrates how to map a field named 'my_vector' as a k-NN vector type with specified dimension and space type.

LANGUAGE: json
CODE:
PUT /test-index
{
  "settings": {
    "index": {
      "knn": true
    }
  },
  "mappings": {
    "properties": {
      "my_vector": {
        "type": "knn_vector",
        "dimension": 3,
        "space_type": "l2"
      }
    }
  }
}

----------------------------------------

TITLE: Using Phrase Suggester in OpenSearch
DESCRIPTION: Example of using the phrase suggester to get suggestions for an incorrect phrase. It uses the custom trigram analyzer field for suggestions.

LANGUAGE: json
CODE:
GET books2/_search
{
  "suggest": {
    "phrase-check": {
      "text": "design paterns",
      "phrase": {
        "field": "title.trigram"
      }
    }
  }
}

----------------------------------------

TITLE: Custom Field Format Extraction
DESCRIPTION: Shows how to extract fields with custom formatting, specifically for date fields.

LANGUAGE: json
CODE:
{
  "query": {
    "match_all": {}
  },
  "fields": {
    "date": {
      "format": "yyyy-MM-dd"
    }
  },
  "_source": false
}

----------------------------------------

TITLE: Creating an Index Template in OpenSearch
DESCRIPTION: This snippet demonstrates how to create an index template named 'daily_logs' that applies to indexes matching the pattern 'logs-2020-01-*'. It sets up aliases, shards, replicas, and mappings for timestamp and value fields.

LANGUAGE: json
CODE:
PUT _index_template/daily_logs
{
  "index_patterns": [
    "logs-2020-01-*"
  ],
  "template": {
    "aliases": {
      "my_logs": {}
    },
    "settings": {
      "number_of_shards": 2,
      "number_of_replicas": 1
    },
    "mappings": {
      "properties": {
        "timestamp": {
          "type": "date",
          "format": "yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis"
        },
        "value": {
          "type": "double"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Authenticating with Amazon OpenSearch Service using AWS SDK V2
DESCRIPTION: JavaScript code for authenticating with Amazon OpenSearch Service using AWS Signature Version 4 with AWS SDK V2.

LANGUAGE: javascript
CODE:
const AWS = require('aws-sdk');
const { Client } = require('@opensearch-project/opensearch');
const { AwsSigv4Signer } = require('@opensearch-project/opensearch/aws');

const client = new Client({
  ...AwsSigv4Signer({
    region: 'us-west-2',
    service: 'es',
    getCredentials: () =>
      new Promise((resolve, reject) => {
        AWS.config.getCredentials((err, credentials) => {
          if (err) {
            reject(err);
          } else {
            resolve(credentials);
          }
        });
      }),
  }),
  node: 'https://search-xxx.region.es.amazonaws.com',
});

----------------------------------------

TITLE: Basic Cluster Health Endpoint
DESCRIPTION: Basic GET endpoints to retrieve cluster health status, optionally filtered by index.

LANGUAGE: json
CODE:
GET _cluster/health
GET _cluster/health/<index>

----------------------------------------

TITLE: Querying by Raw Text with Neural Sparse in OpenSearch
DESCRIPTION: This snippet demonstrates how to structure a neural_sparse query using raw text input. It requires specifying the vector field, query text, and model ID for generating sparse vector embeddings.

LANGUAGE: json
CODE:
"neural_sparse": {
  "<vector_field>": {
    "query_text": "<query_text>",
    "model_id": "<model_id>"
  }
}

----------------------------------------

TITLE: Ingesting Documents for Semantic Search in OpenSearch
DESCRIPTION: These snippets show how to ingest documents into a vector index for semantic search in OpenSearch. The ingest pipeline automatically generates embeddings.

LANGUAGE: json
CODE:
PUT /my-nlp-index/_doc/1
{
  "passage_text": "Hello world",
  "id": "s1"
}

LANGUAGE: json
CODE:
PUT /my-nlp-index/_doc/2
{
  "passage_text": "Hi planet",
  "id": "s2"
}

----------------------------------------

TITLE: Star-tree Metric Aggregation Query Example
DESCRIPTION: Example query demonstrating how to get the sum of values in the size field for error logs with status 500 using a star-tree index.

LANGUAGE: json
CODE:
{
  "query": {
    "term": {
      "status": "500"
    }
  },
  "aggs": {
    "sum_size": {
      "sum": {
        "field": "size"
      }
    }
  }
}

----------------------------------------

TITLE: Disabling Private Tenant Configuration in OpenSearch
DESCRIPTION: Configuration to disable private tenants in OpenSearch Dashboards while keeping multitenancy enabled. This helps prevent the creation of unnecessary indices for individual users.

LANGUAGE: yaml
CODE:
config:
  dynamic:
    kibana:
      multitenancy_enabled: true
      private_tenant_enabled: false

----------------------------------------

TITLE: Creating Search Pipeline with Hybrid Score Explanation
DESCRIPTION: Creates a search pipeline that includes a normalization processor and hybrid_score_explanation processor. The pipeline processes search results and adds explanation information.

LANGUAGE: json
CODE:
PUT /_search/pipeline/nlp-search-pipeline
{
  "description": "Post processor for hybrid search",
  "phase_results_processors": [
    {
      "normalization-processor": {
        "normalization": {
          "technique": "min_max"
        },
        "combination": {
          "technique": "arithmetic_mean"
        }
      }
    }
  ],
  "response_processors": [
    {
        "hybrid_score_explanation": {}
    }
  ]
}

----------------------------------------

TITLE: Performing k-NN Warmup Operation in OpenSearch
DESCRIPTION: Shows how to execute a warmup operation on multiple indexes to load native library files into memory for improved search performance.

LANGUAGE: json
CODE:
GET /_plugins/_knn/warmup/index1,index2,index3?pretty

----------------------------------------

TITLE: Searching Raw Vectors with kNN Query in OpenSearch
DESCRIPTION: Demonstrates how to search raw vectors using the kNN query type. The query requires a vector array input and k parameter to specify the number of results to return.

LANGUAGE: json
CODE:
GET /my-raw-vector-index/_search
{
  "query": {
    "knn": {
      "my_vector": {
        "vector": [0.1, 0.2, 0.3],
        "k": 2
      }
    }
  }
}

----------------------------------------

TITLE: Creating DeepSeek Connector Using Python
DESCRIPTION: Python script to create a connector for the DeepSeek chat model using temporary AWS credentials and the OpenSearch API.

LANGUAGE: python
CODE:
import boto3
import requests 
from requests_aws4auth import AWS4Auth

host = 'your_amazon_opensearch_domain_endpoint'
region = 'your_amazon_opensearch_domain_region'
service = 'es'

credentials = boto3.Session().get_credentials()
awsauth = AWS4Auth(credentials.access_key, credentials.secret_key, region, service, session_token=credentials.token)

path = '/_plugins/_ml/connectors/_create'
url = host + path

payload = {
  "name": "DeepSeek Chat",
  "description": "Test connector for DeepSeek Chat",
  "version": "1",
  "protocol": "http",
  "parameters": {
    "endpoint": "api.deepseek.com",
    "model": "deepseek-chat"
  },
  "credential": {
    "secretArn": "your_secret_arn_created_in_step1",
    "roleArn": "your_iam_role_arn_created_in_step2"
  },
  "actions": [
    {
      "action_type": "predict",
      "method": "POST",
      "url": "https://${parameters.endpoint}/v1/chat/completions",
      "headers": {
        "Content-Type": "application/json",
        "Authorization": "Bearer ${credential.secretArn.my_deepseek_key}"
      },
      "request_body": "{ \"model\": \"${parameters.model}\", \"messages\": ${parameters.messages} }"
    }
  ]
}

headers = {"Content-Type": "application/json"}

r = requests.post(url, auth=awsauth, json=payload, headers=headers)
print(r.status_code)
print(r.text)

----------------------------------------

TITLE: Creating k-NN Vector Index with Faiss Engine
DESCRIPTION: Creates an OpenSearch index with two knn_vector fields using the Faiss engine. Configures settings for approximate k-NN search including dimension sizes and space types.

LANGUAGE: json
CODE:
PUT my-knn-index-1
{
  "settings": {
    "index": {
      "knn": true,
      "knn.algo_param.ef_search": 100
    }
  },
  "mappings": {
    "properties": {
        "my_vector1": {
          "type": "knn_vector",
          "dimension": 2,
          "space_type": "l2",
          "method": {
            "name": "hnsw",
            "engine": "faiss",
            "parameters": {
              "ef_construction": 128,
              "m": 24
            }
          }
        },
        "my_vector2": {
          "type": "knn_vector",
          "dimension": 4,
          "space_type": "innerproduct",
          "method": {
            "name": "hnsw",
            "engine": "faiss",
            "parameters": {
              "ef_construction": 256,
              "m": 48
            }
          }
        }
    }
  }
}

----------------------------------------

TITLE: Put Mapping with Query Parameter
DESCRIPTION: Example of using the ignore_unavailable query parameter when creating/updating mappings.

LANGUAGE: json
CODE:
PUT /sample-index/_mapping?ignore_unavailable

----------------------------------------

TITLE: Configuring Data Prepper Pipeline for Log Metrics
DESCRIPTION: Pipeline configuration that processes Apache logs through two sub-pipelines. The first pipeline receives and parses logs using grok patterns, while the second pipeline aggregates the data into histogram metrics based on client IP and request information. The metrics are stored in separate OpenSearch indices for logs and histograms.

LANGUAGE: yaml
CODE:
apache-log-pipeline-with-metrics:
  source:
    http:
      # Provide the path for ingestion. ${pipelineName} will be replaced with pipeline name configured for this pipeline.
      # In this case it would be "/apache-log-pipeline-with-metrics/logs". This will be the FluentBit output URI value.
      path: "/${pipelineName}/logs"
  processor:
    - grok:
        match:
          log: [ "%{COMMONAPACHELOG_DATATYPED}" ]
  sink:
    - opensearch:
        ...
        index: "logs"
    - pipeline:
        name: "log-to-metrics-pipeline"
        
log-to-metrics-pipeline:
  source:
    pipeline:
      name: "apache-log-pipeline-with-metrics"
  processor:
    - aggregate:
        # Specify the required identification keys
        identification_keys: ["clientip", "request"]
        action:
          histogram:
            # Specify the appropriate values for each of the following fields
            key: "bytes"
            record_minmax: true
            units: "bytes"
            buckets: [0, 25000000, 50000000, 75000000, 100000000]
        # Pick the required aggregation period
        group_duration: "30s"
  sink:
    - opensearch:
        ...
        index: "histogram_metrics"

----------------------------------------

TITLE: Enabling DELETE Operations in OpenSearch SQL
DESCRIPTION: Configuration request to enable DELETE functionality in OpenSearch SQL by updating plugin settings.

LANGUAGE: json
CODE:
PUT _plugins/_query/settings
{
  "transient": {
    "plugins.sql.delete.enabled": "true"
  }
}

----------------------------------------

TITLE: Retrieving All Nested Hits in Vector Search with OpenSearch
DESCRIPTION: This snippet demonstrates how to retrieve all nested hits in a vector search on nested fields in OpenSearch, using expand_nested_docs and score_mode options.

LANGUAGE: json
CODE:
GET my-knn-index-1/_search
{
  "_source": false,
  "query": {
    "nested": {
      "path": "nested_field",
      "query": {
        "knn": {
          "nested_field.my_vector": {
            "vector": [1,1,1],
            "k": 2,
            "expand_nested_docs": true
          }
        }
      },
      "inner_hits": {
        "_source": false,
        "fields":["nested_field.color"]
      },
      "score_mode": "max"
    }
  }
}

----------------------------------------

TITLE: Creating Join Field Mapping in OpenSearch
DESCRIPTION: Example of creating a mapping that establishes a parent/child relationship between products and brands using the join field type.

LANGUAGE: json
CODE:
PUT testindex1
{
  "mappings": {
    "properties": {
      "product_to_brand": { 
        "type": "join",
        "relations": {
          "brand": "product" 
        }
      }
    }
  }
}

----------------------------------------

TITLE: OpenSearch Dashboards YAML Configuration
DESCRIPTION: Additional OpenSearch Dashboards settings for multi-tenancy including authentication, header allowlist, and tenant preferences.

LANGUAGE: yaml
CODE:
opensearch.username: kibanaserver
opensearch.password: kibanaserver
opensearch.requestHeadersAllowlist: ["securitytenant","Authorization"]
opensearch_security.multitenancy.enabled: true
opensearch_security.multitenancy.tenants.enable_global: true
opensearch_security.multitenancy.tenants.enable_private: true
opensearch_security.multitenancy.tenants.preferred: ["Private", "Global"]
opensearch_security.multitenancy.enable_filter: false

----------------------------------------

TITLE: Paginating Hybrid Search Results by Document Price in OpenSearch
DESCRIPTION: This snippet demonstrates how to paginate hybrid search results using the search_after parameter, sorting by document price in descending order. It includes a hybrid query combining term and bool queries, with a search_after value of 200.

LANGUAGE: json
CODE:
GET /my-nlp-index/_search?search_pipeline=nlp-search-pipeline
{
  "query": {
    "hybrid": {
      "queries": [
        {
          "term": {
            "category": "permission"
          }
        },
        {
          "bool": {
            "should": [
              {
                "term": {
                  "category": "editor"
                }
              },
              {
                "term": {
                  "category": "statement"
                }
              }
            ]
          }
        }
      ]
    }
  },
  "sort":[
     {
        "_id": {
          "order": "desc"   
        }
     } 
  ],
  "search_after":[200]
}

----------------------------------------

TITLE: Creating Custom Finnish Analyzer in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a custom Finnish analyzer in OpenSearch. It includes custom stop words, stemmer, and keyword marker filters.

LANGUAGE: json
CODE:
PUT /finnish-index
{
  "settings": {
    "analysis": {
      "filter": {
        "finnish_stop": {
          "type": "stop",
          "stopwords": "_finnish_"
        },
        "finnish_stemmer": {
          "type": "stemmer",
          "language": "finnish"
        },
        "finnish_keywords": {
          "type": "keyword_marker",
          "keywords": ["Helsinki", "Suomi"]
        }
      },
      "analyzer": {
        "finnish_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "finnish_stop",
            "finnish_keywords",
            "finnish_stemmer"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "finnish_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Creating Vector Index with Faiss Scalar Quantization in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a vector index using Faiss scalar quantization in OpenSearch. It sets up an index with a k-NN vector field using the HNSW method and Faiss engine with SQ encoder.

LANGUAGE: json
CODE:
PUT /test-index
{
  "settings": {
    "index": {
      "knn": true,
      "knn.algo_param.ef_search": 100
    }
  },
  "mappings": {
    "properties": {
      "my_vector1": {
        "type": "knn_vector",
        "dimension": 3,
        "space_type": "l2",
        "method": {
          "name": "hnsw",
          "engine": "faiss",
          "parameters": {
            "encoder": {
              "name": "sq"
            },
            "ef_construction": 256,
            "m": 8
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Vector Index
DESCRIPTION: Creates a vector index with KNN vector field type and associated pipeline for embedding generation

LANGUAGE: json
CODE:
{
  "mappings": {
    "properties": {
      "population_description": {
        "type": "text"
      },
      "population_description_embedding": {
        "type": "knn_vector",
        "dimension": 384
      }
    }
  },
  "settings": {
    "index": {
      "knn.space_type": "cosinesimil",
      "default_pipeline": "test_population_data_pipeline",
      "knn": "true"
    }
  }
}

----------------------------------------

TITLE: Basic Document Update in OpenSearch
DESCRIPTION: Example of updating specific fields in a document using the doc object in the request body.

LANGUAGE: json
CODE:
{
  "doc": {
    "first_name": "Thomas",
    "last_name": "Wayne"
    }
}

----------------------------------------

TITLE: Creating a document-level monitor in OpenSearch
DESCRIPTION: Creates a new document-level monitor that checks individual documents against trigger conditions. Includes schedule, input queries, trigger condition, and actions.

LANGUAGE: json
CODE:
POST _plugins/_alerting/monitors
{
  "type": "monitor",
  "monitor_type": "doc_level_monitor",
  "name": "Example document-level monitor",
  "enabled": true,
  "schedule": {
    "period": {
      "interval": 1,
      "unit": "MINUTES"
    }
  },
  "inputs": [
    {
      "doc_level_input": {
        "description": "Example document-level monitor for audit logs",
        "indices": [
          "audit-logs"
        ],
        "queries": [
        {
            "id": "nKQnFYABit3BxjGfiOXC",
            "name": "sigma-123",
            "query": "region:\"us-west-2\"",
            "tags": [
                "tag1"
            ]
        },
        {
            "id": "gKQnABEJit3BxjGfiOXC",
            "name": "sigma-456",
            "query": "region:\"us-east-1\"",
            "tags": [
                "tag2"
            ]
        },
        {
            "id": "h4J2ABEFNW3vxjGfiOXC",
            "name": "sigma-789",
            "query": "message:\"This is a SEPARATE error from IAD region\"",
            "tags": [
                "tag3"
            ]
        }
    ]
      }
    }
  ],
    "triggers": [ { "document_level_trigger": {
      "name": "test-trigger",
      "severity": "1",
      "condition": {
        "script": {
          "source": "(query[name=sigma-123] || query[tag=tag3]) && query[name=sigma-789]",
          "lang": "painless"
        }
      },
      "actions": [
        {
            "name": "test-action",
            "destination_id": "E4o5hnsB6KjPKmHtpfCA",
            "message_template": {
                "source": "Monitor  just entered alert status. Please investigate the issue. Related Finding Ids: {{ctx.alerts.0.finding_ids}}, Related Document Ids: {{ctx.alerts.0.related_doc_ids}}",
                "lang": "mustache"
            },
            "action_execution_policy": {
                "action_execution_scope": {
                    "per_alert": {
                        "actionable_alerts": []
                    }
                }
            },
            "subject_template": {
                "source": "The Subject",
                "lang": "mustache"
            }
         }
      ]
  }}]
}

----------------------------------------

TITLE: Creating Configured Index - OpenSearch
DESCRIPTION: Example request demonstrating how to create an index with custom settings, mappings, and aliases. The example creates an index with 2 shards, 1 replica, an integer field 'age', and an alias 'sample-alias1'.

LANGUAGE: json
CODE:
PUT /sample-index1
{
  "settings": {
    "index": {
      "number_of_shards": 2,
      "number_of_replicas": 1
    }
  },
  "mappings": {
    "properties": {
      "age": {
        "type": "integer"
      }
    }
  },
  "aliases": {
    "sample-alias1": {}
  }
}

----------------------------------------

TITLE: Querying Account Data with SQL in OpenSearch
DESCRIPTION: This SQL query retrieves the first name, last name, and balance from the 'accounts' index for accounts with a balance greater than 10,000 and sorts the results by balance in descending order.

LANGUAGE: sql
CODE:
SELECT
  firstname,
  lastname,
  balance
FROM
  accounts
WHERE
  balance > 10000
ORDER BY
  balance DESC;

----------------------------------------

TITLE: Creating Root Chatbot Agent for OpenSearch Dashboards
DESCRIPTION: Configures a flow agent that combines a conversational agent with question suggestion capabilities for the OpenSearch Assistant interface.

LANGUAGE: json
CODE:
POST /_plugins/_ml/agents/_register
{
  "name": "Chatbot agent",
  "type": "flow",
  "description": "this is a test chatbot agent",
  "tools": [
    {
      "type": "AgentTool",
      "name": "LLMResponseGenerator",
      "parameters": {
        "agent_id": "your_conversational_agent_created_in_prevous_steps" 
      },
      "include_output_in_agent_response": true
    },
    {
      "type": "MLModelTool",
      "name": "QuestionSuggestor",
      "description": "A general tool to answer any question",
      "parameters": {
        "model_id": "your_llm_model_id_created_in_previous_steps",
        "prompt": "Human: You are an AI that only speaks JSON..."  
      },
      "include_output_in_agent_response": true
    }
  ],
  "memory": {
    "type": "conversation_index"
  }
}

----------------------------------------

TITLE: Basic Match Query in SQL
DESCRIPTION: Examples of using MATCHQUERY and MATCH_QUERY functions to perform text searches against specific fields.

LANGUAGE: sql
CODE:
SELECT account_number, address
FROM accounts
WHERE MATCHQUERY(address, 'Holmes')

LANGUAGE: sql
CODE:
SELECT account_number, address
FROM accounts
WHERE address = MATCH_QUERY('Holmes')

----------------------------------------

TITLE: Authorization Backend Configuration
DESCRIPTION: Configuration structure for authorization backends, typically used for role extraction from LDAP implementations.

LANGUAGE: yaml
CODE:
authz:
  <name>:
    http_enabled: <true|false>
    transport_enabled: <true|false>
    authorization_backend:
      type: <type>
      config:
        ...

----------------------------------------

TITLE: Indexing Geo Point Data in OpenSearch
DESCRIPTION: Indexes a document with a geopoint specified by latitude and longitude coordinates.

LANGUAGE: json
CODE:
PUT testindex1/_doc/1
{
  "point": { 
    "lat": 73.71,
    "lon": 41.32
  }
}

----------------------------------------

TITLE: Complete OpenSearch Python Client Sample Program
DESCRIPTION: A comprehensive example demonstrating the full workflow of creating a client, adding an index, inserting a document, performing bulk operations, searching, and deleting in OpenSearch using the Python client.

LANGUAGE: python
CODE:
from opensearchpy import OpenSearch

host = 'localhost'
port = 9200
auth = ('admin', 'admin') # For testing only. Don't store credentials in code.
ca_certs_path = '/full/path/to/root-ca.pem' # Provide a CA bundle if you use intermediate CAs with your root CA.

# Optional client certificates if you don't want to use HTTP basic authentication.
# client_cert_path = '/full/path/to/client.pem'
# client_key_path = '/full/path/to/client-key.pem'

# Create the client with SSL/TLS enabled, but hostname verification disabled.
client = OpenSearch(
    hosts = [{'host': host, 'port': port}],
    http_compress = True, # enables gzip compression for request bodies
    http_auth = auth,
    # client_cert = client_cert_path,
    # client_key = client_key_path,
    use_ssl = True,
    verify_certs = True,
    ssl_assert_hostname = False,
    ssl_show_warn = False,
    ca_certs = ca_certs_path
)

# Create an index with non-default settings.
index_name = 'python-test-index'
index_body = {
  'settings': {
    'index': {
      'number_of_shards': 4
    }
  }
}

response = client.indices.create(index_name, body=index_body)
print('\nCreating index:')
print(response)

# Add a document to the index.
document = {
  'title': 'Moneyball',
  'director': 'Bennett Miller',
  'year': '2011'
}
id = '1'

response = client.index(
    index = index_name,
    body = document,
    id = id,
    refresh = True
)

print('\nAdding document:')
print(response)

# Perform bulk operations

movies = '{ "index" : { "_index" : "my-dsl-index", "_id" : "2" } } \n { "title" : "Interstellar", "director" : "Christopher Nolan", "year" : "2014"} \n { "create" : { "_index" : "my-dsl-index", "_id" : "3" } } \n { "title" : "Star Trek Beyond", "director" : "Justin Lin", "year" : "2015"} \n { "update" : {"_id" : "3", "_index" : "my-dsl-index" } } \n { "doc" : {"year" : "2016"} }'

client.bulk(movies)

# Search for the document.
q = 'miller'
query = {
  'size': 5,
  'query': {
    'multi_match': {
      'query': q,
      'fields': ['title^2', 'director']
    }
  }
}

response = client.search(
    body = query,
    index = index_name
)
print('\nSearch results:')
print(response)

# Delete the document.
response = client.delete(
    index = index_name,
    id = id
)

print('\nDeleting document:')
print(response)

# Delete the index.
response = client.indices.delete(
    index = index_name
)

print('\nDeleting index:')
print(response)

----------------------------------------

TITLE: Testing Text Embedding Pipeline
DESCRIPTION: Example request to test the pipeline by simulating document processing with a sample text input.

LANGUAGE: json
CODE:
{
  "docs": [
    {
      "_index": "testindex1",
      "_id": "1",
      "_source":{
         "passage_text": "hello world"
      }
    }
  ]
}

----------------------------------------

TITLE: Configuring OpenSearch YAML File
DESCRIPTION: This YAML snippet shows example configurations for the opensearch.yml file, including data and log paths, and disabling the security plugin.

LANGUAGE: yaml
CODE:
path.data: /var/lib/opensearch
path.logs: /var/log/opensearch
plugins.security.disabled: true

----------------------------------------

TITLE: Full-text Query for Phrase Search in OpenSearch
DESCRIPTION: Shows a full-text query using match for searching 'To be, or not to be' in the text_entry field. Demonstrates how the query is analyzed and tokenized for better search results.

LANGUAGE: json
CODE:
GET shakespeare/_search
{
  "query": {
    "match": {
      "text_entry": "To be, or not to be"
    }
  }
}

----------------------------------------

TITLE: Case-Insensitive Term Query in OpenSearch
DESCRIPTION: Shows how to perform a case-insensitive term query search using the case_insensitive parameter.

LANGUAGE: json
CODE:
GET shakespeare/_search
{
  "query": {
    "term": {
      "speaker": {
        "value": "HAMLET",
        "case_insensitive": true
      }
    }
  }
}

----------------------------------------

TITLE: Ingesting Documents into OpenSearch Vector Index
DESCRIPTION: These requests ingest sample documents into the created vector index, which will automatically generate embeddings using the configured pipeline.

LANGUAGE: json
CODE:
PUT /my-nlp-index/_doc/1
{
  "text": "A man who is riding a wild horse in the rodeo is very near to falling off ."
}

LANGUAGE: json
CODE:
PUT /my-nlp-index/_doc/2
{
  "text": "A rodeo cowboy , wearing a cowboy hat , is being thrown off of a wild white horse ."
}

LANGUAGE: json
CODE:
PUT /my-nlp-index/_doc/3
{
  "text": "People line the stands which advertise Freemont 's orthopedics , a cowboy rides a light brown bucking bronco ."
}

----------------------------------------

TITLE: Performing a Vector Search on Nested Fields in OpenSearch
DESCRIPTION: This snippet demonstrates how to perform a vector search on nested fields in OpenSearch using the knn query type.

LANGUAGE: json
CODE:
GET my-knn-index-1/_search
{
  "query": {
    "nested": {
      "path": "nested_field",
      "query": {
        "knn": {
          "nested_field.my_vector": {
            "vector": [1,1,1],
            "k": 2
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Running securityadmin.sh with keystore and truststore
DESCRIPTION: This command demonstrates how to use securityadmin.sh with JKS keystore and truststore files.

LANGUAGE: bash
CODE:
./securityadmin.sh -cd ../../../config/opensearch-security -icl -nhnv
  -ts <path/to/truststore> -tspass <truststore password>
  -ks <path/to/keystore> -kspass <keystore password>

----------------------------------------

TITLE: Multi-search Example Response
DESCRIPTION: Sample response showing the results of multiple search requests executed in parallel, including hits and metadata for each search.

LANGUAGE: json
CODE:
{
  "took" : 2150,
  "responses" : [
    {
      "took" : 2149,
      "timed_out" : false,
      "_shards" : {
        "total" : 1,
        "successful" : 1,
        "skipped" : 0,
        "failed" : 0
      },
      "hits" : {
        "total" : {
          "value" : 10000,
          "relation" : "gte"
        },
        "max_score" : 1.0,
        "hits" : [
          {
            "_index" : "opensearch_dashboards_sample_data_logs",
            "_id" : "_fnhBXsBgv2Zxgu9dZ8Y",
            "_score" : 1.0,
            "_source" : {
              "agent" : "Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR 1.1.4322)",
              "bytes" : 4657,
              "clientip" : "213.116.129.196",
              "extension" : "zip",
              "geo" : {
                "srcdest" : "CN:US",
                "src" : "CN",
                "dest" : "US",
                "coordinates" : {
                  "lat" : 42.35083333,
                  "lon" : -86.25613889
                }
              },
              "host" : "artifacts.opensearch.org",
              "index" : "opensearch_dashboards_sample_data_logs",
              "ip" : "213.116.129.196",
              "machine" : {
                "ram" : 16106127360,
                "os" : "ios"
              },
              "memory" : null,
              "message" : "213.116.129.196 - - [2018-07-30T14:12:11.387Z] \"GET /opensearch_dashboards/opensearch_dashboards-1.0.0-windows-x86_64.zip HTTP/1.1\" 200 4657 \"-\" \"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR 1.1.4322)\"",
              "phpmemory" : null,
              "referer" : "http://twitter.com/success/ellison-onizuka",
              "request" : "/opensearch_dashboards/opensearch_dashboards-1.0.0-windows-x86_64.zip",
              "response" : 200,
              "tags" : [
                "success",
                "info"
              ],
              "timestamp" : "2021-08-02T14:12:11.387Z",
              "url" : "https://artifacts.opensearch.org/downloads/opensearch_dashboards/opensearch_dashboards-1.0.0-windows-x86_64.zip",
              "utc_time" : "2021-08-02T14:12:11.387Z",
              "event" : {
                "dataset" : "sample_web_logs"
              }
            }
          }
        ]
      },
      "status" : 200
    }
  ]
}

----------------------------------------

TITLE: Deleting a Document from OpenSearch
DESCRIPTION: JavaScript code for deleting a document from OpenSearch using the client's delete method.

LANGUAGE: javascript
CODE:
var response = await client.delete({
  index: index_name,
  id: id,
});

----------------------------------------

TITLE: Pattern-based Field Masking in roles.yml
DESCRIPTION: Illustrates advanced pattern-based field masking using regular expressions and replacement strings. It includes examples for masking last names, IP addresses, and movie titles and genres.

LANGUAGE: yml
CODE:
hr_employee:
  index_permissions:
    - index_patterns:
      - 'humanresources'
      allowed_actions:
        - read
      masked_fields:
        - 'lastname::/.*/::*'
        - '*ip_source::/[0-9]{1,3}$/::XXX::/^[0-9]{1,3}/::***'
someonerole:
  index_permissions:
    - index_patterns:
      - 'movies'
      allowed_actions:
        - read
      masked_fields:
        - "title::/./::*"
        - "genres::/^[a-zA-Z]{1,3}/::XXX::/[a-zA-Z]{1,3}$/::YYY"

----------------------------------------

TITLE: Continuing a Conversation with Memory in OpenSearch
DESCRIPTION: This snippet shows how to continue a conversation by providing the same memory ID in a subsequent search. It demonstrates how the model uses previous context to answer related questions.

LANGUAGE: json
CODE:
GET /qa_demo/_search?search_pipeline=my-conversation-search-pipeline-openai
{
"query": {
    "match": {
    "text": "What's the population increase of Miami from 2021 to 2023?"
    }
},
"size": 1,
"_source": [
    "text"
],
"ext": {
    "generative_qa_parameters": {
    "llm_model": "gpt-4o",
    "llm_question": "compare population increase of New York City and Miami",
    "context_size": 5,
    "timeout": 15,
    "memory_id": "rBAbY5UBSzdNxlHvIyI3"
    }
}
}

----------------------------------------

TITLE: Applying Boolean Filter Query for Smartphones from BrandA in OpenSearch
DESCRIPTION: This snippet demonstrates how to use a Boolean query with filter clauses to search for smartphones from a specific brand (BrandA) in the electronics index.

LANGUAGE: json
CODE:
GET /electronics/_search
{
  "query": {
    "bool": {
      "filter": [
        { "term": { "brand": "BrandA" }},
        { "term": { "category": "Smartphone" }}
      ]
    }
  }
}

----------------------------------------

TITLE: Updating Dynamic Index Settings in OpenSearch
DESCRIPTION: This snippet demonstrates how to update a dynamic index setting, specifically the refresh interval, for an index named 'testindex'.

LANGUAGE: json
CODE:
PUT /testindex/_settings
{
  "index": {
    "refresh_interval": "2s"
  }
}

----------------------------------------

TITLE: Creating Text Chunking and Embedding Ingest Pipeline in OpenSearch
DESCRIPTION: This snippet demonstrates how to create an ingest pipeline that chunks text and generates embeddings. It uses a fixed token length algorithm for chunking and a text embedding processor for generating embeddings.

LANGUAGE: json
CODE:
PUT _ingest/pipeline/text-chunking-embedding-ingest-pipeline
{
  "description": "A text chunking and embedding ingest pipeline",
  "processors": [
    {
      "text_chunking": {
        "algorithm": {
          "fixed_token_length": {
            "token_limit": 10,
            "overlap_rate": 0.2,
            "tokenizer": "standard"
          }
        },
        "field_map": {
          "passage_text": "passage_chunk"
        }
      }
    },
    {
      "text_embedding": {
        "model_id": "LMLPWY4BROvhdbtgETaI",
        "field_map": {
          "passage_chunk": "passage_chunk_embedding"
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Searching Auto-generated Embeddings with Neural Query in OpenSearch
DESCRIPTION: Shows how to perform AI-powered search using the neural query type. The query requires query_text, model_id for the embedding model, and k parameter. Includes source exclusion for embedding fields.

LANGUAGE: json
CODE:
GET /my-ai-search-index/_search
{
  "_source": {
    "excludes": [
      "output_embedding"
    ]
  },
  "query": {
    "neural": {
      "output_embedding": {
        "query_text": "What is AI search?",
        "model_id": "mBGzipQB2gmRjlv_dOoB",
        "k": 2
      }
    }
  }
}

----------------------------------------

TITLE: Initializing OpenSearch Client with SSL/TLS
DESCRIPTION: Example of initializing OpenSearch client with SSL/TLS security configuration using Apache HttpClient 5.

LANGUAGE: java
CODE:
import javax.net.ssl.SSLContext;
import javax.net.ssl.SSLEngine;
// ... [additional imports]

public class OpenSearchClientExample {
  public static void main(String[] args) throws Exception {
    System.setProperty("javax.net.ssl.trustStore", "/full/path/to/keystore");
    System.setProperty("javax.net.ssl.trustStorePassword", "password-to-keystore");

    final HttpHost host = new HttpHost("https", "localhost", 9200);
    final BasicCredentialsProvider credentialsProvider = new BasicCredentialsProvider();
    credentialsProvider.setCredentials(new AuthScope(host), new UsernamePasswordCredentials("admin", "admin".toCharArray()));
    // ... [rest of the initialization code]
  }
}

----------------------------------------

TITLE: Executing an Agent Query for Tech News
DESCRIPTION: Sends a query to the registered agent asking about Vision Pro, demonstrating how the agent retrieves and processes information from the tech news knowledge base.

LANGUAGE: json
CODE:
POST _plugins/_ml/agents/your_agent_id/_execute
{
  "parameters": {
    "question": "What's vision pro",
    "verbose": true
  }
}

----------------------------------------

TITLE: Running OpenSearch with Docker Environment Variables
DESCRIPTION: Demonstrates how to specify environment variables when running OpenSearch in a Docker container.

LANGUAGE: bash
CODE:
docker run -e "OPENSEARCH_JAVA_OPTS=-Xms2g -Xmx2g" -e "OPENSEARCH_PATH_CONF=/usr/share/opensearch/config" opensearchproject/opensearch:latest

----------------------------------------

TITLE: Registering and Deploying a Sparse Encoding Model in OpenSearch
DESCRIPTION: This snippet demonstrates how to register and deploy a pretrained sparse encoding model in OpenSearch. It uses the 'amazon/neural-sparse/opensearch-neural-sparse-encoding-v2-distill' model.

LANGUAGE: json
CODE:
POST /_plugins/_ml/models/_register?deploy=true
{
  "name": "amazon/neural-sparse/opensearch-neural-sparse-encoding-v2-distill",
  "version": "1.0.0",
  "model_format": "TORCH_SCRIPT"
}

----------------------------------------

TITLE: Indexing Documents in OpenSearch
DESCRIPTION: Demonstrates how to index multiple documents into the 'students' and 'classes' indices.

LANGUAGE: json
CODE:
PUT students/_doc/1
{
  "name": "Jane Doe",
  "student_id" : "111"
}

LANGUAGE: json
CODE:
PUT classes/_doc/101
{
  "name": "CS101",
  "enrolled" : ["111" , "222"]
}

----------------------------------------

TITLE: Configuring SAML Authentication Domain in OpenSearch
DESCRIPTION: This YAML snippet shows how to configure a SAML authentication domain in the OpenSearch security config file. It includes settings for the HTTP authenticator, IdP metadata, and authentication backend.

LANGUAGE: yaml
CODE:
_meta:
  type: "config"
  config_version: 2

config:
  dynamic:
    authc:
      saml_auth_domain:
        http_enabled: true
        transport_enabled: false
        order: 1
        http_authenticator:
          type: saml
          challenge: true
          config:
            idp:
              metadata_file: okta.xml
              ...
        authentication_backend:
          type: noop

----------------------------------------

TITLE: Example of Field Masking in JSON Response
DESCRIPTION: Demonstrates how a search result with a masked field appears in JSON format. The 'title' field is replaced with a cryptographic hash.

LANGUAGE: json
CODE:
{
  "_index": "movies",
  "_source": {
    "year": 2013,
    "directors": [
      "Ron Howard"
    ],
    "title": "ca998e768dd2e6cdd84c77015feb29975f9f498a472743f159bec6f1f1db109e"
  }
}

----------------------------------------

TITLE: Creating AWS IAM Role Trust Policy for OpenSearch Service
DESCRIPTION: This JSON defines a custom trust policy for creating an IAM role that allows the OpenSearch service to assume the role. It's used when setting up S3_SOURCE as a remote threat intelligence data store.

LANGUAGE: bash
CODE:
{ 
   "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Principal": {
                "Service": [
                    "opensearchservice.amazonaws.com"
                ]
            },
            "Action": "sts:AssumeRole"
        }
    ]
}

----------------------------------------

TITLE: Custom Document Routing in OpenSearch
DESCRIPTION: Example of indexing a document with a custom routing value. The routing parameter determines which shard will store the document.

LANGUAGE: json
CODE:
POST /index1/_doc/1?routing=user1
{
  "name": "John Doe",
  "age": 20
}

----------------------------------------

TITLE: Creating Index Endpoint - OpenSearch
DESCRIPTION: Basic PUT endpoint format for creating an index in OpenSearch.

LANGUAGE: json
CODE:
PUT <index>

----------------------------------------

TITLE: Creating Claude Model Connector with Embedded Guardrails
DESCRIPTION: Configures a connector for Amazon Bedrock Claude model with embedded guardrails, including headers and post-processing logic for content filtering.

LANGUAGE: json
CODE:
{
  "name": "BedRock claude Connector",
  "description": "BedRock claude Connector",
  "version": 1,
  "protocol": "aws_sigv4",
  "parameters": {
      "region": "your_aws_region like us-east-1",
      "service_name": "bedrock",
      "max_tokens_to_sample": 8000,
      "temperature": 0.0001
  },
  "credential": {
      "access_key": "your_aws_access_key",
      "secret_key": "your_aws_secret_key",
      "session_token": "your_aws_session_token"
  },
  "actions": [
    {
      "action_type": "predict",
      "method": "POST",
      "url": "https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-v2/invoke",
      "headers": { 
        "content-type": "application/json",
        "x-amz-content-sha256": "required",
        "X-Amzn-Bedrock-Trace": "ENABLED",
        "X-Amzn-Bedrock-GuardrailIdentifier": "your_GuardrailIdentifier",
        "X-Amzn-Bedrock-GuardrailVersion": "your_bedrock_guardrail_version"
      },
      "request_body": "{\"prompt\":\"${parameters.prompt}\", \"max_tokens_to_sample\":${parameters.max_tokens_to_sample}, \"temperature\":${parameters.temperature},  \"anthropic_version\":\"${parameters.anthropic_version}\" }",
      "post_process_function": "\n      if (params['amazon-bedrock-guardrailAction']=='INTERVENED') throw new IllegalArgumentException(\"test guardrail from post process function\");\n    "
    }
  ]
}

----------------------------------------

TITLE: Basic Search Query without Collapsing
DESCRIPTION: Performs a basic search query to match items in the cakes category, sorted by price.

LANGUAGE: json
CODE:
GET /bakery-items/_search
{
  "query": {
    "match": {
      "category": "cakes"
    }
  },
  "sort": ["price"]
}

----------------------------------------

TITLE: Creating Two-Phase Search Pipeline - OpenSearch JSON
DESCRIPTION: Creates a search pipeline with a neural_sparse_two_phase_processor to accelerate neural sparse search operations. The processor is tagged and includes a description of its purpose.

LANGUAGE: json
CODE:
PUT /_search/pipeline/two_phase_search_pipeline
{
  "request_processors": [
    {
      "neural_sparse_two_phase_processor": {
        "tag": "neural-sparse",
        "description": "Creates a two-phase processor for neural sparse search."
      }
    }
  ]
}

----------------------------------------

TITLE: Creating Two-Phase Search Pipeline - OpenSearch JSON
DESCRIPTION: Creates a search pipeline with a neural_sparse_two_phase_processor to accelerate neural sparse search operations. The processor is tagged and includes a description of its purpose.

LANGUAGE: json
CODE:
PUT /_search/pipeline/two_phase_search_pipeline
{
  "request_processors": [
    {
      "neural_sparse_two_phase_processor": {
        "tag": "neural-sparse",
        "description": "Creates a two-phase processor for neural sparse search."
      }
    }
  ]
}

----------------------------------------

TITLE: Specifying Existing Search Pipeline in Query Parameter
DESCRIPTION: This snippet demonstrates how to specify an existing search pipeline in the query parameter of a GET request to OpenSearch. It uses the 'search_pipeline' parameter to indicate the pipeline to be used.

LANGUAGE: json
CODE:
GET /my_index/_search?search_pipeline=my_pipeline

----------------------------------------

TITLE: Configuring System Indexes in OpenSearch YAML Configuration
DESCRIPTION: This YAML configuration snippet shows how to enable system indexes and specify additional system index patterns in the opensearch.yml file. It includes indexes for various OpenSearch plugins that integrate with the Security plugin.

LANGUAGE: yml
CODE:
plugins.security.system_indices.enabled: true
plugins.security.system_indices.indices: [".opendistro-alerting-config", ".opendistro-alerting-alert*", ".opendistro-anomaly-results*", ".opendistro-anomaly-detector*", ".opendistro-anomaly-checkpoints", ".opendistro-anomaly-detection-state", ".opendistro-reports-*", ".opendistro-notifications-*", ".opendistro-notebooks", ".opendistro-asynchronous-search-response*"]

----------------------------------------

TITLE: Retrieving All Fields from an Index in OpenSearch SQL
DESCRIPTION: Example of using the SELECT * syntax to retrieve all fields from an index named 'accounts' in OpenSearch.

LANGUAGE: sql
CODE:
SELECT *
FROM accounts

----------------------------------------

TITLE: Testing Reranking with Cohere Rerank in OpenSearch
DESCRIPTION: Performs a search query using the created reranking pipeline to demonstrate the reranking of results based on relevance to the query.

LANGUAGE: json
CODE:
GET my-test-data/_search?search_pipeline=rerank_pipeline_cohere
{
  "query": {
    "match_all": {}
  },
  "size": 4,
  "ext": {
    "rerank": {
      "query_context": {
         "query_text": "What is the capital of the United States?"
      }
    }
  }
}

----------------------------------------

TITLE: Formatting JSON Payload for Custom Webhook in OpenSearch Alerting
DESCRIPTION: This snippet demonstrates how to format a JSON payload for a custom webhook notification in OpenSearch alerting. It uses Mustache templates to include dynamic monitor and trigger information in the message.

LANGUAGE: json
CODE:
{ "text": "Monitor {{ctx.monitor.name}} just entered alert status. Please investigate the issue. - Trigger: {{ctx.trigger.name}} - Severity: {{ctx.trigger.severity}} - Period start: {{ctx.periodStart}} - Period end: {{ctx.periodEnd}}" }

----------------------------------------

TITLE: Indexing Document with Array Field in OpenSearch
DESCRIPTION: Creates an index and adds a document with an array field that will be sorted.

LANGUAGE: json
CODE:
POST /my_index/_doc/1
{
  "message": ["one", "two", "three", "four"], 
  "visibility": "public"
}

----------------------------------------

TITLE: Configuring Hungarian Analyzer with Stem Exclusion
DESCRIPTION: Creates an index with a Hungarian analyzer that excludes specific words from stemming. Demonstrates how to maintain certain words in their original form during analysis.

LANGUAGE: json
CODE:
PUT index_with_stem_exclusion_hungarian_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "stem_exclusion_hungarian_analyzer": {
          "type": "hungarian",
          "stem_exclusion": ["hatalom", "jvhagys"]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Querying IP Ranges with OpenSearch Aggregations
DESCRIPTION: Example of using ip_range aggregation to group IP addresses into specified ranges. Demonstrates usage with explicit from/to ranges and CIDR mask notation.

LANGUAGE: json
CODE:
GET opensearch_dashboards_sample_data_logs/_search
{
  "size": 0,
  "aggs": {
    "access": {
      "ip_range": {
        "field": "ip",
        "ranges": [
          {
            "from": "1.0.0.0",
            "to": "126.158.155.183"
          },
          {
            "mask": "1.0.0.0/8"
          }
        ]
      }
    }
  }
}

----------------------------------------

TITLE: Configuring OpenTelemetry Metrics Anomaly Detection Pipeline in OpenSearch
DESCRIPTION: Pipeline configuration that processes OpenTelemetry metrics and performs anomaly detection. The pipeline filters GAUGE metrics named 'totalApiBytesSent' and applies the Random Cut Forest algorithm for anomaly detection.

LANGUAGE: json
CODE:
{
"entry-pipeline": {
  "source": {
    "otel_metrics_source": {}
  },
  "processor": [
    {
      "otel_metrics": {}
    }
  ],
  "route": [
    {
      "gauge_route": "/kind = \"GAUGE\" and /name = \"totalApiBytesSent\""
    }
  ],
  "sink": [
    {
      "pipeline": {
        "name": "ad-pipeline",
        "routes": [
          "gauge_route"
        ]
      }
    },
    {
      "opensearch": {
        "index": "otel-metrics"
      }
    }
  ]
}}

----------------------------------------

TITLE: High-Level Control Settings for Shard Indexing Backpressure
DESCRIPTION: Core settings to enable/disable shard indexing backpressure and control its enforcement mode. These settings determine whether the feature is active and if it actively rejects requests or operates in shadow mode.

LANGUAGE: yaml
CODE:
shard_indexing_pressure.enabled: false
shard_indexing_pressure.enforced: false

----------------------------------------

TITLE: Configuring Search Pipeline
DESCRIPTION: Creates a search pipeline with normalization processor for combining and reranking search results

LANGUAGE: json
CODE:
PUT /_search/pipeline/nlp-search-pipeline
{
  "description": "Post processor for hybrid search",
  "phase_results_processors": [
    {
      "normalization-processor": {
        "normalization": {
          "technique": "min_max"
        },
        "combination": {
          "technique": "arithmetic_mean",
          "parameters": {
            "weights": [
              0.3,
              0.7
            ]
          }
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Multiple Scoring Functions Query
DESCRIPTION: Combines multiple scoring functions including gauss, field_value_factor, and script_score to rank blog posts.

LANGUAGE: json
CODE:
GET blogs/_search
{
  "query": {
    "function_score": {
      "boost": "5", 
      "functions": [
        {
          "gauss": {
            "date_posted": {
              "origin": "2022-04-24",
              "offset": "1d",
              "scale": "6d"
            }
          }, 
          "weight": 1
        },
        {
          "gauss": {
            "likes": {
              "origin": 200,
              "scale": 200
            }
          }, 
          "weight": 4
        },
        {
          "gauss": {
            "views": {
              "origin": 1000,
              "scale": 800
            }
          }, 
          "weight": 2
        }
      ],
      "query": {
        "match": {
          "name": "opensearch data prepper"
        }
      },
      "max_boost": 10,
      "score_mode": "max",
      "boost_mode": "multiply",
      "min_score": 10
    }
  }
}

----------------------------------------

TITLE: Creating a rank features index for sparse vectors in OpenSearch
DESCRIPTION: This snippet demonstrates how to create an index in OpenSearch that can store sparse vector embeddings using the rank_features field type.

LANGUAGE: json
CODE:
PUT /my-nlp-index
{
  "mappings": {
    "properties": {
      "id": {
        "type": "text"
      },
      "passage_embedding": {
        "type": "rank_features"
      },
      "passage_text": {
        "type": "text"
      }
    }
  }
}

----------------------------------------

TITLE: Searching for Documents
DESCRIPTION: Use the Search class to construct and execute a query, combining filters and match conditions.

LANGUAGE: python
CODE:
s = Search(using=client, index=index_name) \
    .filter("term", year="2011") \
    .query("match", title="Moneyball")

response = s.execute()

----------------------------------------

TITLE: Basic Aggregation Query Structure in OpenSearch
DESCRIPTION: This snippet shows the general structure of an aggregation query in OpenSearch. It includes setting the size to 0 to focus on aggregation results and defines a named aggregation of a specific type.

LANGUAGE: json
CODE:
GET _search
{
  "size": 0,
  "aggs": {
    "NAME": {
      "AGG_TYPE": {}
    }
  }
}

----------------------------------------

TITLE: Creating Mapping with Object Field in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a mapping with an object field in OpenSearch. It defines a 'patient' object with 'name' and 'id' properties.

LANGUAGE: json
CODE:
PUT testindex1/_mappings
{
    "properties": {
      "patient": { 
        "properties" :
          {
            "name" : {
              "type" : "text"
            },
            "id" : {
              "type" : "keyword"
            }
          }   
      }
    }
}

----------------------------------------

TITLE: Configuring Vector Compression Level in OpenSearch
DESCRIPTION: Creates a vector field with custom compression level to optimize memory usage while maintaining search accuracy.

LANGUAGE: json
CODE:
PUT test-index
{
  "settings": {
    "index": {
      "knn": true
    }
  },
  "mappings": {
    "properties": {
      "my_vector": {
        "type": "knn_vector",
        "dimension": 3,
        "space_type": "l2",
        "mode": "on_disk",
        "compression_level": "16x"
      }
    }
  }
}

----------------------------------------

TITLE: Creating Index with Advanced Method-Based Space Type Configuration in OpenSearch
DESCRIPTION: Example of creating an OpenSearch index with detailed method configuration for k-NN vector search. Shows how to specify space type within a method object along with additional parameters like ef_search, ef_construction, and m.

LANGUAGE: json
CODE:
{
  "settings": {
    "index": {
      "knn": true,
      "knn.algo_param.ef_search": 100
    }
  },
  "mappings": {
    "properties": {
      "my_vector1": {
        "type": "knn_vector",
        "dimension": 1024,
        "method": {
          "name": "hnsw",
          "space_type": "l2",
          "engine": "nmslib",
          "parameters": {
            "ef_construction": 128,
            "m": 24
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Searching Documents Without Pipeline
DESCRIPTION: Basic search query without using the search pipeline.

LANGUAGE: json
CODE:
GET /my_index/_search

----------------------------------------

TITLE: Hybrid Search with Aggregations Query
DESCRIPTION: Executes a hybrid search query combined with sum and terms aggregations. The query filters documents by category while calculating the total price and gathering keyword statistics.

LANGUAGE: json
CODE:
GET /my-nlp-index/_search?search_pipeline=nlp-search-pipeline
{
  "query": {
    "hybrid": {
      "queries": [
        {
          "term": {
            "category": "permission"
          }
        },
        {
          "bool": {
            "should": [
              {
                "term": {
                  "category": "editor"
                }
              },
              {
                "term": {
                  "category": "statement"
                }
              }
            ]
          }
        }
      ]
    }
  },
  "aggs": {
    "total_price": {
      "sum": {
        "field": "doc_price"
      }
    },
    "keywords": {
      "terms": {
        "field": "doc_keyword",
        "size": 10
      }
    }
  }
}

----------------------------------------

TITLE: Data Stream Template Definition
DESCRIPTION: Shows how to configure an index template for use with data streams.

LANGUAGE: json
CODE:
PUT /_index_template/template_1
{
  "index_patterns": ["logs-*"],
  "data_stream": { }
}

----------------------------------------

TITLE: Prefix Matching Query in OpenSearch
DESCRIPTION: Demonstrates how to use the match_phrase_prefix query to implement prefix matching for autocomplete functionality. This method finds documents that match the last term in a query string.

LANGUAGE: json
CODE:
GET shakespeare/_search
{
  "query": {
    "match_phrase_prefix": {
      "text_entry": {
        "query": "qui",
        "slop": 3,
        "max_expansions": 10
      }
    }
  }
}

----------------------------------------

TITLE: Basic Search Query with match_all
DESCRIPTION: Demonstrates how to retrieve all documents from an index using the match_all query

LANGUAGE: json
CODE:
GET /students/_search
{
  "query": {
    "match_all": {}
  }
}

----------------------------------------

TITLE: Running a RAG Search with Memory in OpenSearch
DESCRIPTION: This snippet demonstrates how to perform a RAG search while storing the conversation history in a memory. It includes the memory ID in the generative QA parameters.

LANGUAGE: json
CODE:
GET /qa_demo/_search?search_pipeline=my-conversation-search-pipeline-openai
{
"query": {
    "match": {
    "text": "What's the population increase of New York City from 2021 to 2023?"
    }
},
"size": 1,
"_source": [
    "text"
],
"ext": {
    "generative_qa_parameters": {
    "llm_model": "gpt-4o",
    "llm_question": "What's the population increase of New York City from 2021 to 2023?",
    "context_size": 5,
    "timeout": 15,
    "memory_id": "rBAbY5UBSzdNxlHvIyI3"
    }
}
}

----------------------------------------

TITLE: Generic Fuzzy Query Template
DESCRIPTION: Template showing the basic structure of a fuzzy query with field parameter placeholder.

LANGUAGE: json
CODE:
GET _search
{
  "query": {
    "fuzzy": {
      "<field>": {
        "value": "sample",
        ...
      }
    }
  }
}

----------------------------------------

TITLE: Creating a Student Document in OpenSearch JSON Format
DESCRIPTION: Example showing how to structure a basic document representing a student record in OpenSearch's JSON format. Contains fields for name, GPA, and graduation year.

LANGUAGE: json
CODE:
{
  "name": "John Doe",
  "gpa": 3.89,
  "grad_year": 2022
}

----------------------------------------

TITLE: Boolean Filter with ANN Search in OpenSearch
DESCRIPTION: Example of a k-NN search query combined with Boolean filters to find hotels based on location, rating, and parking availability. The query returns the closest hotels to a specified location vector that have ratings between 8-10 and provide parking.

LANGUAGE: json
CODE:
POST /hotels-index/_search
{
  "size": 3,
  "query": {
    "bool": {
      "filter": {
        "bool": {
          "must": [
            {
              "range": {
                "rating": {
                  "gte": 8,
                  "lte": 10
                }
              }
            },
            {
              "term": {
                "parking": "true"
              }
            }
          ]
        }
      },
      "must": [
        {
          "knn": {
            "location": {
              "vector": [
                5,
                4
              ],
              "k": 20
            }
          }
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Registering a sparse encoding model for doc-only mode
DESCRIPTION: Registers the amazon/neural-sparse/opensearch-neural-sparse-encoding-doc-v2-distill model for use in doc-only mode neural sparse search.

LANGUAGE: json
CODE:
POST /_plugins/_ml/models/_register?deploy=true
{
  "name": "amazon/neural-sparse/opensearch-neural-sparse-encoding-doc-v2-distill",
  "version": "1.0.0",
  "model_format": "TORCH_SCRIPT"
}

----------------------------------------

TITLE: Setting OpenSearch Java Home Path
DESCRIPTION: Sets the OPENSEARCH_JAVA_HOME environment variable to specify a custom Java installation path for OpenSearch.

LANGUAGE: bash
CODE:
export OPENSEARCH_JAVA_HOME=/path/to/opensearch-{{site.opensearch_version}}/jdk

----------------------------------------

TITLE: Executing Hybrid Search Query
DESCRIPTION: Performs a hybrid search combining neural and match queries with a specified search pipeline

LANGUAGE: json
CODE:
GET /my-nlp-index/_search?search_pipeline=nlp-search-pipeline
{
  "_source": {
    "exclude": [
      "passage_embedding"
    ]
  },
  "query": {
    "hybrid": {
      "queries": [
        {
          "match": {
            "passage_text": {
              "query": "Hi world"
            }
          }
        },
        {
          "neural": {
            "passage_embedding": {
              "query_text": "Hi world",
              "model_id": "aVeif4oB5Vm0Tdw8zYO2",
              "k": 5
            }
          }
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Filtered Radial Search with Max Distance in OpenSearch
DESCRIPTION: Executes a radial search with both max_distance parameter and a price range filter to narrow down results.

LANGUAGE: json
CODE:
GET knn-index-test/_search
{
  "query": {
    "knn": {
      "my_vector": {
        "vector": [7.1, 8.3],
        "max_distance": 2,
        "filter": {
          "range": {
            "price": {
              "gte": 1,
              "lte": 5
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Refining Aggregations with Aggregation-Level Filtering in OpenSearch
DESCRIPTION: This snippet demonstrates how to apply filters to specific aggregations without affecting the main aggregation, showing price ranges for selected brands and overall price ranges for all products.

LANGUAGE: json
CODE:
GET /electronics/_search
{
  "query": {
    "bool": {
      "filter": { "term": { "category": "Smartphone" }}
    }
  },
  "aggs": {
    "price_ranges": {
      "range": {
        "field": "price",
        "ranges": [
          { "to": 500 },
          { "from": 500, "to": 1000 },
          { "from": 1000 }
        ]
      }
    },
    "filtered_brands": {
      "filter": {
        "terms": { "brand": ["BrandA", "BrandB"] }
      },
      "aggs": {
        "price_ranges": {
          "range": {
            "field": "price",
            "ranges": [
              { "to": 500 },
              { "from": 500, "to": 1000 },
              { "from": 1000 }
            ]
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Simple k-NN Search Query
DESCRIPTION: Example of a basic k-NN search query searching for 3 nearest neighbors using a 2-dimensional vector.

LANGUAGE: json
CODE:
GET /my-vector-index/_search
{
  "query": {
    "knn": {
      "my_vector": {
        "vector": [1.5, 2.5],
        "k": 3
      }
    }
  }
}

----------------------------------------

TITLE: Setting OpenSearch Shell Environment Variables
DESCRIPTION: Shows how to configure OpenSearch environment variables directly in the shell environment before starting the service.

LANGUAGE: bash
CODE:
export OPENSEARCH_JAVA_OPTS="-Xms2g -Xmx2g"
export OPENSEARCH_PATH_CONF="/etc/opensearch"
./opensearch

----------------------------------------

TITLE: Advanced Fuzzy Query with Parameters
DESCRIPTION: Extended fuzzy query example with custom parameters including fuzziness, max_expansions, prefix_length, transpositions, and rewrite method.

LANGUAGE: json
CODE:
GET shakespeare/_search
{
  "query": {
    "fuzzy": {
      "speaker": {
        "value": "HALET",
        "fuzziness": "2",
        "max_expansions": 40,
        "prefix_length": 0,
        "transpositions": true,
        "rewrite": "constant_score"
      }
    }
  }
}

----------------------------------------

TITLE: Enabling Agent Framework and RAG Settings in YAML
DESCRIPTION: YAML configuration settings to enable the agent framework and retrieval-augmented generation (RAG) functionality in OpenSearch Assistant.

LANGUAGE: yaml
CODE:
plugins.ml_commons.agent_framework_enabled: true
plugins.ml_commons.rag_pipeline_feature_enabled: true

----------------------------------------

TITLE: Listing Installed OpenSearch Plugins
DESCRIPTION: Command to list all currently installed OpenSearch plugins using the opensearch-plugin tool.

LANGUAGE: bash
CODE:
bin/opensearch-plugin list

----------------------------------------

TITLE: Deleting Documents with Bulk Helper in OpenSearch JavaScript Client
DESCRIPTION: Shows how to use the bulk helper to delete documents from an OpenSearch index.

LANGUAGE: javascript
CODE:
client.helpers.bulk({
  datasource: arrayOfDocuments,
  onDocument (doc) {
    return {
      delete: { _index: 'example-index', _id: doc.id }
    }
  }
})

----------------------------------------

TITLE: Named Query Parameters in Boolean Search
DESCRIPTION: Demonstrates how to use _name parameter to identify which clauses matched in the search results.

LANGUAGE: json
CODE:
GET shakespeare/_search
{
  "query": {
    "bool": {
      "must": [
        {
          "match": {
            "text_entry": {
              "query": "love",
              "_name": "love-must"
            }
          }
        }
      ],
      "should": [
        {
          "match": {
            "text_entry": {
              "query": "life",
              "_name": "life-should"
            }
          }
        },
        {
          "match": {
            "text_entry": {
              "query": "grace",
              "_name": "grace-should"
            }
          }
        }
      ],
      "minimum_should_match": 1,
      "must_not": [
        {
          "match": {
            "speaker": {
              "query": "ROMEO",
              "_name": "ROMEO-must-not"
            }
          }
        }
      ],
      "filter": {
        "term": {
          "play_name": "Romeo and Juliet"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating Index Template with Aliases
DESCRIPTION: Example of creating an index template with index aliases, including filter and routing settings.

LANGUAGE: json
CODE:
PUT _index_template/alias-template
{
  "index_patterns" : ["sh*"],
  "template": {
    "settings" : {
        "number_of_shards" : 1
    },
    "aliases" : {
        "alias1" : {},
        "alias2" : {
            "filter" : {
                "term" : {"user.id" : "hamlet" }
            },
            "routing" : "shard-1"
        },
        "{index}-alias" : {} 
    }
  }
}

----------------------------------------

TITLE: OpenSearch Configuration Settings
DESCRIPTION: Basic OpenSearch configuration settings for network binding and discovery type.

LANGUAGE: bash
CODE:
network.host: 0.0.0.0
discovery.type: single-node
plugins.security.disabled: false

----------------------------------------

TITLE: Installing OpenSearch with Docker
DESCRIPTION: Downloads and runs OpenSearch in a Docker container, exposing ports 9200 and 9600, and disabling security for demonstration purposes.

LANGUAGE: bash
CODE:
docker pull opensearchproject/opensearch:latest && docker run -it -p 9200:9200 -p 9600:9600 -e "discovery.type=single-node" -e "DISABLE_SECURITY_PLUGIN=true" opensearchproject/opensearch:latest

----------------------------------------

TITLE: Filtering and k-NN Search with Scoring Script in OpenSearch
DESCRIPTION: Demonstrates how to perform a compound search that first filters documents based on specific criteria (hotel rating and parking availability) and then performs a k-NN search to find the closest matches based on location. The query returns the top 3 results using L2 (Euclidean) distance calculation.

LANGUAGE: json
CODE:
{
  "size": 3,
  "query": {
    "script_score": {
      "query": {
        "bool": {
          "filter": {
            "bool": {
              "must": [
                {
                  "range": {
                    "rating": {
                      "gte": 8,
                      "lte": 10
                    }
                  }
                },
                {
                  "term": {
                    "parking": "true"
                  }
                }
              ]
            }
          }
        }
      },
      "script": {
        "source": "knn_score",
        "lang": "knn",
        "params": {
          "field": "location",
          "query_value": [
            5.0,
            4.0
          ],
          "space_type": "l2"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Has Child Query Example - OpenSearch JSON
DESCRIPTION: Basic has_child query to find parent documents (brands) based on matching child documents (products containing 'watch').

LANGUAGE: json
CODE:
GET testindex1/_search
{
  "query" : {
    "has_child": {
      "type":"product",
      "query": {
        "match" : {
            "name": "watch"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating a Vector Index in OpenSearch
DESCRIPTION: This request creates a vector index with KNN enabled and configures it to use the previously created ingest pipeline for automatic embedding generation.

LANGUAGE: json
CODE:
PUT /my-nlp-index
{
  "settings": {
    "index.knn": true,
    "default_pipeline": "nlp-ingest-pipeline"
  },
  "mappings": {
    "properties": {
      "passage_embedding": {
        "type": "knn_vector",
        "dimension": 768,
        "space_type": "l2"
      },
      "text": {
        "type": "text"
      }
    }
  }
}

----------------------------------------

TITLE: Indexing Documents for Weighted Average Calculation in OpenSearch
DESCRIPTION: Creates an index named 'products' and indexes three sample documents with 'name', 'rating', and 'num_reviews' fields to demonstrate the weighted average aggregation.

LANGUAGE: json
CODE:
PUT /products

POST /products/_doc/1
{
  "name": "Product A",
  "rating": 4,
  "num_reviews": 100
}

POST /products/_doc/2
{
  "name": "Product B",
  "rating": 5,
  "num_reviews": 20
}

POST /products/_doc/3
{
  "name": "Product C",
  "rating": 3,
  "num_reviews": 50
}

----------------------------------------

TITLE: Basic Multi-Match Query in OpenSearch
DESCRIPTION: Example of a basic multi-match query that searches across description and item_name fields using the search text variable.

LANGUAGE: json
CODE:
{
  "query": {
    "multi_match": {
      "query": "%SearchText%",
      "fields": [ "description", "item_name" ]
    }
  }
}

----------------------------------------

TITLE: Comparing Text Similarity Using Min Hash in Python
DESCRIPTION: This Python script demonstrates how to use the min_hash analyzer to compare the similarity of two text strings. It uses the OpenSearch Python client to analyze the texts and calculate their Jaccard similarity based on the generated min hash tokens.

LANGUAGE: python
CODE:
from opensearchpy import OpenSearch
from requests.auth import HTTPBasicAuth

# Initialize the OpenSearch client with authentication
host = 'https://localhost:9200'  # Update if using a different host/port
auth = ('admin', 'admin')  # Username and password

# Create the OpenSearch client with SSL verification turned off
client = OpenSearch(
    hosts=[host],
    http_auth=auth,
    use_ssl=True,
    verify_certs=False,  # Disable SSL certificate validation
    ssl_show_warn=False  # Suppress SSL warnings in the output
)

# Analyzes text and returns the minhash tokens
def analyze_text(index, text):
    response = client.indices.analyze(
        index=index,
        body={
            "analyzer": "minhash_analyzer",
            "text": text
        }
    )
    return [token['token'] for token in response['tokens']]

# Analyze two similar texts
tokens_1 = analyze_text('minhash_index', 'OpenSearch is a powerful search engine.')
tokens_2 = analyze_text('minhash_index', 'OpenSearch is a very powerful search engine.')

# Calculate Jaccard similarity
set_1 = set(tokens_1)
set_2 = set(tokens_2)
shared_tokens = set_1.intersection(set_2)
jaccard_similarity = len(shared_tokens) / len(set_1.union(set_2))

print(f"Jaccard Similarity: {jaccard_similarity}")

----------------------------------------

TITLE: Defining IAM Role Permissions for Connector Creation
DESCRIPTION: This JSON snippet specifies the permissions for the IAM role to create a connector in OpenSearch Service.

LANGUAGE: json
CODE:
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": "iam:PassRole",
            "Resource": "your_iam_role_arn_created_in_step1"
        },
        {
            "Effect": "Allow",
            "Action": "es:ESHttpPost",
            "Resource": "your_opensearch_domain_arn"
        }
    ]
}

----------------------------------------

TITLE: Term-level Query for Phrase Search in OpenSearch
DESCRIPTION: Demonstrates a term-level query searching for an exact phrase 'To be, or not to be' in the text_entry field. Shows why term-level queries are not suitable for analyzed text fields.

LANGUAGE: json
CODE:
GET shakespeare/_search
{
  "query": {
    "term": {
      "text_entry": "To be, or not to be"
    }
  }
}

----------------------------------------

TITLE: Installing OpenSearch Package with Custom Admin Password
DESCRIPTION: Command to install the OpenSearch Debian package and set a custom admin password for versions 2.12 and later.

LANGUAGE: bash
CODE:
sudo env OPENSEARCH_INITIAL_ADMIN_PASSWORD=<custom-admin-password> dpkg -i opensearch-{{site.opensearch_version}}-linux-x64.deb

----------------------------------------

TITLE: Creating On-Disk Vector Index in OpenSearch
DESCRIPTION: Creates a vector index using on-disk mode for low-cost search with specified dimension and space type.

LANGUAGE: json
CODE:
PUT test-index
{
  "settings": {
    "index": {
      "knn": true
    }
  },
  "mappings": {
    "properties": {
      "my_vector": {
        "type": "knn_vector",
        "dimension": 3,
        "space_type": "l2",
        "mode": "on_disk"
      }
    }
  }
}

----------------------------------------

TITLE: Enabling SSL/TLS for REST Layer in OpenSearch
DESCRIPTION: Configuration setting to enable SSL/TLS encryption for the REST layer communication in OpenSearch. This setting is essential for securing HTTP traffic.

LANGUAGE: yaml
CODE:
plugins.security.ssl.http.enabled: true

----------------------------------------

TITLE: Amazon Bedrock Connector with Custom Pre- and Post-Processing Functions
DESCRIPTION: This JSON example demonstrates creating an Amazon Bedrock connector for the Titan embedding model. It includes custom pre- and post-processing functions written in Painless script to handle specific input and output formats.

LANGUAGE: json
CODE:
{
  "name": "Amazon Bedrock Connector: embedding",
  "description": "The connector to the Bedrock Titan embedding model",
  "version": 1,
  "protocol": "aws_sigv4",
  "parameters": {
    "region": "<YOUR AWS REGION>",
    "service_name": "bedrock"
  },
  "credential": {
    "access_key": "<YOUR AWS ACCESS KEY>",
    "secret_key": "<YOUR AWS SECRET KEY>",
    "session_token": "<YOUR AWS SECURITY TOKEN>"
  },
  "actions": [
    {
      "action_type": "predict",
      "method": "POST",
      "url": "https://bedrock-runtime.us-east-1.amazonaws.com/model/amazon.titan-embed-text-v1/invoke",
      "headers": {
        "content-type": "application/json",
        "x-amz-content-sha256": "required"
      },
      "request_body": "{ \"inputText\": \"${parameters.inputText}\" }",
      "pre_process_function": "\n    StringBuilder builder = new StringBuilder();\n    builder.append(\"\\\"\");\n    String first = params.text_docs[0];\n    builder.append(first);\n    builder.append(\"\\\"\");\n    def parameters = \"{\" +\"\\\"inputText\\\":\" + builder + \"}\";\n    return  \"{\" +\"\\\"parameters\\\":\" + parameters + \"}\";\n  ",
      "post_process_function": "\n      def name = \"sentence_embedding\";\n      def dataType = \"FLOAT32\";\n      if (params.embedding == null || params.embedding.length == 0) {\n        return params.message;\n      }\n      def shape = [params.embedding.length];\n      def json = \"{\" +\n                 \"\\\"name\\\":\\\"\" + name + \"\\\",\" +\n                 \"\\\"data_type\\\":\\\"\" + dataType + \"\\\",\" +\n                 \"\\\"shape\\\":\" + shape + \",\" +\n                 \"\\\"data\\\":\" + params.embedding +\n                 \"}\";\n      return json;\n    "
    }
  ]
}

----------------------------------------

TITLE: JSON Response Format for List Shards API in OpenSearch
DESCRIPTION: This snippet illustrates the JSON format of the response from the List Shards API. It includes a next_token for pagination and an array of shard information.

LANGUAGE: json
CODE:
{"next_token":"MTcyOTE5NTQ5NjM5N3wub3BlbnNlYXJjaC1zYXAtbG9nLXR5cGVzLWNvbmZpZw==","shards":[{"index":"plugins","shard":"0","prirep":"p","state":"STARTED","docs":"0","store":"208B","ip":"172.18.0.4","node":"odfe-node1"},{"index":"plugins","shard":"0","prirep":"r","state":"STARTED","docs":"0","store":"208B","ip":"172.18.0.3","node":"odfe-node2"}]}

----------------------------------------

TITLE: Executing ML Algorithm Endpoint in OpenSearch
DESCRIPTION: The endpoint for executing a machine learning algorithm in OpenSearch using the ML Commons plugin. Replace <algorithm_name> with the specific algorithm to run.

LANGUAGE: json
CODE:
POST _plugins/_ml/_execute/<algorithm_name>

----------------------------------------

TITLE: Constructing Ranking Evaluation Request in OpenSearch
DESCRIPTION: Demonstrates how to structure a request body for the rank evaluation endpoint in OpenSearch. The request includes multiple search queries with their respective relevance ratings for specific documents, allowing for comprehensive evaluation of search result quality.

LANGUAGE: json
CODE:
GET shakespeare/_rank_eval
{
  "requests": [
    {
      "id": "books_query",                        
      "request": {                                              
          "query": { "match": { "text": "thou" } }
      },
      "ratings": [                                              
        { "_index": "shakespeare", "_id": "80", "rating": 0 },
        { "_index": "shakespeare", "_id": "115", "rating": 1 },
        { "_index": "shakespeare", "_id": "117", "rating": 2 }
      ]
    },
    {
      "id": "words_query",
      "request": {
        "query": { "match": { "text": "art" } }
      },
      "ratings": [
        { "_index": "shakespeare", "_id": "115", "rating": 2 }
      ]
    }
  ]
}

----------------------------------------

TITLE: Retrieving Cluster Settings in OpenSearch
DESCRIPTION: This HTTP GET request retrieves all cluster settings in OpenSearch, including default settings.

LANGUAGE: http
CODE:
GET _cluster/settings?include_defaults=true

----------------------------------------

TITLE: Connecting to OpenSearch with Security Plugin
DESCRIPTION: JavaScript code for creating a client object to connect to OpenSearch with the Security plugin enabled. Includes SSL/TLS configuration.

LANGUAGE: javascript
CODE:
var host = "localhost";
var protocol = "https";
var port = 9200;
var auth = "admin:<custom-admin-password>";
var ca_certs_path = "/full/path/to/root-ca.pem";

var { Client } = require("@opensearch-project/opensearch");
var fs = require("fs");
var client = new Client({
  node: protocol + "://" + auth + "@" + host + ":" + port,
  ssl: {
    ca: fs.readFileSync(ca_certs_path),
  },
});

----------------------------------------

TITLE: Random Score Function Query
DESCRIPTION: Uses the random_score function to provide consistent random scores for documents.

LANGUAGE: json
CODE:
GET blogs/_search
{
  "query": {
    "function_score": {
      "random_score": {
        "seed": 20,
        "field": "_seq_no"
      }
    }
  }
}

----------------------------------------

TITLE: Creating a Search Pipeline in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a search pipeline with request and response processors. The pipeline filters queries to show only public documents and renames a field in the response.

LANGUAGE: json
CODE:
PUT /_search/pipeline/my_pipeline 
{
  "request_processors": [
    {
      "filter_query" : {
        "tag" : "tag1",
        "description" : "This processor is going to restrict to publicly visible documents",
        "query" : {
          "term": {
            "visibility": "public"
          }
        }
      }
    }
  ],
  "response_processors": [
    {
      "rename_field": {
        "field": "message",
        "target_field": "notification"
      }
    }
  ]
}

----------------------------------------

TITLE: Creating a Connector for a Specific OpenAI Model in OpenSearch
DESCRIPTION: Example request to create a connector for a specific OpenAI model using the _plugins/_ml/models/_register endpoint. This connector is embedded within the model configuration and can only be used with this particular model.

LANGUAGE: json
CODE:
POST /_plugins/_ml/models/_register
{
    "name": "openAI-GPT-3.5 model with a connector",
    "function_name": "remote",
    "model_group_id": "lEFGL4kB4ubqQRzegPo2",
    "description": "test model",
    "connector": {
        "name": "OpenAI Connector",
        "description": "The connector to public OpenAI model service for GPT 3.5",
        "version": 1,
        "protocol": "http",
        "parameters": {
            "endpoint": "api.openai.com",
            "max_tokens": 7,
            "temperature": 0,
            "model": "text-davinci-003"
        },
        "credential": {
            "openAI_key": "..."
        },
        "actions": [
            {
                "action_type": "predict",
                "method": "POST",
                "url": "https://${parameters.endpoint}/v1/completions",
                "headers": {
                    "Authorization": "Bearer ${credential.openAI_key}"
                },
                "request_body": "{ \"model\": \"${parameters.model}\", \"prompt\": \"${parameters.prompt}\", \"max_tokens\": ${parameters.max_tokens}, \"temperature\": ${parameters.temperature} }"
            }
        ]
    }
}

----------------------------------------

TITLE: Creating a query-level monitor in OpenSearch
DESCRIPTION: Creates a new query-level monitor that runs a search query and triggers an alert based on the results. Includes schedule, input, trigger condition, and actions.

LANGUAGE: json
CODE:
POST _plugins/_alerting/monitors
{
  "type": "monitor",
  "name": "test-monitor",
  "monitor_type": "query_level_monitor",
  "enabled": true,
  "schedule": {
    "period": {
      "interval": 1,
      "unit": "MINUTES"
    }
  },
  "inputs": [{
    "search": {
      "indices": ["movies"],
      "query": {
        "size": 0,
        "aggregations": {},
        "query": {
          "bool": {
            "filter": {
              "range": {
                "@timestamp": {
                  "gte": "{{period_end}}||-1h",
                  "lte": "{{period_end}}",
                  "format": "epoch_millis"
                }
              }
            }
          }
        }
      }
    }
  }],
  "triggers": [{
    "name": "test-trigger",
    "severity": "1",
    "condition": {
      "script": {
        "source": "ctx.results[0].hits.total.value > 0",
        "lang": "painless"
      }
    },
    "actions": [{
      "name": "test-action",
      "destination_id": "ld7912sBlQ5JUWWFThoW",
      "message_template": {
        "source": "This is my message body."
      },
      "throttle_enabled": true,
      "throttle": {
        "value": 27,
        "unit": "MINUTES"
      },
      "subject_template": {
        "source": "TheSubject"
      }
    }]
  }]
}

----------------------------------------

TITLE: Creating an Outer Pipeline
DESCRIPTION: Creates a pipeline that references the previously defined general pipeline.

LANGUAGE: json
CODE:
{
  "description": "an outer pipeline referencing the general pipeline",
  "processors": [
    {
      "pipeline": {
        "name": "general-pipeline"
      }
    }
  ]
}

----------------------------------------

TITLE: Configuring Super Admin DN in OpenSearch
DESCRIPTION: YAML configuration to define admin distinguished names (DN) for super admin authentication in OpenSearch.

LANGUAGE: yaml
CODE:
plugins.security.authcz.admin_dn:
- CN=kirk,OU=client,O=client,L=test, C=de

----------------------------------------

TITLE: Importing opensearch-py-ml in Python
DESCRIPTION: This code snippet demonstrates how to import the OpenSearch client and the opensearch-py-ml module in a Python script. This is typically done at the beginning of your Python file or Jupyter notebook.

LANGUAGE: python
CODE:
from opensearchpy import OpenSearch
import opensearch_py_ml as oml

----------------------------------------

TITLE: Creating OpenSearch ML Connector Configuration
DESCRIPTION: JSON configuration for creating an OpenSearch ML connector to interface with the SageMaker model endpoint.

LANGUAGE: json
CODE:
{
  "name": "Sagemakre cross-encoder model",
  "description": "Test connector for Sagemaker cross-encoder model",
  "version": 1,
  "protocol": "aws_sigv4",
  "credential": {
    "access_key": "your_access_key",
    "secret_key": "your_secret_key",
    "session_token": "your_session_token"
  },
  "parameters": {
    "region": "your_sagemaker_model_region_like_us-west-2",
    "service_name": "sagemaker"
  },
  "actions": [...]
}

----------------------------------------

TITLE: Executing Terms Aggregation on Response Codes in OpenSearch
DESCRIPTION: This snippet demonstrates how to use the terms aggregation to find the number of documents per response code in web log data. It sets a size of 10 for the number of buckets to return.

LANGUAGE: json
CODE:
GET opensearch_dashboards_sample_data_logs/_search
{
  "size": 0,
  "aggs": {
    "response_codes": {
      "terms": {
        "field": "response.keyword",
        "size": 10
      }
    }
  }
}

----------------------------------------

TITLE: Querying Multiple OpenSearch Indexes Using SQL REST API
DESCRIPTION: Shows how to query multiple OpenSearch indexes using a comma-separated list in the SQL query via the REST API.

LANGUAGE: json
CODE:
POST _plugins/_sql
{
  "query": "SELECT * FROM my-index1,myindex2,myindex3 LIMIT 50"
}

----------------------------------------

TITLE: Performing Bulk Operations
DESCRIPTION: Use the bulk() method to perform multiple operations (index, create, update) in a single API call.

LANGUAGE: python
CODE:
movies = '{ "index" : { "_index" : "my-dsl-index", "_id" : "2" } } \n { "title" : "Interstellar", "director" : "Christopher Nolan", "year" : "2014"} \n { "create" : { "_index" : "my-dsl-index", "_id" : "3" } } \n { "title" : "Star Trek Beyond", "director" : "Justin Lin", "year" : "2015"} \n { "update" : {"_id" : "3", "_index" : "my-dsl-index" } } \n { "doc" : {"year" : "2016"} }'

client.bulk(movies)

----------------------------------------

TITLE: Configuring Text Field Aggregations in OpenSearch
DESCRIPTION: This snippet demonstrates how to configure a text field for aggregations by adding a raw keyword field. This allows for aggregations on the original, untokenized text.

LANGUAGE: json
CODE:
PUT movies
{
  "mappings": {
    "properties": {
      "title": {
        "type": "text",
        "fielddata": true,
        "fields": {
          "raw": {
            "type": "keyword"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating an Index with Limit Token Filter in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a new index named 'my_index' with an analyzer that uses a custom 'limit' token filter. The filter is configured to limit the output to a maximum of 3 tokens.

LANGUAGE: json
CODE:
PUT my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "three_token_limit": {
          "tokenizer": "standard",
          "filter": [ "custom_token_limit" ]
        }
      },
      "filter": {
        "custom_token_limit": {
          "type": "limit",
          "max_token_count": 3
        }
      }
    }
  }
}

----------------------------------------

TITLE: Basic Neural Query Structure in OpenSearch
DESCRIPTION: Basic structure of a neural query showing required and optional fields for vector field search

LANGUAGE: json
CODE:
"neural": {
  "<vector_field>": {
    "query_text": "<query_text>",
    "query_image": "<image_binary>",
    "model_id": "<model_id>",
    "k": 100
  }
}

----------------------------------------

TITLE: Basic Match All Query in OpenSearch
DESCRIPTION: Demonstrates the simplest form of OpenSearch query that matches all documents in an index using match_all query type.

LANGUAGE: json
CODE:
GET testindex/_search
{
  "query": {
     "match_all": { 
     }
  }
}

----------------------------------------

TITLE: Configuring k-NN Vector with Method Definition in OpenSearch
DESCRIPTION: This example demonstrates how to configure a k-NN vector field using a method definition, specifying the HNSW algorithm with Faiss implementation.

LANGUAGE: json
CODE:
PUT test-index
{
  "settings": {
    "index": {
      "knn": true,
      "knn.algo_param.ef_search": 100
    }
  },
  "mappings": {
    "properties": {
      "my_vector1": {
        "type": "knn_vector",
        "dimension": 1024,
        "method": {
          "name": "hnsw",
          "space_type": "l2",
          "engine": "faiss",
          "parameters": {
            "ef_construction": 100,
            "m": 16
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Role Definition Structure in OpenSearch
DESCRIPTION: YAML template showing the structure for defining roles with cluster and index permissions.

LANGUAGE: yaml
CODE:
<rolename>:
  cluster_permissions:
    - <cluster permission>
  index_permissions:
    - index_patterns:
      - <index pattern>
      allowed_actions:
        - <index permissions>

----------------------------------------

TITLE: Creating a Customized Snapshot in OpenSearch
DESCRIPTION: This example shows how to create a snapshot with specific settings, including selecting indices, ignoring unavailable indices, and excluding global state using a PUT request with a JSON body.

LANGUAGE: json
CODE:
PUT _snapshot/my-s3-repository/2
{
  "indices": "opensearch-dashboards*,my-index*,-my-index-2016",
  "ignore_unavailable": true,
  "include_global_state": false,
  "partial": false
}

----------------------------------------

TITLE: Displaying Relevance Score in OpenSearch Results
DESCRIPTION: Example showing the structure of a search result hit including the _score field that indicates document relevance.

LANGUAGE: json
CODE:
"hits" : [
      {
        "_index" : "shakespeare",
        "_id" : "32437",
        "_score" : 18.781435,
        "_source" : {
          "type" : "line",
          "line_id" : 32438,
          "play_name" : "Hamlet",
          "speech_number" : 3,
          "line_number" : "1.1.3",
          "speaker" : "BERNARDO",
          "text_entry" : "Long live the king!"
        }
      },
...

----------------------------------------

TITLE: Starting Replication with Custom Roles in OpenSearch
DESCRIPTION: This curl command demonstrates how to start replication between clusters using custom roles. It includes the leader and follower cluster roles in the request body and uses basic authentication.

LANGUAGE: bash
CODE:
curl -XPUT -k -H 'Content-Type: application/json' -u 'replication_user:password' 'https://localhost:9200/_plugins/_replication/follower-01/_start?pretty' -d '
{
   "leader_alias": "leader-cluster",
   "leader_index": "leader-01",
   "use_roles":{
      "leader_cluster_role": "cross_cluster_replication_leader_full_access",
      "follower_cluster_role": "cross_cluster_replication_follower_full_access"
   }
}'

----------------------------------------

TITLE: Registering and Deploying a Pretrained Model in OpenSearch
DESCRIPTION: This request registers and deploys the DistilBERT model from Hugging Face for text embedding in OpenSearch.

LANGUAGE: json
CODE:
POST /_plugins/_ml/models/_register?deploy=true
{
  "name": "huggingface/sentence-transformers/msmarco-distilbert-base-tas-b",
  "version": "1.0.1",
  "model_format": "TORCH_SCRIPT"
}

----------------------------------------

TITLE: Installing OpenSearch Dashboards RPM Package
DESCRIPTION: These commands demonstrate how to install OpenSearch Dashboards RPM package using yum or rpm for both x64 and arm64 architectures.

LANGUAGE: bash
CODE:
# Install the x64 package using yum.
sudo yum install opensearch-dashboards-{{site.opensearch_version}}-linux-x64.rpm
# Install the x64 package using rpm.
sudo rpm -ivh opensearch-dashboards-{{site.opensearch_version}}-linux-x64.rpm

# Install the arm64 package using yum.
sudo yum install opensearch-dashboards-{{site.opensearch_version}}-linux-arm64.rpm
# Install the arm64 package using rpm.
sudo rpm -ivh opensearch-dashboards-{{site.opensearch_version}}-linux-arm64.rpm

----------------------------------------

TITLE: Complete Hybrid Search Query with Explain
DESCRIPTION: Full example of a hybrid search query combining text and neural search with the explain parameter enabled.

LANGUAGE: json
CODE:
POST my-nlp-index/_search?search_pipeline=my_pipeline&explain=true
{
  "_source": {
    "exclude": [
      "passage_embedding"
    ]
  },
  "query": {
    "hybrid": {
      "queries": [
        {
          "match": {
            "text": {
              "query": "horse"
            }
          }
        },
        {
          "neural": {
            "passage_embedding": {
              "query_text": "wild west",
              "model_id": "aVeif4oB5Vm0Tdw8zYO2",
              "k": 5
            }
          }
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Register Flow Agent - Example Request
DESCRIPTION: Example request body for registering a flow agent with vector database and ML model tools for RAG implementation.

LANGUAGE: json
CODE:
{
  "name": "Test_Agent_For_RAG",
  "type": "flow",
  "description": "this is a test agent",
  "tools": [
    {
      "name": "vector_tool",
      "type": "VectorDBTool",
      "parameters": {
        "model_id": "zBRyYIsBls05QaITo5ex",
        "index": "my_test_data",
        "embedding_field": "embedding",
        "source_field": [
          "text"
        ],
        "input": "${parameters.question}"
      }
    },
    {
      "type": "MLModelTool",
      "description": "A general tool to answer any question",
      "parameters": {
        "model_id": "NWR9YIsBUysqmzBdifVJ",
        "prompt": "\n\nHuman:You are a professional data analyst. You will always answer question based on the given context first. If the answer is not directly shown in the context, you will analyze the data and find the answer. If you don't know the answer, just say don't know. \n\n Context:\n${parameters.vector_tool.output}\n\nHuman:${parameters.question}\n\nAssistant:"
      }
    }
  ]
}

----------------------------------------

TITLE: Deleting a Document using DELETE HTTP Method in OpenSearch
DESCRIPTION: This endpoint allows deleting a specific document from an index in OpenSearch. It requires the index name and document ID as path parameters.

LANGUAGE: json
CODE:
DELETE /<index>/_doc/<_id>

----------------------------------------

TITLE: Executing Pre-filtered k-NN Search with Scoring Script in OpenSearch
DESCRIPTION: This code demonstrates how to perform a k-NN search with pre-filtering using the script_score query in OpenSearch. It filters documents by color before applying the k-NN algorithm.

LANGUAGE: json
CODE:
GET my-knn-index-2/_search
{
  "size": 2,
  "query": {
    "script_score": {
      "query": {
        "bool": {
          "filter": {
            "term": {
              "color": "BLUE"
            }
          }
        }
      },
      "script": {
        "lang": "knn",
        "source": "knn_score",
        "params": {
          "field": "my_vector",
          "query_value": [9.9, 9.9],
          "space_type": "l2"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Querying Ranking Evaluation Endpoint in OpenSearch
DESCRIPTION: Example of using the GET or POST methods to access the rank evaluation endpoint for a specific index in OpenSearch. This endpoint allows evaluation of search result quality based on predefined queries and relevance ratings.

LANGUAGE: json
CODE:
GET <index_name>/_rank_eval 
POST <index_name>/_rank_eval

----------------------------------------

TITLE: Sample JSON Input for Translate Processor
DESCRIPTION: Example JSON input file (logs_json.log) containing an HTTP status code to be translated by the processor.

LANGUAGE: json
CODE:
{ "status": "404" }

----------------------------------------

TITLE: Deleting an Index
DESCRIPTION: Use the client's indices.delete() method to remove an entire index and all its documents.

LANGUAGE: python
CODE:
response = client.indices.delete(
    index = 'my-dsl-index'
)

----------------------------------------

TITLE: Creating Vector Index for Chunked Text in OpenSearch
DESCRIPTION: This snippet shows how to create a vector index in OpenSearch to store chunked text and embeddings. It defines the mapping for the text field and the nested embedding field with KNN vector type.

LANGUAGE: json
CODE:
PUT testindex
{
  "settings": {
    "index": {
      "knn": true
    }
  },
  "mappings": {
    "properties": {
      "text": {
        "type": "text"
      },
      "passage_chunk_embedding": {
        "type": "nested",
        "properties": {
          "knn": {
            "type": "knn_vector",
            "dimension": 768
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Registering a Flow Agent with VectorDBTool in OpenSearch
DESCRIPTION: This code registers a flow agent that uses the VectorDBTool to perform vector search operations on the previously created index.

LANGUAGE: json
CODE:
POST /_plugins/_ml/agents/_register
{
  "name": "Test_Agent_For_VectorDB",
  "type": "flow",
  "description": "this is a test agent",
  "tools": [
    {
      "type": "VectorDBTool",
      "parameters": {
        "model_id": "Hv_PY40Bk4MTqircAVmm",
        "index": "my_test_data",
        "embedding_field": "embedding",
        "source_field": ["text"],
        "input": "${parameters.question}"
      }
    }
  ]
}

----------------------------------------

TITLE: Mapping S3 Log Fields to ECS Format
DESCRIPTION: JSON mapping configuration that defines how raw S3 log fields are mapped to Elastic Common Schema (ECS) fields. Maps event name, source and time from CloudTrail format to standardized ECS fields.

LANGUAGE: json
CODE:
  "mappings": [
    {
      "raw_field":"eventName",
      "ecs":"aws.cloudtrail.event_name"
    },
    {
      "raw_field":"eventSource",
      "ecs":"aws.cloudtrail.event_source"
    },
    {
      "raw_field":"eventTime",
      "ecs":"timestamp"
    }
  ]

----------------------------------------

TITLE: Creating a Mapping with Binary Field in OpenSearch
DESCRIPTION: This snippet demonstrates how to create an index mapping that includes a binary field type. The binary field is named 'binary_value' and is set to type 'binary'.

LANGUAGE: json
CODE:
PUT testindex 
{
  "mappings" : {
    "properties" :  {
      "binary_value" : {
        "type" : "binary"
      }
    }
  }
}

----------------------------------------

TITLE: Converting Field Types with Logstash Mutate Filter
DESCRIPTION: Demonstrates how to use the mutate filter to convert a field's data type from string to integer. The configuration includes input from HTTP, mutation of the quantity field, and output to a file.

LANGUAGE: yaml
CODE:
input {
  http {
    host => "127.0.0.1"
    port => 8080
  }
}

filter {
  mutate {
   convert => {"quantity" => "integer"}
  }
}

output {
  file {
    path => "output.txt"
  }
}

----------------------------------------

TITLE: Assigning Full Access to Flow Framework APIs for Users in OpenSearch
DESCRIPTION: This snippet demonstrates how to assign full access to Flow Framework APIs for specific users ('alice' and 'bob') using the Security plugin's role mapping feature.

LANGUAGE: json
CODE:
PUT _plugins/_security/api/rolesmapping/flow_framework_full_access
{
  "backend_roles": [],
  "hosts": [],
  "users": [
    "alice",
    "bob"
  ]
}

----------------------------------------

TITLE: Aggregate Function Usage in OpenSearch SQL
DESCRIPTION: Examples of using aggregate functions in OpenSearch SQL queries. These functions perform calculations on a set of values and return a single result.

LANGUAGE: SQL
CODE:
SELECT avg(column) FROM my-index
SELECT count(date) FROM my-index
SELECT min(column) FROM my-index
SHOW TABLES LIKE my-index

----------------------------------------

TITLE: Querying OpenSearch Index Using SQL REST API
DESCRIPTION: Demonstrates how to query an OpenSearch index using SQL via the REST API. This example shows a basic SELECT query with a LIMIT clause.

LANGUAGE: json
CODE:
POST _plugins/_sql
{
  "query": "SELECT * FROM my-index LIMIT 50"
}

----------------------------------------

TITLE: Running OpenSearch in a Docker Container
DESCRIPTION: Commands to pull OpenSearch and OpenSearch Dashboards Docker images from Docker Hub or Amazon ECR.

LANGUAGE: bash
CODE:
docker pull opensearchproject/opensearch:{{ site.opensearch_version | split: "." | first }}

docker pull opensearchproject/opensearch-dashboards:{{ site.opensearch_version | split: "." | first }}

docker pull public.ecr.aws/opensearchproject/opensearch:{{ site.opensearch_version | split: "." | first }}

docker pull public.ecr.aws/opensearchproject/opensearch-dashboards:{{ site.opensearch_version | split: "." | first }}

----------------------------------------

TITLE: Creating Mapping with Search-as-you-type Field in OpenSearch
DESCRIPTION: This snippet shows how to create a mapping with a search-as-you-type field in OpenSearch. It creates additional n-gram subfields and an index prefix subfield.

LANGUAGE: json
CODE:
PUT books
{
  "mappings": {
    "properties": {
      "suggestions": {
        "type": "search_as_you_type"
      }
    }
  }
}

----------------------------------------

TITLE: Querying Model Group Endpoint - OpenSearch REST API
DESCRIPTION: HTTP GET request to retrieve model group information using the model group ID. This endpoint returns details like name, version, description, and access level of the specified model group.

LANGUAGE: json
CODE:
GET /_plugins/_ml/model_groups/<model_group_id>

----------------------------------------

TITLE: Wait for Cluster Status Example
DESCRIPTION: Request that waits up to 50 seconds for the cluster to reach yellow status or better.

LANGUAGE: json
CODE:
GET _cluster/health?wait_for_status=yellow&timeout=50s

----------------------------------------

TITLE: Configuring Minimal Data Prepper Pipeline in YAML
DESCRIPTION: This snippet demonstrates a minimal Data Prepper pipeline configuration that reads from a file source and writes to a file sink. It uses default options for buffer and processor components.

LANGUAGE: yaml
CODE:
sample-pipeline:
  source:
    file:
        path: <path/to/input-file>
  sink:
    - file:
        path: <path/to/output-file>

----------------------------------------

TITLE: Creating Text Field Mapping in OpenSearch
DESCRIPTION: Example of creating a mapping with a basic text field for a movies index.

LANGUAGE: json
CODE:
PUT movies
{
  "mappings" : {
    "properties" : {
      "title" : {
        "type" :  "text"
      }
    }
  }
}

----------------------------------------

TITLE: Querying Segments for All Indexes in OpenSearch Cluster
DESCRIPTION: This request demonstrates how to use the Segment API to retrieve segment information for all indexes and data streams in an OpenSearch cluster.

LANGUAGE: json
CODE:
GET /_segments

----------------------------------------

TITLE: Enabling ML in OpenSearch Dashboards Configuration
DESCRIPTION: YAML configuration setting required to enable machine learning functionality in OpenSearch Dashboards. This setting needs to be added to the opensearch_dashboards.yml configuration file.

LANGUAGE: yaml
CODE:
ml_commons_dashboards.enabled: true

----------------------------------------

TITLE: Text/Image Embedding Processor Syntax
DESCRIPTION: Basic JSON structure for configuring the text_image_embedding processor with required fields for model ID, embedding field, and field mappings.

LANGUAGE: json
CODE:
{
  "text_image_embedding": {
    "model_id": "<model_id>",
    "embedding": "<vector_field>",
    "field_map": {
      "text": "<input_text_field>",
      "image": "<input_image_field>"
    }
  }
}

----------------------------------------

TITLE: Paginating Results with 'from' and 'size' Parameters in OpenSearch
DESCRIPTION: This snippet demonstrates how to use the 'from' and 'size' parameters to paginate search results in OpenSearch. It shows a query that searches for the play name 'Hamlet' in the 'shakespeare' index, starting from the first result and returning 10 results.

LANGUAGE: json
CODE:
GET shakespeare/_search
{
  "from": 0,
  "size": 10,
  "query": {
    "match": {
      "play_name": "Hamlet"
    }
  }
}

----------------------------------------

TITLE: Querying Cluster Stats Endpoints in OpenSearch
DESCRIPTION: Basic REST endpoints for retrieving cluster statistics. These endpoints support optional node filters, metric groups, and index metric filters.

LANGUAGE: json
CODE:
GET _cluster/stats
GET _cluster/stats/nodes/<node-filters>
GET _cluster/stats/<metric>/nodes/<node-filters>
GET _cluster/stats/<metric>/<index_metric>/nodes/<node-filters>

----------------------------------------

TITLE: Aggregating UBI Events by Action Name using OpenSearch Query DSL
DESCRIPTION: Query that aggregates UBI events by action_name field to count event occurrences. Uses terms aggregation with size 0 to focus on aggregation results only. Returns the top 10 most frequent action types.

LANGUAGE: json
CODE:
{
  "size":0, 
  "aggs":{ 
    "event_types":{
      "terms": {
        "field":"action_name", 
        "size":10
      }
    }
  }
}

----------------------------------------

TITLE: Connecting to OpenSearch with Client Certificates
DESCRIPTION: Create an OpenSearch client object using client certificates for authentication instead of HTTP basic authentication. This snippet shows how to configure the connection with client certificate paths.

LANGUAGE: python
CODE:
host = 'localhost'
port = 9200
auth = ('admin', 'admin') # For testing only. Don't store credentials in code.
ca_certs_path = '/full/path/to/root-ca.pem' # Provide a CA bundle if you use intermediate CAs with your root CA.

# Optional client certificates if you don't want to use HTTP basic authentication.
client_cert_path = '/full/path/to/client.pem'
client_key_path = '/full/path/to/client-key.pem'

# Create the client with SSL/TLS enabled, but hostname verification disabled.
client = OpenSearch(
    hosts = [{'host': host, 'port': port}],
    http_compress = True, # enables gzip compression for request bodies
    http_auth = auth,
    client_cert = client_cert_path,
    client_key = client_key_path,
    use_ssl = True,
    verify_certs = True,
    ssl_assert_hostname = False,
    ssl_show_warn = False,
    ca_certs = ca_certs_path
)

----------------------------------------

TITLE: Getting Remote Store Stats for an Index
DESCRIPTION: API endpoint to retrieve remote store statistics for all shards in an index. Returns metrics about segment transfers, translog transfers, and routing information.

LANGUAGE: json
CODE:
GET _remotestore/stats/<index_name>

----------------------------------------

TITLE: Importing OpenSearch Python Client
DESCRIPTION: Import the OpenSearch class from the opensearchpy module to use the client in your Python code.

LANGUAGE: python
CODE:
from opensearchpy import OpenSearch

----------------------------------------

TITLE: Creating ISM Policy - JSON
DESCRIPTION: Creates a new index management policy with states for ingestion, search, and deletion based on conditions like document count and index age.

LANGUAGE: json
CODE:
PUT _plugins/_ism/policies/policy_1
{
  "policy": {
    "description": "ingesting logs",
    "default_state": "ingest",
    "states": [
      {
        "name": "ingest",
        "actions": [
          {
            "rollover": {
              "min_doc_count": 5
            }
          }
        ],
        "transitions": [
          {
            "state_name": "search"
          }
        ]
      },
      {
        "name": "search",
        "actions": [],
        "transitions": [
          {
            "state_name": "delete",
            "conditions": {
              "min_index_age": "5m"
            }
          }
        ]
      },
      {
        "name": "delete",
        "actions": [
          {
            "delete": {}
          }
        ],
        "transitions": []
      }
    ]
  }
}

----------------------------------------

TITLE: Defining Datetime Type in SQL for OpenSearch
DESCRIPTION: Specifies the syntax and range for the 'datetime' type in SQL for OpenSearch. The datetime type combines date and time without time zone information.

LANGUAGE: sql
CODE:
datetime | yyyy-MM-dd hh:mm:ss[.fraction] | 0001-01-01 00:00:00.0000000000 to 9999-12-31 23:59:59.9999999999

----------------------------------------

TITLE: Correlation Alerts Management APIs
DESCRIPTION: APIs for listing and acknowledging correlation alerts, including filtering by correlation rule ID and bulk acknowledgment of multiple alerts.

LANGUAGE: json
CODE:
GET /_plugins/_security_analytics/correlationAlerts

POST /_plugins/_security_analytics/_acknowledge/correlationAlerts
{
   "alertIds": ["8532c08b-3ab5-4e95-a1c2-5884c4cd41a5", "8bba85d9-a7fc-4c87-b35e-a7236b87159f"]
}

----------------------------------------

TITLE: Configuring Remote Store Repository in OpenSearch
DESCRIPTION: Example YAML configuration for setting up remote store repositories in opensearch.yml.

LANGUAGE: yaml
CODE:
# Repository name
node.attr.remote_store.segment.repository: my-repo-1
node.attr.remote_store.translog.repository: my-repo-2
node.attr.remote_store.state.repository: my-repo-3

# Segment repository settings
node.attr.remote_store.repository.my-repo-1.type: s3
node.attr.remote_store.repository.my-repo-1.settings.bucket: <Bucket Name 1>
node.attr.remote_store.repository.my-repo-1.settings.base_path: <Bucket Base Path 1>
node.attr.remote_store.repository.my-repo-1.settings.region: us-east-1

# Translog repository settings
node.attr.remote_store.repository.my-repo-2.type: s3
node.attr.remote_store.repository.my-repo-2.settings.bucket: <Bucket Name 2>
node.attr.remote_store.repository.my-repo-2.settings.base_path: <Bucket Base Path 2>
node.attr.remote_store.repository.my-repo-2.settings.region: us-east-1

# Enable Remote cluster state cluster setting
cluster.remote_store.state.enabled: true

# Remote cluster state repository settings
node.attr.remote_store.repository.my-remote-state-repo.type: s3
node.attr.remote_store.repository.my-remote-state-repo.settings.bucket: <Bucket Name 3>
node.attr.remote_store.repository.my-remote-state-repo.settings.base_path: <Bucket Base Path 3>
node.attr.remote_store.repository.my-remote-state-repo.settings.region: <Bucket region>

----------------------------------------

TITLE: Indexing Nested Objects as Flattened Form in OpenSearch
DESCRIPTION: This snippet shows how to index an array of objects in OpenSearch, which are stored in flattened form by default.

LANGUAGE: json
CODE:
PUT testindex1/_doc/100
{ 
  "patients": [ 
    {"name" : "John Doe", "age" : 56, "smoker" : true},
    {"name" : "Mary Major", "age" : 85, "smoker" : false}
  ] 
}

----------------------------------------

TITLE: Indexing Document in OpenSearch
DESCRIPTION: Demonstrates how to index a document into OpenSearch using the IndexRequest method

LANGUAGE: go
CODE:
document := strings.NewReader(`{
    "title": "Moneyball",
    "director": "Bennett Miller",
    "year": "2011"
}`)

docId := "1"
req := opensearchapi.IndexRequest{
    Index:      "go-test-index1",
    DocumentID: docId,
    Body:       document,
}
insertResponse, err := req.Do(context.Background(), client)

----------------------------------------

TITLE: Rescoring with Active Features Selection
DESCRIPTION: Shows how to selectively score specific features using the active_features parameter in the sltr query. This example only scores the 'title_query' feature while other features are marked as missing.

LANGUAGE: json
CODE:
    POST tmdb/_search
    {
        "query": {
            "match": {
                "_all": "rambo"
            }
        },
        "rescore": {
            "window_size": 1000,
            "query": {
                "rescore_query": {
                    "sltr": {
                        "params": {
                            "keywords": "rambo"
                        },
                        "model": "my_model",
                        "active_features": ["title_query"]
                    }
                }
            }
        }
    }

----------------------------------------

TITLE: Using 'search_after' for Pagination in OpenSearch
DESCRIPTION: This snippet shows how to use the 'search_after' parameter for pagination in OpenSearch. It searches for 'Hamlet' in the 'shakespeare' index, sorts the results, and uses the 'search_after' parameter to retrieve the next page of results based on the last result of the previous page.

LANGUAGE: json
CODE:
GET shakespeare/_search
{
  "size": 10,
  "query": {
    "match": {
      "play_name": "Hamlet"
    }
  },
  "search_after": [ 1, "32635"],
  "sort": [
    { "speech_number": "asc" },
    { "_id": "asc" } 
  ]
}

----------------------------------------

TITLE: Properties Request Body Example
DESCRIPTION: Example of a request body showing how to define properties with different field types.

LANGUAGE: json
CODE:
{
  "properties":{
    "color":{
      "type": "text"
    },
    "year":{
      "type": "integer"
    }
  }
}

----------------------------------------

TITLE: Bulk API Endpoints in OpenSearch
DESCRIPTION: Defines the endpoints for the bulk API operation in OpenSearch. These endpoints allow for performing multiple document operations in a single request.

LANGUAGE: json
CODE:
POST _bulk
POST <index>/_bulk

----------------------------------------

TITLE: Basic Term Query Search in OpenSearch
DESCRIPTION: Demonstrates how to perform a basic term query search using an exact line_id match.

LANGUAGE: json
CODE:
GET shakespeare/_search
{
  "query": {
    "term": {
      "line_id": {
        "value": "61809"
      }
    }
  }
}

----------------------------------------

TITLE: Setting the default search pipeline for an index
DESCRIPTION: Configures an index to use a specific search pipeline by default for all queries.

LANGUAGE: json
CODE:
PUT /my-nlp-index/_settings 
{
  "index.search.default_pipeline" : "neural_search_pipeline"
}

----------------------------------------

TITLE: Defining OpenSearch Batch Ingestion API Endpoint
DESCRIPTION: The base endpoint for the Asynchronous Batch Ingestion API.

LANGUAGE: json
CODE:
POST /_plugins/_ml/_batch_ingestion

----------------------------------------

TITLE: Faiss IVF with PQ Encoder
DESCRIPTION: Example of configuring IVF method with Product Quantization encoder using the Faiss engine.

LANGUAGE: json
CODE:
"method": {
  "name":"ivf",
  "engine":"faiss",
  "parameters":{
    "encoder":{
      "name":"pq",
      "parameters":{
        "code_size": 8,
        "m": 8
      }
    }
  }
}

----------------------------------------

TITLE: Defining Anonymous User Role in roles.yml
DESCRIPTION: Example role definition for anonymous users with limited read-only privileges in OpenSearch's roles.yml file.

LANGUAGE: yaml
CODE:
anonymous_users_role:
  reserved: false
  hidden: false
  cluster_permissions:
  - "OPENDISTRO_SECURITY_CLUSTER_COMPOSITE_OPS"
  index_permissions:
  - index_patterns:
    - "public_index_*"
    allowed_actions:
    - "read"

----------------------------------------

TITLE: Sum Bucket Pipeline Aggregation Example
DESCRIPTION: Demonstrates summing buckets from a histogram aggregation using a pipeline aggregation

LANGUAGE: json
CODE:
{
  "size": 0,
  "aggs": {
    "number_of_bytes": {
      "histogram": {
        "field": "bytes",
        "interval": 10000
      },
      "aggs": {
        "sum_total_memory": {
          "sum": {
            "field": "phpmemory"
          }
        }
      }
    },
    "sum_copies": {
      "sum_bucket": {
        "buckets_path": "number_of_bytes>sum_total_memory"
      }
    }
  }
}

----------------------------------------

TITLE: OpenSearch Dashboards Basic Configuration
DESCRIPTION: Basic YAML configuration for OpenSearch Dashboards without security plugin.

LANGUAGE: yml
CODE:
---
server.name: opensearch-dashboards
server.host: "0.0.0.0"
opensearch.hosts: http://localhost:9200

----------------------------------------

TITLE: Connecting to Amazon OpenSearch Service with IAM Credentials
DESCRIPTION: Create an OpenSearch client to connect to Amazon OpenSearch Service using IAM credentials. This snippet demonstrates how to use AWSV4SignerAuth for authentication.

LANGUAGE: python
CODE:
from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth
import boto3

host = '' # cluster endpoint, for example: my-test-domain.us-east-1.es.amazonaws.com
region = 'us-west-2'
service = 'es'
credentials = boto3.Session().get_credentials()
auth = AWSV4SignerAuth(credentials, region, service)

client = OpenSearch(
    hosts = [{'host': host, 'port': 443}],
    http_auth = auth,
    use_ssl = True,
    verify_certs = True,
    connection_class = RequestsHttpConnection,
    pool_maxsize = 20
)

----------------------------------------

TITLE: Updating Cluster Max Shards Setting
DESCRIPTION: PUT request to update the cluster.max_shards_per_node setting using persistent configuration.

LANGUAGE: json
CODE:
PUT _cluster/settings
{
   "persistent":{
      "cluster.max_shards_per_node": 500
   }
}

----------------------------------------

TITLE: Installing OpenSearch Using Helm
DESCRIPTION: Command to deploy OpenSearch using the Helm chart.

LANGUAGE: bash
CODE:
helm install my-deployment opensearch/opensearch

----------------------------------------

TITLE: Configuring Action Groups in action_groups.yml
DESCRIPTION: Defines custom action groups with specific permissions for OpenSearch Security. This example creates a group with index write and read permissions.

LANGUAGE: yaml
CODE:
---
my-action-group:
  reserved: false
  hidden: false
  allowed_actions:
  - "indices:data/write/index*"
  - "indices:data/write/update*"
  - "indices:admin/mapping/put"
  - "indices:data/write/bulk*"
  - "read"
  - "write"
  static: false
_meta:
  type: "actiongroups"
  config_version: 2

----------------------------------------

TITLE: Configuring a search pipeline with rerank processor in OpenSearch
DESCRIPTION: This snippet shows how to configure a search pipeline with a rerank processor using the 'by_field' rerank type. It specifies sorting by the 'reviews.stars' field and retains the original query scores.

LANGUAGE: json
CODE:
PUT /_search/pipeline/rerank_byfield_pipeline
{
  "response_processors": [
    {
      "rerank": {
        "by_field": {
          "target_field": "reviews.stars",
          "keep_previous_score" : true
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Pulling OpenSearch Dashboards Docker Image
DESCRIPTION: Command to pull the OpenSearch Dashboards Docker image from the official repository. This step is necessary before running the container.

LANGUAGE: bash
CODE:
docker pull opensearchproject/opensearch-dashboards:2

----------------------------------------

TITLE: Creating an Index with Specific Settings in OpenSearch
DESCRIPTION: This snippet demonstrates how to create an index named 'testindex' with specific settings for the number of shards and replicas.

LANGUAGE: json
CODE:
PUT /testindex
{
  "settings": {
    "index.number_of_shards": 1,
    "index.number_of_replicas": 2
  }
}

----------------------------------------

TITLE: Full-Text Search with match Query
DESCRIPTION: Shows how to perform a full-text search on the name field using the match query

LANGUAGE: json
CODE:
GET /students/_search
{
  "query": {
    "match": {
      "name": "john"
    }
  }
}

----------------------------------------

TITLE: Creating an index with default search pipeline in OpenSearch
DESCRIPTION: This snippet demonstrates how to create an OpenSearch index with a specified mapping and set the default search pipeline. The index includes fields for book information and reviews.

LANGUAGE: json
CODE:
PUT /book-index
{
  "settings": {
    "index.search.default_pipeline" : "rerank_byfield_pipeline"
  },
  "mappings": {
    "properties": {
      "title": {
        "type": "text"
      },
      "author": {
        "type": "text"
      },
      "genre": {
        "type": "keyword"
      },
      "reviews": {
        "properties": {
          "stars": {
            "type": "float"
          }
        }
      },
      "description": {
        "type": "text"
      }
    }
  }
}

----------------------------------------

TITLE: Local Model Pipeline Configuration
DESCRIPTION: Example of creating a search pipeline with a local text embedding model to convert term queries to k-NN queries.

LANGUAGE: json
CODE:
PUT /_search/pipeline/ml_inference_pipeline_local
{
  "description": "searchs reviews and generates embeddings",
  "processors": [
    {
      "ml_inference": {
        "function_name": "text_embedding",
        "full_response_path": true,
        "model_id": "<your model id>",
        "model_config": {
          "return_number": true,
          "target_response": [
            "sentence_embedding"
          ]
        },
        "model_input": "{ \"text_docs\": ${input_map.text_docs}, \"return_number\": ${model_config.return_number}, \"target_response\": ${model_config.target_response} }",
        "query_template": "\"{\n        \"size\": 2,\n        \"query\": {\n          \"knn\": {\n            \"passage_embedding\": {\n              \"vector\": ${modelPredictionOutcome},\n              \"k\": 5\n              }\n            }\n           }\n          }\"",
        "input_map": [
          {
            "text_docs": "query.term.passage_embedding.value"
          }
        ],
        "output_map": [
          {
            "modelPredictionOutcome": "$.inference_results.*.output.*.data"
          }
        ],
        "ignore_missing": true,
        "ignore_failure": true
      }
    }
  ]
}

----------------------------------------

TITLE: Deleting an OpenSearch Index
DESCRIPTION: Use the client's indices.delete() method to remove an entire index from OpenSearch. This operation deletes all documents in the index.

LANGUAGE: python
CODE:
response = client.indices.delete(
    index = 'python-test-index'
)

----------------------------------------

TITLE: Configuring Admin Certificate DNs
DESCRIPTION: YAML configuration for specifying super admin certificate Distinguished Names (DNs) in OpenSearch. These certificates have elevated rights for administrative tasks.

LANGUAGE: yaml
CODE:
plugins.security.authcz.admin_dn:
  - CN=admin,OU=SSL,O=Test,L=Test,C=DE

----------------------------------------

TITLE: Basic k-NN Query Structure in OpenSearch
DESCRIPTION: Basic structure for k-NN query showing the required vector field format and supported request fields.

LANGUAGE: json
CODE:
"knn": {
  "<vector_field>": {
    "vector": [<vector_values>],
    "k": <k_value>,
    ...
  }
}

----------------------------------------

TITLE: Example Bulk Request in OpenSearch
DESCRIPTION: Provides a complete example of a bulk request in OpenSearch, including multiple actions (delete, index, create, update) in a single request.

LANGUAGE: json
CODE:
POST _bulk
{ "delete": { "_index": "movies", "_id": "tt2229499" } }
{ "index": { "_index": "movies", "_id": "tt1979320" } }
{ "title": "Rush", "year": 2013 }
{ "create": { "_index": "movies", "_id": "tt1392214" } }
{ "title": "Prisoners", "year": 2013 }
{ "update": { "_index": "movies", "_id": "tt0816711" } }
{ "doc" : { "title": "World War Z" } }

----------------------------------------

TITLE: Querying OpenSearch Nodes Information
DESCRIPTION: This bash command queries the _cat/nodes API endpoint to retrieve information about nodes in the OpenSearch cluster, including name, version, role, and master status.

LANGUAGE: bash
CODE:
GET "/_cat/nodes?v&h=name,version,node.role,master" | column -t

----------------------------------------

TITLE: Executing a Search Request in OpenSearch
DESCRIPTION: Example of how to perform a search request in OpenSearch using the GET method. This snippet demonstrates querying the 'movies' index for documents matching the text 'I am the night'.

LANGUAGE: json
CODE:
GET /movies/_search
{
  "query": {
    "match": {
      "text_entry": "I am the night"
    }
  }
}

----------------------------------------

TITLE: Configuring Delete Entries Pipeline in YAML
DESCRIPTION: Example configuration showing how to set up a pipeline with the delete_entries processor to remove specific keys from events.

LANGUAGE: yaml
CODE:
pipeline:
  source:
    ...
  ....
  processor:
    - delete_entries:
        with_keys: ["message"]
  sink:

----------------------------------------

TITLE: Installing OpenSearch Operator Manager
DESCRIPTION: This Helm command installs the OpenSearch Kubernetes Operator manager, which controls all operator actions.

LANGUAGE: bash
CODE:
helm install opensearch-operator opensearch-operator/opensearch-operator

----------------------------------------

TITLE: Searching for Documents in OpenSearch
DESCRIPTION: Use the client's search() method to search for documents in an OpenSearch index. This example uses a multi-match query to search for 'miller' in the title and director fields.

LANGUAGE: python
CODE:
q = 'miller'
query = {
  'size': 5,
  'query': {
    'multi_match': {
      'query': q,
      'fields': ['title^2', 'director']
    }
  }
}

response = client.search(
    body = query,
    index = 'python-test-index'
)

----------------------------------------

TITLE: Creating Guardrail Index Structure in OpenSearch
DESCRIPTION: Creates an index to store stopwords with a title field and percolator query field for matching LLM input/output

LANGUAGE: json
CODE:
{
  "mappings": {
    "properties": {
      "title": {
        "type": "text"
      },
      "query": {
        "type": "percolator"
      }
    }
  }
}

----------------------------------------

TITLE: Registering a Conversational Flow Agent for Population Data Analysis in OpenSearch
DESCRIPTION: This snippet shows how to register a conversational flow agent for population data analysis. It uses a VectorDBTool to query a knowledge base and an MLModelTool to process the query results, maintaining conversation history in an index.

LANGUAGE: json
CODE:
{
  "name": "population data analysis agent",
  "type": "conversational_flow",
  "description": "This is a demo agent for population data analysis",
  "app_type": "rag",
  "memory": {
    "type": "conversation_index"
  },
  "tools": [
    {
      "type": "VectorDBTool",
      "name": "population_knowledge_base",
      "parameters": {
        "model_id": "YOUR_TEXT_EMBEDDING_MODEL_ID",
        "index": "test_population_data",
        "embedding_field": "population_description_embedding",
        "source_field": [
          "population_description"
        ],
        "input": "${parameters.question}"
      }
    },
    {
      "type": "MLModelTool",
      "name": "bedrock_claude_model",
      "description": "A general tool to answer any question",
      "parameters": {
        "model_id": "YOUR_LLM_MODEL_ID",
        "prompt": """

H:You are a professional data analyst. You will always answer question based on the given context first. If the answer is not directly shown in the context, you will analyze the data and find the answer. If you don't know the answer, just say don't know. 

Context:
${parameters.population_knowledge_base.output:-}

${parameters.chat_history:-}

H:${parameters.question}

A:"""
      }
    }
  ]
}

----------------------------------------

TITLE: Update Action in OpenSearch Bulk API
DESCRIPTION: Shows the format for an update action in the bulk API. This action updates existing documents and returns an error if the document doesn't exist.

LANGUAGE: json
CODE:
{ "update": { "_index": "movies", "_id": "tt0816711" } }
{ "doc" : { "title": "World War Z" } }

----------------------------------------

TITLE: Specific Task Cancellation
DESCRIPTION: POST endpoint to cancel a specific task using its task ID.

LANGUAGE: json
CODE:
POST _tasks/<task_id>/_cancel

----------------------------------------

TITLE: Updating Index Settings in OpenSearch
DESCRIPTION: This snippet demonstrates how to update index-level settings using the Update Settings API. It shows the endpoint structure and an example request body that updates the index state management rollover skip setting and the number of replicas.

LANGUAGE: json
CODE:
PUT /<index>/_settings

LANGUAGE: json
CODE:
{
  "index.plugins.index_state_management.rollover_skip": true,
  "index": {
    "number_of_replicas": 4
  }
}

----------------------------------------

TITLE: Deleting Specific Points in Time (PITs) by ID in OpenSearch
DESCRIPTION: Deletes one or more PITs by specifying their IDs in the request body of a DELETE request.

LANGUAGE: json
CODE:
DELETE /_search/point_in_time

{
    "pit_id": [
        "o463QQEPbXktaW5kZXgtMDAwMDAxFkhGN09fMVlPUkVPLXh6MUExZ1hpaEEAFjBGbmVEZHdGU1EtaFhhUFc4ZkR5cWcAAAAAAAAAAAEWaXBPNVJtZEhTZDZXTWFFR05waXdWZwEWSEY3T18xWU9SRU8teHoxQTFnWGloQQAA",
        "o463QQEPbXktaW5kZXgtMDAwMDAxFkhGN09fMVlPUkVPLXh6MUExZ1hpaEEAFjBGbmVEZHdGU1EtaFhhUFc4ZkR5cWcAAAAAAAAAAAIWaXBPNVJtZEhTZDZXTWFFR05waXdWZwEWSEY3T18xWU9SRU8teHoxQTFnWGloQQAA"
    ]
}

----------------------------------------

TITLE: Using a Search Pipeline in OpenSearch Query
DESCRIPTION: This snippet shows how to use a previously defined search pipeline in a query by specifying the pipeline name in the search_pipeline query parameter.

LANGUAGE: json
CODE:
GET /my_index/_search?search_pipeline=my_pipeline

----------------------------------------

TITLE: Enabling Model Access Control in OpenSearch
DESCRIPTION: JSON request to dynamically enable model access control in OpenSearch cluster settings.

LANGUAGE: json
CODE:
PUT _cluster/settings
{
  "transient": {
    "plugins.ml_commons.model_access_control_enabled": "true"
  }
}

----------------------------------------

TITLE: Multi-search Example Request
DESCRIPTION: Example of a multi-search request querying multiple indexes with different search configurations.

LANGUAGE: json
CODE:
GET _msearch
{ "index": "opensearch_dashboards_sample_data_logs"}
{ "query": { "match_all": {} }, "from": 0, "size": 10}
{ "index": "opensearch_dashboards_sample_data_ecommerce", "search_type": "dfs_query_then_fetch"}
{ "query": { "match_all": {} } }


----------------------------------------

TITLE: Configuring Required Routing for an Index in OpenSearch
DESCRIPTION: Example of creating an index with required custom routing for all CRUD operations. OpenSearch will throw an exception if a document is indexed without providing a routing value.

LANGUAGE: json
CODE:
PUT sample-index2
{
  "mappings": {
    "_routing": {
      "required": true
    }
  }
}

----------------------------------------

TITLE: Upsert Operation Example
DESCRIPTION: Example showing how to use upsert to conditionally update or insert a document.

LANGUAGE: json
CODE:
{
  "doc": {
    "first_name": "Martha",
    "last_name": "Rivera"
  },
  "upsert": {
    "last_name": "Oliveira",
    "age": "31"
  }
}

----------------------------------------

TITLE: Defining Temporary Search Pipeline for Single Request
DESCRIPTION: This example demonstrates how to define a temporary search pipeline for a single request. It includes both request and response processors in the pipeline definition, which is only used for this specific query.

LANGUAGE: json
CODE:
POST /my-index/_search
{
  "query" : {
    "match" : {
      "text_field" : "some search text"
    }
  },
  "search_pipeline" : {
    "request_processors": [
      {
        "filter_query" : {
          "tag" : "tag1",
          "description" : "This processor is going to restrict to publicly visible documents",
          "query" : {
            "term": {
              "visibility": "public"
            }
          }
        }
      }
    ],
    "response_processors": [
      {
        "rename_field": {
          "field": "message",
          "target_field": "notification"
        }
      }
    ]
  }
}

----------------------------------------

TITLE: Boolean Query with Filters
DESCRIPTION: Demonstrates combining multiple search criteria using bool query with must clauses and filters

LANGUAGE: json
CODE:
GET students/_search
{
  "query": {
    "bool": {
      "must": [
        {
          "match": {
            "name": "doe"
          }
        },
        { "range": { "gpa": { "gte": 3.6, "lte": 3.9 } } },
        { "term":  { "grad_year": 2022 }}
      ]
    }
  }
}

----------------------------------------

TITLE: Querying Active Search Tasks
DESCRIPTION: Curl command to return detailed information about active search tasks.

LANGUAGE: bash
CODE:
curl -XGET "localhost:9200/_tasks?actions=*search&detailed

----------------------------------------

TITLE: Generated Tokens from Custom Whitespace Analyzer in OpenSearch
DESCRIPTION: This snippet shows the response from the _analyze API, displaying the tokens generated by the custom whitespace analyzer. Each token includes information about its position, start and end offsets, and type.

LANGUAGE: json
CODE:
{
  "tokens": [
    {"token": "the","start_offset": 0,"end_offset": 3,"type": "word","position": 0},
    {"token": "slow","start_offset": 4,"end_offset": 8,"type": "word","position": 1},
    {"token": "turtle","start_offset": 9,"end_offset": 15,"type": "word","position": 2},
    {"token": "swims","start_offset": 16,"end_offset": 21,"type": "word","position": 3},
    {"token": "away!","start_offset": 22,"end_offset": 27,"type": "word","position": 4},
    {"token": "123","start_offset": 28,"end_offset": 31,"type": "word","position": 5}
  ]
}

----------------------------------------

TITLE: Registering a Flow Agent with SearchMonitorsTool in OpenSearch
DESCRIPTION: This snippet demonstrates how to register a flow agent that includes the SearchMonitorsTool. It specifies the agent type, description, memory type, and the tool configuration.

LANGUAGE: json
CODE:
POST /_plugins/_ml/agents/_register
{
  "name": "Test_Agent_For_Search_Monitors_Tool",
  "type": "flow",
  "description": "this is a test agent for the SearchMonitorsTool",
  "memory": {
    "type": "demo"
  },
  "tools": [
    {
      "type": "SearchMonitorsTool",
      "name": "DemoSearchMonitorsTool",
      "parameters": {}
    }
  ]
}

----------------------------------------

TITLE: Query Multiple Specific Indices
DESCRIPTION: Example request to get information about multiple specific indices.

LANGUAGE: json
CODE:
GET _cat/indices/index1,index2,index3

----------------------------------------

TITLE: Retrieving Alerts from Security Analytics
DESCRIPTION: GET endpoint to retrieve alerts filtered by detector type, severity, state and other parameters. Returns alerts with their full details including state, trigger info, and timestamps.

LANGUAGE: json
CODE:
GET /_plugins/_security_analytics/alerts?detectorType=windows

----------------------------------------

TITLE: Using a Search Pipeline with Query Text Path
DESCRIPTION: This snippet demonstrates using a search pipeline with a rerank processor, specifying the query text path instead of direct query text.

LANGUAGE: json
CODE:
POST /_search?search_pipeline=rerank_pipeline
{
  "query": {
    "match": {
      "text_representation": {
        "query": "Where is Albuquerque?"
      }
    }
  },
  "ext": {
    "rerank": {
      "query_context": {
        "query_text_path": "query.match.text_representation.query"
      }
    }
  }
}

----------------------------------------

TITLE: Querying Documents with Exists Field
DESCRIPTION: OpenSearch query to find documents that contain the 'description' field.

LANGUAGE: json
CODE:
GET testindex/_search
{
  "query": {
    "exists": {
      "field": "description"
    }
  }
}

----------------------------------------

TITLE: Executing k-NN Search with Scoring Script in OpenSearch
DESCRIPTION: This snippet demonstrates how to perform an exact k-nearest neighbors search using the knn_score script in OpenSearch. It specifies the vector field, query vector, and space type for distance calculation.

LANGUAGE: json
CODE:
GET my-knn-index-1/_search
{
 "size": 4,
 "query": {
   "script_score": {
     "query": {
       "match_all": {}
     },
     "script": {
       "source": "knn_score",
       "lang": "knn",
       "params": {
         "field": "my_vector2",
         "query_value": [2.0, 3.0, 5.0, 6.0],
         "space_type": "cosinesimil"
       }
     }
   }
 }
}

----------------------------------------

TITLE: Creating Anomaly Detector with Recommended Parameters
DESCRIPTION: Creates an anomaly detector using the parameters recommended by the tool, including feature attributes and detection intervals.

LANGUAGE: json
CODE:
POST _plugins/_anomaly_detection/detectors
{
  "name": "test-detector",
  "description": "Test detector",
  "time_field": "timestamp",
  "indices": [
    "sample_weblogs_test"
  ],
  "feature_attributes": [
    {
      "feature_name": "feature_bytes",
      "feature_enabled": true,
      "aggregation_query": {
        "agg1": {
          "sum": {
            "field": "bytes"
          }
        }
      }
    },
    {
      "feature_name": "feature_response",
      "feature_enabled": true,
      "aggregation_query": {
        "agg2": {
          "avg": {
            "field": "response"
          }
        }
      }
    },
    {
      "feature_name": "feature_responseLatency",
      "feature_enabled": true,
      "aggregation_query": {
        "agg3": {
          "avg": {
            "field": "responseLatency"
          }
        }
      }
    }
  ],
  "detection_interval": {
    "period": {
      "interval": 1,
      "unit": "Minutes"
    }
  },
  "window_delay": {
    "period": {
      "interval": 1,
      "unit": "Minutes"
    }
  }
}

----------------------------------------

TITLE: Listing Supported Channel Configurations in OpenSearch
DESCRIPTION: Retrieves a list of all supported notification configuration types using a GET request to the features endpoint.

LANGUAGE: json
CODE:
GET /_plugins/_notifications/features

----------------------------------------

TITLE: Fuzzy Completion Query in OpenSearch
DESCRIPTION: This snippet shows how to use fuzzy matching in a completion query. It allows for misspellings in the search term while still returning relevant results.

LANGUAGE: json
CODE:
GET chess_store/_search
{
  "suggest": {
    "product-suggestions": {
      "prefix": "chesc",        
      "completion": {         
          "field": "suggestions",
          "size" : 3,
          "fuzzy" : {
            "fuzziness" : "AUTO"
          }
      }
    }
  }
}

----------------------------------------

TITLE: Defining Workspace Data Model in TypeScript
DESCRIPTION: This snippet defines the structure of a Workspace object in TypeScript. It includes properties for id, name, description, features, color, and uiSettings.

LANGUAGE: typescript
CODE:
interface Workspace {
  id: string;
  name: string;
  description?: string;
  features?: string[];
  color: string;
  uiSettings: Record<string, unknown>;
}

----------------------------------------

TITLE: Executing Match Phrase Prefix Query with SQL and PPL in OpenSearch
DESCRIPTION: Examples of using the MATCH_PHRASE_PREFIX function in SQL and PPL to search for phrases by given prefix. Demonstrates syntax and basic usage.

LANGUAGE: sql
CODE:
SELECT author, title
FROM books
WHERE match_phrase_prefix(author, 'Alexander Mil')

LANGUAGE: ppl
CODE:
source=books | where match_phrase_prefix(author, 'Alexander Mil') | fields author, title

----------------------------------------

TITLE: Configuring Field Boost Values in OpenSearch Mapping
DESCRIPTION: Demonstrates how to set up field mappings with different boost values to control relevance scoring. The example shows boost configuration for text and keyword fields, with the title field weighted double, tags field at 1.5x, and description field at normal weight.

LANGUAGE: json
CODE:
PUT my-index1
{
  "mappings": {
    "properties": {
      "title": {
        "type": "text",
        "boost": 2
      },
      "description": {
        "type": "text",
        "boost": 1
      },
      "tags": {
        "type": "keyword",
        "boost": 1.5
      }
    }
  }
}

----------------------------------------

TITLE: Basic Intervals Query in OpenSearch
DESCRIPTION: An example of a basic Intervals query that searches for documents containing 'key-value pairs' followed by either 'hash table' or 'hash map', demonstrating the use of all_of and any_of rules.

LANGUAGE: json
CODE:
GET /testindex/_search
{
  "query": {
    "intervals": {
      "title": {
        "all_of": {
          "ordered": true,
          "intervals": [
            {
              "match": {
                "query": "key-value pairs",
                "max_gaps": 0,
                "ordered": true
              }
            },
            {
              "any_of": {
                "intervals": [
                  {
                    "match": {
                      "query": "hash table"
                    }
                  },
                  {
                    "match": {
                      "query": "hash map"
                    }
                  }
                ]
              }
            }
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Complete ISM Policy Example
DESCRIPTION: A comprehensive example of an ISM policy implementing a hot, warm, and delete workflow.

LANGUAGE: json
CODE:
{
  "policy": {
    "description": "hot warm delete workflow",
    "default_state": "hot",
    "schema_version": 1,
    "states": [
      {
        "name": "hot",
        "actions": [
          {
            "rollover": {
              "min_index_age": "7d",
              "min_primary_shard_size": "30gb"
            }
          }
        ],
        "transitions": [
          {
            "state_name": "warm"
          }
        ]
      },
      {
        "name": "warm",
        "actions": [
          {
            "replica_count": {
              "number_of_replicas": 1
            }
          },
          {
            "allocation": {
              "require": {
                "temp": "warm"
              }
            }
          }
        ],
        "transitions": [
          {
            "state_name": "delete",
            "conditions": {
              "min_index_age": "30d"
            }
          }
        ]
      },
      {
        "name": "delete",
        "actions": [
          {
            "notification": {
              "destination": {
                "chime": {
                  "url": "<URL>"
                }
              },
              "message_template": {
                "source": "The index {{ctx.index}} is being deleted"
              }
            }
          },
          {
            "delete": {}
          }
        ]
      }
    ],
    "ism_template": {
      "index_patterns": ["log*"],
      "priority": 100
    }
  }
}

----------------------------------------

TITLE: Creating Ingest Pipeline with Mustache Template in OpenSearch
DESCRIPTION: Example of creating an ingest pipeline named 'my-pipeline' using Mustache template snippets. This pipeline sets a field dynamically based on the 'role' value and assigns it the value of 'tenure'.

LANGUAGE: json
CODE:
PUT _ingest/pipeline/my-pipeline
{
 "processors": [
    {
      "set": {
        "field": "{{{role}}}",
        "value": "{{{tenure}}}"
         }
    }
  ]
}

----------------------------------------

TITLE: Enabling ISM Error Prevention Validation in OpenSearch
DESCRIPTION: This snippet demonstrates how to enable ISM error prevention validation by setting the 'plugins.index_state_management.action_validation.enabled' parameter to true using a PUT request to the cluster settings API.

LANGUAGE: bash
CODE:
PUT _cluster/settings
{
   "persistent":{
      "plugins.index_state_management.action_validation.enabled": true
   }
}

----------------------------------------

TITLE: Configuring Semantic Search Pipeline
DESCRIPTION: Sets up a search pipeline with ML inference processor for semantic search capabilities.

LANGUAGE: json
CODE:
PUT _search/pipeline/bedrock_semantic_search_pipeline
{
  "request_processors": [
    {
      "ml_inference": {
        "model_id": "xhR35JQBLopfJ2xsO9pr",
        "input_map": [
          {
            "inputText": "ext.ml_inference.params.text"
          }
        ],
        "output_map": [
          {
            "ext.ml_inference.params.vector": "embedding"
          }
        ]
      }
    }
  ]
}

----------------------------------------

TITLE: Checking Flush Stats in OpenSearch
DESCRIPTION: API call to verify flush statistics after modifying flush threshold settings.

LANGUAGE: json
CODE:
GET /<index>/_stats/flush

----------------------------------------

TITLE: Sorting hybrid query results by document price in OpenSearch
DESCRIPTION: This snippet demonstrates how to apply sorting to a hybrid query search request by using the 'doc_price' field in descending order. It includes a hybrid query combining term and bool queries, with sorting applied.

LANGUAGE: json
CODE:
GET /my-nlp-index/_search?search_pipeline=nlp-search-pipeline
{
  "query": {
    "hybrid": {
      "queries": [
        {
          "term": {
            "category": "permission"
          }
        },
        {
          "bool": {
            "should": [
              {
                "term": {
                  "category": "editor"
                }
              },
              {
                "term": {
                  "category": "statement"
                }
              }
            ]
          }
        }
      ]
    }
  }, 
    "sort":[
       {
         "doc_price": {
             "order": "desc"
         }
       }
    ]
}

----------------------------------------

TITLE: Example Response for CAT Field Data in OpenSearch
DESCRIPTION: This is an example response from the CAT Field Data API, showing the memory size for all fields as 284 bytes across two nodes.

LANGUAGE: json
CODE:
id                     host       ip         node       field size
1vo54NuxSxOrbPEYdkSF0w 172.18.0.4 172.18.0.4 odfe-node1 _id   284b
ZaIkkUd4TEiAihqJGkp5CA 172.18.0.3 172.18.0.3 odfe-node2 _id   284b

----------------------------------------

TITLE: Searching Documents in OpenSearch
DESCRIPTION: Performs a multi-match search query across multiple fields with field boosting

LANGUAGE: php
CODE:
var_dump(
    $client->search([
        'index' => $indexName,
        'body' => [
            'size' => 5,
            'query' => [
                'multi_match' => [
                    'query' => 'miller',
                    'fields' => ['title^2', 'director']
                ]
            ]
        ]
    ])
);

----------------------------------------

TITLE: Defining Transitions in an ISM Policy
DESCRIPTION: Example of how to configure transitions between states in an ISM policy.

LANGUAGE: json
CODE:
"transitions": [
  {
    "state_name": "cold",
    "conditions": {
      "min_index_age": "30d"
    }
  }
]

----------------------------------------

TITLE: Bulk Data Ingestion for Vector Index
DESCRIPTION: Demonstrates how to bulk index multiple documents with vector data into an OpenSearch disk-based vector index.

LANGUAGE: json
CODE:
POST _bulk
{ "index": { "_index": "my-vector-index", "_id": "1" } }
{ "my_vector_field": [1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5], "price": 12.2 }
{ "index": { "_index": "my-vector-index", "_id": "2" } }
{ "my_vector_field": [2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5], "price": 7.1 }

----------------------------------------

TITLE: Advanced Highlight Query with Field Mapping
DESCRIPTION: Example showing field mapping configuration for highlight analysis

LANGUAGE: json
CODE:
{
  "mappings" : {
    "properties" : {
      "text_entry" : {
        "type" :  "text",
        "term_vector": "with_positions_offsets",
        "fields": {
          "english": { 
            "type":     "text",
            "analyzer": "english",
            "term_vector": "with_positions_offsets"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Retrieving Settings for a Specific Index in OpenSearch
DESCRIPTION: Example request for retrieving all settings for a specific index named 'sample-index1' using the Get Settings API in OpenSearch.

LANGUAGE: json
CODE:
GET /sample-index1/_settings

----------------------------------------

TITLE: Shrink Index API Example Request
DESCRIPTION: Example request demonstrating how to shrink an index with custom settings for replica count, shard count, and aliases. Creates a new index with 3 primary shards and 4 replicas.

LANGUAGE: json
CODE:
POST /my-old-index/_shrink/my-new-index\n{\n  "settings": {\n    "index.number_of_replicas": 4,\n    "index.number_of_shards": 3\n  },\n  "aliases":{\n    "new-index-alias": {}\n  }\n}

----------------------------------------

TITLE: Testing a Question Answering Model in OpenSearch
DESCRIPTION: JSON request to test a deployed question answering model using the Predict API.

LANGUAGE: json
CODE:
POST /_plugins/_ml/_predict/question_answering/<model_id>
{
  "question": "Where do I live?"
  "context": "My name is John. I live in New York"
}

----------------------------------------

TITLE: Basic Match Query in OpenSearch
DESCRIPTION: A simple Match query searching for the word 'wind' in the 'title' field.

LANGUAGE: json
CODE:
GET _search
{
  "query": {
    "match": {
      "title": "wind"
    }
  }
}

----------------------------------------

TITLE: Searching Security Detectors
DESCRIPTION: Searches for detectors based on ID, name or type. Supports complex query conditions.

LANGUAGE: json
CODE:
POST /_plugins/_security_analytics/detectors/_search
{
    "query": {
        "match": {
            "_id": "MFRg1IMByX0LvTiGHtcN"
        }
    }
}

----------------------------------------

TITLE: Performing a semantic search
DESCRIPTION: Executes a semantic search query using the neural query type and the deployed language model.

LANGUAGE: json
CODE:
GET /my-nlp-index/_search
{
  "_source": {
    "excludes": [
      "passage_embedding"
    ]
  },
  "query": {
    "neural": {
      "passage_embedding": {
        "query_text": "wild west",
        "model_id": "aVeif4oB5Vm0Tdw8zYO2",
        "k": 5
      }
    }
  }
}

----------------------------------------

TITLE: Enabling Shallow Snapshot v2 in OpenSearch using Snapshot API
DESCRIPTION: This code snippet shows how to enable shallow snapshot v2 using the Snapshot API. It creates an S3 repository with both 'remote_store_index_shallow_copy' and 'shallow_snapshot_v2' settings set to true.

LANGUAGE: bash
CODE:
PUT /_snapshot/snap_repo
{
"type": "s3",
"settings": {
"bucket": "test-bucket",
"base_path": "daily-snaps",
"remote_store_index_shallow_copy": true,
"shallow_snapshot_v2": true
}
}

----------------------------------------

TITLE: Indexing Document in OpenSearch
DESCRIPTION: Indexes a single document with specified fields into OpenSearch

LANGUAGE: php
CODE:
$client->create([
    'index' => $indexName,
    'id' => 1,
    'body' => [
        'title' => 'Moneyball',
        'director' => 'Bennett Miller',
        'year' => 2011
    ]
]);

----------------------------------------

TITLE: Executing VisualizationTool Agent in OpenSearch
DESCRIPTION: This snippet shows how to execute the registered VisualizationTool agent. It includes the agent ID and the question parameter used to find relevant visualizations.

LANGUAGE: json
CODE:
POST /_plugins/_ml/agents/9X7xWI0Bpc3sThaJdY9i/_execute
{
  "parameters": {
    "question": "what's the revenue for today?"
  }
}

----------------------------------------

TITLE: OpenSearch POST Document Example
DESCRIPTION: Example of adding a document with an auto-generated ID using POST request. Shows how to add a document with name, price, and description fields.

LANGUAGE: json
CODE:
POST /sample_index/_doc
{
  "name": "Another Example",
  "price": 19.99,
  "description": "We are such stuff as dreams are made on"
}

----------------------------------------

TITLE: Configuring Named Route Role Permission in YAML
DESCRIPTION: Example showing how to define a role with permissions using the named route format for anomaly detection.

LANGUAGE: yaml
CODE:
ad_role:
  reserved: true
  cluster_permissions:
    - 'ad:detectors/profile'

----------------------------------------

TITLE: Querying CAT Field Data Endpoints in OpenSearch
DESCRIPTION: These endpoints allow retrieving field data information. The first endpoint retrieves data for all fields, while the second allows specifying particular fields.

LANGUAGE: json
CODE:
GET /_cat/fielddata
GET /_cat/fielddata/{fields}

----------------------------------------

TITLE: Defining derived fields in index mappings
DESCRIPTION: Configures mappings to derive 'timestamp', 'method', and 'size' fields from the 'request' field in the 'logs' index.

LANGUAGE: json
CODE:
PUT /logs/_mapping
{
  "derived": {
    "timestamp": {
      "type": "date",
      "format": "MM/dd/yyyy",
      "script": {
        "source": """
        emit(Long.parseLong(doc["request.keyword"].value.splitOnToken(" ")[0]))
        """
      }
    },
    "method": {
      "type": "keyword",
      "script": {
        "source": """
        emit(doc["request.keyword"].value.splitOnToken(" ")[1])
        """
      }
    },
    "size": {
      "type": "long",
      "script": {
        "source": """
        emit(Long.parseLong(doc["request.keyword"].value.splitOnToken(" ")[5]))
        """
      }
    }
  }
}

----------------------------------------

TITLE: Retrieving Specific Notification Settings
DESCRIPTION: API request and response for retrieving notification settings for a specific reindex operation configuration.

LANGUAGE: json
CODE:
{
  "lron_configs": [
    {
      "_id": "LRON:indices:data/write/reindex",
      "lron_config": {
        "lron_condition": {
          "success": false,
          "failure": true
        },
        "action_name": "indices:data/write/reindex",
        "channels": [
          {
            "id": "my_chime"
          }
        ]
      }
    }
  ],
  "total_number": 1
}

----------------------------------------

TITLE: Upsert Action in OpenSearch Bulk API
DESCRIPTION: Illustrates the format for an upsert action in the bulk API. This action updates a document if it exists or creates a new one if it doesn't.

LANGUAGE: json
CODE:
{ "update": { "_index": "movies", "_id": "tt0816711" } }
{ "doc" : { "title": "World War Z" }, "doc_as_upsert": true }

----------------------------------------

TITLE: Update Model API Endpoint in OpenSearch
DESCRIPTION: The PUT endpoint for updating an existing machine learning model in OpenSearch using its model ID.

LANGUAGE: json
CODE:
PUT /_plugins/_ml/models/<model_id>

----------------------------------------

TITLE: Connecting to Amazon OpenSearch Service in Rust
DESCRIPTION: Create an OpenSearch client to connect to Amazon OpenSearch Service.

LANGUAGE: rust
CODE:
let url = Url::parse("https://...");
let service_name = "es";
let conn_pool = SingleNodeConnectionPool::new(url?);
let region_provider = RegionProviderChain::default_provider().or_else("us-east-1");
let aws_config = aws_config::from_env().region(region_provider).load().await.clone();
let transport = TransportBuilder::new(conn_pool)
    .auth(aws_config.clone().try_into()?)
    .service_name(service_name)
    .build()?
let client = OpenSearch::new(transport);

----------------------------------------

TITLE: Retrieving a Specific ML Commons Stat for a Specific Node in OpenSearch
DESCRIPTION: This request retrieves a specified ML Commons statistic for a specific node in the OpenSearch cluster. Replace <nodeId> with the ID of the desired node and <stat> with the name of the desired statistic.

LANGUAGE: json
CODE:
GET /_plugins/_ml/<nodeId>/stats/<stat>

----------------------------------------

TITLE: Applying Write Block to OpenSearch Index
DESCRIPTION: Example request to disable write operations on the 'test-index' in OpenSearch using the Blocks API.

LANGUAGE: json
CODE:
PUT /test-index/_block/write

----------------------------------------

TITLE: Validating Query Using GET Endpoint in OpenSearch
DESCRIPTION: Demonstrates the basic GET endpoint for validating a query in OpenSearch. This endpoint allows validating a query against a specified index without executing it.

LANGUAGE: json
CODE:
GET <index>/_validate/query

----------------------------------------

TITLE: Querying Index Settings in OpenSearch
DESCRIPTION: Demonstrates the endpoint structure for retrieving index settings in OpenSearch. Shows variations for getting all settings, settings for specific indexes, or specific settings within an index.

LANGUAGE: json
CODE:
GET /_settings
GET /<target-index>/_settings
GET /<target-index>/_settings/<setting>

----------------------------------------

TITLE: Checking Cluster Health in OpenSearch Benchmark
DESCRIPTION: Example of a cluster health check operation for specific indices.

LANGUAGE: yaml
CODE:
{
  "name": "check-cluster-green",
  "operation-type": "cluster-health",
  "index": "logs-*",
  "request-params": {
    "wait_for_status": "green",
    "wait_for_no_relocating_shards": "true"
  },
  "retry-until-success": true
}

----------------------------------------

TITLE: Configuring a search pipeline for hybrid search
DESCRIPTION: Sets up a search pipeline with a normalization processor for combining keyword and semantic search scores.

LANGUAGE: json
CODE:
PUT /_search/pipeline/nlp-search-pipeline
{
  "description": "Post processor for hybrid search",
  "phase_results_processors": [
    {
      "normalization-processor": {
        "normalization": {
          "technique": "min_max"
        },
        "combination": {
          "technique": "arithmetic_mean",
          "parameters": {
            "weights": [
              0.3,
              0.7
            ]
          }
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Enabling Client Certificate Authentication in opensearch.yml
DESCRIPTION: Configuration snippet to enable client certificate authentication by setting the clientauth_mode in the opensearch.yml file.

LANGUAGE: yaml
CODE:
plugins.security.ssl.http.clientauth_mode: OPTIONAL

----------------------------------------

TITLE: Defining IAM Permissions for Kinesis Source in JSON
DESCRIPTION: JSON configuration for the minimum IAM permissions required to run Kinesis as a source in OpenSearch Data Prepper. It includes permissions for Kinesis and DynamoDB operations.

LANGUAGE: json
CODE:
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "kinesis:DescribeStream",
        "kinesis:DescribeStreamConsumer",
        "kinesis:DescribeStreamSummary",
        "kinesis:GetRecords",
        "kinesis:GetShardIterator",
        "kinesis:ListShards",
        "kinesis:ListStreams",
        "kinesis:ListStreamConsumers",
        "kinesis:RegisterStreamConsumer",
        "kinesis:SubscribeToShard"
      ],
      "Resource": [
        "arn:aws:kinesis:us-east-1:{account-id}:stream/stream1",
        "arn:aws:kinesis:us-east-1:{account-id}:stream/stream2"
      ]
    },
    {
      "Sid": "allowCreateTable",
      "Effect": "Allow",
      "Action": [
        "dynamodb:CreateTable",
        "dynamodb:PutItem",
        "dynamodb:DescribeTable",
        "dynamodb:DeleteItem",
        "dynamodb:GetItem",
        "dynamodb:Scan",
        "dynamodb:UpdateItem",
        "dynamodb:Query"
      ],
      "Resource": [
        "arn:aws:dynamodb:us-east-1:{account-id}:table/kinesis-pipeline"
      ]
    }
  ]
}

----------------------------------------

TITLE: Retrieving Specific Pipeline in OpenSearch
DESCRIPTION: GET request to retrieve information about a specific ingest pipeline by name.

LANGUAGE: json
CODE:
GET _ingest/pipeline/my-pipeline

----------------------------------------

TITLE: OpenSearch Alias API Response
DESCRIPTION: Example response showing successful acknowledgment of alias creation or update operation.

LANGUAGE: json
CODE:
{
    "acknowledged": true
}

----------------------------------------

TITLE: Multi-search Template Example Request
DESCRIPTION: Example request demonstrating how to execute multiple search templates against the Shakespeare index using line_search_template and play_search_template.

LANGUAGE: json
CODE:
GET _msearch/template
{"index":"shakespeare"}
{"id":"line_search_template","params":{"text_entry":"All the world's a stage","limit":false,"size":2}}
{"index":"shakespeare"}
{"id":"play_search_template","params":{"play_name":"Henry IV"}}

----------------------------------------

TITLE: Defining Fail Processor Syntax in OpenSearch JSON
DESCRIPTION: This snippet demonstrates the basic syntax for the fail processor in OpenSearch. It shows how to define conditions for failure and specify a custom error message.

LANGUAGE: json
CODE:
"fail": { 
  "if": "ctx.foo == 'bar'", 
  "message": "Custom error message" 
  }

----------------------------------------

TITLE: Performing Simple Query String Search with SQL and PPL in OpenSearch
DESCRIPTION: Examples of using the SIMPLE_QUERY_STRING function in SQL and PPL for simplified query string searches. Shows syntax with field boosting and options.

LANGUAGE: sql
CODE:
SELECT account_number, address
FROM accounts
WHERE simple_query_string(['address'], 'Lane Street', default_operator='OR')

LANGUAGE: ppl
CODE:
SOURCE=accounts | WHERE simple_query_string(['address'], 'Lane Street', default_operator='OR') | fields account_number, address

----------------------------------------

TITLE: Configuring Search-as-you-type Index
DESCRIPTION: Creates an index optimized for search-as-you-type functionality using edge n-gram tokenizer with separate analyzers for indexing and searching.

LANGUAGE: json
CODE:
PUT /my-autocomplete-index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "autocomplete": {
          "tokenizer": "autocomplete",
          "filter": [
            "lowercase"
          ]
        },
        "autocomplete_search": {
          "tokenizer": "lowercase"
        }
      },
      "tokenizer": {
        "autocomplete": {
          "type": "edge_ngram",
          "min_gram": 2,
          "max_gram": 10,
          "token_chars": [
            "letter"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "title": {
        "type": "text",
        "analyzer": "autocomplete",
        "search_analyzer": "autocomplete_search"
      }
    }
  }
}

----------------------------------------

TITLE: AWS Secrets Extension Configuration in YAML
DESCRIPTION: Configuration example for setting up AWS Secrets Manager extension plugin in Data Prepper, showing how to configure multiple secret configurations with their respective parameters.

LANGUAGE: json
CODE:
extensions:
  aws:
    secrets:
      <YOUR_SECRET_CONFIG_ID_1>:
        secret_id: <YOUR_SECRET_ID_1>
        region: <YOUR_REGION_1>
        sts_role_arn: <YOUR_STS_ROLE_ARN_1>
        refresh_interval: <YOUR_REFRESH_INTERVAL>
        disable_refresh: false
      <YOUR_SECRET_CONFIG_ID_2>:
        ...

----------------------------------------

TITLE: Dissociate Saved Objects API Endpoint
DESCRIPTION: API endpoint to remove associations between saved objects and a workspace.

LANGUAGE: json
CODE:
POST <osd host>:<port>/api/workspaces/_dissociate

----------------------------------------

TITLE: Performing a neural sparse search query
DESCRIPTION: Executes a search query using the neural_sparse clause to find relevant documents based on text input.

LANGUAGE: json
CODE:
GET my-nlp-index/_search
{
  "query": {
    "neural_sparse": {
      "passage_embedding": {
        "query_text": "Hi world",
        "model_id": "<model ID>"
      }
    }
  }
}

----------------------------------------

TITLE: Creating Semantic Search Workflow in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a semantic search workflow using the Flow Framework in OpenSearch. It automatically sets up an ingest pipeline and index for semantic search.

LANGUAGE: json
CODE:
POST /_plugins/_flow_framework/workflow?use_case=semantic_search&provision=true
{
  "create_ingest_pipeline.model_id": "mBGzipQB2gmRjlv_dOoB"
}

----------------------------------------

TITLE: Train and Predict with K-means Using Direct Data Input
DESCRIPTION: Example request demonstrating k-means training and prediction with directly provided data. Uses EUCLIDEAN distance with 2 centroids and 1 iteration on a dataset with two features.

LANGUAGE: json
CODE:
POST /_plugins/_ml/_train_predict/kmeans
{
    "parameters": {
        "centroids": 2,
        "iterations": 1,
        "distance_type": "EUCLIDEAN"
    },
    "input_data": {
        "column_metas": [
            {
                "name": "k1",
                "column_type": "DOUBLE"
            },
            {
                "name": "k2",
                "column_type": "DOUBLE"
            }
        ],
        "rows": [
            {
                "values": [
                    {
                        "column_type": "DOUBLE",
                        "value": 1.00
                    },
                    {
                        "column_type": "DOUBLE",
                        "value": 2.00
                    }
                ]
            },
            {
                "values": [
                    {
                        "column_type": "DOUBLE",
                        "value": 1.00
                    },
                    {
                        "column_type": "DOUBLE",
                        "value": 4.00
                    }
                ]
            },
            {
                "values": [
                    {
                        "column_type": "DOUBLE",
                        "value": 1.00
                    },
                    {
                        "column_type": "DOUBLE",
                        "value": 0.00
                    }
                ]
            },
            {
                "values": [
                    {
                        "column_type": "DOUBLE",
                        "value": 10.00
                    },
                    {
                        "column_type": "DOUBLE",
                        "value": 2.00
                    }
                ]
            },
            {
                "values": [
                    {
                        "column_type": "DOUBLE",
                        "value": 10.00
                    },
                    {
                        "column_type": "DOUBLE",
                        "value": 4.00
                    }
                ]
            },
            {
                "values": [
                    {
                        "column_type": "DOUBLE",
                        "value": 10.00
                    },
                    {
                        "column_type": "DOUBLE",
                        "value": 0.00
                    }
                ]
            }
        ]
    }
}

----------------------------------------

TITLE: Expanded Match Phrase Query with Parameters
DESCRIPTION: An expanded match_phrase query that includes additional parameters like analyzer specification.

LANGUAGE: json
CODE:
GET _search
{
  "query": {
    "match_phrase": {
      "title": {
        "query": "the wind",
        "analyzer": "stop"
      }
    }
  }
}

----------------------------------------

TITLE: Updating Helm Chart Repositories
DESCRIPTION: Command to update the available charts locally from chart repositories.

LANGUAGE: bash
CODE:
helm repo update

----------------------------------------

TITLE: Performing a Sliced Scroll Search in OpenSearch
DESCRIPTION: This snippet shows how to perform a sliced scroll search in OpenSearch. It sets up a slice with ID 0 out of a maximum of 10 slices, allowing for parallel scroll operations on the same dataset.

LANGUAGE: json
CODE:
GET shakespeare/_search?scroll=10m
{
  "slice": {
    "id": 0,
    "max": 10
  },
  "query": {
    "match_all": {}
  }
}

----------------------------------------

TITLE: Creating Pipeline with Append Processor in OpenSearch
DESCRIPTION: Example of creating an ingest pipeline named 'user-behavior' that appends 'page_view' to an event_types array field.

LANGUAGE: json
CODE:
PUT _ingest/pipeline/user-behavior
{
  "description": "Pipeline that appends event type",
  "processors": [
    {
      "append": {
        "field": "event_types",
        "value": ["page_view"]
      }
    }
  ]
}

----------------------------------------

TITLE: Using a Search Pipeline with Score Ranker Processor in OpenSearch
DESCRIPTION: This example shows how to apply a search pipeline with a score-ranker-processor, specifying a custom rank_constant as part of the pipeline configuration.

LANGUAGE: json
CODE:
PUT /_search/pipeline/<rrf-pipeline>
{
  "description": "Post processor for hybrid RRF search",
  "phase_results_processors": [
    {
      "score-ranker-processor": {
        "combination": {
          "technique": "rrf",
          "rank_constant": 40
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Register Restricted Model Group with All Roles
DESCRIPTION: Example request for registering a model group with restricted access mode and all backend roles

LANGUAGE: json
CODE:
{
    "name": "model_group_test",
    "description": "This is an example description",
    "access_mode": "restricted",
    "add_all_backend_roles": "true"
}

----------------------------------------

TITLE: Initiating a Scroll Search in OpenSearch
DESCRIPTION: This snippet shows how to start a scroll search in OpenSearch. It sets a scroll time of 10 minutes and a batch size of 10,000 results. This method is useful for retrieving large volumes of data.

LANGUAGE: json
CODE:
GET shakespeare/_search?scroll=10m
{
  "size": 10000
}

----------------------------------------

TITLE: Retrieving Segments for All Points in Time (PITs) in OpenSearch
DESCRIPTION: Retrieves segment information for all PITs in the OpenSearch cluster using a GET request.

LANGUAGE: json
CODE:
GET /_cat/pit_segments/_all

----------------------------------------

TITLE: Complete Delete by Query Example Request
DESCRIPTION: Full example of a Delete by Query request targeting a specific index with a match query.

LANGUAGE: json
CODE:
POST sample-index1/_delete_by_query
{
  "query": {
    "match": {
      "movie-length": "124"
    }
  }
}

----------------------------------------

TITLE: Performing Search with Reranking in OpenSearch
DESCRIPTION: This JSON request performs a search on the 'nyc_areas' index using the created search pipeline. It searches for specified terms in the 'description' and 'facts' fields and applies reranking using the cross-encoder model.

LANGUAGE: json
CODE:
POST /nyc_areas/_search?search_pipeline=my_pipeline
{
  "query": {
    "multi_match": {
      "query": "artists art creative community",
      "fields": ["description", "facts"]
    }
  }
}

----------------------------------------

TITLE: Clearing Query Cache in OpenSearch
DESCRIPTION: Example request to clear only the query cache for a specific index in OpenSearch.

LANGUAGE: json
CODE:
POST /my-index/_cache/clear?query=true

----------------------------------------

TITLE: Match Query with Custom Analyzer in OpenSearch
DESCRIPTION: A Match query using a custom analyzer (English) for text analysis.

LANGUAGE: json
CODE:
GET testindex/_search
{
  "query": {
    "match": {
      "title": {
        "query": "the wind rises",
        "operator": "and",
        "analyzer": "english"
      }
    }
  }
}

----------------------------------------

TITLE: Bulk Request Body Structure in OpenSearch
DESCRIPTION: Demonstrates the structure of a bulk request body in OpenSearch. Each action and its metadata are followed by an optional document, with each line separated by a newline character.

LANGUAGE: json
CODE:
Action and metadata\n
Optional document\n
Action and metadata\n
Optional document\n

----------------------------------------

TITLE: Creating Knowledge Base Index in OpenSearch
DESCRIPTION: Defines an index mapping with text and vector fields for storing stock price data with embeddings.

LANGUAGE: json
CODE:
PUT test_stock_price_data
{
  "mappings": {
    "properties": {
      "stock_price_history": {
        "type": "text"
      },
      "stock_price_history_embedding": {
        "type": "knn_vector",
        "dimension": 384
      }
    }
  },
  "settings": {
    "index": {
      "knn.space_type": "cosinesimil",
      "default_pipeline": "test_stock_price_data_pipeline",
      "knn": "true"
    }
  }
}

----------------------------------------

TITLE: Installing OpenSearch Ruby Client
DESCRIPTION: Commands for installing the OpenSearch Ruby client gem and importing it as a module.

LANGUAGE: bash
CODE:
gem install opensearch-ruby

LANGUAGE: ruby
CODE:
require 'opensearch'

----------------------------------------

TITLE: Indexing Document with Specific ID in OpenSearch
DESCRIPTION: This snippet demonstrates how to index a document with a specific ID in OpenSearch. It uses the PUT method and includes 'title' and 'year' fields in the document body.

LANGUAGE: json
CODE:
PUT my-logs/_doc/1
{
  "title": "Weathering with You",
  "year": "2019"
}

----------------------------------------

TITLE: Adding OpenSearch Helm Chart Repository
DESCRIPTION: Command to add the OpenSearch helm-charts repository to Helm for installation.

LANGUAGE: bash
CODE:
helm repo add opensearch https://opensearch-project.github.io/helm-charts/

----------------------------------------

TITLE: Routed Search Query in OpenSearch
DESCRIPTION: Demonstrates how to perform a search query with a specific routing value to target particular shards.

LANGUAGE: json
CODE:
GET /index1/_search?routing=user1
{
  "query": {
    "match": {
      "name": "John Doe"
    }
  }
}

----------------------------------------

TITLE: Executing Multi-Match Query with SQL and PPL in OpenSearch
DESCRIPTION: Examples of using the MULTI_MATCH function in SQL and PPL to search for text across multiple fields. Demonstrates syntax and usage with field boosting.

LANGUAGE: sql
CODE:
SELECT firstname, lastname
FROM accounts
WHERE multi_match(['*name'], 'Dale')

LANGUAGE: ppl
CODE:
SOURCE=accounts | WHERE multi_match(['*name'], 'Dale') | fields firstname, lastname

----------------------------------------

TITLE: Configuring Remote Cluster Connection in Sniff Mode
DESCRIPTION: JSON configuration for setting up a remote cluster connection using sniff mode, specifying seed nodes for cluster discovery.

LANGUAGE: json
CODE:
{
  "persistent": {
    "cluster": {
      "remote": {
        "my-connection-alias": {
          "seeds": ["172.22.0.3:9300"]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Delete Index Example Request
DESCRIPTION: Example of how to delete a specific index named 'sample-index'.

LANGUAGE: json
CODE:
DELETE /sample-index

----------------------------------------

TITLE: Versioning Search Pipeline in OpenSearch
DESCRIPTION: Demonstrates how to create a versioned search pipeline and retrieve version information.

LANGUAGE: json
CODE:
PUT _search/pipeline/my_pipeline
{
  "version": 1234,
  "request_processors": [
    {
      "script": {
        "source": """
           if (ctx._source['size'] > 100) {
             ctx._source['explain'] = false;
           }
         """
      }
    }
  ]
}

----------------------------------------

TITLE: Generating a Root Certificate for OpenSSL
DESCRIPTION: Command to create a self-signed root certificate using the private key, valid for 730 days.

LANGUAGE: bash
CODE:
openssl req -new -x509 -sha256 -key root-ca-key.pem -out root-ca.pem -days 730

----------------------------------------

TITLE: Example Request for Deleting a Document in OpenSearch
DESCRIPTION: This example shows how to delete a document with ID 1 from the 'sample-index1' index using the Delete Document API.

LANGUAGE: json
CODE:
DELETE /sample-index1/_doc/1

----------------------------------------

TITLE: Creating Search Pipeline with Neural Query Enricher in OpenSearch
DESCRIPTION: Example of creating a search pipeline that configures default ML model IDs at both index and field levels. The processor assigns a global default model ID and specific model IDs for individual fields.

LANGUAGE: json
CODE:
PUT /_search/pipeline/default_model_pipeline 
{
  "request_processors": [
    {
      "neural_query_enricher" : {
        "tag": "tag1",
        "description": "Sets the default model ID at index and field levels",
        "default_model_id": "u5j0qYoBMtvQlfhaxOsa",
        "neural_field_default_id": {
           "my_field_1": "uZj0qYoBMtvQlfhaYeud",
           "my_field_2": "upj0qYoBMtvQlfhaZOuM"
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Basic OpenSearch Sink Configuration
DESCRIPTION: Basic configuration example for the OpenSearch sink plugin with authentication and connection settings

LANGUAGE: yaml
CODE:
pipeline:
  ...
  sink:
    opensearch:
      hosts: ["https://localhost:9200"]
      cert: path/to/cert
      username: YOUR_USERNAME
      password: YOUR_PASSWORD
      index_type: trace-analytics-raw
      dlq_file: /your/local/dlq-file
      max_retries: 20
      bulk_size: 4

----------------------------------------

TITLE: Put Mapping Success Response
DESCRIPTION: Example of a successful response from the put mapping API operation.

LANGUAGE: json
CODE:
{
    "acknowledged": true
}

----------------------------------------

TITLE: Creating an OpenAI Chat Connector in OpenSearch
DESCRIPTION: This example demonstrates how to create a standalone connector for OpenAI's Chat API. It includes parameters for the endpoint, model, credentials, and the predict action configuration.

LANGUAGE: json
CODE:
POST /_plugins/_ml/connectors/_create
{
    "name": "OpenAI Chat Connector",
    "description": "The connector to public OpenAI model service for GPT 3.5",
    "version": 1,
    "protocol": "http",
    "parameters": {
        "endpoint": "api.openai.com",
        "model": "gpt-3.5-turbo"
    },
    "credential": {
        "openAI_key": "..."
    },
    "actions": [
        {
            "action_type": "predict",
            "method": "POST",
            "url": "https://${parameters.endpoint}/v1/chat/completions",
            "headers": {
                "Authorization": "Bearer ${credential.openAI_key}"
            },
            "request_body": "{ \"model\": \"${parameters.model}\", \"messages\": ${parameters.messages} }"
        }
    ]
}

----------------------------------------

TITLE: Sample Script for Generating Self-Signed PEM Certificates
DESCRIPTION: Comprehensive bash script to generate root CA, admin, node, and client certificates for OpenSearch.

LANGUAGE: bash
CODE:
#!/bin/sh
# Root CA
openssl genrsa -out root-ca-key.pem 2048
openssl req -new -x509 -sha256 -key root-ca-key.pem -subj "/C=CA/ST=ONTARIO/L=TORONTO/O=ORG/OU=UNIT/CN=root.dns.a-record" -out root-ca.pem -days 730
# Admin cert
openssl genrsa -out admin-key-temp.pem 2048
openssl pkcs8 -inform PEM -outform PEM -in admin-key-temp.pem -topk8 -nocrypt -v1 PBE-SHA1-3DES -out admin-key.pem
openssl req -new -key admin-key.pem -subj "/C=CA/ST=ONTARIO/L=TORONTO/O=ORG/OU=UNIT/CN=A" -out admin.csr
openssl x509 -req -in admin.csr -CA root-ca.pem -CAkey root-ca-key.pem -CAcreateserial -sha256 -out admin.pem -days 730
# Node cert 1
openssl genrsa -out node1-key-temp.pem 2048
openssl pkcs8 -inform PEM -outform PEM -in node1-key-temp.pem -topk8 -nocrypt -v1 PBE-SHA1-3DES -out node1-key.pem
openssl req -new -key node1-key.pem -subj "/C=CA/ST=ONTARIO/L=TORONTO/O=ORG/OU=UNIT/CN=node1.dns.a-record" -out node1.csr
echo 'subjectAltName=DNS:node1.dns.a-record' > node1.ext
openssl x509 -req -in node1.csr -CA root-ca.pem -CAkey root-ca-key.pem -CAcreateserial -sha256 -out node1.pem -days 730 -extfile node1.ext
# Node cert 2
openssl genrsa -out node2-key-temp.pem 2048
openssl pkcs8 -inform PEM -outform PEM -in node2-key-temp.pem -topk8 -nocrypt -v1 PBE-SHA1-3DES -out node2-key.pem
openssl req -new -key node2-key.pem -subj "/C=CA/ST=ONTARIO/L=TORONTO/O=ORG/OU=UNIT/CN=node2.dns.a-record" -out node2.csr
echo 'subjectAltName=DNS:node2.dns.a-record' > node2.ext
openssl x509 -req -in node2.csr -CA root-ca.pem -CAkey root-ca-key.pem -CAcreateserial -sha256 -out node2.pem -days 730 -extfile node2.ext
# Client cert
openssl genrsa -out client-key-temp.pem 2048
openssl pkcs8 -inform PEM -outform PEM -in client-key-temp.pem -topk8 -nocrypt -v1 PBE-SHA1-3DES -out client-key.pem
openssl req -new -key client-key.pem -subj "/C=CA/ST=ONTARIO/L=TORONTO/O=ORG/OU=UNIT/CN=client.dns.a-record" -out client.csr
echo 'subjectAltName=DNS:client.dns.a-record' > client.ext
openssl x509 -req -in client.csr -CA root-ca.pem -CAkey root-ca-key.pem -CAcreateserial -sha256 -out client.pem -days 730 -extfile client.ext
# Cleanup
rm admin-key-temp.pem
rm admin.csr
rm node1-key-temp.pem
rm node1.csr
rm node1.ext
rm node2-key-temp.pem
rm node2.csr
rm node2.ext
rm client-key-temp.pem
rm client.csr
rm client.ext

----------------------------------------

TITLE: Creating Single-Entity Anomaly Detector in OpenSearch
DESCRIPTION: Creates a single-entity anomaly detector that finds anomalies based on sum aggregation of a value field. Specifies detection interval, window delay and custom result index.

LANGUAGE: json
CODE:
POST _plugins/_anomaly_detection/detectors
{
  "name": "test-detector",
  "description": "Test detector",
  "time_field": "timestamp",
  "indices": [
    "server_log*"
  ],
  "feature_attributes": [
    {
      "feature_name": "test",
      "feature_enabled": true,
      "aggregation_query": {
        "test": {
          "sum": {
            "field": "value"
          }
        }
      }
    }
  ],
  "filter_query": {
    "bool": {
      "filter": [
        {
          "range": {
            "value": {
              "gt": 1
            }
          }
        }
      ],
      "adjust_pure_negative": true,
      "boost": 1
    }
  },
  "detection_interval": {
    "period": {
      "interval": 1,
      "unit": "Minutes"
    }
  },
  "window_delay": {
    "period": {
      "interval": 1,
      "unit": "Minutes"
    }
  },
  "result_index" : "opensearch-ad-plugin-result-test"
}

----------------------------------------

TITLE: Executing a Vector Search Query Using the Registered Agent in OpenSearch
DESCRIPTION: This snippet demonstrates how to execute a vector search query using the previously registered agent, providing a natural language question as input.

LANGUAGE: json
CODE:
POST /_plugins/_ml/agents/9X7xWI0Bpc3sThaJdY9i/_execute
{
  "parameters": {
    "question": "what's the population increase of Seattle from 2021 to 2023"
  }
}

----------------------------------------

TITLE: Loading OpenSearch PHP Client
DESCRIPTION: Required code to load the OpenSearch client autoloader

LANGUAGE: php
CODE:
require __DIR__ . '/vendor/autoload.php';

----------------------------------------

TITLE: Example operations in _operations/default.json for OpenSearch Benchmark
DESCRIPTION: Shows a list of supported operations from the nyc_taxis workload's _operations/default.json file. This includes various search and aggregation operations that can be used in test procedures.

LANGUAGE: json
CODE:
[
    {
      "name": "index",
      "operation-type": "bulk",
      "bulk-size": {% raw %}{{bulk_size | default(10000)}},
      "ingest-percentage": {{ingest_percentage | default(100)}}{% endraw %}
    },
    {
      "name": "update",
      "operation-type": "bulk",
      "bulk-size": {% raw %}{{bulk_size | default(10000)}},
      "ingest-percentage": {{ingest_percentage | default(100)}},
      "conflicts": "{{conflicts | default('random')}}",
      "on-conflict": "{{on_conflict | default('update')}}",
      "conflict-probability": {{conflict_probability | default(25)}},
      "recency": {{recency | default(0)}}{% endraw %}
    },
    {
      "name": "wait-until-merges-finish",
      "operation-type": "index-stats",
      "index": "_all",
      "condition": {
        "path": "_all.total.merges.current",
        "expected-value": 0
      },
      "retry-until-success": true,
      "include-in-reporting": false
    },
    {
      "name": "default",
      "operation-type": "search",
      "body": {
        "query": {
          "match_all": {}
        }
      }
    },
    {
      "name": "range",
      "operation-type": "search",
      "body": {
        "query": {
          "range": {
            "total_amount": {
              "gte": 5,
              "lt": 15
            }
          }
        }
      }
    },
    {
      "name": "distance_amount_agg",
      "operation-type": "search",
      "body": {
        "size": 0,
        "query": {
          "bool": {
            "filter": {
              "range": {
                "trip_distance": {
                  "lt": 50,
                  "gte": 0
                }
              }
            }
          }
        },
        "aggs": {
          "distance_histo": {
            "histogram": {
              "field": "trip_distance",
              "interval": 1
            },
            "aggs": {
              "total_amount_stats": {
                "stats": {
                  "field": "total_amount"
                }
              }
            }
          }
        }
      }
    }
]

----------------------------------------

TITLE: Adding Tokio Dependency to Cargo.toml
DESCRIPTION: Add the Tokio dependency to Cargo.toml for asynchronous functionality.

LANGUAGE: rust
CODE:
tokio = { version = "*", features = ["full"] }

----------------------------------------

TITLE: Porter Stem Analyzer Token Output in OpenSearch
DESCRIPTION: This snippet shows the response from the '_analyze' endpoint, displaying the tokens generated by the Porter stem analyzer. It demonstrates how 'running' and 'runners' are stemmed to their base forms.

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "run",
      "start_offset": 0,
      "end_offset": 7,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "runner",
      "start_offset": 8,
      "end_offset": 15,
      "type": "<ALPHANUM>",
      "position": 1
    },
    {
      "token": "ran",
      "start_offset": 16,
      "end_offset": 19,
      "type": "<ALPHANUM>",
      "position": 2
    }
  ]
}

----------------------------------------

TITLE: Clearing Cache for Multiple Indexes in OpenSearch
DESCRIPTION: Example request to clear the cache for two specific indexes in OpenSearch.

LANGUAGE: json
CODE:
POST /my-index,my-index2/_cache/clear

----------------------------------------

TITLE: Basic Reindex Operation
DESCRIPTION: Copies all documents from a source index to a destination index using the _reindex API.

LANGUAGE: json
CODE:
POST _reindex
{
   "source":{
      "index":"source"
   },
   "dest":{
      "index":"destination"
   }
}

----------------------------------------

TITLE: Analyzing text with a custom word_delimiter_graph filter in OpenSearch
DESCRIPTION: This example shows how to use the _analyze API to test the custom analyzer with the word_delimiter_graph filter. It demonstrates the token generation for a sample text input.

LANGUAGE: json
CODE:
GET /my-custom-index/_analyze
{
  "analyzer": "custom_analyzer",
  "text": "FastCar's Model2023"
}

----------------------------------------

TITLE: Registering Flow Agent for CreateAnomalyDetectorTool
DESCRIPTION: Creates a flow agent that runs the CreateAnomalyDetectorTool by sending a POST request to register the agent with required parameters including model ID.

LANGUAGE: json
CODE:
POST /_plugins/_ml/agents/_register
{
  "name": "Test_Agent_For_Create_Anomaly_Detector_Tool",
  "type": "flow",
  "description": "this is a test agent for the CreateAnomalyDetectorTool",
  "memory": {
    "type": "demo"
  },
  "tools": [
      {
      "type": "CreateAnomalyDetectorTool",
      "name": "DemoCreateAnomalyDetectorTool",
      "parameters": {
        "model_id": "<the model id of LLM>"
      }
    }
  ]
}

----------------------------------------

TITLE: Retrieving Top N Query Groups in OpenSearch
DESCRIPTION: Sends a GET request to retrieve the top N query groups and their metrics.

LANGUAGE: json
CODE:
GET /_insights/top_queries

----------------------------------------

TITLE: Testing Text Chunking Pipeline in OpenSearch
DESCRIPTION: Example of simulating the text chunking pipeline with a sample document to verify the chunking results.

LANGUAGE: json
CODE:
POST _ingest/pipeline/text-chunking-ingest-pipeline/_simulate
{
  "docs": [
    {
      "_index": "testindex",
      "_id": "1",
      "_source":{
         "passage_text": "This is an example document to be chunked. The document contains a single paragraph, two sentences and 24 tokens by standard tokenizer in OpenSearch."
      }
    }
  ]
}

----------------------------------------

TITLE: Training K-means Model Asynchronously
DESCRIPTION: Shows how to train a k-means model asynchronously by adding the async=true parameter. Uses the same configuration as the synchronous version but returns a task ID instead of waiting for completion.

LANGUAGE: json
CODE:
POST /_plugins/_ml/_train/kmeans?async=true
{
    "parameters": {
        "centroids": 3,
        "iterations": 10,
        "distance_type": "COSINE"
    },
    "input_query": {
        "_source": ["petal_length_in_cm", "petal_width_in_cm"],
        "size": 10000
    },
    "input_index": [
        "iris_data"
    ]
}

----------------------------------------

TITLE: Clearing Cache for All Indexes in OpenSearch
DESCRIPTION: Example request to clear the cache for all data streams and indexes in OpenSearch.

LANGUAGE: json
CODE:
POST /_cache/clear

----------------------------------------

TITLE: Role Configuration with Tenant Permissions
DESCRIPTION: Example of role configuration in roles.yml demonstrating how to assign tenant permissions to a role.

LANGUAGE: yaml
CODE:
---
test-role:
  reserved: false
  hidden: false
  cluster_permissions:
  - "cluster_composite_ops"
  - "indices_monitor"
  index_permissions:
  - index_patterns:
    - "movies*"
    dls: ""
    fls: []
    masked_fields: []
    allowed_actions:
    - "read"
  tenant_permissions:
  - tenant_patterns:
    - "human_resources"
    allowed_actions:
    - "kibana_all_read"
  static: false
_meta:
  type: "roles"
  config_version: 2

----------------------------------------

TITLE: Configuring Logger in Properties File
DESCRIPTION: Illustrates how to define a new logger and set its log level using the Log4j 2 property file syntax in log4j2.properties.

LANGUAGE: properties
CODE:
# Define a new logger with unique ID of reindex
logger.reindex.name = org.opensearch.index.reindex
# Set the log level for that ID
logger.reindex.level = debug

----------------------------------------

TITLE: Creating Basic Painless Script in OpenSearch
DESCRIPTION: Creates a stored script named 'my-first-script' that calculates the sum of ratings for each book document.

LANGUAGE: json
CODE:
PUT _scripts/my-first-script
{
  "script": {
      "lang": "painless",
      "source": """
          int total = 0;
          for (int i = 0; i < doc['ratings'].length; ++i) {
            total += doc['ratings'][i];
          }
          return total;
        """
  }
}

----------------------------------------

TITLE: Testing the OpenAI GPT-4o Model in OpenSearch
DESCRIPTION: This snippet demonstrates how to test the registered OpenAI GPT-4o model by sending a prediction request. It includes a system message and a user question about the 2020 World Series.

LANGUAGE: json
CODE:
POST /_plugins/_ml/models/your_model_id/_predict
{
  "parameters": {
    "messages": [
      {
        "role": "system",
        "content": "You are a helpful assistant."
      },
      {
        "role": "user",
        "content": "Who won the world series in 2020?"
      }
    ]
  }
}

----------------------------------------

TITLE: Subquery Example with IN Clause
DESCRIPTION: Shows how to use a subquery with IN clause to filter accounts with balance over 10000

LANGUAGE: sql
CODE:
SELECT a1.firstname, a1.lastname, a1.balance
FROM accounts a1
WHERE a1.account_number IN (
  SELECT a2.account_number
  FROM accounts a2
  WHERE a2.balance > 10000
)

----------------------------------------

TITLE: Parsing Streaming Bulk API Response in OpenSearch
DESCRIPTION: Shows an example of the streaming response from a bulk operation, including successful and failed operations with detailed error messages.

LANGUAGE: json
CODE:
{"took": 11, "errors": false, "items": [ { "index": {"_index": "movies", "_id": "tt1979320", "_version": 1, "result": "created", "_shards": { "total": 2 "successful": 1, "failed": 0 }, "_seq_no": 1, "_primary_term": 1, "status": 201 } } ] }
{"took": 2, "errors": true, "items": [ { "create": { "_index": "movies", "_id": "tt1392214", "status": 409, "error": { "type": "version_conflict_engine_exception", "reason": "[tt1392214]: version conflict, document already exists (current version [1])", "index": "movies", "shard": "0", "index_uuid": "yhizhusbSWmP0G7OJnmcLg" } } } ] }
{"took": 4, "errors": true, "items": [ { "update": { "_index": "movies", "_id": "tt0816711", "status": 404, "error": { "type": "document_missing_exception", "reason": "[_doc][tt0816711]: document missing", "index": "movies", "shard": "0", "index_uuid": "yhizhusbSWmP0G7OJnmcLg" } } } ] }

----------------------------------------

TITLE: Stop Token Filter Analysis Response
DESCRIPTION: Response showing the tokens generated after analysis, demonstrating how stopwords ("a" and "the") have been removed from the original text.

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "quick",
      "start_offset": 2,
      "end_offset": 7,
      "type": "<ALPHANUM>",
      "position": 1
    },
    {
      "token": "dog",
      "start_offset": 8,
      "end_offset": 11,
      "type": "<ALPHANUM>",
      "position": 2
    },
    {
      "token": "jumps",
      "start_offset": 12,
      "end_offset": 17,
      "type": "<ALPHANUM>",
      "position": 3
    },
    {
      "token": "over",
      "start_offset": 18,
      "end_offset": 22,
      "type": "<ALPHANUM>",
      "position": 4
    },
    {
      "token": "turtle",
      "start_offset": 27,
      "end_offset": 33,
      "type": "<ALPHANUM>",
      "position": 6
    }
  ]
}

----------------------------------------

TITLE: Basic Rename Processor Syntax in OpenSearch
DESCRIPTION: Basic JSON structure for configuring the rename processor to rename fields in documents.

LANGUAGE: json
CODE:
{
    "rename": {
        "field": "field_name",
        "target_field" : "target_field_name"
    }
}

----------------------------------------

TITLE: Custom Pattern-Based Phone Number Analyzer in OpenSearch
DESCRIPTION: Implements a custom analyzer for normalizing phone numbers by removing dashes and spaces, and applies edge n-grams for partial matching support.

LANGUAGE: json
CODE:
PUT advanced_pattern_replace_analyzer_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "phone_number_analyzer": {
          "type": "custom",
          "char_filter": ["phone_normalization"],
          "tokenizer": "standard",
          "filter": ["lowercase", "edge_ngram"]
        }
      },
      "char_filter": {
        "phone_normalization": {
          "type": "pattern_replace",
          "pattern": "[-\\s]",
          "replacement": ""
        }
      },
      "filter": {
        "edge_ngram": {
          "type": "edge_ngram",
          "min_gram": 3,
          "max_gram": 10
        }
      }
    }
  }
}

----------------------------------------

TITLE: Basic Prefix Query in OpenSearch
DESCRIPTION: Simple prefix query example that searches for documents where the 'speaker' field contains terms starting with 'KING H'.

LANGUAGE: json
CODE:
GET shakespeare/_search
{
  "query": {
    "prefix": {
      "speaker": "KING H"
    }
  }
}

----------------------------------------

TITLE: Max Distance Radial Search Query in OpenSearch
DESCRIPTION: Performs a radial search query using max_distance parameter to find vectors within a specified Euclidean distance.

LANGUAGE: json
CODE:
GET knn-index-test/_search
{
    "query": {
        "knn": {
            "my_vector": {
                "vector": [
                    7.1,
                    8.3
                ],
                "max_distance": 2
            }
        }
    }
}

----------------------------------------

TITLE: Configuring Search Thread Pool in OpenSearch
DESCRIPTION: Static configuration settings for the search thread pool size and queue capacity in opensearch.yml.

LANGUAGE: yaml
CODE:
thread_pool.search.size: 100
thread_pool.search.queue_size: 1000

----------------------------------------

TITLE: Optimizing Vector Storage in OpenSearch
DESCRIPTION: This example shows how to optimize vector storage by specifying a vector workload mode and compression level for a k-NN vector field.

LANGUAGE: json
CODE:
PUT test-index
{
  "settings": {
    "index": {
      "knn": true
    }
  },
  "mappings": {
    "properties": {
      "my_vector": {
        "type": "knn_vector",
        "dimension": 3,
        "space_type": "l2",
        "mode": "on_disk",
        "compression_level": "16x"
      }
    }
  }
}

----------------------------------------

TITLE: Performing a Sliced Scroll Search in OpenSearch
DESCRIPTION: This snippet illustrates how to perform a sliced scroll search, which allows for parallel scroll operations. It sets the slice ID to 0 and the maximum number of slices to 10.

LANGUAGE: json
CODE:
GET shakespeare/_search?scroll=10m
{
  "slice": {
    "id": 0,
    "max": 10
  },
  "query": {
    "match_all": {}
  }
}

----------------------------------------

TITLE: Multi-Match Query Examples
DESCRIPTION: Examples demonstrating multi-match queries with field weights and parameters.

LANGUAGE: sql
CODE:
multi_match('fields' = "Tags^2,Title^3.4,Body,Comments^0.3", ...)
multi_match('fields' = "Title", ...)

----------------------------------------

TITLE: Creating an index with mappings for derived fields
DESCRIPTION: Creates a 'logs' index with mappings for 'request' and 'clientip' fields, which will be used to derive additional fields.

LANGUAGE: json
CODE:
PUT logs
{
  "mappings": {
    "properties": {
      "request": {
        "type": "text",
        "fields": {
          "keyword": {
            "type": "keyword"
          }
        }
      },
      "clientip": {
        "type": "keyword"
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Custom Analyzer and Field Mapping in OpenSearch
DESCRIPTION: This snippet demonstrates how to define a custom analyzer called 'my_custom_analyzer' with specific tokenization and normalization settings, and then map a text field to use this analyzer for both indexing and searching.

LANGUAGE: json
CODE:
PUT my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_custom_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "my_stop_filter",
            "my_stemmer"
          ]
        }
      },
      "filter": {
        "my_stop_filter": {
          "type": "stop",
          "stopwords": ["the", "a", "and", "or"]
        },
        "my_stemmer": {
          "type": "stemmer",
          "language": "english"
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "my_text_field": {
        "type": "text",
        "analyzer": "my_custom_analyzer",
        "search_analyzer": "standard",
        "search_quote_analyzer": "my_custom_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Defining Clone Index API Endpoints in OpenSearch
DESCRIPTION: Specifies the HTTP methods and URL patterns for the Clone Index API endpoints in OpenSearch.

LANGUAGE: json
CODE:
POST /<source-index>/_clone/<target-index>
PUT /<source-index>/_clone/<target-index>

----------------------------------------

TITLE: Running Basic OpenSearch Benchmark Test
DESCRIPTION: Example of executing a test using the geonames workload in test mode with OpenSearch Benchmark.

LANGUAGE: bash
CODE:
opensearch-benchmark execute-test --workload=geonames --test-mode

----------------------------------------

TITLE: Expanded Match Query with Parameters in OpenSearch
DESCRIPTION: An expanded Match query with additional parameters like 'analyzer'.

LANGUAGE: json
CODE:
GET _search
{
  "query": {
    "match": {
      "title": {
        "query": "wind",
        "analyzer": "stop"
      }
    }
  }
}

----------------------------------------

TITLE: Faiss IVF Configuration
DESCRIPTION: Example of configuring IVF method without an encoder using the Faiss engine.

LANGUAGE: json
CODE:
"method": {
  "name":"ivf",
  "engine":"faiss",
  "parameters":{
    "nlist": 4,
    "nprobes": 2
  }
}

----------------------------------------

TITLE: Basic OpenSearch Connection Setup
DESCRIPTION: Examples of creating client connections with different configuration options

LANGUAGE: ruby
CODE:
client = OpenSearch::Client.new(host: 'http://localhost:9200')

LANGUAGE: ruby
CODE:
client = OpenSearch::Client.new(
    url: "http://localhost:9200",
    retry_on_failure: 5,
    request_timeout: 120,
    log: true
  )

client.cluster.health

----------------------------------------

TITLE: Configuring Max Slice Count at Index Level
DESCRIPTION: Sets the maximum slice count for concurrent segment search for a specific index.

LANGUAGE: json
CODE:
PUT <index-name>/_settings
{
    "index.search.concurrent.max_slice_count": 2
}

----------------------------------------

TITLE: Configuring Basic Data Prepper Pipeline in YAML
DESCRIPTION: This snippet demonstrates a basic Data Prepper pipeline configuration. It includes settings for workers, delay, source, buffer, processor, and sink components.

LANGUAGE: yaml
CODE:
simple-sample-pipeline:
  workers: 2 # the number of workers
  delay: 5000 # in milliseconds, how long workers wait between read attempts
  source:
    random:
  buffer:
    bounded_blocking:
      buffer_size: 1024 # max number of records the buffer accepts
      batch_size: 256 # max number of records the buffer drains after each read
  processor:
    - string_converter:
        upper_case: true
  sink:
    - stdout:

----------------------------------------

TITLE: Pipeline Reindex Operation
DESCRIPTION: Reindexes documents using a predefined ingest pipeline for data transformation.

LANGUAGE: json
CODE:
POST _reindex
{
  "source": {
    "index": "source"
  },
  "dest": {
    "index": "destination",
    "pipeline": "pipeline-test"
  }
}

----------------------------------------

TITLE: Executing SQL Query on OpenSearch Using Curl
DESCRIPTION: Demonstrates how to execute an SQL query on OpenSearch using the curl command-line tool. This example includes authentication and content-type headers.

LANGUAGE: bash
CODE:
curl -XPOST https://localhost:9200/_plugins/_sql -u 'admin:<custom-admin-password>' -k -H 'Content-Type: application/json' -d '{"query": "SELECT * FROM my-index* LIMIT 50"}'

----------------------------------------

TITLE: Configuring Encryption for Performance Analyzer
DESCRIPTION: Steps to enable encryption in transit for Performance Analyzer by modifying the performance-analyzer.properties file.

LANGUAGE: bash
CODE:
vi $OPENSEARCH_HOME/config/opensearch-performance-analyzer/performance-analyzer.properties

LANGUAGE: properties
CODE:
https-enabled = true

#Setup the correct path for certificates
certificate-file-path = specify_path

private-key-file-path = specify_path

----------------------------------------

TITLE: Creating Parameterized Painless Script in OpenSearch
DESCRIPTION: Creates a stored script named 'multiplier-script' that calculates the sum of ratings and multiplies it by a parameter value.

LANGUAGE: json
CODE:
PUT _scripts/multiplier-script
{
  "script": {
      "lang": "painless",
      "source": """
          int total = 0;
          for (int i = 0; i < doc['ratings'].length; ++i) {
            total += doc['ratings'][i];
          }
          return total * params['multiplier'];
        """
  }
}

----------------------------------------

TITLE: Configuring Reranking Pipeline
DESCRIPTION: JSON configuration for setting up a reranking pipeline using the deployed SageMaker model in OpenSearch.

LANGUAGE: json
CODE:
{
    "description": "Pipeline for reranking with Sagemaker cross-encoder model",
    "response_processors": [
        {
            "rerank": {
                "ml_opensearch": {
                    "model_id": "your_model_id"
                },
                "context": {
                    "document_fields": ["passage_text"]
                }
            }
        }
    ]
}

----------------------------------------

TITLE: Configuring REST Impersonation in OpenSearch YAML
DESCRIPTION: Configuration settings in opensearch.yml to enable REST interface impersonation. Defines which authenticated users can impersonate other users, with support for wildcards.

LANGUAGE: yaml
CODE:
plugins.security.authcz.rest_impersonation_user:
  <AUTHENTICATED_USER>:
    - <IMPERSONATED_USER_1>
    - <IMPERSONATED_USER_2>

----------------------------------------

TITLE: Updating Search Pipeline in OpenSearch
DESCRIPTION: Shows how to update an existing search pipeline by adding new processors using the Search Pipeline API.

LANGUAGE: json
CODE:
PUT /_search/pipeline/my_pipeline
{
  "request_processors": [
    {
      "filter_query": {
        "tag": "tag1",
        "description": "This processor returns only publicly visible documents",
        "query": {
          "term": {
            "visibility": "public"
          }
        }
      }
    }
  ],
  "response_processors": [
    {
      "rename_field": {
        "field": "message",
        "target_field": "notification"
      }
    }
  ]
}

----------------------------------------

TITLE: Configuring Conditional Routing in Data Prepper Pipeline
DESCRIPTION: This snippet shows how to implement conditional routing in a Data Prepper pipeline. It defines routes based on log types and directs events to different OpenSearch sinks accordingly.

LANGUAGE: yaml
CODE:
conditional-routing-sample-pipeline:
  source:
    http:
  processor:
  route:
    - application-logs: '/log_type == "application"'
    - http-logs: '/log_type == "apache"'
  sink:
    - opensearch:
        hosts: [ "https://opensearch:9200" ]
        index: application_logs
        routes: [application-logs]
    - opensearch:
        hosts: [ "https://opensearch:9200" ]
        index: http_logs
        routes: [http-logs]
    - opensearch:
        hosts: [ "https://opensearch:9200" ]
        index: all_logs

----------------------------------------

TITLE: Fine-tuned Binary Quantization Configuration
DESCRIPTION: Creates an index with detailed configuration including encoder settings and bits specification for binary quantization.

LANGUAGE: json
CODE:
PUT my-vector-index
{
  "settings" : {
    "index": {
      "knn": true
    }
  },
  "mappings": {
    "properties": {
      "my_vector_field": {
        "type": "knn_vector",
        "dimension": 8,
        "method": {
            "name": "hnsw",
            "engine": "faiss",
            "space_type": "l2",
            "parameters": {
              "m": 16,
              "ef_construction": 512,
              "encoder": {
                "name": "binary",
                "parameters": {
                  "bits": 1 
                }
              }
            }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating a mapping with xy point field type in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a mapping with an xy point field type in OpenSearch. It defines a field named 'point' of type 'xy_point'.

LANGUAGE: json
CODE:
PUT testindex1
{
  "mappings": {
    "properties": {
      "point": {
        "type": "xy_point"
      }
    }
  }
}

----------------------------------------

TITLE: Testing Predicate Token Filter Analyzer
DESCRIPTION: Demonstrates how to test the predicate analyzer by analyzing a sample text string. The analyzer will only return tokens that meet the predicate condition of being longer than 7 characters.

LANGUAGE: json
CODE:
POST /predicate_index/_analyze
{
  "text": "The OpenSearch community is growing rapidly",
  "analyzer": "predicate_analyzer"
}

----------------------------------------

TITLE: Disabling Shard Replication in OpenSearch
DESCRIPTION: This code snippet shows how to disable shard replication in OpenSearch by setting the cluster routing allocation to primaries only. This step is crucial before taking nodes offline for upgrading.

LANGUAGE: json
CODE:
PUT "/_cluster/settings?pretty"
{
    "persistent": {
        "cluster.routing.allocation.enable": "primaries"
    }
}

----------------------------------------

TITLE: Force Merge Primary Shards
DESCRIPTION: Example request demonstrating how to force merge only the primary shards of an index.

LANGUAGE: json
CODE:
POST /.testindex-logs/_forcemerge?primary_only=true

----------------------------------------

TITLE: Bulk Loading Vector Data in OpenSearch
DESCRIPTION: Adds multiple vector data points with associated prices to the KNN index using bulk API operations.

LANGUAGE: json
CODE:
PUT _bulk?refresh=true
{"index": {"_index": "knn-index-test", "_id": "1"}}
{"my_vector": [7.0, 8.2], "price": 4.4}
{"index": {"_index": "knn-index-test", "_id": "2"}}
{"my_vector": [7.1, 7.4], "price": 14.2}
{"index": {"_index": "knn-index-test", "_id": "3"}}
{"my_vector": [7.3, 8.3], "price": 19.1}
{"index": {"_index": "knn-index-test", "_id": "4"}}
{"my_vector": [6.5, 8.8], "price": 1.2}
{"index": {"_index": "knn-index-test", "_id": "5"}}
{"my_vector": [5.7, 7.9], "price": 16.5}

----------------------------------------

TITLE: Boosting Query in OpenSearch
DESCRIPTION: A boosting query that searches for 'pitcher' but downgrades documents containing 'glass', 'crystal', or 'water'. The negative_boost parameter is set to 0.1, reducing the relevance score of matching negative documents by a factor of 10.

LANGUAGE: json
CODE:
GET testindex/_search
{
  "query": {
    "boosting": {
      "positive": {
        "match": {
          "article_name": "pitcher"
        }
      },
      "negative": {
        "match": {
          "article_name": "glass crystal water"
        }
      },
      "negative_boost": 0.1
    }
  }
}

----------------------------------------

TITLE: Continuing a Scroll Search in OpenSearch
DESCRIPTION: This snippet demonstrates how to continue a scroll search in OpenSearch using a scroll ID. It sets the scroll time to 10 minutes and uses a previously obtained scroll ID to fetch the next batch of results.

LANGUAGE: json
CODE:
GET _search/scroll
{
  "scroll": "10m",
  "scroll_id": "DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAAUWdmpUZDhnRFBUcWFtV21nMmFwUGJEQQ=="
}

----------------------------------------

TITLE: Basic SQL Query Request
DESCRIPTION: Example of sending a basic SQL query to retrieve all records from the accounts table.

LANGUAGE: json
CODE:
{
  "query" : "SELECT * FROM accounts"
}

----------------------------------------

TITLE: Multiple Component Templates
DESCRIPTION: Demonstrates using multiple component templates with merge ordering to control final template configuration.

LANGUAGE: json
CODE:
PUT /_component_template/template_with_1_shard
{
  "template": {
    "settings": {
      "index.number_of_shards": 1
    }
  }
}

PUT /_component_template/template_with_2_shards
{
  "template": {
    "settings": {
      "index.number_of_shards": 2
    }
  }
}

PUT /_index_template/template_1
{
  "index_patterns": ["h*"],
  "composed_of": ["template_with_1_shard", "template_with_2_shards"]
}

----------------------------------------

TITLE: Testing a Sparse Encoding Model in OpenSearch
DESCRIPTION: JSON request to test a deployed sparse encoding model using the Predict API.

LANGUAGE: json
CODE:
POST /_plugins/_ml/_predict/sparse_encoding/cleMb4kBJ1eYAeTMFFg4
{
  "text_docs":[ "today is sunny"]
}

----------------------------------------

TITLE: Performing a neural sparse search query in OpenSearch
DESCRIPTION: This snippet demonstrates how to perform a neural sparse search query using the neural_sparse query type in OpenSearch, providing sparse embeddings as the search input.

LANGUAGE: json
CODE:
GET my-nlp-index/_search
{
  "query": {
    "neural_sparse": {
      "passage_embedding": {
        "query_tokens": {
          "hi" : 4.338913,
          "planets" : 2.7755864,
          "planet" : 5.0969057,
          "mars" : 1.7405145,
          "earth" : 2.6087382,
          "hello" : 3.3210192
        }
      }
    }
  }
}

----------------------------------------

TITLE: Basic Geo Distance Aggregation Syntax
DESCRIPTION: Generic syntax structure for creating a geo_distance aggregation in OpenSearch.

LANGUAGE: json
CODE:
{
  "aggs": {
    "aggregation_name": {
      "geo_distance": {
        "field": "field_1",
        "origin": "x, y",
        "ranges": [
          {
            "to": "value_1"
          },
          {
            "from": "value_2",
            "to": "value_3"
          },
          {
            "from": "value_4"
          }
        ]
      }
    }
  }
}

----------------------------------------

TITLE: OpenSearch Search API Response with Extended Fields
DESCRIPTION: Example of an OpenSearch search response including the 'ext' object, which contains plugin-specific response fields. This example demonstrates the inclusion of a Retrieval Augmented Generation (RAG) answer in the response.

LANGUAGE: json
CODE:
{
  "took": 3,
  "timed_out": false,
  "_shards": {
    "total": 3,
    "successful": 3,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 110,
      "relation": "eq"
    },
    "max_score": 0.55129033,
    "hits": [
      {
       "_index": "...",
        "_id": "...",
        "_score": 0.55129033,
        "_source": {
          "text": "...",
          "title": "..."
        }
      },
      {
      ...
      }
      ...
      {
      ...
      }
    ]
  },
  "ext": {
    "retrieval_augmented_generation": {
      "answer": "RAG answer"
    }
  }
}

----------------------------------------

TITLE: Enabling Telemetry Feature via Environment Variable
DESCRIPTION: Sets the OPENSEARCH_JAVA_OPTS environment variable to enable the experimental telemetry feature when starting OpenSearch.

LANGUAGE: bash
CODE:
OPENSEARCH_JAVA_OPTS="-Dopensearch.experimental.feature.telemetry.enabled=true" ./opensearch-2.9.0/bin/opensearch

----------------------------------------

TITLE: Analyzing Text with Custom Analyzer in OpenSearch
DESCRIPTION: Demonstrates how to analyze text using the custom analyzer with keyword marker filter.

LANGUAGE: json
CODE:
GET /my_index/_analyze
{
  "analyzer": "custom_analyzer",
  "text": "Favorite example"
}

----------------------------------------

TITLE: Set Processor Basic Syntax
DESCRIPTION: Basic syntax example of the Set processor configuration in an OpenSearch pipeline.

LANGUAGE: json
CODE:
{
  "description": "...",
  "processors": [
    {
      "set": {
        "field": "new_field",
        "value": "some_value"
      }
    }
  ]
}

----------------------------------------

TITLE: Creating Custom Dutch Analyzer in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a custom Dutch analyzer with specific token filters and rules for stemming override.

LANGUAGE: json
CODE:
PUT /dutch-index
{
  "settings": {
    "analysis": {
      "filter": {
        "dutch_stop": {
          "type": "stop",
          "stopwords": "_dutch_"
        },
        "dutch_stemmer": {
          "type": "stemmer",
          "language": "dutch"
        },
        "dutch_keywords": {
          "type": "keyword_marker",
          "keywords": []
        },
        "dutch_override": {
          "type": "stemmer_override",
          "rules": [
            "fiets=>fiets",
            "bromfiets=>bromfiets",
            "ei=>eier",
            "kind=>kinder"
          ]
        }
      },
      "analyzer": {
        "dutch_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "dutch_stop",
            "dutch_keywords",
            "dutch_override",
            "dutch_stemmer"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "dutch_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Performing a hybrid search
DESCRIPTION: Executes a hybrid search combining keyword and semantic queries using the hybrid query type and search pipeline.

LANGUAGE: json
CODE:
GET /my-nlp-index/_search?search_pipeline=nlp-search-pipeline
{
  "_source": {
    "exclude": [
      "passage_embedding"
    ]
  },
  "query": {
    "hybrid": {
      "queries": [
        {
          "match": {
            "text": {
              "query": "cowboy rodeo bronco"
            }
          }
        },
        {
          "neural": {
            "passage_embedding": {
              "query_text": "wild west",
              "model_id": "aVeif4oB5Vm0Tdw8zYO2",
              "k": 5
            }
          }
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Enabling Remote Cluster State Publication in OpenSearch YAML
DESCRIPTION: Configuration setting to enable remote cluster state publication feature for direct state fetching from remote store by follower nodes.

LANGUAGE: yaml
CODE:
# Enable Remote cluster state publication
cluster.remote_store.publication.enabled: true

----------------------------------------

TITLE: Creating Index with Dynamic Strict Allow Templates
DESCRIPTION: Creates an OpenSearch index that allows new fields matching predefined dynamic templates while rejecting other unmapped fields.

LANGUAGE: json
CODE:
PUT testindex1
{
  "mappings": {
    "dynamic": "strict_allow_templates",
    "dynamic_templates": [
      {
        "strings": {
          "match": "room*",
          "match_mapping_type": "string",
          "mapping": {
            "type": "keyword"
          }
        }
      }
    ],
    "properties": {
      "patient": {
        "properties": {
          "id": {
            "type": "keyword"
          },
          "name": {
            "type": "keyword"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Adding User Rating Feature to Existing Feature Set
DESCRIPTION: Shows how to append a new feature for user ratings to an existing feature set using the Feature Set Append API.

LANGUAGE: json
CODE:
{
    "features": [{
        "name": "user_rating",
        "params": [],
        "template_language": "mustache",
        "template" : {
            "function_score": {
                "functions": {
                    "field": "vote_average"
                },
                "query": {
                    "match_all": {}
                }
            }
        }
    }]
}

----------------------------------------

TITLE: Creating Searchable Snapshot Index
DESCRIPTION: JSON request for restoring an index as a searchable snapshot using the restore snapshots API.

LANGUAGE: json
CODE:
POST /_snapshot/my-repository/my-snapshot/_restore
{
  "storage_type": "remote_snapshot",
  "indices": "my-index"
}

----------------------------------------

TITLE: Querying Performance Analyzer Metrics in OpenSearch
DESCRIPTION: Demonstrates how to query Performance Analyzer metrics using the HTTP GET method. The request includes parameters for metrics, aggregations, dimensions, and nodes.

LANGUAGE: http
CODE:
GET <endpoint>:9600/_plugins/_performanceanalyzer/metrics

LANGUAGE: http
CODE:
?metrics=<metrics>&agg=<aggregations>&dim=<dimensions>&nodes=all"

----------------------------------------

TITLE: Querying OpenSearch with Range Aggregation
DESCRIPTION: This query demonstrates how to use range aggregation to distribute log data into buckets based on byte ranges. It defines three ranges: 1000-2000, 2000-3000, and 3000-4000 bytes.

LANGUAGE: json
CODE:
GET opensearch_dashboards_sample_data_logs/_search
{
  "size": 0,
  "aggs": {
    "number_of_bytes_distribution": {
      "range": {
        "field": "bytes",
        "ranges": [
          {
            "from": 1000,
            "to": 2000
          },
          {
            "from": 2000,
            "to": 3000
          },
          {
            "from": 3000,
            "to": 4000
          }
        ]
      }
    }
  }
}

----------------------------------------

TITLE: Example Request for Updating Index Settings in OpenSearch
DESCRIPTION: This snippet provides a complete example of an Update Settings API request. It updates the index state management rollover skip setting and the number of replicas for a specific index named 'sample-index1'.

LANGUAGE: json
CODE:
PUT /sample-index1/_settings
{
  "index.plugins.index_state_management.rollover_skip": true,
  "index": {
    "number_of_replicas": 4
  }
}

----------------------------------------

TITLE: Example Response from Significant Text Query
DESCRIPTION: Sample response showing the aggregation results with significant terms related to 'breathe', including their document counts, background counts, and significance scores.

LANGUAGE: json
CODE:
"aggregations" : {
  "my_sample" : {
    "doc_count" : 59,
    "keywords" : {
      "doc_count" : 59,
      "bg_count" : 111396,
      "buckets" : [
        {
          "key" : "breathe",
          "doc_count" : 59,
          "score" : 1887.0677966101694,
          "bg_count" : 59
        },
        {
          "key" : "air",
          "doc_count" : 4,
          "score" : 2.641295376716233,
          "bg_count" : 189
        },
        {
          "key" : "dead",
          "doc_count" : 4,
          "score" : 0.9665839666414213,
          "bg_count" : 495
        },
        {
          "key" : "life",
          "doc_count" : 5,
          "score" : 0.9090787433467572,
          "bg_count" : 805
        }
      ]
    }
  }
 }
}

----------------------------------------

TITLE: Search-as-You-Type Field Mapping in OpenSearch
DESCRIPTION: Demonstrates how to map a field as search_as_you_type, which is optimized for search-as-you-type functionality and can match terms using both prefix and infix completion.

LANGUAGE: json
CODE:
PUT shakespeare
{
  "mappings": {
    "properties": {
      "text_entry": {
        "type": "search_as_you_type"
      }
    }
  }
}

----------------------------------------

TITLE: Configuring OpenSearch Cluster Settings for Model Registration
DESCRIPTION: Updates cluster settings to allow registering models via URLs and running models on non-ML nodes.

LANGUAGE: json
CODE:
PUT _cluster/settings
{
  "persistent": {
    "plugins.ml_commons.allow_registering_model_via_url": "true",
    "plugins.ml_commons.only_run_on_ml_node": "false",
    "plugins.ml_commons.model_access_control_enabled": "true",
    "plugins.ml_commons.native_memory_threshold": "99"
  }
}

----------------------------------------

TITLE: Using HAVING Clause in OpenSearch SQL
DESCRIPTION: Example of using the HAVING clause to filter grouped results based on an aggregation condition in OpenSearch SQL.

LANGUAGE: sql
CODE:
SELECT age, MAX(balance)
FROM accounts
GROUP BY age HAVING MIN(balance) > 10000

----------------------------------------

TITLE: Querying Vector Data with Faiss Scalar Quantization in OpenSearch
DESCRIPTION: This example demonstrates how to query vector data using Faiss scalar quantization in OpenSearch. The query vector has no range limitation during the search process.

LANGUAGE: json
CODE:
GET test-index/_search
{
  "size": 2,
  "query": {
    "knn": {
      "my_vector1": {
        "vector": [265436.876, -120906.256, 99.84],
        "k": 2
      }
    }
  }
}

----------------------------------------

TITLE: Querying Extended Stats for Taxful Total Price in OpenSearch
DESCRIPTION: This snippet demonstrates how to use the extended_stats aggregation to get comprehensive statistical data for the 'taxful_total_price' field in an OpenSearch index.

LANGUAGE: json
CODE:
GET opensearch_dashboards_sample_data_ecommerce/_search
{
  "size": 0,
  "aggs": {
    "extended_stats_taxful_total_price": {
      "extended_stats": {
        "field": "taxful_total_price"
      }
    }
  }
}

----------------------------------------

TITLE: Authenticating from within an AWS Lambda Function
DESCRIPTION: JavaScript code demonstrating the correct initialization of the OpenSearch client within an AWS Lambda function.

LANGUAGE: javascript
CODE:
const { defaultProvider } = require('@aws-sdk/credential-provider-node');
const { Client } = require('@opensearch-project/opensearch');
const { AwsSigv4Signer } = require('@opensearch-project/opensearch/aws');

const client = new Client({
  ...AwsSigv4Signer({
    region: 'us-east-1',
    service: 'es',
    getCredentials: () => {
      const credentialsProvider = defaultProvider();
      return credentialsProvider();
    },
  }),
  node: 'https://search-xxx.region.es.amazonaws.com',
});

export const handler = async (event, context) => {
  const indexName = "books";

  const settings = {
    settings: {
      index: {
        number_of_shards: 4,
        number_of_replicas: 3,
      },
    },
  };

  const response = await client.indices.create({
    index: indexName,
    body: settings,
  });

};

----------------------------------------

TITLE: Installing Querqy Plugin for OpenSearch 2.3
DESCRIPTION: Command to install the Querqy plugin for OpenSearch 2.3.0. This command downloads and installs the plugin from the Maven repository. Users should answer 'yes' to security prompts during installation.

LANGUAGE: bash
CODE:
./bin/opensearch-plugin install \
   "https://repo1.maven.org/maven2/org/querqy/opensearch-querqy/1.0.os2.3.0/opensearch-querqy-1.0.os2.3.0.zip"

----------------------------------------

TITLE: Sample List Request for Dangling Indexes in OpenSearch
DESCRIPTION: This is an example of how to list dangling indexes using a GET request to the /_dangling endpoint.

LANGUAGE: bash
CODE:
GET /_dangling

----------------------------------------

TITLE: Retrieving Document Source
DESCRIPTION: Endpoints for retrieving or verifying existence of a document's source content.

LANGUAGE: json
CODE:
GET <index>/_source/<_id>\nHEAD <index>/_source/<_id>

----------------------------------------

TITLE: Sorting on Multiple Fields in OpenSearch
DESCRIPTION: This example shows how to sort results by multiple fields. It sorts first by 'line_id' in descending order, then by 'speech_number' also in descending order.

LANGUAGE: json
CODE:
GET shakespeare/_search
{
  "query": {
    "term": {
      "play_name": {
        "value": "Henry IV"
      }
    }
  },
  "sort": [
    {
      "line_id": {
        "order": "desc"
      }
    },
    {
      "speech_number": {
        "order": "desc"
      }
    }
  ]
}

----------------------------------------

TITLE: Indexing Documents for Term Suggester in OpenSearch
DESCRIPTION: Example of indexing documents into a 'books' index to be used with the term suggester. The 'title' field is automatically mapped as text and tokenized.

LANGUAGE: json
CODE:
PUT books/_doc/1
{
  "title": "Design Patterns (Object-Oriented Software)"
}

PUT books/_doc/2
{
  "title": "Software Architecture Patterns Explained"
}

----------------------------------------

TITLE: Using Post-Filter to Narrow Results While Preserving Aggregations in OpenSearch
DESCRIPTION: This snippet shows how to use post_filter to limit search hits to a specific brand while maintaining all brand options in the aggregations for smartphones.

LANGUAGE: json
CODE:
GET /electronics/_search
{
  "query": {
    "bool": {
      "filter": { "term": { "category": "Smartphone" }}
    }
  },
  "aggs": {
    "brands": {
      "terms": { "field": "brand" }
    }
  },
  "post_filter": {
    "term": { "brand": "BrandA" }
  }
}

----------------------------------------

TITLE: Creating Multifields in OpenSearch Mappings
DESCRIPTION: Shows how to create multifields in OpenSearch mappings. This example maps a 'title' field as both 'text' for full-text search and 'keyword' (as a subfield) for exact matching.

LANGUAGE: json
CODE:
PUT books
{
  "mappings" : {
    "properties" : {
      "title" : {
        "type" : "text",
        "fields" : {
          "raw" : {
            "type" : "keyword"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Maven Dependency for OpenSearch Java Client
DESCRIPTION: Add the OpenSearch Java high-level REST client dependency to your project's pom.xml file. This snippet specifies the required Maven dependency for using the client in your Java project.

LANGUAGE: xml
CODE:
<dependency>
  <groupId>org.opensearch.client</groupId>
  <artifactId>opensearch-rest-high-level-client</artifactId>
  <version>{{site.opensearch_version}}</version>
</dependency>

----------------------------------------

TITLE: Performing a Filtered k-NN Search with Faiss in OpenSearch
DESCRIPTION: This snippet shows how to perform a k-NN search with filters using the Faiss engine, searching for small shirts with high ratings similar to a given vector.

LANGUAGE: json
CODE:
POST /products-shirts/_search
{
  "size": 2,
  "query": {
    "knn": {
      "item_vector": {
        "vector": [
          2, 4, 3
        ],
        "k": 10,
        "filter": {
          "bool": {
            "must": [
              {
                "range": {
                  "rating": {
                    "gte": 7,
                    "lte": 10
                  }
                }
              },
              {
                "term": {
                  "size": "small"
                }
              }
            ]
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating Filtered Alias
DESCRIPTION: Creates an alias that only includes documents matching specific criteria using a filter.

LANGUAGE: json
CODE:
POST _aliases
{
  "actions": [
    {
      "add": {
        "index": "index-1",
        "alias": "alias1",
        "filter": {
          "term": {
            "timestamp": "1574641891142"
          }
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Named Route Role Mapping Configuration in YAML
DESCRIPTION: Example demonstrating how to map users to roles using the named route format.

LANGUAGE: yaml
CODE:
abcplugin_read_access_nr:
	 reserved: true
	 users:
		 - "user-B"

----------------------------------------

TITLE: Creating Custom Date Format Mapping
DESCRIPTION: Example demonstrating how to create an index mapping with a custom date format MM/dd/yyyy.

LANGUAGE: json
CODE:
PUT testindex
{
  "mappings" : {
    "properties" :  {
      "release_date" : {
        "type" : "date",
        "format" : "MM/dd/yyyy"
      }
    }
  }
}

----------------------------------------

TITLE: Querying OpenSearch Indexes Using Wildcard Pattern in SQL REST API
DESCRIPTION: Illustrates how to use a wildcard pattern to query multiple OpenSearch indexes matching the pattern in an SQL query via the REST API.

LANGUAGE: json
CODE:
POST _plugins/_sql
{
  "query": "SELECT * FROM my-index* LIMIT 50"
}

----------------------------------------

TITLE: Applying Romanian Analyzer to Text Field in OpenSearch
DESCRIPTION: This snippet demonstrates how to apply the built-in Romanian analyzer to a text field when creating an index in OpenSearch.

LANGUAGE: json
CODE:
PUT /romanian-index
{
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "romanian"
      }
    }
  }
}

----------------------------------------

TITLE: Searching Using copy_to Field
DESCRIPTION: Demonstrates how to search for products using the combined product_info field that contains values from both name and description fields.

LANGUAGE: json
CODE:
GET my-products-index/_search
{
  "query": {
    "match": {
      "product_info": "wireless headphones"
    }
  }
}

----------------------------------------

TITLE: Bulk Ingesting Raw Vector Data in OpenSearch
DESCRIPTION: Shows how to use the Bulk API to efficiently ingest multiple raw vectors into an OpenSearch index. This method is ideal for inserting large amounts of pre-generated vector data.

LANGUAGE: json
CODE:
PUT /_bulk
{"index": {"_index": "my-raw-vector-index", "_id": 1}}
{"my_vector": [0.1, 0.2, 0.3], "metadata": "First item"}
{"index": {"_index": "my-raw-vector-index", "_id": 2}}
{"my_vector": [0.2, 0.3, 0.4], "metadata": "Second item"}

----------------------------------------

TITLE: Configuring Migration Assistant Settings
DESCRIPTION: JSON configuration for Migration Assistant deployment including cluster endpoints, authentication, and service enablement settings. Required for setting up source and target cluster connections.

LANGUAGE: json
CODE:
{
"migration-assistant": {
    "stage": "dev",
    "vpcId": "<TARGET CLUSTER VPC ID>",
    "targetCluster": {
        "endpoint": "<TARGET CLUSTER ENDPOINT>",
        "auth": {
            "type": "basic",
            "username": "<TARGET CLUSTER USERNAME>",
            "passwordFromSecretArn": "<TARGET CLUSTER PASSWORD SECRET>"
        }
    },
    "sourceCluster": {
        "endpoint": "<SOURCE CLUSTER ENDPOINT>",
        "version": "<SOURCE ENGINE VERSION>",
        "auth": {
            "type": "basic",
            "username": "<TARGET CLUSTER USERNAME>",
            "passwordFromSecretArn": "<TARGET CLUSTER PASSWORD SECRET>"
        }
    },
    "reindexFromSnapshotExtraArgs": "<RFS PARAMETERS>",
    "otelCollectorEnabled": true,
    "migrationConsoleServiceEnabled": true,
    "reindexFromSnapshotServiceEnabled": true,
    "migrationAssistanceEnabled": true
}
}

----------------------------------------

TITLE: Analyzing Text with Snowball Analyzer in OpenSearch
DESCRIPTION: This example shows how to use the _analyze API to examine the tokens generated by the custom Snowball analyzer. It demonstrates the stemming effect on the words 'running' and 'runners'.

LANGUAGE: json
CODE:
GET /my-snowball-index/_analyze
{
  "analyzer": "my_snowball_analyzer",
  "text": "running runners"
}

----------------------------------------

TITLE: Configuring Basic LDAP Authentication in OpenSearch
DESCRIPTION: Basic YAML configuration for enabling LDAP authentication with internal authentication support for Kibana server

LANGUAGE: yaml
CODE:
authc:
  internal_auth:
    order: 0
    description: "HTTP basic authentication using the internal user database"
    http_enabled: true
    transport_enabled: true
    http_authenticator:
      type: basic
      challenge: false
    authentication_backend:
      type: internal
  ldap:
    http_enabled: true
    transport_enabled: true
    order: 1
    http_authenticator:
      type: basic
      challenge: false
    authentication_backend:
      type: ldap
      config:
        ...

----------------------------------------

TITLE: OpenSearch Search API Response Structure
DESCRIPTION: Example of a typical response structure from an OpenSearch search request. It includes metadata about the search execution, hit count, and the matching documents with their scores and source data.

LANGUAGE: json
CODE:
{
  "took": 3,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 1,
      "relation": "eq"
    },
    "max_score": 1.0,
    "hits": [
      {
        "_index": "superheroes",
        "_id": "1",
        "_score": 1.0,
        "_source": {
          "superheroes": [
            {
              "Hero name": "Superman",
              "Real identity": "Clark Kent",
              "Age": 28
            },
            {
              "Hero name": "Batman",
              "Real identity": "Bruce Wayne",
              "Age": 26
            },
            {
              "Hero name": "Flash",
              "Real identity": "Barry Allen",
              "Age": 28
            },
            {
              "Hero name": "Robin",
              "Real identity": "Dick Grayson",
              "Age": 15
            }
          ]
        }
      }
    ]
  }
}

----------------------------------------

TITLE: Executing SearchIndexTool Query in OpenSearch
DESCRIPTION: Runs the registered agent to execute a query using the SearchIndexTool. The query retrieves 20 email addresses from the sample eCommerce dataset.

LANGUAGE: json
CODE:
POST /_plugins/_ml/agents/9X7xWI0Bpc3sThaJdY9i/_execute
{
  "parameters": {
    "input": "{\"index\": \"opensearch_dashboards_sample_data_ecommerce\", \"query\": {\"size\": 20,  \"_source\": \"email\"}}"
  }
}

----------------------------------------

TITLE: Basic Document Retrieval Example
DESCRIPTION: Simple example of retrieving a document by its ID.

LANGUAGE: json
CODE:
GET sample-index1/_doc/1

----------------------------------------

TITLE: Querying with Inner Hits
DESCRIPTION: Demonstrates how to query nested objects using the inner_hits parameter to retrieve matching nested documents.

LANGUAGE: json
CODE:
GET /my_index/_search
{
  "query": {
    "nested": {
      "path": "user",
      "query": {
        "bool": {
          "must": [
            { "match": { "user.name": "John" } }
          ]
        }
      },
      "inner_hits": {}
    }
  }
}

----------------------------------------

TITLE: Standard Tokenizer Response Example - OpenSearch JSON
DESCRIPTION: Example response showing the tokens generated by the standard tokenizer, including token positions, offsets, and types.

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "opensearch",
      "start_offset": 0,
      "end_offset": 10,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "is",
      "start_offset": 11,
      "end_offset": 13,
      "type": "<ALPHANUM>",
      "position": 1
    },
    {
      "token": "powerful",
      "start_offset": 14,
      "end_offset": 22,
      "type": "<ALPHANUM>",
      "position": 2
    },
    {
      "token": "fast",
      "start_offset": 24,
      "end_offset": 28,
      "type": "<ALPHANUM>",
      "position": 3
    },
    {
      "token": "and",
      "start_offset": 30,
      "end_offset": 33,
      "type": "<ALPHANUM>",
      "position": 4
    },
    {
      "token": "scalable",
      "start_offset": 34,
      "end_offset": 42,
      "type": "<ALPHANUM>",
      "position": 5
    }
  ]
}

----------------------------------------

TITLE: Debugging Temporary Search Pipeline
DESCRIPTION: Executes a search with debugging enabled using a temporary pipeline definition that includes request and response processors.

LANGUAGE: json
CODE:
POST /my_index/_search?verbose_pipeline=true
{
  "query": {
    "match": { "text_field": "some search text" }
  },
  "search_pipeline": {
    "request_processors": [
      {
        "filter_query": {
          "query": { "term": { "visibility": "public" } }
        }
      }
    ],
    "response_processors": [
      {
        "collapse": {
          "field": "category"
        }
      }
    ]
  }
}

----------------------------------------

TITLE: Using a Search Pipeline with By-Field Rerank Processor
DESCRIPTION: This snippet demonstrates how to apply a search pipeline with a by_field rerank processor to a query, using the pipeline name in the query parameter.

LANGUAGE: json
CODE:
POST /book-index/_search?search_pipeline=rerank_byfield_pipeline
{
  "query": {
     "match_all": {}
  }
}

----------------------------------------

TITLE: Delete Task Example Request
DESCRIPTION: Example request showing how to delete a specific ML Commons task using its ID.

LANGUAGE: json
CODE:
DELETE /_plugins/_ml/tasks/xQRYLX8BydmmU1x6nuD3

----------------------------------------

TITLE: Simulating Pipeline with Document Processing
DESCRIPTION: Example request showing how to simulate a pipeline by ID with sample student documents. The pipeline processes graduation status and student names.

LANGUAGE: json
CODE:
{
  "docs": [
    {
      "_index": "my-index",
      "_id": "1",
      "_source": {
        "grad_year": 2024,
        "graduated": false,
        "name": "John Doe"
      }
    },
    {
      "_index": "my-index",
      "_id": "2",
      "_source": {
        "grad_year": 2025,
        "graduated": false,
        "name": "Jane Doe"
      }
    }
  ]
}

----------------------------------------

TITLE: Implementing Random Value Generation in Python
DESCRIPTION: Functions to generate random money values for range queries and register them as standard value sources in OpenSearch Benchmark.

LANGUAGE: python
CODE:
def random_money_values(max_value):
    gte_cents = random.randrange(0, max_value*100)
    lte_cents = random.randrange(gte_cents, max_value*100)
    return {
        "gte":gte_cents/100,
        "lte":lte_cents/100
    }

def range_query_standard_value_source():
    return random_money_values(120.00)

----------------------------------------

TITLE: Performing Vector Search Query
DESCRIPTION: Executes a neural search query against the vector index using the specified embedding model to find similar documents.

LANGUAGE: json
CODE:
POST /my_index/_search
{
  "query": {
    "neural": {
      "text_knn": {
        "query_text": "hello",
        "model_id": "your_embedding_model_id_created_in_step4",
        "k": 100
      }
    }
  },
  "size": "1",
  "_source": ["text"]
}

----------------------------------------

TITLE: Geotile Grid Aggregation with Bounds in OpenSearch
DESCRIPTION: This query demonstrates how to use the 'bounds' parameter to restrict the geographical area for the geotile grid aggregation.

LANGUAGE: json
CODE:
GET national_parks/_search
{
  "size": 0,
  "aggregations": {
    "grouped": {
      "geotile_grid": {
        "field": "location",
        "precision": 6,
        "bounds": {
            "top_left": "POINT (-120 38)",
            "bottom_right": "POINT (-116 36)"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Query Context Search in OpenSearch
DESCRIPTION: Example of a match query using query context to perform a full-text search in the Shakespeare index.

LANGUAGE: json
CODE:
GET shakespeare/_search
{
  "query": {
    "match": {
      "text_entry": "long live king"
    }
  }
}

----------------------------------------

TITLE: Querying Index Templates with Wildcard - JSON
DESCRIPTION: Example request demonstrating how to get information about index templates using a wildcard pattern.

LANGUAGE: json
CODE:
GET /_index_template/h*

----------------------------------------

TITLE: Querying SQL with Default JDBC Format in OpenSearch
DESCRIPTION: Demonstrates a SQL query to select data from accounts table without specifying a format, which defaults to JDBC. The response includes schema information and result set.

LANGUAGE: json
CODE:
POST _plugins/_sql
{
  "query" : "SELECT firstname, lastname, age FROM accounts ORDER BY age LIMIT 2"
}

LANGUAGE: json
CODE:
{
  "schema": [{
      "name": "firstname",
      "type": "text"
    },
    {
      "name": "lastname",
      "type": "text"
    },
    {
      "name": "age",
      "type": "long"
    }
  ],
  "total": 4,
  "datarows": [
    [
      "Nanette",
      "Bates",
      28
    ],
    [
      "Amber",
      "Duke",
      32
    ]
  ],
  "size": 2,
  "status": 200
}

----------------------------------------

TITLE: Performing Geodistance Query in OpenSearch
DESCRIPTION: This snippet illustrates how to perform a geodistance query in OpenSearch. It searches for documents whose 'point' objects are within a specified distance from a given point. The query uses a boolean must clause with a geo_distance filter.

LANGUAGE: json
CODE:
GET /testindex1/_search
{
  "query": {
    "bool": {
      "must": {
        "match_all": {}
      },
      "filter": {
        "geo_distance": {
          "distance": "50mi",
          "point": {
            "lat": 73.5,
            "lon": 40.5
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Counting logouts without queries per user
DESCRIPTION: SQL query to count the number of times each user logged out without submitting a query, grouped by client_id.

LANGUAGE: sql
CODE:
select 
    client_id, count(0) EventTotal
from ubi_events
where action_name='logout' and query_id is null
group by client_id
order by EventTotal desc

----------------------------------------

TITLE: Querying Cluster Health in OpenSearch
DESCRIPTION: This snippet demonstrates how to check the health status of an OpenSearch cluster using the _cluster/health API endpoint. It's an important step before beginning the upgrade process.

LANGUAGE: json
CODE:
GET "/_cluster/health?pretty"

----------------------------------------

TITLE: Example Response for Update Settings API in OpenSearch
DESCRIPTION: This snippet shows the expected response from a successful Update Settings API request. The response is a simple acknowledgment of the operation's success.

LANGUAGE: json
CODE:
{
    "acknowledged": true
}

----------------------------------------

TITLE: Creating Index with Standard Tokenizer - OpenSearch JSON
DESCRIPTION: Example request that creates a new index with a standard tokenizer configuration. It sets up an analyzer named 'my_standard_analyzer' and applies it to a content field.

LANGUAGE: json
CODE:
PUT /my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_standard_analyzer": {
          "type": "standard"
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "my_standard_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Sparse Encoding Processor Basic Syntax
DESCRIPTION: Basic JSON structure for configuring the sparse_encoding processor with required model_id and field_map parameters.

LANGUAGE: json
CODE:
{
  "sparse_encoding": {
    "model_id": "<model_id>",
    "field_map": {
      "<input_field>": "<vector_field>"
    }
  }
}

----------------------------------------

TITLE: Creating Custom German Analyzer in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a custom German analyzer with specific token filters and apply it to a text field in an index mapping.

LANGUAGE: json
CODE:
PUT /german-index
{
  "settings": {
    "analysis": {
      "filter": {
        "german_stop": {
          "type": "stop",
          "stopwords": "_german_"
        },
        "german_stemmer": {
          "type": "stemmer",
          "language": "light_german"
        },
        "german_keywords": {
          "type": "keyword_marker",
          "keywords": []
        }
      },
      "analyzer": {
        "german_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "german_stop",
            "german_keywords",
            "german_normalization",
            "german_stemmer"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "german_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Querying Date Range Aggregation in OpenSearch
DESCRIPTION: This snippet demonstrates how to use a date_range aggregation in an OpenSearch query. It retrieves documents from the last 10 days and formats the date output.

LANGUAGE: json
CODE:
GET opensearch_dashboards_sample_data_logs/_search
{
  "size": 0,
  "aggs": {
    "number_of_bytes": {
      "date_range": {
        "field": "@timestamp",
        "format": "MM-yyyy",
        "ranges": [
          {
            "from": "now-10d/d",
            "to": "now"
          }
        ]
      }
    }
  }
}

----------------------------------------

TITLE: Analyzing Bengali Text with OpenSearch Analyzer
DESCRIPTION: This snippet shows how to use the _analyze API to examine the tokens generated by the Bengali analyzer for a given text input.

LANGUAGE: json
CODE:
POST /bengali-index/_analyze
{
  "field": "content",
  "text": "      "
}

----------------------------------------

TITLE: Complete OpenSearch Dashboards Configuration with Security and Branding
DESCRIPTION: Comprehensive configuration example including security settings, SSL configuration, and custom branding elements.

LANGUAGE: yaml
CODE:
server.host: "0"
opensearch.hosts: ["https://localhost:9200"]
opensearch.ssl.verificationMode: none
opensearch.username: "kibanaserver"
opensearch.password: "kibanaserver"
opensearch.requestHeadersAllowlist: [ authorization,securitytenant ]
#server.ssl.enabled: true
#server.ssl.certificate: /path/to/your/server/certificate
#server.ssl.key: /path/to/your/server/key

opensearch_security.multitenancy.enabled: true
opensearch_security.multitenancy.tenants.preferred: ["Private", "Global"]
opensearch_security.readonly_mode.roles: ["kibana_read_only"]
# Use this setting if you are running opensearch-dashboards without https
opensearch_security.cookie.secure: false

opensearchDashboards.branding:
  logo:
    defaultUrl: "https://example.com/sample.svg"
    darkModeUrl: "https://example.com/dark-mode-sample.svg"
  # mark:
  #   defaultUrl: ""
  #   darkModeUrl: ""
  # loadingLogo:
  #   defaultUrl: ""
  #   darkModeUrl: ""
  # faviconUrl: ""
  applicationTitle: "Just some testing"

----------------------------------------

TITLE: Complete OpenSearch Operations Example
DESCRIPTION: Comprehensive example demonstrating index creation, document indexing, and search operations using OpenSearch.Net.

LANGUAGE: csharp
CODE:
using OpenSearch.Net;
using OpenSearch.Client;

namespace NetClientProgram;

internal class Program
{
    public static void Main(string[] args)
    {
        var uri = new Uri("http://localhost:9200");
        var connectionPool = new SingleNodeConnectionPool(uri);
        var settings = new ConnectionSettings(connectionPool)
            .PrettyJson();
        var client = new OpenSearchLowLevelClient(settings);

        Console.WriteLine("Indexing one student......");
        var student = new Student { 
            Id = 100, 
            FirstName = "Paulo", 
            LastName = "Santos", 
            Gpa = 3.93, 
            GradYear = 2021 };
        var response = client.Index<StringResponse>("students", "100",  
                                        PostData.Serializable(student));
        Console.WriteLine(response.Body);

        // Additional operations...
    }
}

----------------------------------------

TITLE: Creating an index for neural sparse search
DESCRIPTION: Creates an index with appropriate mappings for storing sparse vector embeddings and configures the default ingest pipeline.

LANGUAGE: json
CODE:
PUT /my-nlp-index
{
  "settings": {
    "default_pipeline": "nlp-ingest-pipeline-sparse"
  },
  "mappings": {
    "properties": {
      "id": {
        "type": "text"
      },
      "passage_embedding": {
        "type": "rank_features"
      },
      "passage_text": {
        "type": "text"
      }
    }
  }
}

----------------------------------------

TITLE: Creating Custom Analyzer with Preserved HTML Tags in OpenSearch
DESCRIPTION: This example creates a custom analyzer that uses the HTML strip character filter but preserves specific HTML tags (b and i) in the output.

LANGUAGE: json
CODE:
PUT /html_strip_preserve_analyzer
{
  "settings": {
    "analysis": {
      "char_filter": {
        "html_filter": {
          "type": "html_strip",
          "escaped_tags": ["b", "i"]
        }
      },
      "analyzer": {
        "html_strip_analyzer": {
          "type": "custom",
          "char_filter": ["html_filter"],
          "tokenizer": "keyword"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating Index with Pattern Capture Filter for Email Analysis in OpenSearch
DESCRIPTION: This snippet demonstrates how to create an index named 'email_index' with a custom analyzer using the pattern_capture filter. The analyzer is configured to extract the local part and domain name from email addresses.

LANGUAGE: json
CODE:
PUT /email_index
{
  "settings": {
    "analysis": {
      "filter": {
        "email_pattern_capture": {
          "type": "pattern_capture",
          "preserve_original": true,
          "patterns": [
            "^([^@]+)",
            "@(.+)$"
          ]
        }
      },
      "analyzer": {
        "email_analyzer": {
          "tokenizer": "uax_url_email",
          "filter": [
            "email_pattern_capture",
            "lowercase"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating an OpenSearch CLI Profile
DESCRIPTION: This snippet demonstrates how to create a profile for OpenSearch CLI using the command line interface.

LANGUAGE: bash
CODE:
opensearch-cli profile create --auth-type basic --endpoint https://localhost:9200 --name docker-local

----------------------------------------

TITLE: Querying Tasks Endpoint
DESCRIPTION: Basic GET endpoint to retrieve information about all tasks running in the cluster.

LANGUAGE: json
CODE:
GET _tasks

----------------------------------------

TITLE: Search Query with Request Body
DESCRIPTION: Example of sending a search request with JSON payload using cURL.

LANGUAGE: json
CODE:
curl -X GET "https://localhost:9200/students/_search?pretty" -H 'Content-Type: application/json' -d'
{
  "query": {
    "match_all": {}
  }
}'

----------------------------------------

TITLE: Range Query with Relative Dates in OpenSearch
DESCRIPTION: This example shows how to use date math to specify relative dates in a range query, subtracting 1 year and 1 day from the given date.

LANGUAGE: json
CODE:
GET products/_search
{
  "query": {
    "range": {
      "created": {
        "gte": "2019/01/01||-1y-1d"
      }
    }
  }
}

----------------------------------------

TITLE: Performing Asynchronous Search in OpenSearch
DESCRIPTION: Demonstrates how to initiate an asynchronous search request with custom parameters such as timeout, result persistence, and cache settings.

LANGUAGE: json
CODE:
POST _plugins/_asynchronous_search/?pretty&size=10&wait_for_completion_timeout=1ms&keep_on_completion=true&request_cache=false
{
  "aggs": {
    "city": {
      "terms": {
        "field": "city",
        "size": 10
      }
    }
  }
}

----------------------------------------

TITLE: Creating an index for raw vector storage in OpenSearch
DESCRIPTION: This snippet shows how to create an index for storing raw vectors or pre-generated embeddings in OpenSearch. It configures a vector field with a specified dimension.

LANGUAGE: json
CODE:
PUT /my-raw-vector-index
{
  "settings": {
    "index.knn": true
  },
  "mappings": {
    "properties": {
      "my_vector": {
        "type": "knn_vector",
        "dimension": 3
      }
    }
  }
}

----------------------------------------

TITLE: Enabling Conversation Memory and RAG Pipeline Features
DESCRIPTION: This snippet shows how to enable the conversation memory and RAG pipeline features in OpenSearch via cluster settings.

LANGUAGE: json
CODE:
PUT /_cluster/settings
{
  "persistent": {
    "plugins.ml_commons.memory_feature_enabled": true,
    "plugins.ml_commons.rag_pipeline_feature_enabled": true
  }
}

----------------------------------------

TITLE: Indexing a Document with Double and Date Ranges in OpenSearch
DESCRIPTION: This example shows how to index a document in OpenSearch that contains a double range for GPA and a date range for graduation dates. It uses the 'gte' and 'lte' operators to define the ranges.

LANGUAGE: json
CODE:
PUT testindex/_doc/1
{
  "gpa" : {
    "gte" : 1.0,
    "lte" : 4.0
  },
  "graduation_date" : {
    "gte" : "2019-05-01",
    "lte" : "2019-05-15"
  }
}

----------------------------------------

TITLE: Disabling Security Plugin in OpenSearch YAML Configuration
DESCRIPTION: YAML configuration setting to disable the OpenSearch Security plugin in opensearch.yml file.

LANGUAGE: yml
CODE:
plugins.security.disabled: true

----------------------------------------

TITLE: String Function Usage in OpenSearch SQL
DESCRIPTION: Examples of using string functions in OpenSearch SQL queries. These functions perform various operations on string data types.

LANGUAGE: SQL
CODE:
SELECT ascii('h')
SELECT concat('hello', 'world')
SELECT concat_ws(" ", "Hello", "World!")
SELECT left('hello', 2)
SELECT length('hello')
SELECT locate('o', 'hello'), locate('l', 'hello world', 5)
SELECT replace('hello', 'l', 'x')
SELECT right('hello', 2)
SELECT rtrim('hello   ')
SELECT substring('hello', 2, 2) -> 'el'
SELECT trim('   hello')
SELECT upper('hello world')

----------------------------------------

TITLE: Configuring Basic Translate Processor in YAML
DESCRIPTION: Demonstrates a basic configuration of the translate processor in a pipeline.yaml file. It maps HTTP status codes to human-readable descriptions.

LANGUAGE: yaml
CODE:
translate-pipeline:
  source:
    file:
      path: "/full/path/to/logs_json.log"
      record_type: "event"
      format: "json"
  processor:
    - translate:
        mappings:
          - source: "status"
            targets:
              - target: "translated_result"
                map:
                  404: "Not Found"
  sink:
    - stdout:

----------------------------------------

TITLE: Creating a Query Group in OpenSearch
DESCRIPTION: API request to create a query group named 'analytics' with specific resource limits for CPU and memory. Query groups are used to manage and allocate resources for search requests.

LANGUAGE: json
CODE:
PUT _wlm/query_group
{
  "name": "analytics",
  "resiliency_mode": "enforced",
  "resource_limits": {
    "cpu": 0.4,
    "memory": 0.2
  }
}

----------------------------------------

TITLE: Querying by Sparse Vector with Neural Sparse in OpenSearch
DESCRIPTION: This snippet shows how to structure a neural_sparse query using pre-computed sparse vector tokens. It requires specifying the vector field and the query tokens as a map of strings to float values.

LANGUAGE: json
CODE:
"neural_sparse": {
  "<vector_field>": {
    "query_tokens": "<query_tokens>"
  }
}

----------------------------------------

TITLE: Configuring TLS Settings for SAML in OpenSearch
DESCRIPTION: This YAML snippet shows how to configure TLS settings for SAML authentication in OpenSearch, including enabling SSL and hostname verification.

LANGUAGE: yaml
CODE:
authc:
  saml_auth_domain:
    http_enabled: true
    transport_enabled: false
    order: 1
    http_authenticator:
      type: saml
      challenge: true
      config:
        idp:
          enable_ssl: true
          verify_hostnames: true
          ...
    authentication_backend:
      type: noop

----------------------------------------

TITLE: Example Agent Execution Response
DESCRIPTION: Sample response showing inference results with calculated population increase for Seattle.

LANGUAGE: json
CODE:
{
  "inference_results": [
    {
      "output": [
        {
          "result": """ Based on the given context, the key information is:\n\nThe metro area population of Seattle in 2021 was 3,461,000.\nThe metro area population of Seattle in 2023 is 3,519,000.\n\nTo calculate the population increase from 2021 to 2023:\n\nPopulation in 2023 (3,519,000) - Population in 2021 (3,461,000) = 58,000\n\nTherefore, the population increase of Seattle from 2021 to 2023 is 58,000."""
        }
      ]
    }
  ]
}

----------------------------------------

TITLE: Executing k-NN Search with Hamming Distance on Long Field in OpenSearch
DESCRIPTION: This code shows how to perform a k-NN search using Hamming distance on a long field type in OpenSearch. It uses the knn_score script with the hammingbit space type and a numeric query value.

LANGUAGE: json
CODE:
GET my-long-index/_search
{
  "size": 2,
  "query": {
    "script_score": {
      "query": {
        "bool": {
          "filter": {
            "term": {
              "color": "BLUE"
            }
          }
        }
      },
      "script": {
        "lang": "knn",
        "source": "knn_score",
        "params": {
          "field": "my_long",
          "query_value": 23,
          "space_type": "hammingbit"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Validating Query with Request Body in OpenSearch
DESCRIPTION: Demonstrates validating a more complex query using a request body in OpenSearch. This example uses a bool query with must and filter clauses.

LANGUAGE: json
CODE:
GET hamlet/_validate/query
{
  "query" : {
    "bool" : {
      "must" : {
        "query_string" : {
          "query" : "*:*"
        }
      },
      "filter" : {
        "term" : { "user.id" : "hamlet" }
      }
    }
  }
}

----------------------------------------

TITLE: Creating Index with Thai Tokenizer Configuration
DESCRIPTION: Example of creating a new index with a custom analyzer using the Thai tokenizer. This configuration sets up proper text analysis for Thai language content.

LANGUAGE: json
CODE:
PUT /thai_index
{
  "settings": {
    "analysis": {
      "tokenizer": {
        "thai_tokenizer": {
          "type": "thai"
        }
      },
      "analyzer": {
        "thai_analyzer": {
          "type": "custom",
          "tokenizer": "thai_tokenizer"
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "thai_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Defining Community ID Processor Syntax in JSON
DESCRIPTION: This snippet shows the JSON syntax for configuring the community_id processor. It specifies fields for source and destination IP addresses and ports, protocol number, and the target field for the generated hash.

LANGUAGE: json
CODE:
{
  "community_id": {
    "source_ip_field": "source_ip",
    "source_port_field": "source_port",
    "destination_ip_field": "destination_ip",
    "destination_port_field": "destination_port",
    "iana_protocol_number_field": "iana_protocol_number",
    "source_port_field": "source_port",
    "target_field": "community_id"
  }
}

----------------------------------------

TITLE: Convert Processor Basic Syntax in OpenSearch
DESCRIPTION: Basic JSON syntax for the convert processor showing the required field and type parameters.

LANGUAGE: json
CODE:
{
    "convert": {
        "field": "field_name",
        "type": "type-value"
    }
}

----------------------------------------

TITLE: Defining Index Mapping with Enabled Parameter in OpenSearch
DESCRIPTION: This example demonstrates how to use the 'enabled' parameter in an OpenSearch index mapping. It disables parsing and indexing for the 'session_data' field while allowing other fields to be indexed normally.

LANGUAGE: json
CODE:
PUT my-index-002
{
  "mappings": {
    "properties": {
      "user_id": {
        "type": "keyword"
      },
      "last_updated": {
        "type": "date"
      },
      "session_data": {
        "type": "object",
        "enabled": false
      }
    }
  }
}

----------------------------------------

TITLE: Deleting IP2Geo Data Source in OpenSearch
DESCRIPTION: This snippet shows how to delete an IP2Geo data source. Note that all associated processors must be deleted first.

LANGUAGE: json
CODE:
DELETE /_plugins/geospatial/ip2geo/datasource/my-datasource

----------------------------------------

TITLE: Sorting Results by Descending Line ID in OpenSearch
DESCRIPTION: This snippet demonstrates how to sort search results by the 'line_id' field in descending order. It includes a term query to filter results for the play 'Henry IV'.

LANGUAGE: json
CODE:
GET shakespeare/_search
{
  "query": {
    "term": {
      "play_name": {
        "value": "Henry IV"
      }
    }
  },
  "sort": [
    {
      "line_id": {
        "order": "desc"
      }
    }
  ]
}

----------------------------------------

TITLE: Creating Index with Parent-Child Relationship - OpenSearch JSON
DESCRIPTION: Creates an index with a join field to establish parent-child relationships between documents. The example maps brand as parent and product as child.

LANGUAGE: json
CODE:
PUT testindex1
{
  "mappings": {
    "properties": {
      "product_to_brand": { 
        "type": "join",
        "relations": {
          "brand": "product" 
        }
      }
    }
  }
}

----------------------------------------

TITLE: Querying Node-Specific Tasks
DESCRIPTION: Request to return tasks currently running on a specific node named 'opensearch-node1'.

LANGUAGE: json
CODE:
GET /_tasks?nodes=opensearch-node1

----------------------------------------

TITLE: Indexing Geopoint as String Format
DESCRIPTION: Demonstrates indexing a geopoint using a string in 'latitude,longitude' format.

LANGUAGE: json
CODE:
PUT testindex1/_doc/2
{
  "point": "40.71,74.00" 
}

----------------------------------------

TITLE: Creating Mapping with Rank Features Field in OpenSearch
DESCRIPTION: This snippet shows how to create a mapping with a rank_features field in OpenSearch. The rank_features field is designed for indexing sparse numeric feature vectors.

LANGUAGE: json
CODE:
PUT testindex1
{
  "mappings": {
    "properties": {
      "correlations": {
        "type": "rank_features" 
      }
    }
  }
}

----------------------------------------

TITLE: Registering Conversational Flow Agent
DESCRIPTION: Defines a conversational flow agent that combines vector search and LLM capabilities for question answering

LANGUAGE: json
CODE:
{
    "name": "population data analysis agent",
    "type": "conversational_flow",
    "description": "This is a demo agent for population data analysis",
    "app_type": "rag",
    "memory": {
        "type": "conversation_index"
    },
    "tools": [
        {
            "type": "VectorDBTool",
            "name": "population_knowledge_base",
            "parameters": {
                "model_id": "your_text_embedding_model_id",
                "index": "test_population_data",
                "embedding_field": "population_description_embedding",
                "source_field": [
                    "population_description"
                ],
                "input": "${parameters.question}"
            }
        },
        {
            "type": "MLModelTool",
            "name": "bedrock_claude_model",
            "description": "A general tool to answer any question",
            "parameters": {
                "model_id": "your_LLM_model_id",
                "prompt": "\n\nHuman:You are a professional data analysist. You will always answer question based on the given context first. If the answer is not directly shown in the context, you will analyze the data and find the answer. If you don't know the answer, just say don't know. \n\nContext:\n${parameters.population_knowledge_base.output:-}\n\n${parameters.chat_history:-}\n\nHuman:${parameters.question}\n\nAssistant:"
            }
        }
    ]
}

----------------------------------------

TITLE: Configuring Windows Settings for OpenSearch
DESCRIPTION: Commands to set vm.max_map_count for Windows workloads using WSL through Docker Desktop.

LANGUAGE: bash
CODE:
wsl -d docker-desktop
sysctl -w vm.max_map_count=262144

----------------------------------------

TITLE: Creating Convert Pipeline in OpenSearch
DESCRIPTION: Example of creating a pipeline that converts price to floating-point number and handles negative values.

LANGUAGE: json
CODE:
PUT _ingest/pipeline/convert-price
{
  "description": "Pipeline that converts price to floating-point number and sets value to zero if price less than zero",
  "processors": [
    {
      "convert": {
        "field": "price",
        "type": "float",
        "target_field": "price_float"
      }
    },
    {
      "set": {
        "field": "price",
        "value": "0",
        "if": "ctx.price_float < 0"
      }
    }
  ]
}

----------------------------------------

TITLE: Adding Index to OpenSearch Alias
DESCRIPTION: Creates an alias named 'alias1' and adds 'index-1' to it using the actions method.

LANGUAGE: json
CODE:
POST _aliases
{
  "actions": [
    {
      "add": {
        "index": "index-1",
        "alias": "alias1"
      }
    }
  ]
}

----------------------------------------

TITLE: Applying Swedish Analyzer to Text Field in OpenSearch
DESCRIPTION: This snippet demonstrates how to apply the built-in Swedish analyzer to a text field when creating an index in OpenSearch. It sets up a mapping for a 'content' field using the 'swedish' analyzer.

LANGUAGE: json
CODE:
PUT /swedish-index
{
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "swedish"
      }
    }
  }
}

----------------------------------------

TITLE: Creating Custom Catalan Analyzer in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a custom Catalan analyzer in OpenSearch, including custom token filters for elision, stop words, stemming, and keyword marking.

LANGUAGE: json
CODE:
PUT /catalan-index
{
  "settings": {
    "analysis": {
      "filter": {
        "catalan_stop": {
          "type": "stop",
          "stopwords": "_catalan_"
        },
        "catalan_elision": {
          "type":       "elision",
          "articles":   [ "d", "l", "m", "n", "s", "t"],
          "articles_case": true
        },
        "catalan_stemmer": {
          "type": "stemmer",
          "language": "catalan"
        },
        "catalan_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] 
        }
      },
      "analyzer": {
        "catalan_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "catalan_elision",
            "lowercase",
            "catalan_stop",
            "catalan_keywords",
            "catalan_stemmer"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "catalan_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Calculating Average Values Using OpenSearch Aggregations
DESCRIPTION: Demonstrates how to use the avg aggregation to calculate the average value of the taxful_total_price field. The query sets size to 0 to only return aggregation results without documents.

LANGUAGE: json
CODE:
GET opensearch_dashboards_sample_data_ecommerce/_search
{
  "size": 0,
  "aggs": {
    "avg_taxful_total_price": {
      "avg": {
        "field": "taxful_total_price"
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Cascaded Text Chunking Processors in OpenSearch
DESCRIPTION: Example of creating an ingest pipeline with multiple text chunking processors chained together, using both delimiter and fixed_token_length algorithms.

LANGUAGE: json
CODE:
PUT _ingest/pipeline/text-chunking-cascade-ingest-pipeline
{
  "description": "A text chunking pipeline with cascaded algorithms",
  "processors": [
    {
      "text_chunking": {
        "algorithm": {
          "delimiter": {
            "delimiter": "\n\n"
          }
        },
        "field_map": {
          "passage_text": "passage_chunk1"
        }
      }
    },
    {
      "text_chunking": {
        "algorithm": {
          "fixed_token_length": {
            "token_limit": 500,
            "overlap_rate": 0.2,
            "tokenizer": "standard"
          }
        },
        "field_map": {
          "passage_chunk1": "passage_chunk2"
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Configuring Segment Replication Settings in OpenSearch
DESCRIPTION: This snippet shows how to configure cluster-wide settings for segment replication, including enabling backpressure and balanced primary shard allocation.

LANGUAGE: json
CODE:
PUT /_cluster/settings
{
  "persistent": {
    "cluster.routing.allocation.balance.prefer_primary": true,
    "segrep.pressure.enabled": true
  }
}

----------------------------------------

TITLE: Creating Query Group Endpoint
DESCRIPTION: PUT endpoint for creating a new query group in OpenSearch workload management.

LANGUAGE: json
CODE:
PUT /_wlm/query_group

----------------------------------------

TITLE: Configuring Field Masking in roles.yml
DESCRIPTION: Illustrates how to configure field masking for a specific role and index in the roles.yml file. It masks the 'title' and 'genres' fields for the 'movies' index.

LANGUAGE: yml
CODE:
someonerole:
  index_permissions:
    - index_patterns:
      - 'movies'
      allowed_actions:
        - read
      masked_fields:
        - "title"
        - "genres"

----------------------------------------

TITLE: Bulk Indexing Documents in OpenSearch
DESCRIPTION: This snippet shows how to index multiple documents at once using the bulk API in OpenSearch. It includes examples of indexing with and without specifying document IDs.

LANGUAGE: json
CODE:
POST _bulk
{ "index": { "_index": "my-logs", "_id": "2" } }
{ "title": "The Garden of Words", "year": 2013 }
{ "index" : { "_index": "my-logs", "_id" : "3" } }
{ "title": "5 Centimeters Per Second", "year": 2007 }


----------------------------------------

TITLE: Query Document Count with Term Filter
DESCRIPTION: Example request demonstrating how to count documents matching a specific term query condition.

LANGUAGE: json
CODE:
GET opensearch_dashboards_sample_data_logs/_count\n{\n  "query": {\n    "term": {\n      "response": "200"\n    }\n  }\n}

----------------------------------------

TITLE: Jekyll Front Matter Configuration for Reporting Documentation
DESCRIPTION: YAML front matter configuration for Jekyll static site generator that sets up the reporting documentation page layout, navigation order, and URL redirects.

LANGUAGE: yaml
CODE:
---
layout: default
title: Reporting
nav_order: 1
has_children: false
nav_exclude: true
permalink: /reporting/
redirect_from:
  - /reporting/index/
---

----------------------------------------

TITLE: Executing List Shards API Request for All Indexes in OpenSearch
DESCRIPTION: This example demonstrates how to query shard information for all indexes using the List Shards API. It includes the 'v' parameter for verbose output and uses a next_token for pagination.

LANGUAGE: json
CODE:
GET _list/shards/<index>?v&next_token=token

----------------------------------------

TITLE: Count API Response Format
DESCRIPTION: Example response showing the document count and shard statistics returned by the Count API.

LANGUAGE: json
CODE:
{\n  "count" : 14074,\n  "_shards" : {\n    "total" : 1,\n    "successful" : 1,\n    "skipped" : 0,\n    "failed" : 0\n  }\n}

----------------------------------------

TITLE: Range Query with Time Zone in OpenSearch
DESCRIPTION: This query demonstrates how to specify a time zone for date conversion in a range query using the 'time_zone' parameter.

LANGUAGE: json
CODE:
GET /products/_search
{
  "query": {
    "range": {
      "created": {
        "time_zone": "-04:00",
        "gte": "2022-04-17T06:00:00"
      }
    }
  }
}

----------------------------------------

TITLE: Creating Custom Arabic Analyzer in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a custom Arabic analyzer in OpenSearch. It defines custom token filters and combines them into a new analyzer, which is then applied to a text field in the index mapping.

LANGUAGE: json
CODE:
PUT /arabic-index
{
  "settings": {
    "analysis": {
      "filter": {
        "arabic_stop": {
          "type": "stop",
          "stopwords": "_arabic_"
        },
        "arabic_stemmer": {
          "type": "stemmer",
          "language": "arabic"
        },
        "arabic_normalization": {
          "type": "arabic_normalization"
        },
        "decimal_digit": {
          "type": "decimal_digit"
        },
        "arabic_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] 
        }
      },
      "analyzer": {
        "arabic_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "arabic_normalization",
            "decimal_digit",
            "arabic_stop",
            "arabic_keywords",
            "arabic_stemmer"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "arabic_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Deleting OpenSearch Index
DESCRIPTION: Removes an entire index from OpenSearch

LANGUAGE: php
CODE:
$client->indices()->delete([
    'index' => $indexName
]);

----------------------------------------

TITLE: Creating Index with ASCII Folding Filter Configuration
DESCRIPTION: Creates a new index with a custom analyzer that includes ASCII folding filter. The example sets preserve_original to true to maintain both original and folded versions of tokens.

LANGUAGE: json
CODE:
PUT /example_index
{
  "settings": {
    "analysis": {
      "filter": {
        "custom_ascii_folding": {
          "type": "asciifolding",
          "preserve_original": true
        }
      },
      "analyzer": {
        "custom_ascii_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "custom_ascii_folding"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Basic Multi-match Query Example
DESCRIPTION: Demonstrates a basic multi-match query searching for 'wind' across title and plot fields, with title field boosted by 4x.

LANGUAGE: json
CODE:
GET _search
{
  "query": {
    "multi_match": {
      "query": "wind",
      "fields": ["title^4", "plot"]
    }
  }
}

----------------------------------------

TITLE: Deleting Document from OpenSearch
DESCRIPTION: Removes a single document from an OpenSearch index

LANGUAGE: php
CODE:
$client->delete([
    'index' => $indexName,
    'id' => 1,
]);

----------------------------------------

TITLE: Importing OpenSearch Python Client
DESCRIPTION: Import the necessary classes from the opensearchpy and opensearch_dsl modules to use the OpenSearch client.

LANGUAGE: python
CODE:
from opensearchpy import OpenSearch
from opensearch_dsl import Search

----------------------------------------

TITLE: Implementing Search Slicing with PIT in OpenSearch
DESCRIPTION: Shows how to use search slicing with PIT to parallelize search operations by breaking down results into multiple slices.

LANGUAGE: json
CODE:
{
  "slice": {
    "id": 0,
    "max": 2
  },
  "query": {
    "match": {
      "message": "foo"
    }
  },
  "pit": {
    "id": "46ToAwMDaWR5BXV1aWQyKwZub2RlXzMAAAAAAAAAACoBYwADaWR4BXV1aWQxAgZub2RlXzEAAAAAAAAAAAEBYQADaWR5BXV1aWQyKgZub2RlXzIAAAAAAAAAAAwBYgACBXV1aWQyAAAFdXVpZDEAAQltYXRjaF9hbGw_gAAAAA=="
  }
}

----------------------------------------

TITLE: Querying Top Hits in OpenSearch
DESCRIPTION: Example query demonstrating how to retrieve the top 5 products from an eCommerce dataset using top_hits aggregation. The query sets size to 0 to focus on aggregation results and configures the top_hits aggregation with a size parameter of 5.

LANGUAGE: json
CODE:
GET opensearch_dashboards_sample_data_ecommerce/_search
{
  "size": 0,
  "aggs": {
    "top_hits_products": {
      "top_hits": {
        "size": 5
      }
    }
  }
}

----------------------------------------

TITLE: Match Query with Minimum Should Match in OpenSearch
DESCRIPTION: A Match query using 'minimum_should_match' to control the number of terms that must match.

LANGUAGE: json
CODE:
GET testindex/_search
{
  "query": {
    "match": {
      "title": {
        "query": "wind rise",
        "operator": "or",
        "minimum_should_match": 2
      }
    }
  }
}

----------------------------------------

TITLE: Querying Account Data with PPL in OpenSearch
DESCRIPTION: This PPL query retrieves the 'firstname' and 'lastname' fields for documents in the 'accounts' index with age greater than 18.

LANGUAGE: sql
CODE:
search source=accounts
| where age > 18
| fields firstname, lastname

----------------------------------------

TITLE: Connecting to OpenSearch without SSL/TLS
DESCRIPTION: Create an OpenSearch client object with SSL/TLS disabled for environments not using the Security plugin. This configuration is less secure and should be used cautiously.

LANGUAGE: python
CODE:
host = 'localhost'
port = 9200

# Create the client with SSL/TLS and hostname verification disabled.
client = OpenSearch(
    hosts = [{'host': host, 'port': port}],
    http_compress = True, # enables gzip compression for request bodies
    use_ssl = False,
    verify_certs = False,
    ssl_assert_hostname = False,
    ssl_show_warn = False
)

----------------------------------------

TITLE: Installing Custom Plugins in OpenSearch Docker Image
DESCRIPTION: A Dockerfile example showing how to install a custom plugin in the OpenSearch Docker image.

LANGUAGE: Dockerfile
CODE:
FROM opensearchproject/opensearch:latest
RUN /usr/share/opensearch/bin/opensearch-plugin install --batch <pluginId>

----------------------------------------

TITLE: Executing Terms Aggregation on Pre-aggregated Data in OpenSearch
DESCRIPTION: This snippet demonstrates how to perform a terms aggregation on the response_code field for documents with pre-aggregated data. It shows how to retrieve the aggregated results.

LANGUAGE: json
CODE:
GET /my_index/_search
{
  "size": 0,
  "aggs": {
    "response_codes": {
      "terms": {
        "field": "response_code"
      }
    }
  }
}

----------------------------------------

TITLE: Creating Star-tree Index Mapping in OpenSearch
DESCRIPTION: Example of creating an index with star-tree configuration for computing metric aggregations on request_size and latency fields with queries on port and status fields. Includes settings for shards, replicas, and composite index configuration.

LANGUAGE: json
CODE:
PUT logs
{
  "settings": {
    "index.number_of_shards": 1,
    "index.number_of_replicas": 0,
    "index.composite_index": true,
    "index.append_only.enabled": true
  },
  "mappings": {
    "composite": {
      "request_aggs": {
        "type": "star_tree",
        "config": {
          "max_leaf_docs": 10000,
          "skip_star_node_creation_for_dimensions": [
            "port"
          ],
          "date_dimension" : {
            "name": "@timestamp",
            "calendar_intervals": [
              "month",
              "day"
            ]
          },
          "ordered_dimensions": [
            {
              "name": "status"
            },
            {
              "name": "port"
            },
            {
              "name": "method"
            }
          ],
          "metrics": [
            {
              "name": "request_size",
              "stats": [
                "sum",
                "value_count",
                "min",
                "max"
              ]
            },
            {
              "name": "latency",
              "stats": [
                "sum",
                "value_count",
                "min",
                "max"
              ]
            }
          ]
        }
      }
    },
    "properties": {
      "@timestamp": {
        "format": "strict_date_optional_time||epoch_second",
        "type": "date"
      },
      "status": {
        "type": "integer"
      },
      "port": {
        "type": "integer"
      },
      "request_size": {
        "type": "integer"
      },
      "method" : {
        "type": "keyword"
      },
      "latency": {
        "type": "scaled_float",
        "scaling_factor": 10
      }
    }
  }
}

----------------------------------------

TITLE: Parsing Anomaly Detection Results in JSON (No Anomaly Detected)
DESCRIPTION: Example JSON structure of an anomaly detection result when no anomaly is detected. Includes fields such as detector_id, schema_version, data timestamps, feature data, execution times, anomaly score, and confidence.

LANGUAGE: json
CODE:
{
  "detector_id": "kzcZ43wBgEQAbjDnhzGF",
  "schema_version": 5,
  "data_start_time": 1635898161367,
  "data_end_time": 1635898221367,
  "feature_data": [
    {
      "feature_id": "processing_bytes_max",
      "feature_name": "processing bytes max",
      "data": 2322
    },
    {
      "feature_id": "processing_bytes_avg",
      "feature_name": "processing bytes avg",
      "data": 1718.6666666666667
    },
    {
      "feature_id": "processing_bytes_min",
      "feature_name": "processing bytes min",
      "data": 1375
    },
    {
      "feature_id": "processing_bytes_sum",
      "feature_name": "processing bytes sum",
      "data": 5156
    },
    {
      "feature_id": "processing_time_max",
      "feature_name": "processing time max",
      "data": 31198
    }
  ],
  "execution_start_time": 1635898231577,
  "execution_end_time": 1635898231622,
  "anomaly_score": 1.8124904404395776,
  "anomaly_grade": 0,
  "confidence": 0.9802940756605277,
  "entity": [
    {
      "name": "process_name",
      "value": "process_3"
    }
  ],
  "model_id": "kzcZ43wBgEQAbjDnhzGF_entity_process_3",
  "threshold": 1.2368549346675202
}

----------------------------------------

TITLE: Using Field Aliases in OpenSearch SQL
DESCRIPTION: Example of using a field alias (AS keyword) to rename the 'account_number' field as 'num' in the query result.

LANGUAGE: sql
CODE:
SELECT account_number AS num
FROM accounts

----------------------------------------

TITLE: Creating a Pipeline with Community ID Processor in OpenSearch
DESCRIPTION: This JSON query creates a pipeline named 'community_id_pipeline' that uses the community_id processor to generate a hash value for the network flow tuple. It specifies the fields for source and destination IP addresses and ports, protocol number, and the target field.

LANGUAGE: json
CODE:
PUT /_ingest/pipeline/commnity_id_pipeline
{
  "description": "generate hash value for the network flow tuple",
  "processors": [
    {
      "community_id": {
        "source_ip_field": "source_ip",
        "source_port_field": "source_port",
        "destination_ip_field": "destination_ip",
        "destination_port_field": "destination_port",
        "iana_protocol_number_field": "iana_protocol_number",
        "target_field": "community_id"
     }
    }
  ]
}

----------------------------------------

TITLE: Boolean Field Aggregation and Script Query
DESCRIPTION: Example demonstrating terms aggregation and script fields usage with Boolean values, showing how Boolean values are represented in different contexts.

LANGUAGE: json
CODE:
GET testindex/_search
{
  "aggs": {
    "agg1": {
      "terms": {
        "field": "a"
      }
    }
  },
  "script_fields": {
    "a": {
      "script": {
        "lang": "painless",
        "source": "doc['a'].value"
      }
    }
  }
}

----------------------------------------

TITLE: Applying Default Search Pipeline in OpenSearch
DESCRIPTION: This snippet demonstrates how to apply a default search pipeline to an index in OpenSearch, which sets the default model for semantic search queries.

LANGUAGE: json
CODE:
PUT /my-nlp-index/_settings
{
  "index.search.default_pipeline" : "default_model_pipeline"
}

----------------------------------------

TITLE: Explain API Response Structure
DESCRIPTION: Example response showing the detailed explanation of how the relevance score is calculated, including term frequency, inverse document frequency, and field normalization factors.

LANGUAGE: json
CODE:
{\n  "_index" : "kibana_sample_data_ecommerce",\n  "_id" : "EVz1Q3sBgg5eWQP6RSte",\n  "matched" : true,\n  "explanation" : {\n    "value" : 3.5671005,\n    "description" : "weight(customer_first_name:mary in 1) [PerFieldSimilarity], result of:",\n    "details" : [\n      {\n        "value" : 3.5671005,\n        "description" : "score(freq=1.0), computed as boost * idf * tf from:",\n        "details" : [\n          {\n            "value" : 2.2,\n            "description" : "boost",\n            "details" : [ ]\n          },\n          {\n            "value" : 3.4100041,\n            "description" : "idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:",\n            "details" : [\n              {\n                "value" : 154,\n                "description" : "n, number of documents containing term",\n                "details" : [ ]\n              },\n              {\n                "value" : 4675,\n                "description" : "N, total number of documents with field",\n                "details" : [ ]\n              }\n            ]\n          },\n          {\n            "value" : 0.47548598,\n            "description" : "tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:",\n            "details" : [\n              {\n                "value" : 1.0,\n                "description" : "freq, occurrences of term within document",\n                "details" : [ ]\n              },\n              {\n                "value" : 1.2,\n                "description" : "k1, term saturation parameter",\n                "details" : [ ]\n              },\n              {\n                "value" : 0.75,\n                "description" : "b, length normalization parameter",\n                "details" : [ ]\n              },\n              {\n                "value" : 1.0,\n                "description" : "dl, length of field",\n                "details" : [ ]\n              },\n              {\n                "value" : 1.1206417,\n                "description" : "avgdl, average length of field",\n                "details" : [ ]\n              }\n            ]\n          }\n        ]\n      }\n    ]\n  }\n}

----------------------------------------

TITLE: Indexing a polygon document in OpenSearch
DESCRIPTION: Indexes a document with a polygon location into the 'testindex' index.

LANGUAGE: json
CODE:
PUT testindex/_doc/2
{
  "location": {
    "type": "polygon",
    "coordinates": [
      [
        [
          73.0515,
          41.5582
        ],
        [
          72.6506,
          41.5623
        ],
        [
          72.6734,
          41.7658
        ],
        [
          73.0515,
          41.5582
        ]
      ]
    ]
  }
}

----------------------------------------

TITLE: Configuring TLS Protocol Settings
DESCRIPTION: Example YAML configuration for specifying enabled TLS ciphers and protocols for HTTP layer security in OpenSearch.

LANGUAGE: yaml
CODE:
plugins.security.ssl.http.enabled_ciphers:
  - "TLS_DHE_RSA_WITH_AES_256_CBC_SHA"
  - "TLS_DHE_DSS_WITH_AES_128_CBC_SHA256"
plugins.security.ssl.http.enabled_protocols:
  - "TLSv1.1"
  - "TLSv1.2"

----------------------------------------

TITLE: Configuring OpenSearch Network and Discovery Settings
DESCRIPTION: This YAML configuration snippet sets up network binding and discovery type for OpenSearch, allowing external access and configuring it for single-node operation.

LANGUAGE: yaml
CODE:
# Bind OpenSearch to the correct network interface. Use 0.0.0.0
# to include all available interfaces or specify an IP address
# assigned to a specific interface.
network.host: 0.0.0.0

# Unless you have already configured a cluster, you should set
# discovery.type to single-node, or the bootstrap checks will
# fail when you try to start the service.
discovery.type: single-node

# If you previously disabled the Security plugin in opensearch.yml,
# be sure to re-enable it. Otherwise you can skip this setting.
plugins.security.disabled: false

----------------------------------------

TITLE: Sample OpenSearch Dashboards Configuration with Multiple Authentication
DESCRIPTION: This comprehensive YAML configuration demonstrates setting up OpenSearch Dashboards with multiple authentication options, including basic settings, multiple auth enablement, and customization for basic auth and OpenID Connect.

LANGUAGE: yaml
CODE:
server.host: 0.0.0.0
server.port: 5601
opensearch.hosts: ["https://localhost:9200"]
opensearch.ssl.verificationMode: none
opensearch.username: <preferred username>
opensearch.password: <preferred password>
opensearch.requestHeadersAllowlist: ["securitytenant","Authorization"]
opensearch_security.multitenancy.enabled: true
opensearch_security.multitenancy.tenants.preferred: ["Private", "Global"]
opensearch_security.readonly_mode.roles: ["<role_for_read_only>"]

opensearch_security.auth.multiple_auth_enabled: true
opensearch_security.auth.type: ["basicauth","openid"]

opensearch_security.ui.basicauth.login.brandimage: <path/to/OSlogo.png>
opensearch_security.ui.basicauth.login.showbrandimage: true

opensearch_security.ui.openid.login.buttonname: Log in with <IdP name or other> 
opensearch_security.ui.openid.login.brandimage: <path/to/brand-logo.png>
opensearch_security.ui.openid.login.showbrandimage: true

opensearch_security.openid.base_redirect_url: <"OIDC redirect URL">
opensearch_security.openid.verify_hostnames: false
opensearch_security.openid.refresh_tokens: false
opensearch_security.openid.logout_url: <"OIDC logout URL">

opensearch_security.openid.connect_url: <"OIDC connect URL">
opensearch_security.openid.client_id: <Client ID>
opensearch_security.openid.client_secret: <Client secret>

----------------------------------------

TITLE: Create Action in OpenSearch Bulk API
DESCRIPTION: Shows the format for a create action in the bulk API. This action creates a document if it doesn't already exist and returns an error otherwise.

LANGUAGE: json
CODE:
{ "create": { "_index": "movies", "_id": "tt1392214" } }
{ "title": "Prisoners", "year": 2013 }

----------------------------------------

TITLE: Cleanup Commands for Test Resources
DESCRIPTION: Series of commands to clean up test snapshots, repositories, and S3 buckets after verification.

LANGUAGE: shell
CODE:
curl -X DELETE "http://<your-source-cluster>:9200/_snapshot/test_s3_repository/test_snapshot_1?pretty"
curl -X DELETE "http://<your-source-cluster>:9200/_snapshot/test_s3_repository?pretty"
aws s3 rm s3://<your-bucket-name> --recursive
aws s3api delete-bucket --bucket <your-bucket-name> --region <your-aws-region>

----------------------------------------

TITLE: Creating an index with geo_shape mapping in OpenSearch
DESCRIPTION: Creates an index named 'testindex' with a 'location' field mapped as a geo_shape type.

LANGUAGE: json
CODE:
PUT /testindex
{
  "mappings": {
    "properties": {
      "location": {
        "type": "geo_shape"
      }
    }
  }
}

----------------------------------------

TITLE: Creating Custom English Analyzer in OpenSearch
DESCRIPTION: This snippet illustrates how to create a custom English analyzer in OpenSearch. It defines custom token filters and combines them to create an analyzer that closely mimics the built-in English analyzer.

LANGUAGE: json
CODE:
PUT /english-index
{
  "settings": {
    "analysis": {
      "filter": {
        "english_stop": {
          "type": "stop",
          "stopwords": "_english_"
        },
        "english_stemmer": {
          "type": "stemmer",
          "language": "english"
        },
        "english_keywords": {
          "type": "keyword_marker",
          "keywords": []
        },
        "english_possessive_stemmer": {
          "type":       "stemmer",
          "language":   "possessive_english"
        }
      },
      "analyzer": {
        "english_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "english_possessive_stemmer",
            "lowercase",
            "english_stop",
            "english_keywords",
            "english_stemmer"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "english_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Performing Semantic Search in OpenSearch
DESCRIPTION: This request performs a semantic search on the vector index using a neural query, automatically generating embeddings for the query text.

LANGUAGE: json
CODE:
GET /my-nlp-index/_search
{
  "_source": {
    "excludes": [
      "passage_embedding"
    ]
  },
  "query": {
    "neural": {
      "passage_embedding": {
        "query_text": "wild west",
        "model_id": "aVeif4oB5Vm0Tdw8zYO2",
        "k": 3
      }
    }
  }
}

----------------------------------------

TITLE: Shutting Down Data Prepper
DESCRIPTION: cURL command to shut down a running Data Prepper instance.

LANGUAGE: bash
CODE:
POST /shutdown

----------------------------------------

TITLE: Registering Flow Agent with AgentTool - JSON
DESCRIPTION: Request structure for registering a flow agent that uses AgentTool, including name, type, description, and tool configuration.

LANGUAGE: json
CODE:
{
  "name": "Test agent tool",
  "type": "flow",
  "description": "this is a test agent",
  "tools": [
    {
      "type": "AgentTool",
      "description": "A general agent to answer any question",
      "parameters": {
        "agent_id": "9X7xWI0Bpc3sThaJdY9i"
      }
    }
  ]
}

----------------------------------------

TITLE: Parsing and Converting Timestamp Format and Timezone in OpenSearch Data Prepper (YAML)
DESCRIPTION: This configuration parses a timestamp in 'dd/MMM/yyyy:HH:mm:ss' format, converts it to 'yyyy-MM-dd'T'HH:mm:ss.SSSXXX' format, and changes the timezone from Los Angeles to Chicago.

LANGUAGE: yaml
CODE:
- date:
    match:
      - key: timestamp
        patterns: ["dd/MMM/yyyy:HH:mm:ss"] 
    destination: "@timestamp"
    output_format: "yyyy-MM-dd'T'HH:mm:ss.SSSXXX"
    source_timezone: "America/Los_Angeles"
    destination_timezone: "America/Chicago"
    locale: "en_US"

----------------------------------------

TITLE: Deploying OpenSearch Cluster with Kubernetes
DESCRIPTION: This command applies the OpenSearch cluster configuration defined in the YAML file to create a new OpenSearch cluster in Kubernetes.

LANGUAGE: bash
CODE:
kubectl apply -f opensearch-cluster.yaml

----------------------------------------

TITLE: Excluding Model Chunks in OpenSearch Search
DESCRIPTION: This query demonstrates how to exclude model chunks from the search results. It uses a bool query with a must_not clause to filter out documents with a 'chunk_number' field.

LANGUAGE: json
CODE:
GET /_plugins/_ml/models/_search
{
  "query": {
    "bool": {
      "must_not": {
        "exists": {
          "field": "chunk_number"
        }
      }
    }
  },
  "sort": [
    {
      "created_time": {
        "order": "desc"
      }
    }
  ]
}

----------------------------------------

TITLE: Nested Boolean Queries in OpenSearch
DESCRIPTION: Shows how to construct complex Boolean expressions by nesting bool queries to find text matching (love OR hate) AND (life OR grace).

LANGUAGE: json
CODE:
GET shakespeare/_search
{
  "query": {
    "bool": {
      "must": [
        {
          "bool": {
            "should": [
              {
                "match": {
                  "text_entry": "love"
                }
              },
              {
                "match": {
                  "text": "hate"
                }
              }
            ]
          }
        },
        {
          "bool": {
            "should": [
              {
                "match": {
                  "text_entry": "life"
                }
              },
              {
                "match": {
                  "text": "grace"
                }
              }
            ]
          }
        }
      ],
      "filter": {
        "term": {
          "play_name": "Romeo and Juliet"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Indexing a Document in OpenSearch
DESCRIPTION: Use the client's index() method to add a document to an OpenSearch index. This example indexes a movie document with a specified ID.

LANGUAGE: python
CODE:
document = {
  'title': 'Moneyball',
  'director': 'Bennett Miller',
  'year': '2011'
}

response = client.index(
    index = 'python-test-index',
    body = document,
    id = '1',
    refresh = True
)

----------------------------------------

TITLE: Updating IP2Geo Data Source Settings in OpenSearch
DESCRIPTION: This snippet demonstrates how to update the settings of an existing IP2Geo data source, including the endpoint and update interval.

LANGUAGE: json
CODE:
PUT /_plugins/geospatial/ip2geo/datasource/my-datasource/_settings
{
    "endpoint": "https://geoip.maps.opensearch.org/v1/geolite2-city/manifest.json",
    "update_interval_in_days": 10
}

----------------------------------------

TITLE: Creating a bucket-level monitor in OpenSearch
DESCRIPTION: Creates a new bucket-level monitor that runs an aggregation query and triggers alerts based on bucket results. Includes schedule, input aggregation, trigger condition, and actions.

LANGUAGE: json
CODE:
POST _plugins/_alerting/monitors
{
  "type": "monitor",
  "name": "Demo bucket-level monitor",
  "monitor_type": "bucket_level_monitor",
  "enabled": true,
  "schedule": {
    "period": {
      "interval": 1,
      "unit": "MINUTES"
    }
  },
  "inputs": [
    {
      "search": {
        "indices": [
          "movies"
        ],
        "query": {
          "size": 0,
          "query": {
            "bool": {
              "filter": [
                {
                  "range": {
                    "order_date": {
                      "from": "{{period_end}}||-1h",
                      "to": "{{period_end}}",
                      "include_lower": true,
                      "include_upper": true,
                      "format": "epoch_millis"
                    }
                  }
                }
              ]
            }
          },
          "aggregations": {
            "composite_agg": {
              "composite": {
                "sources": [
                  {
                    "user": {
                      "terms": {
                        "field": "user"
                      }
                    }
                  }
                ]
              },
              "aggregations": {
                "avg_products_base_price": {
                  "avg": {
                    "field": "products.base_price"
                  }
                }
              }
            }
          }
        }
      }
    }
  ],
  "triggers": [
    {
      "bucket_level_trigger": {
        "name": "test-trigger",
        "severity": "1",
        "condition": {
          "buckets_path": {
            "_count": "_count",
            "avg_products_base_price": "avg_products_base_price"
          },
          "parent_bucket_path": "composite_agg",
          "script": {
            "source": "params._count > 50 || params.avg_products_base_price < 35",
            "lang": "painless"
          }
        },
        "actions": [
          {
            "name": "test-action",
            "destination_id": "E4o5hnsB6KjPKmHtpfCA",
            "message_template": {
              "source": "Monitor {{ctx.monitor.name}} just entered alert status. Please investigate the issue.   - Trigger: {{ctx.trigger.name}}   - Severity: {{ctx.trigger.severity}}   - Period start: {{ctx.periodStart}}   - Period end: {{ctx.periodEnd}}    - Deduped Alerts:   {{ctx.dedupedAlerts}}     * {{id}} : {{bucket_keys}}   {{ctx.dedupedAlerts}}    - New Alerts:   {{ctx.newAlerts}}     * {{id}} : {{bucket_keys}}   {{ctx.newAlerts}}    - Completed Alerts:   {{ctx.completedAlerts}}     * {{id}} : {{bucket_keys}}   {{ctx.completedAlerts}}",
              "lang": "mustache"
            },
            "throttle_enabled": false,
            "throttle": {
              "value": 10,
              "unit": "MINUTES"
            },
            "action_execution_policy": {
              "action_execution_scope": {
                "per_alert": {
                  "actionable_alerts": [
                    "DEDUPED",
                    "NEW"
                  ]
                }
              }
            },
            "subject_template": {
              "source": "The Subject",
              "lang": "mustache"
            }
          }
        ]
      }
    }
  ]
}

----------------------------------------

TITLE: Executing a basic search query with profiling enabled
DESCRIPTION: Sends a search request to the testindex with profiling enabled to get timing information about the query execution.

LANGUAGE: json
CODE:
GET /testindex/_search
{
  "profile": true,
  "query" : {
    "match" : { "title" : "wind" }
  }
}

----------------------------------------

TITLE: Testing OpenSearch with Security
DESCRIPTION: Commands to test OpenSearch installation with security enabled using curl requests.

LANGUAGE: bash
CODE:
curl -X GET https://localhost:9200 -u 'admin:<custom-admin-password>' --insecure

curl -X GET https://localhost:9200/_cat/plugins?v -u 'admin:<custom-admin-password>' --insecure

----------------------------------------

TITLE: Using Command Flags in OpenSearch Benchmark (Bash)
DESCRIPTION: Demonstrates the syntax for using command flags with OpenSearch Benchmark commands. Flags can accept simple values, comma-separated lists, or JSON input.

LANGUAGE: bash
CODE:
opensearch-benchmark <command> --<command-flag>

LANGUAGE: bash
CODE:
opensearch-benchmark ... --test-procedure="ingest-only,search-aggregations"

LANGUAGE: bash
CODE:
opensearch-benchmark ... --workload-params="params.json"

LANGUAGE: bash
CODE:
opensearch-benchmark  ... --telemetry='["node-stats", "recovery-stats"]'

----------------------------------------

TITLE: Querying CAT Nodes Endpoint - OpenSearch REST API
DESCRIPTION: Basic endpoint for retrieving node information from the OpenSearch cluster.

LANGUAGE: json
CODE:
GET /_cat/nodes

----------------------------------------

TITLE: Applying Czech Analyzer to Text Field in OpenSearch
DESCRIPTION: This snippet demonstrates how to apply the built-in Czech analyzer to a text field in an OpenSearch index mapping.

LANGUAGE: json
CODE:
PUT /czech-index
{
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "czech"
      }
    }
  }
}

----------------------------------------

TITLE: Executing a Reverse Nested Aggregation Query in OpenSearch
DESCRIPTION: This query demonstrates how to use reverse_nested aggregation to aggregate a field from the parent document after grouping by a field from the nested object. It searches for logs with a 200 response and aggregates page load times.

LANGUAGE: json
CODE:
GET logs/_search
{
  "query": {
    "match": { "response": "200" }
  },
  "aggs": {
    "pages": {
      "nested": {
        "path": "pages"
      },
      "aggs": {
        "top_pages_per_load_time": {
          "terms": {
            "field": "pages.load_time"
          },
          "aggs": {
            "comment_to_logs": {
              "reverse_nested": {},
              "aggs": {
                "min_load_time": {
                  "min": {
                    "field": "pages.load_time"
                  }
                }
              }
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Extended Proxy Authentication in OpenSearch YAML
DESCRIPTION: This YAML configuration sets up extended proxy authentication in OpenSearch. It includes settings for user and roles headers, as well as an attribute header prefix for additional user attributes.

LANGUAGE: yaml
CODE:
proxy_auth_domain:
  http_enabled: true
  transport_enabled: true
  order: 0
  http_authenticator:
    type: extended-proxy
    challenge: false
    config:
      user_header: "x-proxy-user"
      roles_header: "x-proxy-roles"
      attr_header_prefix: "x-proxy-ext-"
  authentication_backend:
    type: noop

----------------------------------------

TITLE: Delete Action in OpenSearch Bulk API
DESCRIPTION: Illustrates the format for a delete action in the bulk API. This action deletes a document if it exists and doesn't require a document on the next line.

LANGUAGE: json
CODE:
{ "delete": { "_index": "movies", "_id": "tt2229499" } }

----------------------------------------

TITLE: Example Request for Deleting a Script in OpenSearch
DESCRIPTION: This example shows how to delete a script named 'my-script' using the Delete Script API.

LANGUAGE: json
CODE:
DELETE _scripts/my-script

----------------------------------------

TITLE: Creating a Pipeline with JSON Processor in OpenSearch
DESCRIPTION: Shows how to create an ingest pipeline named 'my-json-pipeline' that uses the JSON processor to parse raw JSON data and enrich documents. It also includes error handling and timestamp addition.

LANGUAGE: json
CODE:
PUT _ingest/pipeline/my-json-pipeline
{
  "description": "Example pipeline using the JsonProcessor",
  "processors": [
    {
      "json": {
        "field": "raw_data",
        "target_field": "parsed_data"
        "on_failure": [
          {
            "set": {
              "field": "error_message",
              "value": "Failed to parse JSON data"
            }
          },
          {
            "fail": {
              "message": "Failed to process JSON data"
            }
          }
        ]
      }
    },
    {
      "set": {
        "field": "processed_timestamp",
        "value": "{{_ingest.timestamp}}"
      }
    }
  ]
}

----------------------------------------

TITLE: Basic Function Score Query with Weight Function
DESCRIPTION: A simple function score query that uses the weight function to double all relevance scores.

LANGUAGE: json
CODE:
GET shakespeare/_search
{
  "query": {
    "function_score": {
      "weight": "2"
    }
  }
}

----------------------------------------

TITLE: Analyzing Text with Czech Analyzer in OpenSearch
DESCRIPTION: This snippet shows how to analyze a Czech text using the configured analyzer and examine the generated tokens.

LANGUAGE: json
CODE:
POST /czech-index/_analyze
{
  "field": "content",
  "text": "Studenti studuj na eskch univerzitch. Jejich sla jsou 123456."
}

----------------------------------------

TITLE: Configuring OpenSearch Network and Discovery Settings
DESCRIPTION: YAML configuration to bind OpenSearch to a network interface and set single-node discovery.

LANGUAGE: yaml
CODE:
network.host: 0.0.0.0
discovery.type: single-node
plugins.security.disabled: false

----------------------------------------

TITLE: Parameterized Prefix Query Template
DESCRIPTION: Template showing the full structure of a prefix query with parameter placeholders. Supports optional parameters like boost, case_insensitive, and rewrite.

LANGUAGE: json
CODE:
GET _search
{
  "query": {
    "prefix": {
      "<field>": {
        "value": "sample",
        "..."
      }
    }
  }
}

----------------------------------------

TITLE: Creating Mapping with Completion Field in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a mapping with a completion field in OpenSearch. It defines a 'suggestions' field of type 'completion' and a 'product' field of type 'keyword'.

LANGUAGE: json
CODE:
PUT chess_store
{
  "mappings": {
    "properties": {
      "suggestions": {
        "type": "completion"
      },
      "product": {
        "type": "keyword"
      }
    }
  }
}

----------------------------------------

TITLE: Creating Geo Point Mapping in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a mapping with a 'point' field of type 'geo_point' in OpenSearch. This mapping is necessary for performing geodistance queries.

LANGUAGE: json
CODE:
PUT testindex1
{
  "mappings": {
    "properties": {
      "point": {
        "type": "geo_point"
      }
    }
  }
}

----------------------------------------

TITLE: Creating Index with Dynamic True
DESCRIPTION: Creates an OpenSearch index with dynamic mapping enabled, allowing new fields to be automatically added to the mapping during indexing.

LANGUAGE: json
CODE:
PUT testindex1
{
  "mappings": {
    "dynamic": true
  }
}

----------------------------------------

TITLE: Example Response for Exists Query
DESCRIPTION: Sample response showing a matching document containing the description field.

LANGUAGE: json
CODE:
{
  "took": 3,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 1,
      "relation": "eq"
    },
    "max_score": 1,
    "hits": [
      {
        "_index": "testindex",
        "_id": "2",
        "_score": 1,
        "_source": {
          "title": "Gone with the wind",
          "description": "A 1939 American epic historical film"
        }
      }
    ]
  }
}

----------------------------------------

TITLE: Querying Website Hits per Month Using Date Histogram in OpenSearch
DESCRIPTION: This snippet demonstrates how to use a date histogram aggregation to analyze website hits per month. It queries the 'opensearch_dashboards_sample_data_logs' index, aggregating on the '@timestamp' field with a monthly interval.

LANGUAGE: json
CODE:
GET opensearch_dashboards_sample_data_logs/_search
{
  "size": 0,
  "aggs": {
    "logs_per_month": {
      "date_histogram": {
        "field": "@timestamp",
        "interval": "month"
      }
    }
  }
}

----------------------------------------

TITLE: Basic Match Phrase Query in OpenSearch
DESCRIPTION: A simple match_phrase query to search for documents containing the exact phrase "the wind" in the title field.

LANGUAGE: json
CODE:
GET _search
{
  "query": {
    "match_phrase": {
      "title": "the wind"
    }
  }
}

----------------------------------------

TITLE: Setting Node Attributes in YAML
DESCRIPTION: Configures node name and roles for different node types in the cluster.

LANGUAGE: yaml
CODE:
node.name: opensearch-cluster_manager
node.roles: [ cluster_manager ]

LANGUAGE: yaml
CODE:
node.name: opensearch-d1
node.roles: [ data, ingest ]

LANGUAGE: yaml
CODE:
node.name: opensearch-c1
node.roles: []

----------------------------------------

TITLE: Parameterized SQL Query
DESCRIPTION: Example of using parameters in SQL queries for dynamic value injection.

LANGUAGE: json
CODE:
{
  "query": "SELECT * FROM accounts WHERE age = ?",
  "parameters": [{
    "type": "integer",
    "value": 30
  }]
}

----------------------------------------

TITLE: OpenSearch CAT Indices API Endpoints
DESCRIPTION: The base endpoints for retrieving index information. Supports querying all indices or specific indices by name.

LANGUAGE: json
CODE:
GET /_cat/indices
GET /_cat/indices/{index}

----------------------------------------

TITLE: Creating Filter Query Search Pipeline
DESCRIPTION: Creates a search pipeline that filters documents based on visibility using a term query.

LANGUAGE: json
CODE:
PUT /_search/pipeline/my_pipeline 
{
  "request_processors": [
    {
      "filter_query" : {
        "tag" : "tag1",
        "description" : "This processor is going to restrict to publicly visible documents",
        "query" : {
          "term": {
            "visibility": "public"
          }
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Text Field with Term Vector Configuration
DESCRIPTION: Example showing how to create a text field that stores character offsets in a term vector for highlighting purposes.

LANGUAGE: json
CODE:
PUT testindex
{
  "mappings" : {
    "properties" : {
      "dob" : {
        "type" :  "text",
        "term_vector": "with_positions_offsets"
      }
    }
  }
}

----------------------------------------

TITLE: Testing Foreach Pipeline
DESCRIPTION: Simulation request to test the foreach processor pipeline with sample data containing protocol names.

LANGUAGE: json
CODE:
POST _ingest/pipeline/test-foreach/_simulate  
{  
  "docs": [  
    {  
      "_index": "testindex1",  
      "_id": "1",  
      "_source": {  
        "protocols": ["HTTP","HTTPS","TCP","UDP"]  
      }  
    }  
  ]  
}

----------------------------------------

TITLE: Creating Vector Index in OpenSearch
DESCRIPTION: Creates a vector index with KNN capabilities and nested document structure for storing book data with embeddings.

LANGUAGE: json
CODE:
PUT my_books
{
  "settings" : {
      "index.knn" : "true",
      "default_pipeline": "bedrock_embedding_foreach_pipeline"
  },
  "mappings": {
    "properties": {
      "books": {
        "type": "nested",
        "properties": {
          "title_embedding": {
            "type": "knn_vector",
            "dimension": 1536
          },
          "title": {
            "type": "text"
          },
          "description": {
            "type": "text"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Weekend Monitor Intervals in OpenSearch Alerting
DESCRIPTION: This cron expression configures a monitor to run every 10 minutes on Saturday and Sunday. It uses a step value for the minute field and a range for the day of week field.

LANGUAGE: cron
CODE:
0/10 * * * 6-7

----------------------------------------

TITLE: Configuring Remote-Backed Storage Settings in OpenSearch
DESCRIPTION: Sets cluster settings to enable mixed mode and migration direction for remote-backed storage.

LANGUAGE: json
CODE:
PUT "/_cluster/settings?pretty"
{
    "persistent": {
        "cluster.remote_store.compatibility_mode": "mixed",
        "cluster.migration.direction" :  "remote_store"
    }
}

----------------------------------------

TITLE: Mapping Azure Log Fields to ECS Schema
DESCRIPTION: Comprehensive mapping configuration that defines relationships between Azure raw log fields and their corresponding ECS (Elastic Common Schema) fields. Covers various Azure services including SignInLogs, PlatformLogs, AuditLogs, and ActivityLogs.

LANGUAGE: json
CODE:
"mappings": [
    {
      "raw_field":"Resultdescription",
      "ecs":"azure.signinlogs.result_description"
    },
    {
      "raw_field":"eventSource",
      "ecs":"eventSource"
    },
    {
      "raw_field":"eventName",
      "ecs":"eventName"
    },
    {
      "raw_field":"Status",
      "ecs":"azure.platformlogs.status"
    },
    {
      "raw_field":"LoggedByService",
      "ecs":"azure.auditlogs.properties.logged_by_service"
    },
    {
      "raw_field":"properties_message",
      "ecs":"properties_message"
    },
    {
      "raw_field":"status",
      "ecs":"azure.platformlogs.status"
    },
    {
      "raw_field":"TargetUserName",
      "ecs":"azure.signinlogs.properties.user_id"
    },
    {
      "raw_field":"creationTime",
      "ecs":"timestamp"
    },
    {
      "raw_field":"Category",
      "ecs":"azure.activitylogs.category"
    },
    {
      "raw_field":"OperationName",
      "ecs":"azure.platformlogs.operation_name"
    },
    {
      "raw_field":"ModifiedProperties_NewValue",
      "ecs":"modified_properties.new_value"
    },
    {
      "raw_field":"ResourceProviderValue",
      "ecs":"azure.resource.provider"
    },
    {
      "raw_field":"conditionalAccessStatus",
      "ecs":"azure.signinlogs.properties.conditional_access_status"
    },
    {
      "raw_field":"SearchFilter",
      "ecs":"search_filter"
    },
    {
      "raw_field":"Operation",
      "ecs":"azure.platformlogs.operation_name"
    },
    {
      "raw_field":"ResultType",
      "ecs":"azure.platformlogs.result_type"
    },
    {
      "raw_field":"DeviceDetail_isCompliant",
      "ecs":"azure.signinlogs.properties.device_detail.is_compliant"
    },
    {
      "raw_field":"ResourceDisplayName",
      "ecs":"resource_display_name"
    },
    {
      "raw_field":"AuthenticationRequirement",
      "ecs":"azure.signinlogs.properties.authentication_requirement"
    },
    {
      "raw_field":"TargetResources",
      "ecs":"target_resources"
    },
    {
      "raw_field":"Workload",
      "ecs":"Workload"
    },
    {
      "raw_field":"DeviceDetail_deviceId",
      "ecs":"azure.signinlogs.properties.device_detail.device_id"
    },
    {
      "raw_field":"OperationNameValue",
      "ecs":"azure.platformlogs.operation_name"
    },
    {
      "raw_field":"ResourceId",
      "ecs":"azure.signinlogs.properties.resource_id"
    },
    {
      "raw_field":"ResultDescription",
      "ecs":"azure.signinlogs.result_description"
    },
    {
      "raw_field":"EventID",
      "ecs":"EventID"
    },
    {
      "raw_field":"NetworkLocationDetails",
      "ecs":"azure.signinlogs.properties.network_location_details"
    },
    {
      "raw_field":"CategoryValue",
      "ecs":"azure.activitylogs.category"
    },
    {
      "raw_field":"ActivityDisplayName",
      "ecs":"azure.auditlogs.properties.activity_display_name"
    },
    {
      "raw_field":"Initiatedby",
      "ecs":"azure.activitylogs.identity.claims_initiated_by_user.name"
    },
    {
      "raw_field":"Count",
      "ecs":"Count"
    },
    {
      "raw_field":"ResourceTenantId",
      "ecs":"azure.signinlogs.properties.resource_tenant_id"
    },
    {
      "raw_field":"failure_status_reason",
      "ecs":"failure_status_reason"
    },
    {
      "raw_field":"AppId",
      "ecs":"azure.signinlogs.properties.app_id"
    },
    {
      "raw_field":"properties.message",
      "ecs":"properties.message"
    },
    {
      "raw_field":"ClientApp",
      "ecs":"azure.signinlogs.properties.client_app_used"
    },
    {
      "raw_field":"ActivityDetails",
      "ecs":"ActivityDetails"
    },
    {
      "raw_field":"Target",
      "ecs":"Target"
    },
    {
      "raw_field":"DeviceDetail.trusttype",
      "ecs":"azure.signinlogs.properties.device_detail.trust_type"
    },
    {
      "raw_field":"HomeTenantId",
      "ecs":"azure.signinlogs.properties.home_tenant_id"
    },
    {
      "raw_field":"ConsentContext.IsAdminConsent",
      "ecs":"ConsentContext.IsAdminConsent"
    },
    {
      "raw_field":"InitiatedBy",
      "ecs":"InitiatedBy"
    },
    {
      "raw_field":"ActivityType",
      "ecs":"azure.auditlogs.properties.activity_display_name"
    },
    {
      "raw_field":"operationName",
      "ecs":"azure.activitylogs.operation_name"
    },
    {
      "raw_field":"ModifiedProperties{}.NewValue",
      "ecs":"modified_properties.new_value"
    },
    {
      "raw_field":"userAgent",
      "ecs":"user_agent.name"
    },
    {
      "raw_field":"RiskState",
      "ecs":"azure.signinlogs.properties.risk_state"
    },
    {
      "raw_field":"Username",
      "ecs":"azure.activitylogs.identity.claims_initiated_by_user.name"
    },
    {
      "raw_field":"DeviceDetail.deviceId",
      "ecs":"azure.signinlogs.properties.device_detail.device_id"
    },
    {
      "raw_field":"DeviceDetail.isCompliant",
      "ecs":"azure.signinlogs.properties.device_detail.is_compliant"
    },
    {
      "raw_field":"Location",
      "ecs":"azure.signinlogs.properties.network_location_details"
    }
  ]

----------------------------------------

TITLE: Script Update with Secret Identity
DESCRIPTION: Example of using a script to add a secret_identity field to a document.

LANGUAGE: json
CODE:
{
  "script" : {
    "source": "ctx._source.secret_identity = \"Batman\""
  }
}

----------------------------------------

TITLE: Executing Painless Script with Score Context in OpenSearch
DESCRIPTION: This example demonstrates how to execute a Painless script using the score context. The script converts a GPA on a 4.0 scale to a different scale provided as a parameter.

LANGUAGE: json
CODE:
POST /_scripts/painless/_execute
{
  "script": {
    "source": "doc['gpa_4_0'].value * params.max_gpa / 4.0",
    "params": {
      "max_gpa": 5.0
    }
  },
  "context": "score",
  "context_setup": {
    "index": "testindex1",
    "document": {
      "gpa_4_0": 3.5
    }
  }
}

----------------------------------------

TITLE: Example Response from CAT Pending Tasks API in OpenSearch
DESCRIPTION: This snippet shows a sample response from the CAT pending tasks API. It includes information about pending tasks such as insert order, time in queue, priority, and source.

LANGUAGE: json
CODE:
insertOrder | timeInQueue | priority | source
  1786      |    1.8s     |  URGENT  | shard-started

----------------------------------------

TITLE: Creating Star-tree Index Mapping in OpenSearch
DESCRIPTION: Example of creating an index with star-tree configuration that precomputes aggregations on size and latency fields based on port and status dimensions. Includes settings for shards, replicas, and append-only mode.

LANGUAGE: json
CODE:
{
  "settings": {
    "index.number_of_shards": 1,
    "index.number_of_replicas": 0,
    "index.composite_index": true,
    "index.append_only.enabled": true
  },
  "mappings": {
    "composite": {
      "request_aggs": {
        "type": "star_tree",
        "config": {
          "date_dimension" : {
            "name": "@timestamp",
            "calendar_intervals": [
              "month",
              "day"
            ]
          },
          "ordered_dimensions": [
            {
              "name": "status"
            },
            {
              "name": "port"
            },
            {
              "name": "method"
            }
          ],
          "metrics": [
            {
              "name": "size",
              "stats": [
                "sum"
              ]
            },
            {
              "name": "latency",
              "stats": [
                "avg"
              ]
            }
          ]
        }
      }
    },
    "properties": {
      "status": {
        "type": "integer"
      },
      "port": {
        "type": "integer"
      },
      "size": {
        "type": "integer"
      },
      "method" : {
        "type": "keyword"
      },
      "latency": {
        "type": "scaled_float",
        "scaling_factor": 10
      }
    }
  }
}

----------------------------------------

TITLE: Configuring IAM Policy for Bootstrap Access in AWS
DESCRIPTION: JSON policy configuration for enabling AWS Systems Manager session access to the bootstrap EC2 instance. Requires replacing placeholders for AWS region, account, stage and EC2 instance ID.

LANGUAGE: json
CODE:
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": "ssm:StartSession",
            "Resource": [
                "arn:aws:ec2:<aws-region>:<aws-account>:instance/<ec2-instance-id>",
                "arn:aws:ssm:<aws-region>:<aws-account>:document/BootstrapShellDoc-<stage>-<aws-region>"
            ]
        }
    ]
}

----------------------------------------

TITLE: Enabling Shallow Snapshots in OpenSearch using Snapshot API
DESCRIPTION: This code snippet demonstrates how to enable shallow snapshot copies using the Snapshot API. It creates an S3 repository with the 'remote_store_index_shallow_copy' setting set to true.

LANGUAGE: bash
CODE:
PUT /_snapshot/snap_repo
{
        "type": "s3",
        "settings": {
            "bucket": "test-bucket",
            "base_path": "daily-snaps",
            "remote_store_index_shallow_copy": true
        }
    }

----------------------------------------

TITLE: Retrieving a Stored Script using GET Request in OpenSearch
DESCRIPTION: This snippet demonstrates how to retrieve a stored script named 'my-first-script' using a GET request to the _scripts endpoint in OpenSearch.

LANGUAGE: json
CODE:
GET _scripts/my-first-script

----------------------------------------

TITLE: Retrieving Zone Decommission Status in OpenSearch using JSON
DESCRIPTION: This API endpoint retrieves the decommission status of all zones. It uses the GET method to fetch the current status.

LANGUAGE: json
CODE:
GET /_cluster/decommission/awareness/zone/_status

----------------------------------------

TITLE: Configuring OpenSearch Dashboards for Proxy Authentication
DESCRIPTION: These YAML snippets configure OpenSearch Dashboards to work with proxy authentication. They set up the allowed request headers and specify the proxy authentication type and headers.

LANGUAGE: yaml
CODE:
opensearch.requestHeadersAllowlist: ["securitytenant","Authorization","x-forwarded-for","x-proxy-user","x-proxy-roles"]

LANGUAGE: yaml
CODE:
opensearch_security.auth.type: "proxy"
opensearch_security.proxycache.user_header: "x-proxy-user"
opensearch_security.proxycache.roles_header: "x-proxy-roles"

----------------------------------------

TITLE: Executing Parent ID Query - OpenSearch JSON
DESCRIPTION: Performs a search query to find child documents of type 'product' whose parent document has the ID '1'. This query demonstrates how to retrieve specific child documents based on their parent's ID.

LANGUAGE: json
CODE:
GET testindex1/_search
{
  "query": {
    "parent_id": {
      "type": "product",
      "id": "1"
    }
  }
}

----------------------------------------

TITLE: Managing Performance Analyzer in RPM/YUM Installations
DESCRIPTION: Commands to start and stop the Performance Analyzer service using systemctl in RPM-based installations.

LANGUAGE: bash
CODE:
# Start OpenSearch Performance Analyzer
sudo systemctl start opensearch-performance-analyzer.service
# Stop OpenSearch Performance Analyzer
sudo systemctl stop opensearch-performance-analyzer.service

----------------------------------------

TITLE: Launching PPL CLI for OpenSearch
DESCRIPTION: Command to launch the OpenSearch CLI in PPL mode, specifying the query language option.

LANGUAGE: console
CODE:
opensearchsql -l ppl <params>

----------------------------------------

TITLE: Ingesting Document with Foreach Pipeline
DESCRIPTION: Example of ingesting a document using the foreach processor pipeline to transform protocol names.

LANGUAGE: json
CODE:
POST testindex1/_doc/1?pipeline=test-foreach  
{  
  "protocols": ["HTTP","HTTPS","TCP","UDP"]  
}

----------------------------------------

TITLE: Applying a single YAML file with securityadmin.sh
DESCRIPTION: This command shows how to apply a single configuration file (config.yml) using PEM certificates.

LANGUAGE: bash
CODE:
./securityadmin.sh \
  -f ../../../config/opensearch-security/config.yml \
  -icl -nhnv -cert /etc/opensearch/kirk.pem \
  -cacert /etc/opensearch/root-ca.pem \
  -key /etc/opensearch/kirk-key.pem \
  -t config

----------------------------------------

TITLE: Lambda Function Test Configuration JSON
DESCRIPTION: JSON configuration for testing the Lambda function, specifying report parameters including URL, transport method, and email details.

LANGUAGE: json
CODE:
{
  "url": "https://playground.opensearch.org/app/dashboards#/view/084aed50-6f48-11ed-a3d5-1ddbf0afc873",
  "transport": "ses",
  "from": "sender@amazon.com", 
  "to": "recipient@amazon.com", 
  "subject": "Test lambda docker image"
}

----------------------------------------

TITLE: Deleting a Stored Script in OpenSearch
DESCRIPTION: This endpoint deletes a stored script in OpenSearch. It requires the script ID as a path parameter.

LANGUAGE: json
CODE:
DELETE _scripts/my-script

----------------------------------------

TITLE: Applying Arabic Analyzer to Text Field in OpenSearch
DESCRIPTION: This snippet demonstrates how to apply the built-in Arabic analyzer to a text field when creating an index in OpenSearch. It defines a mapping for a 'content' field using the 'arabic' analyzer.

LANGUAGE: json
CODE:
PUT /arabic-index
{
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "arabic"
      }
    }
  }
}

----------------------------------------

TITLE: Configuring IP Address Rate Limiting in OpenSearch
DESCRIPTION: Configuration settings for IP address-based rate limiting in OpenSearch Security plugin. This configuration limits login attempts by IP address with settings for attempt limits, time windows, and blocking periods.

LANGUAGE: yml
CODE:
auth_failure_listeners:
  ip_rate_limiting:
    type: ip
    allowed_tries: 1
    time_window_seconds: 20
    block_expiry_seconds: 180
    max_blocked_clients: 100000
    max_tracked_clients: 100000

----------------------------------------

TITLE: Connecting to OpenSearch with Security
DESCRIPTION: Creates a client connection to OpenSearch with security enabled using basic authentication

LANGUAGE: go
CODE:
client, err := opensearch.NewClient(opensearch.Config{
        Transport: &http.Transport{
            TLSClientConfig: &tls.Config{InsecureSkipVerify: true},
        },
        Addresses: []string{"https://localhost:9200"},
        Username:  "admin",
        Password:  "admin",
    })

----------------------------------------

TITLE: Creating a Search Pipeline with RAG Processor
DESCRIPTION: This request creates a search pipeline with a retrieval_augmented_generation processor for handling RAG queries.

LANGUAGE: json
CODE:
PUT /_search/pipeline/rag_pipeline
{
  "response_processors": [
    {
      "retrieval_augmented_generation": {
        "tag": "openai_pipeline_demo",
        "description": "Demo pipeline Using OpenAI Connector",
        "model_id": "gnDIbI0BfUsSoeNT_jAw",
        "context_field_list": ["text"],
        "system_prompt": "You are a helpful assistant",
        "user_instructions": "Generate a concise and informative answer in less than 100 words for the given question"
      }
    }
  ]
}

----------------------------------------

TITLE: Token Generation Result with Unique Filter in OpenSearch
DESCRIPTION: This snippet shows the response from the _analyze API, demonstrating the tokens generated after applying the unique_analyzer. Note how duplicate tokens like 'OpenSearch' and 'powerful' are removed.

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "opensearch",
      "start_offset": 0,
      "end_offset": 10,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "is",
      "start_offset": 22,
      "end_offset": 24,
      "type": "<ALPHANUM>",
      "position": 1
    },
    {
      "token": "powerful",
      "start_offset": 25,
      "end_offset": 33,
      "type": "<ALPHANUM>",
      "position": 2
    },
    {
      "token": "and",
      "start_offset": 43,
      "end_offset": 46,
      "type": "<ALPHANUM>",
      "position": 3
    },
    {
      "token": "scalable",
      "start_offset": 47,
      "end_offset": 55,
      "type": "<ALPHANUM>",
      "position": 4
    }
  ]
}

----------------------------------------

TITLE: Creating Documents with Bulk Helper in OpenSearch JavaScript Client
DESCRIPTION: Shows how to use the bulk helper to create new documents in an OpenSearch index. This operation only creates documents if they don't already exist.

LANGUAGE: javascript
CODE:
client.helpers.bulk({
  datasource: arrayOfDocuments,
  onDocument (doc) {
    return {
      create: { _index: 'example-index', _id: doc.id }
    }
  }
})

----------------------------------------

TITLE: Creating workload.json File
DESCRIPTION: Example of creating a workload.json file that defines the workload structure, including indices, corpora, and schedule.

LANGUAGE: json
CODE:
{
    "version": 2,
    "description": "Tutorial benchmark for OpenSearch Benchmark",
    "indices": [
        {
        "name": "movies",
        "body": "index.json"
        }
    ],
    "corpora": [
        {
        "name": "movies",
        "documents": [
            {
            "source-file": "movies-documents.json",
            "document-count": 11658903,
            "uncompressed-bytes": 1544799789
            }
        ]
        }
    ],
    "schedule": [
        {
        "operation": {
            "operation-type": "delete-index"
        }
        },
        {
        "operation": {
            "operation-type": "create-index"
        }
        },
        {
        "operation": {
            "operation-type": "cluster-health",
            "request-params": {
            "wait_for_status": "green"
            },
            "retry-until-success": true
        }
        },
        {
        "operation": {
            "operation-type": "bulk",
            "bulk-size": 5000
        },
        "warmup-time-period": 120,
        "clients": 8
        },
        {
        "operation": {
            "operation-type": "force-merge"
        }
        },
        {
        "operation": {
            "name": "query-match-all",
            "operation-type": "search",
            "body": {
            "query": {
                "match_all": {}
            }
            }
        },
        "clients": 8,
        "warmup-iterations": 1000,
        "iterations": 1000,
        "target-throughput": 100
        }
    ]
    }

----------------------------------------

TITLE: Term-level Query for Exact Term Search in OpenSearch
DESCRIPTION: Illustrates using a term-level query to search for the exact term 'HAMLET' in the speaker field. Shows proper usage of term queries for keyword fields.

LANGUAGE: json
CODE:
GET shakespeare/_search
{
  "query": {
    "term": {
      "speaker": "HAMLET"
    }
  }
}

----------------------------------------

TITLE: Filter Context Query in OpenSearch
DESCRIPTION: Example of a Boolean query using filter context to search for students who graduated with honors within a specific year range.

LANGUAGE: json
CODE:
GET students/_search
{
  "query": { 
    "bool": { 
      "filter": [ 
        { "term":  { "honors": true }},
        { "range": { "graduation_year": { "gte": 2020, "lte": 2022 }}}
      ]
    }
  }
}

----------------------------------------

TITLE: Creating Explicit Mappings in OpenSearch
DESCRIPTION: This example shows how to create an index with explicit mappings for 'year', 'age', and 'director' fields, specifying their data types.

LANGUAGE: json
CODE:
PUT sample-index1
{
  "mappings": {
    "properties": {
      "year":    { "type" : "text" },
      "age":     { "type" : "integer" },
      "director":{ "type" : "text" }
    }
  }
}

----------------------------------------

TITLE: Creating a Mapping with Keyword Field in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a mapping with a keyword field in OpenSearch. The 'genre' field is set as a keyword type with indexing disabled, which means it will be stored on disk and can be retrieved using doc_values.

LANGUAGE: json
CODE:
PUT movies
{
  "mappings" : {
    "properties" : {
      "genre" : {
        "type" :  "keyword",
        "index" : false
      }
    }
  }
}

----------------------------------------

TITLE: Installing OpenSearch.Client via XML Project Configuration
DESCRIPTION: XML configuration to add the OpenSearch.Client NuGet package to a .NET project file.

LANGUAGE: xml
CODE:
<Project>
  ...
  <ItemGroup>
    <PackageReference Include="OpenSearch.Client" Version="1.0.0" />
  </ItemGroup>
</Project>

----------------------------------------

TITLE: Successful Zone Decommission Response in OpenSearch JSON
DESCRIPTION: This JSON response indicates a successful zone decommission operation. The 'acknowledged' field is set to true.

LANGUAGE: json
CODE:
{
      "acknowledged": true
}

----------------------------------------

TITLE: Performing Geohash Grid Aggregation on Geoshape Field in OpenSearch
DESCRIPTION: This snippet shows how to perform a geohash grid aggregation on a geoshape field in OpenSearch. It uses the 'national_parks' index and sets a precision of 1 for the aggregation.

LANGUAGE: json
CODE:
GET national_parks/_search
{
  "aggregations": {
    "grouped": {
      "geohash_grid": {
        "field": "location",
        "precision": 1
      }
    }
  }
}

----------------------------------------

TITLE: Setting Throttling Threshold for Put-Mapping Tasks in OpenSearch
DESCRIPTION: This JSON request sets the throttling threshold for the 'put-mapping' task type to 100 using the OpenSearch cluster settings API. This limits the number of put-mapping tasks in the cluster manager's pending task queue.

LANGUAGE: json
CODE:
PUT _cluster/settings
{
  "persistent": {
    "cluster_manager.throttling.thresholds": {
      "put-mapping": {
        "value": 100
      }
    }
  }
}

----------------------------------------

TITLE: Indexing Nested Document
DESCRIPTION: Example of indexing a document with nested fields into OpenSearch.

LANGUAGE: json
CODE:
PUT /testindex/_doc/1
{
  "patient": {
    "name": "John Doe",
    "age": 56
  }
}

----------------------------------------

TITLE: Querying IP Address in OpenSearch
DESCRIPTION: This snippet illustrates how to query an OpenSearch index for a specific IP address using a term query. It searches for the exact IP address '10.24.34.0'.

LANGUAGE: json
CODE:
GET testindex/_doc/1 
{
  "query": {
    "term": {
      "ip_address": "10.24.34.0"
    }
  }
}

----------------------------------------

TITLE: Minimal OpenSearch Configuration for Proxy Authentication
DESCRIPTION: This YAML configuration provides a minimal setup for OpenSearch to work with proxy authentication. It enables XFF, sets the internal proxy IP, and configures the proxy authentication domain.

LANGUAGE: yaml
CODE:
---
_meta:
  type: "config"
  config_version: 2

config:
  dynamic:
    http:
      xff:
        enabled: true
        internalProxies: '172.16.0.203' # the nginx proxy
    authc:
      proxy_auth_domain:
        http_enabled: true
        transport_enabled: true
        order: 0
        http_authenticator:
          type: proxy
          #type: extended-proxy
          challenge: false
          config:
            user_header: "x-proxy-user"
            roles_header: "x-proxy-roles"
            #attr_header_prefix: "x-proxy-ext-"
        authentication_backend:
          type: noop

----------------------------------------

TITLE: Radial Search with max_distance
DESCRIPTION: Example of a k-NN radial search query using max_distance parameter to limit search results by distance threshold.

LANGUAGE: json
CODE:
GET /my-vector-index/_search
{
    "query": {
        "knn": {
            "my_vector": {
                "vector": [
                    7.1,
                    8.3
                ],
                "max_distance": 2
            }
        }
    }
}

----------------------------------------

TITLE: Verbose Pipeline Simulation Response
DESCRIPTION: Example response showing detailed processor results in verbose mode, displaying the transformation sequence for each document through the pipeline.

LANGUAGE: json
CODE:
{
  "docs": [
    {
      "processor_results": [
        {
          "processor_type": "set",
          "status": "success",
          "description": "Sets the graduation year to 2023",
          "doc": {
            "_index": "my-index",
            "_id": "1",
            "_source": {
              "name": "John Doe",
              "grad_year": 2023,
              "graduated": false
            },
            "_ingest": {
              "pipeline": "my-pipeline",
              "timestamp": "2023-06-20T23:23:26.656564631Z"
            }
          }
        },
        {
          "processor_type": "set",
          "status": "success",
          "description": "Sets 'graduated' to true",
          "doc": {
            "_index": "my-index",
            "_id": "1",
            "_source": {
              "name": "John Doe",
              "grad_year": 2023,
              "graduated": true
            },
            "_ingest": {
              "pipeline": "my-pipeline",
              "timestamp": "2023-06-20T23:23:26.656564631Z"
            }
          }
        },
        {
          "processor_type": "uppercase",
          "status": "success",
          "doc": {
            "_index": "my-index",
            "_id": "1",
            "_source": {
              "name": "JOHN DOE",
              "grad_year": 2023,
              "graduated": true
            },
            "_ingest": {
              "pipeline": "my-pipeline",
              "timestamp": "2023-06-20T23:23:26.656564631Z"
            }
          }
        }
      ]
    }
  ]
}

----------------------------------------

TITLE: Date and Time Function Usage in OpenSearch SQL
DESCRIPTION: Examples of using date and time functions in OpenSearch SQL queries. These functions perform various operations on date and time data types.

LANGUAGE: SQL
CODE:
SELECT adddate(date('2020-08-26'), INTERVAL 1 hour)
SELECT addtime(date('2008-12-12'), date('2008-12-12'))
SELECT convert_tz('2008-12-25 05:30:00', '+00:00', 'America/Los_Angeles')
SELECT curtime()
SELECT curdate()
SELECT current_date()
SELECT current_time()
SELECT current_timestamp()
SELECT date('2000-01-02')
SELECT datediff(date('2000-01-02'), date('2000-01-01'))
SELECT datetime('2008-12-25 00:00:00')
SELECT date_add('2020-08-26', INTERVAL 1 HOUR)
SELECT date_format(date('2020-08-26'), 'Y')
SELECT date_sub(date('2008-01-02'), INTERVAL 31 day)
SELECT dayofmonth(date('2001-05-07'))
SELECT day(date('2020-08-25'))
SELECT dayname(date('2020-08-26'))
SELECT dayofmonth(date('2020-08-26'))
SELECT dayofweek(date('2020-08-26'))
SELECT dayofyear(date('2020-08-26'))
SELECT dayofweek(date('2020-08-26'))
SELECT day_of_month(date('2020-08-26'))
SELECT day_of_week(date('2020-08-26'))
SELECT day_of_year(date('2020-08-26'))
SELECT extract(MONTH FROM datetime('2020-08-26 10:11:12'))
SELECT from_days(733687)
SELECT from_unixtime(1220249547)
SELECT get_format(DATE, 'USA')
SELECT hour(time '01:02:03')
SELECT hour_of_day(time '01:02:03')
SELECT last_day(date('2020-08-26'))
SELECT localtime()
SELECT localtimestamp()
SELECT makedate(1945, 5.9)
SELECT maketime(1, 2, 3)
SELECT microsecond(time '01:02:03.123456')
SELECT minute(time '01:02:03')
SELECT minute_of_day(time '01:02:03')
SELECT minute_of_hour(time '01:02:03')
SELECT month(date('2020-08-26'))
SELECT month_of_year(date('2020-08-26'))
SELECT monthname(date('2020-08-26'))
SELECT now()
SELECT period_add(200801, 2)
SELECT period_diff(200802, 200703)
SELECT quarter(date('2020-08-26'))
SELECT second(time '01:02:03')
SELECT second_of_minute(time '01:02:03')
SELECT sec_to_time(10000)
SELECT subdate(date('2008-01-02'), INTERVAL 31 day)
SELECT subtime(date('2008-12-12'), date('2008-11-15'))
SELECT str_to_date("01,5,2013", "%d,%m,%Y")
SELECT time('13:49:00')
SELECT timediff(time('23:59:59'), time('13:00:00'))
SELECT timestamp('2001-05-07 00:00:00')
SELECT timestampadd(DAY, 17, datetime('2000-01-01 00:00:00'))
SELECT timestampdiff(YEAR, '1997-01-01 00:00:00', '2001-03-06 00:00:00')
SELECT time_format('1998-01-31 13:14:15.012345', '%f %H %h %I %i %p %r %S %s %T')
SELECT time_to_sec(time '22:23:00')
SELECT to_days(date '2008-10-07')
SELECT to_seconds(date('2008-10-07'))
SELECT unix_timestamp(timestamp('1996-11-15 17:05:42'))
SELECT utc_date()
SELECT utc_time()
SELECT utc_timestamp()
SELECT week(date('2008-02-20'))
SELECT weekofyear(date('2008-02-20'))
SELECT week_of_year(date('2008-02-20'))
SELECT year(date('2001-07-05'))
SELECT yearweek(date('2008-02-20'))

----------------------------------------

TITLE: Configuring Text Chunking Processor in OpenSearch
DESCRIPTION: JSON configuration for the text_chunking processor, specifying the field mapping and algorithm parameters.

LANGUAGE: json
CODE:
{
  "text_chunking": {
    "field_map": {
      "<input_field>": "<output_field>"
    },
    "algorithm": {
      "<name>": "<parameters>"
    }
  }
}

----------------------------------------

TITLE: Basic GET Endpoints for List Indices API
DESCRIPTION: Core REST API endpoints for listing indices with optional index parameter specification

LANGUAGE: json
CODE:
GET _list/indices
GET _list/indices/<index>

----------------------------------------

TITLE: Registering a snapshot repository in OpenSearch
DESCRIPTION: Commands to register a snapshot repository and verify its creation.

LANGUAGE: bash
CODE:
curl -H 'Content-Type: application/json' \
   -X PUT "https://localhost:9201/_snapshot/snapshot-repo?pretty" \
   -d '{"type":"fs","settings":{"location":"/usr/share/opensearch/snapshots"}}' \
   -ku admin:<custom-admin-password>

LANGUAGE: bash
CODE:
curl -H 'Content-Type: application/json' \
   -X POST "https://localhost:9201/_snapshot/snapshot-repo/_verify?timeout=0s&master_timeout=50s&pretty" \
   -ku admin:<custom-admin-password>

----------------------------------------

TITLE: Installing opensearch-py-ml with pip
DESCRIPTION: This snippet shows how to install the opensearch-py-ml package using pip. This is a prerequisite step for using the client in your Python projects.

LANGUAGE: bash
CODE:
pip install opensearch-py-ml

----------------------------------------

TITLE: Mapping Roles in roles_mapping.yml
DESCRIPTION: Maps backend roles, users, and hosts to OpenSearch Security roles. This example includes mappings for various predefined roles.

LANGUAGE: yaml
CODE:
---
manage_snapshots:
  reserved: true
  hidden: false
  backend_roles:
  - "snapshotrestore"
  hosts: []
  users: []
  and_backend_roles: []
logstash:
  reserved: false
  hidden: false
  backend_roles:
  - "logstash"
  hosts: []
  users: []
  and_backend_roles: []
own_index:
  reserved: false
  hidden: false
  backend_roles: []
  hosts: []
  users:
  - "*"
  and_backend_roles: []
  description: "Allow full access to an index named like the username"
_meta:
  type: "rolesmapping"
  config_version: 2

----------------------------------------

TITLE: Analyzing Thai Text with Custom Analyzer
DESCRIPTION: Example request to analyze Thai text using the configured Thai analyzer, demonstrating how to test token generation.

LANGUAGE: json
CODE:
POST /thai_index/_analyze
{
  "analyzer": "thai_analyzer",
  "text": ""
}

----------------------------------------

TITLE: Querying Nodes Info API Endpoints in OpenSearch
DESCRIPTION: Examples of various endpoint structures for the Nodes Info API, including options to filter by node ID and specific metrics.

LANGUAGE: json
CODE:
GET /_nodes
GET /_nodes/<nodeId>
GET /_nodes/<metrics>
GET /_nodes/<nodeId>/<metrics>
# or full path equivalent
GET /_nodes/<nodeId>/info/<metrics>

----------------------------------------

TITLE: Performing Search Operations in OpenSearch Benchmark
DESCRIPTION: Example of a search operation with match_all query and custom request parameters.

LANGUAGE: yaml
CODE:
{
  "name": "default",
  "operation-type": "search",
  "body": {
    "query": {
      "match_all": {}
    }
  },
  "request-params": {
    "_source_include": "some_field",
    "analyze_wildcard": "false"
  }
}

----------------------------------------

TITLE: Sample Docker Compose File for Development
DESCRIPTION: A sample docker-compose.yml file that creates two OpenSearch nodes and one OpenSearch Dashboards node with the Security plugin disabled. This can be used as a starting point for development environments.

LANGUAGE: yaml
CODE:
services:
  opensearch-node1:
    image: opensearchproject/opensearch:latest
    container_name: opensearch-node1
    environment:
      - cluster.name=opensearch-cluster # Name the cluster
      - node.name=opensearch-node1 # Name the node that will run in this container
      - discovery.seed_hosts=opensearch-node1,opensearch-node2 # Nodes to look for when discovering the cluster
      - cluster.initial_cluster_manager_nodes=opensearch-node1,opensearch-node2 # Nodes eligibile to serve as cluster manager
      - bootstrap.memory_lock=true # Disable JVM heap memory swapping
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m" # Set min and max JVM heap sizes to at least 50% of system RAM
      - "DISABLE_INSTALL_DEMO_CONFIG=true" # Prevents execution of bundled demo script which installs demo certificates and security configurations to OpenSearch
      - "DISABLE_SECURITY_PLUGIN=true" # Disables Security plugin
    ulimits:
      memlock:
        soft: -1 # Set memlock to unlimited (no soft or hard limit)
        hard: -1
      nofile:
        soft: 65536 # Maximum number of open files for the opensearch user - set to at least 65536
        hard: 65536
    volumes:
      - opensearch-data1:/usr/share/opensearch/data # Creates volume called opensearch-data1 and mounts it to the container
    ports:
      - 9200:9200 # REST API
      - 9600:9600 # Performance Analyzer
    networks:
      - opensearch-net # All of the containers will join the same Docker bridge network
  opensearch-node2:
    image: opensearchproject/opensearch:latest
    container_name: opensearch-node2
    environment:
      - cluster.name=opensearch-cluster # Name the cluster
      - node.name=opensearch-node2 # Name the node that will run in this container
      - discovery.seed_hosts=opensearch-node1,opensearch-node2 # Nodes to look for when discovering the cluster
      - cluster.initial_cluster_manager_nodes=opensearch-node1,opensearch-node2 # Nodes eligibile to serve as cluster manager
      - bootstrap.memory_lock=true # Disable JVM heap memory swapping
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m" # Set min and max JVM heap sizes to at least 50% of system RAM
      - "DISABLE_INSTALL_DEMO_CONFIG=true" # Prevents execution of bundled demo script which installs demo certificates and security configurations to OpenSearch
      - "DISABLE_SECURITY_PLUGIN=true" # Disables Security plugin
    ulimits:
      memlock:
        soft: -1 # Set memlock to unlimited (no soft or hard limit)
        hard: -1
      nofile:
        soft: 65536 # Maximum number of open files for the opensearch user - set to at least 65536
        hard: 65536
    volumes:
      - opensearch-data2:/usr/share/opensearch/data # Creates volume called opensearch-data2 and mounts it to the container
    networks:
      - opensearch-net # All of the containers will join the same Docker bridge network
  opensearch-dashboards:
    image: opensearchproject/opensearch-dashboards:latest
    container_name: opensearch-dashboards
    ports:
      - 5601:5601 # Map host port 5601 to container port 5601
    expose:
      - "5601" # Expose port 5601 for web access to OpenSearch Dashboards
    environment:
      - 'OPENSEARCH_HOSTS=["http://opensearch-node1:9200","http://opensearch-node2:9200"]'
      - "DISABLE_SECURITY_DASHBOARDS_PLUGIN=true" # disables security dashboards plugin in OpenSearch Dashboards
    networks:
      - opensearch-net

volumes:
  opensearch-data1:
  opensearch-data2:

networks:
  opensearch-net:

----------------------------------------

TITLE: Indexing Geopoint as WKT Point
DESCRIPTION: Shows how to index a geopoint using Well-Known Text (WKT) POINT format.

LANGUAGE: json
CODE:
PUT testindex1/_doc/5
{
  "point": "POINT (74.00 40.71)"
}

----------------------------------------

TITLE: Retrieving Processed Document
DESCRIPTION: Query to retrieve the document after processing with the foreach pipeline.

LANGUAGE: json
CODE:
GET testindex1/_doc/1

----------------------------------------

TITLE: Creating Ingest Pipeline with Multiple Processors in OpenSearch
DESCRIPTION: Example of creating an ingest pipeline named 'my-pipeline' with two set processors and an uppercase processor. This pipeline processes student data, setting graduation year, graduation status, and converting the name to uppercase.

LANGUAGE: json
CODE:
PUT _ingest/pipeline/my-pipeline
{
  "description": "This pipeline processes student data",
  "processors": [
    {
      "set": {
        "description": "Sets the graduation year to 2023",
        "field": "grad_year",
        "value": 2023
      }
    },
    {
      "set": {
        "description": "Sets graduated to true",
        "field": "graduated",
        "value": true
      }
    },
    {
      "uppercase": {
        "field": "name"
      }
    }
  ]
}

----------------------------------------

TITLE: Node Stats API Endpoints
DESCRIPTION: Available endpoints for retrieving node statistics, supporting optional node ID, metric and index metric filters.

LANGUAGE: json
CODE:
GET /_nodes/stats
GET /_nodes/<node_id>/stats
GET /_nodes/stats/<metric>
GET /_nodes/<node_id>/stats/<metric>
GET /_nodes/stats/<metric>/<index_metric>
GET /_nodes/<node_id>/stats/<metric>/<index_metric>

----------------------------------------

TITLE: Querying Cluster Nodes via cURL
DESCRIPTION: cURL command to list all nodes in the OpenSearch cluster.

LANGUAGE: bash
CODE:
curl -XGET https://<private-ip>:9200/_cat/nodes?v -u 'admin:<custom-admin-password>' --insecure

----------------------------------------

TITLE: Get Zone Weights Response
DESCRIPTION: Example response showing the current weights configured for each zone in the cluster.

LANGUAGE: json
CODE:
{
      "weights":
      {
      
        "zone_1": "1.0", 
        "zone_2": "1.0", 
        "zone_3": "0.0"
      },
      "_version":1
}

----------------------------------------

TITLE: Defining VPC Flow Log Mappings in JSON for OpenSearch
DESCRIPTION: This JSON snippet defines mappings for VPC Flow log fields to ECS and OCSF schemas. It includes mappings for various network traffic attributes such as IP addresses, ports, protocols, and AWS-specific information like account IDs and regions. This mapping structure allows for standardized processing and analysis of VPC Flow log data in OpenSearch.

LANGUAGE: json
CODE:
"mappings": [
    {
      "raw_field":"version",
      "ecs":"netflow.version",
      "ocsf": "metadata.product.version"
    },
    {
      "raw_field":"account_id",
      "ecs":"netflow.account_id",
      "ocsf": "cloud.account_uid"
    },
    {
      "raw_field":"region",
      "ecs":"netflow.region",
      "ocsf": "cloud.region"
    },
    {
      "raw_field":"az_id",
      "ecs":"netflow.az_id",
      "ocsf": "cloud.zone"
    },
    {
      "raw_field":"srcport",
      "ecs":"netflow.srcport",
      "ocsf": "src_endpoint.port"
    },
    {
      "raw_field":"dstport",
      "ecs":"netflow.dstport",
      "ocsf": "dst_endpoint.port"
    },
    {
      "raw_field":"protocol",
      "ecs":"netflow.protocol",
      "ocsf": "connection_info.protocol_num"
    },
    {
      "raw_field":"packets",
      "ecs":"netflow.packets",
      "ocsf": "traffic.packets"
    },
    {
      "raw_field":"bytes",
      "ecs":"netflow.bytes",
      "ocsf": "traffic.bytes"
    },
    {
      "raw_field":"end",
      "ecs":"netflow.end",
      "ocsf": "end_time"
    },
    {
      "raw_field":"tcp_flags",
      "ecs":"netflow.tcp_flags",
      "ocsf": "connection_info.tcp_flags"
    },
    {
      "raw_field":"protocol_ver",
      "ecs":"netflow.protocol_ver",
      "ocsf": "connection_info.protocol_ver"
    },
    {
      "raw_field":"pkt_src_aws_service",
      "ecs":"netflow.pkt_src_aws_service",
      "ocsf": "src_endpoint.svc_name"
    },
    {
      "raw_field":"pkt_dst_aws_service",
      "ecs":"netflow.pkt_dst_aws_service",
      "ocsf": "dst_endpoint.svc_name"
    },
    {
      "raw_field":"log_status",
      "ecs":"netflow.log_status",
      "ocsf": "status_code"
    },
    {
      "raw_field":"action",
      "ecs":"netflow.action",
      "ocsf": "disposition_id"
    },
    {
      "raw_field":"traffic_path",
      "ecs":"netflow.traffic_path",
      "ocsf": "boundary_id"
    },
    {
      "raw_field":"flow_direction",
      "ecs":"netflow.flow_direction",
      "ocsf": "connection_info.direction_id"
    },
    {
      "raw_field":"dstaddr",
      "ecs":"netflow.dstaddr",
      "ocsf": "dst_endpoint.ip"
    },
    {
      "raw_field":"srcaddr",
      "ecs":"netflow.srcaddr",
      "ocsf": "src_endpoint.ip"
    },
    {
      "raw_field":"interface_id",
      "ecs":"netflow.interface_id",
      "ocsf": "dst_endpoint.interface_uid"
    },
    {
      "raw_field":"vpc_id",
      "ecs":"netflow.vpc_id",
      "ocsf": "dst_endpoint.vpc_uid"
    },
    {
      "raw_field":"instance_id",
      "ecs":"netflow.instance_id",
      "ocsf": "dst_endpoint.instance_uid"
    },
    {
      "raw_field":"subnet_id",
      "ecs":"netflow.subnet_id",
      "ocsf": "dst_endpoint.subnet_uid"
    },
    {
      "raw_field":"start",
      "ecs":"timestamp",
      "ocsf": "time"
    }
  ]

----------------------------------------

TITLE: Update by Query API Endpoint in OpenSearch
DESCRIPTION: The endpoint for the Update by Query API in OpenSearch. It allows updating documents in one or more indexes that match a specified query.

LANGUAGE: json
CODE:
POST <index1>, <index2>/_update_by_query

----------------------------------------

TITLE: Analyzing Text with N-gram Analyzer
DESCRIPTION: Example of using the analyze API to test the N-gram analyzer with sample text. Shows how to analyze the word 'Search' using the configured N-gram analyzer.

LANGUAGE: json
CODE:
POST /ngram_example_index/_analyze
{
  "analyzer": "ngram_analyzer",
  "text": "Search"
}

----------------------------------------

TITLE: Retrieving a Specific ML Commons Stat for All Nodes in OpenSearch
DESCRIPTION: This request retrieves a specified ML Commons statistic for all nodes in the OpenSearch cluster. Replace <stat> with the name of the desired statistic.

LANGUAGE: json
CODE:
GET /_plugins/_ml/stats/<stat>

----------------------------------------

TITLE: Formatting Model Output for Amazon Bedrock Titan Embedding
DESCRIPTION: Example of how to format the output from the Amazon Bedrock Titan embedding model using a post-processing function. This function transforms the Bedrock model output into the format expected by OpenSearch.

LANGUAGE: json
CODE:
"post_process_function": """
      def name = "sentence_embedding";
      def dataType = "FLOAT32";
      if (params.embedding == null || params.embedding.length == 0) {
        return params.message;
      }
      def shape = [params.embedding.length];
      def json = "{" +
                 "\"name\":\"" + name + "\"," +
                 "\"data_type\":\"" + dataType + "\"," +
                 "\"shape\":" + shape + "," +
                 "\"data\":" + params.embedding +
                 "}";
      return json;
    """

----------------------------------------

TITLE: Listing All Indexes in OpenSearch
DESCRIPTION: This HTTP GET request retrieves a list of all indexes in the OpenSearch cluster, including hidden indexes. It uses the _cat API for a verbose output.

LANGUAGE: http
CODE:
GET _cat/indices?v&expand_wildcards=all

----------------------------------------

TITLE: Creating Ingest Pipeline API Path in OpenSearch
DESCRIPTION: Demonstrates the HTTP method and path for creating an ingest pipeline in OpenSearch. The <pipeline-id> placeholder should be replaced with the actual pipeline ID.

LANGUAGE: json
CODE:
PUT _ingest/pipeline/<pipeline-id>

----------------------------------------

TITLE: Creating Message in OpenSearch Memory API - JSON
DESCRIPTION: Example request for creating a new message in a memory with input, prompt template, response, origin, and additional information.

LANGUAGE: json
CODE:
POST /_plugins/_ml/memory/SXA2cY0BfUsSoeNTz-8m/messages
{
    "input": "How do I make an interaction?",
    "prompt_template": "Hello OpenAI, can you answer this question?",
    "response": "Hello, this is OpenAI. Here is the answer to your question.",
    "origin": "MyFirstOpenAIWrapper",
    "additional_info": {
      "suggestion": "api.openai.com"
    }
}

----------------------------------------

TITLE: Sample Mutated Output Structure
DESCRIPTION: Shows the structure of output data after the mutate filter has processed it, demonstrating the conversion of the quantity field to an integer type.

LANGUAGE: yaml
CODE:
{
  "quantity" => 3,
  "host" => "127.0.0.1",
  "@timestamp" => 2021-05-23T19:02:08.026Z,
  "amount" => 10,
  "@version" => "1",
  "headers" => {
    "request_path" => "/",
    "connection" => "keep-alive",
    "content_length" => "41",
    "http_user_agent" => "PostmanRuntime/7.26.8",
    "request_method" => "PUT",
    "cache_control" => "no-cache",
    "http_accept" => "*/*",
    "content_type" => "application/json",
    "http_version" => "HTTP/1.1",
    "http_host" => "127.0.0.1:8080",
    "accept_encoding" => "gzip, deflate, br",
    "postman_token" => "ffd1cdcb-7a1d-4d63-90f8-0f2773069205"
   }
}

----------------------------------------

TITLE: Zone Decommission Status Response in OpenSearch JSON
DESCRIPTION: This JSON response shows the decommission status of a zone. The status can be one of INIT, DRAINING, IN_PROGRESS, SUCCESSFUL, or FAILED.

LANGUAGE: json
CODE:
{
     "zone-1": "INIT | DRAINING | IN_PROGRESS | SUCCESSFUL | FAILED"
}

----------------------------------------

TITLE: Document Retrieval Operations
DESCRIPTION: Examples of retrieving single and multiple documents, including field filtering and document existence checks.

LANGUAGE: json
CODE:
GET movies/_doc/1

LANGUAGE: json
CODE:
GET _mget
{
  "docs": [
    {
      "_index": "<index>",
      "_id": "<id>"
    },
    {
      "_index": "<index>",
      "_id": "<id>"
    }
  ]
}

LANGUAGE: json
CODE:
HEAD movies/_doc/<doc-id>

----------------------------------------

TITLE: Field Inclusion Example - JSON Response
DESCRIPTION: Example JSON response showing included fields (actors, title, year) when field-level security is configured with field inclusion.

LANGUAGE: json
CODE:
{
  "_index": "movies",
  "_source": {
    "year": 2013,
    "title": "Rush",
    "actors": [
      "Daniel Brhl",
      "Chris Hemsworth",
      "Olivia Wilde"
    ]
  }
}

----------------------------------------

TITLE: Example Neural Sparse Query by Sparse Vector in OpenSearch
DESCRIPTION: This example shows a complete search request using the neural_sparse query with pre-computed sparse vector tokens. It includes the index to search and a map of token-score pairs representing the query.

LANGUAGE: json
CODE:
GET my-nlp-index/_search
{
  "query": {
    "neural_sparse": {
      "passage_embedding": {
        "query_tokens": {
          "hi" : 4.338913,
          "planets" : 2.7755864,
          "planet" : 5.0969057,
          "mars" : 1.7405145,
          "earth" : 2.6087382,
          "hello" : 3.3210192
        }
      }
    }
  }
}

----------------------------------------

TITLE: Querying Data Node Statistics in OpenSearch
DESCRIPTION: Shows how to get statistics from data-only nodes in the cluster using the Nodes API.

LANGUAGE: json
CODE:
GET /_nodes/data:true/stats

----------------------------------------

TITLE: Using Path Parameter in Dot Expander Processor
DESCRIPTION: Example of using the path parameter to specify the path to a dotted field within an object in the dot_expander processor.

LANGUAGE: json
CODE:
PUT /_ingest/pipeline/dot-expander-pipeline
{
  "description": "Dot expander processor",
  "processors": [
    {
      "dot_expander": {
        "field": "address.city",
        "path": "user"
      }
    },
    {
      "dot_expander":{
       "field": "address.state",
       "path": "user"
      }
    }
  ]
}

----------------------------------------

TITLE: Retrieving Index Template Information in OpenSearch
DESCRIPTION: This snippet shows various ways to retrieve information about index templates, including listing all templates, finding a specific template by name, and checking if a template exists.

LANGUAGE: json
CODE:
GET _cat/templates
GET /_index_template
GET _index_template/daily_logs
GET _index_template/daily*
HEAD _index_template/<name>

----------------------------------------

TITLE: Single Document Explain Query
DESCRIPTION: Example request demonstrating how to get explanation for a specific document's score using its ID.

LANGUAGE: json
CODE:
POST opensearch_dashboards_sample_data_ecommerce/_explain/EVz1Q3sBgg5eWQP6RSte\n{\n  "query": {\n    "match": {\n      "customer_first_name": "Mary"\n    }\n  }\n}

----------------------------------------

TITLE: Function Score Query with Term Frequency
DESCRIPTION: Example of a function score query that uses term frequency from the delimited token filter to calculate document scores.

LANGUAGE: json
CODE:
{
  "query": {
    "function_score": {
      "query": {
        "match_all": {}
      },
      "script_score": {
        "script": {
          "source": "termFreq(params.field, params.term)",
          "params": {
            "field": "f2",
            "term": "v1"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Profile API endpoints in OpenSearch ML Commons
DESCRIPTION: This snippet lists the available endpoints for the Profile API in OpenSearch ML Commons. These endpoints allow querying profile information for models and tasks.

LANGUAGE: json
CODE:
GET /_plugins/_ml/profile
GET /_plugins/_ml/profile/models
GET /_plugins/_ml/profile/models/<model_id>
GET /_plugins/_ml/profile/tasks
GET /_plugins/_ml/profile/tasks/<task_id>

----------------------------------------

TITLE: Creating an Index with Snowball Filter in OpenSearch
DESCRIPTION: This example demonstrates how to create a new index named 'my-snowball-index' with a custom analyzer that includes a Snowball filter. The analyzer uses the standard tokenizer, lowercase filter, and a custom Snowball filter for English language stemming.

LANGUAGE: json
CODE:
PUT /my-snowball-index
{
  "settings": {
    "analysis": {
      "filter": {
        "my_snowball_filter": {
          "type": "snowball",
          "language": "English"
        }
      },
      "analyzer": {
        "my_snowball_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "my_snowball_filter"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring HTTP Basic Authentication for IP Rate Limiting
DESCRIPTION: Configuration for HTTP basic authentication required for IP-based rate limiting. Sets the challenge parameter to false in the http_authenticator section.

LANGUAGE: yml
CODE:
http_authenticator:
  type: basic
  challenge: false

----------------------------------------

TITLE: Local Model Pipeline Configuration
DESCRIPTION: Example configuration for using a local text embedding model in a search pipeline.

LANGUAGE: json
CODE:
PUT /_search/pipeline/ml_inference_pipeline_local
{
  "description": "search passage and generates embeddings",
  "processors": [
    {
      "ml_inference": {
        "function_name": "text_embedding",
        "full_response_path": true,
        "model_id": "<your model id>",
        "model_config": {
          "return_number": true,
          "target_response": ["sentence_embedding"]
        },
        "model_input": "{ \"text_docs\": ${input_map.text_docs}, \"return_number\": ${model_config.return_number}, \"target_response\": ${model_config.target_response} }",
        "input_map": [
          {
            "text_docs": "passage_text"
          }
        ],
        "output_map": [
          {
            "passage_embedding": "$.inference_results.*.output.*.data"
          }
        ],
        "ignore_missing": true,
        "ignore_failure": true
      }
    }
  ]
}

----------------------------------------

TITLE: Creating an Index with N-gram Tokenizer in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a new index named 'my_index' with a custom N-gram tokenizer and analyzer. The tokenizer is configured to generate N-grams of length 3 to 4, including only letters and digits.

LANGUAGE: json
CODE:
PUT /my_index
{
  "settings": {
    "analysis": {
      "tokenizer": {
        "my_ngram_tokenizer": {
          "type": "ngram",
          "min_gram": 3,
          "max_gram": 4,
          "token_chars": ["letter", "digit"]
        }
      },
      "analyzer": {
        "my_ngram_analyzer": {
          "type": "custom",
          "tokenizer": "my_ngram_tokenizer"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Installing OpenSearch Dashboards Debian Package
DESCRIPTION: Commands to install the OpenSearch Dashboards Debian package using dpkg, enable the service, and start it.

LANGUAGE: bash
CODE:
sudo dpkg -i opensearch-dashboards-{{site.opensearch_version}}-linux-x64.deb
sudo systemctl daemon-reload
sudo systemctl enable opensearch-dashboards
sudo systemctl start opensearch-dashboards
sudo systemctl status opensearch-dashboards

----------------------------------------

TITLE: Creating Index Mappings and Settings
DESCRIPTION: Example of creating index mappings and settings in the index.json file for a custom workload.

LANGUAGE: json
CODE:
{
    "settings": {
        "index.number_of_replicas": 0
    },
    "mappings": {
        "dynamic": "strict",
        "properties": {
        "title": {
            "type": "text"
        },
        "director": {
            "type": "text"
        },
        "revenue": {
            "type": "text"
        },
        "rating": {
            "type": "text"
        },
        "image_url": {
            "type": "text"
        }
        }
    }
    }

----------------------------------------

TITLE: Example Response from OpenSearch Segment API
DESCRIPTION: This JSON snippet shows a sample response from the Segment API, including information about shards, segments, and their properties such as document count, size, and memory usage.

LANGUAGE: json
CODE:
{
  "_shards": ...
  "indices": {
    "test": {
      "shards": {
        "0": [
          {
            "routing": {
              "state": "STARTED",
              "primary": true,
              "node": "zDC_RorJQCao9xf9pg3Fvw"
            },
            "num_committed_segments": 0,
            "num_search_segments": 1,
            "segments": {
              "_0": {
                "generation": 0,
                "num_docs": 1,
                "deleted_docs": 0,
                "size_in_bytes": 3800,
                "memory_in_bytes": 1410,
                "committed": false,
                "search": true,
                "version": "7.0.0",
                "compound": true,
                "attributes": {
                }
              }
            }
          }
        ]
      }
    }
  }
}

----------------------------------------

TITLE: Creating Index with Ignored Fields in OpenSearch
DESCRIPTION: This example shows how to create an index with ignore_malformed set to true, index a document with malformed data, and then search for documents with ignored fields.

LANGUAGE: json
CODE:
PUT test-ignored
{
  "mappings": {
    "properties": {
      "title": {
        "type": "text"
      },
      "length": {
        "type": "long",
        "ignore_malformed": true
      }
    }
  }
}

POST test-ignored/_doc
{
  "title": "correct text",
  "length": "not a number"
}

GET test-ignored/_search
{
  "query": {
    "exists": {
      "field": "_ignored"
    }
  }
}

----------------------------------------

TITLE: Indexing Sample Documents with Bulk API in OpenSearch
DESCRIPTION: This snippet demonstrates how to index sample documents using the OpenSearch Bulk API. It creates four documents in the 'accounts' index with various fields such as account number, balance, name, age, and address.

LANGUAGE: json
CODE:
PUT accounts/_bulk?refresh
{"index":{"_id":"1"}}
{"account_number":1,"balance":39225,"firstname":"Amber","lastname":"Duke","age":32,"gender":"M","address":"880 Holmes Lane","employer":"Pyrami","email":"amberduke@pyrami.com","city":"Brogan","state":"IL"}
{"index":{"_id":"6"}}
{"account_number":6,"balance":5686,"firstname":"Hattie","lastname":"Bond","age":36,"gender":"M","address":"671 Bristol Street","employer":"Netagy","email":"hattiebond@netagy.com","city":"Dante","state":"TN"}
{"index":{"_id":"13"}}
{"account_number":13,"balance":32838,"firstname":"Nanette","lastname":"Bates","age":28,"gender":"F","address":"789 Madison Street","employer":"Quility","email":"nanettebates@quility.com","city":"Nogal","state":"VA"}
{"index":{"_id":"18"}}
{"account_number":18,"balance":4180,"firstname":"Dale","lastname":"Adams","age":33,"gender":"M","address":"467 Hutchinson Court","email":"daleadams@boink.com","city":"Orick","state":"MD"}

----------------------------------------

TITLE: Troubleshooting Log Access Commands
DESCRIPTION: Commands for accessing and analyzing metadata migration logs.

LANGUAGE: shell
CODE:
ls -al /shared-logs-output/migration-console-default/*/metadata/

LANGUAGE: shell
CODE:
tail /shared-logs-output/migration-console-default/*/metadata/*.log

----------------------------------------

TITLE: Bitmap Filtering Query in OpenSearch
DESCRIPTION: Demonstrates how to use bitmap filtering in a terms query for efficient large-scale filtering.

LANGUAGE: json
CODE:
POST /products/_search
{
  "query": {
    "terms": {
      "product_id": {
        "index": "customers",
        "id": "customer123",
        "path": "customer_filter",
        "store": true               
      },
      "value_type": "bitmap"      
    }
  }
}

----------------------------------------

TITLE: Creating Index with knn_vector and Keyword Fields in OpenSearch
DESCRIPTION: This code creates an OpenSearch index with a knn_vector field for vector data and a keyword field for filtering. It's used to demonstrate pre-filtering in k-NN search.

LANGUAGE: json
CODE:
PUT my-knn-index-2
{
  "mappings": {
    "properties": {
      "my_vector": {
        "type": "knn_vector",
        "dimension": 2
      },
      "color": {
        "type": "keyword"
      }
    }
  }
}

----------------------------------------

TITLE: Executing Terms Query in OpenSearch
DESCRIPTION: Demonstrates how to use the terms query to search for multiple terms in the 'line_id' field of the 'shakespeare' index.

LANGUAGE: json
CODE:
GET shakespeare/_search
{
  "query": {
    "terms": {
      "line_id": [
        "61809",
        "61810"
      ]
    }
  }
}

----------------------------------------

TITLE: Delete Index Example Response
DESCRIPTION: The expected JSON response format when an index is successfully deleted.

LANGUAGE: json
CODE:
{
  "acknowledged": true
}

----------------------------------------

TITLE: Creating Index with Stemmer Override Filter
DESCRIPTION: Example request that creates a new index with a custom analyzer using stemmer_override filter. The filter includes custom stemming rules for words like 'running', 'bought', and 'best'.

LANGUAGE: json
CODE:
PUT /my-index
{
  "settings": {
    "analysis": {
      "filter": {
        "my_stemmer_override_filter": {
          "type": "stemmer_override",
          "rules": [
            "running, runner => run",
            "bought => buy",
            "best => good"
          ]
        }
      },
      "analyzer": {
        "my_custom_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "my_stemmer_override_filter"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Complete Logstash Pipeline Configuration
DESCRIPTION: Full pipeline configuration including input from stdin and output to OpenSearch. Accepts JSON input and ships to local OpenSearch cluster.

LANGUAGE: yaml
CODE:
input {
  stdin {
    codec => json
  }
}

output {
  opensearch {
    hosts       => "https://localhost:9200"
    user        => "admin"
    password    => "admin"
    index       => "logstash-logs-%{+YYYY.MM.dd}"
    ssl_certificate_verification => false
  }
}

----------------------------------------

TITLE: Count API Endpoints
DESCRIPTION: The basic endpoint structure for the Count API in OpenSearch, supporting both GET and POST methods.

LANGUAGE: json
CODE:
GET <target>/_count/<id>\nPOST <target>/_count/<id>

----------------------------------------

TITLE: Connecting to Amazon OpenSearch Serverless
DESCRIPTION: Create an OpenSearch client to connect to Amazon OpenSearch Serverless Service. This configuration uses AWSV4SignerAuth for authentication with the 'aoss' service.

LANGUAGE: python
CODE:
from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth
import boto3

host = '' # cluster endpoint, for example: my-test-domain.us-east-1.aoss.amazonaws.com
region = 'us-west-2'
service = 'aoss'
credentials = boto3.Session().get_credentials()
auth = AWSV4SignerAuth(credentials, region, service)

client = OpenSearch(
    hosts = [{'host': host, 'port': 443}],
    http_auth = auth,
    use_ssl = True,
    verify_certs = True,
    connection_class = RequestsHttpConnection,
    pool_maxsize = 20
)

----------------------------------------

TITLE: Executing CAT Allocation Query with Verbose Output
DESCRIPTION: This example demonstrates how to query the CAT allocation API with verbose output enabled.

LANGUAGE: json
CODE:
GET _cat/allocation?v

----------------------------------------

TITLE: Basic query_string query
DESCRIPTION: A simple query_string query searching for documents containing 'the wind' and either 'rises' or 'rising'.

LANGUAGE: json
CODE:
GET _search
{
  "query": {
    "query_string": {
      "query": "the wind AND (rises OR rising)"
    }
  }
}

----------------------------------------

TITLE: Connecting to OpenSearch with SSL/TLS
DESCRIPTION: Create an OpenSearch client object with SSL/TLS enabled, using default credentials for testing purposes. This snippet demonstrates how to configure the connection with various SSL options.

LANGUAGE: python
CODE:
host = 'localhost'
port = 9200
auth = ('admin', 'admin') # For testing only. Don't store credentials in code.
ca_certs_path = '/full/path/to/root-ca.pem' # Provide a CA bundle if you use intermediate CAs with your root CA.

# Create the client with SSL/TLS enabled, but hostname verification disabled.
client = OpenSearch(
    hosts = [{'host': host, 'port': port}],
    http_compress = True, # enables gzip compression for request bodies
    http_auth = auth,
    use_ssl = True,
    verify_certs = True,
    ssl_assert_hostname = False,
    ssl_show_warn = False,
    ca_certs = ca_certs_path
)

----------------------------------------

TITLE: Indexing Geopoint as GeoJSON
DESCRIPTION: Demonstrates indexing a geopoint using GeoJSON Point format with coordinates array.

LANGUAGE: json
CODE:
PUT testindex1/_doc/6
{
  "point": {
    "type": "Point",
    "coordinates": [74.00, 40.71]
  }
}

----------------------------------------

TITLE: Example Request for Opening an Index in OpenSearch
DESCRIPTION: This example shows how to open a specific index named 'sample-index' using the Open Index API in OpenSearch.

LANGUAGE: json
CODE:
POST /sample-index/_open

----------------------------------------

TITLE: Creating an Index with N-gram Tokenizer in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a new index named 'my_index' with a custom N-gram tokenizer and analyzer. The tokenizer is configured to generate N-grams of length 3 to 4, including only letters and digits.

LANGUAGE: json
CODE:
PUT /my_index
{
  "settings": {
    "analysis": {
      "tokenizer": {
        "my_ngram_tokenizer": {
          "type": "ngram",
          "min_gram": 3,
          "max_gram": 4,
          "token_chars": ["letter", "digit"]
        }
      },
      "analyzer": {
        "my_ngram_analyzer": {
          "type": "custom",
          "tokenizer": "my_ngram_tokenizer"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Enabling Backend Role Filtering for Alerting
DESCRIPTION: JSON configuration to enable filtering of alerting resources by backend roles at the cluster level. This setting restricts users to only see monitors and destinations created by users who share at least one backend role.

LANGUAGE: json
CODE:
{
  "transient": {
    "plugins.alerting.filter_by_backend_roles": "true"
  }
}

----------------------------------------

TITLE: Using LIMIT with Offset in OpenSearch SQL
DESCRIPTION: Example of using the LIMIT clause with both offset and size parameters for simple pagination in OpenSearch SQL.

LANGUAGE: sql
CODE:
SELECT account_number
FROM accounts
ORDER BY account_number LIMIT 1, 1

----------------------------------------

TITLE: Mapping AWS CloudTrail Fields to ECS and OCSF in JSON
DESCRIPTION: This JSON snippet defines mappings between raw AWS CloudTrail fields and their corresponding ECS (Elastic Common Schema) and OCSF (Open Cybersecurity Schema Framework) fields. It covers a wide range of CloudTrail event attributes, including event details, user identity, and resource information.

LANGUAGE: json
CODE:
  "mappings": [
    {
      "raw_field":"eventName",
      "ecs":"aws.cloudtrail.event_name",
      "ocsf": "api.operation"
    },
    {
      "raw_field":"eventSource",
      "ecs":"aws.cloudtrail.event_source",
      "ocsf": "api.service.name"
    },
    {
      "raw_field":"eventVersion",
      "ecs":"aws.cloudtrail.event_version",
      "ocsf": "metadata.product.version"
    },
    {
      "raw_field":"eventID",
      "ecs":"aws.cloudtrail.event_id",
      "ocsf": "metadata.uid"
    },
    {
      "raw_field":"eventType",
      "ecs":"aws.cloudtrail.event_type",
      "ocsf": "unmapped.eventType"
    },
    {
      "raw_field":"eventCategory",
      "ecs":"aws.cloudtrail.event_category",
      "ocsf": "metadata.product.feature.name"
    },
    {
      "raw_field":"errorMessage",
      "ecs":"aws.cloudtrail.error_message",
      "ocsf": "api.response.message"
    },
    {
      "raw_field":"errorCode",
      "ecs":"aws.cloudtrail.error_code",
      "ocsf": "api.response.error"
    },
    {
      "raw_field":"apiVersion",
      "ecs":"aws.cloudtrail.api_version",
      "ocsf": "api.version"
    },
    {
      "raw_field":"awsRegion",
      "ecs":"aws.cloudtrail.aws_region",
      "ocsf": "cloud.region"
    },
    {
      "raw_field":"additionalEventData.LoginTo",
      "ecs":"aws.cloudtrail.additional_event_data.loginTo",
      "ocsf": "dst_endpoint.svc_name"
    },
    {
      "raw_field":"additionalEventData.MFAUsed",
      "ecs":"aws.cloudtrail.additional_event_data.mfaUsed",
      "ocsf": "mfa"
    },
    {
      "raw_field":"responseElements",
      "ecs":"aws.cloudtrail.response_elements.text",
      "ocsf": "unmapped.responseElements"
    },
    {
      "raw_field":"requestID",
      "ecs":"aws.cloudtrail.request_id",
      "ocsf": "api.request.uid"
    },
    {
      "raw_field":"sourceIPAddress",
      "ecs":"aws.cloudtrail.source_ip_address",
      "ocsf": "src_endpoint.ip"
    },
    {
      "raw_field":"userAgent",
      "ecs":"aws.cloudtrail.user_agent",
      "ocsf": "http_request.user_agent"
    },
    {
      "raw_field":"vpcEndpointId",
      "ecs":"aws.cloudtrail.vpc_endpoint_id",
      "ocsf": "src_endpoint.uid"
    },
    {
      "raw_field":"responseElements.pendingModifiedValues.masterUserPassword",
      "ecs":"aws.cloudtrail.response_elements.pending_modified_values.master_user_password",
      "ocsf": "unmapped.responseElements.pendingModifiedValues.masterUserPassword"
    },
    {
      "raw_field":"responseElements.publiclyAccessible",
      "ecs":"aws.cloudtrail.response_elements.publicly_accessible",
      "ocsf": "unmapped.responseElements.publiclyAccessible"
    },
    {
      "raw_field":"responseElements.ConsoleLogin",
      "ecs":"aws.cloudtrail.response_elements.publicly_accessible",
      "ocsf": "status_id"
    },
    {
      "raw_field":"requestParameters.arn",
      "ecs":"aws.cloudtrail.request_parameters.arn",
      "ocsf": "unmapped.requestParameters.arn"
    },
    {
      "raw_field":"requestParameters.attribute",
      "ecs":"aws.cloudtrail.request_parameters.attribute",
      "ocsf": "unmapped.requestParameters.attribute"
    },
    {
      "raw_field":"requestParameters.userName",
      "ecs":"aws.cloudtrail.request_parameters.username",
      "ocsf": "unmapped.requestParameters.userName"
    },
    {
      "raw_field":"requestParameters.roleArn",
      "ecs":"aws.cloudtrail.request_parameters.roleArn",
      "ocsf": "user.uuid"
    },
    {
      "raw_field":"requestParameters.roleSessionName",
      "ecs":"aws.cloudtrail.request_parameters.roleSessionName",
      "ocsf": "user.name"
    },
    {
      "raw_field":"requestParameters.containerDefinitions.command",
      "ecs":"aws.cloudtrail.request_parameters.container_definitions.command",
      "ocsf": "unmapped.requestParameters.containerDefinitions.command"
    },
    {
      "raw_field":"userIdentity.type",
      "ecs":"aws.cloudtrail.user_identity.type",
      "ocsf": "actor.user.type"
    },
    {
      "raw_field":"userIdentity.principalId",
      "ecs":"aws.cloudtrail.user_identity.principalId",
      "ocsf": "actor.user.uid"
    },
    {
      "raw_field":"userIdentity.arn",
      "ecs":"aws.cloudtrail.user_identity.arn",
      "ocsf": "actor.user.uuid"
    },
    {
      "raw_field":"userIdentity.accountId",
      "ecs":"aws.cloudtrail.user_identity.accountId",
      "ocsf": "actor.user.account_uid"
    },
    {
      "raw_field":"userIdentity.accessKeyId",
      "ecs":"aws.cloudtrail.user_identity.accessKeyId",
      "ocsf": "actor.user.credential_uid"
    },
    {
      "raw_field":"userIdentity.identityProvider",
      "ecs":"aws.cloudtrail.user_identity.identityProvider",
      "ocsf": "actor.idp.name"
    },
    {
      "raw_field":"userIdentity.userName",
      "ecs":"aws.cloudtrail.user_identity.userName",
      "ocsf": "actor.user.name"
    },
    {
      "raw_field":"userIdentity.invokedBy",
      "ecs":"aws.cloudtrail.user_identity.invokedBy",
      "ocsf": "actor.invoked_by"
    },
    {
      "raw_field":"userIdentity.sessionContext.sessionIssuer.type",
      "ecs":"aws.cloudtrail.user_identity.session_context.session_issuer.type",
      "ocsf": "unmapped.userIdentity.sessionContext.sessionIssuer.type"
    },
    {
      "raw_field":"userIdentity.sessionContext.sessionIssuer.arn",
      "ecs":"aws.cloudtrail.user_identity.session_context.session_issuer.arn",
      "ocsf": "actor.session.issuer"
    },
    {
      "raw_field":"userIdentity.sessionContext.attributes.creationDate",
      "ecs":"aws.cloudtrail.user_identity.session_context.attributes.creationDate",
      "ocsf": "actor.session.created_time"
    },
    {
      "raw_field":"userIdentity.sessionContext.attributes.mfaAuthenticated",
      "ecs":"aws.cloudtrail.user_identity.session_context.attributes.mfaAuthenticated",
      "ocsf": "actor.session.mfa"
    },
    {
      "raw_field":"userIdentity.webIdFederationData.federatedProvider",
      "ecs":"aws.cloudtrail.user_identity.web_id_federation_data.federatedProvider",
      "ocsf": "actor.idp.name"
    },
    {
      "raw_field":"resources[].ARN",
      "ecs":"aws.cloudtrail.resources.ARN",
      "ocsf": "resources[].uid"
    },
    {
      "raw_field":"resources[].accountId",
      "ecs":"aws.cloudtrail.resources.account_uid",
      "ocsf": "resources[].account_uid"
    },
    {
      "raw_field":"resources[].type",
      "ecs":"aws.cloudtrail.resources.type",
      "ocsf": "resources[].type"
    },
    {
      "raw_field":"eventTime",
      "ecs":"timestamp",
      "ocsf": "time"
    }
  ]

----------------------------------------

TITLE: Delete by Query Request Body
DESCRIPTION: Example request body showing how to specify a query to match documents for deletion. This example matches documents where the movie-length field equals 124.

LANGUAGE: json
CODE:
{
  "query": {
    "match": {
      "movie-length": "124"
    }
  }
}

----------------------------------------

TITLE: Example GET Request for ML Commons Controller in OpenSearch
DESCRIPTION: Example of a GET request to retrieve controller information for a specific model ID in OpenSearch ML Commons.

LANGUAGE: json
CODE:
GET /_plugins/_ml/controllers/T_S-cY0BKCJ3ot9qr0aP

----------------------------------------

TITLE: Updating Model Guardrails with Model-based Guardrails in OpenSearch
DESCRIPTION: Example request to update the guardrails for a model using another model for both input and output guardrails.

LANGUAGE: json
CODE:
PUT /_plugins/_ml/models/9uGdCJABjaMXYrp14YRj
{
  "guardrails": {
    "type": "model",
    "input_guardrail": {
      "model_id": "V-G1CJABjaMXYrp1QoUC",
      "response_validation_regex": "^\\s*[Aa]ccept\\s*$"
    },
    "output_guardrail": {
      "model_id": "V-G1CJABjaMXYrp1QoUC",
      "response_validation_regex": "^\\s*[Aa]ccept\\s*$"
    }
  }
}

----------------------------------------

TITLE: Creating OpenAI Connector with Python
DESCRIPTION: Python script to create an OpenAI connector using AWS authentication and configuration.

LANGUAGE: python
CODE:
import boto3
import requests 
from requests_aws4auth import AWS4Auth

host = 'your_amazon_opensearch_domain_endpoint_created'
region = 'your_amazon_opensearch_domain_region'
service = 'es'

credentials = boto3.Session().get_credentials()
awsauth = AWS4Auth(credentials.access_key, credentials.secret_key, region, service, session_token=credentials.token)

path = '/_plugins/_ml/connectors/_create'
url = host + path

payload = {
  "name": "OpenAI embedding model connector",
  "description": "Connector for OpenAI embedding model",
  "version": "1.0",
  "protocol": "http",
  "credential": {
    "secretArn": "your_secret_arn_created_in_step1",
    "roleArn": "your_iam_role_arn_created_in_step2"
  },
  "parameters": {
    "model": "text-embedding-ada-002"
  },
  "actions": [
    {
      "action_type": "predict",
      "method": "POST",
      "url": "https://api.openai.com/v1/embeddings",
      "headers": {
        "Authorization": "Bearer ${credential.secretArn.my_openai_key}"
      },
      "request_body": "{ \"input\": ${parameters.input}, \"model\": \"${parameters.model}\" }",
      "pre_process_function": "connector.pre_process.openai.embedding",
      "post_process_function": "connector.post_process.openai.embedding"
    }
  ]
}

headers = {"Content-Type": "application/json"}

r = requests.post(url, auth=awsauth, json=payload, headers=headers)
print(r.text)

----------------------------------------

TITLE: XGBoost Model Upload with Parameters
DESCRIPTION: Example of uploading an XGBoost model with additional parameters like objective function.

LANGUAGE: json
CODE:
{
    "model": {
        "name": "my_xgboost_model",
        "model": {
            "type": "model/xgboost+json",
            "definition": "{ \"objective\": \"reg:logistic\", \"splits\": [  { \"nodeid\": 0, \"depth\": 0, \"split\": \"tmdb_multi\", \"split_condition\": 11.2009, \"yes\": 1, \"no\": 2, \"missing\": 1, \"children\": [ { \"nodeid\": 1, \"depth\": 1, \"split\": \"tmdb_title\", \"split_condition\": 2.20631, \"yes\": 3, \"no\": 4, \"missing\": 3, \"children\": [ { \"nodeid\": 3, \"leaf\": -0.03125 }, ...] }"
        }
    }
}

----------------------------------------

TITLE: Deleting Specific Search Pipeline in OpenSearch (JSON)
DESCRIPTION: This code snippet demonstrates how to delete a specific search pipeline in OpenSearch by providing its ID. The request uses the DELETE HTTP method and targets the /_search/pipeline endpoint.

LANGUAGE: json
CODE:
DELETE /_search/pipeline/<pipeline-id>

----------------------------------------

TITLE: API Endpoint - Register Agent
DESCRIPTION: The base endpoint for registering an agent in OpenSearch ML Commons.

LANGUAGE: json
CODE:
POST /_plugins/_ml/agents/_register

----------------------------------------

TITLE: Sample Response from Get Index API in OpenSearch
DESCRIPTION: This snippet illustrates a typical response from the Get Index API. It includes information about the index's aliases, mappings, and settings, such as creation date, number of shards and replicas, UUID, and version details.

LANGUAGE: json
CODE:
{
  "sample-index1": {
    "aliases": {},
    "mappings": {},
    "settings": {
      "index": {
        "creation_date": "1633044652108",
        "number_of_shards": "2",
        "number_of_replicas": "1",
        "uuid": "XcXA0aZ5S0aiqx3i1Ce95w",
        "version": {
          "created": "135217827"
        },
        "provided_name": "sample-index1"
      }
    }
  }
}

----------------------------------------

TITLE: do_not_fail_on_forbidden Configuration
DESCRIPTION: Example of configuring the do_not_fail_on_forbidden option in config.yml.

LANGUAGE: yaml
CODE:
_meta:
  type: "config"
  config_version: 2
config:
  dynamic:
    http:
      anonymous_auth_enabled: false
      xff:
        enabled: false
        internalProxies: "192\\.168\\.0\\.10|192\\.168\\.0\\.11"
    do_not_fail_on_forbidden: true
    authc:
      basic_internal_auth_domain:
      ...

----------------------------------------

TITLE: Creating Index with Min Hash Filter in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a new index named 'minhash_index' with a custom analyzer that includes the min_hash filter. It configures various parameters of the filter such as hash_count, bucket_count, hash_set_size, and with_rotation.

LANGUAGE: json
CODE:
PUT /minhash_index
{
  "settings": {
    "analysis": {
      "filter": {
        "minhash_filter": {
          "type": "min_hash",
          "hash_count": 3,
          "bucket_count": 512,
          "hash_set_size": 1,
          "with_rotation": false
        }
      },
      "analyzer": {
        "minhash_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "minhash_filter"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Applying Latvian Analyzer to Text Field in OpenSearch
DESCRIPTION: This snippet demonstrates how to apply the built-in Latvian analyzer to a text field when creating an index in OpenSearch.

LANGUAGE: json
CODE:
PUT /latvian-index
{
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "latvian"
      }
    }
  }
}

----------------------------------------

TITLE: Searching for Models by Description in OpenSearch
DESCRIPTION: This query demonstrates how to search for models based on their description. It uses a bool query with a should clause to match the description and excludes model chunks.

LANGUAGE: json
CODE:
GET _plugins/_ml/models/_search
{
  "query": {
    "bool": {
      "should": [
        {
          "match": {
            "description": "sentence transformer"
          }
        }
      ],
      "must_not": {
        "exists": {
          "field": "chunk_number"
        }
      }
    }
  },
  "size": 1000
}

----------------------------------------

TITLE: Retrieving Multiple Specific Aliases
DESCRIPTION: Example request demonstrating how to fetch information for multiple specific aliases using comma separation.

LANGUAGE: json
CODE:
GET _cat/aliases/alias1,alias2,alias3

----------------------------------------

TITLE: Search Template Definition with Mustache Variables
DESCRIPTION: Example of a search template definition using Mustache variables for dynamic play name matching.

LANGUAGE: json
CODE:
{
  "source": {
    "query": {
      "match": {
        "play_name": "{{play_name}}"
      }
    }
  },
  "params": {
    "play_name": "Henry IV"
  }
}

----------------------------------------

TITLE: Dockerfile for OpenSearch Dashboards without Security
DESCRIPTION: Dockerfile configuration to create an OpenSearch Dashboards image without the Security plugin.

LANGUAGE: dockerfile
CODE:
FROM opensearchproject/opensearch-dashboards:{{site.opensearch_dashboards_version}}
RUN /usr/share/opensearch-dashboards/bin/opensearch-dashboards-plugin remove securityDashboards
COPY --chown=opensearch-dashboards:opensearch-dashboards opensearch_dashboards.yml /usr/share/opensearch-dashboards/config/

----------------------------------------

TITLE: Searching for Agents by Type in OpenSearch
DESCRIPTION: This example shows how to search for agents of a specific type using a term query. In this case, it's searching for agents of type 'flow'.

LANGUAGE: json
CODE:
POST /_plugins/_ml/agents/_search
{
  "query": {
    "term": {
      "type": {
        "value": "flow"
      }
    }
  }
}

----------------------------------------

TITLE: Defining Basic Match Query Feature in OpenSearch
DESCRIPTION: Demonstrates how to create a basic match query feature using a Mustache template for dynamic keyword insertion in the title field.

LANGUAGE: json
CODE:
{
    "query": {
        "match": {
            "title": "{{keywords}}"
        }
    }
}

----------------------------------------

TITLE: Has Child Query with Inner Hits - OpenSearch JSON
DESCRIPTION: Enhanced has_child query that includes inner_hits parameter to return matching child documents along with parent results.

LANGUAGE: json
CODE:
GET testindex1/_search
{
  "query" : {
    "has_child": {
      "type":"product",
      "query": {
        "match" : {
            "name": "watch"
        }
      },
      "inner_hits": {}
    }
  }
}

----------------------------------------

TITLE: Associate Saved Objects API Endpoint
DESCRIPTION: API endpoint to associate existing saved objects with a specified workspace.

LANGUAGE: json
CODE:
POST <osd host>:<port>/api/workspaces/_associate

----------------------------------------

TITLE: Registering a Flow Agent with NeuralSparseSearchTool in OpenSearch
DESCRIPTION: This snippet demonstrates how to register a flow agent that uses the NeuralSparseSearchTool. It specifies the model, index, and other parameters for the neural sparse search.

LANGUAGE: json
CODE:
POST /_plugins/_ml/agents/_register
{
  "name": "Test_Neural_Sparse_Agent_For_RAG",
  "type": "flow",
  "tools": [
    {
      "type": "NeuralSparseSearchTool",
      "parameters": {
        "description":"use this tool to search data from the knowledge base of company AAA",
        "model_id": "Nf9KY40Bk4MTqirc6FO7",
        "index": "index_for_neural_sparse",
        "embedding_field": "passage_embedding",
        "source_field": ["passage_text"],
        "input": "${parameters.question}",
        "doc_size":2
      }
    }
  ]
}

----------------------------------------

TITLE: Creating Index with Geoshape Mapping in OpenSearch
DESCRIPTION: This snippet shows how to create an index with a geoshape mapping for the 'location' field in OpenSearch. This is necessary for aggregating geoshape data.

LANGUAGE: json
CODE:
PUT national_parks
{
  "mappings": {
    "properties": {
      "location": {
        "type": "geo_shape"
      }
    }
  }
}

----------------------------------------

TITLE: Source Filtering Example
DESCRIPTION: Demonstrates source filtering to include or exclude specific fields from the search response.

LANGUAGE: json
CODE:
{
  "_source": ["title", "author"],
  "query": {
    "match_all": {}
  }
}

----------------------------------------

TITLE: Retrieving Verbose Node Information - OpenSearch REST API
DESCRIPTION: Example request that retrieves node information with verbose output enabled, showing column headers in the response.

LANGUAGE: json
CODE:
GET _cat/nodes?v

----------------------------------------

TITLE: Creating Index Rollup Job
DESCRIPTION: Example of creating an index rollup job configuration with dimensions, metrics and scheduling details

LANGUAGE: json
CODE:
{
  "rollup": {
    "enabled": true,
    "schedule": {
      "interval": {
        "period": 1,
        "unit": "Minutes",
        "start_time": 1602100553
      }
    },
    "last_updated_time": 1602100553,
    "description": "An example policy that rolls up the sample ecommerce data",
    "source_index": "opensearch_dashboards_sample_data_ecommerce",
    "target_index": "example_rollup",
    "page_size": 1000,
    "delay": 0,
    "continuous": false,
    "dimensions": [...],
    "metrics": [...]
  }
}

----------------------------------------

TITLE: Sorting Nested Objects in OpenSearch
DESCRIPTION: This example shows how to sort nested objects. It sorts by the average of grades in the nested 'first_sem' field.

LANGUAGE: json
CODE:
GET students/_search
{
 "query" : {
    "match_all": {}
 },
 "sort" : [
    {"first_sem.grades": {
      "order" : "desc", 
      "mode" : "avg",
      "nested": {
        "path": "first_sem"
     }
    }
    }
 ]
}

----------------------------------------

TITLE: Enabling Features in OpenSearch YAML Configuration
DESCRIPTION: Configure experimental features by adding a feature flag to the opensearch.yml configuration file.

LANGUAGE: yaml
CODE:
opensearch.experimental.feature.<feature_name>.enabled: true

----------------------------------------

TITLE: Configuring HTTP Basic Authentication in OpenSearch
DESCRIPTION: YAML configuration example showing how to enable HTTP basic authentication in OpenSearch. The configuration sets up a basic internal authentication domain with HTTP and transport enabled, using the internal user database as the authentication backend.

LANGUAGE: yaml
CODE:
_meta:
  type: "config"
  config_version: 2

config:
  dynamic:
    authc:
      basic_internal_auth_domain:
        description: "Authenticate using HTTP basic against the internal users database"
        http_enabled: true
        transport_enabled: true
        order: 1
        http_authenticator:
          type: basic
          challenge: true
        authentication_backend:
          type: internal

----------------------------------------

TITLE: Executing Constant Score Query in OpenSearch
DESCRIPTION: Demonstrates how to use a constant_score query to search for documents containing 'Hamlet' with a fixed boost value of 1.2. All matching documents receive the same relevance score.

LANGUAGE: json
CODE:
GET shakespeare/_search
{
  "query": {
    "constant_score": {
      "filter": {
        "match": {
          "text_entry": "Hamlet"
        }
      },
      "boost": 1.2
    }
  }
}

----------------------------------------

TITLE: Sample Response from CAT nodeattrs API
DESCRIPTION: This snippet shows a sample response from the CAT nodeattrs API. It includes information about node attributes, including the node name, host, IP address, attribute name, and attribute value.

LANGUAGE: json
CODE:
node | host | ip | attr | value
odfe-node2 | 172.18.0.3 | 172.18.0.3 | testattr | test

----------------------------------------

TITLE: Creating an index with a custom word_delimiter_graph filter in OpenSearch
DESCRIPTION: This example demonstrates how to create a new index named 'my-custom-index' with a custom analyzer using the word_delimiter_graph filter. The filter is configured with specific settings for splitting tokens and stemming possessives.

LANGUAGE: json
CODE:
PUT /my-custom-index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "custom_analyzer": {
          "tokenizer": "keyword",
          "filter": [ "custom_word_delimiter_filter" ]
        }
      },
      "filter": {
        "custom_word_delimiter_filter": {
          "type": "word_delimiter_graph",
          "split_on_case_change": true,
          "split_on_numerics": true,
          "stem_english_possessive": true
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating Index with Edge N-gram Tokenizer
DESCRIPTION: Creates a new index with a custom edge n-gram tokenizer configured for tokens between 3-6 characters in length, considering only letters as valid token characters.

LANGUAGE: json
CODE:
PUT /edge_n_gram_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_custom_analyzer": {
          "tokenizer": "my_custom_tokenizer"
        }
      },
      "tokenizer": {
        "my_custom_tokenizer": {
          "type": "edge_ngram",
          "min_gram": 3,
          "max_gram": 6,
          "token_chars": [
            "letter"          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Querying CAT Allocation Endpoints in OpenSearch
DESCRIPTION: These endpoints allow retrieving allocation information for all nodes or specific nodes in the cluster.

LANGUAGE: json
CODE:
GET /_cat/allocation
GET /_cat/allocation/{node_id}

----------------------------------------

TITLE: Installing Reporting CLI via npm
DESCRIPTION: Command to install the OpenSearch Reporting CLI tool using the npm package manager.

LANGUAGE: bash
CODE:
npm i @opensearch-project/reporting-cli

----------------------------------------

TITLE: Upgrading OpenSearch Dashboards using RPM or YUM
DESCRIPTION: These commands show how to upgrade OpenSearch Dashboards to a newer version using either RPM or YUM package managers.

LANGUAGE: bash
CODE:
rpm -Uvh opensearch-dashboards-{{site.opensearch_version}}-linux-x64.rpm

sudo yum update opensearch-dashboards

sudo yum update opensearch-dashboards-<version-number>

----------------------------------------

TITLE: Date Range Aggregation Response in OpenSearch
DESCRIPTION: This snippet shows the response structure for a date_range aggregation query in OpenSearch. It includes the formatted date range and document count.

LANGUAGE: json
CODE:
...
"aggregations" : {
  "number_of_bytes" : {
    "buckets" : [
      {
        "key" : "03-2021-03-2021",
        "from" : 1.6145568E12,
        "from_as_string" : "03-2021",
        "to" : 1.615451329043E12,
        "to_as_string" : "03-2021",
        "doc_count" : 0
      }
    ]
  }
 }
}

----------------------------------------

TITLE: Analyzing Text with Porter Stem Analyzer in OpenSearch
DESCRIPTION: This example demonstrates how to use the '_analyze' endpoint to examine the tokens generated by the Porter stem analyzer. It applies the analyzer to the text 'running runners ran' to show how words are stemmed.

LANGUAGE: json
CODE:
POST /my_stem_index/_analyze
{
  "text": "running runners ran",
  "analyzer": "porter_analyzer"
}

----------------------------------------

TITLE: Configuring OpenSearch YAML Settings
DESCRIPTION: Add network and discovery settings to the opensearch.yml configuration file.

LANGUAGE: bash
CODE:
network.host: 0.0.0.0
discovery.type: single-node
plugins.security.disabled: false

----------------------------------------

TITLE: Security Configuration Upload Command
DESCRIPTION: Command to upload security configurations to OpenSearch security index using securityadmin.sh tool.

LANGUAGE: bash
CODE:
./plugins/opensearch-security/tools/securityadmin.sh -cd "config/opensearch-security" -icl -key "../kirk-key.pem" -cert "../kirk.pem" -cacert "../root-ca.pem" -nhnv

----------------------------------------

TITLE: Direct Pipeline Specification with CSV Processing
DESCRIPTION: Example showing how to specify a pipeline directly in the request body with CSV processing and uppercase transformation of names.

LANGUAGE: json
CODE:
{
  "pipeline" :
  {
    "description": "Splits text on white space characters",
    "processors": [
      {
        "csv" : {
          "field" : "name",
          "separator": ",",
          "target_fields": ["last_name", "first_name"],
          "trim": true
        }
      },
      {
      "uppercase": {
        "field": "last_name"
      }
    }
    ]
  },
  "docs": [
    {
      "_index": "second-index",
      "_id": "1",
      "_source": {
        "name": "Doe,John"
      }
    },
    {
      "_index": "second-index",
      "_id": "2",
      "_source": {
        "name": "Doe, Jane"
      }
    }
  ]
}

----------------------------------------

TITLE: Setting Request Timeouts in OpenSearch C# Client
DESCRIPTION: Demonstrates how to configure request timeout settings for individual requests and maximum retry duration using ConnectionSettings.

LANGUAGE: csharp
CODE:
var settings = new ConnectionSettings(connectionPool)
            .RequestTimeout(TimeSpan.FromSeconds(4))
            .MaxRetryTimeout(TimeSpan.FromSeconds(12));

----------------------------------------

TITLE: Creating an OpenSearch Index
DESCRIPTION: JavaScript code for creating an OpenSearch index with custom settings using the indices.create() method.

LANGUAGE: javascript
CODE:
var index_name = "books";

var settings = {
  settings: {
    index: {
      number_of_shards: 4,
      number_of_replicas: 3,
    },
  },
};

var response = await client.indices.create({
  index: index_name,
  body: settings,
});

----------------------------------------

TITLE: Requesting Verbose CAT Health Information in OpenSearch
DESCRIPTION: This example demonstrates how to request verbose CAT health information for the past 5 days using query parameters. It includes the 'v' parameter for verbose output and 'time' parameter to specify the time range.

LANGUAGE: json
CODE:
GET _cat/health?v&time=5d

----------------------------------------

TITLE: OpenSearch Blocks API Response
DESCRIPTION: Example response from the OpenSearch Blocks API after successfully applying a write block to the 'test-index'. It confirms the acknowledgment and blocked status of the index.

LANGUAGE: json
CODE:
{
  "acknowledged" : true,
  "shards_acknowledged" : true,
  "indices" : [ {
    "name" : "test-index",
    "blocked" : true
  } ]
}

----------------------------------------

TITLE: Get Message by ID Endpoint
DESCRIPTION: API endpoint for retrieving a specific message using its message ID. Returns detailed message information including memory ID, creation time, and response content.

LANGUAGE: json
CODE:
GET /_plugins/_ml/memory/message/<message_id>

----------------------------------------

TITLE: Setting Default Index Analyzer for an Index in OpenSearch
DESCRIPTION: This JSON snippet shows how to specify a default analyzer for all text fields in an index using the 'analysis.analyzer.default' setting. It sets the 'simple' analyzer as the default.

LANGUAGE: json
CODE:
PUT testindex
{
  "settings": {
    "analysis": {
      "analyzer": {
        "default": {
          "type": "simple"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Performing Percolate Query in OpenSearch
DESCRIPTION: This snippet shows how to perform a percolate query to find matching documents. It searches for documents that match the indexed query, using a sample document with an item 'Mahogany table' priced at $399.99.

LANGUAGE: json
CODE:
GET testindex1/_search
{
  "query" : {
    "bool" : {
      "filter" : 
        {
          "percolate" : {
            "field" : "search.query",
            "document" : {
              "item" : "Mahogany table",
              "price": 399.99
            }
          }
        }
    }
  }
}

----------------------------------------

TITLE: Indexing Array Values in OpenSearch
DESCRIPTION: Demonstrates how to index both single and array values for the same field in OpenSearch. This example shows that OpenSearch automatically handles arrays without a dedicated array type.

LANGUAGE: json
CODE:
PUT testindex1/_doc/1
{
  "number": 1 
}

PUT testindex1/_doc/2
{
  "number": [1, 2, 3] 
}

----------------------------------------

TITLE: Creating Custom Italian Analyzer in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a custom Italian analyzer with specific token filters and apply it to a text field in OpenSearch.

LANGUAGE: json
CODE:
PUT /italian-index
{
  "settings": {
    "analysis": {
      "filter": {
        "italian_stop": {
          "type": "stop",
          "stopwords": "_italian_"
        },
        "italian_elision": {
          "type": "elision",
          "articles": [
                "c", "l", "all", "dall", "dell",
                "nell", "sull", "coll", "pell",
                "gl", "agl", "dagl", "degl", "negl",
                "sugl", "un", "m", "t", "s", "v", "d"
          ],
          "articles_case": true
        },
        "italian_stemmer": {
          "type": "stemmer",
          "language": "light_italian"
        },
        "italian_keywords": {
          "type": "keyword_marker",
          "keywords": []
        }
      },
      "analyzer": {
        "italian_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "italian_elision",
            "lowercase",
            "italian_stop",
            "italian_keywords",
            "italian_stemmer"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "italian_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Delete Agent Response Example
DESCRIPTION: Example response showing successful deletion of an ML agent, including operation details and shard information.

LANGUAGE: json
CODE:
{
  "_index" : ".plugins-ml-agent",
  "_id" : "MzcIJX8BA7mbufL6DOwl",
  "_version" : 2,
  "result" : "deleted",
  "_shards" : {
    "total" : 2,
    "successful" : 2,
    "failed" : 0
  },
  "_seq_no" : 27,
  "_primary_term" : 18
}

----------------------------------------

TITLE: FROM Clause Subquery Example
DESCRIPTION: Demonstrates using a subquery in the FROM clause with column aliases

LANGUAGE: sql
CODE:
SELECT a.f, a.l, a.a
FROM (
  SELECT firstname AS f, lastname AS l, age AS a
  FROM accounts
  WHERE age > 30
) AS a

----------------------------------------

TITLE: Closing a Specific Scroll Context in OpenSearch
DESCRIPTION: This example shows how to close a specific scroll context using its scroll ID, which helps in freeing up resources.

LANGUAGE: json
CODE:
DELETE _search/scroll/DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAAcWdmpUZDhnRFBUcWFtV21nMmFwUGJEQQ==

----------------------------------------

TITLE: Configuring Google Workspace Field Mappings in JSON
DESCRIPTION: Defines the field mappings between raw Google Workspace log fields and their corresponding ECS (Elastic Common Schema) fields. Maps eventSource to service name, eventName to event name, and new_value to admin new value fields.

LANGUAGE: json
CODE:
  "mappings": [
    {
      "raw_field":"eventSource",
      "ecs":"google_workspace.admin.service.name"
    },
    {
      "raw_field":"eventName",
      "ecs":"google_workspace.event.name"
    },
    {
      "raw_field":"new_value",
      "ecs":"google_workspace.admin.new_value"
    }
  ]

----------------------------------------

TITLE: Example Bulk Response in OpenSearch
DESCRIPTION: Shows a sample response to a bulk request in OpenSearch. The response includes details for each action, including success or failure status and any error messages.

LANGUAGE: json
CODE:
{
  "took": 11,
  "errors": true,
  "items": [
    {
      "index": {
        "_index": "movies",
        "_id": "tt1979320",
        "_version": 1,
        "result": "created",
        "_shards": {
          "total": 2,
          "successful": 1,
          "failed": 0
        },
        "_seq_no": 1,
        "_primary_term": 1,
        "status": 201
      }
    },
    {
      "create": {
        "_index": "movies",
        "_id": "tt1392214",
        "status": 409,
        "error": {
          "type": "version_conflict_engine_exception",
          "reason": "[tt1392214]: version conflict, document already exists (current version [1])",
          "index": "movies",
          "shard": "0",
          "index_uuid": "yhizhusbSWmP0G7OJnmcLg"
        }
      }
    },
    {
      "update": {
        "_index": "movies",
        "_id": "tt0816711",
        "status": 404,
        "error": {
          "type": "document_missing_exception",
          "reason": "[_doc][tt0816711]: document missing",
          "index": "movies",
          "shard": "0",
          "index_uuid": "yhizhusbSWmP0G7OJnmcLg"
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Basic Segment Replication Query
DESCRIPTION: Example request for segment replication metrics with column headings for all indexes.

LANGUAGE: json
CODE:
GET /_cat/segment_replication?v=true

----------------------------------------

TITLE: ML Task Search Response Example
DESCRIPTION: Example response showing the search results containing two KMEANS tasks with their metadata including creation time, state, and model IDs.

LANGUAGE: json
CODE:
{
  "took" : 12,
  "timed_out" : false,
  "_shards" : {
    "total" : 1,
    "successful" : 1,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : {
      "value" : 2,
      "relation" : "eq"
    },
    "max_score" : 0.0,
    "hits" : [
      {
        "_index" : ".plugins-ml-task",
        "_id" : "_wnLJ38BvytMh9aUi-Ia",
        "_version" : 4,
        "_seq_no" : 29,
        "_primary_term" : 4,
        "_score" : 0.0,
        "_source" : {
          "last_update_time" : 1645640125267,
          "create_time" : 1645640125209,
          "is_async" : true,
          "function_name" : "KMEANS",
          "input_type" : "SEARCH_QUERY",
          "worker_node" : "jjqFrlW7QWmni1tRnb_7Dg",
          "state" : "COMPLETED",
          "model_id" : "AAnLJ38BvytMh9aUi-M2",
          "task_type" : "TRAINING"
        }
      },
      {
        "_index" : ".plugins-ml-task",
        "_id" : "wwRRLX8BydmmU1x6I-AI",
        "_version" : 3,
        "_seq_no" : 38,
        "_primary_term" : 7,
        "_score" : 0.0,
        "_source" : {
          "last_update_time" : 1645732766656,
          "create_time" : 1645732766472,
          "is_async" : true,
          "function_name" : "KMEANS",
          "input_type" : "SEARCH_QUERY",
          "worker_node" : "A_IiqoloTDK01uZvCjREaA",
          "state" : "COMPLETED",
          "model_id" : "xARRLX8BydmmU1x6I-CG",
          "task_type" : "TRAINING"
        }
      }
    ]
  }
}

----------------------------------------

TITLE: Creating a Mapping with IP Address Ranges in OpenSearch
DESCRIPTION: This snippet illustrates how to create a mapping in OpenSearch that includes fields for IP address ranges. It defines two fields: one for standard IP ranges and another for CIDR notation.

LANGUAGE: json
CODE:
PUT testindex 
{
  "mappings" : {
    "properties" :  {
      "ip_address_range" : {
        "type" : "ip_range" 
      },
      "ip_address_cidr" : {
        "type" : "ip_range" 
      }
    }
  }
}

----------------------------------------

TITLE: Executing Terms Set Query with Field-Based Matching
DESCRIPTION: Demonstrates how to perform a terms set query using a field to specify minimum required matches. Shows query structure for searching across multiple terms.

LANGUAGE: json
CODE:
GET students/_search
{
  "query": {
    "terms_set": {
      "classes": {
        "terms": [ "CS101", "CS102", "MATH101" ],
        "minimum_should_match_field": "min_required"
      }
    }
  }
}

----------------------------------------

TITLE: Single Index CAT Shards Query - JSON
DESCRIPTION: Example request to retrieve shard information for a specific index with verbose output.

LANGUAGE: json
CODE:
GET _cat/shards/<index>?v

----------------------------------------

TITLE: Configuring Routing to Specific Shards in OpenSearch
DESCRIPTION: Example of creating an index that routes documents to a subset of shards (4 in this case) rather than a single shard. It also requires custom routing for all operations.

LANGUAGE: json
CODE:
PUT sample-index3
{
  "settings": {
    "index.routing_partition_size": 4
  },
  "mappings": {
    "_routing": {
      "required": true
    }
  }
}

----------------------------------------

TITLE: Creating S3 Bucket for Snapshots
DESCRIPTION: AWS CLI command to create an S3 bucket for storing Elasticsearch/OpenSearch snapshots. Requires AWS CLI configuration and appropriate IAM permissions.

LANGUAGE: shell
CODE:
aws s3api create-bucket --bucket <your-bucket-name> --region <your-aws-region>

----------------------------------------

TITLE: Retrieving Available Headers for CAT API Aliases in OpenSearch
DESCRIPTION: This snippet demonstrates how to get all available headers for the CAT API aliases operation. It uses the 'help' query parameter to list default and other available headers.

LANGUAGE: json
CODE:
GET _cat/aliases?help

----------------------------------------

TITLE: Inserting Data into a Nested Vector Index in OpenSearch
DESCRIPTION: This snippet shows how to insert data into a nested vector index in OpenSearch using the bulk API.

LANGUAGE: json
CODE:
PUT _bulk?refresh=true
{ "index": { "_index": "my-knn-index-1", "_id": "1" } }
{"nested_field":[{"my_vector":[1,1,1], "color": "blue"},{"my_vector":[2,2,2], "color": "yellow"},{"my_vector":[3,3,3], "color": "white"}]}
{ "index": { "_index": "my-knn-index-1", "_id": "2" } }
{"nested_field":[{"my_vector":[10,10,10], "color": "red"},{"my_vector":[20,20,20], "color": "green"},{"my_vector":[30,30,30], "color": "black"}]}

----------------------------------------

TITLE: Installing OpenSearch Dashboards from APT Repository
DESCRIPTION: Commands to install OpenSearch Dashboards from the APT repository, including listing available versions and specifying a particular version.

LANGUAGE: bash
CODE:
sudo apt list -a opensearch-dashboards
sudo apt-get install opensearch-dashboards
sudo apt-get install opensearch-dashboards={{site.opensearch_version}}
sudo systemctl enable opensearch-dashboards
sudo systemctl start opensearch-dashboards
sudo systemctl status opensearch-dashboards

----------------------------------------

TITLE: IP Range Aggregation Response Example
DESCRIPTION: Example response showing the structure of IP range aggregation results, including bucket information with key, from/to ranges, and document counts.

LANGUAGE: json
CODE:
{
  "aggregations": {
    "access": {
      "buckets": [
        {
          "key": "1.0.0.0/8",
          "from": "1.0.0.0",
          "to": "2.0.0.0",
          "doc_count": 98
        },
        {
          "key": "1.0.0.0-126.158.155.183",
          "from": "1.0.0.0",
          "to": "126.158.155.183",
          "doc_count": 7184
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Creating Index with Flatten Graph Filter in OpenSearch
DESCRIPTION: Example of creating a new index with a custom analyzer that includes the flatten_graph filter and a word_delimiter_graph filter. The analyzer is configured to handle multi-position tokens during indexing.

LANGUAGE: json
CODE:
PUT /test_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_index_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "my_custom_filter",
            "flatten_graph"
          ]
        }
      },
      "filter": {
        "my_custom_filter": {
          "type": "word_delimiter_graph",
          "catenate_all": true
        }
      }
    }
  }
}

----------------------------------------

TITLE: User ID Query with Special Characters
DESCRIPTION: Examples showing how special characters in text fields can affect query parsing when using the standard analyzer.

LANGUAGE: json
CODE:
{
  "bool": {
    "must": {
      "match": {
        "user.id": "User-1"
      }
    }
  }
}

LANGUAGE: json
CODE:
{
  "bool": {
    "must": {
      "match": {
        "user.id": "User-2"
      }
    }
  }
}

----------------------------------------

TITLE: Indexing xy point as string in OpenSearch
DESCRIPTION: This snippet demonstrates indexing an xy point as a string in the 'x, y' format in OpenSearch.

LANGUAGE: json
CODE:
PUT testindex1/_doc/2
{
  "point": "0.5, 4.5" 
}

----------------------------------------

TITLE: Retrieving All Aliases with Verbose Output
DESCRIPTION: Example request to fetch all aliases with verbose output enabled, which displays column headers.

LANGUAGE: json
CODE:
GET _cat/aliases?v

----------------------------------------

TITLE: Testing Basque Analyzer Token Generation
DESCRIPTION: Shows how to analyze text and view the generated tokens using the Basque analyzer.

LANGUAGE: json
CODE:
POST /basque-index/_analyze
{
  "field": "content",
  "text": "Ikasleek euskal unibertsitateetan ikasten dute. Haien zenbakiak 123456 dira."
}

----------------------------------------

TITLE: Search Connector Response
DESCRIPTION: Example response showing connector search results, including metadata and configurations for multiple AWS Bedrock connectors.

LANGUAGE: json
CODE:
{
  "took" : 1,
  "timed_out" : false,
  "_shards" : {
    "total" : 1,
    "successful" : 1,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : {
      "value" : 3,
      "relation" : "eq"
    },
    "max_score" : 1.0,
    "hits" : [
      {
        "_index" : ".plugins-ml-connector",
        "_id" : "7W-d74sBPD67W0wkEZdE",
        "_version" : 1,
        "_seq_no" : 2,
        "_primary_term" : 1,
        "_score" : 1.0,
        "_source" : {
          "protocol" : "aws_sigv4",
          "name" : "BedRock claude Connector",
          "description" : "The connector to BedRock service for claude model",
          "version" : "1",
          "parameters" : {
            "endpoint" : "bedrock.us-east-1.amazonaws.com",
            "content_type" : "application/json",
            "auth" : "Sig_V4",
            "max_tokens_to_sample" : "8000",
            "service_name" : "bedrock",
            "temperature" : "1.0E-4",
            "response_filter" : "$.completion",
            "region" : "us-east-1",
            "anthropic_version" : "bedrock-2023-05-31"
          },
          "actions" : [
            {
              "headers" : {
                "x-amz-content-sha256" : "required",
                "content-type" : "application/json"
              },
              "method" : "POST",
              "request_body" : "{\"prompt\":\"${parameters.prompt}\", \"max_tokens_to_sample\":${parameters.max_tokens_to_sample}, \"temperature\":${parameters.temperature},  \"anthropic_version\":\"${parameters.anthropic_version}\" }",
              "action_type" : "PREDICT",
              "url" : "https://bedrock.us-east-1.amazonaws.com/model/anthropic.claude-v2/invoke"
            }
          ]
        }
      },
      {
        "_index" : ".plugins-ml-connector",
        "_id" : "9W-d74sBPD67W0wk4pf_",
        "_version" : 1,
        "_seq_no" : 3,
        "_primary_term" : 1,
        "_score" : 1.0,
        "_source" : {
          "protocol" : "aws_sigv4",
          "name" : "BedRock claude Connector",
          "description" : "The connector to BedRock service for claude model",
          "version" : "1",
          "parameters" : {
            "endpoint" : "bedrock.us-east-1.amazonaws.com",
            "content_type" : "application/json",
            "auth" : "Sig_V4",
            "max_tokens_to_sample" : "8000",
            "service_name" : "bedrock",
            "temperature" : "1.0E-4",
            "response_filter" : "$.completion",
            "region" : "us-east-1",
            "anthropic_version" : "bedrock-2023-05-31"
          },
          "actions" : [
            {
              "headers" : {
                "x-amz-content-sha256" : "required",
                "content-type" : "application/json"
              },
              "method" : "POST",
              "request_body" : "{\"prompt\":\"${parameters.prompt}\", \"max_tokens_to_sample\":${parameters.max_tokens_to_sample}, \"temperature\":${parameters.temperature},  \"anthropic_version\":\"${parameters.anthropic_version}\" }",
              "action_type" : "PREDICT",
              "url" : "https://bedrock.us-east-1.amazonaws.com/model/anthropic.claude-v2/invoke"
            }
          ]
        }
      },
      {
        "_index" : ".plugins-ml-connector",
        "_id" : "rm_u8osBPD67W0wkCpsG",
        "_version" : 1,
        "_seq_no" : 4,
        "_primary_term" : 1,
        "_score" : 1.0,
        "_source" : {
          "protocol" : "aws_sigv4",
          "name" : "BedRock Claude-Instant v1",
          "description" : "Bedrock connector for Claude Instant testing",
          "version" : "1",
          "parameters" : {
            "endpoint" : "bedrock.us-east-1.amazonaws.com",
            "content_type" : "application/json",
            "auth" : "Sig_V4",
            "service_name" : "bedrock",
            "region" : "us-east-1",
            "anthropic_version" : "bedrock-2023-05-31"
          },
          "actions" : [
            {
              "headers" : {
                "x-amz-content-sha256" : "required",
                "content-type" : "application/json"
              },
              "method" : "POST",
              "request_body" : "{\"prompt\":\"${parameters.prompt}\", \"max_tokens_to_sample\":${parameters.max_tokens_to_sample}, \"temperature\":${parameters.temperature},  \"anthropic_version\":\"${parameters.anthropic_version}\" }",
              "action_type" : "PREDICT",
              "url" : "https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-instant-v1/invoke"
            }
          ]
        }
      }
    ]
  }
}

----------------------------------------

TITLE: Running OpenSearch Benchmark with Telemetry Device
DESCRIPTION: Command example showing how to run the OpenSearch Benchmark with the JFR telemetry device using the geonames workload. The --telemetry flag enables telemetry collection during the benchmark execution.

LANGUAGE: json
CODE:
opensearch-benchmark workload --workload=geonames --telemetry=jfr

----------------------------------------

TITLE: Example Neural Sparse Query by Raw Text in OpenSearch
DESCRIPTION: This example demonstrates a complete search request using the neural_sparse query with raw text input. It specifies the index to search, the query text, and the model ID for generating embeddings.

LANGUAGE: json
CODE:
GET my-nlp-index/_search
{
  "query": {
    "neural_sparse": {
      "passage_embedding": {
        "query_text": "Hi world",
        "model_id": "aP2Q8ooBpBj3wT4HVS8a"
      }
    }
  }
}

----------------------------------------

TITLE: Viewing Keystore Contents
DESCRIPTION: Command to inspect keystore certificates and their properties using keytool

LANGUAGE: bash
CODE:
keytool -list -v -keystore keystore.jks

----------------------------------------

TITLE: Creating JSON Input for list_to_map Processor
DESCRIPTION: Example of creating a JSON input file (logs_json.log) containing a list of objects to be processed by the list_to_map processor.

LANGUAGE: json
CODE:
{"mylist":[{"name":"a","value":"val-a"},{"name":"b","value":"val-b1"},{"name":"b",  "value":"val-b2"},{"name":"c","value":"val-c"}]}

----------------------------------------

TITLE: Multiple Indexes CAT Segments Query
DESCRIPTION: Query to retrieve segment information for multiple specified indexes.

LANGUAGE: json
CODE:
GET _cat/segments/index1,index2,index3

----------------------------------------

TITLE: Querying SQL with JSON Format in OpenSearch
DESCRIPTION: Demonstrates a SQL query with the response format set to JSON, returning the original OpenSearch response in JSON format.

LANGUAGE: json
CODE:
POST _plugins/_sql?format=json
{
  "query" : "SELECT firstname, lastname, age FROM accounts ORDER BY age LIMIT 2"
}

LANGUAGE: json
CODE:
{
  "_shards": {
    "total": 5,
    "failed": 0,
    "successful": 5,
    "skipped": 0
  },
  "hits": {
    "hits": [{
        "_index": "accounts",
        "_type": "account",
        "_source": {
          "firstname": "Nanette",
          "age": 28,
          "lastname": "Bates"
        },
        "_id": "13",
        "sort": [
          28
        ],
        "_score": null
      },
      {
        "_index": "accounts",
        "_type": "account",
        "_source": {
          "firstname": "Amber",
          "age": 32,
          "lastname": "Duke"
        },
        "_id": "1",
        "sort": [
          32
        ],
        "_score": null
      }
    ],
    "total": {
      "value": 4,
      "relation": "eq"
    },
    "max_score": null
  },
  "took": 100,
  "timed_out": false
}

----------------------------------------

TITLE: Range Query with Custom Date Format in OpenSearch
DESCRIPTION: This query demonstrates how to specify a custom date format for a range query on the 'created' field.

LANGUAGE: json
CODE:
GET /products/_search
{
  "query": {
    "range": {
      "created": {
        "gte": "01/01/2022",
        "lte": "31/12/2022",
        "format":"dd/MM/yyyy"
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Letter Tokenizer Index
DESCRIPTION: Creates a new index with a custom analyzer using the letter tokenizer. The example configures both analysis settings and mappings for a content field.

LANGUAGE: json
CODE:
PUT /my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_letter_analyzer": {
          "type": "custom",
          "tokenizer": "letter"
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "my_letter_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Analyzing Text with Synonym Graph Analyzer
DESCRIPTION: This example shows how to use the _analyze API to examine the tokens generated by the custom synonym_graph analyzer for a given text input.

LANGUAGE: json
CODE:
GET /my-car-index/_analyze
{
  "analyzer": "my_synonym_graph_analyzer",
  "text": "I just bought a sports car and it is a fast car."
}

----------------------------------------

TITLE: Complete Put Mapping Request Example
DESCRIPTION: Full example of creating a new mapping with multiple fields for the sample-index.

LANGUAGE: json
CODE:
PUT /sample-index/_mapping

{
  "properties": {
    "age": {
      "type": "integer"
    },
    "occupation":{
      "type": "text"
    }
  }
}

----------------------------------------

TITLE: Time Series Metric Query with PPL
DESCRIPTION: Example PPL query for creating a time series metric visualization. The query spans over a timestamp field with 1-hour intervals to generate data points for a line chart.

LANGUAGE: ppl
CODE:
source = <index_name> | ... | ... | stats ... by span(<timestamp_field>, 1h)

----------------------------------------

TITLE: Nested Geo_centroid with Terms Aggregation
DESCRIPTION: Demonstrates how to nest geo_centroid under terms aggregation to calculate centroids for data subsets.

LANGUAGE: json
CODE:
GET /restaurants/_search
{
  "size": 0,
  "aggs": {
    "cities": {
      "terms": {
        "field": "city.keyword"
      },
      "aggs": {
        "centroid": {
          "geo_centroid": {
            "field": "location"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Applying Spanish Analyzer to Text Field in OpenSearch
DESCRIPTION: This snippet demonstrates how to apply the built-in Spanish analyzer to a text field in an OpenSearch index mapping.

LANGUAGE: json
CODE:
PUT /spanish-index
{
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "spanish"
      }
    }
  }
}

----------------------------------------

TITLE: Creating Index with Greek Lowercase Filter in OpenSearch
DESCRIPTION: This example creates a new index named 'custom_lowercase_example' with a custom analyzer using the lowercase filter. It specifies 'greek' as the language for the lowercase filter.

LANGUAGE: json
CODE:
PUT /custom_lowercase_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "greek_lowercase_example": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": ["greek_lowercase"]
        }
      },
      "filter": {
        "greek_lowercase": {
          "type": "lowercase",
          "language": "greek"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Parallel Tasks Configuration in OpenSearch Benchmark
DESCRIPTION: Example showing how to configure parallel tasks executing bulk operations concurrently with different client configurations.

LANGUAGE: yaml
CODE:
{
  "name": "parallel-any",
  "description": "Workload completed-by property",
  "schedule": [
    {
      "parallel": {
        "tasks": [
          {
            "name": "parellel-task-1",
            "operation": {
              "operation-type": "bulk",
              "bulk-size": 1000
            },
            "clients": 8
          },
          {
            "name": "parellel-task-2",
            "operation": {
              "operation-type": "bulk",
              "bulk-size": 500
            },
            "clients": 8
          }
        ]
      }
    }
  ]
}

----------------------------------------

TITLE: Configuring Split Event Pipeline in YAML
DESCRIPTION: Example configuration for setting up a split-event processor in a pipeline. The processor splits events based on the 'query' field using a space delimiter.

LANGUAGE: yaml
CODE:
split-event-pipeline:
  source:
    http:
  processor:
    - split_event:
        field: query
        delimiter: ' '    
  sink:
    - stdout:

----------------------------------------

TITLE: Search Operations Sample
DESCRIPTION: Examples of performing various search operations including boolean queries and scrolling

LANGUAGE: ruby
CODE:
q = 'James'
query = {
  'size': 5,
  'query': {
    'multi_match': {
      'query': q,
      'fields': ['first_name', 'last_name^2']
    }
  }
}

response = client.search(
  body: query,
  index: 'students'
)

----------------------------------------

TITLE: Validating Query with URL Parameters in OpenSearch
DESCRIPTION: Illustrates how to validate a query using URL parameters in OpenSearch. This example validates a simple query against the 'hamlet' index.

LANGUAGE: json
CODE:
GET hamlet/_validate/query?q=user.id:hamlet

----------------------------------------

TITLE: Querying List Shards API Endpoints in OpenSearch
DESCRIPTION: These endpoints allow retrieving shard information for all indexes or a specific index. They support various query parameters for customization.

LANGUAGE: json
CODE:
GET _list/shards
GET _list/shards/<index>

----------------------------------------

TITLE: Analyzing Text with Fingerprint Filter in OpenSearch
DESCRIPTION: Example request to analyze text using the custom analyzer with fingerprint filter, showing how the text is processed and tokenized.

LANGUAGE: json
CODE:
POST /my_index/_analyze
{
  "analyzer": "my_analyzer",
  "text": "OpenSearch is a powerful search engine that scales easily"
}

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "a-easily-engine-is-opensearch-powerful-scales-search-that",
      "start_offset": 0,
      "end_offset": 57,
      "type": "fingerprint",
      "position": 0
    }
  ]
}

----------------------------------------

TITLE: Creating Index with Keyword Marker Filter in OpenSearch
DESCRIPTION: Creates a new index with a custom analyzer that uses the keyword_marker filter to prevent the word 'example' from being stemmed.

LANGUAGE: json
CODE:
PUT /my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "custom_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": ["lowercase", "keyword_marker_filter", "stemmer"]
        }
      },
      "filter": {
        "keyword_marker_filter": {
          "type": "keyword_marker",
          "keywords": ["example"]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Discovery and Initial Cluster Manager Nodes in YAML
DESCRIPTION: Sets up discovery hosts and initial cluster manager nodes for cluster formation.

LANGUAGE: yaml
CODE:
cluster.initial_cluster_manager_nodes: ["opensearch-cluster_manager"]
discovery.seed_hosts: ["<private IP of opensearch-d1>", "<private IP of opensearch-d2>", "<private IP of opensearch-c1>"]

----------------------------------------

TITLE: Intervals Query with Filter in OpenSearch
DESCRIPTION: An example of an Intervals query using a filter to search for 'pairs' and 'hash' within five positions of each other, excluding results where 'efficiently' appears between them.

LANGUAGE: json
CODE:
POST /testindex/_search
{
  "query": {
    "intervals" : {
      "title" : {
        "match" : {
          "query" : "pairs hash",
          "max_gaps" : 5,
          "filter" : {
            "not_containing" : {
              "match" : {
                "query" : "efficiently"
              }
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Enabling Long Path Support in Windows via PowerShell
DESCRIPTION: PowerShell command to enable long path support in Windows registry, which is necessary when encountering path-length-related errors during extraction.

LANGUAGE: batch
CODE:
Set-ItemProperty -Path HKLM:\SYSTEM\CurrentControlSet\Control\FileSystem LongPathsEnabled -Type DWORD -Value 1 -Force

----------------------------------------

TITLE: Querying SQL with CSV Format in OpenSearch
DESCRIPTION: Shows how to request SQL query results in CSV format, which returns data in comma-separated values.

LANGUAGE: json
CODE:
POST /_plugins/_sql?format=csv
{
  "query" : "SELECT firstname, lastname, age FROM accounts ORDER BY age"
}

LANGUAGE: text
CODE:
firstname,lastname,age
Nanette,Bates,28
Amber,Duke,32
Dale,Adams,33
Hattie,Bond,36

----------------------------------------

TITLE: Docker Compose Configuration for OpenSearch with Jaeger
DESCRIPTION: Docker Compose configuration that sets up OpenSearch cluster with Jaeger integration. Includes configuration for OpenSearch nodes, Dashboards, Jaeger collector, agent, and HotROD demo application. Enables error tracking by setting ES_TAGS_AS_FIELDS_ALL to true.

LANGUAGE: yaml
CODE:
version: '3'
services:
  opensearch-node1: # This is also the hostname of the container within the Docker network (i.e. https://opensearch-node1/)
    image: opensearchproject/opensearch:latest # Specifying the latest available image - modify if you want a specific version
    container_name: opensearch-node1
    environment:
      - cluster.name=opensearch-cluster # Name the cluster
      - node.name=opensearch-node1 # Name the node that will run in this container
      - discovery.seed_hosts=opensearch-node1,opensearch-node2 # Nodes to look for when discovering the cluster
      - cluster.initial_cluster_manager_nodes=opensearch-node1,opensearch-node2 # Nodes eligible to serve as cluster manager
      - bootstrap.memory_lock=true # Disable JVM heap memory swapping
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m" # Set min and max JVM heap sizes to at least 50% of system RAM
    ulimits:
      memlock:
        soft: -1 # Set memlock to unlimited (no soft or hard limit)
        hard: -1
      nofile:
        soft: 65536 # Maximum number of open files for the opensearch user - set to at least 65536
        hard: 65536
    volumes:
      - opensearch-data1:/usr/share/opensearch/data # Creates volume called opensearch-data1 and mounts it to the container
    ports:
      - "9200:9200"
      - "9600:9600"
    networks:
      - opensearch-net # All of the containers will join the same Docker bridge network

  opensearch-node2:
    image: opensearchproject/opensearch:latest # This should be the same image used for opensearch-node1 to avoid issues
    container_name: opensearch-node2
    environment:
      - cluster.name=opensearch-cluster
      - node.name=opensearch-node2
      - discovery.seed_hosts=opensearch-node1,opensearch-node2
      - cluster.initial_cluster_manager_nodes=opensearch-node1,opensearch-node2
      - bootstrap.memory_lock=true
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - opensearch-data2:/usr/share/opensearch/data
    networks:
      - opensearch-net
  opensearch-dashboards:
    image: opensearchproject/opensearch-dashboards:latest # Make sure the version of opensearch-dashboards matches the version of opensearch installed on other nodes
    container_name: opensearch-dashboards
    ports:
      - 5601:5601 # Map host port 5601 to container port 5601
    expose:
      - "5601" # Expose port 5601 for web access to OpenSearch Dashboards
    environment:
      OPENSEARCH_HOSTS: '["https://opensearch-node1:9200","https://opensearch-node2:9200"]' # Define the OpenSearch nodes that OpenSearch Dashboards will query
    networks:
      - opensearch-net

  jaeger-collector:
    image: jaegertracing/jaeger-collector:latest
    ports:
      - "14269:14269"
      - "14268:14268"
      - "14267:14267"
      - "14250:14250"
      - "9411:9411"
    networks:
      - opensearch-net
    restart: on-failure
    environment:
      - SPAN_STORAGE_TYPE=opensearch
      - ES_TAGS_AS_FIELDS_ALL=true
      - ES_USERNAME=admin
      - ES_PASSWORD=admin
      - ES_TLS_SKIP_HOST_VERIFY=true
    command: [
      "--es.server-urls=https://opensearch-node1:9200",
      "--es.tls.enabled=true",
    ]
    depends_on:
      - opensearch-node1

  jaeger-agent:
    image: jaegertracing/jaeger-agent:latest
    hostname: jaeger-agent
    command: ["--reporter.grpc.host-port=jaeger-collector:14250"]
    ports:
      - "5775:5775/udp"
      - "6831:6831/udp"
      - "6832:6832/udp"
      - "5778:5778"
    networks:
      - opensearch-net
    restart: on-failure
    environment:
      - SPAN_STORAGE_TYPE=opensearch
    depends_on:
      - jaeger-collector

  hotrod:
    image: jaegertracing/example-hotrod:latest
    ports: 
      - "8080:8080"
    command: ["all"]
    environment:
      - JAEGER_AGENT_HOST=jaeger-agent
      - JAEGER_AGENT_PORT=6831
    networks:
      - opensearch-net
    depends_on:
      - jaeger-agent

volumes:
  opensearch-data1:
  opensearch-data2:

networks:
  opensearch-net:

----------------------------------------

TITLE: Creating Component Template with Index Aliases in OpenSearch
DESCRIPTION: This example demonstrates how to create a component template that includes index aliases, specifying settings for shards and custom routing.

LANGUAGE: json
CODE:
PUT _component_template/alias_template
{
  "template": {
    "settings" : {
        "number_of_shards" : 1
    },
    "aliases" : {
        "alias1" : {},
        "alias2" : {
            "filter" : {
                "term" : {"user.id" : "hamlet" }
            },
            "routing" : "shard-1"
        },
        "{index}-alias" : {} 
    }
  }
}

----------------------------------------

TITLE: Sample Response from Analyzer in OpenSearch
DESCRIPTION: This is an example of the response returned by the _analyze API, showing the tokens generated by the custom analyzer with the pattern_replace filter.

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "visit",
      "start_offset": 0,
      "end_offset": 5,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "us",
      "start_offset": 6,
      "end_offset": 8,
      "type": "<ALPHANUM>",
      "position": 1
    },
    {
      "token": "at",
      "start_offset": 9,
      "end_offset": 11,
      "type": "<ALPHANUM>",
      "position": 2
    },
    {
      "token": "[NUM]",
      "start_offset": 12,
      "end_offset": 17,
      "type": "<NUM>",
      "position": 3
    },
    {
      "token": "example",
      "start_offset": 18,
      "end_offset": 25,
      "type": "<ALPHANUM>",
      "position": 4
    },
    {
      "token": "st",
      "start_offset": 26,
      "end_offset": 28,
      "type": "<ALPHANUM>",
      "position": 5
    }
  ]
}

----------------------------------------

TITLE: Checking ML Task Status in OpenSearch
DESCRIPTION: GET request to check the status of a model registration or deployment task.

LANGUAGE: bash
CODE:
GET /_plugins/_ml/tasks/cVeMb4kBJ1eYAeTMFFgj

----------------------------------------

TITLE: Configuring DNS Lookup Discovery Mode in YAML
DESCRIPTION: Example YAML configuration for setting up DNS lookup discovery mode in peer forwarder.

LANGUAGE: yaml
CODE:
peer_forwarder:
  discovery_mode: dns
  domain_name: "data-prepper-cluster.my-domain.net"

----------------------------------------

TITLE: Creating a Mapping with date_nanos Field in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a mapping with a date field of type date_nanos using the strict_date_optional_time_nanos format.

LANGUAGE: json
CODE:
PUT testindex/_mapping
{
  "properties": {
      "date": {
        "type": "date_nanos",
        "format" : "strict_date_optional_time_nanos"
      }
    }
}

----------------------------------------

TITLE: Retrieving Next Batch of Scroll Results in OpenSearch
DESCRIPTION: This example shows how to use the scroll ID to retrieve the next batch of results in a scroll search, maintaining the scroll context for 10 minutes.

LANGUAGE: json
CODE:
GET _search/scroll
{
  "scroll": "10m",
  "scroll_id": "DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAAUWdmpUZDhnRFBUcWFtV21nMmFwUGJEQQ=="
}

----------------------------------------

TITLE: Join Operation with Custom Delimiter
DESCRIPTION: Example of using join() with a custom delimiter (hyphen) instead of the default comma. Shows the syntax for specifying an alternative delimiter in the function call.

LANGUAGE: json
CODE:
join("-", /source)

----------------------------------------

TITLE: PIT Segments Request Example
DESCRIPTION: Example request showing how to retrieve PIT segments information using specific PIT IDs.

LANGUAGE: json
CODE:
GET /_cat/pit_segments
{
    "pit_id": [
        "o463QQEPbXktaW5kZXgtMDAwMDAxFkhGN09fMVlPUkVPLXh6MUExZ1hpaEEAFjBGbmVEZHdGU1EtaFhhUFc4ZkR5cWcAAAAAAAAAAAEWaXBPNVJtZEhTZDZXTWFFR05waXdWZwEWSEY3T18xWU9SRU8teHoxQTFnWGloQQAA",
        "o463QQEPbXktaW5kZXgtMDAwMDAxFkhGN09fMVlPUkVPLXh6MUExZ1hpaEEAFjBGbmVEZHdGU1EtaFhhUFc4ZkR5cWcAAAAAAAAAAAIWaXBPNVJtZEhTZDZXTWFFR05waXdWZwEWSEY3T18xWU9SRU8teHoxQTFnWGloQQAA"
    ]
}

----------------------------------------

TITLE: Close Index Request Example
DESCRIPTION: Example request to close a specific index named 'sample-index' using the close index API endpoint.

LANGUAGE: json
CODE:
POST /sample-index/_close

----------------------------------------

TITLE: Maximum Aggregation Response Format
DESCRIPTION: Example response showing the structure of a maximum aggregation result, including metadata about the query execution and the maximum value found in the specified field.

LANGUAGE: json
CODE:
{
  "took": 17,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 4675,
      "relation": "eq"
    },
    "max_score": null,
    "hits": []
  },
  "aggregations": {
    "max_taxful_total_price": {
      "value": 2250
    }
  }
}

----------------------------------------

TITLE: Script Score Query - OpenSearch JSON
DESCRIPTION: Demonstrates a script_score query that multiplies the document's relevance score by a field value.

LANGUAGE: json
CODE:
GET testindex1/_search
{
  "query": {
    "script_score": {
      "query": {
        "match": { 
            "name": "John" 
        }
      },
      "script": {
        "source": "_score * doc['multiplier'].value"
      }
    }
  }
}

----------------------------------------

TITLE: Get All Messages Example Response
DESCRIPTION: Example response showing the structure of returned messages data including multiple message entries with their details.

LANGUAGE: json
CODE:
{
  "messages": [
    {
      "memory_id": "gW8Aa40BfUsSoeNTvOKI",
      "message_id": "BW8ha40BfUsSoeNT8-i3",
      "create_time": "2024-02-02T18:43:23.566994302Z",
      "input": "How do I make an interaction?",
      "prompt_template": "Hello OpenAI, can you answer this question?",
      "response": "Hello, this is OpenAI. Here is the answer to your question.",
      "origin": "MyFirstOpenAIWrapper",
      "additional_info": {
        "suggestion": "api.openai.com"
      }
    },
    {
      "memory_id": "gW8Aa40BfUsSoeNTvOKI",
      "message_id": "0m8ya40BfUsSoeNTj-pU",
      "create_time": "2024-02-02T19:01:32.113621539Z",
      "input": null,
      "prompt_template": null,
      "response": "Hello, this is OpenAI. Here is the answer to your question.",
      "origin": null,
      "additional_info": {
        "suggestion": "api.openai.com"
      }
    }
  ]
}

----------------------------------------

TITLE: Example Request for CAT cluster_manager API in OpenSearch
DESCRIPTION: An example GET request to the /_cat/cluster_manager endpoint with the 'v' parameter enabled for verbose output, which displays column headers.

LANGUAGE: json
CODE:
GET _cat/cluster_manager?v

----------------------------------------

TITLE: Analyzing Text with Shingle Analyzer
DESCRIPTION: Demonstrates how to analyze text using the configured shingle analyzer and shows the resulting tokens with their positions and offsets.

LANGUAGE: json
CODE:
GET /my-shingle-index/_analyze
{
  "analyzer": "my_shingle_analyzer",
  "text": "slow green turtle"
}

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "slow",
      "start_offset": 0,
      "end_offset": 4,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "slow green",
      "start_offset": 0,
      "end_offset": 10,
      "type": "shingle",
      "position": 0,
      "positionLength": 2
    },
    {
      "token": "green",
      "start_offset": 5,
      "end_offset": 10,
      "type": "<ALPHANUM>",
      "position": 1
    },
    {
      "token": "green turtle",
      "start_offset": 5,
      "end_offset": 17,
      "type": "shingle",
      "position": 1,
      "positionLength": 2
    },
    {
      "token": "turtle",
      "start_offset": 11,
      "end_offset": 17,
      "type": "<ALPHANUM>",
      "position": 2
    }
  ]
}

----------------------------------------

TITLE: Mixed-Level ACL Permissions Configuration
DESCRIPTION: Demonstrates how to configure mixed-level permissions where one user has write access while all authenticated users have read access using wildcards.

LANGUAGE: json
CODE:
{
  "permissions": {
    "read": {
        "users": ["*"]
    },
    "write": {
        "users": ["user-1"]
    },
  }
}

----------------------------------------

TITLE: Executing Data Prepper Shutdown API
DESCRIPTION: Example of how to trigger a graceful shutdown of Data Prepper using the shutdown API endpoint

LANGUAGE: bash
CODE:
curl -X POST http://localhost:4900/shutdown

----------------------------------------

TITLE: Configuring ML Inference Search Request Processor in OpenSearch
DESCRIPTION: This snippet shows the configuration for the ml_inference search request processor. It maps document fields to model inputs and outputs, specifically mapping the text input to the model's input field and the model's embedding output to the document's text_embedding field.

LANGUAGE: json
CODE:
PUT /_search/pipeline/my_knn_pipeline
{
  "request_processors": [
    {
      "ml_inference": {
        "model_id": "Sz-wFZQBUpPSu0bsJTBG",
        "input_map": [
          {
            "inputText": "ext.ml_inference.text"
          }
        ],
        "output_map": [
          {
            "text_embedding": "embedding"
          }
        ]
      }
    }
  ]
}

----------------------------------------

TITLE: Dictionary Decompounder Analysis Result in OpenSearch
DESCRIPTION: This snippet shows the response from the _analyze API, demonstrating how the dictionary_decompounder filter splits the compound word 'slowgreenturtleswim' into its constituent parts based on the predefined dictionary.

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "slowgreenturtleswim",
      "start_offset": 0,
      "end_offset": 19,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "slow",
      "start_offset": 0,
      "end_offset": 19,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "green",
      "start_offset": 0,
      "end_offset": 19,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "turtle",
      "start_offset": 0,
      "end_offset": 19,
      "type": "<ALPHANUM>",
      "position": 0
    }
  ]
}

----------------------------------------

TITLE: Creating Index with Custom Normalizer in OpenSearch
DESCRIPTION: Creates a new index with a custom normalizer that applies ASCII folding and lowercase filters. The normalizer is applied to a keyword field named 'approach'.

LANGUAGE: json
CODE:
PUT /sample-index
{
  "settings": {
    "analysis": {
      "normalizer": {
        "normalized_keyword": {
          "type": "custom",
          "char_filter": [],
          "filter": [ "asciifolding", "lowercase" ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "approach": {
        "type": "keyword",
        "normalizer": "normalized_keyword"
      }
    }
  }
}

----------------------------------------

TITLE: CJK Width Analysis Response
DESCRIPTION: Shows the normalized tokens generated by the CJK width analyzer, including converted ASCII and katakana characters.

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "Tokyo",
      "start_offset": 0,
      "end_offset": 5,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "2024",
      "start_offset": 6,
      "end_offset": 10,
      "type": "<NUM>",
      "position": 1
    },
    {
      "token": "",
      "start_offset": 11,
      "end_offset": 15,
      "type": "<KATAKANA>",
      "position": 2
    }
  ]
}

----------------------------------------

TITLE: Reindexing Data to match_only_text Field - OpenSearch JSON
DESCRIPTION: Example showing how to reindex data from a source index to a destination index with match_only_text field type.

LANGUAGE: json
CODE:
POST _reindex
{
   "source": {
      "index":"source"
   },
   "dest": {
      "index":"destination"
   }
}

----------------------------------------

TITLE: Querying Rank Feature Fields in OpenSearch
DESCRIPTION: This snippet demonstrates how to use a rank feature query to search for chess players based on their age and rating in OpenSearch. The query uses a bool should clause to combine both rank features.

LANGUAGE: json
CODE:
GET chessplayers/_search
{
  "query": {
    "bool": {
      "should": [
        {
          "rank_feature": {
            "field": "rating"
          }
        },
        {
          "rank_feature": {
            "field": "age"
          }
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Retrieving Thread Pool Information for All Nodes in OpenSearch
DESCRIPTION: This example demonstrates how to retrieve thread pool information for all nodes in the cluster. The 'v' parameter enables verbose mode to display column headers.

LANGUAGE: json
CODE:
GET _cat/thread_pool?v

----------------------------------------

TITLE: Boolean operators with + and -
DESCRIPTION: Using + and - operators to specify required, optional, and excluded terms in a query_string query.

LANGUAGE: json
CODE:
GET /testindex/_search
{
 "query": {
    "query_string": {
      "query": "title: (gone +wind -turbines)"
    }
  }
}

----------------------------------------

TITLE: Configuring Conditional Grok Processing in YAML
DESCRIPTION: Example of how to configure the Grok processor to run conditionally based on the 'type' field of incoming events. It demonstrates separate patterns for IPv4 and IPv6 addresses.

LANGUAGE: yaml
CODE:
processor:
  - grok:
      grok_when: '/type == "ipv4"'
        match:
          message: ['%{IPV4:clientip} %{WORD:request} %{POSINT:bytes}']
  - grok:
      grok_when: '/type == "ipv6"'
        match:
          message: ['%{IPV6:clientip} %{WORD:request} %{POSINT:bytes}']

----------------------------------------

TITLE: Creating a Composite Monitor
DESCRIPTION: API request to create a composite monitor with two delegate monitors and chained alert triggers using AND/OR conditions.

LANGUAGE: json
CODE:
POST _plugins/_alerting/workflows
{
	"last_update_time": 1679468231835,
	"owner": "alerting",
	"type": "workflow",
	"schedule": {
		"period": {
			"interval": 1,
			"unit": "MINUTES"
		}
	},
	"inputs": [{
		"composite_input": {
			"sequence": {
				"delegates": [{
						"order": 1,
						"monitor_id": "grsbCIcBvEHfkjWFeCqb"
					},
					{
						"order": 2,
						"monitor_id": "agasbCIcBvEHfkjWFeCqa"
					}
				]
			}
		}
	}],
	"enabled_time": 1679468231835,
	"enabled": true,
	"workflow_type": "composite",
	"name": "scale_up",
	"triggers": [{
			"chained_alert_trigger": {
				"id": "m1ANDm2",
				"name": "jnkjn",
				"severity": "1",
				"condition": {
					"script": {
						"source": "(monitor[id=grsbCIcBvEHfkjWFeCqb] && monitor[id=agasbCIcBvEHfkjWFeCqa])",
						"lang": "painless"
					}
				}
			}
		}
	]
}

----------------------------------------

TITLE: Setting Default Replication Type in OpenSearch YAML Configuration
DESCRIPTION: This snippet demonstrates how to set the default replication type for newly created cluster indexes in the opensearch.yml configuration file.

LANGUAGE: yaml
CODE:
cluster.indices.replication.strategy: 'SEGMENT'

----------------------------------------

TITLE: List Indices with Token Pagination Example
DESCRIPTION: Example request showing how to retrieve paginated index information using next_token parameter

LANGUAGE: json
CODE:
GET _list/indices/<index>?v&next_token=token

----------------------------------------

TITLE: Explaining an Index Rollup Job in OpenSearch
DESCRIPTION: This snippet demonstrates how to retrieve detailed metadata and progress information about an index rollup job using a GET request with the rollup_id and the _explain action.

LANGUAGE: json
CODE:
GET _plugins/_rollup/jobs/<rollup_id>/_explain

----------------------------------------

TITLE: Search With Pipeline
DESCRIPTION: Executes a search operation using the split processor pipeline to transform the results.

LANGUAGE: json
CODE:
GET /my_index/_search?search_pipeline=my_pipeline

----------------------------------------

TITLE: OpenSearch YAML Configuration for Certificates
DESCRIPTION: Example YAML configuration for specifying certificate paths and distinguished names in OpenSearch.

LANGUAGE: yaml
CODE:
plugins.security.ssl.transport.pemcert_filepath: node1.pem
plugins.security.ssl.transport.pemkey_filepath: node1-key.pem
plugins.security.ssl.transport.pemtrustedcas_filepath: root-ca.pem
plugins.security.ssl.transport.enforce_hostname_verification: false
plugins.security.ssl.http.enabled: true
plugins.security.ssl.http.pemcert_filepath: node1.pem
plugins.security.ssl.http.pemkey_filepath: node1-key.pem
plugins.security.ssl.http.pemtrustedcas_filepath: root-ca.pem
plugins.security.authcz.admin_dn:
  - 'CN=A,OU=UNIT,O=ORG,L=TORONTO,ST=ONTARIO,C=CA'
plugins.security.nodes_dn:
  - 'CN=node1.dns.a-record,OU=UNIT,O=ORG,L=TORONTO,ST=ONTARIO,C=CA'
  - 'CN=node2.dns.a-record,OU=UNIT,O=ORG,L=TORONTO,ST=ONTARIO,C=CA'

----------------------------------------

TITLE: Configuring File Sink in OpenSearch Pipeline
DESCRIPTION: Demonstrates basic configuration of a file sink in an OpenSearch pipeline. The example shows how to specify the output file path in the pipeline configuration.

LANGUAGE: yaml
CODE:
sample-pipeline:
  sink:
    - file:
        path: path/to/output-file

----------------------------------------

TITLE: Rolling Over a Data Stream in OpenSearch
DESCRIPTION: Demonstrates how to roll over a data stream in OpenSearch using specified conditions such as maximum age, document count, and primary shard size.

LANGUAGE: json
CODE:
POST my-data-stream/_rollover
{
  "conditions": {
    "max_age": "5d",
    "max_docs": 500,
    "max_primary_shard_size": "100gb"
  }
}

----------------------------------------

TITLE: Configuring Root Agent ID for OpenSearch Assistant using JSON API
DESCRIPTION: Use a PUT request to configure the root agent_id for OpenSearch Assistant through the REST API. This sets up the root chatbot agent in OpenSearch Dashboards.

LANGUAGE: json
CODE:
PUT .plugins-ml-config/_doc/os_chat
{
    "type":"os_chat_root_agent",
    "configuration":{
        "agent_id": "your root agent id"
    }
}

----------------------------------------

TITLE: Creating Custom Russian Analyzer in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a custom Russian analyzer with specific token filters and apply it to a text field in an OpenSearch index.

LANGUAGE: json
CODE:
PUT /russian-index
{
  "settings": {
    "analysis": {
      "filter": {
        "russian_stop": {
          "type": "stop",
          "stopwords": "_russian_"
        },
        "russian_stemmer": {
          "type": "stemmer",
          "language": "russian"
        },
        "russian_keywords": {
          "type": "keyword_marker",
          "keywords": []
        }
      },
      "analyzer": {
        "russian_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "russian_stop",
            "russian_keywords",
            "russian_stemmer"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "russian_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Creating Index with Custom French Elision Analyzer in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a new index named 'french_texts' with a custom analyzer that includes a French elision filter. It configures the elision filter with specific articles and sets up the analyzer to use this filter along with lowercase tokenization.

LANGUAGE: json
CODE:
PUT /french_texts
{
  "settings": {
    "analysis": {
      "filter": {
        "french_elision": {
          "type": "elision",
          "articles": [ "l", "t", "m", "d", "n", "s", "j" ]
        }
      },
      "analyzer": {
        "french_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": ["lowercase", "french_elision"]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "text": {
        "type": "text",
        "analyzer": "french_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Bulk Data Upload Using cURL
DESCRIPTION: Example of how to upload bulk data using cURL command line tool, showing headers and authentication requirements.

LANGUAGE: json
CODE:
curl -H "Content-Type: application/x-ndjson" -POST https://localhost:9200/data/_bulk -u 'admin:admin' --insecure --data-binary "@data.json"

----------------------------------------

TITLE: Split Event Input Example in JSON
DESCRIPTION: Example JSON input showing the format of data before processing by the split-event processor.

LANGUAGE: json
CODE:
{"query" : "open source", "some_other_field" : "abc" }

----------------------------------------

TITLE: Connecting to OpenSearch without Security Plugin
DESCRIPTION: JavaScript code for creating a client object to connect to OpenSearch without the Security plugin.

LANGUAGE: javascript
CODE:
var host = "localhost";
var protocol = "http";
var port = 9200;

var { Client } = require("@opensearch-project/opensearch");
var client = new Client({
  node: protocol + "://" + host + ":" + port
});

----------------------------------------

TITLE: Creating a Snapshot with Specific Settings
DESCRIPTION: JSON request to create a snapshot with custom settings for included indices and other options.

LANGUAGE: json
CODE:
PUT /_snapshot/my-repository/2
{
  "indices": "opensearch-dashboards*,my-index*,-my-index-2016",
  "ignore_unavailable": true,
  "include_global_state": false,
  "partial": false
}

----------------------------------------

TITLE: Specifying Index Analyzer for a Field in OpenSearch
DESCRIPTION: This JSON snippet demonstrates how to create index mappings with a specified analyzer for a text field. It uses the 'simple' analyzer for the 'text_entry' field.

LANGUAGE: json
CODE:
PUT testindex
{
  "mappings": {
    "properties": {
      "text_entry": {
        "type": "text",
        "analyzer": "simple"
      }
    }
  }
}

----------------------------------------

TITLE: Testing IP2Geo Pipeline in OpenSearch
DESCRIPTION: This snippet shows how to test the IP2Geo pipeline using the simulate API before ingesting actual documents.

LANGUAGE: json
CODE:
POST _ingest/pipeline/my-pipeline/_simulate
{
  "docs": [
    {
      "_index": "testindex1",
      "_id": "1",
      "_source": {
        "ip": "172.0.0.1"
      }
    }
  ]
}

----------------------------------------

TITLE: Profiling a search query with human-readable timing
DESCRIPTION: Executes a search query with profiling enabled and requests human-readable timing information in the response.

LANGUAGE: json
CODE:
GET /testindex/_search?human=true
{
  "profile": true,
  "query" : {
    "match" : { "title" : "wind" }
  }
}

----------------------------------------

TITLE: Creating a New User for Anomaly Detection in OpenSearch
DESCRIPTION: This code snippet demonstrates how to create a new user for anomaly detection and map them to the 'anomaly_full_access' role using the OpenSearch Security API.

LANGUAGE: bash
CODE:
curl -XPUT -k -u 'admin:<custom-admin-password>' 'https://localhost:9200/_plugins/_security/api/internalusers/anomalyuser' -H 'Content-Type: application/json' -d '{"password":"password"}'

LANGUAGE: bash
CODE:
curl -XPUT -k -u 'admin:<custom-admin-password>' -H 'Content-Type: application/json' 'https://localhost:9200/_plugins/_security/api/rolesmapping/anomaly_full_access' -d '{"users" : ["anomalyuser"]}'

----------------------------------------

TITLE: Installing OpenSearch Plugin Using Maven Coordinates
DESCRIPTION: Command syntax for installing an OpenSearch plugin using Maven coordinates format.

LANGUAGE: bash
CODE:
bin/opensearch-plugin install <groupId>:<artifactId>:<version>

----------------------------------------

TITLE: Analyzing Text with Detailed Explanation in OpenSearch
DESCRIPTION: Shows how to analyze text with additional parameters to examine the keyword marker filter's impact.

LANGUAGE: json
CODE:
GET /my_index/_analyze
{
  "analyzer": "custom_analyzer",
  "text": "This is an OpenSearch example demonstrating keyword marker.",
  "explain": true,
  "attributes": "keyword"
}

----------------------------------------

TITLE: Example Response for OpenSearch ML Model Deletion
DESCRIPTION: The response to a successful model deletion request, including details about the operation such as the index, version, and shard information.

LANGUAGE: json
CODE:
{
  "_index" : ".plugins-ml-model",
  "_id" : "MzcIJX8BA7mbufL6DOwl",
  "_version" : 2,
  "result" : "deleted",
  "_shards" : {
    "total" : 2,
    "successful" : 2,
    "failed" : 0
  },
  "_seq_no" : 27,
  "_primary_term" : 18
}

----------------------------------------

TITLE: Performing Bulk Operations in OpenSearch using Rust
DESCRIPTION: Perform multiple operations at once using the bulk() function in OpenSearch.

LANGUAGE: rust
CODE:
let mut body: Vec<JsonBody<_>> = Vec::with_capacity(4);

body.push(json!({"index": {"_id": "2"}}).into());
body.push(json!({
    "id": 2,
    "title": "Interstellar",
    "director": "Christopher Nolan",
    "year": "2014"
}).into());

body.push(json!({"index": {"_id": "3"}}).into());
body.push(json!({
    "id": 3,
    "title": "Star Trek Beyond",
    "director": "Justin Lin",
    "year": "2015"
}).into());

let response = client
    .bulk(BulkParts::Index("movies"))
    .body(body)
    .send()
    .await?;

----------------------------------------

TITLE: OpenSearch Built-in Analyzers Example Output
DESCRIPTION: Example output demonstration showing how different built-in analyzers process the text 'It's fun to contribute a brand-new PR or 2 to OpenSearch!' Each analyzer applies different tokenization and normalization rules.

LANGUAGE: markdown
CODE:
[`it's`, `fun`, `to`, `contribute`, `a`,`brand`, `new`, `pr`, `or`, `2`, `to`, `opensearch`]

----------------------------------------

TITLE: Retrieving frame-ancestors from CSP rules using cURL
DESCRIPTION: cURL command to get the current frame-ancestors directive from CSP rules in OpenSearch Dashboards.

LANGUAGE: bash
CODE:
curl '{osd endpoint}/api/appconfig/csp.rules.frame-ancestors'

----------------------------------------

TITLE: Docker Compose configuration for cross-cluster search setup
DESCRIPTION: Docker Compose YAML file for setting up two single-node OpenSearch clusters on the same network for cross-cluster search testing.

LANGUAGE: yaml
CODE:
version: '3'
services:
  opensearch-ccs-node1:
    image: opensearchproject/opensearch:{{site.opensearch_version}}
    container_name: opensearch-ccs-node1
    environment:
      - cluster.name=opensearch-ccs-cluster1
      - discovery.type=single-node
      - bootstrap.memory_lock=true # along with the memlock settings below, disables swapping
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m" # minimum and maximum Java heap size, recommend setting both to 50% of system RAM
      - "OPENSEARCH_INITIAL_ADMIN_PASSWORD=<custom-admin-password>" # The initial admin password used by the demo configuration
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - opensearch-data1:/usr/share/opensearch/data
    ports:
      - 9200:9200
      - 9600:9600 # required for Performance Analyzer
    networks:
      - opensearch-net

  opensearch-ccs-node2:
    image: opensearchproject/opensearch:{{site.opensearch_version}}
    container_name: opensearch-ccs-node2
    environment:
      - cluster.name=opensearch-ccs-cluster2
      - discovery.type=single-node
      - bootstrap.memory_lock=true # along with the memlock settings below, disables swapping
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m" # minimum and maximum Java heap size, recommend setting both to 50% of system RAM
      - "OPENSEARCH_INITIAL_ADMIN_PASSWORD=<custom-admin-password>" # The initial admin password used by the demo configuration
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - opensearch-data2:/usr/share/opensearch/data
    ports:
      - 9250:9200
      - 9700:9600 # required for Performance Analyzer
    networks:
      - opensearch-net

volumes:
  opensearch-data1:
  opensearch-data2:

networks:
  opensearch-net:

----------------------------------------

TITLE: Executing CAT nodeattrs Request with Verbose Output
DESCRIPTION: This example demonstrates how to make a GET request to the CAT nodeattrs endpoint with verbose output enabled. The 'v' parameter is set to display column headers in the response.

LANGUAGE: json
CODE:
GET _cat/nodeattrs?v

----------------------------------------

TITLE: Data Prepper Pipeline Configuration
DESCRIPTION: YAML configuration for Data Prepper pipeline to process and emit metric signals to OpenSearch

LANGUAGE: yaml
CODE:
otel-metrics-pipeline:
  workers: 8
  delay: 3000
  source:
    otel_metrics_source:
      health_check_service: true
      ssl: false
  buffer:
    bounded_blocking:
      buffer_size: 1024
      batch_size: 1024
  processor:
    - otel_metrics:
        calculate_histogram_buckets: true
        calculate_exponential_histogram_buckets: true
        exponential_histogram_max_allowed_scale: 10
        flatten_attributes: false
  sink:
    - opensearch:
        hosts: ["https://opensearch-node1:9200"]
        username: "admin"
        password: "my_%New%_passW0rd!@#"
        insecure: true
        index_type: custom
        template_file: "templates/ss4o_metrics.json"
        index: ss4o_metrics-otel-%{yyyy.MM.dd}
        bulk_size: 4

----------------------------------------

TITLE: Delete Index Endpoint Definition
DESCRIPTION: The basic endpoint structure for deleting an index in OpenSearch.

LANGUAGE: json
CODE:
DELETE /<index-name>

----------------------------------------

TITLE: SES Permission Policy Configuration
DESCRIPTION: JSON policy configuration for granting Amazon SES permissions to the Lambda function for sending emails.

LANGUAGE: json
CODE:
{
"Effect": "Allow",
"Action": [
      "ses:SendEmail",
      "ses:SendRawEmail"
            ],
"Resource": "arn:aws:ses:us-west-2:555555511111:identity/username@amazon.com"
}

----------------------------------------

TITLE: Configuring SAML Subject Key in OpenSearch Dashboards YAML
DESCRIPTION: This configuration sets the subject_key for SAML authentication. Use this to specify which SAML attribute should be used as the username in OpenSearch Dashboards.

LANGUAGE: yaml
CODE:
saml:
  ...
  http_authenticator:
    type: 'saml'
    challenge: true
    config:
      ...
      subject_key: preferred_username

----------------------------------------

TITLE: Configuring Greek Analyzer with Stem Exclusion
DESCRIPTION: Demonstrates how to create a Greek analyzer with stem exclusion for specific words.

LANGUAGE: json
CODE:
PUT index_with_stem_exclusion_greek_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "stem_exclusion_greek_analyzer": {
          "type": "greek",
          "stem_exclusion": ["", ""]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Geoshape query using pre-indexed shape in OpenSearch
DESCRIPTION: Searches for documents whose geoshapes are within the pre-indexed 'search_triangle' shape.

LANGUAGE: json
CODE:
GET /testindex/_search
{
  "query": {
    "bool": {
      "must": {
        "match_all": {}
      },
      "filter": {
        "geo_shape": {
          "location": {
            "indexed_shape": {
              "index": "pre-indexed-shapes",
              "id": "search_triangle",
              "path": "boundaries"
            },
            "relation": "WITHIN"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Training K-means Model Synchronously
DESCRIPTION: Demonstrates how to train a k-means model synchronously using the ML Commons API. The request specifies parameters for 3 centroids, 10 iterations, and cosine distance type, targeting the iris_data index.

LANGUAGE: json
CODE:
POST /_plugins/_ml/_train/kmeans
{
    "parameters": {
        "centroids": 3,
        "iterations": 10,
        "distance_type": "COSINE"
    },
    "input_query": {
        "_source": ["petal_length_in_cm", "petal_width_in_cm"],
        "size": 10000
    },
    "input_index": [
        "iris_data"
    ]
}

----------------------------------------

TITLE: Creating Index with Synonym Filter (Solr Format) in OpenSearch
DESCRIPTION: This example creates a new index named 'my-synonym-index' and configures an analyzer with a synonym filter using the default Solr rule format. It demonstrates how to set up synonym rules for words like 'car', 'quick', and 'laptop'.

LANGUAGE: json
CODE:
PUT /my-synonym-index
{
  "settings": {
    "analysis": {
      "filter": {
        "my_synonym_filter": {
          "type": "synonym",
          "synonyms": [
            "car, automobile",
            "quick, fast, speedy",
            "laptop => computer"
          ]
        }
      },
      "analyzer": {
        "my_synonym_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "my_synonym_filter"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Starting Replication with Security Roles
DESCRIPTION: JSON configuration for initiating replication between clusters with security role specifications for both leader and follower clusters.

LANGUAGE: json
CODE:
{
   "leader_alias": "my-connection-alias",
   "leader_index": "leader-01",
   "use_roles":{
      "leader_cluster_role": "all_access",
      "follower_cluster_role": "all_access"
   }
}

----------------------------------------

TITLE: Force Merge API Endpoints
DESCRIPTION: Basic endpoint definitions for the force merge API, showing both general and index-specific paths.

LANGUAGE: json
CODE:
POST /_forcemerge
POST /<index>/_forcemerge/

----------------------------------------

TITLE: Enabling Task Resource Consumers in JSON
DESCRIPTION: Shows how to enable task resource consumers for logging CPU time and memory utilization of search tasks using the Cluster Settings API.

LANGUAGE: json
CODE:
PUT _cluster/settings
{
  "persistent" : {
    "task_resource_consumers.enabled" : "true"
  }
}

----------------------------------------

TITLE: Specifying Settings During Index Rollover in OpenSearch
DESCRIPTION: Demonstrates how to specify additional index settings or override template settings during a rollover operation for an index alias in OpenSearch.

LANGUAGE: json
CODE:
POST my-alias/_rollover
{
  "settings": {
    "index.number_of_shards": 4
  }
}

----------------------------------------

TITLE: Configuring CSV Pipeline with User-Specified Columns in YAML
DESCRIPTION: Example configuration for processing CSV data with manually specified column names using a file source. The processor will parse CSV data and map it to defined column names, automatically generating names for any additional columns.

LANGUAGE: yaml
CODE:
csv-pipeline:
  source:
    file:
      path: "/full/path/to/ingest.csv"
      record_type: "event"
  processor:
    - csv:
        column_names: ["col1", "col2"]
  sink:
    - stdout:

----------------------------------------

TITLE: Basic Search Without Pipeline
DESCRIPTION: Performs a basic search operation without using the split processor pipeline.

LANGUAGE: json
CODE:
GET /my_index/_search

----------------------------------------

TITLE: Creating Text to Visualization Workflow
DESCRIPTION: JSON request to create a workflow template for text-to-visualization agents including Claude connector and tools configuration.

LANGUAGE: json
CODE:
POST /_plugins/_flow_framework/workflow
{
  "name": "Text to visualization agents",
  "description": "This template is to create all Agents required for text to visualization",
  "use_case": "REGISTER_AGENTS",
  "version": {
    "template": "1.0.0",
    "compatibility": [
      "2.18.0",
      "3.0.0"
    ]
  },
  "workflows": {
    "provision": {
      "user_params": {},
      "nodes": [...]
    }
  }
}

----------------------------------------

TITLE: Successful Deprovision Response
DESCRIPTION: Response returned when workflow deprovisioning is successful, containing the workflow ID.

LANGUAGE: json
CODE:
{
  "workflow_id" : "8xL8bowB8y25Tqfenm50"
}

----------------------------------------

TITLE: Excluding Source Field Example
DESCRIPTION: Example of retrieving a document while excluding the _source field from the response.

LANGUAGE: json
CODE:
GET test-index/_doc/0?_source=false

----------------------------------------

TITLE: Querying Multiple Filters with OpenSearch
DESCRIPTION: Example of a filters aggregation query that creates buckets for HTTP 200 responses and OSX operating systems, with an additional bucket for non-matching documents. Includes a nested aggregation to calculate average bytes.

LANGUAGE: json
CODE:
{
  "size": 0,
  "aggs": {
    "200_os": {
      "filters": {
        "other_bucket": true,
        "filters": [
          {
            "term": {
              "response.keyword": "200"
            }
          },
          {
            "term": {
              "machine.os.keyword": "osx"
            }
          }
        ]
      },
      "aggs": {
        "avg_amount": {
          "avg": {
            "field": "bytes"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Transport Layer Impersonation in OpenSearch YAML
DESCRIPTION: Configuration settings in opensearch.yml to enable transport layer impersonation, specifying which DN certificates can impersonate specific users.

LANGUAGE: yaml
CODE:
plugins.security.authcz.impersonation_dn:
  "CN=spock,OU=client,O=client,L=Test,C=DE":
    - worf

----------------------------------------

TITLE: Setting Cache Store Name in YAML Configuration
DESCRIPTION: Configures the cache store name to use the OpenSearch-provided tiered spillover cache implementation.

LANGUAGE: yaml
CODE:
indices.requests.cache.store.name: tiered_spillover

----------------------------------------

TITLE: Creating Test Document - OpenSearch JSON
DESCRIPTION: Creates an index with a single document containing a name and multiplier field.

LANGUAGE: json
CODE:
PUT testindex1/_doc/1
{
  "name": "John Doe",
  "multiplier": 0.5
}

----------------------------------------

TITLE: Scripting with Unsigned Long Fields
DESCRIPTION: Shows how to use scripting with unsigned_long fields using BigInteger class.

LANGUAGE: json
CODE:
POST _search
{
  "query": {
    "bool": {
      "filter": {
        "script": {
          "script": "BigInteger amount = doc['counter'].value; return amount.compareTo(BigInteger.ZERO) > 0;"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Restoring Snapshot in OpenSearch
DESCRIPTION: This JSON POST request shows how to restore a specific snapshot from a repository in OpenSearch, excluding security-related indices and global state.

LANGUAGE: json
CODE:
POST _snapshot/my-repository/my-snapshot/_restore
{
  "indices": "-.opendistro_security",
  "include_global_state": false
}

----------------------------------------

TITLE: Creating Custom Spanish Analyzer in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a custom Spanish analyzer with specific token filters and apply it to a text field in an OpenSearch index.

LANGUAGE: json
CODE:
PUT /spanish-index
{
  "settings": {
    "analysis": {
      "filter": {
        "spanish_stop": {
          "type": "stop",
          "stopwords": "_spanish_"
        },
        "spanish_stemmer": {
          "type": "stemmer",
          "language": "light_spanish"
        },
        "spanish_keywords": {
          "type": "keyword_marker",
          "keywords": []
        }
      },
      "analyzer": {
        "spanish_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "spanish_stop",
            "spanish_keywords",
            "spanish_stemmer"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "spanish_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Searching Normalized Field - Accent Query
DESCRIPTION: Shows how normalization allows matching regardless of diacritics and case.

LANGUAGE: json
CODE:
GET /sample-index/_search
{
  "query": {
    "term": {
      "approach": "Nave"
    }
  }
}

----------------------------------------

TITLE: Significant Text Query with Background Filter
DESCRIPTION: Advanced query showing how to use a background filter to narrow the scope of statistical analysis to specific documents, in this case filtering by speaker.

LANGUAGE: json
CODE:
GET shakespeare/_search
{
  "query": {
    "match": {
      "text_entry": "breathe"
    }
  },
  "aggregations": {
    "my_sample": {
      "sampler": {
        "shard_size": 100
      },
      "aggregations": {
        "keywords": {
          "significant_text": {
            "field": "text_entry",
            "background_filter": {
              "term": {
                "speaker": "JOHN OF GAUNT"
              }
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Simplified Source Field Selection
DESCRIPTION: Shorter notation for including specific source fields in the response.

LANGUAGE: json
CODE:
GET test-index/_doc/0?_source=*.id

----------------------------------------

TITLE: Querying OpenSearch Cluster Settings
DESCRIPTION: API requests to view current cluster settings, including both default and non-default settings.

LANGUAGE: json
CODE:
GET _cluster/settings?include_defaults=true

LANGUAGE: json
CODE:
GET _cluster/settings

----------------------------------------

TITLE: Example Node Usage API Response in OpenSearch
DESCRIPTION: Sample response showing node usage statistics including REST action counts, timestamps, and cluster information.

LANGUAGE: json
CODE:
{
  "_nodes" : {
    "total" : 1,
    "successful" : 1,
    "failed" : 0
  },
  "cluster_name" : "opensearch-cluster",
  "nodes" : {
    "t7uqHu4SSuWObK3ElkCRfw" : {
      "timestamp" : 1665695174312,
      "since" : 1663994849643,
      "rest_actions" : {
        "opendistro_get_rollup_action" : 3,
        "nodes_usage_action" : 1,
        "list_dangling_indices" : 1,
        "get_index_template_action" : 258,
        "nodes_info_action" : 152665,
        "get_mapping_action" : 259,
        "get_data_streams_action" : 12,
        "cat_indices_action" : 6,
        "get_indices_action" : 3,
        "ism_explain_action" : 7,
        "nodes_reload_action" : 1,
        "get_policy_action" : 3,
        "PerformanceAnalyzerClusterConfigAction" : 2,
        "index_policy_action" : 1,
        "rank_eval_action" : 3,
        "search_action" : 592,
        "get_aliases_action" : 258,
        "document_mget_action" : 2,
        "document_get_action" : 30,
        "count_action" : 1,
        "main_action" : 1
      },
      "aggregations" : { }
    }
  }
}

----------------------------------------

TITLE: Creating Index with Uppercase Filter - OpenSearch JSON
DESCRIPTION: Creates a new index with a custom analyzer that includes an uppercase filter. The analyzer first applies lowercase filter and then uppercase filter to standardized tokens.

LANGUAGE: json
CODE:
PUT /uppercase_example
{
  "settings": {
    "analysis": {
      "filter": {
        "uppercase_filter": {
          "type": "uppercase"
        }
      },
      "analyzer": {
        "uppercase_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "uppercase_filter"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Adding Default Timestamp to Events in OpenSearch Data Prepper (YAML)
DESCRIPTION: This configuration adds a default timestamp in the '@timestamp' field to all events using the date processor.

LANGUAGE: yaml
CODE:
- date:
    from_time_received: true
    destination: "@timestamp"

----------------------------------------

TITLE: Creating Custom Galician Analyzer
DESCRIPTION: Detailed configuration for creating a custom Galician analyzer with specific token filters and tokenizer settings.

LANGUAGE: json
CODE:
PUT /galician-index
{
  "settings": {
    "analysis": {
      "filter": {
        "galician_stop": {
          "type": "stop",
          "stopwords": "_galician_"
        },
        "galician_stemmer": {
          "type": "stemmer",
          "language": "galician"
        },
        "galician_keywords": {
          "type": "keyword_marker",
          "keywords": []
        }
      },
      "analyzer": {
        "galician_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "galician_stop",
            "galician_keywords",
            "galician_stemmer"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "galician_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Creating an Index with Decimal Digit Filter in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a new index named 'my_index' with a custom analyzer that includes the decimal_digit filter. The analyzer is configured to use the standard tokenizer followed by the decimal_digit filter.

LANGUAGE: json
CODE:
PUT /my_index
{
  "settings": {
    "analysis": {
      "filter": {
        "my_decimal_digit_filter": {
          "type": "decimal_digit"
        }
      },
      "analyzer": {
        "my_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": ["my_decimal_digit_filter"]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Basic Italian Analyzer in OpenSearch
DESCRIPTION: Basic configuration to apply the built-in Italian analyzer to a text field in an OpenSearch index mapping.

LANGUAGE: json
CODE:
PUT /italian-index
{
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "italian"
      }
    }
  }
}

----------------------------------------

TITLE: CSV Processor Intermediate JSON Output
DESCRIPTION: Example of intermediate JSON output after initial CSV processing with header information.

LANGUAGE: json
CODE:
{"header": "a,b,c", "message": "1,2,3"}

----------------------------------------

TITLE: Analyzing Text with Greek Analyzer
DESCRIPTION: Example of analyzing Greek text and generating tokens using the configured analyzer.

LANGUAGE: json
CODE:
POST /greek-index/_analyze
{
  "field": "content",
  "text": "     .     123456."
}

----------------------------------------

TITLE: Indexing Geopoint as Latitude-Longitude Object
DESCRIPTION: Shows how to index a geopoint using an object with explicit lat/lon properties.

LANGUAGE: json
CODE:
PUT testindex1/_doc/1
{
  "point": { 
    "lat": 40.71,
    "lon": 74.00
  }
}

----------------------------------------

TITLE: Get All Messages Example Request
DESCRIPTION: Example request showing how to retrieve all messages for a specific memory ID.

LANGUAGE: json
CODE:
GET /_plugins/_ml/memory/gW8Aa40BfUsSoeNTvOKI/messages

LANGUAGE: json
CODE:
POST /_plugins/_ml/message/_search
{
  "query": {
    "match_all": {}
  },
  "size": 1000
}

----------------------------------------

TITLE: Executing Painless Script with Filter Context in OpenSearch
DESCRIPTION: This example demonstrates how to execute a Painless script using the filter context. The script determines if a student is eligible to graduate with honors based on GPA.

LANGUAGE: json
CODE:
POST /_scripts/painless/_execute
{
  "script": {
    "source": "doc['grad'].value == true && doc['gpa'].value >= params.min_honors_gpa",
    "params": {
      "min_honors_gpa": 3.5
    }
  },
  "context": "filter",
  "context_setup": {
    "index": "testindex1",
    "document": {
      "grad": true,
      "gpa": 3.79
    }
  }
}

----------------------------------------

TITLE: Analyzing Text with Uppercase Filter - OpenSearch JSON
DESCRIPTION: Demonstrates how to analyze text using the configured uppercase analyzer. Shows both the analysis request and response with generated uppercase tokens.

LANGUAGE: json
CODE:
GET /uppercase_example/_analyze
{
  "analyzer": "uppercase_analyzer",
  "text": "OpenSearch is powerful"
}

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "OPENSEARCH",
      "start_offset": 0,
      "end_offset": 10,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "IS",
      "start_offset": 11,
      "end_offset": 13,
      "type": "<ALPHANUM>",
      "position": 1
    },
    {
      "token": "POWERFUL",
      "start_offset": 14,
      "end_offset": 22,
      "type": "<ALPHANUM>",
      "position": 2
    }
  ]
}

----------------------------------------

TITLE: Registering an Externally Hosted Model in OpenSearch
DESCRIPTION: JSON request to register an external model using a connector and model group.

LANGUAGE: json
CODE:
POST /_plugins/_ml/models/_register
{
    "name": "openAI-gpt-3.5-turbo",
    "function_name": "remote",
    "model_group_id": "1jriBYsBq7EKuKzZX131",
    "description": "test model",
    "connector_id": "a1eMb4kBJ1eYAeTMAljY"
}

----------------------------------------

TITLE: Executing Diversified Sampler Query in OpenSearch
DESCRIPTION: Example query demonstrating how to use the diversified_sampler aggregation with shard_size and field parameters, combined with a terms aggregation. The query targets the opensearch_dashboards_sample_data_logs index.

LANGUAGE: json
CODE:
{
  "size": 0,
  "aggs": {
    "sample": {
      "diversified_": {
        "shard_size": 1000,
        "field": "response.keyword"
      },
      "aggs": {
        "terms": {
          "terms": {
            "field": "agent.keyword"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Sample Output Document After Obfuscation
DESCRIPTION: Example showing the processed document after obfuscation has been applied to both fields.

LANGUAGE: json
CODE:
{
  "id": 1,
  "phone": "***",
  "log": "My name is Bob and my email address is abc@example.com",
  "newLog": "My name is Bob and my email address is ######"
}

----------------------------------------

TITLE: Creating Index with Nested Fields
DESCRIPTION: Example of creating an OpenSearch index with nested field mappings for patient data.

LANGUAGE: json
CODE:
PUT /testindex 
{
  "mappings": {
    "properties": {
      "patient": {
        "type": "nested",
        "properties": {
          "name": {
            "type": "text"
          },
          "age": {
            "type": "integer"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Response for Creating an ML Connector in OpenSearch
DESCRIPTION: This snippet shows the expected response format when successfully creating a connector. It returns a JSON object containing the unique connector_id for the newly created connector.

LANGUAGE: json
CODE:
{
  "connector_id": "a1eMb4kBJ1eYAeTMAljY"
}

----------------------------------------

TITLE: Clone Index API Response in OpenSearch
DESCRIPTION: Shows the expected JSON response format for a successful Clone Index API operation, including acknowledgment and the new index name.

LANGUAGE: json
CODE:
{
    "acknowledged": true,
    "shards_acknowledged": true,
    "index": "cloned-index1"
}

----------------------------------------

TITLE: Analyzing Text with Remove Duplicates Filter
DESCRIPTION: Analyzes text using the analyzer with remove_duplicates filter to show the final token output.

LANGUAGE: json
CODE:
GET /index-remove-duplicate/_analyze
{
  "analyzer": "custom_analyzer",
  "text": "Slower turtle"
}

----------------------------------------

TITLE: Creating Custom Irish Analyzer
DESCRIPTION: Shows how to create a custom Irish analyzer with specific token filters and configurations including stopwords, elision, hyphenation, and stemming.

LANGUAGE: json
CODE:
PUT /irish-index
{
  "settings": {
    "analysis": {
      "filter": {
        "irish_stop": {
          "type": "stop",
          "stopwords": "_irish_"
        },
        "irish_elision": {
          "type":       "elision",
          "articles":   [ "d", "m", "b" ],
          "articles_case": true
        },
        "irish_hyphenation": {
          "type":       "stop",
          "stopwords":  [ "h", "n", "t" ],
          "ignore_case": true
        },
        "irish_lowercase": {
          "type":       "lowercase",
          "language":   "irish"
        },
        "irish_stemmer": {
          "type": "stemmer",
          "language": "irish"
        },
        "irish_keywords": {
          "type": "keyword_marker",
          "keywords": []
        }
      },
      "analyzer": {
        "irish_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "irish_hyphenation",
            "irish_elision",
            "irish_lowercase",
            "irish_stop",
            "irish_keywords",
            "irish_stemmer"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "irish_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Plain Text Response Format
DESCRIPTION: Example response showing index information in plain text tabular format

LANGUAGE: json
CODE:
health | status | index | uuid | pri | rep | docs.count | docs.deleted | store.size | pri.store.size
green  | open | movies | UZbpfERBQ1-3GSH2bnM3sg | 1 | 1 | 1 | 0 | 7.7kb | 3.8kb
next_token MTcyOTE5NTQ5NjM5N3wub3BlbnNlYXJjaC1zYXAtbG9nLXR5cGVzLWNvbmZpZw==

----------------------------------------

TITLE: Basic Uppercase Processor Syntax in OpenSearch
DESCRIPTION: Demonstrates the basic JSON syntax for configuring the uppercase processor in an ingest pipeline.

LANGUAGE: json
CODE:
{
  "uppercase": {
    "field": "field_name"
  }
}

----------------------------------------

TITLE: Setting Index-Level Coercion in OpenSearch
DESCRIPTION: This example illustrates how to set the index-level coercion setting to false while overriding it for a specific field. It demonstrates the interaction between index-level and field-level coercion settings.

LANGUAGE: json
CODE:
PUT inventory
{
  "settings": {
    "index.mapping.coerce": false
  },
  "mappings": {
    "properties": {
      "stock_count": {
        "type": "integer",
        "coerce": true
      },
      "sku": {
        "type": "keyword"
      }
    }
  }
}

PUT inventory/_doc/1
{
  "sku": "ABC123",
  "stock_count": "50"
}

----------------------------------------

TITLE: Opening an Index using POST Request in OpenSearch
DESCRIPTION: This snippet demonstrates the endpoint for opening a closed index in OpenSearch. It allows you to add or search for data within the index after opening.

LANGUAGE: json
CODE:
POST /<index>/_open

----------------------------------------

TITLE: Example Request for Restoring a Snapshot in OpenSearch
DESCRIPTION: This example demonstrates how to restore a specific index from a snapshot, renaming it in the process. It includes various optional parameters to customize the restoration process.

LANGUAGE: json
CODE:
POST /_snapshot/my-opensearch-repo/my-first-snapshot/_restore
{
  "indices": "opendistro-reports-definitions",
  "ignore_unavailable": true,
  "include_global_state": false,              
  "rename_pattern": "(.+)",
  "rename_replacement": "$1_restored",
  "include_aliases": false
}

----------------------------------------

TITLE: Configuring parse_ion Processor in YAML for OpenSearch Data Prepper
DESCRIPTION: This snippet shows the minimum configuration required to use the parse_ion processor in an OpenSearch Data Prepper pipeline. It sets up a pipeline that reads from stdin, processes the 'my_ion' field using parse_ion, and outputs to stdout.

LANGUAGE: yaml
CODE:
parse-json-pipeline:
  source:
    stdin:
  processor:
    - parse_json:
        source: "my_ion"
  sink:
    - stdout:

----------------------------------------

TITLE: Testing Set Processor Pipeline
DESCRIPTION: Example of testing the Set processor pipeline using the simulate API.

LANGUAGE: json
CODE:
POST _ingest/pipeline/set-pipeline/_simulate
{
  "docs": [
    {
      "_source": {
        "existing_field": "value"
      }
    }
  ]
}

----------------------------------------

TITLE: Creating a k-NN Index with Text Embedding Pipeline in OpenSearch
DESCRIPTION: This snippet creates a k-NN index that uses the previously defined pipeline for text embedding, setting up the necessary mappings and settings.

LANGUAGE: json
CODE:
PUT my_test_data
{
  "mappings": {
    "properties": {
      "text": {
        "type": "text"
      },
      "embedding": {
        "type": "knn_vector",
        "dimension": 384
      }
    }
  },
  "settings": {
    "index": {
      "knn.space_type": "cosinesimil",
      "default_pipeline": "test-pipeline-local-model",
      "knn": "true"
    }
  }
}

----------------------------------------

TITLE: HTTP Authenticator Configuration
DESCRIPTION: Configuration structure for HTTP authenticators specifying type, challenge settings, and additional config options.

LANGUAGE: yaml
CODE:
http_authenticator:
  type: <type>
  challenge: <true|false>
  config:
    ...

----------------------------------------

TITLE: Registering File System Snapshot Repository in OpenSearch
DESCRIPTION: This JSON request registers a new file system repository named 'my-fs-repository' using the local directory '/mnt/snapshots' as the storage location.

LANGUAGE: json
CODE:
PUT /_snapshot/my-fs-repository
{
  "type": "fs",
  "settings": {
    "location": "/mnt/snapshots"
  }
}

----------------------------------------

TITLE: Analyzing Text with Pattern Tokenizer in OpenSearch
DESCRIPTION: This snippet shows how to use the _analyze API to examine the tokens generated by the custom pattern analyzer. It splits the text 'OpenSearch-2024_v1.2' using the previously defined analyzer.

LANGUAGE: json
CODE:
POST /my_index/_analyze
{
  "analyzer": "my_pattern_analyzer",
  "text": "OpenSearch-2024_v1.2"
}

----------------------------------------

TITLE: Searching for All Models in OpenSearch
DESCRIPTION: This snippet demonstrates how to search for all ML models using a match_all query. It uses the POST method and sets a size limit of 1000 results.

LANGUAGE: json
CODE:
POST /_plugins/_ml/models/_search
{
  "query": {
    "match_all": {}
  },
  "size": 1000
}

----------------------------------------

TITLE: Ingesting a Document with a Dissect Pipeline in OpenSearch
DESCRIPTION: Ingests a document into 'testindex1' using the 'dissect-test' pipeline.

LANGUAGE: json
CODE:
PUT testindex1/_doc/1?pipeline=dissect-test
{
   "message": "192.168.1.10 - - [03/Nov/2023:15:20:45 +0000] \"POST /login HTTP/1.1\" 200 3456"
}

----------------------------------------

TITLE: Adding Grok Performance Metadata in YAML Pipeline Configuration
DESCRIPTION: Configuration example showing how to enable Grok performance metadata and add it to events using the 'add_entries' processor. This allows tracking of pattern matching attempts and processing time.

LANGUAGE: yaml
CODE:
processor:
    - grok:
        performance_metadata: true
        match:
          log: "%{COMMONAPACHELOG"
    - add_entries:
        entries:
          - add_when: 'getMetadata("_total_grok_patterns_attempted") != null'
            key: "grok_patterns_attempted"
            value_expression: 'getMetadata("_total_grok_patterns_attempted")'
          - add_when: 'getMetadata("_total_grok_processing_time") != null'
            key: "grok_time_spent"
            value_expression: 'getMetadata("_total_grok_processing_time")'

----------------------------------------

TITLE: Uppercase Pipeline Response Example
DESCRIPTION: Shows the expected response from testing the uppercase pipeline, demonstrating the transformation of text to uppercase.

LANGUAGE: json
CODE:
{
  "docs": [
    {
      "doc": {
        "_index": "testindex1",
        "_id": "1",
        "_source": {
          "name": "JOHN"
        },
        "_ingest": {
          "timestamp": "2023-08-28T19:54:42.289624792Z"
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Indexing Documents with Rank Features Field in OpenSearch
DESCRIPTION: This snippet demonstrates how to index documents with a rank_features field in OpenSearch. It uses a hashmap with string keys and positive float values to represent the features.

LANGUAGE: json
CODE:
PUT testindex1/_doc/1
{
  "correlations": { 
    "young kids" : 1,
    "older kids" : 15,
    "teens" : 25.9
  }
}

LANGUAGE: json
CODE:
PUT testindex1/_doc/2
{
  "correlations": {
    "teens": 10,
    "adults": 95.7
  }
}

----------------------------------------

TITLE: Liquid Template Include
DESCRIPTION: Liquid template syntax for including card components with dynamic content from page variables.

LANGUAGE: liquid
CODE:
{% include cards.html cards=page.getting_started %}
{% include cards.html cards=page.why_use documentation_link=true %}
{% include cards.html cards=page.features%}

----------------------------------------

TITLE: Enabling Query Assistant in OpenSearch Dashboards YAML Configuration
DESCRIPTION: YAML configuration to enable the Query Assistant and response summarization in OpenSearch Dashboards. This snippet shows how to set the necessary options in the opensearch_dashboards.yml file.

LANGUAGE: yaml
CODE:
observability.summarize.enabled: true
observability.summarize.response_summary_agent_name: "Response summary agent"
observability.summarize.error_summary_agent_name: "Error summary agent"

----------------------------------------

TITLE: Defining Basic Logstash Pipeline Structure in YAML
DESCRIPTION: Demonstrates the basic structure of a Logstash pipeline configuration with input, filter, and output phases using YAML syntax.

LANGUAGE: yaml
CODE:
input {
  input_plugin => {}
}

filter {
  filter_plugin => {}
}

output {
  output_plugin => {}
}

----------------------------------------

TITLE: Searching IP Address with CIDR Notation in OpenSearch (IPv6)
DESCRIPTION: This snippet shows how to query an OpenSearch index for an IP address using CIDR notation in IPv6 format. It searches for IP addresses within the '2001:DB8::/24' network.

LANGUAGE: json
CODE:
GET testindex/_search 
{
  "query": {
    "term": {
      "ip_address": "2001:DB8::/24"
    }
  }
}

----------------------------------------

TITLE: Force Merge Data Stream to Single Segment
DESCRIPTION: Example request showing how to force merge a data stream's backing indexes into one segment using max_num_segments parameter.

LANGUAGE: json
CODE:
POST /.testindex-logs/_forcemerge?max_num_segments=1

----------------------------------------

TITLE: Multi-get Response in OpenSearch
DESCRIPTION: Example response from a multi-get request in OpenSearch. Shows the structure of the response, including document metadata and source fields for multiple documents across different indexes.

LANGUAGE: json
CODE:
{
  "docs": [
    {
      "_index": "sample-index1",
      "_id": "1",
      "_version": 4,
      "_seq_no": 5,
      "_primary_term": 19,
      "found": true,
      "_source": {
        "Title": "Batman Begins",
        "Director": "Christopher Nolan"
      }
    },
    {
      "_index": "sample-index2",
      "_id": "1",
      "_version": 1,
      "_seq_no": 6,
      "_primary_term": 19,
      "found": true,
      "_source": {
        "Title": "The Dark Knight",
        "Director": "Christopher Nolan"
      }
    }
  ]
}

----------------------------------------

TITLE: Configuring uppercase_string Processor in YAML
DESCRIPTION: Pipeline configuration for the uppercase_string processor that converts specified field values to uppercase.

LANGUAGE: yaml
CODE:
pipeline:
  source:
    file:
      path: "/full/path/to/logs_json.log"
      record_type: "event"
      format: "json"
  processor:
    - uppercase_string:
        with_keys:
          - "uppercaseField"
  sink:
    - stdout:

----------------------------------------

TITLE: Cluster Not Reachable Error Output
DESCRIPTION: Example error message when securityadmin.sh cannot connect to the OpenSearch cluster on the specified host and port.

LANGUAGE: bash
CODE:
OpenSearch Security Admin v6
Will connect to localhost:9200
ERR: Seems there is no opensearch running on localhost:9200 - Will exit

----------------------------------------

TITLE: Refreshing Multiple Indexes using POST in OpenSearch
DESCRIPTION: This example demonstrates how to refresh two specific indexes named 'my-index-A' and 'my-index-B' using the Refresh Index API in OpenSearch.

LANGUAGE: json
CODE:
POST /my-index-A,my-index-B/_refresh

----------------------------------------

TITLE: Querying Index Information with GET Request in OpenSearch
DESCRIPTION: This snippet demonstrates the endpoint for retrieving information about an index using the GET method. It allows querying a specific index or using wildcards to match multiple indexes.

LANGUAGE: json
CODE:
GET /<index>

----------------------------------------

TITLE: Inspecting Scheduler Metadata
DESCRIPTION: REST API call to search and retrieve scheduler metadata.

LANGUAGE: json
CODE:
GET /.async-query-scheduler/_search

----------------------------------------

TITLE: Update Document with Name Fields
DESCRIPTION: Example request showing how to update first_name and last_name fields in a document.

LANGUAGE: json
CODE:
{
  "doc": {
    "first_name" : "Bruce",
    "last_name" : "Wayne"
  }
}

----------------------------------------

TITLE: Interval Minimization Example in OpenSearch
DESCRIPTION: An example demonstrating interval minimization in OpenSearch, searching for 'd' contained by 'a' and 'c' in a specific text sequence.

LANGUAGE: json
CODE:
POST /testindex/_search
{
  "query": {
    "intervals" : {
      "my_text" : {
        "match" : {
          "query" : "d",
          "filter" : {
            "contained_by" : {
              "match" : {
                "query" : "a c"
              }
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: JSON Format Response - OpenSearch List API
DESCRIPTION: Demonstrates how to retrieve List API data in JSON format using the format parameter.

LANGUAGE: json
CODE:
GET _list/<operation_name>?format=json

----------------------------------------

TITLE: Configuring Basic Kafka Pipeline in Data Prepper
DESCRIPTION: Example configuration showing how to set up a basic Kafka source in a Data Prepper pipeline with multiple topics and a single consumer group.

LANGUAGE: json
CODE:
kafka-pipeline:
  source:
    kafka:
      bootstrap_servers:
        - 127.0.0.1:9093
      topics:
        - name: Topic1
          group_id: groupID1
        - name: Topic2
          group_id: groupID1

----------------------------------------

TITLE: Creating Custom Romanian Analyzer in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a custom Romanian analyzer with specific token filters and apply it to a text field when creating an index in OpenSearch.

LANGUAGE: json
CODE:
PUT /romanian-index
{
  "settings": {
    "analysis": {
      "filter": {
        "romanian_stop": {
          "type": "stop",
          "stopwords": "_romanian_"
        },
        "romanian_stemmer": {
          "type": "stemmer",
          "language": "romanian"
        },
        "romanian_keywords": {
          "type": "keyword_marker",
          "keywords": []
        }
      },
      "analyzer": {
        "romanian_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "romanian_stop",
            "romanian_keywords",
            "romanian_stemmer"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "romanian_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Analyzing Text with Norwegian Analyzer in OpenSearch
DESCRIPTION: This snippet shows how to use the _analyze API to examine the tokens generated by the Norwegian analyzer for a given text input.

LANGUAGE: json
CODE:
POST /norwegian-index/_analyze
{
  "field": "content",
  "text": "Studentene studerer ved norske universiteter. Deres nummer er 123456."
}

----------------------------------------

TITLE: Creating Custom Hindi Analyzer in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a custom Hindi analyzer with specific tokenizer and token filters when creating an index in OpenSearch.

LANGUAGE: json
CODE:
PUT /hindi-index
{
  "settings": {
    "analysis": {
      "filter": {
        "hindi_stop": {
          "type": "stop",
          "stopwords": "_hindi_"
        },
        "hindi_stemmer": {
          "type": "stemmer",
          "language": "hindi"
        },
        "hindi_keywords": {
          "type": "keyword_marker",
          "keywords": []
        }
      },
      "analyzer": {
        "hindi_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "decimal_digit",
            "hindi_keywords",
            "indic_normalization",
            "hindi_normalization",
            "hindi_stop",
            "hindi_stemmer"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "hindi_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Anomaly Detector Pipeline in YAML
DESCRIPTION: Basic YAML configuration example showing how to set up an anomaly detector processor in a pipeline to monitor latency values.

LANGUAGE: yaml
CODE:
ad-pipeline:
  source:
    ...
  ....  
  processor:
    - anomaly_detector:
        keys: ["latency"]
        mode: 
            random_cut_forest:

----------------------------------------

TITLE: Creating Index with Keyword Tokenizer
DESCRIPTION: Creates a new index with a custom analyzer using the keyword tokenizer. The example configures mappings for a content field that uses this analyzer.

LANGUAGE: json
CODE:
PUT /my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_keyword_analyzer": {
          "type": "custom",
          "tokenizer": "keyword"
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "my_keyword_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Updating SQL Settings in OpenSearch Cluster
DESCRIPTION: Demonstrates how to update SQL plugin settings using the cluster settings API. This example disables the SQL plugin.

LANGUAGE: json
CODE:
PUT _cluster/settings
{
  "transient" : {
    "plugins.sql.enabled" : false
  }
}

----------------------------------------

TITLE: Configuring Stem Exclusion for Arabic Analyzer in OpenSearch
DESCRIPTION: This example shows how to use the 'stem_exclusion' feature with the Arabic analyzer. It creates an index with a custom analyzer that excludes specific words from stemming.

LANGUAGE: json
CODE:
PUT index_with_stem_exclusion_arabic
{
  "settings": {
    "analysis": {
      "analyzer": {
        "stem_exclusion_arabic_analyzer":{
          "type":"arabic",
          "stem_exclusion":[""," "]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Indexing Point Geoshape
DESCRIPTION: Examples of indexing a point geometry in both GeoJSON and WKT formats.

LANGUAGE: json
CODE:
PUT testindex/_doc/1
{
  "location" : {
    "type" : "point",
    "coordinates" : [74.0060, 40.7128]
  }
}

LANGUAGE: json
CODE:
PUT testindex/_doc/1
{
  "location" : "POINT (74.0060 40.7128)"
}

----------------------------------------

TITLE: Querying OpenSearch for Ingested Log Data using cURL
DESCRIPTION: This cURL command retrieves a single document from the apache_logs index in the OpenSearch cluster, demonstrating how to access the ingested and structured log data.

LANGUAGE: bash
CODE:
curl -X GET -u 'admin:<custom-admin-password>' -k 'https://localhost:9200/apache_logs/_search?pretty&size=1'

----------------------------------------

TITLE: Querying Geobounds for Geo Points in OpenSearch
DESCRIPTION: This snippet demonstrates how to perform a geo_bounds aggregation on a geo_point field in OpenSearch. It queries the 'geoip.location' field in the 'opensearch_dashboards_sample_data_ecommerce' index.

LANGUAGE: json
CODE:
GET opensearch_dashboards_sample_data_ecommerce/_search
{
  "size": 0,
  "aggs": {
    "geo": {
      "geo_bounds": {
        "field": "geoip.location"
      }
    }
  }
}

----------------------------------------

TITLE: Creating Index with Mapping for Filter Context in OpenSearch
DESCRIPTION: This snippet shows how to create an index with a mapping for a test document to be used in the filter context of the Execute Painless script API.

LANGUAGE: json
CODE:
PUT /testindex1
{
  "mappings": {
    "properties": {
      "grad": {
        "type": "boolean"
      },
      "gpa": {
        "type": "float"
      }
    }
  }
}

----------------------------------------

TITLE: Using Index Aliases in OpenSearch SQL
DESCRIPTION: Examples of using index aliases in OpenSearch SQL queries. The first query uses the full index name, while the second uses an alias 'acc' for the 'accounts' index.

LANGUAGE: sql
CODE:
SELECT account_number, accounts.age
FROM accounts

LANGUAGE: sql
CODE:
SELECT account_number, acc.age
FROM accounts acc

----------------------------------------

TITLE: Audit Log Category Configuration
DESCRIPTION: Configuration for disabling specific audit log categories for REST and transport layers

LANGUAGE: yaml
CODE:
plugins.security.audit.config.disabled_rest_categories: AUTHENTICATED, opensearch_SECURITY_INDEX_ATTEMPT
plugins.security.audit.config.disabled_transport_categories: GRANTED_PRIVILEGES

----------------------------------------

TITLE: Creating a Mapping with Geo-point Field in OpenSearch
DESCRIPTION: Creates an index mapping with a 'point' field of type 'geo_point' to store geographical coordinates.

LANGUAGE: json
CODE:
PUT testindex1
{
  "mappings": {
    "properties": {
      "point": {
        "type": "geo_point"
      }
    }
  }
}

----------------------------------------

TITLE: Adding Grok Performance Metadata in YAML Pipeline Configuration
DESCRIPTION: Configuration example showing how to enable Grok performance metadata and add it to events using the 'add_entries' processor. This allows tracking of pattern matching attempts and processing time.

LANGUAGE: yaml
CODE:
processor:
    - grok:
        performance_metadata: true
        match:
          log: "%{COMMONAPACHELOG"
    - add_entries:
        entries:
          - add_when: 'getMetadata("_total_grok_patterns_attempted") != null'
            key: "grok_patterns_attempted"
            value_expression: 'getMetadata("_total_grok_patterns_attempted")'
          - add_when: 'getMetadata("_total_grok_processing_time") != null'
            key: "grok_time_spent"
            value_expression: 'getMetadata("_total_grok_processing_time")'

----------------------------------------

TITLE: Custom Admin Password for Helm Configuration
DESCRIPTION: YAML configuration to set custom admin password in Helm values.yaml file for OpenSearch 2.12+

LANGUAGE: yaml
CODE:
extraEnvs:
  - name: OPENSEARCH_INITIAL_ADMIN_PASSWORD
    value: <custom-admin-password>

----------------------------------------

TITLE: Creating Index with Join Field Mapping - OpenSearch JSON
DESCRIPTION: Creates an index with a join field that establishes parent-child relationships between documents. The mapping defines a relationship between parent_doc and child_doc types.

LANGUAGE: json
CODE:
PUT /example_index
{
  "mappings": {
    "properties": {
      "relationship_field": {
        "type": "join",
        "relations": {
          "parent_doc": "child_doc"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Snapshot Creation Response in OpenSearch (Without wait_for_completion)
DESCRIPTION: This snippet shows the JSON response when creating a snapshot without the 'wait_for_completion' parameter, indicating that the snapshot creation request was accepted.

LANGUAGE: json
CODE:
{
  "accepted": true
}

----------------------------------------

TITLE: Configuring trim_string Processor in OpenSearch Data Prepper
DESCRIPTION: This table describes the configuration option for the trim_string processor. It requires a 'with_keys' parameter, which is a list of keys to trim whitespace from.

LANGUAGE: markdown
CODE:
Option | Required | Type | Description
:--- | :--- | :--- | :---
with_keys | Yes | List | A list of keys to trim the white space from.

----------------------------------------

TITLE: Adding New OpenSearch Keystore Setting
DESCRIPTION: Command to add a new secure setting to the keystore. Will prompt for the setting value.

LANGUAGE: bash
CODE:
./bin/opensearch-keystore add plugins.security.ssl.http.pemkey_password_secure

----------------------------------------

TITLE: Updating Meta Information for an Existing Index in OpenSearch
DESCRIPTION: This example shows how to update the _meta information for an existing index using the Put Mapping API. It updates the version and author fields of the metadata.

LANGUAGE: json
CODE:
PUT my-index/_mapping
{
  "_meta": {
    "application": "MyApp",
    "version": "1.3.0",
    "author": "Jane Smith"
  }
}

----------------------------------------

TITLE: Querying SQL with Raw Format in OpenSearch
DESCRIPTION: Shows how to request SQL query results in raw format, which returns data separated by pipe characters for easy post-processing.

LANGUAGE: json
CODE:
POST /_plugins/_sql?format=raw
{
  "query" : "SELECT firstname, lastname, age FROM accounts ORDER BY age"
}

LANGUAGE: text
CODE:
Nanette|Bates|28
Amber|Duke|32
Dale|Adams|33
Hattie|Bond|36

----------------------------------------

TITLE: Mathematical Function Usage in OpenSearch SQL
DESCRIPTION: Examples of using mathematical functions in OpenSearch SQL queries. These functions perform various mathematical operations on numeric data types.

LANGUAGE: SQL
CODE:
SELECT abs(0.5)
SELECT add(1, 5)
SELECT cbrt(8)
SELECT ceil(0.5)
SELECT conv('2C', 16, 10), conv(1111, 2, 10)
SELECT crc32('MySQL')
SELECT divide(1, 0.5)
SELECT e()
SELECT exp(0.5)
SELECT expm1(0.5)
SELECT floor(0.5)
SELECT ln(10)
SELECT log(10) -> 2.3, SELECT log(2, 16) -> 4
SELECT log2(10)
SELECT log10(100)
SELECT mod(10,4) -> 2
SELECT modulus(2, 3)
SELECT multiply(2, 3)
SELECT pi()
SELECT pow(2, 3)
SELECT power(2, 3)
SELECT rand(), SELECT rand(0.5)
SELECT rint(1.5)
SELECT round(1.5), SELECT round(1.175, 2)
SELECT sign(1.5)
SELECT signum(0.5)
SELECT sqrt(0.5)
SELECT strcmp('hello', 'hello world')
SELECT subtract(3, 2)
SELECT truncate(56.78, 1)
SELECT 1 + 5
SELECT 3 - 2
SELECT 2 * 3
SELECT 1 / 0.5
SELECT 2 % 3

----------------------------------------

TITLE: Response from Querying Documents by _id in OpenSearch
DESCRIPTION: This snippet shows the response returned when querying documents by _id in OpenSearch. It includes metadata and the matched documents.

LANGUAGE: json
CODE:
{
  "took": 10,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 2,
      "relation": "eq"
    },
    "max_score": 1,
    "hits": [
      {
        "_index": "test-index1",
        "_id": "1",
        "_score": 1,
        "_source": {
          "text": "Document with ID 1"
        }
      },
      {
        "_index": "test-index1",
        "_id": "2",
        "_score": 1,
        "_source": {
          "text": "Document with ID 2"
        }
      }
    ]
  }

----------------------------------------

TITLE: Pipeline Information Response Structure
DESCRIPTION: Example response showing the structure of a pipeline containing multiple processors including set and uppercase operations.

LANGUAGE: json
CODE:
{
  "my-pipeline": {
    "description": "This pipeline processes student data",
    "processors": [
      {
        "set": {
          "description": "Sets the graduation year to 2023",
          "field": "grad_year",
          "value": 2023
        }
      },
      {
        "set": {
          "description": "Sets graduated to true",
          "field": "graduated",
          "value": true
        }
      },
      {
        "uppercase": {
          "field": "name"
        }
      }
    ]
  }
}

----------------------------------------

TITLE: Basic Simple Query String Search
DESCRIPTION: Demonstrates a basic fuzzy search on the title field using simple_query_string query type.

LANGUAGE: json
CODE:
GET _search
{
  "query": {
    "simple_query_string": {
      "query": "\"rises wind the\"~4 | *ising~2",
      "fields": ["title"]
    }
  }
}

----------------------------------------

TITLE: Using OpenSearch CLI for Various Operations
DESCRIPTION: This snippet demonstrates different usage examples of OpenSearch CLI, including retrieving detector information and making a CAT API request.

LANGUAGE: bash
CODE:
opensearch-cli ad get my-detector --profile docker-local
opensearch-cli curl get --path _cat/plugins --profile aws
opensearch-cli -h
opensearch-cli ad -h
opensearch-cli ad get -h

----------------------------------------

TITLE: Delete by Query Endpoint
DESCRIPTION: The basic endpoint structure for the Delete by Query API.

LANGUAGE: json
CODE:
POST <index>/_delete_by_query

----------------------------------------

TITLE: Scheduling Monitor Every Other Day in OpenSearch Alerting
DESCRIPTION: This cron expression sets up a monitor to run every other day at 1:45 PM. It uses specific values for minute and hour fields, and a step value for the day of month field.

LANGUAGE: cron
CODE:
45 13 1-31/2 * *

----------------------------------------

TITLE: Querying Specific Task Endpoint
DESCRIPTION: GET endpoint to retrieve information about a specific task using its task ID.

LANGUAGE: json
CODE:
GET _tasks/<task_id>

----------------------------------------

TITLE: Configuring Kinesis Source in YAML for OpenSearch Data Prepper
DESCRIPTION: Example YAML configuration for a pipeline using Kinesis as a source. It demonstrates how to ingest data from multiple Kinesis streams with specific settings.

LANGUAGE: yaml
CODE:
version: "2"
kinesis-pipeline:
  source:
    kinesis:
      streams:
        - stream_name: "stream1"
          initial_position: "LATEST"
        - stream_name: "stream2"
          initial_position: "LATEST"
      aws:
        region: "us-west-2"
        sts_role_arn: "arn:aws:iam::123456789012:role/my-iam-role"

----------------------------------------

TITLE: Example Response from Adjacency Matrix Aggregation in OpenSearch
DESCRIPTION: This is an example response to the adjacency matrix aggregation query. It shows the buckets returned, including intersections between different manufacturer groups. Each bucket represents a combination of filters and includes a doc_count indicating the number of documents matching that combination.

LANGUAGE: json
CODE:
{
  "aggregations": {
    "interactions": {
      "buckets": [
        {
          "key": "grpA",
          "doc_count": 1553
        },
        {
          "key": "grpA&grpB",
          "doc_count": 590
        },
        {
          "key": "grpA&grpC",
          "doc_count": 329
        },
        {
          "key": "grpB",
          "doc_count": 1370
        },
        {
          "key": "grpB&grpC",
          "doc_count": 299
        },
        {
          "key": "grpC",
          "doc_count": 1218
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Pulling OpenSearch Benchmark Docker Image from Amazon ECR
DESCRIPTION: Downloads the latest OpenSearch Benchmark Docker image from Amazon Elastic Container Registry.

LANGUAGE: bash
CODE:
docker pull public.ecr.aws/opensearchproject/opensearch-benchmark:latest

----------------------------------------

TITLE: Histogram Bucket JSON Structure
DESCRIPTION: Example JSON structure showing how histogram buckets are represented in the output, including min/max boundaries and counts for each bucket.

LANGUAGE: json
CODE:
"buckets": [
    {
      "min": 0.0,
      "max": 5.0,
      "count": 2
    },
    {
      "min": 5.0,
      "max": 10.0,
      "count": 5
    }
  ]

----------------------------------------

TITLE: Deleting Snapshot Repository Endpoint - JSON
DESCRIPTION: The DELETE endpoint for removing a snapshot repository configuration. The repository parameter specifies which repository to delete.

LANGUAGE: json
CODE:
DELETE _snapshot/<repository>

----------------------------------------

TITLE: Analyzing Text with Edge N-gram Filter in OpenSearch
DESCRIPTION: This snippet shows how to use the _analyze API to examine the tokens generated by the custom analyzer with the edge_ngram filter. It applies the analyzer to the text 'slow green turtle'.

LANGUAGE: json
CODE:
POST /edge_ngram_example/_analyze
{
  "analyzer": "my_analyzer",
  "text": "slow green turtle"
}

----------------------------------------

TITLE: Indexing Document with Special Characters in OpenSearch
DESCRIPTION: Demonstrates indexing a document with fields that start with special characters or contain commas, which affects CSV sanitization.

LANGUAGE: json
CODE:
PUT /userdata/_doc/1?refresh=true
{
  "+firstname": "-Hattie",
  "=lastname": "@Bond",
  "address": "671 Bristol Street, Dente, TN"
}

----------------------------------------

TITLE: Checking Write Index Status in OpenSearch
DESCRIPTION: This snippet demonstrates how to check if an index is set as a write index using the OpenSearch API. It shows both the query and an example response indicating a write index.

LANGUAGE: bash
CODE:
GET <index>/_alias?pretty

LANGUAGE: json
CODE:
{
  "<index>" : {
    "aliases" : {
      "<index_alias>" : { 
        "is_write_index" : true
      }
    }
  }
}

----------------------------------------

TITLE: Ingesting Document with OpenSearch Date Processor Pipeline
DESCRIPTION: Example of ingesting a document into the 'testindex1' index using the 'date-output-format' pipeline to process the date field.

LANGUAGE: json
CODE:
PUT testindex1/_doc/1?pipeline=date-output-format
{
  "date_european": "30/06/2023"
}

----------------------------------------

TITLE: Enabling Distributed Tracing Flag in opensearch.yml
DESCRIPTION: Add this line to the opensearch.yml file to enable the experimental distributed tracing feature.

LANGUAGE: yaml
CODE:
opensearch.experimental.feature.telemetry.enabled=true

----------------------------------------

TITLE: Installing OpenSearch Benchmark with pip
DESCRIPTION: Installs OpenSearch Benchmark using pip after all required software dependencies are met.

LANGUAGE: bash
CODE:
pip install opensearch-benchmark

----------------------------------------

TITLE: Querying IPv6 Address with Escaped Characters in OpenSearch
DESCRIPTION: This example illustrates how to query an OpenSearch index for an IPv6 address using a query_string query. It demonstrates escaping the ':' characters by wrapping the IP address in escaped quotation marks.

LANGUAGE: json
CODE:
GET testindex/_search 
{
  "query" : {
    "query_string": {
      "query": "ip_address:\"2001:DB8::/24\""
    }
  }
}

----------------------------------------

TITLE: Authenticating with Amazon OpenSearch Serverless using AWS SDK V2
DESCRIPTION: JavaScript code for authenticating with Amazon OpenSearch Serverless using AWS Signature Version 4 with AWS SDK V2.

LANGUAGE: javascript
CODE:
const AWS = require('aws-sdk');
const { Client } = require('@opensearch-project/opensearch');
const { AwsSigv4Signer } = require('@opensearch-project/opensearch/aws');

const client = new Client({
  ...AwsSigv4Signer({
    region: 'us-west-2',
    service: 'aoss',
    getCredentials: () =>
      new Promise((resolve, reject) => {
        AWS.config.getCredentials((err, credentials) => {
          if (err) {
            reject(err);
          } else {
            resolve(credentials);
          }
        });
      }),
  }),
  node: "https://xxx.region.aoss.amazonaws.com"
});

----------------------------------------

TITLE: Clearing Request Cache in OpenSearch
DESCRIPTION: Example request to clear only the request cache for a specific index in OpenSearch.

LANGUAGE: json
CODE:
POST /my-index/_cache/clear?request=true

----------------------------------------

TITLE: Basic Explain Parameter Usage in URL
DESCRIPTION: Shows the basic GET and POST syntax for using the explain parameter with a search pipeline in the URL.

LANGUAGE: json
CODE:
GET <index>/_search?search_pipeline=<search_pipeline>&explain=true
POST <index>/_search?search_pipeline=<search_pipeline>&explain=true

----------------------------------------

TITLE: Configuring TLS Certificates in Docker Compose
DESCRIPTION: Example of how to add TLS certificates to OpenSearch nodes using Docker Compose volumes.

LANGUAGE: yaml
CODE:
volumes:
  - ./root-ca.pem:/usr/share/opensearch/config/root-ca.pem
  - ./admin.pem:/usr/share/opensearch/config/admin.pem
  - ./admin-key.pem:/usr/share/opensearch/config/admin-key.pem
  - ./node1.pem:/usr/share/opensearch/config/node1.pem
  - ./node1-key.pem:/usr/share/opensearch/config/node1-key.pem
  - ./custom-opensearch.yml:/usr/share/opensearch/config/opensearch.yml

----------------------------------------

TITLE: Extended Prefix Query in OpenSearch
DESCRIPTION: Extended syntax version of the prefix query that provides the same functionality but allows for additional parameters.

LANGUAGE: json
CODE:
GET shakespeare/_search
{
  "query": {
    "prefix": {
      "speaker": {
        "value": "KING H"
      }
    }
  }
}

----------------------------------------

TITLE: Querying date_nanos Fields with Range Query in OpenSearch
DESCRIPTION: This snippet demonstrates how to use a range query to search for documents within a specific date range, utilizing the nanosecond precision of date_nanos fields.

LANGUAGE: json
CODE:
GET testindex/_search
{
  "query": {
    "range": {
      "date": {
        "gte": "2022-06-15T10:12:52.382719621Z",
        "lte": "2022-06-15T10:12:52.382719623Z"
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Stem Exclusion for Catalan Analyzer in OpenSearch
DESCRIPTION: This snippet shows how to use stem exclusion with the Catalan analyzer in OpenSearch, allowing certain words to be excluded from stemming.

LANGUAGE: json
CODE:
PUT index_with_stem_exclusion_catalan_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "stem_exclusion_catalan_analyzer": {
          "type": "catalan",
          "stem_exclusion": ["autoritat", "aprovaci"]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Analyzing Text with Hindi Analyzer in OpenSearch
DESCRIPTION: This snippet shows how to use the _analyze API to examine the tokens generated by the Hindi analyzer for a given text input.

LANGUAGE: json
CODE:
POST /hindi-index/_analyze
{
  "field": "content",
  "text": "         "
}

----------------------------------------

TITLE: Configuring Stem Exclusion for Czech Analyzer in OpenSearch
DESCRIPTION: This snippet shows how to configure stem exclusion for the Czech analyzer in OpenSearch index settings.

LANGUAGE: json
CODE:
PUT index_with_stem_exclusion_czech_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "stem_exclusion_czech_analyzer": {
          "type": "czech",
          "stem_exclusion": ["autorita", "schvlen"]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring a Force Merge Action
DESCRIPTION: Example of how to configure a force_merge action in an ISM policy.

LANGUAGE: json
CODE:
{
  "force_merge": {
    "max_num_segments": 1
  }
}

----------------------------------------

TITLE: Analyzing Text with Synonym Analyzer in OpenSearch
DESCRIPTION: This request examines the tokens generated using the previously defined synonym analyzer. It analyzes the text 'The quick dog jumps into the car with a laptop' to showcase how synonyms are applied.

LANGUAGE: json
CODE:
GET /my-synonym-index/_analyze
{
  "analyzer": "my_synonym_analyzer",
  "text": "The quick dog jumps into the car with a laptop"
}

----------------------------------------

TITLE: Deleting a Dangling Index in OpenSearch
DESCRIPTION: This endpoint deletes a specific dangling index from the OpenSearch cluster. It requires the index UUID as a path parameter and the accept_data_loss query parameter set to true.

LANGUAGE: json
CODE:
DELETE /_dangling/<index-uuid>

----------------------------------------

TITLE: Inserting Sample Documents with Parent-Child Relationships in OpenSearch
DESCRIPTION: This snippet shows how to insert sample documents representing authors, posts, and comments with the appropriate parent-child relationships defined.

LANGUAGE: json
CODE:
POST /blog-sample/_doc/1?routing=1
{
  "type": "author",
  "name": "John Doe",
  "join_field": "author"
}

POST /blog-sample/_doc/2?routing=1
{
  "type": "post",
  "title": "Introduction to OpenSearch",
  "content": "OpenSearch is a powerful search and analytics engine...",
  "author": "John Doe",
  "join_field": {
    "name": "post",
    "parent": "1"
  }
}

POST /blog-sample/_doc/3?routing=1
{
  "type": "comment",
  "content": "Great article! Very informative.",
  "join_field": {
    "name": "comment",
    "parent": "2"
  }
}

POST /blog-sample/_doc/4?routing=1
{
  "type": "comment",
  "content": "Thanks for the clear explanation.",
  "join_field": {
    "name": "comment",
    "parent": "2"
  }
}

----------------------------------------

TITLE: Executing Painless Script with Default Context in OpenSearch
DESCRIPTION: This example demonstrates how to execute a Painless script using the default painless_test context. The script calculates the average of two parameters.

LANGUAGE: json
CODE:
GET /_scripts/painless/_execute
{
  "script": {
    "source": "(params.x + params.y)/ 2",
    "params": {
      "x": 80,
      "y": 100
    }
  }
}

----------------------------------------

TITLE: Wildcard Query in SQL
DESCRIPTION: Example of using wildcard queries to search for patterns in text fields.

LANGUAGE: sql
CODE:
SELECT account_number, address
FROM accounts
WHERE wildcard_query(address, '*Holmes*');

----------------------------------------

TITLE: Testing JSON Processor Pipeline in OpenSearch
DESCRIPTION: Demonstrates how to test the created pipeline using the _simulate endpoint. It processes two sample documents with JSON data to verify the pipeline's functionality.

LANGUAGE: json
CODE:
POST _ingest/pipeline/my-json-pipeline/_simulate
{
  "docs": [
    {
      "_source": {
        "raw_data": "{\"name\":\"John\",\"age\":30,\"city\":\"New York\"}"
      }
    },
    {
      "_source": {
        "raw_data": "{\"name\":\"Jane\",\"age\":25,\"city\":\"Los Angeles\"}"
      }
    }
  ]
}

----------------------------------------

TITLE: Creating Index with Join Field for Parent-Child Relationships in OpenSearch
DESCRIPTION: This snippet demonstrates how to create an index with a join field to establish parent-child relationships between documents.

LANGUAGE: json
CODE:
PUT /example_index
{
  "mappings": {
    "properties": {
      "relationship_field": {
        "type": "join",
        "relations": {
          "parent_doc": "child_doc"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Enabling Cluster-Level Concurrent Segment Search Mode
DESCRIPTION: Sets the concurrent segment search mode at the cluster level using the search.concurrent_segment_search.mode setting.

LANGUAGE: json
CODE:
PUT _cluster/settings
{
   "persistent":{
      "search.concurrent_segment_search.mode": "all"
   }
}

----------------------------------------

TITLE: Querying XY Points Using Circle in OpenSearch
DESCRIPTION: Shows how to search for xy_point type fields using a circle shape as the query boundary.

LANGUAGE: json
CODE:
GET testindex1/_search
{
  "query": {
    "xy_shape": {
      "point": {
        "shape": {
          "type": "circle",
          "coordinates": [0.0, 0.0],
          "radius": 2
        }
      }
    }
  }
}

----------------------------------------

TITLE: Searching Transformed Index in OpenSearch
DESCRIPTION: Example of using the _search API to query a transformed index. Shows how to search for specific field values in the transformed data.

LANGUAGE: json
CODE:
GET <target_index>/_search

----------------------------------------

TITLE: Enabling Audit Logging in OpenSearch YAML
DESCRIPTION: Basic configuration required in opensearch.yml to enable audit logging with internal storage

LANGUAGE: yaml
CODE:
plugins.security.audit.type: internal_opensearch

----------------------------------------

TITLE: Creating Russian Analyzer with Stem Exclusion in OpenSearch
DESCRIPTION: This snippet shows how to create a Russian analyzer with stem exclusion for specific words in OpenSearch index settings.

LANGUAGE: json
CODE:
PUT index_with_stem_exclusion_russian_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "stem_exclusion_russian_analyzer": {
          "type": "russian",
          "stem_exclusion": ["", ""]
        }
      }
    }
  }
}

----------------------------------------

TITLE: SQL Stats Response in OpenSearch
DESCRIPTION: This JSON snippet shows the structure of the response from the SQL stats endpoint. It includes various metrics such as request counts, failed request counts, and circuit breaker status.

LANGUAGE: json
CODE:
{
  "failed_request_count_cb": 0,
  "failed_request_count_cuserr": 0,
  "circuit_breaker": 0,
  "request_total": 0,
  "request_count": 0,
  "failed_request_count_syserr": 0
}

----------------------------------------

TITLE: Boolean Search Query Implementation
DESCRIPTION: Example of implementing a Boolean search query with filtering, sorting, and scrolling functionality.

LANGUAGE: csharp
CODE:
var gradResponse = await osClient.SearchAsync<Student>(s => s
                        .Index(index)
                        .From(0)
                        .Size(10)
                        .Scroll("1m")
                        .Query(q => q
                        .Bool(b => b
                        .Filter(f => f
                        .Term(t => t.Field(fld => fld.GradYear).Value(2022)))))
                        .Sort(srt => srt.Ascending(f => f.LastName)));

----------------------------------------

TITLE: Querying CAT Plugins Endpoint
DESCRIPTION: The base endpoint for retrieving information about installed plugins.

LANGUAGE: json
CODE:
GET /_cat/plugins

----------------------------------------

TITLE: Grok Filter Configuration for Log Parsing
DESCRIPTION: Configuration showing how to use the Grok filter to parse a log entry into structured fields including IP address, timestamp, HTTP verb, and status code.

LANGUAGE: yaml
CODE:
filter {
  grok {
   match => { "message" => " %{IP: ip_address} %{USER:identity}
                             %{USER:auth} \[%{HTTPDATE:reg_ts}\]
                             \"%{WORD:http_verb}
                             %{URIPATHPARAM: req_path}
                             \" %{INT:http_status:int}
                             %{INT:num_bytes:int}"}
  }
}

----------------------------------------

TITLE: Analyzing Text with Decimal Digit Filter in OpenSearch
DESCRIPTION: This snippet shows how to use the _analyze API to test the custom analyzer with the decimal_digit filter. It processes a string containing digits in ASCII, Arabic-Indic, and Devanagari scripts, demonstrating how the filter normalizes all digits to their ASCII equivalents.

LANGUAGE: json
CODE:
POST /my_index/_analyze
{
  "analyzer": "my_analyzer",
  "text": "123  "
}

----------------------------------------

TITLE: Get Workflow Steps API Endpoints
DESCRIPTION: Lists the available endpoints for retrieving workflow steps, including options to fetch all steps or specific steps by name.

LANGUAGE: json
CODE:
GET /_plugins/_flow_framework/workflow/_steps
GET /_plugins/_flow_framework/workflow/_step?workflow_step=<step_name>

----------------------------------------

TITLE: Querying CAT cluster_manager Endpoint in OpenSearch
DESCRIPTION: HTTP GET request to the /_cat/cluster_manager endpoint in OpenSearch. This endpoint lists information that helps identify the elected cluster manager node.

LANGUAGE: json
CODE:
GET /_cat/cluster_manager

----------------------------------------

TITLE: Using prefilter_field for performance optimization
DESCRIPTION: Updates the index mapping to add a prefilter_field to the 'method' derived field for improved performance.

LANGUAGE: json
CODE:
PUT /logs/_mapping
{
  "derived": {
    "method": {
      "type": "keyword",
      "script": {
        "source": """
        emit(doc["request.keyword"].value.splitOnToken(" ")[1])
        """
      },
      "prefilter_field": "request"
    }
  }
}

----------------------------------------

TITLE: Retrieving search journey details
DESCRIPTION: SQL query to fetch details of a specific search query using its query_id from the ubi_queries table.

LANGUAGE: sql
CODE:
select
  client_id, query_id, user_query, query_response_hit_ids, query_response_id, timestamp 
from ubi_queries where query_id = '7ae52966-4fd4-4ab1-8152-0fd0b52bdadf'

----------------------------------------

TITLE: Hiding Local Cluster in YAML Configuration
DESCRIPTION: Set the data_source.hideLocalCluster flag to true in the opensearch_dashboards.yml file to hide the local cluster option from data source selections.

LANGUAGE: yaml
CODE:
data_source.hideLocalCluster: true

----------------------------------------

TITLE: Output JSON Example for Basic Truncation
DESCRIPTION: Sample JSON output showing the results after truncation is applied with various configurations.

LANGUAGE: json
CODE:
{"message1":"hello", "message2":"test ", "info":"inform", "log": "log message"}

----------------------------------------

TITLE: Example Request for Retrieving Snapshot Information in OpenSearch
DESCRIPTION: This example demonstrates how to retrieve information for a specific snapshot named 'my-first-snapshot' from the 'my-opensearch-repo' repository using the GET API.

LANGUAGE: json
CODE:
GET _snapshot/my-opensearch-repo/my-first-snapshot

----------------------------------------

TITLE: Finding trending queries on client-side
DESCRIPTION: SQL query to identify the most common search queries by counting occurrences in the ubi_events table for 'on_search' actions.

LANGUAGE: sql
CODE:
select 
	message, count(0) Total  
from ubi_events
where 
	action_name='on_search' 
group by message 
order by Total desc

----------------------------------------

TITLE: Executing Subquery in FROM Clause with SQL in OpenSearch
DESCRIPTION: Demonstrates a supported subquery in the FROM clause, selecting flight number and destination country from a sample dataset where the origin country is 'US'.

LANGUAGE: sql
CODE:
SELECT t.f, t.d
FROM (
    SELECT FlightNum as f, DestCountry as d
    FROM opensearch_dashboards_sample_data_flights
    WHERE OriginCountry = 'US') t

----------------------------------------

TITLE: Testing CSV Pipeline with Simulate API
DESCRIPTION: Shows how to test the CSV processor pipeline using the simulate API before actual implementation. Includes example document data for testing.

LANGUAGE: json
CODE:
{
  "docs": [
    {
      "_index": "testindex1",
      "_id": "1",
      "_source": {
        "resource_usage": "25,4096,10",
        "memory_usage": "4096",
        "disk_usage": "10",
        "cpu_usage": "25"
      }
    }
  ]
}

----------------------------------------

TITLE: Creating Pipeline with Foreach Processor
DESCRIPTION: Example of creating a pipeline that uses the foreach processor to lowercase all elements in an array field named 'protocols'.

LANGUAGE: json
CODE:
PUT _ingest/pipeline/test-foreach  
{  
  "description": "Lowercase all the elements in an array",  
  "processors": [  
    {  
      "foreach": {  
        "field": "protocols",  
        "processor": {  
          "lowercase": {  
            "field": "_ingest._value"  
          }  
        }  
      }  

----------------------------------------

TITLE: Extended Stats Aggregation Response in OpenSearch
DESCRIPTION: This snippet shows the response structure of an extended_stats aggregation, including various statistical measures such as count, min, max, average, sum, variance, and standard deviation.

LANGUAGE: json
CODE:
{
  "aggregations": {
    "extended_stats_taxful_total_price": {
      "count": 4675,
      "min": 6.98828125,
      "max": 2250.0,
      "avg": 75.05542864304813,
      "sum": 350884.12890625,
      "sum_of_squares": 3.9367749294174194E7,
      "variance": 2787.59157113862,
      "variance_population": 2787.59157113862,
      "variance_sampling": 2788.187974983536,
      "std_deviation": 52.79764740155209,
      "std_deviation_population": 52.79764740155209,
      "std_deviation_sampling": 52.80329511482722,
      "std_deviation_bounds": {
        "upper": 180.6507234461523,
        "lower": -30.53986616005605,
        "upper_population": 180.6507234461523,
        "lower_population": -30.53986616005605,
        "upper_sampling": 180.66201887270256,
        "lower_sampling": -30.551161586606312
      }
    }
  }
}

----------------------------------------

TITLE: Searching with a collapse pipeline in OpenSearch
DESCRIPTION: This snippet shows how to perform a search query using the 'collapse_pipeline', which collapses results based on the 'color' field.

LANGUAGE: json
CODE:
POST /my_index/_search?search_pipeline=collapse_pipeline
{
  "size": 3
}

----------------------------------------

TITLE: Provisioning OpenSearch Cluster with Benchmark Test
DESCRIPTION: Executes a test and provisions an OpenSearch cluster with a specified distribution version using the geonames workload.

LANGUAGE: bash
CODE:
opensearch-benchmark execute-test --distribution-version=2.3.0 --workload=geonames --test-mode

----------------------------------------

TITLE: Configuring Stem Exclusion for German Analyzer in OpenSearch
DESCRIPTION: This snippet shows how to use the stem_exclusion parameter with the German analyzer to exclude specific words from stemming.

LANGUAGE: json
CODE:
PUT index_with_stem_exclusion_german_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "stem_exclusion_german_analyzer": {
          "type": "german",
          "stem_exclusion": ["Autoritt", "Genehmigung"]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Retrieving Multi-Index Recovery Information in OpenSearch
DESCRIPTION: Example request for retrieving recovery information from multiple specific indexes with human-readable output formatting.

LANGUAGE: json
CODE:
GET index1,index2/_recovery?human

----------------------------------------

TITLE: Retrieving Document with Custom Routing in OpenSearch
DESCRIPTION: Example of retrieving a document using the same custom routing value 'JohnDoe1' that was used during indexing.

LANGUAGE: json
CODE:
GET sample-index1/_doc/1?routing=JohnDoe1

----------------------------------------

TITLE: Creating OpenSearch Index
DESCRIPTION: Creates an OpenSearch index with custom shard settings

LANGUAGE: php
CODE:
$indexName = 'test-index-name';

$client->indices()->create([
    'index' => $indexName,
    'body' => [
        'settings' => [
            'index' => [
                'number_of_shards' => 4
            ]
        ]
    ]
]);

----------------------------------------

TITLE: Creating Index Mapping with Alias Field
DESCRIPTION: Example showing how to create an index mapping that includes an alias field 'release_date' pointing to an original date field 'year'

LANGUAGE: json
CODE:
PUT movies 
{
  "mappings" : {
    "properties" : {
      "year" : {
        "type" : "date"
      },
      "release_date" : {
        "type" : "alias",
        "path" : "year"
      }
    }
  }
}

----------------------------------------

TITLE: Disabling Vector Data Structure Creation in OpenSearch Index Settings
DESCRIPTION: This code shows how to disable vector data structure creation for new segments in OpenSearch by setting the index.knn.advanced.approximate_threshold to -1.

LANGUAGE: json
CODE:
PUT /test-index/
{
  "settings": {
    "index.knn.advanced.approximate_threshold": "-1"
  }
}

----------------------------------------

TITLE: Not Started Status Response
DESCRIPTION: Example response when workflow provisioning hasn't started.

LANGUAGE: json
CODE:
{
  "workflow_id" : "8xL8bowB8y25Tqfenm50",
  "state": "NOT_STARTED"
}

----------------------------------------

TITLE: Retrieving Script Contexts with GET Request in OpenSearch
DESCRIPTION: Sends a GET request to the _script_context endpoint to retrieve all available script contexts.

LANGUAGE: json
CODE:
GET _script_context

----------------------------------------

TITLE: Match All Model Groups Query
DESCRIPTION: Example request to search for all accessible model groups with a size limit of 1000 results.

LANGUAGE: json
CODE:
{
  "query": {
    "match_all": {}
  },
  "size": 1000
}

----------------------------------------

TITLE: Generating Encryption Master Key for OpenSearch Data Sources
DESCRIPTION: Command to generate a 24-character hexadecimal encryption master key using OpenSSL. This key is required for securely storing and encrypting data source connections in OpenSearch.

LANGUAGE: bash
CODE:
openssl rand -hex 12

----------------------------------------

TITLE: Configuring Flatten Processor to Remove List Indexes in YAML
DESCRIPTION: This example demonstrates how to use the remove_list_indices option to convert fields from the source map into lists and put them into the target field.

LANGUAGE: yaml
CODE:
processor:
  - flatten:
      source: ""   # empty string represents root of event
      target: ""   # empty string represents root of event
      remove_processed_fields: true
      remove_list_indices: true

----------------------------------------

TITLE: Single Index CAT Count Query
DESCRIPTION: Request to get document count for a specific index or alias with verbose output.

LANGUAGE: json
CODE:
GET _cat/count/<index_or_alias>?v

----------------------------------------

TITLE: Defining Subfield as Flat Object in OpenSearch
DESCRIPTION: This snippet shows how to define a subfield of a JSON object as a flat object in OpenSearch.

LANGUAGE: json
CODE:
PUT /test-index/
{
  "mappings": {
    "properties": {
      "issue": {
        "properties": {
          "number": {
            "type": "double"
          },
          "labels": {
            "type": "flat_object"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Analyzing Text with Bulgarian Analyzer in OpenSearch
DESCRIPTION: This snippet shows how to analyze a sample Bulgarian text using the Bulgarian analyzer and view the generated tokens in OpenSearch.

LANGUAGE: json
CODE:
POST /bulgarian-index/_analyze
{
  "field": "content",
  "text": "    .    123456."
}

----------------------------------------

TITLE: Configuring Stem Exclusion for Hindi Analyzer in OpenSearch
DESCRIPTION: This snippet shows how to use the stem_exclusion feature with the Hindi language analyzer when creating an index in OpenSearch.

LANGUAGE: json
CODE:
PUT index_with_stem_exclusion_hindi_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "stem_exclusion_hindi_analyzer": {
          "type": "hindi",
          "stem_exclusion": ["", ""]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating an Index with Porter Stem Analyzer in OpenSearch
DESCRIPTION: This example creates a new index named 'my_stem_index' and configures an analyzer with a Porter stem filter. The analyzer includes a standard tokenizer and applies lowercase and Porter stemming filters.

LANGUAGE: json
CODE:
PUT /my_stem_index
{
  "settings": {
    "analysis": {
      "filter": {
        "my_porter_stem": {
          "type": "porter_stem"
        }
      },
      "analyzer": {
        "porter_analyzer": {
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "my_porter_stem"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Setting Up a Rollover Action
DESCRIPTION: Example of how to configure a rollover action with various conditions in an ISM policy.

LANGUAGE: json
CODE:
{
  "rollover": {
    "min_size": "50gb",
    "min_doc_count": 100000000,
    "min_index_age": "30d"
  }
}

----------------------------------------

TITLE: Indexing Geopoint Data in OpenSearch
DESCRIPTION: This example shows how to index a geopoint in OpenSearch by specifying its latitude and longitude. This data can then be queried using geodistance searches.

LANGUAGE: json
CODE:
PUT testindex1/_doc/1
{
  "point": { 
    "lat": 74.00,
    "lon": 40.71
  }
}

----------------------------------------

TITLE: Defining PerfTop Dashboard Grid and Element Positions in JSON
DESCRIPTION: This JSON snippet demonstrates how to define a 12x12 grid for a PerfTop dashboard and position three table elements within it. It specifies the grid size and the position and dimensions of each table element.

LANGUAGE: json
CODE:
{
  "gridOptions": {
    "rows": 12,
    "cols": 12
  },
  "graphs": {
    "tables": [{
        "options": {
          "gridPosition": {
            "row": 0,
            "col": 0,
            "rowSpan": 2,
            "colSpan": 4
          }
        }
      },
      {
        "options": {
          "gridPosition": {
            "row": 2,
            "col": 2,
            "rowSpan": 1,
            "colSpan": 4
          }
        }
      },
      {
        "options": {
          "gridPosition": {
            "row": 1,
            "col": 6,
            "rowSpan": 3,
            "colSpan": 2
          }
        }
      }
    ]
  }
}

----------------------------------------

TITLE: Defining JSON Processor Syntax in OpenSearch
DESCRIPTION: Demonstrates the basic syntax for configuring a JSON processor in an OpenSearch ingest pipeline. The processor deserializes a JSON string into a map of maps.

LANGUAGE: json
CODE:
{
  "processor": {
    "json": {
      "field": "<field_name>",
      "target_field": "<target_field_name>",
      "add_to_root": <boolean>
    }
  }
}

----------------------------------------

TITLE: Installing Mapper-size Plugin in OpenSearch
DESCRIPTION: Command to install the mapper-size plugin using the OpenSearch plugin installation tool.

LANGUAGE: sh
CODE:
./bin/opensearch-plugin install mapper-size

----------------------------------------

TITLE: Creating XY Shape Field Mapping in OpenSearch
DESCRIPTION: Creates an index mapping with an xy_shape field type.

LANGUAGE: json
CODE:
PUT testindex
{
  "mappings": {
    "properties": {
      "location": {
        "type": "xy_shape"
      }
    }
  }
}

----------------------------------------

TITLE: RankLib Training Input Format
DESCRIPTION: Example of a RankLib-consumable judgment file showing feature scores for documents matching the query 'rambo'.

LANGUAGE: text
CODE:
4   qid:1   1:9.8376875     2:12.318446     # 7555 rambo
3   qid:1   1:10.7808075    2:9.510193      # 1370 rambo
3   qid:1   1:10.7808075    2:6.8449354     # 1369 rambo
3   qid:1   1:10.7808075    2:0.0           # 1368 rambo

----------------------------------------

TITLE: Obtaining Detailed Token Information in OpenSearch
DESCRIPTION: This example demonstrates how to get detailed token information by setting the 'explain' attribute to true in an OpenSearch analyze request.

LANGUAGE: json
CODE:
GET /_analyze
{
  "tokenizer" : "standard",
  "filter" : ["reverse"],
  "text" : "OpenSearch analyze test",
  "explain" : true,
  "attributes" : ["keyword"] 
}

----------------------------------------

TITLE: Implementing Geo-Distance Query Feature
DESCRIPTION: Example of a location-based feature using geo-distance filtering with dynamic latitude and longitude parameters.

LANGUAGE: json
CODE:
{
    "query": {
        "bool" : {
            "must" : {
                "match_all" : {}
            },
            "filter" : {
                "geo_distance" : {
                    "distance" : "200km",
                    "pin.location" : {
                        "lat" : "{{users_lat}}",
                        "lon" : "{{users_lon}}"
                    }
                }
            }
        }
    }
}

----------------------------------------

TITLE: Output JSON Example for Conditional Truncation
DESCRIPTION: Sample JSON output showing the results after conditional truncation is applied.

LANGUAGE: json
CODE:
{"message": "world", "id": 1}
{"message": "hello, world,not-truncated", "id": 2}

----------------------------------------

TITLE: Creating Documents with Specific _id Values in OpenSearch
DESCRIPTION: This snippet demonstrates how to create an index named 'test-index1' and add two documents with specific _id values using PUT requests.

LANGUAGE: json
CODE:
PUT test-index1/_doc/1
{
  "text": "Document with ID 1"
}

PUT test-index1/_doc/2?refresh=true
{
  "text": "Document with ID 2"
}

----------------------------------------

TITLE: Scroll API Response Example in OpenSearch
DESCRIPTION: This snippet shows an example response from the Scroll API, indicating a successful operation and the number of freed contexts.

LANGUAGE: json
CODE:
{
  "succeeded": true,
  "num_freed": 1
}

----------------------------------------

TITLE: Querying with Regular Identifiers in SQL (OpenSearch)
DESCRIPTION: This SQL query demonstrates the use of regular identifiers to select specific fields from the 'accounts' table. The identifiers 'account_number', 'firstname', and 'lastname' are used without any special escaping.

LANGUAGE: sql
CODE:
SELECT account_number, firstname, lastname FROM accounts;

----------------------------------------

TITLE: Creating a Grok Processor Pipeline in OpenSearch
DESCRIPTION: This snippet demonstrates how to create an ingest pipeline named 'log_line' using the grok processor to extract fields from a log message.

LANGUAGE: json
CODE:
PUT _ingest/pipeline/log_line
{
  "description": "Extract fields from a log line",
  "processors": [
    {
      "grok": {
        "field": "message",
        "patterns": ["%{IPORHOST:clientip} %{HTTPDATE:timestamp} %{NUMBER:response_status:int}"]
      }
    }
  ]
}

----------------------------------------

TITLE: Retrieving Snapshot Information in OpenSearch using GET API
DESCRIPTION: This endpoint retrieves information about a specific snapshot from a repository in OpenSearch. It requires the repository name and snapshot name as path parameters.

LANGUAGE: json
CODE:
GET _snapshot/<repository>/<snapshot>/

----------------------------------------

TITLE: Basic Index API Usage in OpenSearch
DESCRIPTION: Demonstrates the basic syntax for indexing a single document using the index API. Shows how to specify the index name, document ID and JSON content.

LANGUAGE: json
CODE:
PUT <index>/_doc/<id>
{ "A JSON": "document" }

----------------------------------------

TITLE: Creating Service Account via REST API
DESCRIPTION: JSON request body for the PUT /_plugins/_security/api/internalusers/{service_account_name} endpoint to create a Service Account with all permissions.

LANGUAGE: json
CODE:
{
 "opendistro_security_roles": ["all_access"],
 "backend_roles": [],
 "attributes": {
  "enabled": "true",
  "service": "true"
 }
}

----------------------------------------

TITLE: Configuring Authentication for Peer Forwarder in YAML
DESCRIPTION: Example YAML configuration for setting up mutual TLS authentication in peer forwarder.

LANGUAGE: yaml
CODE:
peer_forwarder:
  authentication:
    mutual_tls:

----------------------------------------

TITLE: Disabling Request Cache Settings in OpenSearch
DESCRIPTION: Shows how to disable the request cache for a specific index using the OpenSearch REST API.

LANGUAGE: json
CODE:
PUT /my_index/_settings
{
  "index.requests.cache.enable": false
}

----------------------------------------

TITLE: Configuring Source Field Inclusion/Exclusion in OpenSearch
DESCRIPTION: Demonstrates how to selectively include or exclude fields from the _source using pattern matching. This example shows including fields matching '*.count' and 'meta.*' patterns while excluding 'meta.description' and 'meta.other.*' patterns.

LANGUAGE: json
CODE:
PUT logs
{
  "mappings": {
    "_source": {
      "includes": [
        "*.count",
        "meta.*"
      ],
      "excludes": [
        "meta.description",
        "meta.other.*"
      ]
    }
  }
}

----------------------------------------

TITLE: Indexing Document with IP Address in OpenSearch
DESCRIPTION: This example shows how to index a document with an IP address field in OpenSearch. It adds a document with ID 1 and an IP address value.

LANGUAGE: json
CODE:
PUT testindex/_doc/1 
{
  "ip_address" : "10.24.34.0"
}

----------------------------------------

TITLE: Basic OTel Metrics Processor Configuration in YAML
DESCRIPTION: Minimal configuration example for adding the otel_metrics processor to a pipeline.yaml file.

LANGUAGE: yaml
CODE:
processor:
    - otel_metrics:

----------------------------------------

TITLE: Multi-match Query with Wildcards
DESCRIPTION: Shows how to use wildcards in field names to search across 'speaker' and all 'play_*' fields.

LANGUAGE: json
CODE:
GET _search
{
  "query": {
    "multi_match": {
      "query": "hamlet",
      "fields": ["speaker", "play_*"]
    }
  }
}

----------------------------------------

TITLE: Querying Documents by _id in OpenSearch
DESCRIPTION: This snippet shows how to query documents using the _id field in OpenSearch. It uses a terms query to retrieve documents with specific _id values.

LANGUAGE: json
CODE:
GET test-index1/_search
{
  "query": {
    "terms": {
      "_id": ["1", "2"]
    }
  }
}

----------------------------------------

TITLE: Detailed Workflow Provisioning Response
DESCRIPTION: Example response for synchronous provisioning including workflow state and created resources.

LANGUAGE: json
CODE:
{
    "workflow_id": "K13IR5QBEpCfUu_-AQdU",
    "state": "COMPLETED",
    "resources_created": [
        {
            "workflow_step_name": "create_connector",
            "workflow_step_id": "create_connector_1",
            "resource_id": "LF3IR5QBEpCfUu_-Awd_",
            "resource_type": "connector_id"
        },
        {
            "workflow_step_id": "register_model_2",
            "workflow_step_name": "register_remote_model",
            "resource_id": "L13IR5QBEpCfUu_-BQdI",
            "resource_type": "model_id"
        },
        {
            "workflow_step_name": "deploy_model",
            "workflow_step_id": "deploy_model_3",
            "resource_id": "L13IR5QBEpCfUu_-BQdI",
            "resource_type": "model_id"
        }
    ]
}

----------------------------------------

TITLE: Geo-bounding Box Query Using Geohash in OpenSearch
DESCRIPTION: Executes a geo-bounding box query using geohashes to specify the bounding box coordinates.

LANGUAGE: json
CODE:
GET testindex1/_search
{
  "query": {
    "bool": {
      "must": {
        "match_all": {}
      },
      "filter": {
        "geo_bounding_box": {
          "point": {
            "top_left": "ut7ftjkfxm34",
            "bottom_right": "uuvpkcprc4rc"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Retrieving Specific Alias Information
DESCRIPTION: Example request to fetch information for a specific alias with verbose output.

LANGUAGE: json
CODE:
GET _cat/aliases/<alias>?v

----------------------------------------

TITLE: Creating a Mapping with Integer Field in OpenSearch
DESCRIPTION: This example demonstrates how to create a mapping where 'integer_value' is defined as an integer field type in OpenSearch.

LANGUAGE: json
CODE:
PUT testindex 
{
  "mappings" : {
    "properties" :  {
      "integer_value" : {
        "type" : "integer"
      }
    }
  }
}

----------------------------------------

TITLE: Alert Message Template for Associated Queries
DESCRIPTION: This Mustache template demonstrates how to format an alert message to include associated queries from a document-level monitor.

LANGUAGE: groovy
CODE:
Alerts:
{{#ctx.alerts}}
    RULES
    {{#associated_queries}}
        Name: {{name}}
        Id: {{id}}
        Tags: {{tags}}
    ------------------------
    {{/associated_queries}}
{{/ctx.alerts}}

----------------------------------------

TITLE: Querying Field Metadata in OpenSearch SQL
DESCRIPTION: This SQL query uses the DESCRIBE command to retrieve metadata for all fields in the 'accounts' index. It provides detailed information about each field's properties.

LANGUAGE: sql
CODE:
DESCRIBE TABLES LIKE accounts

----------------------------------------

TITLE: Storing an attachment with custom character limit in OpenSearch
DESCRIPTION: JSON command to store a base64-encoded attachment in OpenSearch, specifying a custom character limit for content extraction.

LANGUAGE: json
CODE:
PUT example-attachment-index/_doc/lorem_rtf?pipeline=attachment
{
  "data": "e1xydGYxXGFuc2kNCkxvcmVtIGlwc3VtIGRvbG9yIHNpdCBhbWV0DQpccGFyIH0=",
  "max_chars": 15
}

----------------------------------------

TITLE: Retrieving Snapshot Repository Endpoint - JSON
DESCRIPTION: The GET endpoint for retrieving snapshot repository information. The repository parameter can include comma-separated repository names and supports wildcard expressions.

LANGUAGE: json
CODE:
GET /_snapshot/<repository>

----------------------------------------

TITLE: Retrieving Metric Units in Performance Analyzer API for OpenSearch
DESCRIPTION: Demonstrates how to query the Performance Analyzer API to retrieve the units for each available metric using a specific endpoint.

LANGUAGE: http
CODE:
GET localhost:9600/_plugins/_performanceanalyzer/metrics/units

----------------------------------------

TITLE: Executing Search with Collapse Pipeline
DESCRIPTION: Performs a search request using the collapse pipeline to get deduplicated results.

LANGUAGE: json
CODE:
POST /my_index/_search?search_pipeline=collapse_pipeline
{
  "size": 3
}

----------------------------------------

TITLE: Ingesting Document with CSV Processor
DESCRIPTION: Example of ingesting a document using the CSV processor pipeline, demonstrating how to submit data for processing.

LANGUAGE: json
CODE:
{
  "resource_usage": "25,4096,10"
}

----------------------------------------

TITLE: Indexing XY Polygon with Hole - GeoJSON Format
DESCRIPTION: Indexes a polygon with a triangular hole using GeoJSON format.

LANGUAGE: json
CODE:
PUT testindex/_doc/4
{
  "location" : {
    "type" : "polygon",
    "coordinates" : [
      [[0.5, 4.5], 
      [2.5, 6.0], 
      [1.5, 2.0], 
      [0.5, 4.5]],
      
      [[1.0, 4.5], 
      [1.5, 4.5], 
      [1.5, 4.0], 
      [1.0, 4.5]]
    ]
  }
}

----------------------------------------

TITLE: Setting JVM Heap Sizes for OpenSearch
DESCRIPTION: This configuration snippet sets the initial and maximum JVM heap sizes for OpenSearch in the jvm.options file.

LANGUAGE: yaml
CODE:
-Xms4g
-Xmx4g

----------------------------------------

TITLE: Querying Paginated Data with SQL in OpenSearch
DESCRIPTION: Shows how to execute a paginated query using SQL in OpenSearch, selecting origin and destination countries from a flight dataset with a specified fetch size and ordering.

LANGUAGE: json
CODE:
{
  "fetch_size" : 5,
  "query" : "SELECT OriginCountry, DestCountry FROM opensearch_dashboards_sample_data_flights ORDER BY OriginCountry ASC"
}

----------------------------------------

TITLE: Configuring Job Parameters in Java
DESCRIPTION: Example of job parameter configuration class that implements ScheduledJobParameter interface, defining fields and methods for job configuration.

LANGUAGE: java
CODE:
/**
 * A sample job parameter.
 * <p>
 * It adds an additional "indexToWatch" field to {@link ScheduledJobParameter}, which stores the index
 * the job runner will watch.
 */
public class SampleJobParameter implements ScheduledJobParameter {
    public static final String NAME_FIELD = "name";
    public static final String ENABLED_FILED = "enabled";
    public static final String LAST_UPDATE_TIME_FIELD = "last_update_time";
    public static final String LAST_UPDATE_TIME_FIELD_READABLE = "last_update_time_field";
    public static final String SCHEDULE_FIELD = "schedule";
    public static final String ENABLED_TIME_FILED = "enabled_time";
    public static final String ENABLED_TIME_FILED_READABLE = "enabled_time_field";
    public static final String INDEX_NAME_FIELD = "index_name_to_watch";
    public static final String LOCK_DURATION_SECONDS = "lock_duration_seconds";
    public static final String JITTER = "jitter";

    private String jobName;
    private Instant lastUpdateTime;
    private Instant enabledTime;
    private boolean isEnabled;
    private Schedule schedule;
    private String indexToWatch;
    private Long lockDurationSeconds;
    private Double jitter;

----------------------------------------

TITLE: Configuring Metrics for Star-tree Index
DESCRIPTION: Example showing how to configure multiple fields with various metric statistics in a star-tree index, demonstrating the maximum supported metrics configuration with 25 fields.

LANGUAGE: json
CODE:
{
  "metrics": [
    {
      "name": "field1",
      "stats": [
        "sum",
        "value_count",
        "min",
        "max"
      ],
      ...,
      ...,
      "name": "field25",
      "stats": [
        "sum",
        "value_count",
        "min",
        "max"
      ]
    }
  ]
}

----------------------------------------

TITLE: Indexing Geopoint as Coordinate Array
DESCRIPTION: Demonstrates indexing a geopoint using an array in [longitude, latitude] format.

LANGUAGE: json
CODE:
PUT testindex1/_doc/4
{
  "point": [74.00, 40.71] 
}

----------------------------------------

TITLE: Configuring Kafka Buffer in HTTP Pipeline
DESCRIPTION: Example configuration showing how to set up a Kafka buffer in an HTTP pipeline with a local Kafka cluster. The pipeline includes an HTTP source, Kafka buffer configuration, Grok processor, and stdout sink.

LANGUAGE: yaml
CODE:
kafka-buffer-pipeline:
  source:
    http:
  buffer:
    kafka:
      bootstrap_servers: ["localhost:9092"]
      encryption:
        type: none
      topics:
        - name: my-buffer-topic
          group_id: data-prepper
          create_topic: true
  processor:
    - grok:
        match:
          message: [ "%{COMMONAPACHELOG}" ]
  sink:
    - stdout:

----------------------------------------

TITLE: Render Template API Response
DESCRIPTION: Example response showing the rendered template output with resolved variables and default values.

LANGUAGE: json
CODE:
{
  "template_output": {
    "from": "0",
    "size": "10",
    "query": {
      "match": {
        "play_name": "Henry IV"
      }
    }
  }
}

----------------------------------------

TITLE: Installing OpenSearch Benchmark via pip
DESCRIPTION: Command to install OpenSearch Benchmark using pip package manager.

LANGUAGE: bash
CODE:
pip3 install opensearch-benchmark

----------------------------------------

TITLE: Example GET Request for Retrieving Agent Information in OpenSearch
DESCRIPTION: This snippet shows an example GET request to retrieve information for a specific agent using its ID. The request is made to the /_plugins/_ml/agents/ endpoint followed by the agent ID.

LANGUAGE: json
CODE:
GET /_plugins/_ml/agents/N8AE1osB0jLkkocYjz7D

----------------------------------------

TITLE: Indexing a Query with Percolator Field in OpenSearch
DESCRIPTION: This example demonstrates how to index a query using the percolator field. The query searches for items matching 'table' with a price less than or equal to $400.

LANGUAGE: json
CODE:
PUT testindex1/_doc/1
{
  "search": {
    "query": {
      "bool": {
        "filter": [
          { 
            "match": { 
              "item": { 
                "query": "table" 
              }
            }
          },
          { 
            "range": { 
              "price": { 
                "lte": 400.00 
              } 
            } 
          }
        ]
      }
    }
  }
}

----------------------------------------

TITLE: Creating Custom Bengali Analyzer in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a custom Bengali analyzer with specific token filters and apply it to a text field in an OpenSearch index.

LANGUAGE: json
CODE:
PUT /bengali-index
{
  "settings": {
    "analysis": {
      "filter": {
        "bengali_stop": {
          "type": "stop",
          "stopwords": "_bengali_"
        },
        "bengali_stemmer": {
          "type": "stemmer",
          "language": "bengali"
        },
        "bengali_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] 
        }
      },
      "analyzer": {
        "bengali_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "decimal_digit",
            "indic_normalization",
            "bengali_normalization",
            "bengali_stop",
            "bengali_keywords",
            "bengali_stemmer"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "bengali_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Configuring French Analyzer with Stem Exclusion
DESCRIPTION: Shows how to create a French analyzer with specific terms excluded from stemming process.

LANGUAGE: json
CODE:
PUT index_with_stem_exclusion_french_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "stem_exclusion_french_analyzer": {
          "type": "french",
          "stem_exclusion": ["autorit", "acceptation"]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Analyzing Text with Greek Lowercase Filter in OpenSearch
DESCRIPTION: This example demonstrates how to analyze text using the custom analyzer with the Greek lowercase filter. It sends a request to examine the tokens generated for the given Greek text.

LANGUAGE: json
CODE:
GET /custom_lowercase_example/_analyze
{
  "analyzer": "greek_lowercase_example",
  "text": " "
}

----------------------------------------

TITLE: Retrieving Tiered Spillover Cache Statistics with JSON
DESCRIPTION: Uses the Node Stats API to retrieve statistics for the tiered spillover cache, helping assess its impact on performance.

LANGUAGE: json
CODE:
GET /_nodes/stats/caches/request_cache?level=tier

----------------------------------------

TITLE: Configuring Fingerprint Processor in OpenSearch
DESCRIPTION: Basic configuration example of the fingerprint processor showing the core parameters. Demonstrates setting fields to hash, target field for the hash value, and hash method selection.

LANGUAGE: json
CODE:
{
  "community_id": {
    "fields": ["foo", "bar"],
    "target_field": "fingerprint",
    "hash_method": "SHA-1@2.16.0"
  }
}

----------------------------------------

TITLE: Querying Segments for Specific Index in OpenSearch
DESCRIPTION: This snippet demonstrates how to use the Segment API to retrieve segment information for a specific index named 'index1'.

LANGUAGE: json
CODE:
GET /index1/_segments

----------------------------------------

TITLE: Creating Mapping with Rank Feature Fields in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a mapping with rank_feature fields in OpenSearch. It includes fields for name (text), rating (rank_feature), and age (rank_feature with negative impact).

LANGUAGE: json
CODE:
PUT chessplayers
{
  "mappings": {
    "properties": {
      "name" : {
        "type" : "text"
      },
      "rating": {
        "type": "rank_feature" 
      },
      "age": {
        "type": "rank_feature",
        "positive_score_impact": false 
      }
    }
  }
}

----------------------------------------

TITLE: Script Action in OpenSearch Bulk API
DESCRIPTION: Demonstrates the format for a script action in the bulk API. This allows for more complex document updates using a specified script.

LANGUAGE: json
CODE:
{ "update": { "_index": "movies", "_id": "tt0816711" } }
{ "script" : { "source": "ctx._source.title = \"World War Z\"" } }

----------------------------------------

TITLE: Rescoring Top N Results with LTR
DESCRIPTION: Demonstrates using rescore functionality to apply LTR model to top N results of a baseline query. The query first executes a match for 'rambo' then applies 'my_model' to the top 1000 results.

LANGUAGE: json
CODE:
    POST tmdb/_search
    {
        "query": {
            "match": {
                "_all": "rambo"
            }
        },
        "rescore": {
            "window_size": 1000,
            "query": {
                "rescore_query": {
                    "sltr": {
                        "params": {
                            "keywords": "rambo"
                        },
                        "model": "my_model"
                    }
                }
            }
        }
    }

----------------------------------------

TITLE: Retrieving Index Context Settings Response
DESCRIPTION: Sample response showing the settings and configurations applied after creating an index with metrics context.

LANGUAGE: json
CODE:
{
    "my-metrics-index": {
        "aliases": {},
        "mappings": {},
        "settings": {
            "index": {
                "codec": "zstd_no_dict",
                "refresh_interval": "60s",
                "number_of_shards": "1",
                "provided_name": "my-metrics-index",
                "merge": {
                    "policy": "log_byte_size"
                },
                "context": {
                    "created_version": "1",
                    "current_version": "1"
                }
            }
        },
        "context": {
            "name": "metrics",
            "version": "_latest"
        }
    }
}

----------------------------------------

TITLE: Creating an OpenSearch Index with Custom Mappings in Rust
DESCRIPTION: Create an OpenSearch index with custom mappings using the indices().create() function.

LANGUAGE: rust
CODE:
let response = client
    .indices()
    .create(IndicesCreateParts::Index("movies"))
    .body(json!({
        "mappings" : {
            "properties" : {
                "title" : { "type" : "text" }
            }
        }
    }))
    .send()
    .await?;

----------------------------------------

TITLE: Executing a Complex Children Aggregation Query in OpenSearch
DESCRIPTION: This query demonstrates a complex use of children aggregations to analyze relationships between authors, their posts, and comments on those posts, including counting comments per post.

LANGUAGE: json
CODE:
GET /blog-sample/_search
{
  "size": 0,
  "aggs": {
    "authors": {
      "terms": {
        "field": "name.keyword"
      },
      "aggs": {
        "posts": {
          "children": {
            "type": "post"
          },
          "aggs": {
            "post_titles": {
              "terms": {
                "field": "title.keyword"
              },
              "aggs": {
                "comments": {
                  "children": {
                    "type": "comment"
                  },
                  "aggs": {
                    "comment_count": {
                      "value_count": {
                        "field": "_id"
                      }
                    }
                  }
                }
              }
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating a Pipeline with Bytes Processor in OpenSearch
DESCRIPTION: This example demonstrates how to create an ingest pipeline named 'file_upload' that uses the bytes processor to convert a 'file_size' field to its byte equivalent and store it in a new field.

LANGUAGE: json
CODE:
PUT _ingest/pipeline/file_upload
{
  "description": "Pipeline that converts file size to bytes",
  "processors": [
    {
      "bytes": {
        "field": "file_size",
        "target_field": "file_size_bytes"
      }
    }
  ]
}

----------------------------------------

TITLE: Creating Destination Index for Reindex
DESCRIPTION: Creates a new destination index with custom mappings and settings before reindexing data.

LANGUAGE: json
CODE:
PUT destination
{
   "mappings":{
      "Add in your desired mappings"
   },
   "settings":{
      "Add in your desired settings"
   }
}

----------------------------------------

TITLE: Retrieving Node Cache Statistics in OpenSearch
DESCRIPTION: Shows how to retrieve cache statistics for all nodes using the Nodes Stats API.

LANGUAGE: json
CODE:
GET /_nodes/stats/indices/request_cache

LANGUAGE: json
CODE:
{
  "nodes": {
    "T7aqO6zaQX-lt8XBWBYLsA": {
      "indices": {
        "request_cache": {
          "memory_size_in_bytes": 10240,
          "evictions": 0,
          "hit_count": 50,
          "miss_count": 10
        }
      }
    }
  }
}

----------------------------------------

TITLE: Equality Operator Examples in OpenSearch Data Prepper
DESCRIPTION: Examples of using equality operators to compare JSON pointers, literals, and expressions.

LANGUAGE: markdown
CODE:
/is_cool == true
3.14 != /status_code
{1, 2} == /event/set_property

----------------------------------------

TITLE: Creating Index with Hunspell Filter Configuration
DESCRIPTION: Example of creating a new index with a custom analyzer that includes a Hunspell token filter configuration. The analyzer uses the en_GB dictionary with deduplication and longest-only settings enabled.

LANGUAGE: json
CODE:
PUT /my_index
{
  "settings": {
    "analysis": {
      "filter": {
        "my_hunspell_filter": {
          "type": "hunspell",
          "lang": "en_GB",
          "dedup": true,
          "longest_only": true
        }
      },
      "analyzer": {
        "my_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "my_hunspell_filter"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating Snapshot in OpenSearch
DESCRIPTION: This HTTP PUT request demonstrates how to create a new snapshot in a specified repository in OpenSearch.

LANGUAGE: http
CODE:
PUT _snapshot/my-repository/my-snapshot

----------------------------------------

TITLE: Configuring Date Processor in OpenSearch Ingest Pipeline
DESCRIPTION: Example syntax for configuring the date processor in an OpenSearch ingest pipeline. It specifies the field to process and the expected date format.

LANGUAGE: json
CODE:
{
  "date": {
    "field": "date_field",
    "formats": ["yyyy-MM-dd'T'HH:mm:ss.SSSZZ"]
  }
}

----------------------------------------

TITLE: Multiple Children Join Field Mapping
DESCRIPTION: Example of creating a join field mapping that supports multiple child types for a single parent.

LANGUAGE: json
CODE:
PUT testindex1
{
  "mappings": {
    "properties": {
      "parent_to_child": {
        "type": "join",
        "relations": {
          "parent": ["child 1", "child 2"]  
        }
      }
    }
  }
}

----------------------------------------

TITLE: Performing auto_date_histogram aggregation
DESCRIPTION: Executes an auto_date_histogram aggregation on the 'date_posted' field of the 'blogs' index, requesting 2 buckets.

LANGUAGE: json
CODE:
GET /blogs/_search
{
  "size": 0,
  "aggs": {
    "histogram": {
      "auto_date_histogram": {
        "field": "date_posted",
        "buckets": 2
      }
    }
  }
}

----------------------------------------

TITLE: Starting Performance Analyzer RCA Agent
DESCRIPTION: Command to start the Performance Analyzer root cause analysis agent on a tarball installation.

LANGUAGE: bash
CODE:
OPENSEARCH_HOME=~/opensearch-2.2.1 OPENSEARCH_JAVA_HOME=~/opensearch-2.2.1/jdk OPENSEARCH_PATH_CONF=~/opensearch-2.2.1/bin ./performance-analyzer-agent-cli

----------------------------------------

TITLE: Range Query on Unsigned Long Field
DESCRIPTION: Shows how to perform range queries on unsigned_long fields.

LANGUAGE: json
CODE:
POST _search
{
  "query": {
    "range": {
      "counter": {
        "gte": 10223372036854775807
      }
    }
  }
}

----------------------------------------

TITLE: Querying CAT Snapshots Endpoints in OpenSearch
DESCRIPTION: HTTP GET endpoints for retrieving snapshot information using the CAT API in OpenSearch. These endpoints allow listing all snapshots or snapshots for a specific repository.

LANGUAGE: json
CODE:
GET /_cat/snapshots
GET /_cat/snapshots/{repository}

----------------------------------------

TITLE: Conditional Truncate Processor Configuration in YAML
DESCRIPTION: Shows how to configure the truncate processor with conditional processing using the truncate_when option.

LANGUAGE: yaml
CODE:
pipeline:
  source:
    file:
      path: "/full/path/to/logs_json.log"
      record_type: "event"
      format: "json"
  processor:
    - truncate:
        entries:
          - source_keys: ["message"]
            length: 5
            start_at: 8
            truncate_when: '/id == 1'
  sink:
    - stdout:

----------------------------------------

TITLE: Testing Sparse Encoding Pipeline
DESCRIPTION: Example request to test the sparse encoding pipeline by simulating document processing with sample text input.

LANGUAGE: json
CODE:
{
  "docs": [
    {
      "_index": "testindex1",
      "_id": "1",
      "_source":{
         "passage_text": "hello world"
      }
    }
  ]
}

----------------------------------------

TITLE: Restore Snapshot API Endpoint in OpenSearch
DESCRIPTION: The main endpoint for restoring a snapshot in OpenSearch. It requires the repository and snapshot names as path parameters.

LANGUAGE: json
CODE:
POST _snapshot/<repository>/<snapshot>/_restore

----------------------------------------

TITLE: Mapping Anonymous Role in roles_mapping.yml
DESCRIPTION: Role mapping configuration that associates the anonymous user role with the anonymous backend role in OpenSearch's roles_mapping.yml file.

LANGUAGE: yaml
CODE:
anonymous_users_role:
  reserved: false
  hidden: false
  backend_roles: ["opendistro_security_anonymous_backendrole"]
  hosts: []

----------------------------------------

TITLE: Input JSON for copy_values Processor
DESCRIPTION: This JSON snippet represents an example input event for the copy_values processor, containing a message field to be copied.

LANGUAGE: json
CODE:
{"message1": "hello", "message2": "bye"}

----------------------------------------

TITLE: Creating CSV Processing Pipeline in OpenSearch
DESCRIPTION: Example of creating a pipeline named 'csv-processor' that splits resource usage data into three specific fields: cpu_usage, memory_usage, and disk_usage.

LANGUAGE: json
CODE:
{
  "description": "Split resource usage into individual fields",
  "processors": [
    {
      "csv": {
        "field": "resource_usage",
        "target_fields": ["cpu_usage", "memory_usage", "disk_usage"],
        "separator": ","
      }
    }
  ]
}

----------------------------------------

TITLE: Searching Object Fields in OpenSearch
DESCRIPTION: This snippet demonstrates how to search for a specific value in an object field in OpenSearch. It searches for a patient with ID '123456' using the term query.

LANGUAGE: json
CODE:
GET testindex1/_search
{
  "query": {
    "term" : {
      "patient.id" : "123456"
    }
  }
}

----------------------------------------

TITLE: Sample Output from Grok Processor
DESCRIPTION: This snippet demonstrates the output generated by the grok processor after parsing the input message. It extracts the clientip, timestamp, and response_status fields.

LANGUAGE: json
CODE:
{ 
  "message":"127.0.0.1 198.126.12 [10/Oct/2000:13:55:36 -0700] 200",
  "response_status":200,
  "clientip":"198.126.12",
  "timestamp":"10/Oct/2000:13:55:36 -0700"
}

----------------------------------------

TITLE: Response from Keep Words Filter Analysis in OpenSearch
DESCRIPTION: Example response showing the tokens generated by the keep_words filter, including position and offset information for each retained token.

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "world",
      "start_offset": 7,
      "end_offset": 12,
      "type": "<ALPHANUM>",
      "position": 1
    },
    {
      "token": "OpenSearch",
      "start_offset": 25,
      "end_offset": 35,
      "type": "<ALPHANUM>",
      "position": 5
    },
    {
      "token": "example",
      "start_offset": 36,
      "end_offset": 43,
      "type": "<ALPHANUM>",
      "position": 6
    }
  ]
}

----------------------------------------

TITLE: Configuring Irish Analyzer with Stem Exclusion
DESCRIPTION: Demonstrates how to create an Irish analyzer with stem exclusion for specific words.

LANGUAGE: json
CODE:
PUT index_with_stem_exclusion_irish_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "stem_exclusion_irish_analyzer": {
          "type": "irish",
          "stem_exclusion": ["dars", "faomhadh"]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Mapping Text Field with Custom Analyzer in OpenSearch
DESCRIPTION: This snippet shows how to map a text field to use a custom analyzer for both indexing and searching operations in OpenSearch.

LANGUAGE: json
CODE:
"mappings": {
  "properties": {
    "my_text_field": {
      "type": "text",
      "analyzer": "my_custom_analyzer"
    }
  }
}

----------------------------------------

TITLE: Register Response Example
DESCRIPTION: Example response showing the created model group ID and status

LANGUAGE: json
CODE:
{
    "model_group_id": "GDNmQ4gBYW0Qyy5ZcBcg",
    "status": "CREATED"
}

----------------------------------------

TITLE: Range Query on Date Fields in OpenSearch
DESCRIPTION: This example shows how to use a range query on date fields to find products added in the year 2019.

LANGUAGE: json
CODE:
GET products/_search
{
  "query": {
    "range": {
      "created": {
        "gte": "2019/01/01",
        "lte": "2019/12/31"
      }
    }
  }
}

----------------------------------------

TITLE: Indexing Documents with Flat Object Fields in OpenSearch
DESCRIPTION: These snippets show how to index two documents with flat object fields in OpenSearch.

LANGUAGE: json
CODE:
PUT /test-index/_doc/1
{
  "issue": {
    "number": "123456",
    "labels": {
      "version": "2.1",
      "backport": [
        "2.0",
        "1.3"
      ],
      "category": {
        "type": "API",
        "level": "enhancement"
      }
    }
  }
}

LANGUAGE: json
CODE:
PUT /test-index/_doc/2
{
  "issue": {
    "number": "123457",
    "labels": {
      "version": "2.2",
      "category": {
        "type": "API",
        "level": "bug"
      }
    }
  }
}

----------------------------------------

TITLE: Retrieving Workload Management Stats in OpenSearch
DESCRIPTION: API request to fetch workload management metrics for query groups. This provides information on request completions, rejections, cancellations, and resource usage for CPU and memory.

LANGUAGE: json
CODE:
GET _wlm/stats

----------------------------------------

TITLE: Applying Security Configuration Changes
DESCRIPTION: Use securityadmin.sh to apply security configuration changes to OpenSearch.

LANGUAGE: bash
CODE:
OPENSEARCH_JAVA_HOME=/usr/share/opensearch/jdk ./securityadmin.sh -cd /etc/opensearch/opensearch-security/ -cacert /etc/opensearch/root-ca.pem -cert /etc/opensearch/admin.pem -key /etc/opensearch/admin-key.pem -icl -nhnv

----------------------------------------

TITLE: Querying CAT Recovery for Multiple Indexes in OpenSearch
DESCRIPTION: Example request for retrieving recovery information for multiple indexes using the CAT recovery API in OpenSearch. Indexes are separated by commas.

LANGUAGE: json
CODE:
GET _cat/recovery/index1,index2,index3

----------------------------------------

TITLE: Missing Aggregation with min_doc_count in OpenSearch
DESCRIPTION: Shows how to configure the missing value bucket to appear in results by setting min_doc_count to 0. This ensures the 'N/A' bucket appears even when empty.

LANGUAGE: json
CODE:
GET opensearch_dashboards_sample_data_logs/_search
{
  "size": 0,
  "aggs": {
    "response_codes": {
      "terms": {
        "field": "response.keyword",
        "size": 10,
        "missing": "N/A",
        "min_doc_count": 0
      }
    }
  }
}

----------------------------------------

TITLE: Appending Values to Existing Entries with Add Entries Processor in YAML
DESCRIPTION: This configuration shows how to append values to existing entries, creating an array if the entry doesn't already exist as an array.

LANGUAGE: yaml
CODE:
processor:
  - add_entries:
      entries:
        - key: "message"
          value: "world"
          append_if_key_exists: true

----------------------------------------

TITLE: HTTP Configuration Settings
DESCRIPTION: Configuration block for HTTP-related security settings including anonymous authentication and X-Forwarded-For (XFF) settings.

LANGUAGE: yaml
CODE:
http:
  anonymous_auth_enabled: <true|false>
  xff: # optional section
    enabled: <true|false>
    internalProxies: <string> # Regex pattern
    remoteIpHeader: <string> # Name of the header in which to look. Typically: x-forwarded-for
    proxiesHeader: <string>
    trustedProxies: <string> # Regex pattern

----------------------------------------

TITLE: Configuring Task Logging in YAML
DESCRIPTION: Demonstrates how to configure the logging interval and number of search tasks logged for task resource consumers in the opensearch.yml file.

LANGUAGE: yaml
CODE:
# Number of expensive search tasks to log
cluster.task.consumers.top_n.size:100

# Logging interval
cluster.task.consumers.top_n.frequency:30s

----------------------------------------

TITLE: Ingesting Document with HTML Strip Pipeline in OpenSearch
DESCRIPTION: Ingests a document using the HTML strip pipeline to process HTML content.

LANGUAGE: json
CODE:
PUT products/_doc/1?pipeline=strip-html-pipeline
{
  "name": "Product 1",
  "description": "This is a <b>test</b> product with <i>some</i> HTML tags."
}

----------------------------------------

TITLE: Defining PerfTop Dashboard Query Parameters in JSON
DESCRIPTION: This JSON snippet shows how to define query parameters for a PerfTop dashboard. It specifies metrics, aggregates, dimensions, and sorting criteria for retrieving Performance Analyzer data.

LANGUAGE: json
CODE:
{
  "queryParams": {
    "metrics": "estimated,limitConfigured",
    "aggregates": "avg,avg",
    "dimensions": "type",
    "sortBy": "estimated"
  }
}

----------------------------------------

TITLE: Creating a Mapping with a Wildcard Field in OpenSearch
DESCRIPTION: This JSON snippet demonstrates how to create a mapping with a wildcard field named 'log_line' in OpenSearch. The mapping is applied to an index named 'logs'.

LANGUAGE: json
CODE:
PUT logs
{
  "mappings" : {
    "properties" : {
      "log_line" : {
        "type" :  "wildcard"
      }
    }
  }
}

----------------------------------------

TITLE: Indexing documents with specific timestamps
DESCRIPTION: Indexes documents into a new 'blogs1' index with specific timestamps for demonstrating time zone effects.

LANGUAGE: json
CODE:
PUT blogs1/_doc/1
{
  "name": "Semantic search in OpenSearch",
  "date_posted": "2022-04-17T01:00:00.000Z"
}

LANGUAGE: json
CODE:
PUT blogs1/_doc/2
{
  "name": "Sparse search in OpenSearch",
  "date_posted": "2022-04-17T04:00:00.000Z"
}

----------------------------------------

TITLE: Analyzing Text with Finnish Analyzer in OpenSearch
DESCRIPTION: This example shows how to use the _analyze API to examine the tokens generated by the Finnish analyzer for a given text input in OpenSearch.

LANGUAGE: json
CODE:
POST /finnish-index/_analyze
{
  "field": "content",
  "text": "Opiskelijat opiskelevat Helsingiss ja Suomen yliopistoissa. Heidn numeronsa ovat 123456."
}

----------------------------------------

TITLE: Creating a Threat Intelligence Monitor in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a new threat intelligence monitor using a POST request. It includes the monitor configuration with schedule, user details, indices, IOC scan inputs, and triggers.

LANGUAGE: json
CODE:
{
    "name": "Threat intel monitor",
    "schedule": {
        "period": {
            "interval": 1,
            "unit": "MINUTES"
        }
    },
    "enabled": false,
    "user": {
        "name": "",
        "backend_roles": [],
        "roles": [],
        "custom_attribute_names": [],
        "user_requested_tenant": null
    },
    "indices": [
        "windows"
    ],
    "per_ioc_type_scan_input_list": [
        {
            "ioc_type": "hashes",
            "index_to_fields_map": {
                "windows": [
                    "file_hash"
                ]
            }
        }
    ],
  "triggers": [
        {
            "data_sources": [
                "windows",
                "random"
            ],
            "name": "regwarg",
            "severity": "high"
        }
    ]
}

----------------------------------------

TITLE: Indexing Document with Text Field
DESCRIPTION: Example of indexing a document with a text field value.

LANGUAGE: json
CODE:
PUT testindex/_doc/1
{
    "dob" : "The patient's date of birth."
}

----------------------------------------

TITLE: Retrieving k-NN Model Information in OpenSearch
DESCRIPTION: Shows how to fetch detailed information about a specific k-NN model, including its state, dimensions, and engine type.

LANGUAGE: json
CODE:
GET /_plugins/_knn/models/test-model?pretty

----------------------------------------

TITLE: System Index Permission Configuration
DESCRIPTION: Example of configuring system index permissions in the roles.yml file.

LANGUAGE: yaml
CODE:
alerting-role:
  reserved: true
  hidden: false
  cluster_permissions:
    - 'cluster:admin/opendistro/alerting/alerts/ack'
    - 'cluster:admin/opendistro/alerting/alerts/get'
  index_permissions:
    - index_patterns:
        - .opendistro-alerting-config
    - allowed_actions:
        - 'system:admin/system_index'

----------------------------------------

TITLE: Date Range Query with Format Parameter
DESCRIPTION: Example of a range query using a specific date format for the search criteria.

LANGUAGE: json
CODE:
GET testindex/_search
{
  "query": {
    "range": {
      "release_date": {
        "gte": "2019-01-01",
        "lte": "2019-12-31",
        "format": "yyyy-MM-dd"
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Persian Analyzer with Stem Exclusion
DESCRIPTION: Demonstrates how to create a Persian analyzer with stem exclusion for specific terms.

LANGUAGE: json
CODE:
PUT index_with_stem_exclusion_persian_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "stem_exclusion_persian_analyzer": {
          "type": "persian",
          "stem_exclusion": ["", ""]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Searching for Specific Ignored Field in OpenSearch
DESCRIPTION: This snippet shows how to use a term query to find documents where a specific field (created_at) was ignored during indexing.

LANGUAGE: json
CODE:
GET _search
{
  "query": {
    "term": {
      "_ignored": "created_at"
    }
  }
}

----------------------------------------

TITLE: Using DISTINCT Clause in OpenSearch SQL
DESCRIPTION: Example of using the DISTINCT clause to retrieve only unique values for the 'age' field from the 'accounts' index.

LANGUAGE: sql
CODE:
SELECT DISTINCT age
FROM accounts

----------------------------------------

TITLE: Delete by Query Response Format
DESCRIPTION: Example response showing the format and fields returned by a successful Delete by Query operation.

LANGUAGE: json
CODE:
{
  "took": 143,
  "timed_out": false,
  "total": 1,
  "deleted": 1,
  "batches": 1,
  "version_conflicts": 0,
  "noops": 0,
  "retries": {
    "bulk": 0,
    "search": 0
  },
  "throttled_millis": 0,
  "requests_per_second": -1.0,
  "throttled_until_millis": 0,
  "failures": []
}

----------------------------------------

TITLE: Boosted Field Multi-Match Query in OpenSearch
DESCRIPTION: Example of a multi-match query that boosts the item_name field with a weight of 3 compared to the description field.

LANGUAGE: json
CODE:
{
  "query": {
    "multi_match": {
      "query": "%SearchText%",
      "fields": [ "description", "item_name^3" ]
    }
  }
}

----------------------------------------

TITLE: Analyzing Text with Custom HTML Strip and Lowercase Analyzer in OpenSearch
DESCRIPTION: This snippet shows how to use the custom analyzer created in the previous example to analyze HTML text, removing tags and converting to lowercase.

LANGUAGE: json
CODE:
GET /html_strip_and_lowercase_analyzer/_analyze
{
  "analyzer": "html_strip_analyzer",
  "text": "<h1>Welcome to <strong>OpenSearch</strong>!</h1>"
}

----------------------------------------

TITLE: Connecting to Amazon OpenSearch Serverless in Rust
DESCRIPTION: Create an OpenSearch client to connect to Amazon OpenSearch Serverless Service.

LANGUAGE: rust
CODE:
let url = Url::parse("https://...");
let service_name = "aoss";
let conn_pool = SingleNodeConnectionPool::new(url?);
let region_provider = RegionProviderChain::default_provider().or_else("us-east-1");
let aws_config = aws_config::from_env().region(region_provider).load().await.clone();
let transport = TransportBuilder::new(conn_pool)
    .auth(aws_config.clone().try_into()?)
    .service_name(service_name)
    .build()?
let client = OpenSearch::new(transport);

----------------------------------------

TITLE: Configuring Admin Access for Single User in YAML
DESCRIPTION: This YAML configuration sets admin access for a single user with a specific user ID.

LANGUAGE: yaml
CODE:
opensearchDashboards.dashboardAdmin.users: ["admin-user-id"]

----------------------------------------

TITLE: Anomaly Detection Response Example in JSON
DESCRIPTION: Example JSON output showing an anomaly detection result with latency value, deviation calculation, and anomaly grade.

LANGUAGE: json
CODE:
{ "latency": 11.5, "deviation_from_expected":[10.469302736820003],"grade":1.0}

----------------------------------------

TITLE: Join Pipeline Response Example
DESCRIPTION: Example response showing the successful joining of URI components into a single string.

LANGUAGE: json
CODE:
{  
  "docs": [  
    {  
      "doc": {  
        "_index": "_index",  
        "_id": "_id",  
        "_source": {  
          "uri": "app/home/overview"  
        },  
        "_ingest": {  
          "timestamp": "2024-05-24T02:16:01.00659117Z"  
        }  
      }  
    }  
  ]  
}

----------------------------------------

TITLE: Node-Specific Task Header Attachment
DESCRIPTION: Curl command showing how to associate X-Opaque-Id with tasks on a specific node.

LANGUAGE: bash
CODE:
curl -i -H "X-Opaque-Id: 123456" "https://localhost:9200/_tasks?nodes=opensearch-node1" -u 'admin:<custom-admin-password>' --insecure

----------------------------------------

TITLE: Adding Alias During Index Creation
DESCRIPTION: Shows how to create an alias while creating a new index.

LANGUAGE: json
CODE:
PUT index-1
{
  "aliases": {
    "alias1": {}
  }
}

----------------------------------------

TITLE: Collapsed Search Query by Item Field
DESCRIPTION: Searches for cakes while collapsing results by item field to remove duplicates, sorted by price.

LANGUAGE: json
CODE:
GET /bakery-items/_search
{
  "query": {
    "match": {
      "category": "cakes"
    }
  },
  "collapse": {
    "field": "item"
  },
  "sort": ["price"]
}

----------------------------------------

TITLE: Querying Elasticsearch Nodes
DESCRIPTION: These curl commands show how to query Elasticsearch nodes to verify their status and version, with and without security enabled.

LANGUAGE: bash
CODE:
# Elasticsearch OSS
curl -XGET 'localhost:9200/_nodes/_all?pretty=true'
# Open Distro for Elasticsearch with Security plugin enabled
curl -XGET 'https://localhost:9200/_nodes/_all?pretty=true' -u 'admin:<custom-admin-password>' -k

----------------------------------------

TITLE: Configuring Performance Analyzer Properties
DESCRIPTION: Example configuration for the performance-analyzer.properties file, including webservice bind host and metrics settings.

LANGUAGE: properties
CODE:
webservice-bind-host = 0.0.0.0
metrics-location = /dev/shm/performanceanalyzer/
metrics-deletion-interval = 1
cleanup-metrics-db-files = true
webservice-listener-port = 9600
metrics-db-file-prefix-path = /tmp/metricsdb_
https-enabled = false
plugin-stats-metadata = plugin-stats-metadata
agent-stats-metadata = agent-stats-metadata

----------------------------------------

TITLE: Aggregated Results JSON Structure in OpenSearch Benchmark
DESCRIPTION: This JSON snippet illustrates the structure of aggregated results, including overall min/max values, mean, median, and relative standard deviation (RSD).

LANGUAGE: json
CODE:
{
    "throughput": {
     "overall_min": 29056.890292903263,
     "mean": 50115.8603858536,
     "median": 50099.54349684457,
     "overall_max": 72255.15946248993,
     "unit": "docs/s",
     "mean_rsd": 59.426059705973664
    }
}

----------------------------------------

TITLE: Indexing Suggestions in OpenSearch
DESCRIPTION: This snippet shows how to index suggestions into OpenSearch using the completion field. It includes multiple input suggestions with associated weights for ranking.

LANGUAGE: json
CODE:
PUT chess_store/_doc/1
{
  "suggestions": {
      "input": ["Books on openings", "Books on endgames"],
      "weight" : 10
    }
}

----------------------------------------

TITLE: Wildcard Query with Field Parameters
DESCRIPTION: Template showing the structure of a wildcard query with field parameters including value, boost, case_insensitive, and rewrite options.

LANGUAGE: json
CODE:
GET _search
{
  "query": {
    "wildcard": {
      "<field>": {
        "value": "patt*rn",
        ...
      }
    }
  }
}

----------------------------------------

TITLE: Checking Linux Max Map Count
DESCRIPTION: Command to verify the current vm.max_map_count setting on Linux systems.

LANGUAGE: bash
CODE:
cat /proc/sys/vm/max_map_count

----------------------------------------

TITLE: Executing Minimum Aggregation Query in OpenSearch
DESCRIPTION: This query demonstrates how to use the 'min' aggregation to find the minimum value of the 'taxful_total_price' field in the 'opensearch_dashboards_sample_data_ecommerce' index. The 'size' parameter is set to 0 to exclude individual documents from the response.

LANGUAGE: json
CODE:
GET opensearch_dashboards_sample_data_ecommerce/_search
{
  "size": 0,
  "aggs": {
    "min_taxful_total_price": {
      "min": {
        "field": "taxful_total_price"
      }
    }
  }
}

----------------------------------------

TITLE: Cardinality Aggregation with Precision Threshold
DESCRIPTION: Shows how to configure precision threshold for cardinality calculation. The threshold determines the trade-off between memory usage and count accuracy.

LANGUAGE: json
CODE:
GET opensearch_dashboards_sample_data_ecommerce/_search
{
  "size": 0,
  "aggs": {
    "unique_products": {
      "cardinality": {
        "field": "products.product_id",
        "precision_threshold": 10000
      }
    }
  }
}

----------------------------------------

TITLE: Upgrading OpenSearch Dashboards
DESCRIPTION: Commands to upgrade OpenSearch Dashboards using either dpkg for manual upgrade or apt-get for repository-based upgrade.

LANGUAGE: bash
CODE:
sudo dpkg -i opensearch-dashboards-{{site.opensearch_version}}-linux-x64.deb
sudo apt-get upgrade opensearch-dashboards
sudo apt-get upgrade opensearch-dashboards=<version>
sudo systemctl enable opensearch-dashboards.service

----------------------------------------

TITLE: Querying Hot Shard Identification RCA in OpenSearch
DESCRIPTION: This curl command sends a GET request to the Performance Analyzer plugin to retrieve hot shard identification data. It targets the HotShardClusterRca endpoint.

LANGUAGE: bash
CODE:
GET _plugins/_performanceanalyzer/rca?name=HotShardClusterRca

----------------------------------------

TITLE: Ingesting Document with Bytes Processor Pipeline in OpenSearch
DESCRIPTION: This example shows how to ingest a document into the 'testindex1' index using the 'file_upload' pipeline, which will convert the file size to bytes.

LANGUAGE: json
CODE:
PUT testindex1/_doc/1?pipeline=file_upload
{
  "file_size": "10MB"
}

----------------------------------------

TITLE: Generating a Private Key for OpenSSL
DESCRIPTION: Command to generate a 2048-bit RSA private key using OpenSSL.

LANGUAGE: bash
CODE:
openssl genrsa -out root-ca-key.pem 2048

----------------------------------------

TITLE: Ingesting documents for neural sparse search
DESCRIPTION: Indexes documents into the neural sparse search-enabled index, which will automatically generate embeddings.

LANGUAGE: json
CODE:
PUT /my-nlp-index/_doc/1
{
  "passage_text": "Hello world",
  "id": "s1"
}

----------------------------------------

TITLE: Hunspell Analysis Response
DESCRIPTION: Example response showing the tokens generated by the Hunspell analyzer, including token positions and offsets.

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "the",
      "start_offset": 0,
      "end_offset": 3,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "turtle",
      "start_offset": 4,
      "end_offset": 10,
      "type": "<ALPHANUM>",
      "position": 1
    },
    {
      "token": "move",
      "start_offset": 11,
      "end_offset": 16,
      "type": "<ALPHANUM>",
      "position": 2
    },
    {
      "token": "slow",
      "start_offset": 17,
      "end_offset": 23,
      "type": "<ALPHANUM>",
      "position": 3
    }
  ]
}

----------------------------------------

TITLE: Task Header Attachment
DESCRIPTION: Curl command demonstrating how to attach an X-Opaque-Id header to task requests for tracking.

LANGUAGE: bash
CODE:
curl -i -H "X-Opaque-Id: 111111" "https://localhost:9200/_tasks" -u 'admin:<custom-admin-password>' --insecure

----------------------------------------

TITLE: Basic Append Processor Syntax in OpenSearch
DESCRIPTION: Basic syntax template for configuring the append processor in an OpenSearch ingest pipeline. Shows the required field and value parameters.

LANGUAGE: json
CODE:
{
  "append": {
    "field": "your_target_field",
    "value": ["your_appended_value"]
  }
}

----------------------------------------

TITLE: Creating High-Cardinality Anomaly Detector in OpenSearch
DESCRIPTION: Creates a high-cardinality detector that performs anomaly detection across categorical dimensions using an IP field for categorization. Includes detection interval and window delay configuration.

LANGUAGE: json
CODE:
POST _plugins/_anomaly_detection/detectors
{
  "name": "test-hc-detector",
  "description": "Test detector",
  "time_field": "timestamp",
  "indices": [
    "server_log*"
  ],
  "feature_attributes": [
    {
      "feature_name": "test",
      "feature_enabled": true,
      "aggregation_query": {
        "test": {
          "sum": {
            "field": "value"
          }
        }
      }
    }
  ],
  "filter_query": {
    "bool": {
      "filter": [
        {
          "range": {
            "value": {
              "gt": 1
            }
          }
        }
      ],
      "adjust_pure_negative": true,
      "boost": 1
    }
  },
  "detection_interval": {
    "period": {
      "interval": 1,
      "unit": "Minutes"
    }
  },
  "window_delay": {
    "period": {
      "interval": 1,
      "unit": "Minutes" 
    }
  },
  "category_field": [
    "ip"
  ]
}

----------------------------------------

TITLE: Testing Date Index Name Pipeline in OpenSearch
DESCRIPTION: Shows how to test the 'date-index-name1' pipeline using the _simulate API to ensure it's working as expected before ingesting actual documents.

LANGUAGE: json
CODE:
POST _ingest/pipeline/date-index-name1/_simulate
{
  "docs": [
    {
      "_index": "testindex1",
      "_id": "1",
      "_source": {
        "date_field": "2023-10-30"
      }
    }
  ]
}

----------------------------------------

TITLE: Indexing Document with Object Field in OpenSearch
DESCRIPTION: This snippet shows how to index a document with an object field in OpenSearch. It creates a document with a 'patient' object containing 'name' and 'id' fields.

LANGUAGE: json
CODE:
PUT testindex1/_doc/1
{ 
  "patient": { 
    "name" : "John Doe",
    "id" : "123456"
  } 
}

----------------------------------------

TITLE: Creating OpenSearch Search Pipeline with Oversample Processor
DESCRIPTION: Creates a search pipeline that uses the oversample processor to increase the search size by 50%.

LANGUAGE: json
CODE:
PUT /_search/pipeline/my_pipeline 
{
  "request_processors": [
    {
      "oversample" : {
        "tag" : "oversample_1",
        "description" : "This processor will multiply `size` by 1.5.",
        "sample_factor" : 1.5
      }
    }
  ]
}

----------------------------------------

TITLE: Testing a Grok Processor Pipeline in OpenSearch
DESCRIPTION: This snippet shows how to test the 'log_line' pipeline by simulating document ingestion and processing.

LANGUAGE: json
CODE:
POST _ingest/pipeline/log_line/_simulate
{
  "docs": [
    {
      "_source": {
        "message": "127.0.0.1 198.126.12 10/Oct/2000:13:55:36 -0700 200"
      }
    }
  ]
}

----------------------------------------

TITLE: Creating ML Controller Endpoint Definition
DESCRIPTION: REST endpoint definitions for creating and updating ML controllers.

LANGUAGE: json
CODE:
POST /_plugins/_ml/controllers/<model_id>\nPUT /_plugins/_ml/controllers/<model_id>

----------------------------------------

TITLE: Multi-get API Endpoints in OpenSearch
DESCRIPTION: Defines the available endpoints for the multi-get API in OpenSearch. Supports both GET and POST methods, with optional index specification.

LANGUAGE: json
CODE:
GET _mget
GET <index>/_mget
POST _mget
POST <index>/_mget

----------------------------------------

TITLE: Analyzing Text with Arabic Analyzer in OpenSearch
DESCRIPTION: This example shows how to use the _analyze API to examine the tokens generated by the Arabic analyzer for a given text input. It demonstrates the analyzer's effect on Arabic text, including stemming and number handling.

LANGUAGE: json
CODE:
POST /arabic-index/_analyze
{
  "field": "content",
  "text": "    .  ."
}

----------------------------------------

TITLE: Configuring Decompress Processor in YAML Pipeline
DESCRIPTION: Example configuration of the decompress processor in a Data Prepper pipeline. Shows how to specify fields to decompress, compression type, and conditional execution.

LANGUAGE: yaml
CODE:
processor:
  - decompress:
      decompress_when: '/some_key == null'
      keys: [ "base_64_gzip_key" ]
      type: gzip

----------------------------------------

TITLE: Indexing Geopoint Documents in OpenSearch
DESCRIPTION: These snippets demonstrate how to index documents with geopoint data into the 'national_parks' index.

LANGUAGE: json
CODE:
PUT national_parks/_doc/1
{
  "name": "Yellowstone National Park",
  "location": "44.42, -110.59" 
}

LANGUAGE: json
CODE:
PUT national_parks/_doc/2
{
  "name": "Yosemite National Park",
  "location": "37.87, -119.53" 
}

LANGUAGE: json
CODE:
PUT national_parks/_doc/3
{
  "name": "Death Valley National Park",
  "location": "36.53, -116.93" 
}

----------------------------------------

TITLE: Defining Field Mappings in OpenSearch
DESCRIPTION: This bash command uses cURL to send a PUT request to OpenSearch, defining field mappings for the 'ecommerce' index using the previously downloaded mapping file.

LANGUAGE: bash
CODE:
curl -H "Content-Type: application/json" -X PUT "https://localhost:9200/ecommerce" -ku admin:<custom-admin-password> --data-binary "@ecommerce-field_mappings.json"

----------------------------------------

TITLE: Registering and Deploying a Sparse Encoding Model in OpenSearch
DESCRIPTION: This snippet demonstrates how to register and deploy the 'huggingface/sentence-transformers/all-MiniLM-L12-v2' pretrained model for text embedding in OpenSearch.

LANGUAGE: json
CODE:
POST /_plugins/_ml/models/_register?deploy=true
{
  "name": "huggingface/sentence-transformers/all-MiniLM-L12-v2",
  "version": "1.0.1",
  "model_format": "TORCH_SCRIPT"
}

----------------------------------------

TITLE: Testing Community ID Pipeline in OpenSearch
DESCRIPTION: This JSON query simulates the community_id_pipeline to test its functionality. It provides a sample document with network flow data to process and generate a community ID hash.

LANGUAGE: json
CODE:
POST _ingest/pipeline/commnity_id_pipeline/_simulate
{
  "docs": [
    {
      "_index": "testindex1",
      "_id": "1",
      "_source": {
        "source_ip": "66.35.250.204",
        "source_port": 80,
        "destination_ip": "128.232.110.120",
        "destination_port": 34855,
        "iana_protocol_number": 6
      }
    }
  ]
}

----------------------------------------

TITLE: Auto_date_histogram aggregation with custom date format
DESCRIPTION: Performs an auto_date_histogram aggregation with a custom date format specified for the output.

LANGUAGE: json
CODE:
GET /blogs/_search
{
  "size": 0,
  "aggs": {
    "histogram": {
      "auto_date_histogram": {
        "field": "date_posted",
        "format": "yyyy-MM-dd HH:mm:ss"
      }
    }
  }
}

----------------------------------------

TITLE: Creating Custom Danish Analyzer
DESCRIPTION: Shows how to create a custom Danish analyzer with specific token filters and tokenizer configurations.

LANGUAGE: json
CODE:
{
  "settings": {
    "analysis": {
      "filter": {
        "danish_stop": {
          "type": "stop",
          "stopwords": "_danish_"
        },
        "danish_stemmer": {
          "type": "stemmer",
          "language": "danish"
        },
        "danish_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] 
        }
      },
      "analyzer": {
        "danish_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "danish_stop",
            "danish_keywords",
            "danish_stemmer"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "danish_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Updating Security Detector
DESCRIPTION: Updates an existing detector's configuration using its ID. Allows modifying detector type, name, enabled status, schedule, inputs, and triggers.

LANGUAGE: json
CODE:
PUT /_plugins/_security_analytics/detectors/J1RX1IMByX0LvTiGTddR
{
  "type": "detector",
  "detector_type": "windows",
  "name": "windows_detector",
  "enabled": true,
  "createdBy": "chip",
  "schedule": {
    "period": {
      "interval": 1,
      "unit": "MINUTES"
    }
  },
  "inputs": [
    {
      "input": {
        "description": "windows detector for security analytics",
        "indices": [
          "windows"
        ],
        "custom_rules": [],
        "pre_packaged_rules": [
          {
            "id": "73a883d0-0348-4be4-a8d8-51031c2564f8"
          },
          {
            "id": "1a4bd6e3-4c6e-405d-a9a3-53a116e341d4"
          }
        ]
      }
    }
  ],
  "triggers": [
    {
      "sev_levels": [],
      "tags": [],
      "actions": [],
      "types": [
        "windows"
      ],
      "name": "test-trigger",
      "id": "fyAy1IMBK2A1DZyOuW_b"
    }
  ]
}

----------------------------------------

TITLE: Indexing Documents with Rank Feature Fields in OpenSearch
DESCRIPTION: This snippet shows how to index documents with rank_feature fields in OpenSearch. It includes three examples of indexing chess players with their names, ratings, and ages.

LANGUAGE: json
CODE:
PUT testindex1/_doc/1
{
  "name" : "John Doe",
  "rating" : 2554,
  "age" : 75
}

LANGUAGE: json
CODE:
PUT testindex1/_doc/2
{
  "name" : "Kwaku Mensah",
  "rating" : 2067,
  "age": 10
}

LANGUAGE: json
CODE:
PUT testindex1/_doc/3
{
  "name" : "Nikki Wolf",
  "rating" : 1864,
  "age" : 22
}

----------------------------------------

TITLE: Creating a Mapping with Double and Date Ranges in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a mapping in OpenSearch that includes a double range field for GPA and a date range field for graduation dates. It specifies the field types and formats.

LANGUAGE: json
CODE:
PUT testindex 
{
  "mappings" : {
    "properties" :  {
      "gpa" : {
        "type" : "double_range"
      },
      "graduation_date" : {
        "type" : "date_range",
        "format" : "strict_year_month||strict_year_month_day"
      }
    }
  }
}

----------------------------------------

TITLE: Analyzing Text with German Analyzer in OpenSearch
DESCRIPTION: This snippet shows how to use the _analyze endpoint to examine the tokens generated by the German analyzer for a given text input.

LANGUAGE: json
CODE:
POST /german-index/_analyze
{
  "field": "content",
  "text": "Die Studenten studieren an den deutschen Universitten. Ihre Nummern sind 123456."
}

----------------------------------------

TITLE: Wildcard Query with Alias Field
DESCRIPTION: Example showing how to use wildcards in field capabilities API to match both original and alias fields

LANGUAGE: json
CODE:
GET movies/_field_caps?fields=release*

----------------------------------------

TITLE: Defining a Basic ISM Policy Structure
DESCRIPTION: Example of the basic structure for an ISM policy, including policy ID, description, and states.

LANGUAGE: json
CODE:
{
  "policy_id": "string",
  "description": "string",
  "last_updated_time": "timestamp",
  "error_notification": {},
  "default_state": "string",
  "states": []
}

----------------------------------------

TITLE: Creating a reranking pipeline in OpenSearch
DESCRIPTION: This JSON request creates a reranking pipeline in OpenSearch using the registered Amazon Bedrock Rerank model.

LANGUAGE: json
CODE:
PUT /_search/pipeline/rerank_pipeline_bedrock
{
    "description": "Pipeline for reranking with Bedrock rerank model",
    "response_processors": [
        {
            "rerank": {
                "ml_opensearch": {
                    "model_id": "your_model_id_created_in_step1"
                },
                "context": {
                    "document_fields": ["passage_text"]
                }
            }
        }
    ]
}

----------------------------------------

TITLE: Token Generation Result with Limit Filter in OpenSearch
DESCRIPTION: This snippet shows the response from the '_analyze' endpoint, demonstrating the output of the limit token filter. It includes the three tokens generated from the input text, as specified by the 'max_token_count' parameter.

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "OpenSearch",
      "start_offset": 0,
      "end_offset": 10,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "is",
      "start_offset": 11,
      "end_offset": 13,
      "type": "<ALPHANUM>",
      "position": 1
    },
    {
      "token": "a",
      "start_offset": 14,
      "end_offset": 15,
      "type": "<ALPHANUM>",
      "position": 2
    }
  ]
}

----------------------------------------

TITLE: Installing OpenSearch Java Client with Apache HttpClient 5
DESCRIPTION: Maven and Gradle dependency configurations for installing OpenSearch Java client with Apache HttpClient 5 transport.

LANGUAGE: xml
CODE:
<dependency>
  <groupId>org.opensearch.client</groupId>
  <artifactId>opensearch-java</artifactId>
  <version>2.8.1</version>
</dependency>

<dependency>
  <groupId>org.apache.httpcomponents.client5</groupId>
  <artifactId>httpclient5</artifactId>
  <version>5.2.1</version>
</dependency>

LANGUAGE: gradle
CODE:
dependencies {
  implementation 'org.opensearch.client:opensearch-java:2.8.1'
  implementation 'org.apache.httpcomponents.client5:httpclient5:5.2.1'
}

----------------------------------------

TITLE: Indexing Document with Random ID in OpenSearch
DESCRIPTION: This snippet shows how to index a document with a randomly generated ID in OpenSearch. It includes 'title' and 'year' fields in the document body.

LANGUAGE: json
CODE:
POST my-logs/_doc
{
  "title": "Your Name",
  "year": "2016"
}

----------------------------------------

TITLE: Basic HTML Strip Processor Configuration in OpenSearch
DESCRIPTION: Basic syntax for configuring the HTML strip processor with a field parameter.

LANGUAGE: json
CODE:
{
  "html_strip": {
    "field": "webpage"
  }
}

----------------------------------------

TITLE: Alternative Alias Creation Commands
DESCRIPTION: Different REST endpoints that can be used to create aliases in OpenSearch.

LANGUAGE: json
CODE:
PUT <index>/_aliases/<alias name>
POST <index>/_aliases/<alias name>
PUT <index>/_alias/<alias name>
POST <index>/_alias/<alias name>

----------------------------------------

TITLE: Search Query Examples
DESCRIPTION: Various search query examples showing different aspects of match_bool_prefix functionality.

LANGUAGE: json
CODE:
GET testindex/_search
{
  "query": {
    "match_bool_prefix": {
      "title": "rises wi"
    }
  }
}

LANGUAGE: json
CODE:
GET testindex/_search
{
  "query": {
    "bool" : {
      "should": [
        { "term": { "title": "rises" }},
        { "prefix": { "title": "wi"}}
      ]
    }
  }
}

----------------------------------------

TITLE: Creating Geo-Point Index Mapping
DESCRIPTION: Creates an index with a location field mapped as a geo_point type for storing geographical coordinates.

LANGUAGE: json
CODE:
{
  "mappings": {
    "properties": {
      "location": {
        "type": "geo_point"
      }
    }
  }
}

----------------------------------------

TITLE: Enriching IP Address Data with Geographical Information
DESCRIPTION: Illustrates the use of the 'geoip' filter plugin to add geographical data to events based on IP addresses.

LANGUAGE: yaml
CODE:
geoip {
  source => "clientip"
}

----------------------------------------

TITLE: Executing 'info' Command for OpenSearch Benchmark Workload
DESCRIPTION: This snippet demonstrates how to use the 'info' command to retrieve information about a specific workload named 'nyc_taxis' in OpenSearch Benchmark.

LANGUAGE: bash
CODE:
opensearch-benchmark info --workload=nyc_taxis

----------------------------------------

TITLE: Ingesting Data with cURL for OpenSearch Data Prepper HTTP Source
DESCRIPTION: Example cURL command to ingest data into the HTTP source plugin running on localhost port 2021. The command sends a POST request with a JSON payload containing key-value pairs.

LANGUAGE: bash
CODE:
curl "http://localhost:2021/log/ingest" --data '[{"key1": "value1"}, {"key2": "value2"}]'

----------------------------------------

TITLE: Generated Tokens Response
DESCRIPTION: Response showing the tokens generated after analysis, demonstrating how whitespace is trimmed and text is processed into individual tokens.

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "opensearch",
      "start_offset": 0,
      "end_offset": 12,
      "type": "word",
      "position": 0
    },
    {
      "token": "is",
      "start_offset": 13,
      "end_offset": 18,
      "type": "word",
      "position": 1
    },
    {
      "token": "powerful",
      "start_offset": 19,
      "end_offset": 32,
      "type": "word",
      "position": 2
    }
  ]
}

----------------------------------------

TITLE: Configuring a Custom Whitespace Analyzer in OpenSearch
DESCRIPTION: This example shows how to configure an index with a custom analyzer that is equivalent to a whitespace analyzer with an added lowercase character filter. It creates an index named 'my_custom_whitespace_index' with a custom analyzer named 'my_custom_whitespace_analyzer'.

LANGUAGE: json
CODE:
PUT /my_custom_whitespace_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_custom_whitespace_analyzer": {
          "type": "custom",
          "tokenizer": "whitespace",
          "filter": ["lowercase"]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "my_field": {
        "type": "text",
        "analyzer": "my_custom_whitespace_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Running Geo_centroid Aggregation
DESCRIPTION: Executes a geo_centroid aggregation to calculate the central point of all locations.

LANGUAGE: json
CODE:
GET /restaurants/_search
{
  "size": 0,
  "aggs": {
    "centroid": {
      "geo_centroid": {
        "field": "location"
      }
    }
  }
}

----------------------------------------

TITLE: Basic Type Mapping Transformer Configuration Schema
DESCRIPTION: Example JSON configuration showing the basic structure of the TypeMappingsSanitizationTransformer with static mappings, regex mappings, and source properties.

LANGUAGE: json
CODE:
{
  "TypeMappingSanitizationTransformerProvider": {
    "staticMappings": {
      "{index-name-1}": {
        "{type-name-1}": "{target-index-name-1}",
        "{type-name-2}": "{target-index-name-2}"
      }
    },
    "regexMappings": [
      {
        "sourceIndexPattern": "{source-index-pattern}",
        "sourceTypePattern": "{source-type-pattern}",
        "targetIndexPattern": "{target-index-pattern}"
      }
    ],
    "sourceProperties": {
      "version": {
        "major": "NUMBER",
        "minor": "NUMBER"
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Node Properties in Ansible Hosts File
DESCRIPTION: Example configuration for the inventories/opensearch/hosts file, specifying the target node's public and private IP addresses.

LANGUAGE: bash
CODE:
ansible_host=<Public IP address> ansible_user=root ip=<Private IP address / 0.0.0.0>

----------------------------------------

TITLE: Performing Vector Search on Chunked Text in OpenSearch
DESCRIPTION: This snippet shows how to perform a vector search on the chunked text using a nested query. It uses the neural query type with a query text and specifies the model ID for generating the query embedding.

LANGUAGE: json
CODE:
GET testindex/_search
{
  "query": {
    "nested": {
      "score_mode": "max",
      "path": "passage_chunk_embedding",
      "query": {
        "neural": {
          "passage_chunk_embedding.knn": {
            "query_text": "document",
            "model_id": "-tHZeI4BdQKclr136Wl7"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Basic Geoip Processor in YAML
DESCRIPTION: Minimal configuration for the geoip processor to extract all available geolocation data from an IP address field named 'clientip' and store it in a new field named 'geo'.

LANGUAGE: yaml
CODE:
my-pipeline:
  processor:
    - geoip:
        entries:
          - source: clientip

----------------------------------------

TITLE: Creating an Index with IP Mapping in OpenSearch
DESCRIPTION: This snippet shows how to create an index with an IP mapping that ignores malformed IP addresses. It sets the 'ignore_malformed' parameter to true for the 'ip_address' field.

LANGUAGE: json
CODE:
PUT /test-index 
{
  "mappings" : {
    "properties" :  {
      "ip_address" : {
        "type" : "ip",
        "ignore_malformed": true
      }
    }
  }
}

----------------------------------------

TITLE: Example Response for Get Stored Script API in OpenSearch
DESCRIPTION: This snippet shows an example response from the Get Stored Script API, including the script ID, found status, and the script object containing the language and source code.

LANGUAGE: json
CODE:
{
  "_id" : "my-first-script",
  "found" : true,
  "script" : {
    "lang" : "painless",
    "source" : """
          int total = 0;
          for (int i = 0; i < doc['ratings'].length; ++i) {
            total += doc['ratings'][i];
          }
          return total;
        """
  }
}

----------------------------------------

TITLE: Creating Bedrock Connector in OpenSearch
DESCRIPTION: Python script to create a connector in OpenSearch for accessing the Bedrock Titan embedding model in another account.

LANGUAGE: python
CODE:
import boto3
import requests 
from requests_aws4auth import AWS4Auth

host = 'your_amazon_opensearch_domain_endpoint_created'
region = 'your_amazon_opensearch_domain_region'
service = 'es'

credentials = boto3.Session().get_credentials()
awsauth = AWS4Auth(credentials.access_key, credentials.secret_key, region, service, session_token=credentials.token)

path = '/_plugins/_ml/connectors/_create'
url = host + path

bedrock_model_region='your_bedrock_model_region'
payload = {
  "name": "Amazon Bedrock Connector: titan embedding v1",
  "description": "The connector to bedrock Titan embedding model",
  "version": 1,
  "protocol": "aws_sigv4",
  "parameters": {
    "region": bedrock_model_region,
    "service_name": "bedrock"
  },
  "credential": {
    "roleArn": "arn:aws:iam::<your_aws_account_A>:role/my_cross_account_role_accountA",
    "externalAccountRoleArn": "arn:aws:iam::<your_aws_account_B>:role/my_invoke_bedrock_role_accountB"
  },
  "actions": [
    {
      "action_type": "predict",
      "method": "POST",
      "url": f"https://bedrock-runtime.{bedrock_model_region}.amazonaws.com/model/amazon.titan-embed-text-v1/invoke",
      "headers": {
        "content-type": "application/json",
        "x-amz-content-sha256": "required"
      },
      "request_body": "{ \"inputText\": \"${parameters.inputText}\" }",
      "pre_process_function": "connector.pre_process.bedrock.embedding",
      "post_process_function": "connector.post_process.bedrock.embedding"
    }
  ]
}

headers = {"Content-Type": "application/json"}

r = requests.post(url, auth=awsauth, json=payload, headers=headers)
print(r.text)

----------------------------------------

TITLE: Installing Logstash OpenSearch Plugin via Command Line
DESCRIPTION: Shows the command to install the Logstash OpenSearch output plugin using the Logstash plugin installer.

LANGUAGE: bash
CODE:
bin/logstash-plugin install logstash-output-opensearch

----------------------------------------

TITLE: Indexing Document with Normalized Field
DESCRIPTION: Indexes a document with a normalized keyword field 'approach'.

LANGUAGE: json
CODE:
POST /sample-index/_doc/
{
  "approach": "naive"
}

----------------------------------------

TITLE: Creating Date Field Mapping with Multiple Formats
DESCRIPTION: Example showing how to create an index mapping with a date field that accepts two different date formats.

LANGUAGE: json
CODE:
PUT testindex
{
  "mappings" : {
    "properties" :  {
      "release_date" : {
        "type" : "date",
        "format" : "strict_date_optional_time||epoch_millis"
      }
    }
  }
}

----------------------------------------

TITLE: Adjusting Shard Limits in OpenSearch
DESCRIPTION: These snippets demonstrate how to check and adjust shard limits at both cluster and index levels. This is useful for resolving 'Maximum shards exceeded' errors.

LANGUAGE: bash
CODE:
GET /_cluster/settings

LANGUAGE: bash
CODE:
PUT _cluster/settings
{
   "transient":{
      "cluster.routing.allocation.total_shards_per_node":100
   }
}

LANGUAGE: bash
CODE:
GET <index>/_settings/index.routing-

LANGUAGE: json
CODE:
"index" : {
        "routing" : {
          "allocation" : {
            "total_shards_per_node" : "10"
          }
        }
      }

LANGUAGE: bash
CODE:
PUT <index>/_settings
{"index.routing.allocation.total_shards_per_node":-1}

----------------------------------------

TITLE: Configuring map_to_list Processor with Minimum Settings in YAML
DESCRIPTION: Demonstrates the minimal configuration for the map_to_list processor, specifying only the required source and target parameters.

LANGUAGE: yaml
CODE:
processor:
  - map_to_list:
      source: "my-map"
      target: "my-list"

----------------------------------------

TITLE: Retrieving Ingest Pipeline Metrics in OpenSearch
DESCRIPTION: This snippet shows how to use the Nodes Stats API to retrieve metrics for all ingest pipelines. It includes a filter to focus on ingest-related statistics.

LANGUAGE: json
CODE:
GET /_nodes/stats/ingest?filter_path=nodes.*.ingest

----------------------------------------

TITLE: Retrieving Document from OpenSearch Index
DESCRIPTION: Demonstrates how to retrieve a document from 'testindex1' after it has been processed by the lowercase pipeline.

LANGUAGE: json
CODE:
GET testindex1/_doc/1

----------------------------------------

TITLE: Example Response from Custom Classic Filter Analyzer in OpenSearch
DESCRIPTION: This snippet shows the response returned by the _analyze API when using the custom classic analyzer. It displays the generated tokens along with their positions, offsets, and types.

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "John",
      "start_offset": 0,
      "end_offset": 6,
      "type": "<APOSTROPHE>",
      "position": 0
    },
    {
      "token": "co",
      "start_offset": 7,
      "end_offset": 9,
      "type": "<ALPHANUM>",
      "position": 1
    },
    {
      "token": "operate",
      "start_offset": 10,
      "end_offset": 17,
      "type": "<ALPHANUM>",
      "position": 2
    },
    {
      "token": "was",
      "start_offset": 18,
      "end_offset": 21,
      "type": "<ALPHANUM>",
      "position": 3
    },
    {
      "token": "excellent",
      "start_offset": 22,
      "end_offset": 31,
      "type": "<ALPHANUM>",
      "position": 4
    }
  ]
}

----------------------------------------

TITLE: Creating Component Templates in OpenSearch
DESCRIPTION: This snippet demonstrates how to create two component templates, which can be used as building blocks for composable index templates. The first template defines a mapping for a timestamp field, and the second for an IP address field.

LANGUAGE: json
CODE:
PUT _component_template/component_template_1
{
  "template": {
    "mappings": {
      "properties": {
        "@timestamp": {
          "type": "date"
        }
      }
    }
  }
}

PUT _component_template/component_template_2
{
  "template": {
    "mappings": {
      "properties": {
        "ip_address": {
          "type": "ip"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Analyzing Text with Italian Analyzer
DESCRIPTION: Example of analyzing Italian text and viewing the generated tokens using the configured analyzer.

LANGUAGE: json
CODE:
POST /italian-index/_analyze
{
  "field": "content",
  "text": "Gli studenti studiano nelle universit italiane. I loro numeri sono 123456."
}

----------------------------------------

TITLE: Sample Import Request for a Dangling Index in OpenSearch
DESCRIPTION: This is an example of how to import a dangling index using a POST request. It includes the index UUID in the path and sets the accept_data_loss parameter to true.

LANGUAGE: bash
CODE:
POST /_dangling/msdjernajxAT23RT-BupMB?accept_data_loss=true

----------------------------------------

TITLE: Analyzing Text with Hunspell Filter
DESCRIPTION: Example request to analyze text using the configured Hunspell analyzer, demonstrating how to test token generation for a sample phrase.

LANGUAGE: json
CODE:
POST /my_index/_analyze
{
  "analyzer": "my_analyzer",
  "text": "the turtle moves slowly"
}

----------------------------------------

TITLE: Applying Bulgarian Analyzer to Text Field in OpenSearch
DESCRIPTION: This snippet demonstrates how to apply the built-in Bulgarian analyzer to a text field when creating an index in OpenSearch.

LANGUAGE: json
CODE:
PUT /bulgarian-index
{
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "bulgarian"
      }
    }
  }
}

----------------------------------------

TITLE: YAML Configuration Table for otel_traces Processor
DESCRIPTION: Configuration options table showing the trace_flush_interval parameter for the otel_traces processor

LANGUAGE: markdown
CODE:
Option | Required | Type | Description
:--- | :--- | :--- | :---
trace_flush_interval | No | Integer | Represents the time interval in seconds to flush all the descendant spans without any root span. Default is 180.

----------------------------------------

TITLE: Running Data Prepper Pre-2.0 with Docker
DESCRIPTION: Docker command to run Data Prepper versions earlier than 2.0 with mounted configuration files.

LANGUAGE: bash
CODE:
docker run --name data-prepper -p 4900:4900 -v ${PWD}/pipelines.yaml:/usr/share/data-prepper/pipelines.yaml -v ${PWD}/data-prepper-config.yaml:/usr/share/data-prepper/data-prepper-config.yaml opensearchproject/data-prepper:1.x

----------------------------------------

TITLE: Maximum ML Tasks Per Node
DESCRIPTION: Configures the maximum number of concurrent ML tasks allowed per node.

LANGUAGE: yaml
CODE:
plugins.ml_commons.max_ml_task_per_node: 10

----------------------------------------

TITLE: Retrieving a document processed by URL decode pipeline in OpenSearch
DESCRIPTION: Demonstrates how to retrieve a document that has been processed by the url_decode_pipeline, showing both the original and decoded URL fields.

LANGUAGE: json
CODE:
GET testindex1/_doc/1

----------------------------------------

TITLE: Creating a Snapshot for OpenSearch Backfill
DESCRIPTION: Command to create a snapshot of the source cluster for backfilling data into the target cluster.

LANGUAGE: bash
CODE:
console snapshot create

----------------------------------------

TITLE: Enabling and Starting OpenSearch Service
DESCRIPTION: Commands to enable OpenSearch as a service and start it using systemctl.

LANGUAGE: bash
CODE:
sudo systemctl enable opensearch
sudo systemctl start opensearch

----------------------------------------

TITLE: Creating Custom French Analyzer
DESCRIPTION: Demonstrates creation of a custom French analyzer with specific token filters including elision, stop words, and stemming configurations.

LANGUAGE: json
CODE:
PUT /french-index
{
  "settings": {
    "analysis": {
      "filter": {
        "french_stop": {
          "type": "stop",
          "stopwords": "_french_"
        },
        "french_elision": {
          "type":         "elision",
          "articles_case": true,
          "articles": [
              "l", "m", "t", "qu", "n", "s",
              "j", "d", "c", "jusqu", "quoiqu",
              "lorsqu", "puisqu"
            ]
        },
        "french_stemmer": {
          "type": "stemmer",
          "language": "light_french"
        },
        "french_keywords": {
          "type": "keyword_marker",
          "keywords": []
        }
      },
      "analyzer": {
        "french_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "french_elision",
            "lowercase",
            "french_stop",
            "french_keywords",
            "french_stemmer"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "french_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Creating Index with Geopoint Field
DESCRIPTION: Creates an OpenSearch index named 'restaurants' with a geo_point field type for storing geographic coordinates.

LANGUAGE: json
CODE:
PUT /restaurants
{
  "mappings": {
    "properties": {
      "name": {
        "type": "text"
      },
      "location": {
        "type": "geo_point"
      }
    }
  }
}

----------------------------------------

TITLE: Creating Custom CJK Analyzer
DESCRIPTION: Demonstrates how to create a custom CJK analyzer with specific token filters and stopwords.

LANGUAGE: json
CODE:
{
  "settings": {
    "analysis": {
      "filter": {
        "english_stop": {
          "type":       "stop",
          "stopwords":  [ 
            "a", "and", "are", "as", "at", "be", "but", "by", "for",
            "if", "in", "into", "is", "it", "no", "not", "of", "on",
            "or", "s", "such", "t", "that", "the", "their", "then",
            "there", "these", "they", "this", "to", "was", "will",
            "with", "www"
          ]
        }
      },
      "analyzer": {
        "cjk_custom_analyzer": {
          "tokenizer": "standard",
          "filter": [
            "cjk_width",
            "lowercase",
            "cjk_bigram",
            "english_stop"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "cjk_custom_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Searching Pre-Packaged Security Rules in OpenSearch
DESCRIPTION: API endpoint for searching pre-packaged security rules. Accepts query parameters to filter rules by category and other criteria.

LANGUAGE: json
CODE:
POST /_plugins/_security_analytics/rules/_search?pre_packaged=true

{
  "from": 0,
  "size": 20,  
  "query": {
    "nested": {
      "path": "rule",
      "query": {
        "bool": {
          "must": [
            { "match": { "rule.category": "windows" } }
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Applying German Analyzer to Text Field in OpenSearch
DESCRIPTION: This snippet demonstrates how to apply the built-in German analyzer to a text field in an OpenSearch index mapping.

LANGUAGE: json
CODE:
PUT /german-index
{
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "german"
      }
    }
  }
}

----------------------------------------

TITLE: Executing a Geo-bounding Box Query in OpenSearch
DESCRIPTION: Performs a search using a geo-bounding box query to filter documents based on geopoint coordinates within a specified rectangle.

LANGUAGE: json
CODE:
GET testindex1/_search
{
  "query": {
    "bool": {
      "must": {
        "match_all": {}
      },
      "filter": {
        "geo_bounding_box": {
          "point": {
            "top_left": {
              "lat": 75,
              "lon": 28
            },
            "bottom_right": {
              "lat": 73,
              "lon": 41
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating a Dissect Pipeline in OpenSearch
DESCRIPTION: Creates an ingest pipeline named 'dissect-test' that uses the dissect processor to parse a web server log line.

LANGUAGE: json
CODE:
PUT /_ingest/pipeline/dissect-test
{
  "description": "Pipeline that dissects web server logs",
  "processors": [
    {
      "dissect": {
        "field": "message",
        "pattern": "%{client_ip} - - [%{timestamp}] \"%{http_method} %{url} %{http_version}\" %{response_code} %{response_size}" 
      }
    }
  ]
}

----------------------------------------

TITLE: Accessing Nanoseconds in date_nanos Fields with Painless Script in OpenSearch
DESCRIPTION: This snippet shows how to use a Painless script to access only the nanoseconds part of a date_nanos field in search results.

LANGUAGE: json
CODE:
GET testindex/_search
{
  "script_fields" : {
    "my_field" : {
      "script" : {
        "lang" : "painless",
        "source" : "doc['date'].value.nano" 
      }
    }
  }
}

----------------------------------------

TITLE: Creating Custom French Analyzer
DESCRIPTION: Demonstrates creation of a custom French analyzer with specific token filters including elision, stop words, and stemming configurations.

LANGUAGE: json
CODE:
PUT /french-index
{
  "settings": {
    "analysis": {
      "filter": {
        "french_stop": {
          "type": "stop",
          "stopwords": "_french_"
        },
        "french_elision": {
          "type":         "elision",
          "articles_case": true,
          "articles": [
              "l", "m", "t", "qu", "n", "s",
              "j", "d", "c", "jusqu", "quoiqu",
              "lorsqu", "puisqu"
            ]
        },
        "french_stemmer": {
          "type": "stemmer",
          "language": "light_french"
        },
        "french_keywords": {
          "type": "keyword_marker",
          "keywords": []
        }
      },
      "analyzer": {
        "french_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "french_elision",
            "lowercase",
            "french_stop",
            "french_keywords",
            "french_stemmer"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "french_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Match Phrase Query with Slop Parameter
DESCRIPTION: Example showing match_phrase query with slop parameter to allow flexibility in term ordering.

LANGUAGE: json
CODE:
GET _search
{
  "query": {
    "match_phrase": {
      "title": {
        "query": "wind rises the",
        "slop": 3
      }
    }
  }
}

----------------------------------------

TITLE: Literal String Substring Check in OpenSearch Pipeline
DESCRIPTION: Shows how to use contains() function with a literal string to check for substring presence. This example checks if 'test' exists within the string 'This is a test message'.

LANGUAGE: opensearch
CODE:
contains('This is a test message', 'test')

----------------------------------------

TITLE: Auto-Generated Document ID Example
DESCRIPTION: Demonstrates automatic index creation and ID generation when indexing a document without specifying an ID.

LANGUAGE: json
CODE:
POST movies/_doc
{ "title": "Spirited Away" }

----------------------------------------

TITLE: Running Basic RAG Search with Claude 3.5
DESCRIPTION: Executes a basic RAG search using the configured pipeline without storing conversation history.

LANGUAGE: JSON
CODE:
GET /qa_demo/_search?search_pipeline=my-conversation-search-pipeline-claude
{
  "query": {
    "match": {
      "text": "What's the population increase of New York City from 2021 to 2023?"
    }
  },
  "size": 1,
  "_source": [
    "text"
  ],
  "ext": {
    "generative_qa_parameters": {
      "llm_model": "bedrock-converse/anthropic.claude-3-sonnet-20240229-v1:0",
      "llm_question": "What's the population increase of New York City from 2021 to 2023?",
      "context_size": 5
    }
  }
}

----------------------------------------

TITLE: Highlighting derived fields
DESCRIPTION: Demonstrates how to highlight matches in a derived 'url' field of type 'text'.

LANGUAGE: json
CODE:
POST /logs/_search
{
  "derived": {
    "url": {
      "type": "text",
      "script": {
        "source": """
        emit(doc["request"].value.splitOnToken(" " )[2])
        """
      }
    }
  },
  "query": {
    "bool": {
      "must": [
        {
          "term": {
            "clientip": "61.177.2.0"
          }
        },
        {
          "match": {
            "url": "images"
          }
        }
      ]
    }
  },
  "fields": ["request", "clientip", "url"],
  "highlight": {
    "fields": {
      "url": {}
    }
  }
}

----------------------------------------

TITLE: Searching with Explain Flag
DESCRIPTION: Example request showing how to search with the explain flag enabled to get scoring details for all results.

LANGUAGE: json
CODE:
POST opensearch_dashboards_sample_data_ecommerce/_search?explain=true\n{\n  "query": {\n    "match": {\n      "customer_first_name": "Mary"\n    }\n  }\n}

----------------------------------------

TITLE: Adding Documents to the Electronics Index in OpenSearch
DESCRIPTION: This snippet shows how to add multiple documents to the 'electronics' index, including smartphones and laptops with various attributes.

LANGUAGE: json
CODE:
PUT /electronics/_doc/1?refresh
{
  "brand": "BrandA",
  "category": "Smartphone",
  "price": 699.99,
  "features": ["5G", "Dual Camera"]
}
PUT /electronics/_doc/2?refresh
{
  "brand": "BrandA",
  "category": "Laptop",
  "price": 1199.99,
  "features": ["Touchscreen", "16GB RAM"]
}
PUT /electronics/_doc/3?refresh
{
  "brand": "BrandB",
  "category": "Smartphone",
  "price": 799.99,
  "features": ["5G", "Triple Camera"]
}

----------------------------------------

TITLE: Auto_date_histogram aggregation without time zone
DESCRIPTION: Performs an auto_date_histogram aggregation on the 'blogs1' index without specifying a time zone.

LANGUAGE: json
CODE:
GET /blogs1/_search
{
  "size": 0,
  "aggs": {
    "histogram": {
      "auto_date_histogram": {
        "field": "date_posted",
        "buckets": 2,
        "format": "yyyy-MM-dd HH:mm:ss"
      }
    }
  }
}

----------------------------------------

TITLE: Testing Fail Processor Pipeline in OpenSearch
DESCRIPTION: This snippet demonstrates how to test the 'fail-log-pipeline' using the _simulate API. It simulates indexing a document with sensitive information to verify the pipeline's behavior.

LANGUAGE: json
CODE:
POST _ingest/pipeline/fail-log-pipeline/_simulate  
{  
  "docs": [  
    {  
      "_source": {  
        "user_info": "Sensitive information including credit card"  
      }  
    }  
  ]  
}

----------------------------------------

TITLE: Manually Aggregating Test Executions in OpenSearch Benchmark
DESCRIPTION: This command shows how to manually aggregate multiple test executions by specifying their test execution IDs.

LANGUAGE: bash
CODE:
opensearch-benchmark aggregate --test-executions=<test_execution_id1>,<test_execution_id2>,...

----------------------------------------

TITLE: Retrieving Indices on Follower Cluster in OpenSearch
DESCRIPTION: This curl command retrieves a list of indices on the follower cluster to confirm that the replica of the test index has been created automatically.

LANGUAGE: bash
CODE:
curl -XGET -u 'admin:<custom-admin-password>' -k 'https://localhost:9200/_cat/indices?v'

----------------------------------------

TITLE: Configuring Debug Exporter
DESCRIPTION: JSON request to configure the debug exporter for top N query data.

LANGUAGE: json
CODE:
PUT _cluster/settings
{
  "persistent" : {
      "search.insights.top_queries.exporter.type" : "debug"
  }
}

----------------------------------------

TITLE: Get Single Workspace API Endpoint
DESCRIPTION: API endpoint to retrieve details of a specific workspace by its ID.

LANGUAGE: json
CODE:
GET <osd host>:<port>/api/workspaces/<id>

----------------------------------------

TITLE: Significant Terms Response Structure
DESCRIPTION: Example response showing the structure of significant terms results, including document counts, background counts, and significance scores for each term bucket.

LANGUAGE: json
CODE:
{
  "aggregations": {
    "significant_response_codes": {
      "doc_count": 2737,
      "bg_count": 14074,
      "buckets": [
        {
          "key": "Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR 1.1.4322)",
          "doc_count": 818,
          "score": 0.01462731514608217,
          "bg_count": 4010
        },
        {
          "key": "Mozilla/5.0 (X11; Linux x86_64; rv:6.0a1) Gecko/20110421 Firefox/6.0a1",
          "doc_count": 1067,
          "score": 0.009062566630410223,
          "bg_count": 5362
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Filters Aggregation Response Format
DESCRIPTION: Example response showing the structure of buckets returned by a filters aggregation, including document counts and average values for each bucket.

LANGUAGE: json
CODE:
{
  "aggregations": {
    "200_os": {
      "buckets": [
        {
          "doc_count": 12832,
          "avg_amount": {
            "value": 5897.852711970075
          }
        },
        {
          "doc_count": 2825,
          "avg_amount": {
            "value": 5620.347256637168
          }
        },
        {
          "doc_count": 1017,
          "avg_amount": {
            "value": 3247.0963618485744
          }
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Analyzing Text with Catalan Analyzer in OpenSearch
DESCRIPTION: This snippet shows how to use the _analyze API to examine the tokens generated by the Catalan analyzer for a given text input.

LANGUAGE: json
CODE:
POST /catalan-index/_analyze
{
  "field": "content",
  "text": "Els estudiants estudien a les universitats catalanes. Els seus nmeros sn 123456."
}

----------------------------------------

TITLE: Installing SQL CLI for OpenSearch using pip
DESCRIPTION: Command to install the OpenSearch SQL CLI using pip package manager. Requires Python 3.

LANGUAGE: console
CODE:
pip3 install opensearchsql

----------------------------------------

TITLE: Configuring Flatten Processor to Exclude Specific Keys in YAML
DESCRIPTION: This configuration shows how to use the exclude_keys option to prevent specific keys from being flattened in the output.

LANGUAGE: yaml
CODE:
processor:
  - flatten:
      source: ""   # empty string represents root of event
      target: ""   # empty string represents root of event
      remove_processed_fields: true
      exclude_keys: ["key2"]

----------------------------------------

TITLE: Disabling Authentication
DESCRIPTION: YAML configuration to disable authentication for core endpoints (use with caution)

LANGUAGE: yaml
CODE:
authentication:
  unauthenticated:

----------------------------------------

TITLE: Applying Hindi Analyzer to Text Field in OpenSearch
DESCRIPTION: This snippet demonstrates how to apply the built-in Hindi analyzer to a text field when creating an index in OpenSearch.

LANGUAGE: json
CODE:
PUT /hindi-index
{
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "hindi"
      }
    }
  }
}

----------------------------------------

TITLE: Environment Setup for AWS Inferentia
DESCRIPTION: Commands to set up environment variables for OpenSearch and PyTorch on AWS Inferentia nodes.

LANGUAGE: bash
CODE:
echo "export OPENSEARCH_HOME=~/opensearch-2.5.0" | tee -a ~/.bash_profile
echo "export PYTORCH_VERSION=1.12.1" | tee -a ~/.bash_profile
source ~/.bash_profile

----------------------------------------

TITLE: Verifying OpenSearch Dashboards pod status
DESCRIPTION: This command retrieves the status of all pods in the current Kubernetes namespace, allowing you to verify that the OpenSearch Dashboards pod is running.

LANGUAGE: bash
CODE:
$ kubectl get pods

----------------------------------------

TITLE: Defining Field Mappings for Microsoft 365 Logs in JSON
DESCRIPTION: This JSON snippet defines the mappings between raw fields from Microsoft 365 logs and their corresponding ECS (Elastic Common Schema) fields. It includes mappings for event source, event name, status, and payload.

LANGUAGE: json
CODE:
"mappings": [
    {
      "raw_field":"eventSource",
      "ecs":"rsa.misc.event_source"
    },
    {
      "raw_field":"eventName",
      "ecs":"rsa.misc.event_desc"
    },
    {
      "raw_field":"status",
      "ecs":"rsa.misc.status"
    },
    {
      "raw_field":"Payload",
      "ecs":"rsa.misc.payload_dst"
    }
  ]

----------------------------------------

TITLE: Building OpenSearch Documentation Website
DESCRIPTION: Command to build the OpenSearch documentation website using a shell script, which automates the build process and opens the site in a web browser.

LANGUAGE: shell
CODE:
sh build.sh

----------------------------------------

TITLE: Closing an Index in OpenSearch
DESCRIPTION: This snippet shows how to close an index named 'testindex' using a POST request.

LANGUAGE: json
CODE:
POST /testindex/_close

----------------------------------------

TITLE: Configuring Bulk Operation in OpenSearch Benchmark
DESCRIPTION: Example of a bulk operation configuration with a bulk size of 5000 documents for index appending.

LANGUAGE: yaml
CODE:
{
  "name": "index-append",
  "operation-type": "bulk",
  "bulk-size": 5000
}

----------------------------------------

TITLE: Creating Index Mapping with match_only_text Field - OpenSearch JSON
DESCRIPTION: Example showing how to create an index mapping that includes a match_only_text field type for the 'title' property.

LANGUAGE: json
CODE:
PUT movies
{
  "mappings" : {
    "properties" : {
      "title" : {
        "type" :  "match_only_text"
      }
    }
  }
}

----------------------------------------

TITLE: Indexing Geo Shape Data in OpenSearch
DESCRIPTION: These snippets demonstrate how to index documents with geo_shape data into the 'national_parks' index in OpenSearch. Each document represents a national park with an envelope-type shape.

LANGUAGE: json
CODE:
PUT national_parks/_doc/1
{
  "name": "Yellowstone National Park",
  "location":
  {"type": "envelope","coordinates": [ [-111.15, 45.12], [-109.83, 44.12] ]}
}

LANGUAGE: json
CODE:
PUT national_parks/_doc/2
{
  "name": "Yosemite National Park",
  "location": 
  {"type": "envelope","coordinates": [ [-120.23, 38.16], [-119.05, 37.45] ]}
}

LANGUAGE: json
CODE:
PUT national_parks/_doc/3
{
  "name": "Death Valley National Park",
  "location": 
  {"type": "envelope","coordinates": [ [-117.34, 37.01], [-116.38, 36.25] ]}
}

----------------------------------------

TITLE: Multi-terms Aggregation Response in OpenSearch
DESCRIPTION: Example response showing the results of a multi-terms aggregation, including document counts, maximum CPU and memory values for each bucket combination of region and host.

LANGUAGE: json
CODE:
{
  "took": 118,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 8,
      "relation": "eq"
    },
    "max_score": null,
    "hits": []
  },
  "aggregations": {
    "multi-terms": {
      "doc_count_error_upper_bound": 0,
      "sum_other_doc_count": 0,
      "buckets": [
        {
          "key": [
            "dub",
            "h1"
          ],
          "key_as_string": "dub|h1",
          "doc_count": 2,
          "max-cpu": {
            "value": 90.0
          },
          "max-memory": {
            "value": 50.0
          }
        },
        {
          "key": [
            "dub1",
            "h1"
          ],
          "key_as_string": "dub|h1",
          "doc_count": 2,
          "max-cpu": {
            "value": 90.0
          },
          "max-memory": {
            "value": 40.0
          }
        },
        {
          "key": [
            "dub",
            "h2"
          ],
          "key_as_string": "dub|h2",
          "doc_count": 2,
          "max-cpu": {
            "value": 70.0
          },
          "max-memory": {
            "value": 90.0
          }
        },
        {
          "key": [
            "iad",
            "h2"
          ],
          "key_as_string": "iad|h2",
          "doc_count": 2,
          "max-cpu": {
            "value": 50.0
          },
          "max-memory": {
            "value": 50.0
          }
        },
        {
          "key": [
            "iad",
            "h1"
          ],
          "key_as_string": "iad|h1",
          "doc_count": 2,
          "max-cpu": {
            "value": 15.0
          },
          "max-memory": {
            "value": 20.0
          }
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Creating a Mapping with Constant Keyword Field in OpenSearch
DESCRIPTION: This example demonstrates how to create a mapping with a constant keyword field in OpenSearch. The field 'genre' is set as a constant keyword with the value 'Romantic comedy' for all documents in the 'romcom_movies' index.

LANGUAGE: json
CODE:
PUT romcom_movies
{
  "mappings" : {
    "properties" : {
      "genre" : {
        "type": "constant_keyword",
        "value" : "Romantic comedy"
      }
    }
  }
}

----------------------------------------

TITLE: Creating Index with Custom Classic Filter Analyzer in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a new index named 'custom_classic_filter' with a custom analyzer that uses the classic tokenizer and classic filter. The analyzer is configured in the index settings.

LANGUAGE: json
CODE:
PUT /custom_classic_filter
{
  "settings": {
    "analysis": {
      "analyzer": {
        "custom_classic": {
          "type": "custom",
          "tokenizer": "classic",
          "filter": ["classic"]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Cluster Manager Node Stats Request in OpenSearch
DESCRIPTION: Example request for retrieving statistics specifically from the cluster manager node.

LANGUAGE: json
CODE:
GET _cluster/stats/nodes/_cluster_manager

----------------------------------------

TITLE: Enabling Telemetry Feature Flag in OpenSearch YAML
DESCRIPTION: Adds the setting to enable the experimental telemetry feature in the OpenSearch YAML configuration file.

LANGUAGE: yaml
CODE:
opensearch.experimental.feature.telemetry.enabled=true

----------------------------------------

TITLE: Analyzing Text with Spanish Analyzer in OpenSearch
DESCRIPTION: This snippet shows how to use the _analyze API to examine the tokens generated by the Spanish analyzer for a given text input.

LANGUAGE: json
CODE:
POST /spanish-index/_analyze
{
  "field": "content",
  "text": "Los estudiantes estudian en universidades espaolas. Sus nmeros son 123456."
}

----------------------------------------

TITLE: Creating Custom Analyzer with HTML Strip and Lowercase Filter in OpenSearch
DESCRIPTION: This example creates a custom analyzer that combines the HTML strip character filter with a lowercase filter to remove HTML tags and convert text to lowercase.

LANGUAGE: json
CODE:
PUT /html_strip_and_lowercase_analyzer
{
  "settings": {
    "analysis": {
      "char_filter": {
        "html_filter": {
          "type": "html_strip"
        }
      },
      "analyzer": {
        "html_strip_analyzer": {
          "type": "custom",
          "char_filter": ["html_filter"],
          "tokenizer": "standard",
          "filter": ["lowercase"]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Relational Operator Usage in OpenSearch Data Prepper
DESCRIPTION: Example of using relational operators to check if a status code is within the range of successful HTTP responses (200-299).

LANGUAGE: markdown
CODE:
/status_code >= 200 and /status_code < 300

----------------------------------------

TITLE: Update Model Group Request Example
DESCRIPTION: Example JSON request body for updating a model group, showing how to modify the name, description, and backend role settings.

LANGUAGE: json
CODE:
PUT /_plugins/_ml/model_groups/<model_group_id>
{
    "name": "model_group_test",
    "description": "This is the updated description",
    "add_all_backend_roles": true
}

----------------------------------------

TITLE: ML Node Execution Setting
DESCRIPTION: Configuration to control whether ML tasks run exclusively on ML nodes.

LANGUAGE: yaml
CODE:
plugins.ml_commons.only_run_on_ml_node: true

----------------------------------------

TITLE: Disabling ECS Compatibility in Logstash OSS 8.0
DESCRIPTION: This YAML snippet shows how to disable the Elastic Common Schema (ECS) compatibility mode in Logstash OSS 8.0 and later versions. This is necessary to maintain legacy behavior when using compatible OSS clients.

LANGUAGE: yml
CODE:
ecs_compatibility => disabled

----------------------------------------

TITLE: Updating ML Controller User Rate Limit
DESCRIPTION: Example request for updating the rate limit for a specific user in an existing controller.

LANGUAGE: json
CODE:
PUT _plugins/_ml/controllers/mtw-ZI0B_1JGmyB068C0\n{\n  "user_rate_limiter": {\n    "user1": {\n      "limit": 6,\n      "unit": "MINUTES"\n    }\n  }\n}

----------------------------------------

TITLE: Query All Indices with Verbose Output
DESCRIPTION: Example request to get information about all indices with verbose output enabled.

LANGUAGE: json
CODE:
GET _cat/indices?v

----------------------------------------

TITLE: Configuring Basque Analyzer with Stem Exclusion
DESCRIPTION: Creates an analyzer configuration that excludes specific words from stemming process.

LANGUAGE: json
CODE:
PUT index_with_stem_exclusion_basque_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "stem_exclusion_basque_analyzer": {
          "type": "basque",
          "stem_exclusion": ["autoritate", "baldintza"]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Setting Correlation Time Window using Cluster Settings API in OpenSearch
DESCRIPTION: This code snippet demonstrates how to use the Cluster Settings API to set the time window for correlating findings in Security Analytics. It sets the correlation time window to 2 minutes using a PUT request to the cluster settings endpoint.

LANGUAGE: json
CODE:
PUT /_cluster/settings
{
  "transient": {
    "plugins.security_analytics.correlation_time_window": "2m"
  }
}

----------------------------------------

TITLE: Detailed Analysis with Keyword Attribute in OpenSearch
DESCRIPTION: This example shows how to perform a detailed analysis of text using the custom analyzer, including the 'explain' parameter and 'keyword' attribute to examine the impact of the keyword_repeat filter.

LANGUAGE: json
CODE:
POST /my_index/_analyze
{
  "analyzer": "my_custom_analyzer",
  "text": "Stopped quickly",
  "explain": true,
  "attributes": "keyword"
}

----------------------------------------

TITLE: Creating an Index with Meta Information in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a new index with custom _meta information in OpenSearch. It includes fields for application, version, and author, along with basic properties for the index.

LANGUAGE: json
CODE:
PUT my-index
{
  "mappings": {
    "_meta": {
      "application": "MyApp",
      "version": "1.2.3",
      "author": "John Doe"
    },
    "properties": {
      "title": {
        "type": "text"
      },
      "description": {
        "type": "text"
      }
    }
  }
}

----------------------------------------

TITLE: Creating Custom Brazilian Analyzer
DESCRIPTION: Demonstrates how to create a custom Brazilian analyzer with specific token filters and configurations.

LANGUAGE: json
CODE:
PUT /brazilian-index
{
  "settings": {
    "analysis": {
      "filter": {
        "brazilian_stop": {
          "type": "stop",
          "stopwords": "_brazilian_"
        },
        "brazilian_stemmer": {
          "type": "stemmer",
          "language": "brazilian"
        },
        "brazilian_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] 
        }
      },
      "analyzer": {
        "brazilian_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "brazilian_stop",
            "brazilian_keywords",
            "brazilian_stemmer"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "brazilian_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Expanded Match Phrase Prefix Query with Parameters
DESCRIPTION: Demonstrates expanded syntax including additional parameters like analyzer specification.

LANGUAGE: json
CODE:
GET _search
{
  "query": {
    "match_phrase_prefix": {
      "title": {
        "query": "the wind",
        "analyzer": "stop"
      }
    }
  }
}

----------------------------------------

TITLE: Analyzing Text with Group Parameter in Pattern Tokenizer
DESCRIPTION: This snippet demonstrates how to use the _analyze API to examine the tokens generated by the pattern analyzer with a group parameter. It analyzes the text 'abc123def456ghi'.

LANGUAGE: json
CODE:
POST /my_index_group2/_analyze
{
  "analyzer": "my_pattern_analyzer",
  "text": "abc123def456ghi"
}

----------------------------------------

TITLE: Creating Memory for Conversational Search
DESCRIPTION: Creates a memory to store conversation history for conversational search.

LANGUAGE: JSON
CODE:
POST /_plugins/_ml/memory/
{
"name": "Conversation about NYC population"
}

----------------------------------------

TITLE: Querying Average CPU Usage in OpenSearch
DESCRIPTION: This JSON query calculates the average of the 'cpu_usage' field across all documents in an index. It uses an aggregation to compute the average, which can be used in a per query monitor to track CPU usage trends.

LANGUAGE: json
CODE:
{
  "size": 0,
  "query": {
    "match_all": {}
  },
  "aggs": {
    "avg_cpu": {
      "avg": {
        "field": "cpu_usage"
      }
    }
  }
}

----------------------------------------

TITLE: Hot Threads Response Example 2
DESCRIPTION: Detailed response showing CPU usage and stack traces for multiple nodes with different thread types and activities.

LANGUAGE: bash
CODE:
::: {global-eu-35}{uFPbKLDOTlOmdnwUlKW8sw}{OAM8OT5CQAyasWuIDeVyUA}{global-eu-35.local}{[gdv2:a284:2acv:5fa6:0:3a2:7260:74cf]:9300}{dimr}{zone=west-a2, shard_indexing_pressure_enabled=true}
   Hot threads at 2022-04-01T15:15:27.658Z, interval=500ms, busiestThreads=3, ignoreIdleThreads=true:
   
    0.1% (645micros out of 500ms) cpu usage by thread 'opensearch[global-eu-35][transport_worker][T#7]'
     4/10 snapshots sharing following 3 elements
       io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
       io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
       java.base@11.0.14.1/java.lang.Thread.run(Thread.java:829)

----------------------------------------

TITLE: Example CAT Indices Response
DESCRIPTION: Sample response showing index information including health status, document count, and storage size.

LANGUAGE: json
CODE:
health | status | index | uuid | pri | rep | docs.count | docs.deleted | store.size | pri.store.size
green  | open | movies | UZbpfERBQ1-3GSH2bnM3sg | 1 | 1 | 1 | 0 | 7.7kb | 3.8kb

----------------------------------------

TITLE: Creating Remove Pipeline in OpenSearch
DESCRIPTION: Example of creating an ingest pipeline that removes an IP address field from documents.

LANGUAGE: json
CODE:
PUT /_ingest/pipeline/remove_ip
{
  "description": "Pipeline that excludes the ip_address field.",
  "processors": [
    {
      "remove": {
        "field": "ip_address"
      }
    }
  ]
}

----------------------------------------

TITLE: Installing S3 Repository Plugin in OpenSearch
DESCRIPTION: Bash command to install the repository-s3 plugin for using Amazon S3 as a snapshot repository.

LANGUAGE: bash
CODE:
sudo ./bin/opensearch-plugin install repository-s3

----------------------------------------

TITLE: Query Metrics Table Schema
DESCRIPTION: Structure showing key performance metrics tracked for each query in the Query Insights dashboard.

LANGUAGE: json
CODE:
{
  "ID": "string",
  "Type": "query|group",
  "Query Count": "number", 
  "Timestamp": "datetime",
  "Latency": "duration",
  "CPU Time": "duration",
  "Memory Usage": "bytes",
  "Indexes": "string[]",
  "Search Type": "string",
  "Coordinator Node ID": "string",
  "Total Shards": "number"
}

----------------------------------------

TITLE: Querying RCA Data with HTTP GET in Performance Analyzer
DESCRIPTION: Examples of HTTP GET requests to retrieve RCA data from the Performance Analyzer API. Includes requests for all available RCAs and a specific RCA by name.

LANGUAGE: http
CODE:
# Request all available RCAs
GET localhost:9600/_plugins/_performanceanalyzer/rca

# Request a specific RCA
GET localhost:9600/_plugins/_performanceanalyzer/rca?name=HighHeapUsageClusterRca

----------------------------------------

TITLE: Indexing Geopoint as Geohash
DESCRIPTION: Shows how to index a geopoint using a geohash string representation.

LANGUAGE: json
CODE:
PUT testindex1/_doc/3
{
  "point": "txhxegj0uyp3"
}

----------------------------------------

TITLE: Verifying pip Installation for OpenSearch Benchmark
DESCRIPTION: Checks that pip is installed and functional, as it's needed to install OpenSearch Benchmark.

LANGUAGE: bash
CODE:
pip --version

----------------------------------------

TITLE: Get Snapshot Repository Request Example - JSON
DESCRIPTION: Example request to retrieve information for a specific repository named 'my-opensearch-repo'.

LANGUAGE: json
CODE:
GET /_snapshot/my-opensearch-repo

----------------------------------------

TITLE: Creating Geoshape Mapping in OpenSearch
DESCRIPTION: Creates an index mapping with a geoshape field type named 'location'.

LANGUAGE: json
CODE:
PUT testindex
{
  "mappings": {
    "properties": {
      "location": {
        "type": "geo_shape"
      }
    }
  }
}

----------------------------------------

TITLE: Star-tree Date Histogram Aggregation Example
DESCRIPTION: Example query showing how to use date histogram aggregations with metric sub-aggregations to analyze logs filtered by status code and aggregated by month.

LANGUAGE: json
CODE:
{
    "size": 0,
    "query": {
        "range": {
            "status": {
                "gte": "200",
                "lte": "400"
            }
        }
    },
    "aggs": {
        "by_month": {
            "date_histogram": {
                "field": "@timestamp",
                "calendar_interval": "month"
            },
            "aggs": {
                "sum_size": {
                    "sum": {
                        "field": "size"
                    }
                }
            }
        }
    }
}

----------------------------------------

TITLE: Creating Custom Hungarian Analyzer in OpenSearch
DESCRIPTION: Demonstrates how to create a custom Hungarian analyzer with configurable components including stop words, stemmer, and keyword marker filters.

LANGUAGE: json
CODE:
PUT /hungarian-index
{
  "settings": {
    "analysis": {
      "filter": {
        "hungarian_stop": {
          "type": "stop",
          "stopwords": "_hungarian_"
        },
        "hungarian_stemmer": {
          "type": "stemmer",
          "language": "hungarian"
        },
        "hungarian_keywords": {
          "type": "keyword_marker",
          "keywords": []
        }
      },
      "analyzer": {
        "hungarian_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "hungarian_stop",
            "hungarian_keywords",
            "hungarian_stemmer"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "hungarian_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Defining User Agent Processor in OpenSearch Pipeline
DESCRIPTION: JSON structure for defining a user_agent processor within an OpenSearch ingest pipeline. This processor extracts information from a user agent string field and stores it in a target field.

LANGUAGE: json
CODE:
{
  "processor": {
    "user_agent": {
      "field": "user_agent",
      "target_field": "user_agent_info"
    }
  }
}

----------------------------------------

TITLE: Executing Localization Algorithm in OpenSearch
DESCRIPTION: An example request to execute the Localization algorithm using the ML Commons plugin in OpenSearch. This request finds subset-level information for aggregate data demonstrating activity of interest such as spikes, drops, changes, or anomalies.

LANGUAGE: json
CODE:
POST /_plugins/_ml/_execute/anomaly_localization
{
  "index_name": "rca-index",
  "attribute_field_names": [
    "attribute"
  ],
  "aggregations": [
    {
      "sum": {
        "sum": {
          "field": "value"
        }
      }
    }
  ],
  "time_field_name": "timestamp",
  "start_time": 1620630000000,
  "end_time": 1621234800000,
  "min_time_interval": 86400000,
  "num_outputs": 10
}

----------------------------------------

TITLE: Configuring Custom Simple Analyzer with HTML Strip in OpenSearch
DESCRIPTION: This snippet shows how to configure a custom analyzer equivalent to a simple analyzer with an added HTML strip character filter. It creates an index 'my_custom_simple_index' with a custom analyzer that includes HTML stripping, lowercase tokenization, and lowercase filtering.

LANGUAGE: json
CODE:
PUT /my_custom_simple_index
{
  "settings": {
    "analysis": {
      "char_filter": {
        "html_strip": {
          "type": "html_strip"
        }
      },
      "tokenizer": {
        "my_lowercase_tokenizer": {
          "type": "lowercase"
        }
      },
      "analyzer": {
        "my_custom_simple_analyzer": {
          "type": "custom",
          "char_filter": ["html_strip"],
          "tokenizer": "my_lowercase_tokenizer",
          "filter": ["lowercase"]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "my_field": {
        "type": "text",
        "analyzer": "my_custom_simple_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Including Banner and Cards Components in OpenSearch Search Results Page
DESCRIPTION: Includes the banner and cards components into the OpenSearch documentation search results page using Liquid include tags.

LANGUAGE: liquid
CODE:
{% include banner.html %}

{% include cards.html %}

----------------------------------------

TITLE: Configuring Local Index Exporter
DESCRIPTION: JSON requests to configure the local index exporter and set index retention period.

LANGUAGE: json
CODE:
PUT _cluster/settings
{
  "persistent" : {
    "search.insights.top_queries.exporter.type" : "local_index"
  }
}

LANGUAGE: json
CODE:
PUT _cluster/settings
{
  "persistent" : {
    "search.insights.top_queries.exporter.delete_after_days" : "10"
  }
}

----------------------------------------

TITLE: Refreshing Indices in OpenSearch Benchmark
DESCRIPTION: Example of a refresh operation for specific index patterns.

LANGUAGE: yaml
CODE:
{
 "name": "refresh",
 "operation-type": "refresh",
 "index": "logs-*"
}

----------------------------------------

TITLE: Search Model Groups by Owner
DESCRIPTION: Example request demonstrating how to search for model groups by a specific owner name using a nested query.

LANGUAGE: json
CODE:
{
  "query": {
    "bool": {
      "must": [
        {
          "nested": {
            "query": {
              "term": {
                "owner.name.keyword": {
                  "value": "user1",
                  "boost": 1
                }
              }
            },
            "path": "owner",
            "ignore_unmapped": false,
            "score_mode": "none",
            "boost": 1
          }
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Cross-fields Multi-match Query
DESCRIPTION: Example of a cross-fields query searching for 'John Doe' across first_name and last_name fields with AND operator.

LANGUAGE: json
CODE:
GET /customers/_search
{
  "query": {
    "multi_match" : {
      "query": "John Doe",
      "type": "cross_fields",
      "fields": [ "first_name", "last_name" ],
      "operator": "and"
    }
  }
}

----------------------------------------

TITLE: Field-Specific DQL Queries
DESCRIPTION: Examples of searching within specific fields using DQL syntax.

LANGUAGE: python
CODE:
title: rises wind

----------------------------------------

TITLE: Defining IAM Permissions for DynamoDB Source
DESCRIPTION: This JSON snippet shows the minimum required IAM permissions for running DynamoDB as a source in Data Prepper. It includes permissions for describing tables, running export jobs, reading from streams, and interacting with S3.

LANGUAGE: json
CODE:
{
    "Version": "2012-10-17",
    "Statement": [
      {
        "Sid": "allowDescribeTable",
        "Effect": "Allow",
        "Action": [
          "dynamodb:DescribeTable"
        ],
        "Resource": [
          "arn:aws:dynamodb:us-east-1:{account-id}:table/my-table"
        ]
      },
       {
            "Sid": "allowRunExportJob",
            "Effect": "Allow",
            "Action": [
                "dynamodb:DescribeContinuousBackups",
                "dynamodb:ExportTableToPointInTime"
            ],
            "Resource": [
                "arn:aws:dynamodb:us-east-1:{account-id}:table/my-table"
            ]
        },
        {
            "Sid": "allowCheckExportjob",
            "Effect": "Allow",
            "Action": [
                "dynamodb:DescribeExport"
            ],
            "Resource": [
                "arn:aws:dynamodb:us-east-1:{account-id}:table/my-table/export/*"
            ]
        },
        {
            "Sid": "allowReadFromStream",
            "Effect": "Allow",
            "Action": [
                "dynamodb:DescribeStream",
                "dynamodb:GetRecords",
                "dynamodb:GetShardIterator"
            ],
            "Resource": [
                "arn:aws:dynamodb:us-east-1:{account-id}:table/my-table/stream/*"
            ]
        },
        {
            "Sid": "allowReadAndWriteToS3ForExport",
            "Effect": "Allow",
            "Action": [
                "s3:GetObject",
                "s3:AbortMultipartUpload",
                "s3:PutObject",
                "s3:PutObjectAcl"
            ],
            "Resource": [
                "arn:aws:s3:::my-bucket/*"
            ]
        }
    ]
}

----------------------------------------

TITLE: Creating Mapping with Dynamic Object Field in OpenSearch
DESCRIPTION: This snippet shows how to create a mapping with a dynamic object field in OpenSearch. It defines a 'patient' object with only a 'name' field, allowing for dynamic addition of new fields.

LANGUAGE: json
CODE:
PUT testindex1/_mappings
{
    "properties": {
      "patient": { 
        "properties" :
          {
            "name" : {
              "type" : "text"
            }
          }   
      }
    }
}

----------------------------------------

TITLE: Nested Aggregation Response in OpenSearch
DESCRIPTION: Example response from a nested aggregation query, showing the aggregation results including the document count and minimum load time for the nested 'pages' objects.

LANGUAGE: json
CODE:
...
"aggregations" : {
  "pages" : {
    "doc_count" : 2,
    "min_load_time" : {
      "value" : 200
    }
  }
 }
}

----------------------------------------

TITLE: Setting Windows Max Map Count
DESCRIPTION: Commands to set vm.max_map_count in Windows Subsystem for Linux (WSL) for Docker Desktop.

LANGUAGE: bash
CODE:
wsl -d docker-desktop
sysctl -w vm.max_map_count=262144

----------------------------------------

TITLE: Applying Norwegian Analyzer to Text Field in OpenSearch
DESCRIPTION: This snippet demonstrates how to apply the built-in Norwegian analyzer to a text field in an OpenSearch index mapping.

LANGUAGE: json
CODE:
PUT /norwegian-index
{
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "norwegian"
      }
    }
  }
}

----------------------------------------

TITLE: Indexing Documents with date_nanos Fields in OpenSearch
DESCRIPTION: These snippets show how to index two documents into the previously created index, each with a date_nanos field.

LANGUAGE: json
CODE:
PUT testindex/_doc/1
{ "date": "2022-06-15T10:12:52.382719622Z" }

LANGUAGE: json
CODE:
PUT testindex/_doc/2
{ "date": "2022-06-15T10:12:52.382719624Z" }

----------------------------------------

TITLE: Indexing xy point as object in OpenSearch
DESCRIPTION: This snippet shows how to index an xy point as an object with x and y coordinates in OpenSearch.

LANGUAGE: json
CODE:
PUT testindex1/_doc/1
{
  "point": { 
    "x": 0.5,
    "y": 4.5
  }
}

----------------------------------------

TITLE: Testing HTML Strip Pipeline in OpenSearch
DESCRIPTION: Simulates the HTML strip pipeline with a test document containing HTML tags.

LANGUAGE: json
CODE:
POST _ingest/pipeline/strip-html-pipeline/_simulate
{
  "docs": [
    {
      "_source": {
        "description": "This is a <b>test</b> description with <i>some</i> HTML tags."
      }
    }
  ]
}

----------------------------------------

TITLE: ML Commons Predict API Response in OpenSearch
DESCRIPTION: This snippet shows the response structure from the ML Commons Predict API. It includes the prediction status and results with column metadata and predicted values.

LANGUAGE: json
CODE:
{
  "status" : "COMPLETED",
  "prediction_result" : {
    "column_metas" : [
      {
        "name" : "ClusterID",
        "column_type" : "INTEGER"
      }
    ],
    "rows" : [
      {
        "values" : [
          {
            "column_type" : "INTEGER",
            "value" : 1
          }
        ]
      },
      {
        "values" : [
          {
            "column_type" : "INTEGER",
            "value" : 1
          }
        ]
      },
      {
        "values" : [
          {
            "column_type" : "INTEGER",
            "value" : 0
          }
        ]
      },
      {
        "values" : [
          {
            "column_type" : "INTEGER",
            "value" : 0
          }
        ]
      },
      {
        "values" : [
          {
            "column_type" : "INTEGER",
            "value" : 0
          }
        ]
      },
      {
        "values" : [
          {
            "column_type" : "INTEGER",
            "value" : 0
          }
        ]
      }
    ]
  }
}

----------------------------------------

TITLE: Enabling Root Cause Analysis Framework
DESCRIPTION: cURL commands to enable the Root Cause Analysis (RCA) framework in Performance Analyzer.

LANGUAGE: bash
CODE:
curl -XPOST http://localhost:9200/_plugins/_performanceanalyzer/rca/cluster/config -H 'Content-Type: application/json' -d '{"enabled": true}'

LANGUAGE: bash
CODE:
curl -XPOST https://localhost:9200/_plugins/_performanceanalyzer/rca/cluster/config -H 'Content-Type: application/json' -d '{"enabled": true}' -u 'admin:<custom-admin-password>' -k

----------------------------------------

TITLE: Multi-search Request Pattern
DESCRIPTION: The pattern for structuring a multi-search request body, showing the alternating metadata and query format required.

LANGUAGE: text
CODE:
Metadata\n
Query\n
Metadata\n
Query\n


----------------------------------------

TITLE: Creating Custom Swedish Analyzer in OpenSearch
DESCRIPTION: This snippet illustrates how to create a custom Swedish analyzer in OpenSearch. It defines custom filters for stop words, stemming, and keywords, and combines them into a custom analyzer applied to a 'content' field.

LANGUAGE: json
CODE:
PUT /swedish-index
{
  "settings": {
    "analysis": {
      "filter": {
        "swedish_stop": {
          "type": "stop",
          "stopwords": "_swedish_"
        },
        "swedish_stemmer": {
          "type": "stemmer",
          "language": "swedish"
        },
        "swedish_keywords": {
          "type": "keyword_marker",
          "keywords": []
        }
      },
      "analyzer": {
        "swedish_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "swedish_stop",
            "swedish_keywords",
            "swedish_stemmer"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "swedish_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: String Concatenation Expression Examples in OpenSearch Data Prepper
DESCRIPTION: Examples of using string concatenation to combine strings and use them in conditional expressions.

LANGUAGE: markdown
CODE:
/name + "suffix"
"prefix" + /name
"time of " + /timeInMs + " ms"

----------------------------------------

TITLE: Creating a Custom Abbreviation Mapping Filter in OpenSearch
DESCRIPTION: This example shows how to create a custom mapping character filter in OpenSearch to replace common abbreviations. It defines a new analyzer and character filter with mappings for BTW, IDK, and FYI.

LANGUAGE: json
CODE:
PUT /test-index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "custom_abbr_analyzer": {
          "tokenizer": "standard",
          "char_filter": [
            "custom_abbr_filter"
          ]
        }
      },
      "char_filter": {
        "custom_abbr_filter": {
          "type": "mapping",
          "mappings": [
            "BTW => By the way",
            "IDK => I don't know",
            "FYI => For your information"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Updating Cluster Settings for Shard Allocation Awareness
DESCRIPTION: JSON request to update cluster settings for shard allocation awareness.

LANGUAGE: json
CODE:
PUT _cluster/settings
{
  "persistent": {
    "cluster.routing.allocation.awareness.attributes": "zone"
  }
}

----------------------------------------

TITLE: Creating Index with Standard Analyzer - OpenSearch JSON
DESCRIPTION: Creates an index named 'my_standard_index' with a standard analyzer applied to a text field. This configuration demonstrates basic analyzer setup.

LANGUAGE: json
CODE:
PUT /my_standard_index
{
  "mappings": {
    "properties": {
      "my_field": {
        "type": "text",
        "analyzer": "standard"  
      }
    }
  }
}

----------------------------------------

TITLE: Creating a Sort Pipeline in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a pipeline named 'sort-pipeline' that uses the Sort processor. It sorts the 'my_field' in descending order and stores the result in 'sorted_field'.

LANGUAGE: json
CODE:
PUT _ingest/pipeline/sort-pipeline
{
  "description": "Sort an array of items in descending order",
  "processors": [
    {
      "sort": {
        "field": "my_array_field",
        "order": "desc",
        "target_field": "sorted_array"
      }
    }
  ]
}

----------------------------------------

TITLE: Undeploying a Single Model - OpenSearch REST API
DESCRIPTION: Basic endpoint for undeploying a specific model from all ML nodes using the model ID.

LANGUAGE: json
CODE:
POST /_plugins/_ml/models/<model_id>/_undeploy

----------------------------------------

TITLE: Single Index CAT Segments Query
DESCRIPTION: Query to retrieve segment information for a specific index with verbose output.

LANGUAGE: json
CODE:
GET _cat/segments/<index>?v

----------------------------------------

TITLE: Creating an OpenSearch Index with doc_values Enabled and Disabled
DESCRIPTION: This JSON snippet demonstrates how to create an index in OpenSearch with doc_values enabled for one field (status_code) and explicitly disabled for another (session_id). The doc_values parameter is set to false for the session_id field, while it's implicitly true for status_code.

LANGUAGE: json
CODE:
PUT my-index-001
{
  "mappings": {
    "properties": {
      "status_code": { 
        "type": "keyword"
      },
      "session_id": { 
        "type": "keyword",
        "doc_values": false
      }
    }
  }
}

----------------------------------------

TITLE: Defining Chained Alert Trigger Conditions
DESCRIPTION: Examples of using Painless scripting language to define logical conditions for chained alert triggers.

LANGUAGE: painless
CODE:
// Example 1: AND condition
monitor[id=1] && monitor[id=2]

// Example 2: OR with NOT condition
monitor[id=1] || !monitor[id=2]

// Example 3: Complex condition with precedence
monitor[id=1] && (monitor[id=2] || monitor[id=3])

----------------------------------------

TITLE: Creating Index with Keep Words Filter in OpenSearch
DESCRIPTION: Example of creating a new index with a custom analyzer that uses the keep_words filter. The filter is configured to keep only specific words ('example', 'world', 'opensearch') with case sensitivity enabled.

LANGUAGE: json
CODE:
PUT my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "custom_keep_word": {
          "tokenizer": "standard",
          "filter": [ "keep_words_filter" ]
        }
      },
      "filter": {
        "keep_words_filter": {
          "type": "keep",
          "keep_words": ["example", "world", "opensearch"],
          "keep_words_case": true
        }
      }
    }
  }
}

----------------------------------------

TITLE: Analyzing Text with Custom Analyzer in OpenSearch
DESCRIPTION: This example demonstrates how to use the _analyze API to examine the tokens generated by the custom analyzer with the keyword_repeat filter.

LANGUAGE: json
CODE:
POST /my_index/_analyze
{
  "analyzer": "my_custom_analyzer",
  "text": "Stopped quickly"
}

----------------------------------------

TITLE: Creating an Index with Pattern Analyzer in OpenSearch
DESCRIPTION: This snippet demonstrates how to create an index named 'my_pattern_index' with a custom pattern analyzer. The analyzer is configured to use a specific regex pattern, convert tokens to lowercase, and filter out stopwords.

LANGUAGE: json
CODE:
PUT /my_pattern_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_pattern_analyzer": {
          "type": "pattern",
          "pattern": "\\W+",  
          "lowercase": true,                
          "stopwords": ["and", "is"]       
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "my_field": {
        "type": "text",
        "analyzer": "my_pattern_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Indexing Documents with Null Values in OpenSearch
DESCRIPTION: Shows how to index documents with null values, empty arrays, and arrays of null values in OpenSearch. This example indexes three documents with different representations of null or empty values.

LANGUAGE: json
CODE:
PUT testindex/_doc/1
{
  "name": "Akua Mansa",
  "emergency_phone": null
}

PUT testindex/_doc/2
{
  "name": "Diego Ramirez",
  "emergency_phone" : []
}

PUT testindex/_doc/3 
{
  "name": "Jane Doe",
  "emergency_phone": [null, null]
}

----------------------------------------

TITLE: Analyzing Text with Min Hash Analyzer in OpenSearch
DESCRIPTION: This snippet shows how to use the _analyze API to examine the tokens generated by the min_hash analyzer for a given text input. It demonstrates the format of the generated hash tokens.

LANGUAGE: json
CODE:
POST /minhash_index/_analyze
{
  "analyzer": "minhash_analyzer",
  "text": "OpenSearch is very powerful."
}

----------------------------------------

TITLE: Disabling Expensive Queries Configuration
DESCRIPTION: Shows how to disable expensive queries at the cluster level using cluster settings API.

LANGUAGE: json
CODE:
PUT _cluster/settings
{
  "persistent": {
    "search.allow_expensive_queries": false
  }
}

----------------------------------------

TITLE: Analyzing Text with German Normalization in OpenSearch
DESCRIPTION: This example demonstrates how to use the '_analyze' endpoint to test the custom German normalization analyzer. It shows how to apply the analyzer to a sample text and view the resulting tokens.

LANGUAGE: json
CODE:
POST /german_normalizer_example/_analyze
{
  "text": "Strae Mnchen",
  "analyzer": "german_normalizer_analyzer"
}

----------------------------------------

TITLE: Analyzing Text with HTML Strip Character Filter in OpenSearch
DESCRIPTION: This snippet demonstrates how to use the HTML strip character filter to remove HTML tags from input text and decode HTML entities.

LANGUAGE: json
CODE:
GET /_analyze
{
  "tokenizer": "keyword",
  "char_filter": [
    "html_strip"
  ],
  "text": "<p>Commonly used calculus symbols include &alpha;, &beta; and &theta; </p>"
}

----------------------------------------

TITLE: Executing an Agent Query for Population Data
DESCRIPTION: Sends a query to the registered agent asking about Seattle's population, showing how the agent retrieves and processes information from the population data knowledge base.

LANGUAGE: json
CODE:
POST _plugins/_ml/agents/your_agent_id/_execute
{
  "parameters": {
    "question": "What's the population of Seattle 2023",
    "verbose": true
  }
}

----------------------------------------

TITLE: Getting Local Remote Store Stats
DESCRIPTION: API endpoint to retrieve remote store statistics only for shards present on the node serving the request. Uses the local parameter to filter results.

LANGUAGE: json
CODE:
GET _remotestore/stats/<index_name>?local=true

----------------------------------------

TITLE: Sample Cluster Allocation Response
DESCRIPTION: Detailed response showing allocation decisions, node information, and decider explanations for a shard allocation request.

LANGUAGE: json
CODE:
{
  "index": "movies",
  "shard": 0,
  "primary": true,
  "current_state": "started",
  "current_node": {
    "id": "d8jRZcW1QmCBeVFlgOJx5A",
    "name": "opensearch-node1",
    "transport_address": "172.24.0.4:9300",
    "weight_ranking": 1
  },
  "can_remain_on_current_node": "yes",
  "can_rebalance_cluster": "yes",
  "can_rebalance_to_other_node": "no",
  "rebalance_explanation": "cannot rebalance as no target node exists that can both allocate this shard and improve the cluster balance",
  "node_allocation_decisions": [{
    "node_id": "vRxi4uPcRt2BtHlFoyCyTQ",
    "node_name": "opensearch-node2",
    "transport_address": "172.24.0.3:9300",
    "node_decision": "no",
    "weight_ranking": 1,
    "deciders": [{
        "decider": "max_retry",
        "decision": "YES",
        "explanation": "shard has no previous failures"
      },
      {
        "decider": "replica_after_primary_active",
        "decision": "YES",
        "explanation": "shard is primary and can be allocated"
      },
      {
        "decider": "enable",
        "decision": "YES",
        "explanation": "all allocations are allowed"
      },
      {
        "decider": "node_version",
        "decision": "YES",
        "explanation": "can relocate primary shard from a node with version [1.0.0] to a node with equal-or-newer version [1.0.0]"
      },
      {
        "decider": "snapshot_in_progress",
        "decision": "YES",
        "explanation": "no snapshots are currently running"
      },
      {
        "decider": "restore_in_progress",
        "decision": "YES",
        "explanation": "ignored as shard is not being recovered from a snapshot"
      },
      {
        "decider": "filter",
        "decision": "YES",
        "explanation": "node passes include/exclude/require filters"
      },
      {
        "decider": "same_shard",
        "decision": "NO",
        "explanation": "a copy of this shard is already allocated to this node [[movies][0], node[vRxi4uPcRt2BtHlFoyCyTQ], [R], s[STARTED], a[id=x8w7QxWdQQa188HKGn0iMQ]]"
      },
      {
        "decider": "disk_threshold",
        "decision": "YES",
        "explanation": "enough disk for shard on node, free: [35.9gb], shard size: [15.1kb], free after allocating shard: [35.9gb]"
      },
      {
        "decider": "throttling",
        "decision": "YES",
        "explanation": "below shard recovery limit of outgoing: [0 < 2] incoming: [0 < 2]"
      },
      {
        "decider": "shards_limit",
        "decision": "YES",
        "explanation": "total shard limits are disabled: [index: -1, cluster: -1] <= 0"
      },
      {
        "decider": "awareness",
        "decision": "YES",
        "explanation": "allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it"
      }
    ]
  }]
}

----------------------------------------

TITLE: Multi-search Template Example Response
DESCRIPTION: Example response showing the structure of results returned from a multi-search template request, including timing information and search hits.

LANGUAGE: json
CODE:
{
  "took": 5,
  "responses": [
    {
      "took": 5,
      "timed_out": false,
      "_shards": {
        "total": 1,
        "successful": 1,
        "skipped": 0,
        "failed": 0
      },
      "hits": {
        "total": {
          "value": 0,
          "relation": "eq"
        },
        "max_score": null,
        "hits": []
      },
      "status": 200
    },
    {
      "took": 3,
      "timed_out": false,
      "_shards": {
        "total": 1,
        "successful": 1,
        "skipped": 0,
        "failed": 0
      },
      "hits": {
        "total": {
          "value": 0,
          "relation": "eq"
        },
        "max_score": null,
        "hits": []
      },
      "status": 200
    }
  ]
}

----------------------------------------

TITLE: Analyzing Text with Kuromoji Completion Filter in OpenSearch
DESCRIPTION: This snippet shows how to use the _analyze API to examine the tokens generated by the custom analyzer. It sends a POST request to analyze the Japanese text "" (meaning "use a computer") using the previously defined analyzer.

LANGUAGE: json
CODE:
POST /kuromoji_sample/_analyze
{
  "analyzer": "my_analyzer",
  "text": ""
}

----------------------------------------

TITLE: Sample IndexData Class Definition
DESCRIPTION: Basic Java class for storing index data with firstName and lastName fields.

LANGUAGE: java
CODE:
static class IndexData {
  private String firstName;
  private String lastName;

  public IndexData(String firstName, String lastName) {
    this.firstName = firstName;
    this.lastName = lastName;
  }

  public String getFirstName() {
    return firstName;
  }

  public void setFirstName(String firstName) {
    this.firstName = firstName;
  }

  public String getLastName() {
    return lastName;
  }

  public void setLastName(String lastName) {
    this.lastName = lastName;
  }

  @Override
  public String toString() {
    return String.format("IndexData{first name='%s', last name='%s'}", firstName, lastName);
  }
}

----------------------------------------

TITLE: Indexing a Document with Coerce Disabled in OpenSearch
DESCRIPTION: This example shows how to create an index with the 'coerce' parameter disabled for the 'quantity' field, preventing automatic conversion of string values to integers and causing rejection of mismatched types.

LANGUAGE: json
CODE:
PUT orders
{
  "mappings": {
    "properties": {
      "quantity": {
        "type": "integer",
        "coerce": false
      }
    }
  }
}

PUT orders/_doc/1
{
  "item": "Widget",
  "quantity": "10"
}

----------------------------------------

TITLE: Example Request for Updating Connector in OpenSearch ML Commons
DESCRIPTION: An example JSON request body for updating a connector. This example updates the description field of the connector with ID 'u3DEbI0BfUsSoeNTti-1'.

LANGUAGE: json
CODE:
PUT /_plugins/_ml/connectors/u3DEbI0BfUsSoeNTti-1
{
  "description": "The connector to public OpenAI model service for GPT 3.5"
}

----------------------------------------

TITLE: Enabling Compatibility Mode in OpenSearch
DESCRIPTION: This JSON snippet shows how to enable a compatibility setting in OpenSearch that makes it return version 7.10.2 instead of its actual version. This is useful for clients that include version checks.

LANGUAGE: json
CODE:
PUT _cluster/settings
{
  "persistent": {
    "compatibility": {
      "override_main_response_version": true
    }
  }
}

----------------------------------------

TITLE: Rolling Over an Index Alias in OpenSearch
DESCRIPTION: Illustrates how to roll over an index alias in OpenSearch using specified conditions such as maximum age, document count, and primary shard size.

LANGUAGE: json
CODE:
POST my-alias/_rollover
{
  "conditions": {
    "max_age": "5d",
    "max_docs": 500,
    "max_primary_shard_size": "100gb"
  }
}

----------------------------------------

TITLE: Response from Greek Lowercase Filter Analysis in OpenSearch
DESCRIPTION: This snippet shows the response received after analyzing Greek text with the custom lowercase filter. It displays the generated tokens with their positions and offsets.

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "",
      "start_offset": 0,
      "end_offset": 5,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "",
      "start_offset": 6,
      "end_offset": 12,
      "type": "<ALPHANUM>",
      "position": 1
    }
  ]
}

----------------------------------------

TITLE: Analyzing French Text with Custom Elision Analyzer in OpenSearch
DESCRIPTION: This snippet shows how to use the '_analyze' endpoint to test the custom French analyzer with elision filtering. It applies the analyzer to a sample French sentence to demonstrate how elisions are handled.

LANGUAGE: json
CODE:
POST /french_texts/_analyze
{
  "analyzer": "french_analyzer",
  "text": "L'tudiant aime l'cole et le travail."
}

----------------------------------------

TITLE: Ingesting RAG Data into an Index
DESCRIPTION: This bulk request ingests sample RAG data into the previously created index.

LANGUAGE: json
CODE:
POST _bulk
{"index": {"_index": "my_rag_test_data", "_id": "1"}}
{"text": "Abraham Lincoln was born on February 12, 1809, the second child of Thomas Lincoln and Nancy Hanks Lincoln, in a log cabin on Sinking Spring Farm near Hodgenville, Kentucky.[2] He was a descendant of Samuel Lincoln, an Englishman who migrated from Hingham, Norfolk, to its namesake, Hingham, Massachusetts, in 1638. The family then migrated west, passing through New Jersey, Pennsylvania, and Virginia.[3] Lincoln was also a descendant of the Harrison family of Virginia; his paternal grandfather and namesake, Captain Abraham Lincoln and wife Bathsheba (ne Herring) moved the family from Virginia to Jefferson County, Kentucky.[b] The captain was killed in an Indian raid in 1786.[5] His children, including eight-year-old Thomas, Abraham's father, witnessed the attack.[6][c] Thomas then worked at odd jobs in Kentucky and Tennessee before the family settled in Hardin County, Kentucky, in the early 1800s."}
{"index": {"_index": "my_rag_test_data", "_id": "2"}}
{"text": "Chart and table of population level and growth rate for the New York City metro area from 1950 to 2023. United Nations population projections are also included through the year 2035.\nThe current metro area population of New York City in 2023 is 18,937,000, a 0.37% increase from 2022.\nThe metro area population of New York City in 2022 was 18,867,000, a 0.23% increase from 2021.\nThe metro area population of New York City in 2021 was 18,823,000, a 0.1% increase from 2020.\nThe metro area population of New York City in 2020 was 18,804,000, a 0.01% decline from 2019."}

----------------------------------------

TITLE: Listing Available OpenSearch Benchmark Workloads
DESCRIPTION: Command to display all supported workloads in OpenSearch Benchmark

LANGUAGE: bash
CODE:
opensearch-benchmark list workloads

----------------------------------------

TITLE: Creating index mapping for blogs with date field
DESCRIPTION: Creates an index mapping for a 'blogs' index with a 'date_posted' field of type 'date'.

LANGUAGE: json
CODE:
PUT blogs
{
  "mappings" : {
    "properties" :  {
      "date_posted" : {
        "type" : "date",
        "format" : "yyyy-MM-dd"
      }
    }
  }
}

----------------------------------------

TITLE: Applying Turkish Analyzer to Text Field in OpenSearch
DESCRIPTION: This snippet demonstrates how to apply the built-in Turkish analyzer to a text field when creating an index in OpenSearch.

LANGUAGE: json
CODE:
PUT /turkish-index
{
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "turkish"
      }
    }
  }
}

----------------------------------------

TITLE: Analyzing Text with Preconfigured Delimited Term Frequency Filter
DESCRIPTION: Example of using the preconfigured delimited_term_freq token filter with the default '|' delimiter to analyze text through the _analyze endpoint.

LANGUAGE: json
CODE:
{
  "text": "foo|100",
  "tokenizer": "keyword",
  "filter": ["delimited_term_freq"],
  "attributes": ["termFrequency"],
  "explain": true
}

----------------------------------------

TITLE: Ingesting Document with IP2Geo Pipeline in OpenSearch
DESCRIPTION: This snippet demonstrates how to ingest a document into an index using the IP2Geo pipeline.

LANGUAGE: json
CODE:
PUT /my-index/_doc/my-id?pipeline=my-pipeline
{
  "ip": "172.0.0.1"
}

----------------------------------------

TITLE: Model Group Response Structure - OpenSearch JSON
DESCRIPTION: Example JSON response showing the structure of model group information, including name, version, description, access level, and timestamps for creation and last update.

LANGUAGE: json
CODE:
{
  "name": "test_model_group",
  "latest_version": 0,
  "description": "This is a public model group",
  "access": "public",
  "created_time": 1715112992748,
  "last_updated_time": 1715112992748
}

----------------------------------------

TITLE: Registering Flow Agent with VisualizationTool in OpenSearch
DESCRIPTION: This snippet demonstrates how to register a flow agent that uses the VisualizationTool. It specifies the agent name, type, description, and tool parameters including the index to search and input format.

LANGUAGE: json
CODE:
POST /_plugins/_ml/agents/_register
{
  "name": "Test_Agent_For_Visualization_tool",
  "type": "flow",
  "description": "this is a test agent for the VisuailizationTool",
  "tools": [
      {
      "type": "VisualizationTool",
      "name": "DemoVisualizationTool",
      "parameters": {
        "index": ".kibana",
        "input": "${parameters.question}",
        "size": 3
      }
    }
  ]
}

----------------------------------------

TITLE: Analyzing Text with Multiplexer Analyzer in OpenSearch
DESCRIPTION: This snippet shows how to use the '_analyze' endpoint to test the custom multiplexer analyzer. It analyzes the text 'The slow turtle hides from the quick dog' using the previously defined analyzer.

LANGUAGE: json
CODE:
POST /multiplexer_index/_analyze
{
  "analyzer": "multiplexer_analyzer",
  "text": "The slow turtle hides from the quick dog"
}

----------------------------------------

TITLE: Executing Search with Hybrid Score Explanation
DESCRIPTION: Demonstrates how to use the search pipeline with explain parameter to get detailed scoring information. The query combines both text matching and neural search.

LANGUAGE: json
CODE:
GET /my-nlp-index/_search?search_pipeline=nlp-search-pipeline&explain=true
{
  "_source": {
    "exclude": [
      "passage_embedding"
    ]
  },
  "query": {
    "hybrid": {
      "queries": [
        {
          "match": {
            "text": {
              "query": "horse"
            }
          }
        },
        {
          "neural": {
            "passage_embedding": {
              "query_text": "wild west",
              "model_id": "aVeif4oB5Vm0Tdw8zYO2",
              "k": 5
            }
          }
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Updating Documents with Bulk Helper in OpenSearch JavaScript Client
DESCRIPTION: Demonstrates how to use the bulk helper to update existing documents in an OpenSearch index. This operation requires the document to already exist in the index.

LANGUAGE: javascript
CODE:
client.helpers.bulk({
  datasource: arrayOfDocuments,
  onDocument (doc) {
    return [
      {
        update: { _index: 'example-index', _id: doc.id }
      },
      { doc_as_upsert: true }
    ]
  }
})

----------------------------------------

TITLE: Flow Framework Plugin Multi-tenancy Configuration
DESCRIPTION: Configuration example for enabling multi-tenancy in the Flow Framework plugin using AWS DynamoDB as the remote metadata store. Includes settings for endpoint, region, and service name.

LANGUAGE: yaml
CODE:
plugins.flow_framework.multi_tenancy_enabled: true
plugins.flow_framework.remote_metadata_type: AWSDynamoDB
plugins.flow_framework.remote_metadata_endpoint: <REMOTE_ENDPOINT>
plugins.flow_framework.remote_metadata_region: <AWS_REGION>
plugins.flow_framework.remote_metadata_service_name: <SERVICE_NAME>

----------------------------------------

TITLE: Removing Plugins from OpenSearch Docker Image
DESCRIPTION: A Dockerfile example showing how to remove a plugin (in this case, the Security plugin) from the OpenSearch Docker image.

LANGUAGE: Dockerfile
CODE:
FROM opensearchproject/opensearch:latest
RUN /usr/share/opensearch/bin/opensearch-plugin remove opensearch-security

----------------------------------------

TITLE: Stem Exclusion Configuration in OpenSearch
DESCRIPTION: Example demonstrating how to configure stem exclusion for the English analyzer to prevent specific words from being stemmed.

LANGUAGE: json
CODE:
PUT index_with_stem_exclusion_english_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "stem_exclusion_english_analyzer":{
          "type":"english",
          "stem_exclusion": ["manager", "management"]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Sample Input Event with User Agent String
DESCRIPTION: Example JSON event containing a user agent string in the ua field that will be processed.

LANGUAGE: json
CODE:
{
  "ua":  "Mozilla/5.0 (iPhone; CPU iPhone OS 13_5_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.1.1 Mobile/15E148 Safari/604.1"
}

----------------------------------------

TITLE: Reserved Character Escaping in DQL
DESCRIPTION: Example of escaping reserved characters in DQL queries using backslash.

LANGUAGE: plaintext
CODE:
2\*3

----------------------------------------

TITLE: Cluster Settings Update Response
DESCRIPTION: Example response showing the successful update of the max_shards_per_node cluster setting.

LANGUAGE: json
CODE:
{
   "acknowledged":true,
   "persistent":{
      "cluster":{
         "max_shards_per_node":"500"
      }
   },
   "transient":{}
}

----------------------------------------

TITLE: Configuring IAM Trust Policy for OpenSearch
DESCRIPTION: JSON policy that allows OpenSearch service to assume the IAM role for accessing DeepSeek API credentials.

LANGUAGE: json
CODE:
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "Service": "es.amazonaws.com"
      },
      "Action": "sts:AssumeRole"
    }
  ]
}

----------------------------------------

TITLE: Indexing XY Point - GeoJSON Format
DESCRIPTION: Indexes a point shape using GeoJSON format with x,y coordinates.

LANGUAGE: json
CODE:
PUT testindex/_doc/1
{
  "location" : {
    "type" : "point",
    "coordinates" : [0.5, 4.5]        
  }
}

----------------------------------------

TITLE: Tokens Generated by Pattern Analyzer in OpenSearch
DESCRIPTION: This snippet shows the response from the _analyze API, displaying the tokens generated by the custom pattern analyzer. It illustrates how the analyzer splits the text, removes stopwords, and converts tokens to lowercase.

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "opensearch",
      "start_offset": 0,
      "end_offset": 10,
      "type": "word",
      "position": 0
    },
    {
      "token": "fast",
      "start_offset": 14,
      "end_offset": 18,
      "type": "word",
      "position": 2
    },
    {
      "token": "scalable",
      "start_offset": 23,
      "end_offset": 31,
      "type": "word",
      "position": 4
    }
  ]
}

----------------------------------------

TITLE: Ingesting Document with Gsub Pipeline in OpenSearch
DESCRIPTION: Demonstrates how to ingest a document into the 'logs' index using the gsub_pipeline. The pipeline will process the document before indexing, replacing 'error' with 'warning'.

LANGUAGE: json
CODE:
PUT logs/_doc/1?pipeline=gsub_pipeline
{
  "message": "This is an error message"
}

----------------------------------------

TITLE: WriteJson Processor Example Configuration
DESCRIPTION: Example showing the conversion of a nested object into a JSON string using the write_json processor with source field 'message'.

LANGUAGE: json
CODE:
{"message": {"key1":"value1", "key2":{"key3":"value3"}}}

----------------------------------------

TITLE: Creating Hot Node Index in JSON
DESCRIPTION: JSON request to create an index on a hot node in a hot-warm architecture.

LANGUAGE: json
CODE:
PUT newindex
{
  "settings": {
    "index.routing.allocation.require.temp": "hot"
  }
}

----------------------------------------

TITLE: Performing a Search Query with Query Group ID in OpenSearch
DESCRIPTION: Example of a search query using a queryGroupId to associate the request with a specific query group. This ensures the query adheres to the resource limits defined for that group.

LANGUAGE: json
CODE:
GET testindex/_search
Host: localhost:9200
Content-Type: application/json
queryGroupId: preXpc67RbKKeCyka72_Gw
{
  "query": {
    "match": {
      "field_name": "value"
    }
  }
}

----------------------------------------

TITLE: Querying Profile API for specific node in OpenSearch ML Commons
DESCRIPTION: This example request demonstrates how to query the Profile API for all tasks and models on a specific node in OpenSearch ML Commons.

LANGUAGE: json
CODE:
GET /_plugins/_ml/profile
{
  "node_ids": ["KzONM8c8T4Od-NoUANQNGg"],
  "return_all_tasks": true,
  "return_all_models": true
}

----------------------------------------

TITLE: Querying Cluster Settings Endpoints
DESCRIPTION: Basic GET and PUT endpoints for accessing and modifying cluster settings.

LANGUAGE: json
CODE:
GET _cluster/settings
PUT _cluster/settings

----------------------------------------

TITLE: Retrieving Field Mappings in OpenSearch
DESCRIPTION: This example shows how to retrieve mappings for specific fields ('year' and 'age') from an index.

LANGUAGE: json
CODE:
GET sample-index1/_mapping/field/year,age

----------------------------------------

TITLE: Configuring Bucket-Level Trigger Condition in JSON
DESCRIPTION: This JSON snippet demonstrates how to configure a bucket-level trigger condition with buckets_path, parent_bucket_path, and a script.

LANGUAGE: json
CODE:
{
  "buckets_path": {
    "count_var": "_count"
  },
  "parent_bucket_path": "composite_agg",
  "script": {
    "source": "params.count_var > 5"
  }
}

----------------------------------------

TITLE: Generated Tokens from Reverse Token Filter Analysis in OpenSearch
DESCRIPTION: This snippet shows the response from the _analyze API, displaying the tokens generated after applying the reverse token filter. Each token is reversed, and additional metadata such as offsets and positions are included.

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "olleh",
      "start_offset": 0,
      "end_offset": 5,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "dlrow",
      "start_offset": 6,
      "end_offset": 11,
      "type": "<ALPHANUM>",
      "position": 1
    }
  ]
}

----------------------------------------

TITLE: Force Merge API Response
DESCRIPTION: Example response showing the result of a force merge operation with shard statistics.

LANGUAGE: json
CODE:
{
  "_shards": {
    "total": 2,
    "successful": 1,
    "failed": 0
  }
}

----------------------------------------

TITLE: Analyzing Text with KStem Analyzer in OpenSearch
DESCRIPTION: This snippet shows how to use the _analyze API to test the custom KStem analyzer. It sends a POST request to analyze the text 'stops stopped' using the previously created 'my_kstem_analyzer'.

LANGUAGE: json
CODE:
POST /my_kstem_index/_analyze
{
  "analyzer": "my_kstem_analyzer",
  "text": "stops stopped"
}

----------------------------------------

TITLE: Querqy Search Query Example for OpenSearch
DESCRIPTION: JSON structure for a Querqy search query in OpenSearch. This example demonstrates how to structure a query using Querqy, specifying the matching query and query fields with their respective boost values.

LANGUAGE: json
CODE:
{
   "query": {
       "querqy": {
           "matching_query": {
               "query": "books"
           },
           "query_fields": [ "title^3.0", "words^2.1", "shortSummary"]
       }
   }
}

----------------------------------------

TITLE: Generated Tokens from Length Token Filter in OpenSearch
DESCRIPTION: This snippet shows the response from the _analyze API, displaying the tokens generated after applying the Length token filter. It includes the tokens, their positions, and offsets.

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "OpenSearch",
      "start_offset": 0,
      "end_offset": 10,
      "type": "word",
      "position": 0
    },
    {
      "token": "great",
      "start_offset": 16,
      "end_offset": 21,
      "type": "word",
      "position": 3
    },
    {
      "token": "tool!",
      "start_offset": 22,
      "end_offset": 27,
      "type": "word",
      "position": 4
    }
  ]
}

----------------------------------------

TITLE: Indexing Document with Title and Description
DESCRIPTION: Example of indexing a document containing Shakespeare-related content with title and description fields.

LANGUAGE: json
CODE:
PUT testindex1/_doc/1
{
  "title": " The Top 10 Shakespeare Poems",
  "description": "Top 10 sonnets of England's national poet and the Bard of Avon"
}

----------------------------------------

TITLE: Querying Flush Statistics in OpenSearch
DESCRIPTION: API call to retrieve flush operation statistics for a specific index, showing total flushes and time taken.

LANGUAGE: json
CODE:
GET /<index>/_stats/flush?pretty

----------------------------------------

TITLE: Sample Cluster Allocation Request
DESCRIPTION: Example request to explain shard allocation for a specific index and shard, including yes decisions in the response.

LANGUAGE: json
CODE:
GET _cluster/allocation/explain?include_yes_decisions=true
{
  "index": "movies",
  "shard": 0,
  "primary": true
}

----------------------------------------

TITLE: Creating Index Alias in OpenSearch
DESCRIPTION: This HTTP PUT request demonstrates how to create an alias for an index in OpenSearch. It creates the alias 'my-logs-today' for the index 'my-logs-2019-11-13'.

LANGUAGE: http
CODE:
PUT my-logs-2019-11-13/_alias/my-logs-today

----------------------------------------

TITLE: Phonetic Analysis Response in OpenSearch
DESCRIPTION: Example JSON response showing the generated phonetic token for both 'Stephen' and 'Steven'. The response demonstrates that both names produce the same phonetic representation.

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "STFN",
      "start_offset": 0,
      "end_offset": 6,
      "type": "<ALPHANUM>",
      "position": 0
    }
  ]
}

----------------------------------------

TITLE: Executing CAT Recovery Request in OpenSearch
DESCRIPTION: Example request for retrieving recovery information using the CAT recovery API in OpenSearch. The 'v' parameter enables verbose mode to display column headers.

LANGUAGE: json
CODE:
GET _cat/recovery?v

----------------------------------------

TITLE: Ingesting Single File from S3 to OpenSearch
DESCRIPTION: Example request demonstrating how to ingest a single file from Amazon S3 into OpenSearch with field mappings and credentials.

LANGUAGE: json
CODE:
{
  "index_name": "my-nlp-index",
  "field_map": {
    "chapter": "$.content[0]",
    "title": "$.content[1]",
    "chapter_embedding": "$.SageMakerOutput[0]",
    "title_embedding": "$.SageMakerOutput[1]",
    "_id": "$.id"
  },
  "ingest_fields": ["$.id"],
  "credential": {
    "region": "us-east-1",
    "access_key": "<your access key>",
    "secret_key": "<your secret key>",
    "session_token": "<your session token>"
  },
  "data_source": {
    "type": "s3",
    "source": ["s3://offlinebatch/output/sagemaker_batch.json.out"]
  }
}

----------------------------------------

TITLE: Testing Lowercase Pipeline in OpenSearch
DESCRIPTION: Demonstrates how to test the 'lowercase-title' pipeline using the simulate API. It processes a sample document with an uppercase title.

LANGUAGE: json
CODE:
POST _ingest/pipeline/lowercase-title/_simulate
{
  "docs": [
    {
      "_index": "testindex1",
      "_id": "1",
      "_source": {
        "title": "WAR AND PEACE"
      }
    }
  ]
}

----------------------------------------

TITLE: Creating an index for attachments in OpenSearch
DESCRIPTION: JSON command to create an index in OpenSearch for storing attachments.

LANGUAGE: json
CODE:
PUT /example-attachment-index
{
  "mappings": {
    "properties": {}
  }
}

----------------------------------------

TITLE: Analyzing Text with Classic Tokenizer in OpenSearch
DESCRIPTION: This example shows how to use the _analyze API to test the Classic tokenizer. It sends a POST request to analyze a sample text containing various patterns like product numbers, email addresses, and phone numbers.

LANGUAGE: json
CODE:
POST /my_index/_analyze
{
  "analyzer": "my_classic_analyzer",
  "text": "For product AB3423, visit X&Y at example.com, email info@example.com, or call the operator's phone number 1-800-555-1234. P.S. ."
}

----------------------------------------

TITLE: Expected JSON Output from Translate Processor
DESCRIPTION: The expected JSON output after processing the input with the translate processor, showing both original and translated values.

LANGUAGE: json
CODE:
{
  "status": "404",
  "translated_result": "Not Found"
}

----------------------------------------

TITLE: OpenSearch YAML Configuration for Data Sources
DESCRIPTION: Required YAML configuration entry for enabling encrypted data source connections in OpenSearch. Must be added to opensearch.yml on all nodes.

LANGUAGE: yaml
CODE:
plugins.query.datasources.encryption.masterkey: "YOUR_GENERATED_MASTER_KEY_HERE"

----------------------------------------

TITLE: Date Histogram Aggregation Response in OpenSearch
DESCRIPTION: This snippet shows the response format for a date histogram aggregation query. It includes buckets for each month, with a key (timestamp), key_as_string (formatted date), and doc_count (number of hits) for each bucket.

LANGUAGE: json
CODE:
...
"aggregations" : {
  "logs_per_month" : {
    "buckets" : [
      {
        "key_as_string" : "2020-10-01T00:00:00.000Z",
        "key" : 1601510400000,
        "doc_count" : 1635
      },
      {
        "key_as_string" : "2020-11-01T00:00:00.000Z",
        "key" : 1604188800000,
        "doc_count" : 6844
      },
      {
        "key_as_string" : "2020-12-01T00:00:00.000Z",
        "key" : 1606780800000,
        "doc_count" : 5595
      }
    ]
  }
}
}

----------------------------------------

TITLE: Analyzing Text with Turkish Analyzer in OpenSearch
DESCRIPTION: This example shows how to use the _analyze API to examine the tokens generated by the Turkish analyzer for a given text input.

LANGUAGE: json
CODE:
POST /turkish-index/_analyze
{
  "field": "content",
  "text": "renciler Trk niversitelerinde renim gryor. Numara 123456."
}

----------------------------------------

TITLE: Testing Dot Expander Pipeline in OpenSearch
DESCRIPTION: Simulates the dot_expander pipeline to test its functionality before ingesting actual documents.

LANGUAGE: json
CODE:
POST _ingest/pipeline/dot-expander-pipeline/_simulate
{
  "docs": [
    {
      "_index": "testindex1",
      "_id": "1",
      "_source": {
        "user.address.city": "New York",
        "user.address.state": "NY"
      }
    }
  ]
}

----------------------------------------

TITLE: Example Response for ML Commons Stats in OpenSearch
DESCRIPTION: This JSON response shows the ML executing task count for multiple nodes in the OpenSearch cluster. Each node is identified by its unique ID, and the 'ml_executing_task_count' indicates the number of currently executing ML tasks on that node.

LANGUAGE: json
CODE:
{
  "zbduvgCCSOeu6cfbQhTpnQ" : {
    "ml_executing_task_count" : 0
  },
  "54xOe0w8Qjyze00UuLDfdA" : {
    "ml_executing_task_count" : 0
  },
  "UJiykI7bTKiCpR-rqLYHyw" : {
    "ml_executing_task_count" : 0
  },
  "zj2_NgIbTP-StNlGZJlxdg" : {
    "ml_executing_task_count" : 0
  },
  "jjqFrlW7QWmni1tRnb_7Dg" : {
    "ml_executing_task_count" : 0
  },
  "3pSSjl5PSVqzv5-hBdFqyA" : {
    "ml_executing_task_count" : 0
  },
  "A_IiqoloTDK01uZvCjREaA" : {
    "ml_executing_task_count" : 0
  }
}

----------------------------------------

TITLE: Get Workflow Steps in YAML Format
DESCRIPTION: cURL command to retrieve workflow steps in YAML format by specifying the Content-Type header.

LANGUAGE: bash
CODE:
curl -XGET "http://localhost:9200/_plugins/_flow_framework/workflow/_steps" -H 'Content-Type: application/yaml'

----------------------------------------

TITLE: Retrieving Document Processed by IP2Geo Pipeline in OpenSearch
DESCRIPTION: This snippet shows how to retrieve a document that has been processed by the IP2Geo pipeline.

LANGUAGE: json
CODE:
GET /my-index/_doc/my-id

----------------------------------------

TITLE: Running Logstash with Stdin Input and Stdout Output
DESCRIPTION: Demonstrates how to run Logstash with a simple pipeline that takes input from stdin and outputs to stdout using the -e flag.

LANGUAGE: bash
CODE:
bin/logstash -e "input { stdin { } } output { stdout { } }"

----------------------------------------

TITLE: Deleting an OpenSearch Index
DESCRIPTION: JavaScript code for deleting an OpenSearch index using the indices.delete() method.

LANGUAGE: javascript
CODE:
var response = await client.indices.delete({
  index: index_name,
});

----------------------------------------

TITLE: Basic Put Mapping Endpoints
DESCRIPTION: The basic endpoints for creating or updating mappings for single or multiple indexes.

LANGUAGE: json
CODE:
PUT /<target-index>/_mapping
PUT /<target-index1>,<target-index2>/_mapping

----------------------------------------

TITLE: Registering Flow Agent with SearchAlertsTool
DESCRIPTION: Example of registering a flow agent that uses the SearchAlertsTool. The agent is configured with a demo memory type and basic SearchAlertsTool parameters.

LANGUAGE: json
CODE:
{
  "name": "Test_Agent_For_Search_Alerts_Tool",
  "type": "flow",
  "description": "this is a test agent for the SearchAlertsTool",
  "memory": {
    "type": "demo"
  },
  "tools": [
      {
      "type": "SearchAlertsTool",
      "name": "DemoSearchAlertsTool",
      "parameters": {}
    }
  ]
}

----------------------------------------

TITLE: Custom Analyzer with Keyword Marker Configuration in OpenSearch
DESCRIPTION: Advanced example showing how to create a custom English analyzer with stem exclusion using the keyword_marker token filter.

LANGUAGE: json
CODE:
PUT index_with_keyword_marker_analyzer
{
  "settings": {
    "analysis": {
      "filter": {
        "protected_keywords_filter": {
          "type": "keyword_marker",
          "keywords": ["Apple", "OpenSearch"]
        }
      },
      "analyzer": {
        "custom_english_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "protected_keywords_filter",
            "english_stemmer"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Getting Query Group Endpoint
DESCRIPTION: GET endpoints for retrieving query group information, either for all groups or a specific group by name.

LANGUAGE: json
CODE:
GET /_wlm/query_group
GET /_wlm/query_group/{name}

----------------------------------------

TITLE: Configuring Search Telemetry in OpenSearch Dashboards YAML
DESCRIPTION: Example configuration showing how to enable search telemetry in the OpenSearch Dashboards YAML configuration file. The setting data.search.usageTelemetry.enabled controls whether search usage telemetry is collected.

LANGUAGE: json
CODE:
# Set the value of this setting to false to suppress 
# search usage telemetry to reduce the load of the OpenSearch cluster.
 data.search.usageTelemetry.enabled: true

----------------------------------------

TITLE: Creating an Index with Custom N-gram Difference in OpenSearch
DESCRIPTION: This example demonstrates how to create an index with a custom 'index.max_ngram_diff' setting. It allows for a larger difference between min_gram and max_gram (2 instead of the default 1) and configures an N-gram tokenizer with min_gram 3 and max_gram 5.

LANGUAGE: json
CODE:
PUT /my-index
{
  "settings": {
    "index.max_ngram_diff": 2, 
    "analysis": {
      "tokenizer": {
        "my_ngram_tokenizer": {
          "type": "ngram",
          "min_gram": 3,
          "max_gram": 5,
          "token_chars": ["letter", "digit"]
        }
      },
      "analyzer": {
        "my_ngram_analyzer": {
          "type": "custom",
          "tokenizer": "my_ngram_tokenizer"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Parsing User Agent Strings in Logstash
DESCRIPTION: Shows how to use the 'useragent' filter plugin to parse user agent strings and add detailed browser and OS information to the event.

LANGUAGE: yaml
CODE:
useragent {
  source => "agent"
  target => "ua"
}

----------------------------------------

TITLE: Downloading and Importing OpenSearch Map Tiles
DESCRIPTION: This Docker command downloads and imports the OpenSearch-provided map tiles set into the created volume.

LANGUAGE: bash
CODE:
docker run \
    -e DOWNLOAD_TILES=https://maps.opensearch.org/offline/planet-osm-default-z0-z8.tar.gz \
    -v tiles-data:/usr/src/app/public/tiles/data/ \
    opensearch/opensearch-maps-server \
    import

----------------------------------------

TITLE: Processing Timestamps with date Processor in YAML
DESCRIPTION: This example demonstrates how to use the date processor to parse and convert timestamp formats, including generating timestamps for incoming events and setting timezones.

LANGUAGE: yaml
CODE:
...
  processor:          
    - date:
        match:
          - key: timestamp
            patterns: ["dd/MMM/yyyy:HH:mm:ss"] 
        destination: "@timestamp"
        source_timezone: "America/Los_Angeles"
        destination_timezone: "America/Chicago"
        locale: "en_US"
...
  processor:
    - date:
        from_time_received: true
        destination: "@timestamp"
...

----------------------------------------

TITLE: Token Generation Response from Classic Tokenizer in OpenSearch
DESCRIPTION: This snippet shows the response from the _analyze API, demonstrating how the Classic tokenizer breaks down the input text into tokens. It includes details like token value, position, and type for each generated token.

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "For",
      "start_offset": 0,
      "end_offset": 3,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "product",
      "start_offset": 4,
      "end_offset": 11,
      "type": "<ALPHANUM>",
      "position": 1
    },
    {
      "token": "AB3423",
      "start_offset": 12,
      "end_offset": 18,
      "type": "<ALPHANUM>",
      "position": 2
    },
    {
      "token": "visit",
      "start_offset": 20,
      "end_offset": 25,
      "type": "<ALPHANUM>",
      "position": 3
    },
    {
      "token": "X&Y",
      "start_offset": 26,
      "end_offset": 29,
      "type": "<COMPANY>",
      "position": 4
    },
    {
      "token": "at",
      "start_offset": 30,
      "end_offset": 32,
      "type": "<ALPHANUM>",
      "position": 5
    },
    {
      "token": "example.com",
      "start_offset": 33,
      "end_offset": 44,
      "type": "<HOST>",
      "position": 6
    },
    {
      "token": "email",
      "start_offset": 46,
      "end_offset": 51,
      "type": "<ALPHANUM>",
      "position": 7
    },
    {
      "token": "info@example.com",
      "start_offset": 52,
      "end_offset": 68,
      "type": "<EMAIL>",
      "position": 8
    },
    {
      "token": "or",
      "start_offset": 70,
      "end_offset": 72,
      "type": "<ALPHANUM>",
      "position": 9
    },
    {
      "token": "call",
      "start_offset": 73,
      "end_offset": 77,
      "type": "<ALPHANUM>",
      "position": 10
    },
    {
      "token": "the",
      "start_offset": 78,
      "end_offset": 81,
      "type": "<ALPHANUM>",
      "position": 11
    },
    {
      "token": "operator's",
      "start_offset": 82,
      "end_offset": 92,
      "type": "<APOSTROPHE>",
      "position": 12
    },
    {
      "token": "phone",
      "start_offset": 93,
      "end_offset": 98,
      "type": "<ALPHANUM>",
      "position": 13
    },
    {
      "token": "number",
      "start_offset": 99,
      "end_offset": 105,
      "type": "<ALPHANUM>",
      "position": 14
    },
    {
      "token": "1-800-555-1234",
      "start_offset": 106,
      "end_offset": 120,
      "type": "<NUM>",
      "position": 15
    },
    {
      "token": "P.S.",
      "start_offset": 122,
      "end_offset": 126,
      "type": "<ACRONYM>",
      "position": 16
    },
    {
      "token": "",
      "start_offset": 127,
      "end_offset": 128,
      "type": "<CJ>",
      "position": 17
    },
    {
      "token": "",
      "start_offset": 128,
      "end_offset": 129,
      "type": "<CJ>",
      "position": 18
    }
  ]
}

----------------------------------------

TITLE: Indexing a point document in OpenSearch
DESCRIPTION: Indexes a document with a point location into the 'testindex' index.

LANGUAGE: json
CODE:
PUT testindex/_doc/1
{
  "location": {
    "type": "point",
    "coordinates": [ 73.0515, 41.5582 ]
  }
}

----------------------------------------

TITLE: Handling NULL Values in ORDER BY Clause in OpenSearch SQL
DESCRIPTION: Example of using ORDER BY with IS NOT NULL to control the positioning of NULL or missing field values in the result set.

LANGUAGE: sql
CODE:
SELECT employer
FROM accounts
ORDER BY employer IS NOT NULL

----------------------------------------

TITLE: Analyzing Text with Custom Fingerprint Analyzer in OpenSearch
DESCRIPTION: This snippet shows how to use the _analyze API to examine the tokens generated by the custom fingerprint analyzer for a given text input.

LANGUAGE: json
CODE:
POST /my_custom_fingerprint_index/_analyze
{
  "analyzer": "my_custom_fingerprint_analyzer",
  "text": "The slow turtle swims over to the dog"
}

----------------------------------------

TITLE: Creating an Index with Keyword Analyzer in OpenSearch
DESCRIPTION: This snippet demonstrates how to create an index named 'my_keyword_index' with a keyword analyzer applied to a specific field. The keyword analyzer treats the entire input as a single token without breaking it into individual tokens.

LANGUAGE: json
CODE:
PUT /my_keyword_index
{
  "mappings": {
    "properties": {
      "my_field": {
        "type": "text",
        "analyzer": "keyword"
      }
    }
  }
}

----------------------------------------

TITLE: Ingesting Document with Rename Pipeline in OpenSearch
DESCRIPTION: Example of ingesting a document using the rename pipeline to transform field structure.

LANGUAGE: json
CODE:
PUT testindex1/_doc/1?pipeline=rename_field
{
  "message": {
    "type": "nginx",
    "content": "192.168.1.10 - - [03/Nov/2023:15:20:45 +0000] \"POST /login HTTP/1.1\" 200 3456"
  }
}

----------------------------------------

TITLE: Acknowledging Security Alerts
DESCRIPTION: POST endpoint to acknowledge one or more security alerts by their IDs. Returns the list of successfully acknowledged alerts along with any failed or missing alerts.

LANGUAGE: json
CODE:
POST /_plugins/_security_analytics/detectors/<detector_id>/_acknowledge/alerts\n\n{\"alerts\":[\"4dc7f5a9-2c82-4786-81ca-433a209d5205\"]}

----------------------------------------

TITLE: Upgrading OpenSearch Dashboards
DESCRIPTION: Commands to upgrade the OpenSearch Dashboards container from version 1.3.7 to 2.5.0.

LANGUAGE: bash
CODE:
docker stop os-dashboards-01 && docker rm os-dashboards-01

LANGUAGE: bash
CODE:
docker run -d \
   -p 5601:5601 --expose 5601 \
   -v ~/deploy/opensearch_dashboards.yml:/usr/share/opensearch-dashboards/config/opensearch_dashboards.yml \
   -v ~/deploy/root-ca.pem:/usr/share/opensearch-dashboards/config/root-ca.pem \
   -v ~/deploy/os-dashboards-01.pem:/usr/share/opensearch-dashboards/config/os-dashboards-01.pem \
   -v ~/deploy/os-dashboards-01-key.pem:/usr/share/opensearch-dashboards/config/os-dashboards-01-key.pem \
   --network opensearch-dev-net \
   --ip 172.20.0.10 \
   --name os-dashboards-01 \
   opensearchproject/opensearch-dashboards:2.5.0

----------------------------------------

TITLE: Assuming IAM Role for Temporary Credentials
DESCRIPTION: This Bash command assumes an IAM role to obtain temporary credentials for creating a connector.

LANGUAGE: bash
CODE:
aws sts assume-role --role-arn your_iam_role_arn_created_in_step2.1 --role-session-name your_session_name

----------------------------------------

TITLE: Querying Nested Fields in OpenSearch
DESCRIPTION: This snippet demonstrates how to query nested fields using the nested query, which maintains the relationships between fields in nested objects.

LANGUAGE: json
CODE:
GET testindex1/_search
{
  "query": {
    "nested": {
      "path": "patients",
      "query": {
        "bool": {
          "should": [
            {
              "term": {
                "patients.smoker": true
              }
            },
            {
              "range": {
                "patients.age": {
                  "gte": 75
                }
              }
            }
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Updating Credentials for a Connector Linked to a Specific Model
DESCRIPTION: Example request to update the credentials for a connector that is linked to a specific model without undeploying the model.

LANGUAGE: json
CODE:
PUT /_plugins/_ml/models/<model_id>
{
  "connectors": {
    "credential": {
      "openAI_key": "YOUR NEW OPENAI KEY"
    }
  }
}

----------------------------------------

TITLE: Importing a Dangling Index in OpenSearch
DESCRIPTION: This endpoint imports a specific dangling index into the OpenSearch cluster. It requires the index UUID as a path parameter and the accept_data_loss query parameter set to true.

LANGUAGE: json
CODE:
POST /_dangling/<index-uuid>

----------------------------------------

TITLE: Executing a Flow Agent with SearchAnomalyResultsTool in OpenSearch
DESCRIPTION: This snippet shows how to execute a previously registered flow agent that uses the SearchAnomalyResultsTool. It includes a natural language question as a parameter.

LANGUAGE: json
CODE:
POST /_plugins/_ml/agents/HuJZYo0B9RaBCvhuUlpy/_execute
{
  "parameters": {
    "question": "Do I have any anomalies?"
  }
}

----------------------------------------

TITLE: Delete Agent Endpoint Definition
DESCRIPTION: The DELETE endpoint structure for removing an ML agent from OpenSearch.

LANGUAGE: json
CODE:
DELETE /_plugins/_ml/agents/<agent_id>

----------------------------------------

TITLE: Analyzing Text with WordNet Synonym Graph Analyzer
DESCRIPTION: This example shows how to use the _analyze API to examine the tokens generated by the custom synonym_graph analyzer using WordNet format for a given text input.

LANGUAGE: json
CODE:
GET /my-wordnet-index/_analyze
{
  "analyzer": "my_synonym_graph_analyzer",
  "text": "I just bought a sports car and it is a fast car."
}

----------------------------------------

TITLE: Running OpenSearch Benchmark in Docker Container
DESCRIPTION: Launches an OpenSearch Benchmark Docker container and displays help information.

LANGUAGE: bash
CODE:
docker run opensearchproject/opensearch-benchmark -h

----------------------------------------

TITLE: Configuring Stem Exclusion for Dutch Analyzer in OpenSearch
DESCRIPTION: This snippet shows how to create an index with a Dutch analyzer that includes stem exclusion for specific words.

LANGUAGE: json
CODE:
PUT index_with_stem_exclusion_dutch_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "stem_exclusion_dutch_analyzer": {
          "type": "dutch",
          "stem_exclusion": ["autoriteit", "goedkeuring"]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Basic Index Stats Query
DESCRIPTION: Retrieves stats for a single index

LANGUAGE: json
CODE:
GET /testindex/_stats

----------------------------------------

TITLE: Configuring OpenSearch Node for Searchable Snapshots
DESCRIPTION: YAML configuration for setting up a node with search role and cache size for searchable snapshots in opensearch.yml file.

LANGUAGE: yaml
CODE:
node.name: snapshots-node
node.roles: [ search ]
node.search.cache.size: 50gb

----------------------------------------

TITLE: Using LIMIT Clause in OpenSearch SQL
DESCRIPTION: Example of using the LIMIT clause to restrict the number of results returned in OpenSearch SQL.

LANGUAGE: sql
CODE:
SELECT account_number
FROM accounts
ORDER BY account_number LIMIT 1

----------------------------------------

TITLE: Registering Anthropic Claude 3.5 Model
DESCRIPTION: Registers the Anthropic Claude 3.5 model using the previously created connector ID.

LANGUAGE: JSON
CODE:
POST /_plugins/_ml/models/_register?deploy=true
{
    "name": "Bedrock Claude3.5 model",
    "description": "Bedrock Claude3.5 model",
    "function_name": "remote",
    "connector_id": "your_connector_id"
}

----------------------------------------

TITLE: Cluster-wide Document Count
DESCRIPTION: Request to get the total document count across all indices in the cluster.

LANGUAGE: json
CODE:
GET _count

----------------------------------------

TITLE: Indexing Document with Title and Body
DESCRIPTION: Example of indexing a document about 16th-century sonnets with title and body fields.

LANGUAGE: json
CODE:
PUT testindex1/_doc/2
{
  "title": "Sonnets of the 16th Century",
  "body": "The poems written by various 16-th century poets"
}

----------------------------------------

TITLE: Clear Cache API Response in OpenSearch
DESCRIPTION: Example response from the Clear Cache API in OpenSearch, showing the number of shards affected by the operation.

LANGUAGE: json
CODE:
{
  "_shards" : {
    "total" : 4,
    "successful" : 2,
    "failed" : 0
  }
}

----------------------------------------

TITLE: Get Mappings View API Request/Response
DESCRIPTION: API endpoint to retrieve a view of fields contained in a log source index. Takes index_name and rule_topic as parameters to identify the target index and log type.

LANGUAGE: json
CODE:
GET /_plugins/_security_analytics/mappings/view

{
   "index_name": "windows",
   "rule_topic": "windows"
}

LANGUAGE: json
CODE:
{
    "properties": {
        "windows-event_data-CommandLine": {
            "path": "CommandLine",
            "type": "alias"
        },
        "event_uid": {
            "path": "EventID",
            "type": "alias"
        }
    },
    "unmapped_index_fields": [
        "windows-event_data-CommandLine",
        "unmapped_HiveName",
        "src_ip",
        "sha1",
        "processPath",
        "CallerProcessName",
        "CallTrace",
        "AuthenticationPackageName",
        "AuditSourceName",
        "AuditPolicyChanges",
        "AttributeValue",
        "AttributeLDAPDisplayName",
        "ApplicationPath",
        "Application",
        "AllowedToDelegateTo",
        "Address",
        "Action",
        "AccountType",
        "AccountName",
        "Accesses",
        "AccessMask",
        "AccessList"
    ]
}

----------------------------------------

TITLE: Flow Agent Registration Response - JSON
DESCRIPTION: Response containing the new agent ID after successful flow agent registration.

LANGUAGE: json
CODE:
{
  "agent_id": "EQyyZ40BT2tRrkdmhT7_"
}

----------------------------------------

TITLE: Installing Phonetic Analysis Plugin in OpenSearch
DESCRIPTION: Command to install the analysis-phonetic plugin in OpenSearch, which is required to use the phonetic token filter.

LANGUAGE: bash
CODE:
./bin/opensearch-plugin install analysis-phonetic

----------------------------------------

TITLE: Configuring Advanced Repository Settings in JSON
DESCRIPTION: Example JSON configuration for advanced repository settings when creating a snapshot repository. It includes options for chunk size, compression, and bandwidth limits.

LANGUAGE: json
CODE:
{
    "chunk_size": null,
    "compress": false,
    "max_restore_bytes_per_sec": "40m",
    "max_snapshot_bytes_per_sec": "40m",
    "readonly": false
}

----------------------------------------

TITLE: Sample Response from CAT Allocation API
DESCRIPTION: This example response shows allocation information for two nodes, including shard count and disk usage statistics.

LANGUAGE: json
CODE:
shards | disk.indices | disk.used | disk.avail | disk.total | disk.percent host | ip          | node
  8    |   989.4kb    |   25.9gb  |   32.4gb   |   58.4gb   |   44 172.18.0.4   | 172.18.0.4  | odfe-node1
  8    |   962.4kb    |   25.9gb  |   32.4gb   |   58.4gb   |   44 172.18.0.3   | 172.18.0.3  | odfe-node2

----------------------------------------

TITLE: Example Response for Agent Search in OpenSearch
DESCRIPTION: This is a sample response from the agent search API. It includes metadata about the search and details of a matched agent, including its creation time, name, description, type, and associated tools.

LANGUAGE: json
CODE:
{
  "took": 2,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 6,
      "relation": "eq"
    },
    "max_score": 0.15019803,
    "hits": [
      {
        "_index": ".plugins-ml-agent",
        "_id": "8HXlkI0BfUsSoeNTP_0P",
        "_version": 1,
        "_seq_no": 17,
        "_primary_term": 2,
        "_score": 0.13904166,
        "_source": {
          "created_time": 1707532959502,
          "last_updated_time": 1707532959502,
          "name": "Test_Agent_For_RagTool",
          "description": "this is a test flow agent",
          "type": "flow",
          "tools": [
            {
              "description": "A description of the tool",
              "include_output_in_agent_response": false,
              "type": "RAGTool",
              "parameters": {
                "inference_model_id": "gnDIbI0BfUsSoeNT_jAw",
                "embedding_model_id": "Yg7HZo0B9ggZeh2gYjtu_2",
                "input": "${parameters.question}",
                "source_field": "[\"text\"]",
                "embedding_field": "embedding",
                "index": "my_test_data",
                "query_type": "neural",
                "prompt": "\n\nH:You are a professional data analyst. You will always answer question based on the given context first. If the answer is not directly shown in the context, you will analyze the data and find the answer. If you don't know the answer, just say don't know. \n\n Context:\n${parameters.output_field}\n\nH:${parameters.question}\n\nA:"
              }
            }
          ]
        }
      }
    ]
  }
}

----------------------------------------

TITLE: GET Request for Retrieving Model Information in OpenSearch
DESCRIPTION: Demonstrates the endpoint structure for retrieving model information using the model_id. This GET request is part of the ML Commons API in OpenSearch.

LANGUAGE: json
CODE:
GET /_plugins/_ml/models/<model_id>

----------------------------------------

TITLE: Defining Indices in OpenSearch Benchmark Workload JSON
DESCRIPTION: This JSON snippet demonstrates how to define indices in an OpenSearch Benchmark workload configuration. It shows the structure for specifying an index name and its corresponding index definition file.

LANGUAGE: json
CODE:
"indices": [
    {
      "name": "geonames",
      "body": "geonames-index.json",
    }
]

----------------------------------------

TITLE: Checking Snapshot Status in OpenSearch Migration
DESCRIPTION: Command to check the progress of a snapshot creation, with a deep check option for detailed status.

LANGUAGE: bash
CODE:
console snapshot status --deep-check

----------------------------------------

TITLE: Creating Index Mapping with Unsigned Long Field
DESCRIPTION: Demonstrates how to create an index mapping with an unsigned_long field type that can store 64-bit unsigned integers.

LANGUAGE: json
CODE:
PUT testindex 
{
  "mappings" : {
    "properties" :  {
      "counter" : {
        "type" : "unsigned_long"
      }
    }
  }
}

----------------------------------------

TITLE: Sample E-commerce Data Structure
DESCRIPTION: JSON array containing sample e-commerce product data with item descriptions and prices.

LANGUAGE: json
CODE:
[
    {
        "item_text": "red shoes",
        "item_price": 100
    }
    {
        "item_text": "blue sneakers",
        "item_price": 50
    }
    {
        "item_text": "purple high heels",
        "item_price": 150
    }
    {
        "item_text": "pair of jordans",
        "item_price": 250
    }
    {
        "item_text": "navy plaid shirt",
        "item_price": 35
    }
]

----------------------------------------

TITLE: OpenSearch Domain Access Policy
DESCRIPTION: Example IAM policy showing minimum required permissions for Amazon OpenSearch Service domain access

LANGUAGE: json
CODE:
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "AWS": "arn:aws:iam::<AccountId>:user/data-prepper-user"
      },
      "Action": "es:ESHttp*",
      "Resource": [
        "arn:aws:es:us-east-1:<AccountId>:domain/<domain-name>/otel-v1*",
        "arn:aws:es:us-east-1:<AccountId>:domain/<domain-name>/_template/otel-v1*",
        "arn:aws:es:us-east-1:<AccountId>:domain/<domain-name>/_plugins/_ism/policies/raw-span-policy",
        "arn:aws:es:us-east-1:<AccountId>:domain/<domain-name>/_alias/otel-v1*",
        "arn:aws:es:us-east-1:<AccountId>:domain/<domain-name>/_alias/_bulk"
      ]
    },
    {
      "Effect": "Allow", 
      "Principal": {
        "AWS": "arn:aws:iam::<AccountId>:user/data-prepper-user"
      },
      "Action": "es:ESHttpGet",
      "Resource": "arn:aws:es:us-east-1:<AccountId>:domain/<domain-name>/_cluster/settings"
    }
  ]
}

----------------------------------------

TITLE: Creating Alert Message Template with Mustache in OpenSearch
DESCRIPTION: This snippet shows how to create a message template for alert notifications using Mustache syntax in OpenSearch. It includes placeholders for monitor name, trigger details, and time period information.

LANGUAGE: mustache
CODE:
Monitor {{ctx.monitor.name}} just entered an alert state. Please investigate the issue.
- Trigger: {{ctx.trigger.name}}
- Severity: {{ctx.trigger.severity}}
- Period start: {{ctx.periodStart}}
- Period end: {{ctx.periodEnd}}

----------------------------------------

TITLE: Analyzing Phone Numbers with Phone Analyzer
DESCRIPTION: Example requests demonstrating phone number analysis with the phone analyzer

LANGUAGE: json
CODE:
{
  "analyzer" : "phone-ch",
  "text" : "+41 60 555 12 34"
}

LANGUAGE: json
CODE:
{
  "analyzer" : "phone",
  "text" : "+41 60 555 12 34"
}

LANGUAGE: json
CODE:
{
  "analyzer" : "phone-ch",
  "text" : "060 555 12 34"
}

----------------------------------------

TITLE: Querying Performance Analyzer Metrics
DESCRIPTION: Example API query to retrieve performance metrics from the Performance Analyzer.

LANGUAGE: bash
CODE:
GET localhost:9600/_plugins/_performanceanalyzer/metrics/units

----------------------------------------

TITLE: Sorting on date_nanos Fields in OpenSearch
DESCRIPTION: This snippet demonstrates how to sort search results based on a date_nanos field in ascending order.

LANGUAGE: json
CODE:
GET testindex/_search
{
  "sort": { 
    "date": "asc"
  } 
}

----------------------------------------

TITLE: Installing Reporting CLI from Archive
DESCRIPTION: Command to install the OpenSearch Reporting CLI tool from a downloaded .tar archive using npm global installation.

LANGUAGE: bash
CODE:
npm install -g opensearch-reporting-cli-1.0.0.tgz

----------------------------------------

TITLE: Checking Aggregation Value in Groovy
DESCRIPTION: This Groovy script returns true if the avg_cpu aggregation exceeds 90.

LANGUAGE: groovy
CODE:
if (ctx.results[0].aggregations.avg_cpu.value > 90) {
  return true;
}

----------------------------------------

TITLE: Registering a pretrained language model
DESCRIPTION: Registers the DistilBERT model for generating text embeddings.

LANGUAGE: json
CODE:
POST /_plugins/_ml/models/_register
{
  "name": "huggingface/sentence-transformers/msmarco-distilbert-base-tas-b",
  "version": "1.0.1",
  "model_format": "TORCH_SCRIPT"
}

----------------------------------------

TITLE: Configuring Circuit Breaker in OpenSearch JavaScript Client
DESCRIPTION: JavaScript code demonstrating how to enable and configure the memory circuit breaker when instantiating the OpenSearch client.

LANGUAGE: javascript
CODE:
var client = new Client({
  memoryCircuitBreaker: {
    enabled: true,
    maxPercentage: 0.8,
  },
});

----------------------------------------

TITLE: Delete Workspace API Endpoint
DESCRIPTION: API endpoint to remove an existing workspace by its ID.

LANGUAGE: json
CODE:
DELETE <osd host>:<port>/api/workspaces/<id>

----------------------------------------

TITLE: Querying Local Node Stats for Shard Indexing Pressure in OpenSearch
DESCRIPTION: This request retrieves node-level and shard-level stats for indexing request rejections from the local node. It uses the GET method to access the _nodes/_local/stats/shard_indexing_pressure endpoint.

LANGUAGE: json
CODE:
GET _nodes/_local/stats/shard_indexing_pressure

----------------------------------------

TITLE: Searching Threat Intelligence Sources
DESCRIPTION: Searches for threat intelligence sources using query DSL. Example shows filtering by source type.

LANGUAGE: json
CODE:
POST /_plugins/_security_analytics/threat_intel/sources/_search
{
    "query": {
        "match": {
            "source_config.type": "S3_CUSTOM"
        }
    }
}

----------------------------------------

TITLE: Setting NODE_HOME Environment Variable on Windows
DESCRIPTION: Commands to set the NODE_HOME environment variable on Windows systems using either Command Prompt or PowerShell

LANGUAGE: powershell
CODE:
set "NODE_HOME=C:\Program Files\nodejs"
# or using PowerShell:
$Env:NODE_HOME = 'C:\Program Files\nodejs'

----------------------------------------

TITLE: Sample CSV Processor Output in JSON
DESCRIPTION: Example output showing how the CSV processor transforms input data into a structured JSON format with mapped column names.

LANGUAGE: json
CODE:
{"message": "1,2,3", "col1": "1", "col2": "2", "column3": "3"}

----------------------------------------

TITLE: Analyzing Text with Roman Numeral Mapping in OpenSearch
DESCRIPTION: This snippet demonstrates how to use a mapping character filter to convert Roman numerals to Arabic numerals in OpenSearch. It uses the keyword tokenizer and applies the mapping filter to replace numerals I through V.

LANGUAGE: json
CODE:
GET /_analyze
{
  "tokenizer": "keyword",
  "char_filter": [
    {
      "type": "mapping",
      "mappings": [
        "I => 1",
        "II => 2",
        "III => 3",
        "IV => 4",
        "V => 5"
      ]
    }
  ],
  "text": "I have III apples and IV oranges"
}

----------------------------------------

TITLE: Analyzing Text with Roman Numeral Mapping in OpenSearch
DESCRIPTION: This snippet demonstrates how to use a mapping character filter to convert Roman numerals to Arabic numerals in OpenSearch. It uses the keyword tokenizer and applies the mapping filter to replace numerals I through V.

LANGUAGE: json
CODE:
GET /_analyze
{
  "tokenizer": "keyword",
  "char_filter": [
    {
      "type": "mapping",
      "mappings": [
        "I => 1",
        "II => 2",
        "III => 3",
        "IV => 4",
        "V => 5"
      ]
    }
  ],
  "text": "I have III apples and IV oranges"
}

----------------------------------------

TITLE: Defining Time Type in SQL for OpenSearch
DESCRIPTION: Specifies the syntax and range for the 'time' type in SQL for OpenSearch. The time type represents clock time without date or time zone information.

LANGUAGE: sql
CODE:
time | hh:mm:ss[.fraction] | 00:00:00.0000000000 to 23:59:59.9999999999

----------------------------------------

TITLE: Using Term Suggester in OpenSearch
DESCRIPTION: Example of using the term suggester to get suggestions for a misspelled search term. It specifies the input text and the field from which to get suggestions.

LANGUAGE: json
CODE:
GET books/_search
{
  "suggest": {
    "spell-check": {
      "text": "patern",
      "term": {
        "field": "title"
      }
    }
  }
}

----------------------------------------

TITLE: Deleting a Document
DESCRIPTION: Use the client's delete() method to remove a specific document from an index.

LANGUAGE: python
CODE:
response = client.delete(
    index = 'my-dsl-index',
    id = '1'
)

----------------------------------------

TITLE: Creating Mapping with IP Address Field in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a mapping with an IP address field in OpenSearch. It defines a property named 'ip_address' of type 'ip'.

LANGUAGE: json
CODE:
PUT testindex 
{
  "mappings" : {
    "properties" :  {
      "ip_address" : {
        "type" : "ip"
      }
    }
  }
}

----------------------------------------

TITLE: Script Processor Basic Configuration
DESCRIPTION: Basic JSON structure for configuring a script processor in OpenSearch. Shows the required and optional parameters including source, language, and params.

LANGUAGE: json
CODE:
{
  "processor": {
    "script": {
      "source": "<script_source>",
      "lang": "<script_language>",
      "params": {
        "<param_name>": "<param_value>"
      }
    }
  }
}

----------------------------------------

TITLE: Searching Flat Object Fields in OpenSearch
DESCRIPTION: These snippets demonstrate various ways to search for leaf values in flat object fields, including match, prefix, and range queries.

LANGUAGE: json
CODE:
GET /test-index/_search
{
  "query": {
    "match": {"issue": "bug"}
  }
}

LANGUAGE: json
CODE:
GET /test-index/_search
{
  "query": {
    "match": {"issue.labels.category.level": "bug"}
  }
}

LANGUAGE: json
CODE:
GET /test-index/_search
{
  "query": {
    "prefix": {"issue.labels.version": "2."}
  }
}

LANGUAGE: json
CODE:
GET /test-index/_search
{
  "query": {
    "range": {
      "issue": {
        "gte": "2.0",
        "lte": "2.1"
      }
    }
  }
}

----------------------------------------

TITLE: Registering a Flow Agent with SearchAnomalyResultsTool in OpenSearch
DESCRIPTION: This snippet demonstrates how to register a flow agent that includes the SearchAnomalyResultsTool. It specifies the agent type, description, memory type, and tool configuration.

LANGUAGE: json
CODE:
POST /_plugins/_ml/agents/_register
{
  "name": "Test_Agent_For_Search_Anomaly_Results_Tool",
  "type": "flow",
  "description": "this is a test agent for the SearchAnomalyResultsTool",
  "memory": {
    "type": "demo"
  },
  "tools": [
    {
      "type": "SearchAnomalyResultsTool",
      "name": "DemoSearchAnomalyResultsTool",
      "parameters": {}
    }
  ]
}

----------------------------------------

TITLE: Requesting PNG Report with Basic Authentication
DESCRIPTION: Command to request a report with basic authentication in PNG format using the Reporting CLI

LANGUAGE: bash
CODE:
opensearch-reporting-cli --url https://localhost:5601/app/dashboards#/view/7adfa750-4c81-11e8-b3d7-01146121b73d --format png --auth basic --credentials admin:<custom-admin-password>

----------------------------------------

TITLE: Creating Function Score Query Feature for Movie Ratings
DESCRIPTION: Shows how to implement a function score query feature to retrieve average movie ratings from the vote_average field.

LANGUAGE: json
CODE:
{
    "query": {
        "function_score": {
            "functions": {
                "field": "vote_average"
            },
            "query": {
                "match_all": {}
            }
        }
    }
}

----------------------------------------

TITLE: Hot Threads Response Example 1
DESCRIPTION: Sample response showing CPU usage and stack traces for a single node's hot threads.

LANGUAGE: bash
CODE:
::: {opensearch}{F-ByTQzVQ3GQeYzQJArJGQ}{GxbcLdCATPWggOuQHJAoCw}{127.0.0.1}{127.0.0.1:9300}{dimr}{shard_indexing_pressure_enabled=true}
   Hot threads at 2022-09-29T19:46:44.533Z, interval=500ms, busiestThreads=3, ignoreIdleThreads=true:
   
    0.1% (455.5micros out of 500ms) cpu usage by thread 'ScheduledMetricCollectorsExecutor'
     10/10 snapshots sharing following 2 elements
       java.base@17.0.4/java.lang.Thread.sleep(Native Method)
       org.opensearch.performanceanalyzer.collectors.ScheduledMetricCollectorsExecutor.run(ScheduledMetricCollectorsExecutor.java:100)

----------------------------------------

TITLE: Searching for Model Chunks by Model ID in OpenSearch
DESCRIPTION: This example shows how to search for all chunks of a specific model using its ID. It uses a bool query with a filter clause and sorts the results by chunk number in ascending order.

LANGUAGE: json
CODE:
GET /_plugins/_ml/models/_search
{
  "query": {
    "bool": {
      "filter": [
        {
          "term": {
            "model_id": "9r9w9YwBjWKCe6KgyGST"
          }
        }
      ]
    }
  },
  "sort": [
    {
      "chunk_number": {
        "order": "asc"
      }
    }
  ]
}

----------------------------------------

TITLE: Example Response for Retrieving Connector in OpenSearch ML Commons
DESCRIPTION: This is an example response when retrieving a connector. It includes details such as name, version, description, protocol, parameters, and actions associated with the connector.

LANGUAGE: json
CODE:
{
  "name" : "BedRock Claude-Instant v1",
  "version" : "1",
  "description" : "Bedrock connector for Claude Instant testing",
  "protocol" : "aws_sigv4",
  "parameters" : {
    "endpoint" : "bedrock.us-east-1.amazonaws.com",
    "content_type" : "application/json",
    "auth" : "Sig_V4",
    "service_name" : "bedrock",
    "region" : "us-east-1",
    "anthropic_version" : "bedrock-2023-05-31"
  },
  "actions" : [
    {
      "action_type" : "PREDICT",
      "method" : "POST",
      "url" : "https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-instant-v1/invoke",
      "headers" : {
        "x-amz-content-sha256" : "required",
        "content-type" : "application/json"
      },
      "request_body" : "{\"prompt\":\"${parameters.prompt}\", \"max_tokens_to_sample\":${parameters.max_tokens_to_sample}, \"temperature\":${parameters.temperature},  \"anthropic_version\":\"${parameters.anthropic_version}\" }"
    }
  ]
}

----------------------------------------

TITLE: Registering Text Embedding Model
DESCRIPTION: API request to register and deploy the Hugging Face sentence transformer model for text embeddings.

LANGUAGE: json
CODE:
{
  "name": "huggingface/sentence-transformers/all-MiniLM-L12-v2",
  "version": "1.0.1",
  "model_format": "TORCH_SCRIPT"
}

----------------------------------------

TITLE: Basic Node Stats Query
DESCRIPTION: Simple query to retrieve all node statistics.

LANGUAGE: json
CODE:
GET _nodes/stats/

----------------------------------------

TITLE: ML Sync Job Interval
DESCRIPTION: Controls the interval for synchronizing ML model deployment status across nodes.

LANGUAGE: yaml
CODE:
plugins.ml_commons.sync_up_job_interval_in_seconds: 3

----------------------------------------

TITLE: Analyzing text with simple_pattern tokenizer in OpenSearch
DESCRIPTION: This example shows how to use the _analyze API to examine the tokens generated by the custom analyzer with the simple_pattern tokenizer. It analyzes the text 'OpenSearch-2024-10-09'.

LANGUAGE: json
CODE:
POST /my_index/_analyze
{
  "analyzer": "my_pattern_analyzer",
  "text": "OpenSearch-2024-10-09"
}

----------------------------------------

TITLE: JSON Response Format
DESCRIPTION: Example response showing index information in JSON format with next_token for pagination

LANGUAGE: json
CODE:
{"next_token":"MTcyOTE5NTQ5NjM5N3wub3BlbnNlYXJjaC1zYXAtbG9nLXR5cGVzLWNvbmZpZw==","indices":[{"health":"green","status":"open","index":"movies","uuid":"UZbpfERBQ1-3GSH2bnM3sg","pri":"1","rep":"1","docs.count":"1","docs.deleted":"0","store.size":"7.7kb","pri.store.size":"3.8kb"}]}

----------------------------------------

TITLE: Performing Disjunction Max Query
DESCRIPTION: Example of performing a dis_max query to search for documents containing 'Shakespeare poems' across title and body fields.

LANGUAGE: json
CODE:
GET testindex1/_search
{
  "query": {
    "dis_max": {
      "queries": [
        { "match": { "title": "Shakespeare poems" }},
        { "match": { "body":  "Shakespeare poems" }}
      ]
    }
  }            
}

----------------------------------------

TITLE: Starting Backfill in OpenSearch Migration Console
DESCRIPTION: This command starts an instance of the Reindex-From-Snapshot (RFS) service to begin moving documents to the target cluster, if RFS is enabled.

LANGUAGE: sh
CODE:
console backfill start

----------------------------------------

TITLE: Retrieving All Indexes Recovery Information in OpenSearch
DESCRIPTION: Example request for retrieving recovery information from all indexes with human-readable output formatting.

LANGUAGE: json
CODE:
GET /_recovery?human

----------------------------------------

TITLE: Updating Static Index Settings in OpenSearch
DESCRIPTION: This snippet demonstrates how to update static index settings, specifically the codec and compression level, for a closed index named 'testindex'.

LANGUAGE: json
CODE:
PUT /testindex/_settings
{
  "index": {
    "codec": "zstd_no_dict",
    "codec.compression_level": 3
  }
}

----------------------------------------

TITLE: Analyzing Text with Custom Analyzer in OpenSearch
DESCRIPTION: This example demonstrates how to use the _analyze API to test the custom analyzer created with the pattern_replace filter.

LANGUAGE: json
CODE:
POST /text_index/_analyze
{
  "text": "Visit us at 98765 Example St.",
  "analyzer": "number_analyzer"
}

----------------------------------------

TITLE: PIT Segments Response Example
DESCRIPTION: Example response showing the returned PIT segments information including index, shard, IP, and segment details.

LANGUAGE: json
CODE:
index  shard prirep ip            segment generation docs.count docs.deleted  size size.memory committed searchable version compound
index1 0     r      10.212.36.190 _0               0          4            0 3.8kb        1364 false     true       8.8.2   true
index1 1     p      10.212.36.190 _0               0          3            0 3.7kb        1364 false     true       8.8.2   true
index1 2     r      10.212.74.139 _0               0          2            0 3.6kb        1364 false     true       8.8.2   true

----------------------------------------

TITLE: POST Request for Creating an ML Connector in OpenSearch
DESCRIPTION: This snippet shows the endpoint for creating a standalone connector in OpenSearch ML Commons. It uses a POST request to the /_plugins/_ml/connectors/_create endpoint.

LANGUAGE: json
CODE:
POST /_plugins/_ml/connectors/_create

----------------------------------------

TITLE: SLTR Query Configuration
DESCRIPTION: Configures the SLTR query to specify which features to log and their parameters.

LANGUAGE: json
CODE:
{
    "sltr": {
        "_name": "logged_featureset",
        "featureset": "more_movie_features",
        "params": {
            "keywords": "rambo"
        }
    }
}

----------------------------------------

TITLE: Configuring Cluster Name in YAML
DESCRIPTION: Sets the cluster name in the OpenSearch configuration file.

LANGUAGE: yaml
CODE:
cluster.name: opensearch-cluster

----------------------------------------

TITLE: Memory Deletion Request Example - JSON
DESCRIPTION: Example request showing how to delete a memory using its ID.

LANGUAGE: json
CODE:
DELETE /_plugins/_ml/memory/MzcIJX8BA7mbufL6DOwl

----------------------------------------

TITLE: Retrieving Replication Rules in OpenSearch
DESCRIPTION: This curl command retrieves a list of existing replication rules configured on the cluster, including statistics about successful and failed replications.

LANGUAGE: bash
CODE:
curl -XGET -u 'admin:<custom-admin-password>' -k 'https://localhost:9200/_plugins/_replication/autofollow_stats'

----------------------------------------

TITLE: Creating an email group in OpenSearch
DESCRIPTION: Defines a new group of email recipients for alert notifications.

LANGUAGE: json
CODE:
POST _plugins/_alerting/destinations/email_groups
{
  "name": "example_email_group",
  "emails": [{
    "email": "example@email.com"
  }]
}

----------------------------------------

TITLE: Combining Events with Put All Action in JSON
DESCRIPTION: Demonstration of how the put_all action combines multiple events with the same identification keys into a single event, merging all fields.

LANGUAGE: json
CODE:
{ "sourceIp": "127.0.0.1", "destinationIp": "192.168.0.1", "status": 200 }
{ "sourceIp": "127.0.0.1", "destinationIp": "192.168.0.1", "bytes": 1000 }
{ "sourceIp": "127.0.0.1", "destinationIp": "192.168.0.1", "http_verb": "GET" }

----------------------------------------

TITLE: Analyzing Text with Custom Stop Analyzer
DESCRIPTION: Demonstrates how to analyze text using the custom stop analyzer and shows token generation.

LANGUAGE: json
CODE:
POST /my_custom_stop_analyzer_index/_analyze
{
  "analyzer": "my_custom_stop_analyzer",
  "text": "The large turtle is green and brown"
}

----------------------------------------

TITLE: Configuring Field Names Mapping in OpenSearch JSON
DESCRIPTION: This JSON snippet demonstrates how to configure the _field_names field and other properties in an OpenSearch mapping. It shows the enabled setting for _field_names and different combinations of doc_values and norms for various fields.

LANGUAGE: json
CODE:
{
    "mappings": {
       "_field_names": {
        "enabled": "true"
      },
    "properties": {
      },
      "title": {
        "type": "text",
        "doc_values": false,
        "norms": false
      },
      "description": {
        "type": "text",
        "doc_values": true,
        "norms": false
      },
      "price": {
        "type": "float",
        "doc_values": false,
        "norms": true
      }
    }
  }
}

----------------------------------------

TITLE: Creating Connector for SageMaker Cross-Encoder Model in OpenSearch
DESCRIPTION: This JSON request creates a connector in OpenSearch to interact with the SageMaker-hosted cross-encoder model. It specifies the connection details, authentication, and the predict action for the model.

LANGUAGE: json
CODE:
POST /_plugins/_ml/connectors/_create
{
  "name": "SageMaker cross-encoder model",
  "description": "Test connector for SageMaker cross-encoder hosted model",
  "version": 1,
  "protocol": "aws_sigv4",
  "credential": {
		"access_key": "<YOUR_ACCESS_KEY>",
		"secret_key": "<YOUR_SECRET_KEY>",
		"session_token": "<YOUR_SESSION_TOKEN>"
  },
  "parameters": {
    "region": "<REGION>",
    "service_name": "sagemaker"
  },
  "actions": [
    {
      "action_type": "predict",
      "method": "POST",
      "url": "<YOUR_SAGEMAKER_ENDPOINT_URL>",
      "headers": {
        "content-type": "application/json"
      },
      "request_body": "{ \"inputs\": { \"text\": \"${parameters.text}\", \"text_pair\": \"${parameters.text_pair}\" }}"
    }
  ]
}

----------------------------------------

TITLE: DELETE Operation Result Set
DESCRIPTION: JSON response showing the result of the DELETE operation, including the number of deleted documents.

LANGUAGE: json
CODE:
{
  "schema" : [
    {
      "name" : "deleted_rows",
      "type" : "long"
    }
  ],
  "total" : 1,
  "datarows" : [
    [
      3
    ]
  ],
  "size" : 1,
  "status" : 200
}

----------------------------------------

TITLE: Predicting with Linear Regression Model in OpenSearch
DESCRIPTION: Example of using a trained linear regression model to make predictions in OpenSearch.

LANGUAGE: JSON
CODE:
POST _plugins/_ml/_predict/LINEAR_REGRESSION/ROZs-38Br5eVE0lTsoD9
{
  "parameters": {
    "target": "price"
  },
  "input_data": {
    "column_metas": [
      {
        "name": "A",
        "column_type": "DOUBLE"
      },
      {
        "name": "B",
        "column_type": "DOUBLE"
      }
    ],
    "rows": [
      {
        "values": [
          {
            "column_type": "DOUBLE",
            "value": 3
          },
          {
            "column_type": "DOUBLE",
            "value": 5
          }
        ]
      }
    ]
  }
}

----------------------------------------

TITLE: Configuring Signature Version 4 Authentication for Cluster in AWS CDK
DESCRIPTION: JSON configuration snippet for setting up a cluster with AWS Signature Version 4 authentication in AWS CDK for OpenSearch Migration Assistant. Includes region and service signing name options.

LANGUAGE: json
CODE:
    "sourceCluster": {
        "endpoint": <SOURCE_CLUSTER_ENDPOINT>,
        "version": "ES 7.10",
        "auth": {
            "type": "sigv4",
            "region": "us-east-1",
            "serviceSigningName": "es"
        }
    }

----------------------------------------

TITLE: Configuring Admin Access by Backend Role in YAML
DESCRIPTION: This YAML configuration grants admin access to users with a specific backend role.

LANGUAGE: yaml
CODE:
opensearchDashboards.dashboardAdmin.groups: ["admin-role"]

----------------------------------------

TITLE: Running OpenSearch Upgrade Tool
DESCRIPTION: This bash command runs the opensearch-upgrade tool to automate some migration steps.

LANGUAGE: bash
CODE:
./bin/opensearch-upgrade

----------------------------------------

TITLE: Updating Notification Settings
DESCRIPTION: API request to update an existing notification setting with modified configuration parameters.

LANGUAGE: json
CODE:
PUT /_plugins/_im/lron/<lronID>
{
  "lron_config": {
      "task_id":"dQlcQ0hQS2mwF-AQ7icCMw:12354",
      "action_name":"indices:data/write/reindex",
      "lron_condition": {
        "success": false,
        "failure": true
      },
      "channels":[
          {"id":"channel1"},
          {"id":"channel2"}
      ]
  }
}

----------------------------------------

TITLE: Retrieving Document Processed by User Agent Pipeline in OpenSearch
DESCRIPTION: GET request to retrieve the document from 'testindex1' that was processed by the user_agent_pipeline. This shows the original user agent string and the extracted information.

LANGUAGE: json
CODE:
GET testindex1/_doc/1

----------------------------------------

TITLE: Configuring Aggregate Processor Options in YAML
DESCRIPTION: YAML configuration options for the aggregate processor, including identification keys, action, group duration, and local mode settings.

LANGUAGE: yaml
CODE:
identification_keys: ["sourceIp", "destinationIp", "port"]
action: remove_duplicates
group_duration: "180s"
local_mode: false

----------------------------------------

TITLE: Specifying Alternative Hash Algorithm in OpenSearch YAML Config
DESCRIPTION: Demonstrates how to override the default hashing algorithm for field masking in the opensearch.yml file. In this example, SHA-256 is set as the default algorithm.

LANGUAGE: yml
CODE:
plugins.security.masked_fields.algorithm.default: SHA-256

----------------------------------------

TITLE: Initializing Go Module
DESCRIPTION: Creates a new Go module for the project

LANGUAGE: go
CODE:
go mod init <mymodulename>

----------------------------------------

TITLE: Ingesting Document with Script Pipeline
DESCRIPTION: Example of ingesting a document using the script pipeline to transform the message field.

LANGUAGE: json
CODE:
{
  "message": "hello, world!"
}

----------------------------------------

TITLE: Retrieving Verbose Plugin Information
DESCRIPTION: Example request that lists all installed plugins with verbose output showing column headers.

LANGUAGE: json
CODE:
GET _cat/plugins?v

----------------------------------------

TITLE: Launching SQL CLI for OpenSearch
DESCRIPTION: Command to launch the OpenSearch SQL CLI, connecting to a local instance with default security credentials.

LANGUAGE: console
CODE:
opensearchsql https://localhost:9200 --username admin --password admin

----------------------------------------

TITLE: Retrieving All Pipelines in OpenSearch
DESCRIPTION: GET request to retrieve information about all ingest pipelines in the OpenSearch cluster.

LANGUAGE: json
CODE:
GET _ingest/pipeline/

----------------------------------------

TITLE: Search Response Example
DESCRIPTION: Shows the response format for a search query using the copy_to field, including document matches and scoring information.

LANGUAGE: json
CODE:
{
  "took": 20,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 1,
      "relation": "eq"
    },
    "max_score": 1.9061546,
    "hits": [
      {
        "_index": "my-products-index",
        "_id": "1",
        "_score": 1.9061546,
        "_source": {
          "name": "Wireless Headphones",
          "description": "High-quality wireless headphones with noise cancellation",
          "price": 99.99
        }
      }
    ]
  }
}

----------------------------------------

TITLE: Configuring Uncompressed Logs with Scan
DESCRIPTION: YAML configuration for scanning objects with uncompressed newline-delimited logs using the S3 scan functionality.

LANGUAGE: yaml
CODE:
source:
  s3:
    codec:
      newline:
    compression: none
    aws:
      region: "us-east-1"
      sts_role_arn: "arn:aws:iam::123456789012:role/Data-Prepper"
    scan:
      start_time: 2023-01-01T00:00:00
      range: "P365D"
      buckets:
        - bucket:
            name: "s3-scan-test"
            filter:
              exclude_suffix:
                - "*.log"

----------------------------------------

TITLE: Generating PNG Report with OpenSearch CLI
DESCRIPTION: Command to generate a PNG visualization report using basic authentication and Amazon SES for email delivery. Requires admin credentials and email addresses for sender and recipient.

LANGUAGE: bash
CODE:
opensearch-reporting-cli -u https://localhost:5601/app/dashboards#/view/7adfa750-4c81-11e8-b3d7-01146121b73d -a basic -c admin:Test@1234 -e ses -s <email address>  -r <email address> -f png

----------------------------------------

TITLE: Routing Different Types to Separate Indexes Configuration
DESCRIPTION: Configuration example showing how to split different types from a single index into separate indexes.

LANGUAGE: json
CODE:
[
  {
    "TypeMappingSanitizationTransformerProvider": {
      "staticMappings": {
        "activity": {
          "user": "new_users",
          "post": "new_posts"
        }
      },
      "sourceProperties": {
        "version": {
          "major": 6,
          "minor": 8
        }
      }
    }
  }
]

----------------------------------------

TITLE: Analyzing text with common_grams filter in OpenSearch
DESCRIPTION: This example shows how to use the _analyze API to examine the tokens generated by the custom analyzer with the common_grams filter. It demonstrates the effect of the filter on a sample text.

LANGUAGE: json
CODE:
GET /my_common_grams_index/_analyze
{
  "analyzer": "my_analyzer",
  "text": "A quick black cat jumps over the lazy dog in the park"
}

----------------------------------------

TITLE: Retrieving Document
DESCRIPTION: Example of retrieving a document after processing with the Set processor.

LANGUAGE: json
CODE:
GET testindex1/_doc/1

----------------------------------------

TITLE: Configuring OpenSearch Dashboards Network Interface
DESCRIPTION: Commands to edit the OpenSearch Dashboards configuration file to bind to a specific network interface and restart the service.

LANGUAGE: bash
CODE:
sudo vi /etc/opensearch-dashboards/opensearch_dashboards.yml
# Add the following line to the file:
# server.host: 0.0.0.0
sudo systemctl restart opensearch-dashboards

----------------------------------------

TITLE: Managed Index Policy Example in OpenSearch
DESCRIPTION: Example JSON structure showing a managed index policy configuration with essential fields like name, index UUID, scheduling, and policy versioning details.

LANGUAGE: json
CODE:
{
  "managed_index": {
    "name": "my_index",
    "index": "my_index",
    "index_uuid": "sOKSOfkdsoSKeofjIS",
    "enabled": true,
    "enabled_time": 1553112384,
    "last_updated_time": 1553112384,
    "schedule": {
      "interval": {
        "period": 1,
        "unit": "MINUTES",
        "start_time": 1553112384
      }
    },
    "policy_id": "log_rotation",
    "policy_version": 1,
    "policy": {...},
    "change_policy": null
  }
}

----------------------------------------

TITLE: Ingesting Data with Sparse Encoding in OpenSearch
DESCRIPTION: This snippet shows how to ingest data into the index using a bulk request. The documents will be processed by the sparse encoding pipeline before indexing.

LANGUAGE: json
CODE:
POST _bulk
{ "index" : { "_index" : "index_for_neural_sparse", "_id" : "1" } }
{ "passage_text" : "company AAA has a history of 123 years" }
{ "index" : { "_index" : "index_for_neural_sparse", "_id" : "2" } }
{ "passage_text" : "company AAA has over 7000 employees" }
{ "index" : { "_index" : "index_for_neural_sparse", "_id" : "3" } }
{ "passage_text" : "Jack and Mark established company AAA" }
{ "index" : { "_index" : "index_for_neural_sparse", "_id" : "4" } }
{ "passage_text" : "company AAA has a net profit of 13 millions in 2022" }
{ "index" : { "_index" : "index_for_neural_sparse", "_id" : "5" } }
{ "passage_text" : "company AAA focus on the large language models domain" }

----------------------------------------

TITLE: Configuring Authentication Methods in YAML
DESCRIPTION: Configure which authentication methods are available for data sources by setting their enabled status in the opensearch_dashboards.yml file.

LANGUAGE: yaml
CODE:
data_source.authTypes:
  NoAuthentication:
    enabled: true
  UsernamePassword:
    enabled: true
  AWSSigV4:
    enabled: false

----------------------------------------

TITLE: Configuring Allowlist in allowlist.yml
DESCRIPTION: Specifies allowed endpoints and HTTP requests for non-admin users. This example allows GET requests to cluster settings and node information.

LANGUAGE: yaml
CODE:
---
_meta:
  type: "allowlist"
  config_version: 2

config:
  enabled: true
  requests:
    /_cluster/settings:
      - GET
    /_cat/nodes:
      - GET

----------------------------------------

TITLE: Detailed Snapshot Creation Response in OpenSearch (With wait_for_completion)
DESCRIPTION: This example demonstrates the detailed JSON response when creating a snapshot with the 'wait_for_completion' parameter, including snapshot details, indices, timing information, and shard statistics.

LANGUAGE: json
CODE:
{
  "snapshot" : {
    "snapshot" : "5",
    "uuid" : "ZRH4Zv7cSnuYev2JpLMJGw",
    "version_id" : 136217927,
    "version" : "2.0.1",
    "indices" : [
      ".opendistro-reports-instances",
      ".opensearch-observability",
      ".kibana_1",
      "opensearch_dashboards_sample_data_flights",
      ".opensearch-notifications-config",
      ".opendistro-reports-definitions",
      "shakespeare"
    ],
    "data_streams" : [ ],
    "include_global_state" : true,
    "state" : "SUCCESS",
    "start_time" : "2022-08-10T16:52:15.277Z",
    "start_time_in_millis" : 1660150335277,
    "end_time" : "2022-08-10T16:52:18.699Z",
    "end_time_in_millis" : 1660150338699,
    "duration_in_millis" : 3422,
    "failures" : [ ],
    "shards" : {
      "total" : 7,
      "failed" : 0,
      "successful" : 7
    }
  }
}

----------------------------------------

TITLE: Memory Search Response Example
DESCRIPTION: Example response showing the structure of returned memory search results including metadata and hit information.

LANGUAGE: json
CODE:
{
  "took": 1,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 3,
      "relation": "eq"
    },
    "max_score": 0.2195382,
    "hits": [
      {
        "_index": ".plugins-ml-memory-meta",
        "_id": "znCqcI0BfUsSoeNTntd7",
        "_version": 3,
        "_seq_no": 39,
        "_primary_term": 1,
        "_score": 0.2195382,
        "_source": {
          "updated_time": "2024-02-03T20:36:10.252213029Z",
          "create_time": "2024-02-03T20:30:46.395829411Z",
          "application_type": null,
          "name": "Conversation about NYC population",
          "user": "admin"
        }
      },
      {
        "_index": ".plugins-ml-memory-meta",
        "_id": "iXC4bI0BfUsSoeNTjS30",
        "_version": 4,
        "_seq_no": 11,
        "_primary_term": 1,
        "_score": 0.20763937,
        "_source": {
          "updated_time": "2024-02-03T02:59:39.862347093Z",
          "create_time": "2024-02-03T02:07:30.804554275Z",
          "application_type": null,
          "name": "Test conversation for RAG pipeline",
          "user": "admin"
        }
      },
      {
        "_index": ".plugins-ml-memory-meta",
        "_id": "gW8Aa40BfUsSoeNTvOKI",
        "_version": 4,
        "_seq_no": 6,
        "_primary_term": 1,
        "_score": 0.19754036,
        "_source": {
          "updated_time": "2024-02-02T19:01:32.121444968Z",
          "create_time": "2024-02-02T18:07:06.887061463Z",
          "application_type": null,
          "name": "Conversation for a RAG pipeline",
          "user": "admin"
        }
      }
    ]
  }
}

----------------------------------------

TITLE: Localization Algorithm Response in OpenSearch
DESCRIPTION: An example response from executing the Localization algorithm using the ML Commons plugin in OpenSearch. The response includes results with time buckets, overall aggregate values, and entity contributions.

LANGUAGE: json
CODE:
{
  "results" : [
    {
      "name" : "sum",
      "result" : {
        "buckets" : [
          {
            "start_time" : 1620630000000,
            "end_time" : 1620716400000,
            "overall_aggregate_value" : 65.0
          },
          {
            "start_time" : 1620716400000,
            "end_time" : 1620802800000,
            "overall_aggregate_value" : 75.0,
            "entities" : [
              {
                "key" : [
                  "attr0"
                ],
                "contribution_value" : 1.0,
                "base_value" : 2.0,
                "new_value" : 3.0
              },
              {
                "key" : [
                  "attr1"
                ],
                "contribution_value" : 1.0,
                "base_value" : 3.0,
                "new_value" : 4.0
              },
              {
                "key" : [
                  "attr2"
                ],
                "contribution_value" : 1.0,
                "base_value" : 4.0,
                "new_value" : 5.0
              },
              {
                "key" : [
                  "attr3"
                ],
                "contribution_value" : 1.0,
                "base_value" : 5.0,
                "new_value" : 6.0
              },
              {
                "key" : [
                  "attr4"
                ],
                "contribution_value" : 1.0,
                "base_value" : 6.0,
                "new_value" : 7.0
              },
              {
                "key" : [
                  "attr5"
                ],
                "contribution_value" : 1.0,
                "base_value" : 7.0,
                "new_value" : 8.0
              },
              {
                "key" : [
                  "attr6"
                ],
                "contribution_value" : 1.0,
                "base_value" : 8.0,
                "new_value" : 9.0
              },
              {
                "key" : [
                  "attr7"
                ],
                "contribution_value" : 1.0,
                "base_value" : 9.0,
                "new_value" : 10.0
              },
              {
                "key" : [
                  "attr8"
                ],
                "contribution_value" : 1.0,
                "base_value" : 10.0,
                "new_value" : 11.0
              },
              {
                "key" : [
                  "attr9"
                ],
                "contribution_value" : 1.0,
                "base_value" : 11.0,
                "new_value" : 12.0
              }
            ]
          },
          ...
        ]
      }
    }
  ]
}

----------------------------------------

TITLE: Response to Model Group Deletion in OpenSearch ML Commons
DESCRIPTION: This is the response returned after successfully deleting a model group. It includes details such as the index, ID, version, result, shard information, sequence number, and primary term of the deleted model group.

LANGUAGE: json
CODE:
{
  "_index": ".plugins-ml-model-group",
  "_id": "l8nnQogByXnLJ-QNpEk2",
  "_version": 5,
  "result": "deleted",
  "_shards": {
    "total": 2,
    "successful": 1,
    "failed": 0
  },
  "_seq_no": 70,
  "_primary_term": 23
}

----------------------------------------

TITLE: Analyzing Text with Custom Analyzer - OpenSearch JSON
DESCRIPTION: Demonstrates how to analyze text using a custom analyzer and shows the resulting tokens with their positions and offsets.

LANGUAGE: json
CODE:
POST /my_custom_index/_analyze
{
  "analyzer": "my_custom_analyzer",
  "text": "The slow turtle swims away"
}

LANGUAGE: json
CODE:
{
  "tokens": [
    {"token": "slow","start_offset": 4,"end_offset": 8,"type": "<ALPHANUM>","position": 1},
    {"token": "turtle","start_offset": 9,"end_offset": 15,"type": "<ALPHANUM>","position": 2},
    {"token": "swims","start_offset": 16,"end_offset": 21,"type": "<ALPHANUM>","position": 3},
    {"token": "away","start_offset": 22,"end_offset": 26,"type": "<ALPHANUM>","position": 4}
  ]
}

----------------------------------------

TITLE: Configuring Basic Danish Analyzer
DESCRIPTION: Shows how to apply the built-in Danish analyzer to a text field in an OpenSearch index mapping.

LANGUAGE: json
CODE:
{
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "danish"
      }
    }
  }
}

----------------------------------------

TITLE: Basic CAT Shards Query - JSON
DESCRIPTION: Example request to retrieve information about all shards with verbose output enabled.

LANGUAGE: json
CODE:
GET _cat/shards?v

----------------------------------------

TITLE: Registering Hidden Model in OpenSearch
DESCRIPTION: Bash command with JSON payload to register a hidden model using the ML Commons API in OpenSearch.

LANGUAGE: bash
CODE:
curl -k --cert ./kirk.pem --key ./kirk-key.pem -X POST 'https://localhost:9200/_plugins/_ml/models/_register' -H 'Content-Type: application/json' -d '
{
    "name": "OPENSEARCH_ASSISTANT_MODEL",
    "function_name": "remote",
    "description": "OpenSearch Assistant Model",
    "connector": {
        "name": "Bedrock Claude Connector",
        "description": "The connector to Bedrock Claude",
        "version": 1,
        "protocol": "aws_sigv4",
        "parameters": {
          "region": "us-east-1",
          "service_name": "bedrock"
        },
        "credential": {
            "access_key": "<YOUR_ACCESS_KEY>",
            "secret_key": "<YOUR_SECRET_KEY>",
            "session_token": "<YOUR_SESSION_TOKEN>"
        },
        "actions": [
           {
            "action_type": "predict",
            "method": "POST",
            "headers": {
                "content-type": "application/json"
            },
            "url": "https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-v2/invoke",
            "request_body": "{\"prompt\":\"\\n\\nHuman: ${parameters.inputs}\\n\\nAssistant:\",\"max_tokens_to_sample\":300,\"temperature\":0.5,\"top_k\":250,\"top_p\":1,\"stop_sequences\":[\"\\\\n\\\\nHuman:\"]}"
          }
       ]
    }
}'

----------------------------------------

TITLE: Creating an Index with UAX URL Email Tokenizer in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a new index named 'my_index' with a custom analyzer using the UAX URL email tokenizer.

LANGUAGE: json
CODE:
PUT /my_index
{
  "settings": {
    "analysis": {
      "tokenizer": {
        "uax_url_email_tokenizer": {
          "type": "uax_url_email"
        }
      },
      "analyzer": {
        "my_uax_analyzer": {
          "type": "custom",
          "tokenizer": "uax_url_email_tokenizer"
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "my_uax_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Basic Match Query with Kendra Intelligent Ranking
DESCRIPTION: Example showing how to integrate Amazon Kendra Intelligent Ranking with a basic match query for result reranking.

LANGUAGE: json
CODE:
{
  "query" : {
    "match" : {
      "bullet_point": "%SearchText%"
    }
  },
  "size": 25,
  "ext": {
    "search_configuration":{
      "result_transformer" : {
        "kendra_intelligent_ranking": {
          "order": 1,
          "properties": {
            "title_field": "item_name",
            "body_field": "bullet_point"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating a Basic Snapshot in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a snapshot named 'my-first-snapshot' in an S3 repository called 'my-s3-repository' using a POST request without a body.

LANGUAGE: json
CODE:
POST _snapshot/my-s3-repository/my-first-snapshot

----------------------------------------

TITLE: Retrieving All ML Commons Stats for a Specific Node in OpenSearch
DESCRIPTION: This request retrieves all ML Commons statistics for a specific node in the OpenSearch cluster. Replace <nodeId> with the ID of the desired node.

LANGUAGE: json
CODE:
GET /_plugins/_ml/<nodeId>/stats/

----------------------------------------

TITLE: Describing Kafka Topic Records in Migration Console
DESCRIPTION: Command to view records in the Kafka logging topic, used to verify capture proxy data replication.

LANGUAGE: bash
CODE:
console kafka describe-topic-records

----------------------------------------

TITLE: Example Response for Remote Cluster Information in OpenSearch
DESCRIPTION: This JSON response shows the connection information for a remote OpenSearch cluster named 'opensearch-cluster2'. It includes details such as connection status, mode, seed nodes, number of connected nodes, and various configuration settings.

LANGUAGE: json
CODE:
{
  "opensearch-cluster2": {
    "connected": true,
    "mode": "sniff",
    "seeds": [
      "172.28.0.2:9300"
    ],
    "num_nodes_connected": 1,
    "max_connections_per_cluster": 3,
    "initial_connect_timeout": "30s",
    "skip_unavailable": false
  }
}

----------------------------------------

TITLE: ML Commons Plugin Multi-tenancy Configuration
DESCRIPTION: Configuration example for enabling multi-tenancy in the ML Commons plugin using AWS DynamoDB as the remote metadata store. Specifies settings for endpoint, region, and service name.

LANGUAGE: yaml
CODE:
plugins.ml_commons.multi_tenancy_enabled: true
plugins.ml_commons.remote_metadata_type: AWSDynamoDB
plugins.ml_commons.remote_metadata_endpoint: <REMOTE_ENDPOINT>
plugins.ml_commons.remote_metadata_region: <AWS_REGION>
plugins.ml_commons.remote_metadata_service_name: <SERVICE_NAME>

----------------------------------------

TITLE: Migrating Metadata in OpenSearch Migration Console
DESCRIPTION: This command migrates the metadata from the source cluster to the target cluster.

LANGUAGE: sh
CODE:
console metadata migrate

----------------------------------------

TITLE: Analyzing Text with Hyphenation Decompounder in OpenSearch
DESCRIPTION: Example of using the _analyze endpoint to test the custom analyzer with hyphenation decompounder filter. Shows how to analyze the word 'notebook' and displays the resulting tokens.

LANGUAGE: json
CODE:
POST /test_index/_analyze
{
  "analyzer": "my_analyzer",
  "text": "notebook"
}

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "notebook",
      "start_offset": 0,
      "end_offset": 8,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "note",
      "start_offset": 0,
      "end_offset": 8,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "book",
      "start_offset": 0,
      "end_offset": 8,
      "type": "<ALPHANUM>",
      "position": 0
    }
  ]
}

----------------------------------------

TITLE: Pulling OpenSearch Maps Server Docker Image
DESCRIPTION: This command pulls the OpenSearch Maps Server Docker image from the official repository.

LANGUAGE: bash
CODE:
docker pull opensearchproject/opensearch-maps-server:1.0.0

----------------------------------------

TITLE: Sample CAT Aliases Response
DESCRIPTION: Example response showing alias mappings, including index references and configuration details.

LANGUAGE: json
CODE:
alias   | index     | filter  | routing.index | routing.search  | is_write_index
alias1  | movies    |   *     |      -        |       -         |      -
.opensearch-dashboards | .opensearch-dashboards_1 |   -     |      -        |       -         |      -

----------------------------------------

TITLE: Common Field Mappings Configuration in JSON
DESCRIPTION: Defines standard field mappings used across different log types in Security Analytics. Maps raw fields to their corresponding ECS (Elastic Common Schema) fields, including DNS answer types, question names, registered domains, and timestamps.

LANGUAGE: json
CODE:
  "mappings": [
    {
      "raw_field":"record_type",
      "ecs":"dns.answers.type"
    },
    {
      "raw_field":"query",
      "ecs":"dns.question.name"
    },
    {
      "raw_field":"parent_domain",
      "ecs":"dns.question.registered_domain"
    },
    {
      "raw_field":"creationTime",
      "ecs":"timestamp"
    }
  ]

----------------------------------------

TITLE: Creating k-NN Index
DESCRIPTION: Index configuration for storing vector embeddings with k-NN support.

LANGUAGE: json
CODE:
{
  "mappings": {
    "properties": {
      "text": {
        "type": "text"
      },
      "embedding": {
        "type": "knn_vector",
        "dimension": 384
      }
    }
  },
  "settings": {
    "index": {
      "knn.space_type": "cosinesimil",
      "default_pipeline": "test-pipeline-local-model",
      "knn": "true"
    }
  }
}

----------------------------------------

TITLE: Documenting Path Parameters for OpenSearch Search API
DESCRIPTION: This snippet defines a markdown table for path parameters in the OpenSearch search API. It includes details on the 'index' parameter, which allows specifying data streams, indexes, and aliases to search.

LANGUAGE: markdown
CODE:
## Path parameters

The following table lists the available path parameters. All path parameters are optional.

| Parameter | Data type | Description |
| :--- | :--- | :--- |
| `index` | List or String | Comma-separated list of data streams, indexes, and aliases to search. Supports wildcards (`*`). To search all data streams and indexes, omit this parameter or use `*` or `_all`. <br> Valid values are: `_all`, `_any`, `_none` |

----------------------------------------

TITLE: Retrieving ISM Index Information without Validation in OpenSearch
DESCRIPTION: This snippet demonstrates how to use the Explain API to retrieve information about an ISM-managed index without including validation status and message. Two equivalent requests are shown.

LANGUAGE: bash
CODE:
GET _plugins/_ism/explain/test-000001?validate_action=false
 --- OR ---
GET _plugins/_ism/explain/test-000001

----------------------------------------

TITLE: Indexing a Document with Coerce Enabled in OpenSearch
DESCRIPTION: This example demonstrates how to create an index with the 'coerce' parameter enabled for the 'price' field, allowing automatic conversion of string values to integers during indexing.

LANGUAGE: json
CODE:
PUT products
{
  "mappings": {
    "properties": {
      "price": {
        "type": "integer",
        "coerce": true
      }
    }
  }
}

PUT products/_doc/1
{
  "name": "Product A",
  "price": "19.99"
}

----------------------------------------

TITLE: Port Forwarding for OpenSearch REST API
DESCRIPTION: This command sets up port forwarding to access the OpenSearch REST API on localhost:9200.

LANGUAGE: bash
CODE:
kubectl port-forward svc/my-cluster 9200

----------------------------------------

TITLE: Searching Security Findings
DESCRIPTION: GET endpoint to search and filter security findings based on detector ID, type, severity and other criteria. Supports pagination and sorting options.

LANGUAGE: json
CODE:
GET /_plugins/_security_analytics/findings/_search

LANGUAGE: json
CODE:
GET /_plugins/_security_analytics/findings/_search?severity=high

LANGUAGE: json
CODE:
GET /_plugins/_security_analytics/findings/_search?detectionType=rule

LANGUAGE: json
CODE:
GET /_plugins/_security_analytics/findings/_search?detectionType=rule&severity=high

LANGUAGE: json
CODE:
GET /_plugins/_security_analytics/findings/_search?*detectorType*=

----------------------------------------

TITLE: Scripted Reindex Operation
DESCRIPTION: Transforms documents during reindexing using a Painless script that modifies field values.

LANGUAGE: json
CODE:
POST _reindex
{
   "source":{
      "index":"source"
   },
   "dest":{
      "index":"destination"
   },
   "script":{
      "lang":"painless",
      "source":"ctx._account.number++"
   }
}

----------------------------------------

TITLE: Creating an Index with Length Token Filter in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a new index named 'my_index' with an analyzer that uses a Length token filter. The filter is configured to keep tokens between 4 and 10 characters long.

LANGUAGE: json
CODE:
PUT my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "only_keep_4_to_10_characters": {
          "tokenizer": "whitespace",
          "filter": [ "length_4_to_10" ]
        }
      },
      "filter": {
        "length_4_to_10": {
          "type": "length",
          "min": 4,
          "max": 10
        }
      }
    }
  }
}

----------------------------------------

TITLE: OpenSearch Index Response Example
DESCRIPTION: Example response from OpenSearch after successfully indexing a document. Shows the response structure including index details, document ID, version, and shard information.

LANGUAGE: json
CODE:
{
  "_index": "sample-index",
  "_id": "1",
  "_version": 1,
  "result": "created",
  "_shards": {
    "total": 2,
    "successful": 1,
    "failed": 0
  },
  "_seq_no": 0,
  "_primary_term": 1
}

----------------------------------------

TITLE: Creating a Materialized View in OpenSearch SQL
DESCRIPTION: This SQL query creates a materialized view on a VPC logs table. It includes complex transformations and aggregations of various fields, and specifies refresh settings, checkpoint location, and watermark delay.

LANGUAGE: sql
CODE:
CREATE MATERIALIZED VIEW {table_name}__week_live_mview AS
  SELECT
    cloud.account_uid AS `aws.vpc.cloud_account_uid`,
    cloud.region AS `aws.vpc.cloud_region`,
    cloud.zone AS `aws.vpc.cloud_zone`,
    cloud.provider AS `aws.vpc.cloud_provider`,

    CAST(IFNULL(src_endpoint.port, 0) AS LONG) AS `aws.vpc.srcport`,
    CAST(IFNULL(src_endpoint.svc_name, 'Unknown') AS STRING)  AS `aws.vpc.pkt-src-aws-service`,
    CAST(IFNULL(src_endpoint.ip, '0.0.0.0') AS STRING)  AS `aws.vpc.srcaddr`,
    CAST(IFNULL(src_endpoint.interface_uid, 'Unknown') AS STRING)  AS `aws.vpc.src-interface_uid`,
    CAST(IFNULL(src_endpoint.vpc_uid, 'Unknown') AS STRING)  AS `aws.vpc.src-vpc_uid`,
    CAST(IFNULL(src_endpoint.instance_uid, 'Unknown') AS STRING)  AS `aws.vpc.src-instance_uid`,
    CAST(IFNULL(src_endpoint.subnet_uid, 'Unknown') AS STRING)  AS `aws.vpc.src-subnet_uid`,

    CAST(IFNULL(dst_endpoint.port, 0) AS LONG) AS `aws.vpc.dstport`,
    CAST(IFNULL(dst_endpoint.svc_name, 'Unknown') AS STRING) AS `aws.vpc.pkt-dst-aws-service`,
    CAST(IFNULL(dst_endpoint.ip, '0.0.0.0') AS STRING)  AS `aws.vpc.dstaddr`,
    CAST(IFNULL(dst_endpoint.interface_uid, 'Unknown') AS STRING)  AS `aws.vpc.dst-interface_uid`,
    CAST(IFNULL(dst_endpoint.vpc_uid, 'Unknown') AS STRING)  AS `aws.vpc.dst-vpc_uid`,
    CAST(IFNULL(dst_endpoint.instance_uid, 'Unknown') AS STRING)  AS `aws.vpc.dst-instance_uid`,
    CAST(IFNULL(dst_endpoint.subnet_uid, 'Unknown') AS STRING)  AS `aws.vpc.dst-subnet_uid`,
    CASE
      WHEN regexp(dst_endpoint.ip, '(10\\..*)|(192\\.168\\..*)|(172\\.1[6-9]\\..*)|(172\\.2[0-9]\\..*)|(172\\.3[0-1]\\.*)')
        THEN 'ingress'
      ELSE 'egress'
      END AS `aws.vpc.flow-direction`,

    CAST(IFNULL(connection_info['protocol_num'], 0) AS INT) AS `aws.vpc.connection.protocol_num`,
    CAST(IFNULL(connection_info['tcp_flags'], '0') AS STRING)  AS `aws.vpc.connection.tcp_flags`,
    CAST(IFNULL(connection_info['protocol_ver'], '0') AS STRING)  AS `aws.vpc.connection.protocol_ver`,
    CAST(IFNULL(connection_info['boundary'], 'Unknown') AS STRING)  AS `aws.vpc.connection.boundary`,
    CAST(IFNULL(connection_info['direction'], 'Unknown') AS STRING)  AS `aws.vpc.connection.direction`,

    CAST(IFNULL(traffic.packets, 0) AS LONG) AS `aws.vpc.packets`,
    CAST(IFNULL(traffic.bytes, 0) AS LONG) AS `aws.vpc.bytes`,

    CAST(FROM_UNIXTIME(time / 1000) AS TIMESTAMP) AS `@timestamp`,
    CAST(FROM_UNIXTIME(start_time / 1000) AS TIMESTAMP) AS `start_time`,
    CAST(FROM_UNIXTIME(start_time / 1000) AS TIMESTAMP) AS `interval_start_time`,
    CAST(FROM_UNIXTIME(end_time / 1000) AS TIMESTAMP) AS `end_time`,
    status_code AS `aws.vpc.status_code`,

    severity AS `aws.vpc.severity`,
    class_name AS `aws.vpc.class_name`,
    category_name AS `aws.vpc.category_name`,
    activity_name AS `aws.vpc.activity_name`,
    disposition AS `aws.vpc.disposition`,
    type_name AS `aws.vpc.type_name`,

    region AS `aws.vpc.region`,
    accountid AS `aws.vpc.account-id`
  FROM
  datasourcename.gluedatabasename.vpclogstable 
WITH (
  auto_refresh = true,
  refresh_interval = '15 Minute',
  checkpoint_location = 's3://accountnum-vpcflow/AWSLogs/checkpoint',
  watermark_delay = '1 Minute',
)

----------------------------------------

TITLE: Configuring Security Settings in opensearch.yml
DESCRIPTION: Contains various OpenSearch settings including paths to TLS certificates, security plugin configurations, and system index settings.

LANGUAGE: yaml
CODE:
plugins.security.ssl.transport.pemcert_filepath: esnode.pem
plugins.security.ssl.transport.pemkey_filepath: esnode-key.pem
plugins.security.ssl.transport.pemtrustedcas_filepath: root-ca.pem
plugins.security.ssl.transport.enforce_hostname_verification: false
plugins.security.ssl.http.enabled: true
plugins.security.ssl.http.pemcert_filepath: esnode.pem
plugins.security.ssl.http.pemkey_filepath: esnode-key.pem
plugins.security.ssl.http.pemtrustedcas_filepath: root-ca.pem
plugins.security.allow_unsafe_democertificates: true
plugins.security.allow_default_init_securityindex: true
plugins.security.authcz.admin_dn:
  - CN=kirk,OU=client,O=client,L=test, C=de

plugins.security.audit.type: internal_opensearch
plugins.security.enable_snapshot_restore_privilege: true
plugins.security.check_snapshot_restore_write_privileges: true
plugins.security.cache.ttl_minutes: 60
plugins.security.restapi.roles_enabled: ["all_access", "security_rest_api_access"]
plugins.security.system_indices.enabled: true
plugins.security.system_indices.indices: [".opendistro-alerting-config", ".opendistro-alerting-alert*", ".opendistro-anomaly-results*", ".opendistro-anomaly-detector*", ".opendistro-anomaly-checkpoints", ".opendistro-anomaly-detection-state", ".opendistro-reports-*", ".opendistro-notifications-*", ".opendistro-notebooks", ".opendistro-asynchronous-search-response*"]
node.max_local_storage_nodes: 3

----------------------------------------

TITLE: Checking ISM Validation Status with Explain API in OpenSearch
DESCRIPTION: This example shows how to use the Explain API to check the validation status and message for an index managed by ISM. The 'validate_action=true' parameter is passed to include validation information in the response.

LANGUAGE: bash
CODE:
GET _plugins/_ism/explain/test-000001?validate_action=true

----------------------------------------

TITLE: Retrieving Connector by ID in OpenSearch ML Commons
DESCRIPTION: This endpoint retrieves a connector by its ID. It uses a GET request to the specified path with the connector ID as a parameter.

LANGUAGE: json
CODE:
GET /_plugins/_ml/connectors/<connector_id>

----------------------------------------

TITLE: Creating Pipeline with Drop Processor for PII Detection
DESCRIPTION: Example of creating an ingest pipeline that drops documents containing personally identifiable information (PII).

LANGUAGE: json
CODE:
{
  "description": "Pipeline that prevents PII from being indexed",
  "processors": [
    {
      "drop": {
        "if" : "ctx.user_info.contains('password') || ctx.user_info.contains('credit card')"
      }
    }
  ]
}

----------------------------------------

TITLE: Configuring Add Entries Processor with Format Strings in YAML
DESCRIPTION: This example shows how to use format strings to combine values from existing fields into a new entry.

LANGUAGE: yaml
CODE:
processor:
  - add_entries:
      entries:
        - key: "date"
          format: "${month}-${day}"

----------------------------------------

TITLE: Querying Thread Pool Information for Cluster Manager Node in OpenSearch
DESCRIPTION: Example request to get thread pool information specifically from the cluster manager node using the Nodes Info API.

LANGUAGE: json
CODE:
GET /_nodes/master:true/thread_pool

----------------------------------------

TITLE: Calculating IVF Memory Requirement with PQ in R
DESCRIPTION: Estimates the memory required for IVF with PQ, given specific parameters such as number of vectors, dimensions, and PQ settings.

LANGUAGE: r
CODE:
1.1 * ((8 / 8 * 64 + 24) * 1000000  + 100 * (2^8 * 4 * 256 + 4 * 512 * 256))  ~= 0.171 GB

----------------------------------------

TITLE: Testing User Agent Pipeline in OpenSearch
DESCRIPTION: POST request to simulate the 'user_agent_pipeline' with a sample document containing a user agent string. This helps verify the pipeline's functionality before actual ingestion.

LANGUAGE: json
CODE:
POST _ingest/pipeline/user_agent_pipeline/_simulate
{
  "pipeline": "user_agent_pipeline",
  "docs": [
    {
      "_source": {
        "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3"
      }
    }
  ]
}

----------------------------------------

TITLE: Mutating Strings with split_string Processor in YAML
DESCRIPTION: This example demonstrates how to use the split_string processor to manipulate strings in incoming data, splitting a string into an array based on a delimiter.

LANGUAGE: yaml
CODE:
...
processor:
  - split_string:
      entries:
        - source: "message"
          delimiter: "&"
...

----------------------------------------

TITLE: Extra Logging Implementation - Java
DESCRIPTION: Java implementation showing how to add extra logging information to feature vectors.

LANGUAGE: java
CODE:
@Override
public double runAsDouble() {
    Map<String,Object> extraLoggingMap = ((Supplier<Map<String,Object>>) getParams().get("extra_logging")).get();
    if (extraLoggingMap != null) {
        extraLoggingMap.put("extra_float", 10.0f);
        extraLoggingMap.put("extra_string", "additional_info");
    }
}

----------------------------------------

TITLE: Creating Search Pipeline with Split Processor
DESCRIPTION: Defines a search pipeline that includes a split processor to split the message field using a comma-space delimiter.

LANGUAGE: json
CODE:
PUT /_search/pipeline/my_pipeline
{
  "response_processors": [
    {
      "split": {
        "field": "message",
        "separator": ", ",
        "target_field": "split_message"
      }
    }
  ]
}

----------------------------------------

TITLE: Starting OpenSearch Dashboards
DESCRIPTION: Command to start OpenSearch Dashboards after configuration. This is the final step in the migration process to launch the new dashboard service.

LANGUAGE: bash
CODE:
./bin/opensearch-dashboards

----------------------------------------

TITLE: Indexing a Document
DESCRIPTION: Create an instance of the document class and save it to the OpenSearch index using the client.

LANGUAGE: python
CODE:
# Set up the opensearch-py version of the document
Movie.init(using=client)
doc = Movie(meta={'id': 1}, title='Moneyball', director='Bennett Miller', year='2011')
response = doc.save(using=client)

----------------------------------------

TITLE: Close Index Response Example
DESCRIPTION: Example response showing a successful index closure operation. The response includes acknowledgment flags and the status of the closed index.

LANGUAGE: json
CODE:
{
  "acknowledged": true,
  "shards_acknowledged": true,
  "indices": {
    "sample-index1": {
      "closed": true
    }
  }
}

----------------------------------------

TITLE: Bulk Ingesting Text Data for Embedding Generation in OpenSearch
DESCRIPTION: Demonstrates using the Bulk API to efficiently ingest multiple text documents into an OpenSearch index with a configured ingest pipeline for automatic embedding generation.

LANGUAGE: json
CODE:
PUT /_bulk
{"index": {"_index": "my-ai-search-index", "_id": 1}}
{"input_text": "Example AI search description"}
{"index": {"_index": "my-ai-search-index", "_id": 2}}
{"input_text": "Bulk API operation description"}

----------------------------------------

TITLE: Assigning Backend Role to User in OpenSearch
DESCRIPTION: JSON request to assign the 'analyst' backend role to the user 'alice' using the Security plugin API.

LANGUAGE: json
CODE:
PUT _plugins/_security/api/internalusers/alice
{
  "password": "alice",
  "backend_roles": [
    "analyst"
  ],
  "attributes": {}
}

----------------------------------------

TITLE: Get Message by ID Example Response
DESCRIPTION: Example response showing the structure of returned message data including memory ID, creation time, and response content.

LANGUAGE: json
CODE:
{
  "memory_id": "gW8Aa40BfUsSoeNTvOKI",
  "message_id": "0m8ya40BfUsSoeNTj-pU",
  "create_time": "2024-02-02T19:01:32.113621539Z",
  "input": null,
  "prompt_template": null,
  "response": "Hello, this is OpenAI. Here is the answer to your question.",
  "origin": null,
  "additional_info": {
    "suggestion": "api.openai.com"
  }
}

----------------------------------------

TITLE: Get Mappings API Request/Response
DESCRIPTION: API endpoint to retrieve existing mappings for a specific index. Requires index_name as a path parameter.

LANGUAGE: json
CODE:
GET /_plugins/_security_analytics/mappings?index_name=windows

LANGUAGE: json
CODE:
{
    "windows": {
        "mappings": {
            "properties": {
                "windows-event_data-CommandLine": {
                    "type": "alias",
                    "path": "CommandLine"
                },
                "event_uid": {
                    "type": "alias",
                    "path": "EventID"
                }
            }
        }
    }
}

----------------------------------------

TITLE: Get Snapshot Status API Request Example
DESCRIPTION: Example request to get the status of a specific snapshot, ignoring unavailable snapshots.

LANGUAGE: json
CODE:
GET _snapshot/my-opensearch-repo/my-first-snapshot/_status
{
   "ignore_unavailable": true 
}

----------------------------------------

TITLE: Deleting Memory Endpoint - JSON
DESCRIPTION: The DELETE endpoint for removing a memory by its ID. This endpoint requires a memory_id path parameter and returns a success status.

LANGUAGE: json
CODE:
DELETE /_plugins/_ml/memory/<memory_id>

----------------------------------------

TITLE: ML Task Dispatch Policy
DESCRIPTION: Setting to control how ML tasks are distributed across ML nodes.

LANGUAGE: yaml
CODE:
plugins.ml_commons.task_dispatch_policy: round_robin

----------------------------------------

TITLE: Enabling Workspace Feature in YAML Configuration
DESCRIPTION: This snippet shows the YAML configuration required to enable the Workspace feature in OpenSearch Dashboards. It includes settings for enabling the feature and overriding UI settings.

LANGUAGE: yaml
CODE:
workspace.enabled: true
uiSettings:
  overrides:
    "home:useNewHomePage": true

----------------------------------------

TITLE: Retrieving All Field Data in OpenSearch
DESCRIPTION: This request retrieves field data for all fields with verbose output. It uses the CAT Field Data API endpoint.

LANGUAGE: json
CODE:
GET _cat/fielddata?v

----------------------------------------

TITLE: Example Response for Updating Connector in OpenSearch ML Commons
DESCRIPTION: An example JSON response after successfully updating a connector. It includes details such as the index, ID, version, and update result.

LANGUAGE: json
CODE:
{
  "_index": ".plugins-ml-connector",
  "_id": "u3DEbI0BfUsSoeNTti-1",
  "_version": 2,
  "result": "updated",
  "_shards": {
    "total": 1,
    "successful": 1,
    "failed": 0
  },
  "_seq_no": 2,
  "_primary_term": 1
}

----------------------------------------

TITLE: Analyzing Text with Simple Pattern Split Tokenizer - OpenSearch JSON
DESCRIPTION: Example request to analyze text using the configured simple_pattern_split analyzer to see the generated tokens.

LANGUAGE: json
CODE:
POST /my_index/_analyze
{
  "analyzer": "my_pattern_split_analyzer",
  "text": "OpenSearch-2024-10-09"
}

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "OpenSearch",
      "start_offset": 0,
      "end_offset": 10,
      "type": "word",
      "position": 0
    },
    {
      "token": "2024",
      "start_offset": 11,
      "end_offset": 15,
      "type": "word",
      "position": 1
    },
    {
      "token": "10",
      "start_offset": 16,
      "end_offset": 18,
      "type": "word",
      "position": 2
    },
    {
      "token": "09",
      "start_offset": 19,
      "end_offset": 21,
      "type": "word",
      "position": 3
    }
  ]
}

----------------------------------------

TITLE: Successful Response for Delete Snapshot API in OpenSearch
DESCRIPTION: This JSON response indicates a successful deletion of a snapshot. The 'acknowledged' field set to true confirms that the operation was completed.

LANGUAGE: json
CODE:
{
  "acknowledged": true
}

----------------------------------------

TITLE: Initializing NVIDIA UVM Device Nodes Script
DESCRIPTION: Bash script to initialize NVIDIA device nodes and set up the nvidia-uvm kernel required for CUDA acceleration. Creates necessary device nodes with appropriate permissions.

LANGUAGE: bash
CODE:
#!/bin/bash
## Script to initialize nvidia device nodes.
## https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#runfile-verifications
/sbin/modprobe nvidia
if [ "$?" -eq 0 ]; then
  # Count the number of NVIDIA controllers found.
  NVDEVS=`lspci | grep -i NVIDIA`
  N3D=`echo "$NVDEVS" | grep "3D controller" | wc -l`
  NVGA=`echo "$NVDEVS" | grep "VGA compatible controller" | wc -l`
  N=`expr $N3D + $NVGA - 1`
  for i in `seq 0 $N`; do
    mknod -m 666 /dev/nvidia$i c 195 $i
  done
  mknod -m 666 /dev/nvidiactl c 195 255
else
  exit 1
fi
/sbin/modprobe nvidia-uvm
if [ "$?" -eq 0 ]; then
  # Find out the major device number used by the nvidia-uvm driver
  D=`grep nvidia-uvm /proc/devices | awk '{print $1}'`
  mknod -m 666 /dev/nvidia-uvm c $D 0
  mknod -m 666 /dev/nvidia-uvm-tools c $D 0
else
  exit 1
fi

----------------------------------------

TITLE: Ingesting Document with Convert Pipeline
DESCRIPTION: Example of ingesting a document using the convert pipeline.

LANGUAGE: json
CODE:
PUT testindex1/_doc/1?pipeline=convert-price
{
  "price": "10.5"
}

----------------------------------------

TITLE: Defining Interval Type in SQL for OpenSearch
DESCRIPTION: Specifies the syntax for the 'interval' type in SQL for OpenSearch. The interval type represents a duration or period of time.

LANGUAGE: sql
CODE:
interval | INTERVAL expr unit

----------------------------------------

TITLE: Querying List Shards API for Multiple Indexes in OpenSearch
DESCRIPTION: This example demonstrates how to query shard information for multiple specific indexes using the List Shards API. Indexes are separated by commas in the request.

LANGUAGE: json
CODE:
GET _list/shards/index1,index2,index3?v&next_token=token

----------------------------------------

TITLE: Analyzing Text with Dictionary Decompounder in OpenSearch
DESCRIPTION: This example shows how to use the _analyze API to test the custom analyzer with the dictionary_decompounder filter. It analyzes the compound word 'slowgreenturtleswim' using the previously defined analyzer.

LANGUAGE: json
CODE:
POST /decompound_example/_analyze
{
  "analyzer": "my_analyzer",
  "text": "slowgreenturtleswim"
}

----------------------------------------

TITLE: Querying Specific Shards
DESCRIPTION: Example request for segment replication metrics targeting specific shard IDs across multiple indexes.

LANGUAGE: json
CODE:
GET /_cat/segment_replication/index1,index2?v=true&shards=0

----------------------------------------

TITLE: Defining DNS Log Type Mappings in JSON for OpenSearch
DESCRIPTION: This JSON snippet defines mappings between raw fields, ECS (Elastic Common Schema), and OCSF (Open Cybersecurity Schema Framework) for DNS activity logs. It covers various DNS-related fields including record types, queries, answers, and network information. The mappings are crucial for normalizing and standardizing DNS log data in OpenSearch.

LANGUAGE: json
CODE:
"mappings": [
    {
      "raw_field":"record_type",
      "ecs":"dns.answers.type",
      "ocsf": "unmapped.record_type"
    },
    {
      "raw_field":"answers[].Type",
      "ecs":"aws.route53.answers.Type",
      "ocsf": "answers[].type"
    },
    {
      "raw_field":"answers[].Rdata",
      "ecs":"aws.route53.answers.Rdata",
      "ocsf": "answers[].rdata"
    },
    {
      "raw_field":"answers[].Class",
      "ecs":"aws.route53.answers.Class",
      "ocsf": "answers[].class"
    },
    {
      "raw_field":"query",
      "ecs":"dns.question.name",
      "ocsf": "unmapped.query"
    },
    {
      "raw_field":"query_name",
      "ecs":"aws.route53.query_name",
      "ocsf": "query.hostname"
    },
    {
      "raw_field":"parent_domain",
      "ecs":"dns.question.registered_domain",
      "ocsf": "unmapped.parent_domain"
    },
    {
      "raw_field":"version",
      "ecs":"aws.route53.version",
      "ocsf": "metadata.product.version"
    },
    {
      "raw_field":"account_id",
      "ecs":"aws.route53.account_id",
      "ocsf": "cloud.account_uid"
    },
    {
      "raw_field":"region",
      "ecs":"aws.route53.region",
      "ocsf": "cloud.region"
    },
    {
      "raw_field":"vpc_id",
      "ecs":"aws.route53.vpc_id",
      "ocsf": "src_endpoint.vpc_uid"
    },
    {
      "raw_field":"query_timestamp",
      "ecs":"aws.route53.query_timestamp",
      "ocsf": "time"
    },
    {
      "raw_field":"query_class",
      "ecs":"aws.route53.query_class",
      "ocsf": "query.class"
    },
    {
      "raw_field":"query_type",
      "ecs":"aws.route53.query_type",
      "ocsf": "query.type"
    },
    {
      "raw_field":"srcaddr",
      "ecs":"aws.route53.srcaddr",
      "ocsf": "src_endpoint.ip"
    },
    {
      "raw_field":"srcport",
      "ecs":"aws.route53.srcport",
      "ocsf": "src_endpoint.port"
    },
    {
      "raw_field":"transport",
      "ecs":"aws.route53.transport",
      "ocsf": "connection_info.protocol_name"
    },
    {
      "raw_field":"srcids.instance",
      "ecs":"aws.route53.srcids.instance",
      "ocsf": "src_endpoint.instance_uid"
    },
    {
      "raw_field":"srcids.resolver_endpoint",
      "ecs":"aws.route53.srcids.resolver_endpoint",
      "ocsf": "dst_endpoint.instance_uid"
    },
    {
      "raw_field":"srcids.resolver_network_interface",
      "ecs":"aws.route53.srcids.resolver_network_interface",
      "ocsf": "dst_endpoint.interface_uid"
    },
    {
      "raw_field":"firewall_rule_action",
      "ecs":"aws.route53.srcids.firewall_rule_action",
      "ocsf": "disposition_id"
    },
    {
      "raw_field":"creationTime",
      "ecs":"timestamp",
      "ocsf": "unmapped.creationTime"
    }
  ]

----------------------------------------

TITLE: Testing SageMaker Reranker Model
DESCRIPTION: Python code to test the deployed reranker model with a sample query and document set.

LANGUAGE: python
CODE:
result = predictor.predict(data={
    "query":"What is the capital city of America?",
    "texts":[
        "Carson City is the capital city of the American state of Nevada.",
        "The Commonwealth of the Northern Mariana Islands is a group of islands in the Pacific Ocean. Its capital is Saipan.",
        "Washington, D.C. (also known as simply Washington or D.C., and officially as the District of Columbia) is the capital of the United States. It is a federal district.",
        "Capital punishment (the death penalty) has existed in the United States since beforethe United States was a country. As of 2017, capital punishment is legal in 30 of the 50 states."
    ]
})

print(json.dumps(result, indent=2))

----------------------------------------

TITLE: Creating IAM Role Trust Policy for Connector Requests
DESCRIPTION: This JSON snippet defines the trust policy for an IAM role used to sign Create Connector API requests.

LANGUAGE: json
CODE:
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Principal": {
                "AWS": "your_iam_user_arn"
            },
            "Action": "sts:AssumeRole"
        }
    ]
}

----------------------------------------

TITLE: Using Append with Order Modifier in Dissect Pattern
DESCRIPTION: Shows how to use the append with order modifier to control the order of appended values.

LANGUAGE: json
CODE:
PUT /_ingest/pipeline/dissect-test
{
  "description": "Pipeline that dissects web server logs",
  "processors": [
    {
      "dissect": {
        "field": "message",
        "pattern": "%{+address/3}, %{+address/2} %{+address/1}",
        "append_separator": "|"
      }
    }
  ]
}

----------------------------------------

TITLE: Example Repository Verification Request
DESCRIPTION: POST request example to verify a repository with timeout parameters

LANGUAGE: json
CODE:
POST /_snapshot/my-opensearch-repo/_verify?timeout=0s&cluster_manager_timeout=50s

----------------------------------------

TITLE: Testing French Analyzer Token Generation
DESCRIPTION: Shows how to analyze text using the French analyzer and view the generated tokens.

LANGUAGE: json
CODE:
POST /french-index/_analyze
{
  "field": "content",
  "text": "Les tudiants tudient  Paris et dans les universits franaises. Leurs numros sont 123456."
}

----------------------------------------

TITLE: Parsed Output from Grok Filter
DESCRIPTION: Shows the structured output after the Grok filter has parsed the log entry into individual fields.

LANGUAGE: yaml
CODE:
ip_address: 184.252.108.229
identity: joe
reg_ts: 20/Sep/2017:13:22:22 +0200
http_verb:GET
req_path: /products/view/123
http_status: 200
num_bytes: 12798

----------------------------------------

TITLE: Analyzing Text with Limit Token Filter in OpenSearch
DESCRIPTION: This snippet shows how to use the '_analyze' endpoint to test the custom analyzer with the limit token filter. It applies the analyzer to a sample text and returns the generated tokens.

LANGUAGE: json
CODE:
GET /my_index/_analyze
{
  "analyzer": "three_token_limit",
  "text": "OpenSearch is a powerful and flexible search engine."
}

----------------------------------------

TITLE: Starting OpenSearch Maps Server with Docker Volume
DESCRIPTION: This command starts the OpenSearch Maps Server using the Docker volume containing the map tiles.

LANGUAGE: bash
CODE:
docker run \
    -v tiles-data:/usr/src/app/public/tiles/data/ \
    -e HOST_URL='http://localhost' \
    -p 8080:8080 \
    opensearch/opensearch-maps-server \
    run

----------------------------------------

TITLE: Creating S3_CUSTOM Threat Intelligence Source
DESCRIPTION: Creates a new threat intelligence source using S3_CUSTOM type with scheduled refresh. Configures access to an S3 bucket for IOC data.

LANGUAGE: json
CODE:
POST _plugins/_security_analytics/threat_intel/sources/
{
 "type": "S3_CUSTOM",
 "name": "example-ipv4-from-SAP-account",
 "format": "STIX2",
 "store_type": "OS",
 "enabled": "true",
 "schedule": {
  "interval": {
   "start_time": 1717097122,
   "period": "10",
   "unit": "DAYS"
  }
 },
 "source": {
  "s3": {
   "bucket_name": "threat-intel-s3-test-bucket",
   "object_key": "alltypess3object",
   "region": "us-west-2",
   "role_arn": "arn:aws:iam::248279774929:role/threat_intel_s3_test_role"
  }
 },
 "ioc_types": [
  "domain-name",
  "ipv4-addr"
 ]
}

----------------------------------------

TITLE: Handling OpenSearch Dashboards XSRF Header Issue
DESCRIPTION: Shows how to modify a curl command to use the correct XSRF header when interacting with OpenSearch Dashboards API.

LANGUAGE: bash
CODE:
curl -XPOST -u 'admin:<custom-admin-password>' 'https://DASHBOARDS_ENDPOINT/api/saved_objects/_import' -H 'osd-xsrf:true' --form file=@export.ndjson

----------------------------------------

TITLE: Ingesting Data into Data Stream
DESCRIPTION: Demonstrates data ingestion into a data stream with required timestamp field.

LANGUAGE: json
CODE:
POST logs-staging/_doc
{
  "message": "login attempt failed",
  "@timestamp": "2013-03-01T00:00:00"
}

----------------------------------------

TITLE: Testing Split Pipeline
DESCRIPTION: Example request to test the split pipeline before actual document ingestion.

LANGUAGE: json
CODE:
POST _ingest/pipeline/split_pipeline/_simulate
{
  "docs": [
    {
      "_source": {
        "log_message": "error,warning,info"
      }
    }
  ]
}

----------------------------------------

TITLE: Generating Count Events with Count Action in JSON
DESCRIPTION: Example of how the count action processes events and generates a new event with count information in OTel metrics format.

LANGUAGE: json
CODE:
{"isMonotonic":true,"unit":"1","aggregationTemporality":"AGGREGATION_TEMPORALITY_DELTA","kind":"SUM","name":"count","description":"Number of events","startTime":"2022-12-02T19:29:51.245358486Z","time":"2022-12-02T19:30:15.247799684Z","value":3.0,"sourceIp":"127.0.0.1","destinationIp":"192.168.0.1"}

----------------------------------------

TITLE: Creating Default OpenSearch Client in Rust
DESCRIPTION: Create a default OpenSearch client that connects to http://localhost:9200.

LANGUAGE: rust
CODE:
let client = OpenSearch::default();

----------------------------------------

TITLE: Creating Index with Remove Duplicates Filter
DESCRIPTION: Creates an OpenSearch index that includes the remove_duplicates filter to eliminate duplicate tokens in the same position.

LANGUAGE: json
CODE:
PUT /index-remove-duplicate
{
  "settings": {
    "analysis": {
      "analyzer": {
        "custom_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "keyword_repeat",
            "kstem",
            "remove_duplicates"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating a General Pipeline
DESCRIPTION: Creates a general pipeline that contains common processors for uppercase conversion and field removal.

LANGUAGE: json
CODE:
{
  "description": "a general pipeline",
  "processors": [
    {
      "uppercase": {
        "field": "protocol"
      },
      "remove": {
        "field": "name"
      }
    }
  ]
}

----------------------------------------

TITLE: Mutating Events with add_entries Processor in YAML
DESCRIPTION: This snippet shows how to use the add_entries processor to add or modify event entries. It demonstrates setting a debug flag and creating new entries based on existing event data.

LANGUAGE: yaml
CODE:
...
processor:
  - add_entries:
      entries:
        - key: "debug"
          value: true 
...
processor:
  - add_entries:
      entries:
        - key: "debug"
          value: true 
          overwrite_if_key_exists: true
...
processor:
  - add_entries:
      entries:
        - key: "key_three"
          format: "${key_one}-${key_two}

----------------------------------------

TITLE: Predicate Token Filter Analysis Response
DESCRIPTION: Shows the response from the analyze API, displaying the tokens that passed the predicate condition. Each token includes position and offset information.

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "opensearch",
      "start_offset": 4,
      "end_offset": 14,
      "type": "<ALPHANUM>",
      "position": 1
    },
    {
      "token": "community",
      "start_offset": 15,
      "end_offset": 24,
      "type": "<ALPHANUM>",
      "position": 2
    }
  ]
}

----------------------------------------

TITLE: Using Default Environment Values
DESCRIPTION: Command using default environment values from .env file

LANGUAGE: bash
CODE:
opensearch-reporting-cli --url https://localhost:5601/app/dashboards#/view/7adfa750-4c81-11e8-b3d7-01146121b73d

----------------------------------------

TITLE: Workflow Provisioning Endpoint
DESCRIPTION: Basic endpoint structure for provisioning a workflow in OpenSearch Flow Framework.

LANGUAGE: json
CODE:
POST /_plugins/_flow_framework/workflow/<workflow_id>/_provision

----------------------------------------

TITLE: Address Search Query
DESCRIPTION: Query to search addresses containing 'street' or 'st' but not 'madison'.

LANGUAGE: json
CODE:
GET /customers/_search
{
  "query": {
    "simple_query_string": {
      "fields": [ "address" ],
      "query": "street st -madison"
    }
  }
}

----------------------------------------

TITLE: Refreshing All Indexes and Data Streams in OpenSearch Cluster
DESCRIPTION: This example shows how to refresh all data streams and indexes in an OpenSearch cluster using the Refresh Index API.

LANGUAGE: json
CODE:
POST /_refresh

----------------------------------------

TITLE: Creating an Index with Whitespace Analyzer in OpenSearch
DESCRIPTION: This snippet demonstrates how to create an index named 'my_whitespace_index' with a field using the whitespace analyzer. The analyzer breaks text into tokens based only on white space characters, preserving original case and punctuation.

LANGUAGE: json
CODE:
PUT /my_whitespace_index
{
  "mappings": {
    "properties": {
      "my_field": {
        "type": "text",
        "analyzer": "whitespace"
      }
    }
  }
}

----------------------------------------

TITLE: OpenSearch Create/Update Alias API Endpoints
DESCRIPTION: Lists all available HTTP endpoints for creating or updating aliases in OpenSearch. Includes POST and PUT methods with various path patterns.

LANGUAGE: json
CODE:
POST /<target>/_alias/<alias-name>
PUT /<target>/_alias/<alias-name>
POST /_alias/<alias-name>
PUT /_alias/<alias-name>
POST /<target>/_aliases/<alias-name>
PUT /<target>/_aliases/<alias-name>
POST /_aliases/<alias-name>
PUT /_aliases/<alias-name>
PUT /<target>/_alias
PUT /<target>/_aliases
PUT /_alias

----------------------------------------

TITLE: Expected Output After Dissect Processing
DESCRIPTION: Shows the expected JSON output after the dissect processor has extracted fields from the log message.

LANGUAGE: json
CODE:
{
    "log" : "07-25-2023 10:00:00 ERROR: Some error",
    "Date" : "07-25-2023"
    "Time" : "10:00:00"
    "Log_Type" : "ERROR"
    "Message" : "error message"
}

----------------------------------------

TITLE: Processed User Agent Output
DESCRIPTION: Example JSON output showing the parsed user agent information in ECS-compatible format, including device, OS, and browser details.

LANGUAGE: json
CODE:
{
  "user_agent": {
    "original": "Mozilla/5.0 (iPhone; CPU iPhone OS 13_5_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.1.1 Mobile/15E148 Safari/604.1",
    "os": {
        "version": "13.5.1",
        "full": "iOS 13.5.1",
        "name": "iOS"
    },
    "name": "Mobile Safari",
    "version": "13.1.1",
    "device": {
        "name": "iPhone"
    }
  },
  "ua":  "Mozilla/5.0 (iPhone; CPU iPhone OS 13_5_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.1.1 Mobile/15E148 Safari/604.1"
}

----------------------------------------

TITLE: XML Input Example
DESCRIPTION: Shows a sample input event containing XML data that will be processed by the parse_xml processor.

LANGUAGE: json
CODE:
{ "my_xml": "<Person><name>John Doe</name><age>30</age></Person>" }

----------------------------------------

TITLE: Creating an Index with Multiplexer Filter in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a new index named 'multiplexer_index' with a custom analyzer that uses the multiplexer filter. The analyzer applies both an English stemmer and a synonym filter to the tokens.

LANGUAGE: json
CODE:
PUT /multiplexer_index
{
  "settings": {
    "analysis": {
      "filter": {
        "english_stemmer": {
          "type": "stemmer",
          "name": "english"
        },
        "synonym_filter": {
          "type": "synonym",
          "synonyms": [
            "quick,fast"
          ]
        },
        "multiplexer_filter": {
          "type": "multiplexer",
          "filters": ["english_stemmer", "synonym_filter"],
          "preserve_original": true
        }
      },
      "analyzer": {
        "multiplexer_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "multiplexer_filter"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Downloading OpenSearch Tarball
DESCRIPTION: Commands to download the OpenSearch tarball for x64 or ARM64 architectures using wget.

LANGUAGE: bash
CODE:
# x64
wget https://artifacts.opensearch.org/releases/bundle/opensearch/{{site.opensearch_version}}/opensearch-{{site.opensearch_version}}-linux-x64.tar.gz

# ARM64
wget https://artifacts.opensearch.org/releases/bundle/opensearch/{{site.opensearch_version}}/opensearch-{{site.opensearch_version}}-linux-arm64.tar.gz

----------------------------------------

TITLE: JSON Transformation Configuration
DESCRIPTION: Example Jolt transformation script for modifying request structure and URI paths during traffic replay

LANGUAGE: json
CODE:
[{ "JsonJoltTransformerProvider":
[
  {
    "script": {
      "operation": "shift",
      "spec": {
        "payload": {
          "inlinedJsonBody": {
            "top": {
              "tagToExcise": {
                "*": "payload.inlinedJsonBody.top.&" 
              },
              "*": "payload.inlinedJsonBody.top.&"
            },
            "*": "payload.inlinedJsonBody.&"
          },
          "*": "payload.&"
        },
        "*": "&"
      }
    }
  }, 
 {
   "script": {
     "operation": "modify-overwrite-beta",
     "spec": {
       "URI": "=split('/extraThingToRemove',@(1,&))"
     }
  }
 },
 {
   "script": {
     "operation": "modify-overwrite-beta",
     "spec": {
       "URI": "=join('',@(1,&))"
     }
  }
 }]
}]

----------------------------------------

TITLE: Searching Boolean Fields in OpenSearch
DESCRIPTION: Example of searching for documents with a specific Boolean value using term query.

LANGUAGE: json
CODE:
GET testindex/_search 
{
  "query": {
      "term" : {
        "c" : false
    }
  }
}

----------------------------------------

TITLE: Aggregations on derived fields
DESCRIPTION: Shows how to perform a simple terms aggregation on the 'method' derived field.

LANGUAGE: json
CODE:
POST /logs/_search
{
  "size": 0,
  "aggs": {
    "methods": {
      "terms": {
        "field": "method"
      }
    }
  }
}

----------------------------------------

TITLE: Vega-Lite Visualization Specification
DESCRIPTION: Example Vega-Lite specification for creating a line chart with circles showing average bytes over time from OpenSearch log data. Includes data source configuration, aggregations, and visualization settings.

LANGUAGE: json
CODE:
{
  $schema: https://vega.github.io/schema/vega-lite/v5.json
  data: {
    url: {
      %context%: true
      %timefield%: @timestamp
      index: opensearch_dashboards_sample_data_logs
      data_source_name: YOUR_DATA_SOURCE_TITLE
      body: {
        aggs: {
          1: {
            date_histogram: {
              field: @timestamp
              fixed_interval: 3h
              time_zone: America/Los_Angeles
              min_doc_count: 1
            }
            aggs: {
              2: {
                avg: {
                  field: bytes
                }
              }
            }
          }
        }
        size: 0
      }
    }
    format: {
      property: aggregations.1.buckets
    }
  }
  transform: [
    {
      calculate: datum.key
      as: timestamp
    }
    {
      calculate: datum[2].value
      as: bytes
    }
  ]
  layer: [
    {
      mark: {
        type: line
      }
    }
    {
      mark: {
        type: circle
        tooltip: true
      }
    }
  ]
  encoding: {
    x: {
      field: timestamp
      type: temporal
      axis: {
        title: @timestamp
      }
    }
    y: {
      field: bytes
      type: quantitative
      axis: {
        title: Average bytes
      }
    }
    color: {
      datum: Average bytes
      type: nominal
    }
  }
}

----------------------------------------

TITLE: Configuring Logstash Input, Filter, and Output
DESCRIPTION: Example Logstash configuration showing input from file and HTTP, filtering to remove a field, and output to stdout and file with dynamic naming based on event type.

LANGUAGE: yaml
CODE:
input {
  file {
    path => ""
  start_position => "beginning"
  type => "access"
  }
  http {
    type => "access"
  }
}

filter {
  mutate {
    remove_field => {"host"}
  }
}

output {
  stdout {
    codec => rubydebug
  }
file {
  path => "%{[type]}.log"
  }
}

----------------------------------------

TITLE: Validating Invalid Query in OpenSearch
DESCRIPTION: Shows an example of validating an invalid query in OpenSearch. This query includes a dynamic mapping not configured in the 'hamlet' index, resulting in a validation failure.

LANGUAGE: json
CODE:
GET hamlet/_validate/query
{
  "query": {
    "query_string": {
      "query": "@timestamp:foo",
      "lenient": false
    }
  }
}

----------------------------------------

TITLE: Updating Additional Info Field - JSON
DESCRIPTION: Example request demonstrating how to modify an existing field within the additional_info object of a message.

LANGUAGE: json
CODE:
PUT /_plugins/_ml/memory/message/WnA3cY0BfUsSoeNTI-_J
{
  "additional_info": {
    "feedback": "negative"
  }
}

----------------------------------------

TITLE: Source Filtering with Includes and Excludes
DESCRIPTION: Example of retrieving specific fields using source filtering with includes and excludes parameters.

LANGUAGE: json
CODE:
GET test-index/_doc/0?_source_includes=*.play&_source_excludes=entities

----------------------------------------

TITLE: Setting Global Admin Access in YAML
DESCRIPTION: This YAML configuration grants admin access to all users using a wildcard setting.

LANGUAGE: yaml
CODE:
opensearchDashboards.dashboardAdmin.users: ["*"]

----------------------------------------

TITLE: Configuring system settings for OpenSearch
DESCRIPTION: Commands to disable memory swapping and increase the number of memory maps available to OpenSearch.

LANGUAGE: bash
CODE:
sudo swapoff -a

LANGUAGE: bash
CODE:
sudo vim /etc/sysctl.conf

LANGUAGE: bash
CODE:
vm.max_map_count=262144

LANGUAGE: bash
CODE:
sudo sysctl -p

----------------------------------------

TITLE: Creating an Index with Synonym Graph Filter (Solr Format)
DESCRIPTION: This example demonstrates how to create a new index named 'my-index' with a custom analyzer that includes a synonym_graph filter using the Solr format for synonym rules.

LANGUAGE: json
CODE:
PUT /my-index
{
  "settings": {
    "analysis": {
      "filter": {
        "my_synonym_graph_filter": {
          "type": "synonym_graph",
          "synonyms": [
            "sports car, race car",
            "fast car, speedy vehicle",
            "luxury car, premium vehicle",
            "electric car, EV"
          ]
        }
      },
      "analyzer": {
        "my_synonym_graph_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "my_synonym_graph_filter"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Query String Body Request in OpenSearch
DESCRIPTION: Shows how to pass request body in query string for clients that don't accept request bodies in non-POST requests.

LANGUAGE: json
CODE:
GET shakespeare/search?source={"query":{"exists":{"field":"speaker"}}}&source_content_type=application/json

----------------------------------------

TITLE: Deleting a Specific Snapshot from a Repository in OpenSearch
DESCRIPTION: This example shows a DELETE request to remove a snapshot named 'my-first-snapshot' from the 'my-opensearch-repo' repository. It demonstrates the actual usage of the Delete Snapshot API.

LANGUAGE: json
CODE:
DELETE _snapshot/my-opensearch-repo/my-first-snapshot

----------------------------------------

TITLE: Configuring Stem Exclusion for Sorani Analyzer in OpenSearch
DESCRIPTION: This example shows how to use the 'stem_exclusion' feature with the Sorani language analyzer. It creates an index with a custom analyzer that excludes specific words from stemming.

LANGUAGE: json
CODE:
PUT index_with_stem_exclusion_sorani_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "stem_exclusion_sorani_analyzer": {
          "type": "sorani",
          "stem_exclusion": ["", ""]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Bulk Indexing Documents in OpenSearch
DESCRIPTION: Shows how to use the bulk API to index multiple documents into an OpenSearch index named 'hamlet'. This setup is used for subsequent query validation examples.

LANGUAGE: json
CODE:
PUT hamlet/_bulk?refresh
{"index":{"_id":1}}
{"user" : { "id": "hamlet" }, "@timestamp" : "2099-11-15T14:12:12", "message" : "To Search or Not To Search"}
{"index":{"_id":2}}
{"user" : { "id": "hamlet" }, "@timestamp" : "2099-11-15T14:12:13", "message" : "My dad says that I'm such a ham."}

----------------------------------------

TITLE: Adding Version to Component Template in OpenSearch
DESCRIPTION: This example shows how to add a version number to a component template, which is useful for template management in external systems.

LANGUAGE: json
CODE:
PUT /_component_template/version_template
{
  "template": {
    "settings" : {
        "number_of_shards" : 1
    }
  },
  "version": 3
}

----------------------------------------

TITLE: Processing Search Results in OpenSearch using Rust
DESCRIPTION: Process and print search results from an OpenSearch query.

LANGUAGE: rust
CODE:
let response_body = response.json::<Value>().await?
for hit in response_body["hits"]["hits"].as_array().unwrap() {
    println!("{}", serde_json::to_string_pretty(&hit["_source"]).unwrap());
}

----------------------------------------

TITLE: Clearing k-NN Cache in OpenSearch
DESCRIPTION: Demonstrates how to evict native library indexes of specified indexes from the cache using the clear cache API.

LANGUAGE: json
CODE:
POST /_plugins/_knn/clear_cache/index1,index2,index3?pretty

----------------------------------------

TITLE: Defining Timestamp Type in SQL for OpenSearch
DESCRIPTION: Specifies the syntax and range for the 'timestamp' type in SQL for OpenSearch. The timestamp type represents an absolute time point including time zone information.

LANGUAGE: sql
CODE:
timestamp | yyyy-MM-dd hh:mm:ss[.fraction] | 0001-01-01 00:00:01.9999999999 UTC to 9999-12-31 23:59:59.9999999999

----------------------------------------

TITLE: Configuring Dashboard Administrators in YAML
DESCRIPTION: This YAML configuration defines dashboard administrators by user ID and backend role, and enables saved object permissions.

LANGUAGE: yaml
CODE:
opensearchDashboards.dashboardAdmin.users: ["UserID"]
opensearchDashboards.dashboardAdmin.groups: ["BackendRole"]
savedObjects.permission.enabled: true

----------------------------------------

TITLE: Creating Index with Keyword Repeat Filter
DESCRIPTION: Creates an OpenSearch index with a custom analyzer that uses keyword_repeat and kstem filters to generate multiple versions of tokens.

LANGUAGE: json
CODE:
PUT /example-index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "custom_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "keyword_repeat",
            "kstem"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating Index with Stemmer Filter in OpenSearch
DESCRIPTION: Example request to create a new index with a custom analyzer that includes an English stemmer filter. The analyzer combines a standard tokenizer with lowercase and stemming filters.

LANGUAGE: json
CODE:
PUT /my-stemmer-index
{
  "settings": {
    "analysis": {
      "filter": {
        "my_english_stemmer": {
          "type": "stemmer",
          "language": "english"
        }
      },
      "analyzer": {
        "my_stemmer_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "my_english_stemmer"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Using flattened_element in list_to_map Processor
DESCRIPTION: YAML configuration demonstrating the use of flattened_element set to 'last' in the list_to_map processor.

LANGUAGE: yaml
CODE:
pipeline:
  source:
    file:
      path: "/full/path/to/logs_json.log"
      record_type: "event"
      format: "json"
  processor:
    - list_to_map:
        key: "name"
        source: "mylist"
        target: "mymap"
        value_key: "value"
        flatten: true
        flattened_element: "last"
  sink:
    - stdout:

----------------------------------------

TITLE: Querying CAT Repositories Endpoint in OpenSearch
DESCRIPTION: The basic endpoint for retrieving snapshot repository information from OpenSearch.

LANGUAGE: json
CODE:
GET /_cat/repositories

----------------------------------------

TITLE: Configuring Linux Syslog Field Mappings to ECS
DESCRIPTION: Defines the mapping configuration between raw Linux syslog fields and their corresponding ECS (Elastic Common Schema) fields. The mappings include user information, audit logs, process details, and system authentication data.

LANGUAGE: json
CODE:
  "mappings": [
    {
      "raw_field":"name",
      "ecs":"user.filesystem.name"
    },
    {
      "raw_field":"a0",
      "ecs":"auditd.log.a0"
    },
    {
      "raw_field":"comm",
      "ecs":"auditd.log.comm"
    },
    {
      "raw_field":"exe",
      "ecs":"auditd.log.exe"
    },
    {
      "raw_field":"uid",
      "ecs":"auditd.log.uid"
    },
    {
      "raw_field":"USER",
      "ecs":"system.auth.user"
    },
    {
      "raw_field":"User",
      "ecs":"system.auth.user"
    },
    {
      "raw_field":"Image",
      "ecs":"process.exe"
    },
    {
      "raw_field":"DestinationHostname",
      "ecs":"rsa.web.remote_domain"
    },
    {
      "raw_field":"CommandLine",
      "ecs":"process.command_line"
    },
    {
      "raw_field":"ParentImage",
      "ecs":"process.parent.executable"
    },
    {
      "raw_field":"CurrentDirectory",
      "ecs":"process.working_directory"
    },
    {
      "raw_field":"LogonId",
      "ecs":"process.real_user.id"
    },
    {
      "raw_field":"creationTime",
      "ecs":"timestamp"
    }
  ]

----------------------------------------

TITLE: Markdown Page Layout Configuration
DESCRIPTION: Front matter configuration for the documentation page defining layout, title, navigation, and parent-child relationships.

LANGUAGE: markdown
CODE:
---
layout: default
title: Functions
parent: Pipelines
nav_order: 10
has_children: true
---

----------------------------------------

TITLE: Analyzing Text with Custom Email Analyzer in OpenSearch
DESCRIPTION: This snippet shows how to use the _analyze API to test the custom email analyzer. It demonstrates analyzing an email address to see the tokens generated by the pattern_capture filter.

LANGUAGE: json
CODE:
POST /email_index/_analyze
{
  "text": "john.doe@example.com",
  "analyzer": "email_analyzer"
}

----------------------------------------

TITLE: Disabling PPL via Query Plugin Endpoint
DESCRIPTION: Demonstrates an alternative format for updating query plugin settings, specifically disabling the PPL feature.

LANGUAGE: json
CODE:
PUT _plugins/_query/settings
{
  "transient": {
    "plugins": {
      "ppl": {
        "enabled": "false"
      }
    }
  }
}

----------------------------------------

TITLE: Example Response from Delete Document API in OpenSearch
DESCRIPTION: This JSON response shows the result of a successful delete operation, including the index name, document ID, version, and shard information.

LANGUAGE: json
CODE:
{
  "_index": "sample-index1",
  "_id": "1",
  "_version": 2,
  "result": "deleted",
  "_shards": {
    "total": 2,
    "successful": 2,
    "failed": 0
  },
  "_seq_no": 1,
  "_primary_term": 15
}

----------------------------------------

TITLE: Sample CAT Plugins Response
DESCRIPTION: Example response showing installed plugins across multiple nodes with their components and versions.

LANGUAGE: json
CODE:
name       component                       version
odfe-node2 opendistro-alerting             1.13.1.0
odfe-node2 opendistro-anomaly-detection    1.13.0.0
odfe-node2 opendistro-asynchronous-search  1.13.0.1
odfe-node2 opendistro-index-management     1.13.2.0
odfe-node2 opendistro-job-scheduler        1.13.0.0
odfe-node2 opendistro-knn                  1.13.0.0
odfe-node2 opendistro-performance-analyzer 1.13.0.0
odfe-node2 opendistro-reports-scheduler    1.13.0.0
odfe-node2 opendistro-sql                  1.13.2.0
odfe-node2 opendistro_security             1.13.1.0
odfe-node1 opendistro-alerting             1.13.1.0
odfe-node1 opendistro-anomaly-detection    1.13.0.0
odfe-node1 opendistro-asynchronous-search  1.13.0.1
odfe-node1 opendistro-index-management     1.13.2.0
odfe-node1 opendistro-job-scheduler        1.13.0.0
odfe-node1 opendistro-knn                  1.13.0.0
odfe-node1 opendistro-performance-analyzer 1.13.0.0
odfe-node1 opendistro-reports-scheduler    1.13.0.0
odfe-node1 opendistro-sql                  1.13.2.0
odfe-node1 opendistro_security             1.13.1.0

----------------------------------------

TITLE: Querying Specific Headers for CAT API Aliases in OpenSearch
DESCRIPTION: This example shows how to limit the output of CAT API aliases to specific headers. It uses the 'h' query parameter to specify desired headers.

LANGUAGE: json
CODE:
GET _cat/aliases?h=alias,index

----------------------------------------

TITLE: Example Response from OpenSearch Flush API
DESCRIPTION: A sample response from the Flush API in OpenSearch, showing the number of shards that acknowledged, completed, and failed the flush request.

LANGUAGE: json
CODE:
{
  "_shards": {
    "total": 10,
    "successful": 10,
    "failed": 0
  }
}

----------------------------------------

TITLE: Creating an Index with Pattern Tokenizer in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a new index with a custom analyzer using the pattern tokenizer. The tokenizer is configured to split text on '-', '_', or '.' characters.

LANGUAGE: json
CODE:
PUT /my_index
{
  "settings": {
    "analysis": {
      "tokenizer": {
        "my_pattern_tokenizer": {
          "type": "pattern",
          "pattern": "[-_.]"
        }
      },
      "analyzer": {
        "my_pattern_analyzer": {
          "type": "custom",
          "tokenizer": "my_pattern_tokenizer"
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "my_pattern_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Testing Persian Analyzer Token Generation
DESCRIPTION: Example of analyzing Persian text and viewing the generated tokens.

LANGUAGE: json
CODE:
POST /persian-index/_analyze
{
  "field": "content",
  "text": "     .    ."
}

----------------------------------------

TITLE: Configuring Pipeline Sink in OpenSearch YAML
DESCRIPTION: Example configuration showing how to set up a pipeline sink that writes to another pipeline named 'movies'. The configuration requires specifying the target pipeline name using the name parameter.

LANGUAGE: yaml
CODE:
sample-pipeline:
  sink:
    - pipeline:
        name: movies

----------------------------------------

TITLE: Creating an OpenSearch Index with Segment Replication
DESCRIPTION: This snippet demonstrates how to create an OpenSearch index with segment replication enabled. The 'replication.type' parameter is set to 'SEGMENT' in the index settings.

LANGUAGE: json
CODE:
PUT /my-index1
{
  "settings": {
    "index": {
      "replication.type": "SEGMENT" 
    }
  }
}

----------------------------------------

TITLE: Ingesting Multiple Files from OpenAI to OpenSearch
DESCRIPTION: Example request showing how to ingest multiple files from OpenAI into OpenSearch with complex field mappings.

LANGUAGE: json
CODE:
{
  "index_name": "my-nlp-index-openai",
  "field_map": {
    "question": "source[1].$.body.input[0]",
    "answer": "source[1].$.body.input[1]",
    "question_embedding":"source[0].$.response.body.data[0].embedding",
    "answer_embedding":"source[0].$.response.body.data[1].embedding",
    "_id": ["source[0].$.custom_id", "source[1].$.custom_id"]
  },
  "ingest_fields": ["source[2].$.custom_field1", "source[2].$.custom_field2"],
  "credential": {
    "openAI_key": "<you openAI key>"
  },
  "data_source": {
    "type": "openAI",
    "source": ["file-<your output file id>", "file-<your input file id>", "file-<your other file>"]
  }
}

----------------------------------------

TITLE: GET Workflow Status with All Fields
DESCRIPTION: Example request showing how to retrieve all available status fields using the 'all' query parameter.

LANGUAGE: json
CODE:
GET /_plugins/_flow_framework/workflow/8xL8bowB8y25Tqfenm50/_status?all=true

----------------------------------------

TITLE: Analyzing Text with Lowercase Tokenizer
DESCRIPTION: Example request to analyze text using the configured lowercase analyzer. Shows how to test the tokenizer with a sample text string.

LANGUAGE: json
CODE:
POST /my-lowercase-index/_analyze
{
  "analyzer": "my_lowercase_analyzer",
  "text": "This is a Test. OpenSearch 123!"
}

----------------------------------------

TITLE: Output JSON Example after Rename Keys
DESCRIPTION: Sample JSON output showing the event structure after key renaming.

LANGUAGE: json
CODE:
{"newMessage": "hello"}

----------------------------------------

TITLE: Indexing Document for Autocomplete
DESCRIPTION: Indexes a sample document into the autocomplete-enabled index.

LANGUAGE: json
CODE:
PUT my-autocomplete-index/_doc/1?refresh
{
  "title": "Laptop Pro"
}

----------------------------------------

TITLE: Creating Index with Shingle Filter Configuration
DESCRIPTION: Creates a new index with a custom analyzer that includes a shingle filter configuration. The analyzer combines standard tokenization, lowercase filtering, and shingle generation.

LANGUAGE: json
CODE:
PUT /my-shingle-index
{
  "settings": {
    "analysis": {
      "filter": {
        "my_shingle_filter": {
          "type": "shingle",
          "min_shingle_size": 2,
          "max_shingle_size": 2,
          "output_unigrams": true
        }
      },
      "analyzer": {
        "my_shingle_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "my_shingle_filter"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Retrieving Document After Append Processing in OpenSearch
DESCRIPTION: Example of retrieving a document after it has been processed by the append processor pipeline.

LANGUAGE: json
CODE:
GET testindex1/_doc/1

----------------------------------------

TITLE: Configuring External Scheduler Interval in OpenSearch
DESCRIPTION: REST API call to set the interval for external scheduler checks on asynchronous queries.

LANGUAGE: json
CODE:
PUT /_cluster/settings
{
  "transient": {
    "plugins.query.executionengine.async_query.external_scheduler.interval": "10 minutes"
  }
}

----------------------------------------

TITLE: Stopping OpenSearch Dashboards with Docker Compose
DESCRIPTION: Command to stop and remove the OpenSearch Dashboards containers started with Docker Compose.

LANGUAGE: bash
CODE:
docker compose down

----------------------------------------

TITLE: Enabling Tracing Framework in opensearch.yaml
DESCRIPTION: Add this setting to opensearch.yaml to enable the tracing framework feature.

LANGUAGE: yaml
CODE:
telemetry.feature.tracer.enabled=true

----------------------------------------

TITLE: Configuring Logstash Pipeline for JSON Input and File Output
DESCRIPTION: Shows a Logstash pipeline configuration that accepts JSON input and writes output to a file using the json codec and file output plugin.

LANGUAGE: yaml
CODE:
input {
  stdin {
    codec => json
  }
}
output {
  file {
    path => "output.txt"
  }
}

----------------------------------------

TITLE: CAT Shards Response Format - JSON
DESCRIPTION: Example response showing the format of returned shard information including index, shard number, primary/replica status, state, document count, size, and node details.

LANGUAGE: json
CODE:
index | shard | prirep | state   | docs | store | ip |       | node
plugins | 0   |   p    | STARTED |   0  |  208b | 172.18.0.4 | odfe-node1
plugins | 0   |   r    | STARTED |   0  |  208b | 172.18.0.3 |  odfe-node2

----------------------------------------

TITLE: Querying OpenSearch Server with Security Disabled
DESCRIPTION: These cURL commands send requests to the OpenSearch server to verify its operation with security disabled, using HTTP without authentication.

LANGUAGE: batch
CODE:
curl.exe -X GET http://localhost:9200

LANGUAGE: batch
CODE:
curl.exe -X GET http://localhost:9200/_cat/plugins?v

----------------------------------------

TITLE: Human Resources Role Configuration
DESCRIPTION: Example YAML configuration for creating a role with specific index permissions for human resources data.

LANGUAGE: yaml
CODE:
human_resources:
  index_permissions:
    - index_patterns:
      - "humanresources"
      allowed_actions:
        - "READ"

----------------------------------------

TITLE: Searching IP Address with CIDR Notation in OpenSearch (IPv4)
DESCRIPTION: This example demonstrates how to query an OpenSearch index for an IP address using CIDR notation in IPv4 format. It searches for IP addresses within the '10.24.34.0/24' network.

LANGUAGE: json
CODE:
GET testindex/_search 
{
  "query": {
    "term": {
      "ip_address": "10.24.34.0/24"
    }
  }
}

----------------------------------------

TITLE: Configuring SSL/TLS Connection
DESCRIPTION: YAML configuration for enabling SSL with keystore settings for secure connections

LANGUAGE: yaml
CODE:
ssl: true
keyStoreFilePath: "/usr/share/data-prepper/keystore.p12"
keyStorePassword: "secret"
privateKeyPassword: "secret"

----------------------------------------

TITLE: Managing Policy Execution
DESCRIPTION: API endpoints for starting, stopping and deleting snapshot management policies. These endpoints control the policy lifecycle.

LANGUAGE: json
CODE:
POST _plugins/_sm/policies/<policy_name>/_start

LANGUAGE: json
CODE:
POST _plugins/_sm/policies/<policy_name>/_stop

LANGUAGE: json
CODE:
DELETE _plugins/_sm/policies/<policy_name>

----------------------------------------

TITLE: Get Workflow Endpoint
DESCRIPTION: The main endpoint for retrieving a workflow template by its ID.

LANGUAGE: json
CODE:
GET /_plugins/_flow_framework/workflow/<workflow_id>

----------------------------------------

TITLE: Get Dashboardsinfo Response
DESCRIPTION: Example response showing detailed multi-tenancy and user configuration information from the Dashboardsinfo API.

LANGUAGE: json
CODE:
{
  "user_name" : "admin",
  "not_fail_on_forbidden_enabled" : false,
  "opensearch_dashboards_mt_enabled" : true,
  "opensearch_dashboards_index" : ".kibana",
  "opensearch_dashboards_server_user" : "kibanaserver",
  "multitenancy_enabled" : true,
  "private_tenant_enabled" : true,
  "default_tenant" : "Private"
}

----------------------------------------

TITLE: Retrieving specific template information using CAT API in OpenSearch
DESCRIPTION: This example shows how to retrieve information for a specific template or pattern using the CAT API.

LANGUAGE: json
CODE:
GET _cat/templates/<template_name_or_pattern>

----------------------------------------

TITLE: Deleting frame-ancestors from CSP rules using cURL
DESCRIPTION: cURL command to delete the frame-ancestors directive from CSP rules in OpenSearch Dashboards.

LANGUAGE: bash
CODE:
curl '{osd endpoint}/api/appconfig/csp.rules.frame-ancestors' -X DELETE -H 'osd-xsrf: osd-fetch' -H 'Sec-Fetch-Dest: empty'

----------------------------------------

TITLE: Task Cancellation Endpoint
DESCRIPTION: POST endpoint to cancel all cancelable tasks in the cluster.

LANGUAGE: json
CODE:
POST _tasks/_cancel

----------------------------------------

TITLE: Deleting Index Templates in OpenSearch - HTTP Endpoint
DESCRIPTION: HTTP DELETE endpoint for removing one or more index templates. Template names can be provided as comma-separated values when deleting multiple templates, though wildcards are not supported for multiple deletions.

LANGUAGE: json
CODE:
DELETE /_index_template/<template-name>

----------------------------------------

TITLE: Creating Custom Turkish Analyzer in OpenSearch
DESCRIPTION: This snippet illustrates how to create a custom Turkish analyzer with specific token filters and apply it to a text field in OpenSearch.

LANGUAGE: json
CODE:
PUT /turkish-index
{
  "settings": {
    "analysis": {
      "filter": {
        "turkish_stop": {
          "type": "stop",
          "stopwords": "_turkish_"
        },
        "turkish_stemmer": {
          "type": "stemmer",
          "language": "turkish"
        },
        "turkish_lowercase": {
          "type":       "lowercase",
          "language":   "turkish"
        },
        "turkish_keywords": {
          "type": "keyword_marker",
          "keywords": []
        }
      },
      "analyzer": {
        "turkish_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "apostrophe",
            "turkish_lowercase",
            "turkish_stop",
            "turkish_keywords",
            "turkish_stemmer"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "turkish_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Deleting an Index in OpenSearch using Rust
DESCRIPTION: Delete an entire index from OpenSearch using the indices().delete() function.

LANGUAGE: rust
CODE:
let response = client
    .indices()
    .delete(IndicesDeleteParts::Index(&["movies"]))
    .send()
    .await?;

----------------------------------------

TITLE: Creating an OpenSearch Index
DESCRIPTION: Use the client's indices.create() method to create a new OpenSearch index with custom settings. This example creates an index with 4 shards.

LANGUAGE: python
CODE:
index_name = 'python-test-index'
index_body = {
  'settings': {
    'index': {
      'number_of_shards': 4
    }
  }
}

response = client.indices.create(index_name, body=index_body)

----------------------------------------

TITLE: Configuring Allowed API Fields for Cluster Metrics Monitors
DESCRIPTION: This JSON snippet demonstrates how to configure the supported_json_payloads.json file to restrict which API fields can be used in cluster metrics monitors and trigger conditions.

LANGUAGE: json
CODE:
"/_cluster/stats": {
  "indices": [
    "shards.total",
    "shards.index.shards.min"
  ]
}

----------------------------------------

TITLE: Retrieving Meta Information for an Index in OpenSearch
DESCRIPTION: This snippet demonstrates how to retrieve the _meta information for an index using the Get Mapping API. It shows both the API call and the expected response format.

LANGUAGE: json
CODE:
GET my-index/_mapping

LANGUAGE: json
CODE:
{
  "my-index": {
    "mappings": {
      "_meta": {
        "application": "MyApp",
        "version": "1.3.0",
        "author": "Jane Smith"
      },
      "properties": {
        "description": {
          "type": "text"
        },
        "title": {
          "type": "text"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Async Query Execution in OpenSearch
DESCRIPTION: REST API call to enable asynchronous query execution through cluster settings.

LANGUAGE: json
CODE:
PUT /_cluster/settings
{
  "transient": {
    "plugins.query.executionengine.async_query.enabled": "true"
  }
}

----------------------------------------

TITLE: Exponential Histogram JSON Structure
DESCRIPTION: Example showing the JSON structure for exponential histograms including negative and positive buckets with their boundaries and counts.

LANGUAGE: json
CODE:
"negativeBuckets": [
        {
        "min": 0.0,
        "max": 5.0,
        "count": 2
        },
        {
        "min": 5.0,
        "max": 10.0,
        "count": 5
        }
    ],
    "positiveBuckets": [
        {
        "min": 0.0,
        "max": 5.0,
        "count": 2
        },
        {
        "min": 5.0,
        "max": 10.0,
        "count": 5
        }
    ]

----------------------------------------

TITLE: Querying CAT Health Endpoint in OpenSearch
DESCRIPTION: This snippet shows the GET endpoint for the CAT Health API in OpenSearch. It allows querying the health status of the cluster.

LANGUAGE: json
CODE:
GET /_cat/health

----------------------------------------

TITLE: Enabling Backend Role Filtering for Security Analytics in OpenSearch
DESCRIPTION: This JSON snippet shows how to enable backend role filtering for Security Analytics using the OpenSearch cluster settings API. This setting allows fine-grained access control based on user roles.

LANGUAGE: json
CODE:
PUT /_cluster/settings
{
  "transient": {
    "plugins.security_analytics.filter_by_backend_roles": "true"
  }
}

----------------------------------------

TITLE: Output JSON after List Processing with copy_values
DESCRIPTION: This JSON snippet demonstrates the result of applying the copy_values processor configured for list operations, showing how selected fields are copied to a new list.

LANGUAGE: json
CODE:
{
  "newlist": [
    {"fruit_name": "apple"},
    {"fruit_name": "orange"}
  ],
  "mylist": [
    {"name": "apple", "color": "red"},
    {"name": "orange", "color": "orange"}
  ]
}

----------------------------------------

TITLE: Testing Spark Connection with PPL Query
DESCRIPTION: Shows how to test a configured Spark connection using a PPL query to fetch data from a Spark SQL table.

LANGUAGE: json
CODE:
POST /_plugins/_ppl
content-type: application/json

{
   "query": "source = my_spark.sql('select * from alb_logs')"
}

----------------------------------------

TITLE: Template with Version Control
DESCRIPTION: Shows how to add version control to an index template for better template management.

LANGUAGE: json
CODE:
PUT /_index_template/template_one
{
  "index_patterns" : ["mac", "cheese"],
  "priority" : 0,
  "template": {
    "settings" : {
        "number_of_shards" : 1
    }
  },
  "version": 1
}

----------------------------------------

TITLE: Delete ML Controller Example Response
DESCRIPTION: Example response showing the successful deletion of a controller, including index details, version information, and shard status.

LANGUAGE: json
CODE:
{
  "_index" : ".plugins-ml-controller",
  "_id" : "MzcIJX8BA7mbufL6DOwl",
  "_version" : 2,
  "result" : "deleted",
  "_shards" : {
    "total" : 2,
    "successful" : 2,
    "failed" : 0
  },
  "_seq_no" : 27,
  "_primary_term" : 18
}

----------------------------------------

TITLE: Basic Match Phrase Prefix Query in OpenSearch
DESCRIPTION: Shows the basic syntax for a match_phrase_prefix query searching for 'the wind' in the title field.

LANGUAGE: json
CODE:
GET _search
{
  "query": {
    "match_phrase_prefix": {
      "title": "the wind"
    }
  }
}

----------------------------------------

TITLE: Creating Index with Simple Pattern Split Tokenizer - OpenSearch JSON
DESCRIPTION: Example of creating a new index with a custom analyzer using the simple_pattern_split tokenizer configured to split text on hyphens.

LANGUAGE: json
CODE:
PUT /my_index
{
  "settings": {
    "analysis": {
      "tokenizer": {
        "my_pattern_split_tokenizer": {
          "type": "simple_pattern_split",
          "pattern": "-"
        }
      },
      "analyzer": {
        "my_pattern_split_analyzer": {
          "type": "custom",
          "tokenizer": "my_pattern_split_tokenizer"
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "my_pattern_split_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Complex Pipeline with Template and Actions
DESCRIPTION: Example pipeline configuration with custom template content and conditional actions

LANGUAGE: yaml
CODE:
log-pipeline:
  source:
    http:
  processor:
    - date:
        from_time_received: true
        destination: "@timestamp"
  sink:
    - opensearch:
        hosts: [ "https://<serverless-public-collection-endpoint>" ]
        index: "my-serverless-index"
        template_type: index-template
        template_content: >
          {
            "template" : {
              "mappings" : {
                "properties" : {
                  "Data" : {
                    "type" : "binary"
                  },
                  "EncodedColors" : {
                    "type" : "binary"
                  },
                  "Type" : {
                    "type" : "keyword"
                  },
                  "LargeDouble" : {
                    "type" : "double"
                  }          
                }
              }
            }
          }
        actions:
         - type: "delete"
           when: '/operation == "delete"'
         - type: "update"
           when: '/operation == "update"'
         - type: "index"
        aws:
          sts_role_arn: "arn:aws:iam::<AccountId>:role/PipelineRole"
          region: "us-east-1"

----------------------------------------

TITLE: Ingesting Test Data with Bulk API
DESCRIPTION: Bulk API request to ingest sample population data for various metro areas into OpenSearch.

LANGUAGE: json
CODE:
POST _bulk
{"index": {"_index": "qa_demo", "_id": "1"}}
{"text": "Chart and table of population level and growth rate for the Ogden-Layton metro area from 1950 to 2023. United Nations population projections are also included through the year 2035.\nThe current metro area population of Ogden-Layton in 2023 is 750,000, a 1.63% increase from 2022.\nThe metro area population of Ogden-Layton in 2022 was 738,000, a 1.79% increase from 2021.\nThe metro area population of Ogden-Layton in 2021 was 725,000, a 1.97% increase from 2020.\nThe metro area population of Ogden-Layton in 2020 was 711,000, a 2.16% increase from 2019."}

----------------------------------------

TITLE: Obfuscate Processor Pipeline Configuration
DESCRIPTION: YAML configuration showing how to set up multiple obfuscate processors to handle different fields with custom masking patterns.

LANGUAGE: yaml
CODE:
pipeline:
  source:
    http:
  processor:
    - obfuscate:
        source: "log"
        target: "new_log"
        patterns:
          - "[A-Za-z0-9+_.-]+@([\\w-]+\\.)+[\\w-]{2,4}"
        action:
          mask:
            mask_character: "#"
            mask_character_length: 6
    - obfuscate:
        source: "phone"
  sink:
    - stdout:

----------------------------------------

TITLE: Split Processor Basic Configuration
DESCRIPTION: Basic JSON configuration structure for the split processor, showing required and optional parameters.

LANGUAGE: json
CODE:
{
  "split": {
    "field": "field_to_split",
    "separator": "<delimiter>",
    "target_field": "split_field"
  }
}

----------------------------------------

TITLE: Running Lambda Integration Tests with Gradle
DESCRIPTION: Command for executing integration tests for the AWS Lambda sink plugin with specific test parameters including region, function name, and IAM role.

LANGUAGE: bash
CODE:
./gradlew :data-prepper-plugins:aws-lambda:integrationTest -Dtests.sink.lambda.region="us-east-1" -Dtests.sink.lambda.functionName="lambda_test_function"  -Dtests.sink.lambda.sts_role_arn="arn:aws:iam::123456789012:role/dataprepper-role

----------------------------------------

TITLE: Input JSON Example for Rename Keys
DESCRIPTION: Sample JSON input showing the original event structure before key renaming.

LANGUAGE: json
CODE:
{"message": "hello"}

----------------------------------------

TITLE: Updating Alert Status in OpenSearch Threat Intelligence
DESCRIPTION: This endpoint updates the status of specified alerts to either ACKNOWLEDGED or COMPLETED. Only alerts in the ACTIVE state can be updated.

LANGUAGE: json
CODE:
PUT /plugins/security_analytics/threat_intel/alerts/status

----------------------------------------

TITLE: Retrieving Split Document
DESCRIPTION: Query to retrieve a document processed by the split pipeline.

LANGUAGE: json
CODE:
GET testindex1/_doc/1

----------------------------------------

TITLE: Configuring Anomaly Detector Suggestion Agent
DESCRIPTION: POST request to configure the anomaly detector suggestion agent in the system index. Requires superadmin permissions in security-enabled domains.

LANGUAGE: json
CODE:
{
  "type": "suggest_anomaly_detector_agent",
  "configuration": {
    "agent_id": "<SUGGEST_ANOMALY_DETECTOR_AGENT_ID>"
  }
}

----------------------------------------

TITLE: Basic ACL Permission Schema in JSON
DESCRIPTION: Defines the basic schema structure for ACL permissions, showing how to specify different permission types for users and groups.

LANGUAGE: json
CODE:
{
  "permissions": {
    "<permission_type_1>": {
        "users": ["<principal_1>", "<principal_2>"],
        "groups": ["<principal_3>", "<principal_4>"]
    }
  } 
}

----------------------------------------

TITLE: Query String Examples in OpenSearch
DESCRIPTION: Comparison between OpenSearch DSL and SQL query string syntax.

LANGUAGE: json
CODE:
GET accounts/_search
{
  "query": {
    "query_string": {
      "query": "Lane Street",
      "fields": [ "address" ],
    }
  }
}

LANGUAGE: sql
CODE:
SELECT account_number, address
FROM accounts
WHERE query('address:Lane OR address:Street')

----------------------------------------

TITLE: Creating a Point in Time (PIT) in OpenSearch
DESCRIPTION: Creates a PIT using a POST request to the specified index. The keep_alive parameter is required to set the PIT's lifetime.

LANGUAGE: json
CODE:
POST /<target_indexes>/_search/point_in_time?keep_alive=1h&routing=&expand_wildcards=&preference=

----------------------------------------

TITLE: Evaluating Metadata in OpenSearch Migration Console
DESCRIPTION: This command performs a dry run of metadata migration, showing which indexes, templates, and other objects will be migrated to the target cluster.

LANGUAGE: sh
CODE:
console metadata evaluate

----------------------------------------

TITLE: Checking Default Cluster Settings
DESCRIPTION: GET request to retrieve default cluster settings by including the include_defaults parameter.

LANGUAGE: json
CODE:
GET _cluster/settings?include_defaults=true

----------------------------------------

TITLE: Ingesting Document with JSON Processor Pipeline in OpenSearch
DESCRIPTION: Shows how to ingest a document into an index named 'my-index' using the previously created pipeline. The document contains a JSON string in the 'raw_data' field.

LANGUAGE: json
CODE:
POST my-index/_doc?pipeline=my-json-pipeline
{
  "raw_data": "{\"name\":\"John\",\"age\":30,\"city\":\"New York\"}"
}

----------------------------------------

TITLE: CAT Recovery API Response in OpenSearch
DESCRIPTION: Example response from the CAT recovery API in OpenSearch. It shows recovery information for shards, including index name, shard number, recovery type, stage, and various statistics.

LANGUAGE: json
CODE:
index | shard | time | type | stage | source_host | source_node | target_host | target_node | repository | snapshot | files | files_recovered | files_percent | files_total | bytes | bytes_recovered | bytes_percent | bytes_total | translog_ops | translog_ops_recovered | translog_ops_percent
movies | 0 | 117ms | empty_store | done | n/a | n/a | 172.18.0.4 | odfe-node1 | n/a | n/a | 0 | 0 | 0.0% | 0 | 0 | 0 | 0.0% | 0 | 0 | 0 | 100.0%
movies | 0 | 382ms | peer | done | 172.18.0.4 | odfe-node1 | 172.18.0.3 | odfe-node2 | n/a | n/a | 1 | 1 |  100.0% | 1 | 208 | 208 | 100.0% | 208 | 1 | 1 | 100.0%

----------------------------------------

TITLE: Deleting Documents with WHERE Clause in OpenSearch SQL
DESCRIPTION: Example of using the DELETE statement with a WHERE clause to remove documents that satisfy specific conditions in OpenSearch.

LANGUAGE: sql
CODE:
DELETE FROM accounts
WHERE age > 30

----------------------------------------

TITLE: Creating Markdown Block in OpenSearch Notebooks
DESCRIPTION: Example of how to create a markdown text block in an OpenSearch notebook using the %md interpreter prefix.

LANGUAGE: markdown
CODE:
%md
Add in text formatted in markdown.

----------------------------------------

TITLE: Field Value Factor Function Query
DESCRIPTION: Recalculates scores using the field_value_factor function based on the 'views' field.

LANGUAGE: json
CODE:
GET blogs/_search
{
  "query": {
    "function_score": {
      "field_value_factor": {
        "field": "views",
        "factor": 1.5,
        "modifier": "log1p",
        "missing": 1
      }
    }
  }
}

----------------------------------------

TITLE: Starting OpenSearch Benchmark Daemon on Worker Nodes
DESCRIPTION: These commands start the OpenSearch Benchmark daemon on worker nodes, specifying their own IP addresses and the coordinator's IP address.

LANGUAGE: bash
CODE:
opensearch-benchmarkd start --node-ip=198.52.100.0 --coordinator-ip=192.0.1.0

LANGUAGE: bash
CODE:
opensearch-benchmarkd start --node-ip=198.53.100.0 --coordinator-ip=192.0.1.0

----------------------------------------

TITLE: Training and Predicting with Logistic Regression in OpenSearch
DESCRIPTION: Example of training a logistic regression model on the Iris dataset and using it for prediction in OpenSearch.

LANGUAGE: JSON
CODE:
POST _plugins/_ml/_predict/logistic_regression/SsfQaoIBEoC4g4joZiyD
{
  "parameters": {
    "target": "class"
  },
  "input_data": {
    "column_metas": [
      {
        "name": "sepal_length_in_cm",
        "column_type": "DOUBLE"
      },
      {
        "name": "sepal_width_in_cm",
        "column_type": "DOUBLE"
      },
      {
        "name": "petal_length_in_cm",
        "column_type": "DOUBLE"
      },
      {
        "name": "petal_width_in_cm",
        "column_type": "DOUBLE"
      }
    ],
    "rows": [
      {
        "values": [
          {
            "column_type": "DOUBLE",
            "value": 6.2
          },
          {
            "column_type": "DOUBLE",
            "value": 3.4
          },
          {
            "column_type": "DOUBLE",
            "value": 5.4
          },
          {
            "column_type": "DOUBLE",
            "value": 2.3
          }
        ]
      }
    ]
  }
}

----------------------------------------

TITLE: Example JSON Response from Search Relevance Stats API
DESCRIPTION: Shows a sample JSON response from the Search Relevance Stats API, including data on various search operations, overall statistics, and counts by component and status code.

LANGUAGE: json
CODE:
{
  "data": {
    "search_relevance": {
      "fetch_index": {
        "200": {
          "response_time_total": 28.79286289215088,
          "count": 1
        }
      },
      "single_search": {
        "200": {
          "response_time_total": 29.817723274230957,
          "count": 1
        }
      },
      "comparison_search": {
        "200": {
          "response_time_total": 13.265346050262451,
          "count": 2
        }
      }
    }
  },
  "overall": {
    "response_time_avg": 17.968983054161072,
    "requests_per_second": 0.06666666666666667
  },
  "counts_by_component": {
    "search_relevance": 4
  },
  "counts_by_status_code": {
    "200": 4
  }
}

----------------------------------------

TITLE: Searching for Sentences with Fewer Than 10 Words in OpenSearch
DESCRIPTION: This snippet demonstrates how to perform a search query using the token count field. It searches for sentences with fewer than 10 words by using a range query on the 'sentence.num_words' field.

LANGUAGE: json
CODE:
GET testindex/_search
{
  "query": {
    "range": {
      "sentence.num_words": {
        "lt": 10
      }
    }
  }
}

----------------------------------------

TITLE: Sorting Results by Unsigned Long Field
DESCRIPTION: Example of sorting search results using an unsigned_long field.

LANGUAGE: json
CODE:
POST _search
{
  "sort" : [
    { 
      "counter" : { 
        "order" : "asc" 
      } 
    }
  ],
  "query": {
    "range": {
      "counter": {
        "gte": 10223372036854775807
      }
    }
  }
}

----------------------------------------

TITLE: Configuring map_to_list Processor with Event Root as Source in YAML
DESCRIPTION: Demonstrates how to use the event's root as the source for the map_to_list processor by setting the source to an empty string.

LANGUAGE: yaml
CODE:
processor:
  - map_to_list:
      source: ""
      target: "my-list"

----------------------------------------

TITLE: Creating Vector Search Index
DESCRIPTION: Creates an index with vector search capabilities and nested field mapping for text chunks and embeddings.

LANGUAGE: json
CODE:
PUT opensearch_docs
{
  "settings": {
    "index.knn": true,
    "default_pipeline": "bedrock-text-embedding-pipeline"
  },
  "mappings": {
    "properties": {
      "passage_chunk": {
        "type": "nested",
        "properties": {
          "text": {
            "type": "text"
          },
          "embedding": {
            "type": "knn_vector",
            "dimension": 1024
          }
        }
      },
      "passage_text": {
        "type": "text"
      }
    }
  }
}

----------------------------------------

TITLE: Workflow Provisioning with Request Body
DESCRIPTION: Example request showing parameter substitution using request body.

LANGUAGE: json
CODE:
POST /_plugins/_flow_framework/workflow/8xL8bowB8y25Tqfenm50/_provision
{
  "openai_key" : "12345"
}

----------------------------------------

TITLE: Running securityadmin.sh with PEM files
DESCRIPTION: This command loads the initial Security plugin configuration using PEM files for authentication.

LANGUAGE: bash
CODE:
./securityadmin.sh -cd ../../../config/opensearch-security/ -icl -nhnv \
  -cacert ../../../config/root-ca.pem \
  -cert ../../../config/kirk.pem \
  -key ../../../config/kirk-key.pem

----------------------------------------

TITLE: Multi-Index CAT Shards Query - JSON
DESCRIPTION: Example request showing how to retrieve shard information for multiple indexes at once.

LANGUAGE: json
CODE:
GET _cat/shards/index1,index2,index3

----------------------------------------

TITLE: Enabling applicationConfig and cspHandler plugins in YAML
DESCRIPTION: Configuration snippet to enable the applicationConfig and cspHandler plugins in the opensearch_dashboards.yml file. This is required to use dynamic CSP rule configuration for frame ancestors.

LANGUAGE: yaml
CODE:
application_config.enabled: true
csp_handler.enabled: true

----------------------------------------

TITLE: Stopwords Path Configuration
DESCRIPTION: Creates an index with a custom stop analyzer using stopwords from a file path.

LANGUAGE: json
CODE:
PUT /my_new_custom_stop_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_custom_stop_analyzer": {
          "type": "stop",                     
          "stopwords_path": "stopwords.txt"
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "description": {
        "type": "text",
        "analyzer": "my_custom_stop_analyzer" 
      }
    }
  }
}

----------------------------------------

TITLE: Using Custom Transient Analyzer in OpenSearch
DESCRIPTION: This example demonstrates how to build and use a custom transient analyzer with tokenizers and filters in OpenSearch.

LANGUAGE: json
CODE:
GET /_analyze
{
  "tokenizer" : "keyword",
  "filter" : ["uppercase"],
  "text" : "OpenSearch filter"
}

----------------------------------------

TITLE: Closing All Scroll Contexts in OpenSearch
DESCRIPTION: This snippet demonstrates how to close all open scroll contexts at once in OpenSearch.

LANGUAGE: json
CODE:
DELETE _search/scroll/_all

----------------------------------------

TITLE: Opaque ID Header Request in OpenSearch
DESCRIPTION: Shows how to add an opaque identifier to track tasks and deduplicate deprecation warnings in server-side logs.

LANGUAGE: json
CODE:
curl -H "X-Opaque-Id: my-curl-client-1" -XGET localhost:9200/_tasks

----------------------------------------

TITLE: Creating Index with Apostrophe Token Filter
DESCRIPTION: Creates a new index with a custom analyzer that includes the apostrophe token filter. The analyzer combines standard tokenizer with lowercase and apostrophe filters.

LANGUAGE: json
CODE:
PUT /custom_text_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "custom_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "apostrophe"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "custom_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: System Configuration Commands
DESCRIPTION: Commands to configure important system settings like memory paging and memory maps for OpenSearch performance.

LANGUAGE: bash
CODE:
sudo swapoff -a

# Edit sysctl config
sudo vi /etc/sysctl.conf
vm.max_map_count=262144

sudo sysctl -p
cat /proc/sys/vm/max_map_count

----------------------------------------

TITLE: Importing OpenSearch Module in Rust
DESCRIPTION: Import the OpenSearch module to use the Rust client API.

LANGUAGE: rust
CODE:
use opensearch::OpenSearch;

----------------------------------------

TITLE: Starting OpenSearch Benchmark Daemon on Coordinator Node
DESCRIPTION: This command starts the OpenSearch Benchmark daemon on the coordinator node, specifying its own IP address for both node and coordinator.

LANGUAGE: bash
CODE:
opensearch-benchmarkd start --node-ip=192.0.1.0 --coordinator-ip=192.0.1.0

----------------------------------------

TITLE: Configuring Data Prepper Pipeline
DESCRIPTION: YAML configuration for a simple Data Prepper pipeline with a random source and stdout sink.

LANGUAGE: yaml
CODE:
simple-sample-pipeline:
  workers: 2
  delay: "5000"
  source:
    random:
  sink:
    - stdout:

----------------------------------------

TITLE: Querying an Index with Ignored Malformed IP in OpenSearch
DESCRIPTION: This snippet shows how to query the index containing a document with a malformed IP address. The query will return the document, but the 'ip_address' field will be marked as ignored.

LANGUAGE: json
CODE:
GET /test-index/_search

----------------------------------------

TITLE: Configuring Anonymous Authentication in OpenSearch config.yml
DESCRIPTION: Configuration snippet for enabling anonymous authentication in OpenSearch's config.yml file within the http section.

LANGUAGE: yaml
CODE:
http:
  anonymous_auth_enabled: <true|false>
  ...

----------------------------------------

TITLE: Configuring map_to_list Processor with Key Exclusion and Field Removal in YAML
DESCRIPTION: Demonstrates how to exclude specific keys from processing and remove processed fields from the output using the map_to_list processor.

LANGUAGE: yaml
CODE:
processor:
  - map_to_list:
      source: "my-map"
      target: "my-list"
      exclude_keys: ["key1"]
      remove_processed_fields: true

----------------------------------------

TITLE: Configuring Split String Processor Options in OpenSearch Data Prepper
DESCRIPTION: This markdown table defines the configuration options for the split_string processor in OpenSearch Data Prepper. It includes the option names, whether they are required, their types, and descriptions.

LANGUAGE: markdown
CODE:
Option | Required | Type | Description
:--- | :--- | :--- | :---
entries | Yes | List | List of entries. Valid values are `source`, `delimiter`, and `delimiter_regex`.
source | N/A | N/A | The key to split.
delimiter | No | N/A | The separator character responsible for the split. Cannot be defined at the same time as `delimiter_regex`. At least `delimiter` or `delimiter_regex` must be defined.
delimiter_regex | No | N/A | The regex string responsible for the split. Cannot be defined at the same time as `delimiter`. At least `delimiter` or `delimiter_regex` must be defined.

----------------------------------------

TITLE: Complete Cluster Stats Response in OpenSearch
DESCRIPTION: Example response showing comprehensive cluster statistics including node counts, indices information, JVM stats, and plugin details.

LANGUAGE: json
CODE:
{"_nodes":{"total":1,"successful":1,"failed":0},"cluster_name":"opensearch-cluster","cluster_uuid":"QravFieJS_SlZJyBMcDMqQ","timestamp":1644607845054,"status":"yellow","indices":{...},"nodes":{...}}

----------------------------------------

TITLE: Vector Search Query
DESCRIPTION: Performs a k-NN search query on the disk-based vector index to find the 5 nearest neighbors.

LANGUAGE: json
CODE:
GET my-vector-index/_search
{
  "query": {
    "knn": {
      "my_vector_field": {
        "vector": [1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5],
        "k": 5
      }
    }
  }
}

----------------------------------------

TITLE: Using docvalue_fields
DESCRIPTION: Example showing how to use docvalue_fields for efficient retrieval of non-analyzed fields.

LANGUAGE: json
CODE:
{
  "_source": false,
  "docvalue_fields": ["author", "publication_date"],
  "query": {
    "match_all": {}
  }
}

----------------------------------------

TITLE: Deleting Security Detector
DESCRIPTION: Deletes an existing detector using its ID.

LANGUAGE: json
CODE:
DELETE /_plugins/_security_analytics/detectors/IJAXz4QBrmVplM4JYxx_

----------------------------------------

TITLE: Sorting CAT API Aliases Output in OpenSearch
DESCRIPTION: This snippet demonstrates how to sort the output of CAT API aliases by specific headers. It uses the 's' query parameter to specify sorting criteria.

LANGUAGE: json
CODE:
GET _cat/aliases?s=i,a

----------------------------------------

TITLE: Deriving Punctuation Patterns with substitute_string Processor in YAML
DESCRIPTION: This snippet shows how to use the substitute_string processor to derive punctuation patterns from incoming Apache log events, which can be useful for log analysis and pattern recognition.

LANGUAGE: yaml
CODE:
processor:  
  - substitute_string:
      entries:
        - source: "message"
          from: "[a-zA-Z0-9_]+"
          to:""
        - source: "message"
          from: "[ ]+"
          to: "_"  

----------------------------------------

TITLE: Create and Provision Workflow with Parameters
DESCRIPTION: Example of creating and provisioning a workflow with API key parameter

LANGUAGE: json
CODE:
POST /_plugins/_flow_framework/workflow?use_case=<use_case>&provision=true
{
    "create_connector.credential.key" : "<YOUR API KEY>"
}

----------------------------------------

TITLE: Deleting ML Controller User Rate Limit
DESCRIPTION: Example request for removing a user's rate limit by overwriting the controller with only remaining users.

LANGUAGE: json
CODE:
POST _plugins/_ml/controllers/mtw-ZI0B_1JGmyB068C0\n{\n  "user_rate_limiter": {\n    "user1": {\n      "limit": 6,\n      "unit": "MINUTES"\n    }\n  }\n}

----------------------------------------

TITLE: Disabling Multi-tenancy for Security Plugin in YAML
DESCRIPTION: This snippet demonstrates how to disable multi-tenancy in the Security plugin to avoid conflicts with workspaces, if the Security plugin is installed.

LANGUAGE: yaml
CODE:
opensearch_security.multitenancy.enabled: false

----------------------------------------

TITLE: S3 Select Pipeline Configurations
DESCRIPTION: Examples of using S3 Select to filter and retrieve data from S3 objects in various formats with SQL-like expressions.

LANGUAGE: json
CODE:
pipeline:
  source:
    s3:
      s3_select:
        expression: "select * from s3object s"
        input_serialization: parquet
      notification_type: "sqs"
...

LANGUAGE: json
CODE:
pipeline:
  source:
    s3:
      s3_select:
        expression: "select * from s3object s LIMIT 10000"
        input_serialization: parquet
      notification_type: "sqs"
...

LANGUAGE: json
CODE:
pipeline:
  source:
    s3:
      s3_select:
        expression: "select s.* from s3object s where s.data_value > 200 and s.data_value < 500 "
        input_serialization: parquet
      notification_type: "sqs"
...

----------------------------------------

TITLE: Configuring Log-Based Anomaly Detection Pipeline in OpenSearch
DESCRIPTION: Pipeline configuration that processes Apache logs, converts them to metrics, and performs anomaly detection. The pipeline uses Grok patterns to parse logs, aggregates them into histograms, and applies Random Cut Forest algorithm for anomaly detection.

LANGUAGE: json
CODE:
{
"apache-log-pipeline-with-metrics": {
  "source": {
    "http": {
      "path": "/${pipelineName}/logs"
    }
  },
  "processor": [
    {
      "grok": {
        "match": {
          "log": [ "%{COMMONAPACHELOG_DATATYPED}" ]
        }
      }
    }
  ],
  "sink": [
    {
      "opensearch": {
        "index": "logs"
      }
    },
    {
      "pipeline": {
        "name": "log-to-metrics-pipeline"
      }
    }
  ]
}}

----------------------------------------

TITLE: Creating a Conversation Memory
DESCRIPTION: This request creates a conversation memory to store messages from a conversation.

LANGUAGE: json
CODE:
POST /_plugins/_ml/memory/
{
  "name": "Conversation about NYC population"
}

----------------------------------------

TITLE: Applying English Analyzer to Text Field in OpenSearch
DESCRIPTION: This snippet demonstrates how to apply the built-in English analyzer to a text field when creating an index in OpenSearch. It defines a mapping for a 'content' field using the 'english' analyzer.

LANGUAGE: json
CODE:
PUT /english-index
{
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "english"
      }
    }
  }
}

----------------------------------------

TITLE: Creating OpenAI Connector in OpenSearch
DESCRIPTION: Creates a connector configuration for OpenAI integration with batch processing capabilities.

LANGUAGE: json
CODE:
POST /_plugins/_ml/connectors/_create
{
    "name": "OpenAI Chat Connector",
    "description": "The connector to public OpenAI model service for GPT 3.5",
    "version": 1,
    "protocol": "http",
    "parameters": {
        "endpoint": "api.openai.com",
        "model": "gpt-3.5-turbo",
        "input_docs_processed_step_size": 100
    },
    "credential": {
        "openAI_key": "..."
    },
    "actions": [
        {
            "action_type": "predict",
            "method": "POST",
            "url": "https://${parameters.endpoint}/v1/chat/completions",
            "headers": {
                "Authorization": "Bearer ${credential.openAI_key}"
            },
            "request_body": "{ \"model\": \"${parameters.model}\", \"messages\": ${parameters.messages} }"
        }
    ]
}

----------------------------------------

TITLE: Configuring DynamoDB Source in YAML Pipeline
DESCRIPTION: This YAML snippet demonstrates how to configure a DynamoDB source in a Data Prepper pipeline. It specifies a table ARN, export settings, stream options, and AWS configuration.

LANGUAGE: yaml
CODE:
version: "2"
cdc-pipeline:
  source:
    dynamodb:
      tables:
        - table_arn: "arn:aws:dynamodb:us-west-2:123456789012:table/table-a"
          export:
            s3_bucket: "test-bucket"
            s3_prefix: "myprefix"
          stream:
            start_position: "LATEST" # Read latest data from streams (Default)
            view_on_remove: NEW_IMAGE
      aws:
        region: "us-west-2"
        sts_role_arn: "arn:aws:iam::123456789012:role/my-iam-role"

----------------------------------------

TITLE: Configuring substitute_string Processor in YAML
DESCRIPTION: Configuration table showing the required options for the substitute_string processor. The processor requires a list of entries containing source (key to modify), from (regex pattern to match), and to (replacement string) values.

LANGUAGE: yaml
CODE:
entries:
  - source: "field_name"
    from: "regex_pattern"
    to: "replacement_string"

----------------------------------------

TITLE: Registering Flow Agent for PPLTool in OpenSearch
DESCRIPTION: This JSON request creates a flow agent that uses the PPLTool. It specifies the agent configuration, including the model ID and execution settings.

LANGUAGE: json
CODE:
POST /_plugins/_ml/agents/_register
{
  "name": "Test_Agent_For_PPL",
  "type": "flow",
  "description": "this is a test agent",
  "memory": {
    "type": "demo"
  },
  "tools": [
    {
      "type": "PPLTool",
      "name": "TransferQuestionToPPLAndExecuteTool",
      "description": "Use this tool to transfer natural language to generate PPL and execute PPL to query inside. Use this tool after you know the index name, otherwise, call IndexRoutingTool first. The input parameters are: {index:IndexName, question:UserQuestion}",
      "parameters": {
        "model_id": "h5AUWo0BkIylWTeYT4SU",
        "model_type": "FINETUNE",
        "execute": true
      }
    }
  ]
}

----------------------------------------

TITLE: Creating Latvian Analyzer with Stem Exclusion in OpenSearch
DESCRIPTION: This snippet shows how to create a Latvian analyzer with stem exclusion for specific words in OpenSearch.

LANGUAGE: json
CODE:
PUT index_with_stem_exclusion_latvian_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "stem_exclusion_latvian_analyzer": {
          "type": "latvian",
          "stem_exclusion": ["autoritte", "apstiprinjums"]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Enabling Anomaly Detector Suggestions in YAML Configuration
DESCRIPTION: Configuration setting in opensearch_dashboards.yml to enable the anomaly detector suggestions feature.

LANGUAGE: yaml
CODE:
assistant.smartAnomalyDetector.enabled: true

----------------------------------------

TITLE: Searching for Documents in OpenSearch using Rust
DESCRIPTION: Search for documents in OpenSearch using a multi_match query.

LANGUAGE: rust
CODE:
response = client
    .search(SearchParts::Index(&["movies"]))
    .from(0)
    .size(10)
    .body(json!({
        "query": {
            "multi_match": {
                "query": "miller",
                "fields": ["title^2", "director"]
            }           
        }
    }))
    .send()
    .await?;

----------------------------------------

TITLE: Querying CAT Recovery Endpoints in OpenSearch
DESCRIPTION: Endpoints for the CAT recovery API in OpenSearch. These endpoints allow retrieving information about completed and ongoing index and shard recoveries.

LANGUAGE: json
CODE:
GET /_cat/recovery
GET /_cat/recovery/{index}

----------------------------------------

TITLE: Configuring Stem Exclusion for Turkish Analyzer in OpenSearch
DESCRIPTION: This example shows how to create an index with a Turkish analyzer that includes stem exclusion for specific words.

LANGUAGE: json
CODE:
PUT index_with_stem_exclusion_turkish_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "stem_exclusion_turkish_analyzer": {
          "type": "turkish",
          "stem_exclusion": ["otorite", "onay"]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring AWS STS Header Overrides for otel_trace_group Processor in YAML
DESCRIPTION: Example of defining custom header overrides for AWS STS authentication in the otel_trace_group processor configuration.

LANGUAGE: yaml
CODE:
aws_sts_header_overrides:
  x-my-custom-header-1: my-custom-value-1
  x-my-custom-header-2: my-custom-value-2

----------------------------------------

TITLE: Advanced Field Masking with Custom Algorithms in roles.yml
DESCRIPTION: Shows how to specify a different hashing algorithm for specific fields in the roles.yml file. The 'title' field uses SHA-512, while 'genres' uses the default algorithm.

LANGUAGE: yml
CODE:
someonerole:
  index_permissions:
    - index_patterns:
      - 'movies'
      allowed_actions:
        - read
      masked_fields:
        - "title::SHA-512"
        - "genres"

----------------------------------------

TITLE: Deleting a Connector using OpenSearch ML Commons API
DESCRIPTION: This API endpoint deletes a standalone connector in OpenSearch ML Commons. It requires the connector_id as a path parameter.

LANGUAGE: json
CODE:
DELETE /_plugins/_ml/connectors/<connector_id>

----------------------------------------

TITLE: Getting OpenSearch Reporting CLI Help
DESCRIPTION: Command to display all available CLI arguments for the opensearch-reporting-cli tool

LANGUAGE: bash
CODE:
$ opensearch-reporting-cli -h

----------------------------------------

TITLE: Indexing a Document with Integer Value in OpenSearch
DESCRIPTION: This snippet shows how to index a document with an integer value in the previously defined 'integer_value' field.

LANGUAGE: json
CODE:
PUT testindex/_doc/1 
{
  "integer_value" : 123
}

----------------------------------------

TITLE: DEB Package Installation
DESCRIPTION: Commands to install OpenSearch using DEB package with optional custom admin password

LANGUAGE: bash
CODE:
sudo dpkg -i opensearch-{{site.opensearch_version}}-linux-arm64.deb

LANGUAGE: bash
CODE:
sudo env OPENSEARCH_INITIAL_ADMIN_PASSWORD=<custom-admin-password> dpkg -i opensearch-{{site.opensearch_version}}-linux-arm64.deb

----------------------------------------

TITLE: DEB Package Installation
DESCRIPTION: Commands to install OpenSearch using DEB package with optional custom admin password

LANGUAGE: bash
CODE:
sudo dpkg -i opensearch-{{site.opensearch_version}}-linux-arm64.deb

LANGUAGE: bash
CODE:
sudo env OPENSEARCH_INITIAL_ADMIN_PASSWORD=<custom-admin-password> dpkg -i opensearch-{{site.opensearch_version}}-linux-arm64.deb

----------------------------------------

TITLE: Paginating Hybrid Search Results by Document ID in OpenSearch
DESCRIPTION: This snippet shows how to paginate hybrid search results using the search_after parameter, sorting by document ID in descending order. It uses the same hybrid query structure as the previous example, but with a search_after value of "7yaM4JABZkI1FQv8AwoN".

LANGUAGE: json
CODE:
GET /my-nlp-index/_search?search_pipeline=nlp-search-pipeline
{
  "query": {
    "hybrid": {
      "queries": [
        {
          "term": {
            "category": "permission"
          }
        },
        {
          "bool": {
            "should": [
              {
                "term": {
                  "category": "editor"
                }
              },
              {
                "term": {
                  "category": "statement"
                }
              }
            ]
          }
        }
      ]
    }
  },
  "sort":[
     {
        "_id": {
          "order": "desc"   
        }
     } 
  ],
  "search_after":["7yaM4JABZkI1FQv8AwoN"]
}

----------------------------------------

TITLE: Deleting Multiple Indices in OpenSearch Benchmark
DESCRIPTION: Example configurations for deleting all indices and specific index patterns.

LANGUAGE: yaml
CODE:
{
  "name": "delete-all-indices",
  "operation-type": "delete-index"
}

LANGUAGE: yaml
CODE:
{
  "name": "delete-logs",
  "operation-type": "delete-index",
  "index": "logs-*",
  "only-if-exists": false,
  "request-params": {
    "expand_wildcards": "all",
    "allow_no_indices": "true",
    "ignore_unavailable": "true"
  }
}

----------------------------------------

TITLE: Generating an Admin Certificate for OpenSearch
DESCRIPTION: Series of commands to create an admin certificate, including key generation, conversion to PKCS#8 format, and certificate signing.

LANGUAGE: bash
CODE:
openssl genrsa -out admin-key-temp.pem 2048
openssl pkcs8 -inform PEM -outform PEM -in admin-key-temp.pem -topk8 -nocrypt -v1 PBE-SHA1-3DES -out admin-key.pem
openssl req -new -key admin-key.pem -out admin.csr
openssl x509 -req -in admin.csr -CA root-ca.pem -CAkey root-ca-key.pem -CAcreateserial -sha256 -out admin.pem -days 730

----------------------------------------

TITLE: CAT Segments Response Example
DESCRIPTION: Example response showing segment information including index, shard, replica status, IP, segment details, and various metrics.

LANGUAGE: json
CODE:
index | shard | prirep | ip | segment | generation | docs.count | docs.deleted | size | size.memory | committed | searchable | version | compound
movies | 0 | p | 172.18.0.4 | _0 | 0 | 1 | 0 | 3.5kb | 1364 | true | true | 8.7.0 | true
movies | 0 | r | 172.18.0.3 | _0 | 0 | 1 | 0 | 3.5kb | 1364 | true | true | 8.7.0 | true

----------------------------------------

TITLE: Get Snapshot Status API Endpoint
DESCRIPTION: The main endpoint for retrieving snapshot status. Optional path parameters allow querying specific repositories, snapshots, or indexes.

LANGUAGE: json
CODE:
GET _snapshot/<repository>/<snapshot>/_status

----------------------------------------

TITLE: Configuring Basic Authentication for External OpenSearch
DESCRIPTION: Configuration for HTTP basic authentication when sending audit logs to an external OpenSearch cluster that requires authentication.

LANGUAGE: yaml
CODE:
plugins.security.audit.config.username: <username>
plugins.security.audit.config.password: <password>

----------------------------------------

TITLE: Auto_date_histogram aggregation with time zone
DESCRIPTION: Executes an auto_date_histogram aggregation on the 'blogs1' index with a specified time zone offset.

LANGUAGE: json
CODE:
GET /blogs1/_search
{
  "size": 0,
  "aggs": {
    "histogram": {
      "auto_date_histogram": {
        "field": "date_posted",
        "buckets": 2,
        "format": "yyyy-MM-dd HH:mm:ss",
        "time_zone": "-02:00"
      }
    }
  }
}

----------------------------------------

TITLE: Creating Custom Truststore for Security Configuration
DESCRIPTION: Use keytool to create a custom truststore and add root authority certificates for connecting to the Security plugin. This command is used when working with self-signed certificates or demo configurations.

LANGUAGE: bash
CODE:
keytool -import <path-to-cert> -alias <alias-to-call-cert> -keystore <truststore-name>

----------------------------------------

TITLE: Basic Corpus Expansion Command - Bash
DESCRIPTION: Command to execute the expand-data-corpus.py script with basic options to specify corpus size and output file suffix.

LANGUAGE: bash
CODE:
./expand-data-corpus.py --corpus-size 100 --output-file-suffix 100gb

----------------------------------------

TITLE: Sample Output of OpenSearch Benchmark 'info' Command
DESCRIPTION: This code block shows an example of the detailed output provided by the 'info' command, including workload details and test procedures.

LANGUAGE: yaml
CODE:
   ____                  _____                      __       ____                  __                         __
  / __ \____  ___  ____ / ___/___  ____ ___________/ /_     / __ )___  ____  _____/ /_  ____ ___  ____ ______/ /__
 / / / / __ \/ _ \/ __ \\__ \/ _ \/ __ `/ ___/ ___/ __ \   / __  / _ \/ __ \/ ___/ __ \/ __ `__ \/ __ `/ ___/ //_/
/ /_/ / /_/ /  __/ / / /__/ /  __/ /_/ / /  / /__/ / / /  / /_/ /  __/ / / / /__/ / / / / / / / / /_/ / /  / ,<
\____/ .___/\___/_/ /_/____/\___/\__,_/_/   \___/_/ /_/  /_____/\___/_/ /_/\___/_/ /_/_/ /_/ /_/\__,_/_/  /_/|_|
    /_/

Showing details for workload [nyc_taxis]:

* Description: Taxi rides in New York in 2015
* Documents: 165,346,692
* Compressed Size: 4.5 GB
* Uncompressed Size: 74.3 GB

===================================
TestProcedure [searchable-snapshot]
===================================

Measuring performance for Searchable Snapshot feature. Based on the default test procedure 'append-no-conflicts'.

Schedule: 
----------

1. delete-index
2. create-index 
3. check-cluster-health
4. index (8 clients)
5. refresh-after-index
6. force-merge
7. refresh-after-force-merge
8. wait-until-merges-finish
9. create-snapshot-repository
10. delete-snapshot
11. create-snapshot
12. wait-for-snapshot-creation
13. delete-local-index
14. restore-snapshot
15. default 
16. range
17. distance_amount_agg
18. autohisto_agg
19. date_histogram_agg

====================================================
TestProcedure [append-no-conflicts] (run by default) 
====================================================

Indexes the entire document corpus using a setup that will lead to a larger indexing throughput than the default settings and produce a smaller index (higher compression rate). Document IDs are unique, so all index operations are append only. After that, a couple of queries are run. 

Schedule:
----------

1. delete-index
2. create-index
3. check-cluster-health
4. index (8 clients)
5. refresh-after-index
6. force-merge
7. refresh-after-force-merge
8. wait-until-merges-finish
9. default
10. range
11. distance_amount_agg
12. autohisto_agg
13. date_histogram_agg

==============================================
TestProcedure [append-no-conflicts-index-only]
==============================================

Indexes the whole document corpus using a setup that will lead to a larger indexing throughput than the default settings and produce a smaller index (higher compression rate). Document ids are unique so all index operations are append only.

Schedule:
----------

1. delete-index
2. create-index
3. check-cluster-health
4. index (8 clients)
5. refresh-after-index
6. force-merge
7. refresh-after-force-merge
8. wait-until-merges-finish

=====================================================
TestProcedure [append-sorted-no-conflicts-index-only]
=====================================================

Indexes the whole document corpus in an index sorted by pickup_datetime field in descending order (most recent first) and using a setup that will lead to a larger indexing throughput than the default settings and produce a smaller index (higher compression rate). Document ids are unique so all index operations are append only.

Schedule:
----------

1. delete-index
2. create-index
3. check-cluster-health
4. index (8 clients)
5. refresh-after-index
6. force-merge
7. refresh-after-force-merge
8. wait-until-merges-finish

======================
TestProcedure [update]
======================

Schedule:
----------

1. delete-index
2. create-index
3. check-cluster-health
4. update (8 clients)
5. refresh-after-index
6. force-merge
7. refresh-after-force-merge
8. wait-until-merges-finish


-------------------------------
[INFO] SUCCESS (took 2 seconds)
-------------------------------

----------------------------------------

TITLE: Creating Documents in Multiple Indexes - OpenSearch JSON
DESCRIPTION: Example showing how to create two different indexes (products and customers) and add a document to each index using PUT requests.

LANGUAGE: json
CODE:
PUT products/_doc/1
{
  "name": "Widget X"
}

PUT customers/_doc/2
{
  "name": "John Doe"
}

----------------------------------------

TITLE: Health by Awareness Attribute Request
DESCRIPTION: Request to retrieve cluster health metrics partitioned by awareness attributes like zone or rack.

LANGUAGE: json
CODE:
GET _cluster/health?level=awareness_attributes

----------------------------------------

TITLE: Sample CSV Input Data
DESCRIPTION: Example of raw CSV input data showing header and content rows.

LANGUAGE: text
CODE:
Should,skip,this,line
a,b,c
1,2,3

----------------------------------------

TITLE: Script-based Document Update in OpenSearch
DESCRIPTION: Example of using a script to update a document by incrementing a value using parameters.

LANGUAGE: json
CODE:
{
  "script" : {
    "source": "ctx._source.oldValue += params.newValue",
    "lang": "painless",
    "params" : {
      "newValue" : 10
    }
  }
}

----------------------------------------

TITLE: Searching for k-NN Models in OpenSearch
DESCRIPTION: Demonstrates how to search for k-NN models using an OpenSearch query, excluding the large model_blob field from the results.

LANGUAGE: json
CODE:
GET/POST /_plugins/_knn/models/_search?pretty&_source_excludes=model_blob

----------------------------------------

TITLE: Creating a search pipeline with truncate_hits processor in OpenSearch
DESCRIPTION: This snippet shows how to create a search pipeline named 'my_pipeline' with a truncate_hits response processor that limits results to 5 hits.

LANGUAGE: json
CODE:
PUT /_search/pipeline/my_pipeline 
{
  "response_processors": [
    {
      "truncate_hits" : {
        "tag" : "truncate_1",
        "description" : "This processor will discard results after the first 5.",
        "target_size" : 5
      }
    }
  ]
}

----------------------------------------

TITLE: Update Mappings API Request/Response
DESCRIPTION: API endpoint to update existing field mappings. Allows modification of field aliases for specified index.

LANGUAGE: json
CODE:
PUT /_plugins/_security_analytics/mappings

{
   "index_name": "windows",
   "field": "CommandLine",
   "alias": "windows-event_data-CommandLine"
}

LANGUAGE: json
CODE:
{
    "acknowledged": true
}

----------------------------------------

TITLE: Document Indexing Examples
DESCRIPTION: Shows how to index sample documents for testing match_phrase_prefix queries.

LANGUAGE: json
CODE:
PUT testindex/_doc/1
{
  "title": "The wind rises"
}

LANGUAGE: json
CODE:
PUT testindex/_doc/2
{
  "title": "Gone with the wind"
}

----------------------------------------

TITLE: Querying CAT Thread Pool Endpoints in OpenSearch
DESCRIPTION: These endpoints allow you to retrieve information about thread pools in OpenSearch. You can query all thread pools or specify patterns to filter specific thread pools.

LANGUAGE: json
CODE:
GET /_cat/thread_pool
GET /_cat/thread_pool/{thread_pool_patterns}

----------------------------------------

TITLE: Matrix Stats Response Example in OpenSearch
DESCRIPTION: Sample response showing the calculated matrix statistics including count, mean, variance, skewness, kurtosis, covariance, and correlation for the specified fields.

LANGUAGE: json
CODE:
{
  "aggregations": {
    "matrix_stats_taxful_total_price": {
      "doc_count": 4675,
      "fields": [
        {
          "name": "products.base_price",
          "count": 4675,
          "mean": 34.994239430147196,
          "variance": 360.5035285833703,
          "skewness": 5.530161335032702,
          "kurtosis": 131.16306324042148,
          "covariance": {
            "products.base_price": 360.5035285833703,
            "taxful_total_price": 846.6489362233166
          },
          "correlation": {
            "products.base_price": 1.0,
            "taxful_total_price": 0.8444765264325268
          }
        },
        {
          "name": "taxful_total_price",
          "count": 4675,
          "mean": 75.05542864304839,
          "variance": 2788.1879749835402,
          "skewness": 15.812149139924037,
          "kurtosis": 619.1235507385902,
          "covariance": {
            "products.base_price": 846.6489362233166,
            "taxful_total_price": 2788.1879749835402
          },
          "correlation": {
            "products.base_price": 0.8444765264325268,
            "taxful_total_price": 1.0
          }
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Configuring Multiple Pattern Matching in Grok Processor
DESCRIPTION: This snippet shows how to configure the grok processor to match multiple patterns for different fields in the input message.

LANGUAGE: json
CODE:
processor:
  - grok:
      match:
        message: ['%{SYSLOGBASE}', "%{COMMONAPACHELOG}"]
        timestamp: ["%{TIMESTAMP_ISO8601}"]

----------------------------------------

TITLE: Importing OpenSearch Client in JavaScript
DESCRIPTION: Code snippet showing how to require the OpenSearch client in a JavaScript file.

LANGUAGE: javascript
CODE:
const { Client } = require("@opensearch-project/opensearch");

----------------------------------------

TITLE: Including Banner and Home Cards Components
DESCRIPTION: Liquid template includes for rendering banner and home card components on the OpenSearch documentation homepage.

LANGUAGE: liquid
CODE:
{% include banner.html %}

{% include home_cards.html %}

----------------------------------------

TITLE: Configuring Kerberos Authentication Domain
DESCRIPTION: Configuration for the Kerberos authentication domain in config.yml, including HTTP authenticator settings and authentication backend configuration.

LANGUAGE: yaml
CODE:
kerberos_auth_domain:
  enabled: true
  order: 1
  http_authenticator:
    type: kerberos
    challenge: true
    config:
      krb_debug: false
      strip_realm_from_principal: true
  authentication_backend:
    type: noop

----------------------------------------

TITLE: Analyzing Text with Custom Classic Filter Analyzer in OpenSearch
DESCRIPTION: This snippet shows how to use the _analyze API to examine the tokens generated by the custom classic analyzer. It sends a POST request to analyze the text 'John's co-operate was excellent.' using the previously created analyzer.

LANGUAGE: json
CODE:
POST /custom_classic_filter/_analyze
{
  "analyzer": "custom_classic",
  "text": "John's co-operate was excellent."
}

----------------------------------------

TITLE: Configuring Bulk Operation in YAML for OpenSearch Benchmark
DESCRIPTION: Defines a bulk operation for indexing documents with a specified bulk size. This operation uses the OpenSearch bulk API to index multiple documents in a single request.

LANGUAGE: yaml
CODE:
{
  "name": "index-append",
  "operation-type": "bulk",
  "bulk-size": 5000
}

----------------------------------------

TITLE: Amazon OpenSearch Service Configuration
DESCRIPTION: Configuration example for connecting to an Amazon OpenSearch Service domain using AWS IAM authentication

LANGUAGE: yaml
CODE:
pipeline:
  ...
  sink:
    opensearch:
      hosts: ["https://your-amazon-opensearch-service-endpoint"]
      aws_sigv4: true
      cert: path/to/cert
      insecure: false
      index_type: trace-analytics-service-map
      bulk_size: 4

----------------------------------------

TITLE: Document Routing Example
DESCRIPTION: Example of retrieving a document using a specific routing value.

LANGUAGE: json
CODE:
GET test-index/_doc/1?routing=user1

----------------------------------------

TITLE: Basic Match Query - OpenSearch JSON
DESCRIPTION: Performs a basic match query to find documents containing 'John' in the name field.

LANGUAGE: json
CODE:
GET testindex1/_search
{
  "query": {
    "match": {
      "name": "John"
    }
  }
}

----------------------------------------

TITLE: Creating Data Summary Agent Configuration
DESCRIPTION: JSON configuration for creating a data summary agent using Claude on AWS Bedrock, including connector setup and tool registration.

LANGUAGE: json
CODE:
POST /_plugins/_flow_framework/workflow?provision=true
{
  "name": "Query Assist Agent",
  "description": "Create a Query Assist Agent using Claude on BedRock",
  "use_case": "REGISTER_AGENT",
  "version": {
    "template": "1.0.0",
    "compatibility": ["2.13.0", "3.0.0"]
  },
  "workflows": {
    "provision": {
      "user_params": {},
      "nodes": [
        {
          "id": "create_claude_connector",
          "type": "create_connector",
          "previous_node_inputs": {},
          "user_inputs": {
            "version": "1",
            "name": "Claude instant runtime Connector",
            "protocol": "aws_sigv4",
            "description": "The connector to BedRock service for Claude model",
            "actions": [
              {
                "headers": {
                  "x-amz-content-sha256": "required",
                  "content-type": "application/json"
                },
                "method": "POST",
                "request_body": "{\"prompt\":\"${parameters.prompt}\", \"max_tokens_to_sample\":${parameters.max_tokens_to_sample}, \"temperature\":${parameters.temperature},  \"anthropic_version\":\"${parameters.anthropic_version}\" }",
                "action_type": "predict",
                "url": "https://bedrock-runtime.us-west-2.amazonaws.com/model/anthropic.claude-instant-v1/invoke"
              }
            ],
            "credential": {
                "access_key": "<YOUR_ACCESS_KEY>",
                "secret_key": "<YOUR_SECRET_KEY>",
                "session_token": "<YOUR_SESSION_TOKEN>"
            },
            "parameters": {
              "region": "us-west-2",
              "endpoint": "bedrock-runtime.us-west-2.amazonaws.com",
              "content_type": "application/json",
              "auth": "Sig_V4",
              "max_tokens_to_sample": "8000",
              "service_name": "bedrock",
              "temperature": "0.0001",
              "response_filter": "$.completion",
              "anthropic_version": "bedrock-2023-05-31"
            }
          }
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Displaying Default DSN Connection Information
DESCRIPTION: Shows the default connection information set up as part of the DSN during installation on Windows.

LANGUAGE: plaintext
CODE:
Host: localhost
Port: 9200
Auth: NONE

----------------------------------------

TITLE: Extended Sigma Detection Rule with Multiple Selections
DESCRIPTION: Example showing a detection rule with multiple selection criteria including a list of command line patterns

LANGUAGE: yaml
CODE:
detection:
  selection:
    selection_schtasks:
      Image|endswith: \schtasks.exe
      CommandLine|contains: '/Create '
    selection_rare:
      CommandLine|contains:
      - ' bypass '
      - .DownloadString
      - .DownloadFile
      - FromBase64String
      - ' -w hidden '
      - ' IEX'
      - ' -enc '
      - ' -decode '
      - '/c start /min '
      - ' curl '

----------------------------------------

TITLE: Get Memory by ID Endpoint
DESCRIPTION: API endpoint for retrieving a specific memory by its ID in OpenSearch ML Commons.

LANGUAGE: json
CODE:
GET /_plugins/_ml/memory/<memory_id>

----------------------------------------

TITLE: Ingesting Document with Remove_by_pattern Pipeline
DESCRIPTION: Example of ingesting a document using the remove_by_pattern pipeline.

LANGUAGE: json
CODE:
PUT testindex1/_doc/1?pipeline=remove_fields_by_pattern
{
  "foo1": "foo1",
  "foo2": "foo2",
  "bar": "bar"
}

----------------------------------------

TITLE: Installing Workload Management Plugin in OpenSearch
DESCRIPTION: Command to install the workload management plugin in OpenSearch. This plugin enables features for grouping search traffic and isolating network resources.

LANGUAGE: json
CODE:
./bin/opensearch-plugin install workload-management

----------------------------------------

TITLE: Enabling Data Summary Feature in OpenSearch Dashboards YAML Config
DESCRIPTION: YAML configuration setting to enable the data summary feature in OpenSearch Dashboards.

LANGUAGE: yaml
CODE:
queryEnhancements.queryAssist.summary.enabled: true

----------------------------------------

TITLE: Audit Compliance Configuration
DESCRIPTION: Extended configuration for audit compliance settings including internal security changes monitoring

LANGUAGE: yaml
CODE:
_meta:
  type: "audit"
  config_version: 2

config:
  enabled: true

  compliance:
    enabled: true
    internal_config: true
    write_metadata_only: false
    write_log_diffs: true
    write_watched_indices: [".opendistro_security"]

----------------------------------------

TITLE: Parent ID Query Response - OpenSearch JSON
DESCRIPTION: Example response showing a successful parent_id query result. The response includes metadata and the matched child document with its source data and routing information.

LANGUAGE: json
CODE:
{
  "took": 57,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 1,
      "relation": "eq"
    },
    "max_score": 0.87546873,
    "hits": [
      {
        "_index": "testindex1",
        "_id": "3",
        "_score": 0.87546873,
        "_routing": "1",
        "_source": {
          "name": "Mechanical watch",
          "sales_count": 150,
          "product_to_brand": {
            "name": "product",
            "parent": "1"
          }
        }
      }
    ]
  }
}

----------------------------------------

TITLE: Setting Default Search Analyzer for OpenSearch Index (JSON)
DESCRIPTION: This snippet demonstrates how to set a default index analyzer and search analyzer for an entire OpenSearch index. It specifies the 'simple' analyzer as the default index analyzer and the 'whitespace' analyzer as the default search analyzer.

LANGUAGE: json
CODE:
PUT testindex
{
  "settings": {
    "analysis": {
      "analyzer": {
        "default": {
          "type": "simple"
        },
        "default_search": {
          "type": "whitespace"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Shutdown Timeouts
DESCRIPTION: YAML configuration for customizing processor and sink shutdown timeouts

LANGUAGE: yaml
CODE:
processorShutdownTimeout: "PT15M"
sinkShutdownTimeout: 30s

----------------------------------------

TITLE: Get All Memories Endpoint
DESCRIPTION: API endpoint for retrieving all memories with optional pagination parameters.

LANGUAGE: json
CODE:
GET /_plugins/_ml/memory

----------------------------------------

TITLE: Initiating a Scroll Search in OpenSearch
DESCRIPTION: This snippet demonstrates how to start a scroll search in OpenSearch, setting the scroll time to 10 minutes and the batch size to 10,000 results.

LANGUAGE: json
CODE:
GET shakespeare/_search?scroll=10m
{
  "size": 10000
}

----------------------------------------

TITLE: Deleting Custom Log Type in OpenSearch Security Analytics
DESCRIPTION: This API request deletes a custom log type. It uses a DELETE request to the /_plugins/_security_analytics/logtype/<log_type_id> endpoint, specifying the log type ID in the URL.

LANGUAGE: json
CODE:
DELETE /_plugins/_security_analytics/logtype/m98uk4kBlb9cbROIpEj2

----------------------------------------

TITLE: Register Agent - Example Response
DESCRIPTION: The success response containing the generated agent ID.

LANGUAGE: json
CODE:
{
  "agent_id": "bpV_Zo0BRhAwb9PZqGja"
}

----------------------------------------

TITLE: Custom Field Mapping with OpenSearch DSL
DESCRIPTION: JSON example showing how to define custom field mappings for firstName and lastName fields as keywords in OpenSearch.

LANGUAGE: json
CODE:
{
  "mappings" : {
    "properties" : {
      "firstName" : {
        "type" : "keyword"
      },
      "lastName" : {
        "type" : "keyword"
      }
    }
  }
}

----------------------------------------

TITLE: Documenting Query Parameters for OpenSearch Search API with Global Parameters
DESCRIPTION: This snippet creates a markdown table for query parameters in the OpenSearch search API, including global parameters. It provides detailed information on parameters such as 'analyze_wildcard', 'analyzer', 'expand_wildcards', 'pretty', and 'human'.

LANGUAGE: markdown
CODE:
## Query parameters

The following table lists the available query parameters.

| Data type      | Parameter                 | Description                                                                                                                        | Required     | Default |
|:---------------|:--------------------------|:-----------------------------------------------------------------------------------------------------------------------------------|:-------------|:--------|
| Boolean        | `analyze_wildcard`        | If true, wildcard and prefix queries are analyzed. This parameter can only be used when the q query string parameter is specified. | **Required** | `false` |
| String         | `analyzer`                | Analyzer to use for the query string. This parameter can only be used when the q query string parameter is specified.              | _Optional_   | N/A     |
| List or String | `expand_wildcards`        | Comma-separated list of expand wildcard options. <br> Valid values are: `open`, `closed`, `none`, `all`                            | _Optional_   | N/A     |
| Boolean        | `pretty`                  | Whether to pretty format the returned JSON response.                                                                               | _Optional_   | N/A     |
| Boolean        | `human` <br> _DEPRECATED_ | _(Deprecated since 3.0: Use the `format` parameter instead.)_ Whether to return human readable values for statistics.              | _Optional_   | `true`  |

----------------------------------------

TITLE: Creating and Using Bulk Helper in OpenSearch JavaScript Client
DESCRIPTION: Demonstrates how to create a bulk helper instance and use it to perform bulk index operations on documents. The example includes creating a client, specifying a data source, and defining an onDocument function.

LANGUAGE: javascript
CODE:
const { Client } = require('@opensearch-project/opensearch')
const documents = require('./docs.json')

const client = new Client({ ... })

const result = await client.helpers.bulk({
  datasource: documents,
  onDocument (doc) {
    return {
      index: { _index: 'example-index' }
    }
  }
})

console.log(result)

----------------------------------------

TITLE: Configuring SAML in OpenSearch Dashboards
DESCRIPTION: This YAML snippet shows how to activate SAML authentication in the OpenSearch Dashboards configuration file and set up necessary XSRF allowlists.

LANGUAGE: yaml
CODE:
opensearch_security.auth.type: "saml"
server.xsrf.allowlist: ["/_opendistro/_security/saml/acs", "/_opendistro/_security/saml/logout"]

----------------------------------------

TITLE: Example Repository List Response from OpenSearch
DESCRIPTION: Sample response showing repository IDs and their types in a tabular format.

LANGUAGE: json
CODE:
id    type
repo1   fs
repo2   s3

----------------------------------------

TITLE: Data Stream Configuration
DESCRIPTION: Configuration for using data streams with the OpenSearch output plugin. Enables time series data ingestion with create action.

LANGUAGE: yaml
CODE:
output {
    opensearch {
          hosts  => ["https://hostname:port"]
          auth_type => {
              type => 'basic'
              user => 'admin'
              password => 'admin'
          }
          index => "my-data-stream"
          action => "create"
   }
}

----------------------------------------

TITLE: Multi-terms Aggregation Request in OpenSearch
DESCRIPTION: Example request demonstrating a multi-terms aggregation that groups documents by region and host fields, with ordering based on maximum CPU and memory values. The aggregation includes nested max aggregations for CPU and memory metrics.

LANGUAGE: json
CODE:
{
  "size": 0, 
  "aggs": {
    "hot": {
      "multi_terms": {
        "terms": [{
          "field": "region" 
        },{
          "field": "host" 
        }],
        "order": [{
          "max-cpu": "desc"
        },{
          "max-memory": "desc"
        }]
      },
      "aggs": {
        "max-cpu": { "max": { "field": "cpu" } },
        "max-memory": { "max": { "field": "memory" } }
      }      
    }
  }
}

----------------------------------------

TITLE: Searching Messages in Memory using ML Commons API in OpenSearch
DESCRIPTION: This snippet demonstrates how to search for messages within a memory using the ML Commons API. It shows the endpoint structure and an example GET request with a query to match messages based on input text.

LANGUAGE: json
CODE:
GET /_plugins/_ml/memory/gW8Aa40BfUsSoeNTvOKI/_search
{
  "query": {
    "match": {
      "input": "interaction"
    }
  }
}

----------------------------------------

TITLE: Alert Message Template for Sample Documents
DESCRIPTION: This Mustache template shows how to format an alert message to include sample documents from a per-document monitor.

LANGUAGE: groovy
CODE:
Alerts
{{#ctx.alerts}}
    Sample documents:
    {{#sample_documents}}
        Index: {{_index}}
        Document ID: {{_id}}
       
        Order date: {{_source.order_date}}
        Order ID: {{_source.order_id}}
        Clothing category: {{_source.category}}
        -----------------
    {{/sample_documents}}
{{/ctx.alerts}}

----------------------------------------

TITLE: Enable Shard Allocation API Call
DESCRIPTION: JSON API request to re-enable shard allocation after plugin removal.

LANGUAGE: json
CODE:
curl -XPUT "http://localhost:9200/_cluster/settings" -H 'Content-Type: application/json' -d '{
 "transient": {
   "cluster.routing.allocation.enable": "all"
   }
}'

----------------------------------------

TITLE: Example Response for Value Count Aggregation in OpenSearch
DESCRIPTION: This snippet shows the expected response format for a value_count aggregation. The response includes an 'aggregations' object containing the 'number_of_values' result, which represents the count of values in the specified field.

LANGUAGE: json
CODE:
...
  "aggregations" : {
    "number_of_values" : {
      "value" : 4675
    }
  }
}

----------------------------------------

TITLE: Indexing Private Document in OpenSearch
DESCRIPTION: Adds a document with private visibility to the index.

LANGUAGE: json
CODE:
POST /my_index/_doc/2
{
  "message": "This is a private message", 
  "visibility": "private"
}

----------------------------------------

TITLE: Creating Custom US Counties GeoJSON Map
DESCRIPTION: Example GeoJSON file containing coordinate data for Los Angeles and San Diego counties in California. The file defines polygon coordinates and properties for each county region including ISO codes, names, and country information.

LANGUAGE: json
CODE:
{
  "type": "FeatureCollection",
  "name": "usa counties",
  "features": [
    { "type": "Feature", "properties": { "iso2": "US", "iso3": "LA-CA", "name": "Los Angeles County", "country": "US", "county": "LA" }, "geometry": { "type": "Polygon", "coordinates":[[[-118.71826171875,34.07086232376631],[-118.69628906249999,34.03445260967645],[-118.56994628906249,34.02990029603907],[-118.487548828125,33.957030069982316],[-118.37219238281249,33.86129311351553],[-118.45458984375,33.75631505992707],[-118.33923339843749,33.715201644740844],[-118.22937011718749,33.75631505992707],[-118.1414794921875,33.678639851675555],[-117.9107666015625,33.578014746143985],[-117.75146484375,33.4955977448657],[-117.55920410156249,33.55512901742288],[-117.3065185546875,33.5963189611327],[-117.0703125,33.67406853374198],[-116.69677734375,34.06176136129718],[-116.9439697265625,34.28445325435288],[-117.18017578125,34.42956713470528],[-117.3779296875,34.542762387234845],[-117.62512207031251,34.56990638085636],[-118.048095703125,34.615126683462194],[-118.44909667968749,34.542762387234845],[-118.61938476562499,34.38877925439021],[-118.740234375,34.21180215769026],[-118.71826171875,34.07086232376631]]] } },
    { "type": "Feature", "properties": { "iso2": "US", "iso3": "SD-CA", "name": "San Diego County", "country": "US", "county": "SD" }, "geometry": { "type": "Polygon", "coordinates":[[[-117.23510742187501,32.861132322810946],[-117.2406005859375,32.75494243654723],[-117.1636962890625,32.68099643258195],[-117.14172363281251,32.58384932565662],[-117.09228515624999,32.46342595776104],[-117.0538330078125,32.29177633471201],[-116.96044921875,32.194208672875384],[-116.85607910156249,32.16631295696736],[-116.6748046875,32.20350534542368],[-116.3671875,32.319633552035214],[-116.1474609375,32.55144352864431],[-116.1639404296875,32.80574473290688],[-116.4111328125,33.073130945006625],[-116.72973632812499,33.08233672856376],[-117.09228515624999,32.99484290420988],[-117.2515869140625,32.96258644191747], [-117.23510742187501,32.861132322810946]]] } }
  ]
}

----------------------------------------

TITLE: Refreshing Indices in YAML for OpenSearch Benchmark
DESCRIPTION: Configures a refresh operation to refresh all indices matching the pattern 'logs-*'. This operation is used to ensure that all recent changes are visible to search operations.

LANGUAGE: yaml
CODE:
{
 "name": "refresh",
 "operation-type": "refresh",
 "index": "logs-*"
}

----------------------------------------

TITLE: Creating a Specific Index in YAML for OpenSearch Benchmark
DESCRIPTION: Defines a create-index operation to create a specific index named 'people' with custom settings and mappings. This operation demonstrates how to create an index with full control over its configuration.

LANGUAGE: yaml
CODE:
{
  "name": "create-an-index",
  "operation-type": "create-index",
  "index": "people",
  "body": {
    "settings": {
      "index.number_of_shards": 0
    },
    "mappings": {
      "docs": {
        "properties": {
          "name": {
            "type": "text"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Pattern Replace with Capturing Groups
DESCRIPTION: Example of using pattern_replace with capturing groups to replace hyphens with dots in phone numbers while preserving the digits.

LANGUAGE: json
CODE:
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "standard",
          "char_filter": [
            "pattern_char_filter"
          ]
        }
      },
      "char_filter": {
        "pattern_char_filter": {
          "type": "pattern_replace",
          "pattern": "(\\d+)-(?=\\d)",
          "replacement": "$1."
        }
      }
    }
  }
}

----------------------------------------

TITLE: Authenticating with Amazon OpenSearch Serverless using AWS SDK V3
DESCRIPTION: JavaScript code for authenticating with Amazon OpenSearch Serverless using AWS Signature Version 4 with AWS SDK V3.

LANGUAGE: javascript
CODE:
const { defaultProvider } = require('@aws-sdk/credential-provider-node');
const { Client } = require('@opensearch-project/opensearch');
const { AwsSigv4Signer } = require('@opensearch-project/opensearch/aws');

const client = new Client({
  ...AwsSigv4Signer({
    region: 'us-east-1',
    service: 'aoss',
    getCredentials: () => {
      const credentialsProvider = defaultProvider();
      return credentialsProvider();
    },
  }),
  node: "https://xxx.region.aoss.amazonaws.com"
});

----------------------------------------

TITLE: Basic Rename Keys Pipeline Configuration in YAML
DESCRIPTION: Example pipeline configuration showing how to rename a 'message' key to 'newMessage' with overwrite option enabled.

LANGUAGE: yaml
CODE:
pipeline:
  source:
    file:
      path: "/full/path/to/logs_json.log"
      record_type: "event"
      format: "json"
  processor:
    - rename_keys:
        entries:
        - from_key: "message"
          to_key: "newMessage"
          overwrite_if_to_key_exists: true
  sink:
    - stdout:

----------------------------------------

TITLE: DLQ File Naming Pattern Format
DESCRIPTION: Pattern format used for naming DLQ files when written to S3. Includes version, pipeline name, plugin ID, timestamp, and unique identifier components.

LANGUAGE: text
CODE:
dlq-v${version}-${pipelineName}-${pluginId}-${timestampIso8601}-${uniqueId}

----------------------------------------

TITLE: Update by Query Example Request in OpenSearch
DESCRIPTION: A complete example of an Update by Query request, including the endpoint and request body. It updates documents in 'test-index1' where 'oldValue' is 10, incrementing it by 20.

LANGUAGE: json
CODE:
POST test-index1/_update_by_query
{
  "query": {
    "term": {
      "oldValue": 10
    }
  },
  "script" : {
    "source": "ctx._source.oldValue += params.newValue",
    "lang": "painless",
    "params" : {
      "newValue" : 20
    }
  }
}

----------------------------------------

TITLE: Registering Bedrock Cohere Model in OpenSearch
DESCRIPTION: This JSON request registers the Bedrock Cohere embedding model in OpenSearch, linking it to the created connector.

LANGUAGE: json
CODE:
POST /_plugins/_ml/models/_register
{
  "name": "Bedrock Cohere embedding model v3",
  "function_name": "remote",
  "description": "test embedding model",
  "model_group_id": "050q8o0BWbTmLN9Foo4f",
  "connector_id": "0p0p8o0BWbTmLN9F-o4G"
}

----------------------------------------

TITLE: Configuring Target Key in Grok Processor
DESCRIPTION: This snippet shows how to use the target_key option in the grok processor to wrap all captured fields under a specified parent key in the output.

LANGUAGE: json
CODE:
processor:
   - grok:
       target_key: "grokked"
       match:
         message: ['%{IPORHOST} \[%{HTTPDATE:timestamp}\] %{NUMBER:response_status:int}']

----------------------------------------

TITLE: Complete RDP Security Detection Rule Example
DESCRIPTION: Comprehensive example of a detection rule for monitoring RDP terminal service settings changes including metadata, detection logic, and references

LANGUAGE: yaml
CODE:
title: RDP Sensitive Settings Changed
logsource:
  product: windows
description: 'Detects changes to RDP terminal service sensitive settings'
detection:
  selection:
    EventType: SetValue
    TargetObject|contains:
      - \services\TermService\Parameters\ServiceDll
      - \Control\Terminal Server\fSingleSessionPerUser
      - \Control\Terminal Server\fDenyTSConnections
      - \Policies\Microsoft\Windows NT\Terminal Services\Shadow
      - \Control\Terminal Server\WinStations\RDP-Tcp\InitialProgram
  condition: selection
level: high
tags:
  - attack.defense_evasion
  - attack.t1112
references:
  - https://blog.menasec.net/2019/02/threat-hunting-rdp-hijacking-via.html
  - https://knowledge.insourcess.com/Supporting_Technologies/Wonderware/Tech_Notes/TN_WW213_How_to_shadow_an_established_RDP_Session_on_Windows_10_Pro
  - https://twitter.com/SagieSec/1469001618863624194?t=HRf0eA0W1YYzkTSHb-Ky1A&s=03
  - http://etutorials.org/Microsoft+Products/microsoft+windows+server+2003+terminal+services/Chapter+6+Registry/Registry+Keys+for+Terminal+Services/
falsepositives:
  - Unknown
author:
  - Samir Bousseaden 
  - David ANDRE
status: experimental

----------------------------------------

TITLE: Testing OpenSearch Security Connection with cURL
DESCRIPTION: Command to test OpenSearch security configuration using cURL with basic authentication.

LANGUAGE: bash
CODE:
curl -k -XGET -u admin:<password> https://<opensearch-ip>:9200

----------------------------------------

TITLE: Installing OpenSearch Python Client with pip
DESCRIPTION: Use pip to install the opensearch-py package, which provides the low-level Python client for OpenSearch.

LANGUAGE: bash
CODE:
pip install opensearch-py

----------------------------------------

TITLE: Example Response for GET _script_context in OpenSearch
DESCRIPTION: Shows the structure of the response returned by the GET _script_context request, including contexts, methods, and parameters for each script context.

LANGUAGE: json
CODE:
{
  "contexts": [
    {
      "name": "aggregation_selector",
      "methods": [
        {
          "name": "execute",
          "return_type": "boolean",
          "params": []
        },
        {
          "name": "getParams",
          "return_type": "java.util.Map",
          "params": []
        }
      ]
    },
    // ... other contexts ...
  ]
}

----------------------------------------

TITLE: Querying CAT templates endpoints in OpenSearch
DESCRIPTION: The CAT templates API provides two endpoints for retrieving information about index templates.

LANGUAGE: json
CODE:
GET /_cat/templates
GET /_cat/templates/{name}

----------------------------------------

TITLE: Configuring Cross-Account S3 Access in Data Prepper
DESCRIPTION: Shows how to set up cross-account S3 access using bucket_owners and default_bucket_owner configurations in the S3 sink.

LANGUAGE: yaml
CODE:
sink:
  - s3:
      default_bucket_owner: 111111111111
      bucket_owners:
        my-bucket-01: 123456789012
        my-bucket-02: 999999999999

----------------------------------------

TITLE: Testing Amazon Bedrock Rerank API in Python
DESCRIPTION: This code snippet demonstrates how to use the boto3 library to test the Amazon Bedrock Rerank API with a sample query and documents.

LANGUAGE: python
CODE:
import json
import boto3
bedrock_region = "your_bedrock_model_region_like_us-west-2"
bedrock_agent_runtime_client = boto3.client("bedrock-agent-runtime", region_name=bedrock_region)

model_id = "amazon.rerank-v1:0"

response = bedrock_agent_runtime_client.rerank(
    queries=[
        {
            "textQuery": {
                "text": "What is the capital city of America?",
            },
            "type": "TEXT"
        }
    ],
    rerankingConfiguration={
        "bedrockRerankingConfiguration": {
            "modelConfiguration": {
                "modelArn": f"arn:aws:bedrock:{bedrock_region}::foundation-model/{model_id}"
            },
        },
        "type": "BEDROCK_RERANKING_MODEL"
    },
    sources=[
        {
            "inlineDocumentSource": {
                "textDocument": {
                    "text": "Carson City is the capital city of the American state of Nevada.",
                },
                "type": "TEXT"
            },
            "type": "INLINE"
        },
        {
            "inlineDocumentSource": {
                "textDocument": {
                    "text": "The Commonwealth of the Northern Mariana Islands is a group of islands in the Pacific Ocean. Its capital is Saipan.",
                },
                "type": "TEXT"
            },
            "type": "INLINE"
        },
        {
            "inlineDocumentSource": {
                "textDocument": {
                    "text": "Washington, D.C. (also known as simply Washington or D.C., and officially as the District of Columbia) is the capital of the United States. It is a federal district.",
                },
                "type": "TEXT"
            },
            "type": "INLINE"
        },
        {
            "inlineDocumentSource": {
                "textDocument": {
                    "text": "Capital punishment (the death penalty) has existed in the United States since beforethe United States was a country. As of 2017, capital punishment is legal in 30 of the 50 states."
                },
                "type": "TEXT"
            },
            "type": "INLINE"
        },        
    ]
)

results = response["results"]
print(json.dumps(results, indent=2))

----------------------------------------

TITLE: Defining Student Class Model in C#
DESCRIPTION: Basic C# class definition for a Student entity with properties for Id, FirstName, LastName, GradYear, and Gpa.

LANGUAGE: csharp
CODE:
public class Student
{
    public int Id { get; init; }
    public string FirstName { get; init; }
    public string LastName { get; init; }
    public int GradYear { get; init; }
    public double Gpa { get; init; }
}

----------------------------------------

TITLE: Path Parameters Template for Search API
DESCRIPTION: Template block for inserting path parameters documentation for the OpenSearch search API.

LANGUAGE: html
CODE:
<!-- spec_insert_start
api: search
component: path_parameters
-->
THIS
    TEXT
        SHOULD
            BE
                REPLACED
<!-- spec_insert_end -->

----------------------------------------

TITLE: Adding Serde Dependencies to Cargo.toml
DESCRIPTION: Add Serde dependencies to Cargo.toml for JSON serialization and deserialization.

LANGUAGE: rust
CODE:
serde = "~1"
serde_json = "~1"

----------------------------------------

TITLE: Updating Channel Configuration in OpenSearch
DESCRIPTION: Updates an existing channel configuration by sending a PUT request with modified configuration details.

LANGUAGE: json
CODE:
PUT _plugins/_notifications/configs/<config_id>
{
  "config": {
    "name": "Slack Channel",
    "description": "This is an updated channel configuration",
    "config_type": "slack",
    "is_enabled": true,
    "slack": {
      "url": "https://hooks.slack.com/sample-url"
    }
  }
}

----------------------------------------

TITLE: Configuring OpenSearch Dashboards for Vega
DESCRIPTION: Required YAML configuration settings in opensearch_dashboards.yaml to enable Vega visualizations and multiple data sources.

LANGUAGE: yaml
CODE:
data_source.enabled: true
vis_type_vega.enabled: true

----------------------------------------

TITLE: Parsing Flattened Anomaly Detection Results in JSON
DESCRIPTION: Example JSON structure of a flattened anomaly detection result, where nested fields are flattened according to specific rules. This format is used when the 'Enable flattened custom result index' option is selected.

LANGUAGE: json
CODE:
{
  "detector_id": "kzcZ43wBgEQAbjDnhzGF",
  "confidence": 0.9746820962328963,
  "relevant_attribution": [
    {
      "feature_id": "deny_max1",
      "data": 0.07339452532666227
    },
    {
      "feature_id": "deny_avg",
      "data": 0.04934972719948845
    },
    {
      "feature_id": "deny_min",
      "data": 0.01803003656061806
    },
    {
      "feature_id": "deny_sum",
      "data": 0.14804918212089874
    },
    {
      "feature_id": "accept_max5",
      "data": 0.7111765287923325
    }
  ],
  "relevant_attribution_deny_max1_data": 0.07339452532666227,
  "relevant_attribution_deny_avg_data": 0.04934972719948845,
  "relevant_attribution_deny_min_data": 0.01803003656061806,
  "relevant_attribution_deny_sum_data": 0.14804918212089874,
  "relevant_attribution_deny_max5_data": 0.7111765287923325,
  "task_id": "9Dck43wBgEQAbjDn4zEe",
  "threshold": 1,
  "model_id": "kzcZ43wBgEQAbjDnhzGF_entity_app_0",
  "schema_version": 5,
  "anomaly_score": 1.141419389056506,
  "execution_start_time": 1635898427803,
  "past_values": [
    {
      "feature_id": "processing_bytes_max",
      "data": 905
    },
    {
      "feature_id": "processing_bytes_avg",
      "data": 479
    },
    {
      "feature_id": "processing_bytes_min",
      "data": 128
    },
    {
      "feature_id": "processing_bytes_sum",
      "data": 1437
    },
    {
      "feature_id": "processing_time_max",
      "data": 8440
    }
  ],
  "past_values_processing_bytes_max_data": 905,
  "past_values_processing_bytes_avg_data": 479,
  "past_values_processing_bytes_min_data": 128,
  "past_values_processing_bytes_sum_data": 1437,
  "past_values_processing_bytes_max_data": 8440,
  "data_end_time": 1635883920000,
  "data_start_time": 1635883860000,
  "feature_data": [
    {
      "feature_id": "processing_bytes_max",
      "feature_name": "processing bytes max",
      "data": 1360
    },
    {
      "feature_id": "processing_bytes_avg",
      "feature_name": "processing bytes avg",
      "data": 990
    },
    {
      "feature_id": "processing_bytes_min",
      "feature_name": "processing bytes min",
      "data": 608
    },
    {
      "feature_id": "processing_bytes_sum",
      "feature_name": "processing bytes sum",
      "data": 2970
    },
    {
      "feature_id": "processing_time_max",
      "feature_name": "processing time max",
      "data": 9670
    }
  ],
  "feature_data_processing_bytes_max_data": 1360,
  "feature_data_processing_bytes_avg_data": 990,
  "feature_data_processing_bytes_min_data": 608,
  "feature_data_processing_bytes_sum_data": 2970,
  "feature_data_processing_time_max_data": 9670,
  "expected_values": [
    {
      "likelihood": 1,
      "value_list": [
        {
          "feature_id": "processing_bytes_max",
          "data": 905
        },
        {
          "feature_id": "processing_bytes_avg",
          "data": 479
        },
        {
          "feature_id": "processing_bytes_min",
          "data": 128
        },
        {
          "feature_id": "processing_bytes_sum",
          "data": 4847
        },
        {
          "feature_id": "processing_time_max",
          "data": 15713
        }
      ]
    }
  ],
  "expected_values_processing_bytes_max_data": 905,
  "expected_values_processing_bytes_avg_data": 479,
  "expected_values_processing_bytes_min_data": 128,
  "expected_values_processing_bytes_sum_data": 4847,
  "expected_values_processing_time_max_data": 15713,
  "execution_end_time": 1635898427895,
  "anomaly_grade": 0.5514172746375128,
  "entity": [
    {
      "name": "process_name",
      "value": "process_3"
    }
  ],
  "entity_process_name_value": "process_3",
  "approx_anomaly_start_time": 1635883620000
}

----------------------------------------

TITLE: Analyzing Text with Keyword Analyzer
DESCRIPTION: Demonstrates how to analyze text using the configured keyword analyzer. Shows both the request and response format.

LANGUAGE: json
CODE:
POST /my_index/_analyze
{
  "analyzer": "my_keyword_analyzer",
  "text": "OpenSearch Example"
}

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "OpenSearch Example",
      "start_offset": 0,
      "end_offset": 18,
      "type": "word",
      "position": 0
    }
  ]
}

----------------------------------------

TITLE: Retrieving Document Processed by JSON Processor in OpenSearch
DESCRIPTION: Demonstrates how to retrieve a document that has been processed by the JSON processor pipeline. This query fetches the document with ID 1 from the 'my-index' index.

LANGUAGE: json
CODE:
GET my-index/_doc/1

----------------------------------------

TITLE: Deleting All Ingest Pipelines in OpenSearch Cluster
DESCRIPTION: This API request deletes all ingest pipelines in an OpenSearch cluster. It uses the wildcard character (*) to match all pipeline IDs.

LANGUAGE: json
CODE:
DELETE /_ingest/pipeline/*

----------------------------------------

TITLE: Creating an Index with Unique Token Filter in OpenSearch
DESCRIPTION: This example demonstrates how to create a new index named 'unique_example' with a custom analyzer that includes a unique token filter. The unique filter is configured to remove duplicate tokens across all positions.

LANGUAGE: json
CODE:
PUT /unique_example
{
  "settings": {
    "analysis": {
      "filter": {
        "unique_filter": {
          "type": "unique",
          "only_on_same_position": false
        }
      },
      "analyzer": {
        "unique_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "unique_filter"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Request Body Structure for Secure Settings Reload
DESCRIPTION: Optional request body structure containing the keystore password field used when reloading secure settings.

LANGUAGE: json
CODE:
{
  "secure_settings_password": "keystore_password"
}

----------------------------------------

TITLE: Configuring list_to_map Processor in YAML Pipeline
DESCRIPTION: YAML configuration for a pipeline using the list_to_map processor to transform the input JSON data.

LANGUAGE: yaml
CODE:
pipeline:
  source:
    file:
      path: "/full/path/to/logs_json.log"
      record_type: "event"
      format: "json"
  processor:
    - list_to_map:
        key: "name"
        source: "mylist"
        value_key: "value"
        flatten: true
  sink:
    - stdout:

----------------------------------------

TITLE: Configuring Tenants in tenants.yml
DESCRIPTION: Defines OpenSearch Dashboards tenants. This example adds an admin tenant.

LANGUAGE: yaml
CODE:
---
_meta:
  type: "tenants"
  config_version: 2
admin_tenant:
  reserved: false
  description: "Demo tenant for admin user"

----------------------------------------

TITLE: Disabling a Model in OpenSearch
DESCRIPTION: Example request to disable a specific model by setting the 'is_enabled' field to false.

LANGUAGE: json
CODE:
PUT /_plugins/_ml/models/MzcIJX8BA7mbufL6DOwl
{
    "is_enabled": false
}

----------------------------------------

TITLE: Configuring split_string Processor in YAML
DESCRIPTION: Pipeline configuration for the split_string processor that splits strings into arrays using a delimiter. Demonstrates splitting comma-separated strings into arrays.

LANGUAGE: yaml
CODE:
pipeline:
  source:
    file:
      path: "/full/path/to/logs_json.log"
      record_type: "event"
      format: "json"
  processor:
    - split_string:
        entries:
          - source: "message"
            delimiter: ","
  sink:
    - stdout:

----------------------------------------

TITLE: Retrieving an Index Rollup Job in OpenSearch
DESCRIPTION: This snippet shows how to retrieve information about a specific index rollup job using a GET request with the rollup_id.

LANGUAGE: json
CODE:
GET _plugins/_rollup/jobs/<rollup_id>

----------------------------------------

TITLE: Executing Histogram Aggregation on OpenSearch Index
DESCRIPTION: This query performs a histogram aggregation on the 'bytes' field of the 'opensearch_dashboards_sample_data_logs' index, using an interval of 10,000. It sets the size to 0 to focus only on aggregation results.

LANGUAGE: json
CODE:
{
  "size": 0,
  "aggs": {
    "number_of_bytes": {
      "histogram": {
        "field": "bytes",
        "interval": 10000
      }
    }
  }
}

----------------------------------------

TITLE: Bulk Helper Result Structure in OpenSearch JavaScript Client
DESCRIPTION: Shows the structure of the object returned by bulk helper operations, including total operations, failed operations, retries, successful operations, time taken, bytes processed, and abort status.

LANGUAGE: json
CODE:
{
  total: number,
  failed: number,
  retry: number,
  successful: number,
  time: number,
  bytes: number,
  aborted: boolean
}

----------------------------------------

TITLE: Configuring Nginx Proxy for OpenSearch Authentication
DESCRIPTION: This Nginx configuration sets up a proxy in front of an OpenSearch cluster. It includes upstream server definitions and adds proxy headers for user and role information.

LANGUAGE: nginx
CODE:
events {
  worker_connections  1024;
}

http {

  upstream opensearch {
    server node1.example.com:9200;
    server node2.example.com:9200;
    server node3.example.com:9200;
    keepalive 15;
  }

  server {
    listen       8090;
    server_name  nginx.example.com;

    location / {
      proxy_pass https://opensearch;
      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
      proxy_set_header x-proxy-user test;
      proxy_set_header x-proxy-roles test;
      #proxy_set_header x-proxy-ext-namespace my-namespace;
    }
  }

}

----------------------------------------

TITLE: Querying Indices with Verbose Output - OpenSearch List API
DESCRIPTION: Makes a GET request to list indexes with verbose output including column headers using the v parameter.

LANGUAGE: json
CODE:
GET _list/indices?v

----------------------------------------

TITLE: Amazon SES IAM Policy
DESCRIPTION: Required IAM policy for Amazon SES email transport permissions

LANGUAGE: json
CODE:
{
  "Statement": [
    {
      "Effect": "Allow",
      "Action": "ses:SendRawEmail",
      "Resource": "*"
    }
  ]
}

----------------------------------------

TITLE: Creating Users with Backend Roles for Anomaly Detection
DESCRIPTION: These JSON snippets demonstrate how to create users with specific backend roles for fine-grained access control in anomaly detection.

LANGUAGE: json
CODE:
{
  "password": "alice",
  "backend_roles": [
    "analyst"
  ],
  "attributes": {}
}

LANGUAGE: json
CODE:
{
  "password": "bob",
  "backend_roles": [
    "human-resources"
  ],
  "attributes": {}
}

----------------------------------------

TITLE: Geo Distance Aggregation Response
DESCRIPTION: Example response showing the bucket distribution of documents based on their distance ranges.

LANGUAGE: json
CODE:
{
  "aggregations": {
    "position": {
      "buckets": [
        {
          "key": "*-10.0",
          "from": 0.0,
          "to": 10.0,
          "doc_count": 0
        },
        {
          "key": "10.0-20.0",
          "from": 10.0,
          "to": 20.0,
          "doc_count": 0
        },
        {
          "key": "20.0-50.0",
          "from": 20.0,
          "to": 50.0,
          "doc_count": 0
        },
        {
          "key": "50.0-100.0",
          "from": 50.0,
          "to": 100.0,
          "doc_count": 0
        },
        {
          "key": "100.0-*",
          "from": 100.0,
          "doc_count": 14074
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Example Response for Sampler Aggregation with Terms in OpenSearch
DESCRIPTION: Illustrates the structure of a response from a sampler aggregation with a nested terms aggregation. It shows the total document count and the top buckets from the terms aggregation on the agent.keyword field.

LANGUAGE: json
CODE:
"aggregations" : {
  "sample" : {
    "doc_count" : 1000,
    "terms" : {
      "doc_count_error_upper_bound" : 0,
      "sum_other_doc_count" : 0,
      "buckets" : [
        {
          "key" : "Mozilla/5.0 (X11; Linux x86_64; rv:6.0a1) Gecko/20110421 Firefox/6.0a1",
          "doc_count" : 368
        },
        {
          "key" : "Mozilla/5.0 (X11; Linux i686) AppleWebKit/534.24 (KHTML, like Gecko) Chrome/11.0.696.50 Safari/534.24",
          "doc_count" : 329
        },
        {
          "key" : "Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR 1.1.4322)",
          "doc_count" : 303
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Configuring Tail Sampling in OpenSearch Data Prepper
DESCRIPTION: Configuration for tail sampling of OpenTelemetry traces. Processes all traces with error status 2 and samples 20% of other traces. Includes a 10-second wait period for aggregation completion.

LANGUAGE: json
CODE:
  processor:
   - aggregate:                                                                                                                                          
        identification_keys: ["traceId"]                                                                                                                   
        action:                                                                                                                                           
          tail_sampler:                                                                                                                                   
            percent: 20                                                                                                                                   
            wait_period: "10s"                                                                                                                            
            condition: "/status == 2"

----------------------------------------

TITLE: Configuring Search Request Slow Logs in JSON
DESCRIPTION: Shows how to enable and configure search request slow logs using the Cluster Settings API, setting thresholds for different log levels.

LANGUAGE: json
CODE:
PUT /_cluster/settings
{
"persistent" : {
      "cluster.search.request.slowlog.level" : "TRACE",
      "cluster.search.request.slowlog.threshold.warn": "10s",
      "cluster.search.request.slowlog.threshold.info": "5s",
      "cluster.search.request.slowlog.threshold.debug": "2s",
      "cluster.search.request.slowlog.threshold.trace": "10ms"
}
}

----------------------------------------

TITLE: Join Processor Basic Configuration
DESCRIPTION: Basic JSON configuration syntax for the join processor showing the required field and separator parameters.

LANGUAGE: json
CODE:
{
  "join": {
    "field": "field_name",
    "separator": "separator_string"
  }
}

----------------------------------------

TITLE: Italian Analyzer Token Generation Results
DESCRIPTION: Sample response showing the tokens generated by the Italian analyzer including position and offset information.

LANGUAGE: json
CODE:
{
  "tokens": [
    {"token": "student","start_offset": 4,"end_offset": 12,"type": "<ALPHANUM>","position": 1},
    {"token": "studian","start_offset": 13,"end_offset": 21,"type": "<ALPHANUM>","position": 2},
    {"token": "universit","start_offset": 28,"end_offset": 38,"type": "<ALPHANUM>","position": 4},
    {"token": "italian","start_offset": 39,"end_offset": 47,"type": "<ALPHANUM>","position": 5},
    {"token": "numer","start_offset": 56,"end_offset": 62,"type": "<ALPHANUM>","position": 8},
    {"token": "123456","start_offset": 68,"end_offset": 74,"type": "<NUM>","position": 10}
  ]
}

----------------------------------------

TITLE: Single Index Information Request
DESCRIPTION: Example request for retrieving information about a specific index

LANGUAGE: json
CODE:
GET _list/indices/<index>?v

----------------------------------------

TITLE: Basic OpenSearch Source Configuration (YAML)
DESCRIPTION: Minimum required configuration for using the OpenSearch source plugin with basic authentication.

LANGUAGE: yaml
CODE:
opensearch-source-pipeline:
 source:
  opensearch:
    hosts: [ "https://localhost:9200" ]
    username: "username"
    password: "password"
 ...

----------------------------------------

TITLE: OpenSearch PUT Document Example
DESCRIPTION: Example of adding a document with a specified ID to a sample index using PUT request. Demonstrates adding a document with name, price, and description fields.

LANGUAGE: json
CODE:
PUT /sample_index/_doc/1
{
  "name": "Example",
  "price": 29.99,
  "description": "To be or not to be, that is the question"
}

----------------------------------------

TITLE: Configuring Page Layout in YAML
DESCRIPTION: YAML configuration file defining the layout, navigation structure, and semantic search tutorial collection for the OpenSearch documentation. Includes redirect rules and detailed tutorial cards with platform, model, and deployment information.

LANGUAGE: yaml
CODE:
---
layout: default
title: Semantic search
parent: Vector search
has_children: true
has_toc: false
nav_order: 50
redirect_from:
  - /vector-search/tutorials/semantic-search/
  - /tutorials/vector-search/semantic-search/
semantic_search:
  - heading: "Semantic search using the OpenAI embedding model"
    link: "/tutorials/vector-search/semantic-search/semantic-search-openai/"
    list:
      - "<b>Platform:</b> OpenSearch, Amazon OpenSearch Service"
      - "<b>Model:</b> OpenAI embedding"  
      - "<b>Deployment:</b> Provider API"
# [Additional entries omitted for brevity]
---

----------------------------------------

TITLE: OpenSearch Connection Setup Examples
DESCRIPTION: Different methods of establishing connections to OpenSearch using the client, including single node and multiple node configurations.

LANGUAGE: csharp
CODE:
var client = new OpenSearchClient();

var nodeAddress = new Uri("http://myserver:9200");
var client = new OpenSearchClient(nodeAddress);

var nodes = new Uri[]
{
    new Uri("http://myserver1:9200"),
    new Uri("http://myserver2:9200"),
    new Uri("http://myserver3:9200")
};

var pool = new StaticConnectionPool(nodes);
var settings = new ConnectionSettings(pool);
var client = new OpenSearchClient(settings);

----------------------------------------

TITLE: Diagnostic Mode Command Example
DESCRIPTION: Command example showing how to run securityadmin.sh in diagnostic mode for detailed troubleshooting information.

LANGUAGE: bash
CODE:
./securityadmin.sh -diagnose -cd ../../../config/opensearch-security/ -cacert ... -cert ... -key ... -keypass ...

----------------------------------------

TITLE: Enabling Backend Role Filtering for Flow Framework in OpenSearch
DESCRIPTION: This snippet shows how to enable backend role filtering for the Flow Framework plugin in OpenSearch. This setting allows for fine-grained access control based on user roles.

LANGUAGE: json
CODE:
PUT _cluster/settings
{
  "transient": {
    "plugins.flow_framework.filter_by_backend_roles": "true"
  }
}

----------------------------------------

TITLE: Configuring Proxy Authentication in OpenSearch YAML
DESCRIPTION: This YAML snippet configures proxy authentication settings in OpenSearch. It specifies the HTTP authenticator type, user and roles headers, and sets the authentication backend to 'noop'.

LANGUAGE: yaml
CODE:
proxy_auth_domain:
  http_enabled: true
  transport_enabled: true
  order: 0
  http_authenticator:
    type: proxy
    challenge: false
    config:
      user_header: "x-proxy-user"
      roles_header: "x-proxy-roles"
  authentication_backend:
    type: noop

----------------------------------------

TITLE: Parsing Anomaly Detection Results in JSON (Anomaly Detected)
DESCRIPTION: Example JSON structure of an anomaly detection result when an anomaly is detected. Includes additional fields such as relevant_attribution and expected_values.

LANGUAGE: json
CODE:
{
  "detector_id": "fylE53wBc9MCt6q12tKp",
  "schema_version": 0,
  "data_start_time": 1635927900000,
  "data_end_time": 1635927960000,
  "feature_data": [
    {
      "feature_id": "processing_bytes_max",
      "feature_name": "processing bytes max",
      "data": 2291
    },
    {
      "feature_id": "processing_bytes_avg",
      "feature_name": "processing bytes avg",
      "data": 1677.3333333333333
    },
    {
      "feature_id": "processing_bytes_min",
      "feature_name": "processing bytes min",
      "data": 1054
    },
    {
      "feature_id": "processing_bytes_sum",
      "feature_name": "processing bytes sum",
      "data": 5032
    },
    {
      "feature_id": "processing_time_max",
      "feature_name": "processing time max",
      "data": 11422
    }
  ],
  "anomaly_score": 1.1986675882872033,
  "anomaly_grade": 0.26806225550178464,
  "confidence": 0.9607519742565531,
  "entity": [
    {
      "name": "process_name",
      "value": "process_3"
    }
  ],
  "approx_anomaly_start_time": 1635927900000,
  "relevant_attribution": [
    {
      "feature_id": "processing_bytes_max",
      "data": 0.03628638020431366
    },
    {
      "feature_id": "processing_bytes_avg",
      "data": 0.03384479053991436
    },
    {
      "feature_id": "processing_bytes_min",
      "data": 0.058812549572819096
    },
    {
      "feature_id": "processing_bytes_sum",
      "data": 0.10154576265526988
    },
    {
      "feature_id": "processing_time_max",
      "data": 0.7695105170276828
    }
  ],
  "expected_values": [
    {
      "likelihood": 1,
      "value_list": [
        {
          "feature_id": "processing_bytes_max",
          "data": 2291
        },
        {
          "feature_id": "processing_bytes_avg",
          "data": 1677.3333333333333
        },
        {
          "feature_id": "processing_bytes_min",
          "data": 1054
        },
        {
          "feature_id": "processing_bytes_sum",
          "data": 6062
        },
        {
          "feature_id": "processing_time_max",
          "data": 23379
        }
      ]
    }
  ],
  "threshold": 1.0993584705913992,
  "execution_end_time": 1635898427895,
  "execution_start_time": 1635898427803
}

----------------------------------------

TITLE: Amazon OpenSearch Serverless Configuration (YAML)
DESCRIPTION: Configuration for connecting to an Amazon OpenSearch Serverless collection.

LANGUAGE: yaml
CODE:
    - opensearch:
        hosts: [ 'https://1234567890abcdefghijkl.us-west-2.aoss.amazonaws.com' ]
        aws:
          sts_role_arn: 'arn:aws:iam::123456789012:role/my-domain-role'
          region: 'us-west-2'
          serverless: true

----------------------------------------

TITLE: Displaying OpenSearch Dashboards Index Information
DESCRIPTION: This snippet shows how to display information about an index named 'stocks' in OpenSearch Dashboards. It includes details such as health status, number of shards, document count, and storage size.

LANGUAGE: bash
CODE:
health status index  uuid              pri rep docs.count docs.deleted store.size pri.store.size
green  open   stocks asjdkfjacklajldf   12   1  997818020    232823733    720gb    360gb

----------------------------------------

TITLE: Configuring Basic Basque Analyzer in OpenSearch
DESCRIPTION: Sets up a basic index mapping using the built-in Basque analyzer for text fields.

LANGUAGE: json
CODE:
PUT /basque-index
{
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "basque"
      }
    }
  }
}

----------------------------------------

TITLE: Retrieving CAT API Aliases in JSON Format in OpenSearch
DESCRIPTION: This example shows how to retrieve CAT API aliases data in JSON format instead of the default plain text. It uses the 'format=json' query parameter.

LANGUAGE: json
CODE:
GET _cat/aliases?format=json

----------------------------------------

TITLE: Ingesting Document with Pipeline
DESCRIPTION: Shows how to ingest a document using the configured pipeline.

LANGUAGE: json
CODE:
{
  "protocol": "https",
  "name": "test"
}

----------------------------------------

TITLE: Enabling Backend Role Filtering for Anomaly Detection
DESCRIPTION: This JSON snippet shows how to enable filtering of anomaly detection resources based on backend roles using the OpenSearch cluster settings API.

LANGUAGE: json
CODE:
{
  "transient": {
    "plugins.anomaly_detection.filter_by_backend_roles": "true"
  }
}

----------------------------------------

TITLE: Has Child Query with Function Score - OpenSearch JSON
DESCRIPTION: Advanced has_child query using function_score to sort parent documents based on child document field values.

LANGUAGE: json
CODE:
GET testindex1/_search
{
  "query": {
    "has_child": {
      "type": "product",
      "query": {
        "function_score": {
          "script_score": {
            "script": "_score * doc['sales_count'].value"
          }
        }
      },
      "score_mode": "max"
    }
  }
}

----------------------------------------

TITLE: Indexing a Document in OpenSearch using Rust
DESCRIPTION: Index a single document into OpenSearch using the index() function.

LANGUAGE: rust
CODE:
let response = client
    .index(IndexParts::IndexId("movies", "1"))
    .body(json!({
        "id": 1,
        "title": "Moneyball",
        "director": "Bennett Miller",
        "year": "2011"
    }))
    .send()
    .await?;

----------------------------------------

TITLE: Generating OBO Token via REST API
DESCRIPTION: JSON request body for the POST /_plugins/_security/api/generateonbehalfoftoken endpoint to create a short-lived OBO token.

LANGUAGE: json
CODE:
{
   "description":"Testing",
   "service":"Testing Service",
   "durationSeconds":"180"
}

----------------------------------------

TITLE: Restoring Unassigned Shards from Remote Backup
DESCRIPTION: cURL command to restore only unassigned shards from a remote backup for specified indices using the REST API.

LANGUAGE: bash
CODE:
curl -X POST "https://localhost:9200/_remotestore/_restore" -H 'Content-Type: application/json' -d'
{
  "indices": ["my-index-1", "my-index-2"]
}
'

----------------------------------------

TITLE: Configuring Secure Metrics Store with Self-Signed Certificate in INI Format
DESCRIPTION: This example shows how to configure a secure connection to a metrics store in the local network with a self-signed certificate. It sets the datastore type, host, port, security settings, and user credentials.

LANGUAGE: ini
CODE:
[results_publishing]
datastore.type = opensearch
datastore.host = 192.168.10.22
datastore.port = 9200
datastore.secure = true
datastore.ssl.verification_mode = none
datastore.user = user-name
datastore.password = the-password-to-your-cluster

----------------------------------------

TITLE: Analyzing Text with ASCII Folding Filter
DESCRIPTION: Demonstrates how to analyze text using the custom ASCII folding analyzer. Shows the analysis of text containing accented characters.

LANGUAGE: json
CODE:
POST /example_index/_analyze
{
  "analyzer": "custom_ascii_analyzer",
  "text": "Rsum caf nave cordinate"
}

----------------------------------------

TITLE: Example Response Format
DESCRIPTION: Illustrates the expected response format showing node operation results.

LANGUAGE: json
CODE:
{
  "_nodes" : {
    "total" : 1,
    "successful" : 1,
    "failed" : 0
  }
}

----------------------------------------

TITLE: Configuring SAML Entity ID in OpenSearch Dashboards YAML
DESCRIPTION: This snippet shows how to set the sp.entity_id in the SAML configuration of OpenSearch Dashboards. The entity ID should match the settings in your identity provider.

LANGUAGE: yaml
CODE:
saml:
  ...
  http_authenticator:
    type: 'saml'
    challenge: true
    config:
      ...
      sp:
        entity_id: opensearch-dashboards-saml

----------------------------------------

TITLE: Specifying JSON Response Format for SQL Query in OpenSearch
DESCRIPTION: Shows how to specify the JSON response format for an SQL query in OpenSearch using the 'format' parameter in the REST API request.

LANGUAGE: json
CODE:
POST _plugins/_sql?format=json
{
  "query": "SELECT * FROM my-index LIMIT 50"
}

----------------------------------------

TITLE: Specifying Search Analyzer for Query in OpenSearch (JSON)
DESCRIPTION: This snippet demonstrates how to specify a search analyzer for a query string in OpenSearch. It uses the 'english' analyzer for the 'text_entry' field in a match query against the 'shakespeare' index.

LANGUAGE: json
CODE:
GET shakespeare/_search
{
  "query": {
    "match": {
      "text_entry": {
        "query": "speak the truth",
        "analyzer": "english"
      }
    }
  }
}

----------------------------------------

TITLE: Legacy Cluster-Level Concurrent Search Enable Setting
DESCRIPTION: Uses the deprecated search.concurrent_segment_search.enabled setting to enable concurrent segment search at cluster level.

LANGUAGE: json
CODE:
PUT _cluster/settings
{
   "persistent":{
      "search.concurrent_segment_search.enabled": true
   }
}

----------------------------------------

TITLE: Querying Documents by Routing Value in OpenSearch
DESCRIPTION: Example of querying documents based on their routing value using the _routing field. This query searches only the shard(s) associated with the 'JohnDoe1' routing value.

LANGUAGE: json
CODE:
GET sample-index1/_search
{
  "query": {
    "terms": {
      "_routing": [ "JohnDoe1" ]
    }
  }
}

----------------------------------------

TITLE: Register Private Model Group
DESCRIPTION: Example request for registering a model group with private access mode

LANGUAGE: json
CODE:
{
    "name": "model_group_test",
    "description": "This is an example description",
    "access_mode": "private"
}

----------------------------------------

TITLE: WriteJson Processor Output Example
DESCRIPTION: The resulting JSON string output after processing, showing how nested objects are serialized.

LANGUAGE: json
CODE:
"{\"key1\":\"value1\",\"key2\":{\"key3\":\"value3\"}}"

----------------------------------------

TITLE: Requesting Script Language Information in OpenSearch
DESCRIPTION: Simple GET request to retrieve information about supported script languages and their contexts.

LANGUAGE: json
CODE:
GET _script_language

----------------------------------------

TITLE: Analyzing Text with Trim Token Filter
DESCRIPTION: Example request to analyze text using the custom analyzer with trim filter. Shows how the analyzer processes text with extra whitespace around tokens.

LANGUAGE: json
CODE:
GET /my_pattern_trim_index/_analyze
{
  "analyzer": "my_pattern_trim_analyzer",
  "text": " OpenSearch ,  is ,   powerful  "
}

----------------------------------------

TITLE: Running Data Prepper Docker image with Logstash configuration
DESCRIPTION: This command runs the Data Prepper Docker image, mapping the local logstash.conf file to the container's pipelines.conf. It exposes port 4900 and uses the latest version of the Data Prepper image.

LANGUAGE: bash
CODE:
docker run --name data-prepper -p 4900:4900 -v ${PWD}/logstash.conf:/usr/share/data-prepper/pipelines.conf opensearchproject/data-prepper:latest pipelines.conf

----------------------------------------

TITLE: Simple PPL Index Query
DESCRIPTION: Basic example demonstrating how to retrieve all documents from an index using the search command.

LANGUAGE: sql
CODE:
search source=accounts;

----------------------------------------

TITLE: Disabling Source Field in OpenSearch Index
DESCRIPTION: Shows how to disable the _source field in an OpenSearch index mapping by setting the enabled parameter to false. This can help reduce storage requirements but limits certain functionality like updates and reindexing.

LANGUAGE: json
CODE:
PUT sample-index1
{
  "mappings": {
    "_source": {
      "enabled": false
    }
  }
}

----------------------------------------

TITLE: Setting Environment Variables in Linux
DESCRIPTION: Basic syntax for setting environment variables in Linux systems

LANGUAGE: bash
CODE:
export NAME=VALUE

----------------------------------------

TITLE: Calculating HNSW Memory Requirement with PQ in R
DESCRIPTION: Estimates the memory required for HNSW with PQ, given specific parameters such as number of vectors, dimensions, and PQ settings.

LANGUAGE: r
CODE:
1.1 * ((8 / 8 * 32 + 24 + 8 * 16) * 1000000 + 100 * (2^8 * 4 * 256)) ~= 0.215 GB

----------------------------------------

TITLE: Paginating PIT Search Results with search_after in OpenSearch
DESCRIPTION: Demonstrates how to implement pagination in PIT search using the search_after parameter, allowing retrieval of subsequent result pages.

LANGUAGE: json
CODE:
{
  "size": 10000,
  "query": {
    "match" : {
      "user.id" : "elkbee"
    }
  },
  "pit": {
    "id":  "46ToAwMDaWR5BXV1aWQyKwZub2RlXzMAAAAAAAAAACoBYwADaWR4BXV1aWQxAgZub2RlXzEAAAAAAAAAAAEBYQADaWR5BXV1aWQyKgZub2RlXzIAAAAAAAAAAAwBYgACBXV1aWQyAAAFdXVpZDEAAQltYXRjaF9hbGw_gAAAAA==", 
    "keep_alive": "100m"
  },
  "sort": [ 
    {"@timestamp": {"order": "asc"}}
  ],
  "search_after": [  
    "2021-05-20T05:30:04.832Z"
  ]
}

----------------------------------------

TITLE: Removing OpenSearch Dashboards Plugins
DESCRIPTION: This command removes a specified OpenSearch Dashboards plugin using the opensearch-dashboards-plugin tool. Replace <plugin-name> with the actual plugin name.

LANGUAGE: bash
CODE:
sudo bin/opensearch-dashboards-plugin remove <plugin-name>

----------------------------------------

TITLE: Setting Environment Variables for IAM Role in Bash
DESCRIPTION: Exports the necessary environment variables for AWS Signature Version 4 authentication using an IAM role. This includes the access key ID, secret access key, session token, region, and service name.

LANGUAGE: bash
CODE:
export OSB_AWS_ACCESS_KEY_ID=<IAM Role AWS ACCESS KEY ID>
export OSB_AWS_SECRET_ACCESS_KEY=<IAM Role AWS SECRET ACCESS KEY>
export OSB_AWS_SESSION_TOKEN=<IAM Role SESSION TOKEN>
export OSB_REGION=<YOUR REGION>
export OSB_SERVICE=es

----------------------------------------

TITLE: Custom Logo Configuration Example
DESCRIPTION: Example configuration showing how to customize the logo and application title while leaving other elements as defaults.

LANGUAGE: yaml
CODE:
logo:
  defaultUrl: "https://example.com/validUrl.svg"
  darkModeUrl: "https://example.com/validDarkModeUrl.svg"
# mark:
#   defaultUrl: ""
#   darkModeUrl: ""
# loadingLogo:
#   defaultUrl: ""
#   darkModeUrl: ""
# faviconUrl: ""
applicationTitle: "My custom application"

----------------------------------------

TITLE: Phone Number Standardization using Pattern Replace Filter
DESCRIPTION: Example of using pattern_replace character filter to standardize phone numbers by removing spaces, dashes, and parentheses.

LANGUAGE: json
CODE:
{
  "tokenizer": "standard",
  "char_filter": [
    {
      "type": "pattern_replace",
      "pattern": "[\\s()-]+",
      "replacement": ""
    }
  ],
  "text": "(555) 123-4567"
}

----------------------------------------

TITLE: Configuring Time Sampling in OpenSearch Data Prepper
DESCRIPTION: Configuration example for time-based sampling using the rate_limiter action. Limits processing to 100 events per second per IP address for events with status code 200. Excess events are dropped.

LANGUAGE: json
CODE:
  processor:
   - aggregate:                                                                                                                                          
        identification_keys: ["clientip"]                                                                                                      
        action:                                                                                                                                           
          rate_limiter:                                                                                                                                   
            events_per_second: 100                                                                                                                        
            when_exceeds: drop
        when: "/status == 200"

----------------------------------------

TITLE: Configuring /dev/shm Size in Docker
DESCRIPTION: Commands to configure the /dev/shm size for Docker and Docker Compose to accommodate Performance Analyzer's storage requirements.

LANGUAGE: bash
CODE:
docker run --shm-size 1gb

----------------------------------------

TITLE: Creating Index with Size Mapping in OpenSearch
DESCRIPTION: cURL command to create an index with size mapping enabled, including configuration for text and integer fields.

LANGUAGE: sh
CODE:
curl -XPUT example-index -H "Content-Type: application/json" -d '{
  "mappings": {
    "_size": {
      "enabled": true
    },
    "properties": {
      "name": {
        "type": "text"
      },
      "age": {
        "type": "integer"
      }
    }
  }
}'

----------------------------------------

TITLE: Configuring Stem Exclusion for Spanish Analyzer in OpenSearch
DESCRIPTION: This snippet shows how to use the stem_exclusion option with the Spanish analyzer to exclude specific words from stemming.

LANGUAGE: json
CODE:
PUT index_with_stem_exclusion_spanish_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "stem_exclusion_spanish_analyzer": {
          "type": "spanish",
          "stem_exclusion": ["autoridad", "aprobacin"]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Successful Operation Response
DESCRIPTION: Standard response returned by OpenSearch when successfully allocating shards.

LANGUAGE: json
CODE:
{
     "acknowledged": true
}

----------------------------------------

TITLE: Amazon OpenSearch Service Configuration (YAML)
DESCRIPTION: Configuration for connecting to an Amazon OpenSearch Service domain using IAM role authentication.

LANGUAGE: yaml
CODE:
opensearch-source-pipeline:
  source:
    opensearch:
      hosts: [ "https://search-my-domain-soopywaovobopgs8ywurr3utsu.us-east-1.es.amazonaws.com" ]
      aws:
        region: "us-east-1"
        sts_role_arn: "arn:aws:iam::123456789012:role/my-domain-role"
  ...

----------------------------------------

TITLE: Updating a monitor in OpenSearch
DESCRIPTION: Updates an existing monitor with new configuration. Optionally includes sequence number and primary term for optimistic concurrency control.

LANGUAGE: json
CODE:
PUT _plugins/_alerting/monitors/<monitor_id>
{
  "type": "monitor",
  "name": "test-monitor",
  "enabled": true,
  "enabled_time": 1551466220455,
  "schedule": {
    "period": {
      "interval": 1,
      "unit": "MINUTES"
    }
  },
  "inputs": [{
    "search": {
      "indices": [
        "*"
      ],
      "query": {
        "query": {
          "match_all": {
            "boost": 1
          }
        }
      }
    }
  }],
  "triggers": [{
    "id": "StaeOmkBC25HCRGmL_y-",
    "name": "test-trigger",
    "severity": "1",
    "condition": {
      "script": {
        "source": "return true",
        "lang": "painless"
      }
    },
    "actions": [{
      "name": "test-action",
      "destination_id": "RtaaOmkBC25HCRGm0fxi",
      "subject_template": {
        "source": "My Message Subject",
        "lang": "mustache"
      },
      "message_template": {
        "source": "This is my message body.",
        "lang": "mustache"
      }
    }]
  }],
  "last_update_time": 1551466639295
}

----------------------------------------

TITLE: Example Response Structure
DESCRIPTION: Sample response showing the structure of a successful document retrieval operation.

LANGUAGE: json
CODE:
{\n  "_index": "sample-index1",\n  "_id": "1",\n  "_version": 1,\n  "_seq_no": 0,\n  "_primary_term": 9,\n  "found": true,\n  "_source": {\n    "text": "This is just some sample text."\n  }\n}

----------------------------------------

TITLE: Setting OpenSearch Environment Variables at Startup
DESCRIPTION: Demonstrates how to specify OpenSearch environment variables as command line arguments during startup using the -E flag.

LANGUAGE: bash
CODE:
./opensearch -Ecluster.name=opensearch-cluster -Enode.name=opensearch-node1 -Ehttp.host=0.0.0.0 -Ediscovery.type=single-node

----------------------------------------

TITLE: Re-enabling Shard Replication in OpenSearch
DESCRIPTION: Re-enables shard replication after migration using the Cluster Settings API.

LANGUAGE: json
CODE:
PUT "/_cluster/settings?pretty"
{
    "persistent": {
        "cluster.routing.allocation.enable": "all"
    }
}

----------------------------------------

TITLE: Configuring TLS Protocol Versions in YAML
DESCRIPTION: Configuration example for enabling specific TLS versions in opensearch.yml

LANGUAGE: yaml
CODE:
plugins.security.ssl.http.enabled_protocols:
  - "TLSv1"
  - "TLSv1.1"
  - "TLSv1.2"

----------------------------------------

TITLE: Creating an Index with Geoshape Mapping in OpenSearch
DESCRIPTION: This snippet shows how to create an index named 'national_parks' with a 'location' field mapped as a geo_shape type.

LANGUAGE: json
CODE:
PUT national_parks
{
  "mappings": {
    "properties": {
      "location": {
        "type": "geo_shape"
      }
    }
  }
}

----------------------------------------

TITLE: Querying OpenSearch Explain API Endpoints
DESCRIPTION: Basic endpoint definitions for the OpenSearch Explain API that allow retrieving explanation for document scoring.

LANGUAGE: json
CODE:
GET <index>/_explain/<id>\nPOST <index>/_explain/<id>

----------------------------------------

TITLE: Customizing OpenSearch Dashboards deployment with Helm
DESCRIPTION: This command shows how to install OpenSearch Dashboards using a custom values file to override default settings in the Helm chart.

LANGUAGE: bash
CODE:
helm install --values=customvalues.yaml opensearch-dashboards-1.0.0.tgz

----------------------------------------

TITLE: Creating Boolean Field Mapping in OpenSearch
DESCRIPTION: Example of creating an index mapping with three Boolean fields (a, b, and c). Demonstrates the basic structure for defining Boolean type fields in OpenSearch.

LANGUAGE: json
CODE:
PUT testindex
{
  "mappings" : {
    "properties" :  {
      "a" : {
        "type" : "boolean"
      },
      "b" : {
        "type" : "boolean"
      },
      "c" : {
        "type" : "boolean"
      }
    }
  }
}

----------------------------------------

TITLE: Indexing a Document with IP Address Ranges in OpenSearch
DESCRIPTION: This example demonstrates how to index a document in OpenSearch with IP address ranges. It shows both standard IP range format and CIDR notation for specifying IP ranges.

LANGUAGE: json
CODE:
PUT testindex/_doc/2
{
  "ip_address_range" : {
    "gte" : "10.24.34.0",
    "lte" : "10.24.35.255"
  },
  "ip_address_cidr" : "10.24.34.0/24"
}

----------------------------------------

TITLE: Creating Index with Stop Token Filter
DESCRIPTION: Creates a new index with a custom analyzer that uses the stop token filter configured for English stopwords. The analyzer includes a standard tokenizer and lowercase filter in addition to the stop filter.

LANGUAGE: json
CODE:
PUT /my-stopword-index
{
  "settings": {
    "analysis": {
      "filter": {
        "my_stop_filter": {
          "type": "stop",
          "stopwords": "_english_"
        }
      },
      "analyzer": {
        "my_stop_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "my_stop_filter"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Verifying OpenSearch Dashboards Package Signature
DESCRIPTION: Commands to download the OpenSearch Dashboards package, signature file, GPG key, and verify the package signature.

LANGUAGE: bash
CODE:
curl -SLO https://artifacts.opensearch.org/releases/bundle/opensearch-dashboards/{{site.opensearch_version}}/opensearch-dashboards-{{site.opensearch_version}}-linux-x64.deb
curl -SLO https://artifacts.opensearch.org/releases/bundle/opensearch-dashboards/{{site.opensearch_version}}/opensearch-dashboards-{{site.opensearch_version}}-linux-x64.deb.sig
curl -o- https://artifacts.opensearch.org/publickeys/opensearch.pgp | gpg --import -
gpg --verify opensearch-dashboards-{{site.opensearch_version}}-linux-x64.deb.sig opensearch-dashboards-{{site.opensearch_version}}-linux-x64.deb

----------------------------------------

TITLE: Calculating average cost and margin by action
DESCRIPTION: SQL query to compute the average cost and margin for different user actions, grouping by action_name in the ubi_events table.

LANGUAGE: sql
CODE:
select 
    action_name, 
    count(0) total,
    AVG( event_attributes.object.object_detail.cost ) average_cost,
    AVG( event_attributes.object.object_detail.margin ) average_margin
from ubi_events  
group by action_name
order by average_cost desc

----------------------------------------

TITLE: Disabling Automatic Deployment for Externally Hosted Models in OpenSearch
DESCRIPTION: JSON request to disable automatic deployment of externally hosted models by setting a cluster setting.

LANGUAGE: json
CODE:
PUT _cluster/settings
{
  "persistent": {
    "plugins.ml_commons.model_auto_deploy.enable": "false"
  }
}

----------------------------------------

TITLE: Creating Index Mapping with Flat Object Field in OpenSearch
DESCRIPTION: This snippet demonstrates how to create an index mapping with a field of type 'flat_object' in OpenSearch.

LANGUAGE: json
CODE:
PUT /test-index/
{
  "mappings": {
    "properties": {
      "issue": {
        "type": "flat_object"
      }
    }
  }
}

----------------------------------------

TITLE: Creating Script Pipeline
DESCRIPTION: Example of creating an ingest pipeline with a script processor that converts a message field to uppercase using Painless script.

LANGUAGE: json
CODE:
{
  "description": "Example pipeline using the ScriptProcessor",
  "processors": [
    {
      "script": {
        "source": "ctx.message = ctx.message.toUpperCase()",
        "lang": "painless",
        "description": "Convert message field to uppercase"
      }
    }
  ]
}

----------------------------------------

TITLE: Defining a Document Class
DESCRIPTION: Create a Python class to represent documents that will be indexed in OpenSearch, extending the Document class from opensearch_dsl.

LANGUAGE: python
CODE:
class Movie(Document):
    title = Text(fields={'raw': Keyword()})
    director = Text()
    year = Text()

    class Index:
        name = index_name

    def save(self, ** kwargs):
        return super(Movie, self).save(** kwargs)

----------------------------------------

TITLE: Low-Precision Geotile Grid Aggregation Query in OpenSearch
DESCRIPTION: This query performs a low-precision geotile grid aggregation on the 'location' field with a precision of 1.

LANGUAGE: json
CODE:
GET national_parks/_search
{
  "aggregations": {
    "grouped": {
      "geotile_grid": {
        "field": "location",
        "precision": 1
      }
    }
  }
}

----------------------------------------

TITLE: Error Response for Existing Index Conflict in OpenSearch Snapshot Restoration
DESCRIPTION: This error response is returned when attempting to restore an index that already exists in the cluster. It suggests closing, deleting, or renaming the existing index before restoration.

LANGUAGE: json
CODE:
{
  "error" : {
    "root_cause" : [
      {
        "type" : "snapshot_restore_exception",
        "reason" : "[my-opensearch-repo:my-first-snapshot/dCK4Qth-TymRQ7Tu7Iga0g] cannot restore index [.opendistro-reports-definitions] because an open index with same name already exists in the cluster. Either close or delete the existing index or restore the index under a different name by providing a rename pattern and replacement name"
      }
    ],
    "type" : "snapshot_restore_exception",
    "reason" : "[my-opensearch-repo:my-first-snapshot/dCK4Qth-TymRQ7Tu7Iga0g] cannot restore index [.opendistro-reports-definitions] because an open index with same name already exists in the cluster. Either close or delete the existing index or restore the index under a different name by providing a rename pattern and replacement name"
  },
  "status" : 500
}

----------------------------------------

TITLE: Creating a Covering Index in OpenSearch SQL
DESCRIPTION: This SQL query creates a covering index named 'vpc_covering_index' on a VPC logs table. It includes various columns and specifies auto-refresh settings and checkpoint location.

LANGUAGE: sql
CODE:
CREATE INDEX vpc_covering_index
ON datasourcename.gluedatabasename.vpclogstable (version, account_id, interface_id, 
srcaddr, dstaddr, srcport, dstport, protocol, packets, 
bytes, start, action, log_status STRING, 
`aws-account-id`, `aws-service`, `aws-region`, year, 
month, day, hour )
WITH (
  auto_refresh = true,
  refresh_interval = '15 minute',
  checkpoint_location = 's3://accountnum-vpcflow/AWSLogs/checkpoint'
)

----------------------------------------

TITLE: Authentication Domain Configuration
DESCRIPTION: Structure for configuring authentication domains including HTTP and transport layer settings, order, and authenticator configuration.

LANGUAGE: yaml
CODE:
authc:
  <domain_name>:
    http_enabled: <true|false>
    transport_enabled: <true|false>
    order: <integer>
    http_authenticator:
      ...
    authentication_backend:
      ...

----------------------------------------

TITLE: Customizing OpenSearch Admin Password in values.yaml
DESCRIPTION: YAML configuration to customize the admin password for OpenSearch 2.12 or greater.

LANGUAGE: yaml
CODE:
extraEnvs:
  - name: OPENSEARCH_INITIAL_ADMIN_PASSWORD
    value: <custom-admin-password>

----------------------------------------

TITLE: Parsing Performance Analyzer API Response in OpenSearch
DESCRIPTION: Shows the JSON structure of a Performance Analyzer API response, including timestamp, field definitions, and metric values for multiple nodes and shards.

LANGUAGE: json
CODE:
{
  "keHlhQbbTpm1BYicficEQg": {
    "timestamp": 1554940530000,
    "data": {
      "fields": [{
          "name": "ShardID",
          "type": "VARCHAR"
        },
        {
          "name": "Latency",
          "type": "DOUBLE"
        },
        {
          "name": "CPU_Utilization",
          "type": "DOUBLE"
        }
      ],
      "records": [
        [
          null,
          null,
          0.012552206029147535
        ],
        [
          "1",
          4.8,
          0.0009780939762972104
        ]
      ]
    }
  },
  "bHdpbMJZTs-TKtZro2SmYA": {
    "timestamp": 1554940530000,
    "data": {
      "fields": [{
          "name": "ShardID",
          "type": "VARCHAR"
        },
        {
          "name": "Latency",
          "type": "DOUBLE"
        },
        {
          "name": "CPU_Utilization",
          "type": "DOUBLE"
        }
      ],
      "records": [
        [
          null,
          18.2,
          0.011966493817311527
        ],
        [
          "1",
          14.8,
          0.0007670829370071493
        ]
      ]
    }
  }
}

----------------------------------------

TITLE: Creating a Memory for Conversational Search in OpenSearch
DESCRIPTION: This snippet shows how to create a memory for storing conversation history in OpenSearch. It specifies a name for the conversation topic.

LANGUAGE: json
CODE:
POST /_plugins/_ml/memory/
{
"name": "Conversation about NYC population"
}

----------------------------------------

TITLE: Match Query with Fuzziness in OpenSearch
DESCRIPTION: A Match query using fuzziness to account for typos and misspellings.

LANGUAGE: json
CODE:
GET testindex/_search
{
  "query": {
    "match": {
      "title": {
        "query": "wnid",
        "fuzziness": "AUTO"
      }
    }
  }
}

----------------------------------------

TITLE: Match Query with Fuzziness in OpenSearch
DESCRIPTION: A Match query using fuzziness to account for typos and misspellings.

LANGUAGE: json
CODE:
GET testindex/_search
{
  "query": {
    "match": {
      "title": {
        "query": "wnid",
        "fuzziness": "AUTO"
      }
    }
  }
}

----------------------------------------

TITLE: Adding Dynamic Keys with Add Entries Processor in YAML
DESCRIPTION: This configuration shows how to use dynamic keys in the add_entries processor, where the key itself is derived from an existing field.

LANGUAGE: yaml
CODE:
processor:
  - add_entries:
      entries:
        - key: "${/param_name}"
          value_expression: "/param_value"

----------------------------------------

TITLE: Debugging Specific Search Pipeline
DESCRIPTION: Executes a search query with debugging enabled on a specific named pipeline.

LANGUAGE: json
CODE:
GET /my_index/_search?search_pipeline=my_pipeline&verbose_pipeline=true

----------------------------------------

TITLE: Indexing a Document with Scaled Float Value in OpenSearch
DESCRIPTION: This snippet demonstrates how to index a document with a scaled_float value in the previously defined 'scaled' field.

LANGUAGE: json
CODE:
PUT testindex/_doc/1 
{
  "scaled" : 2.3
}

----------------------------------------

TITLE: Markdown Documentation Layout Configuration
DESCRIPTION: Front matter configuration for the documentation page, specifying layout, title, navigation order, and redirect rules.

LANGUAGE: markdown
CODE:
---
layout: default
title: Reporting using the CLI
nav_order: 10
has_children: true
redirect_from:
  - /dashboards/reporting-cli/rep-cli-index/
---

----------------------------------------

TITLE: Listing Helm Deployments
DESCRIPTION: Command to list all Helm deployments to identify the OpenSearch deployment for deletion.

LANGUAGE: bash
CODE:
helm list

----------------------------------------

TITLE: Kubernetes Configuration for Minikube Cluster
DESCRIPTION: This YAML configuration shows the structure of a Kubernetes config file for a minikube cluster, including cluster, context, and user information.

LANGUAGE: yaml
CODE:
apiVersion: v1
clusters:
- cluster:
    certificate-authority: /Users/naarcha/.minikube/ca.crt
    extensions:
    - extension:
        last-update: Mon, 29 Aug 2022 10:11:47 CDT
        provider: minikube.sigs.k8s.io
        version: v1.26.1
      name: cluster_info
    server: https://127.0.0.1:61661
  name: minikube
contexts:
- context:
    cluster: minikube
    extensions:
    - extension:
        last-update: Mon, 29 Aug 2022 10:11:47 CDT
        provider: minikube.sigs.k8s.io
        version: v1.26.1
      name: context_info
    namespace: default
    user: minikube
  name: minikube
current-context: minikube
kind: Config
preferences: {}
users:
- name: minikube
  user:
    client-certificate: /Users/naarcha/.minikube/profiles/minikube/client.crt
    client-key: /Users/naarcha/.minikube/profiles/minikube/client.key

----------------------------------------

TITLE: Testing Data Summary Agent Configuration
DESCRIPTION: Example JSON payload for testing the data summary agent with sample log data.

LANGUAGE: json
CODE:
POST /_plugins/_ml/agents/<DATA_SUMMARY_AGENT_ID>/_execute
{
  "parameters": {
    "sample_data":"'[{\"_index\":\"90943e30-9a47-11e8-b64d-95841ca0b247\",\"_source\":{\"referer\":\"http://twitter.com/success/gemini-9a\",\"request\":\"/beats/metricbeat/metricbeat-6.3.2-amd64.deb\",\"agent\":\"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR 1.1.4322)\",\"extension\":\"deb\",\"memory\":null,\"ip\":\"239.67.210.53\",\"index\":\"opensearch_dashboards_sample_data_logs\",\"message\":\"239.67.210.53 - - [2018-08-30T15:29:01.686Z] \\\"GET /beats/metricbeat/metricbeat-6.3.2-amd64.deb HTTP/1.1\\\" 404 2633 \\\"-\\\" \\\"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR 1.1.4322)\\\"\",\"url\":\"https://artifacts.opensearch.org/downloads/beats/metricbeat/metricbeat-6.3.2-amd64.deb\",\"tags\":\"success\",\"geo\":{\"srcdest\":\"CN:PL\",\"src\":\"CN\",\"coordinates\":{\"lat\":44.91167028,\"lon\":-108.4455092},\"dest\":\"PL\"},\"utc_time\":\"2024-09-05 15:29:01.686\",\"bytes\":2633,\"machine\":{\"os\":\"win xp\",\"ram\":21474836480},\"response\":\"404\",\"clientip\":\"239.67.210.53\",\"host\":\"artifacts.opensearch.org\",\"event\":{\"dataset\":\"sample_web_logs\"},\"phpmemory\":null,\"timestamp\":\"2024-09-05 15:29:01.686\"}}]'",
    "sample_count":1,
    "total_count":383,
    "question":"Are there any errors in my logs?",
    "ppl":"source=opensearch_dashboards_sample_data_logs| where QUERY_STRING(['response'], '4* OR 5*')"}
}

----------------------------------------

TITLE: Configuring S3-Based CSV Pipeline with Auto-Detection in YAML
DESCRIPTION: Configuration example for processing CSV data from S3 with automatic header detection using SQS notifications. Includes skip line functionality and header handling.

LANGUAGE: yaml
CODE:
csv-s3-pipeline:
  source:
    s3:
      notification_type: "sqs"
      codec:
        newline:
          skip_lines: 1
          header_destination: "header"
      compression: none
      sqs:
        queue_url: "https://sqs.<region>.amazonaws.com/<account id>/<queue name>"
      aws:
        region: "<region>"
  processor:
    - csv:
        column_names_source_key: "header"
  sink:
    - stdout:

----------------------------------------

TITLE: Creating a destination in OpenSearch
DESCRIPTION: Creates a new destination for sending alert notifications. Supports different destination types like Slack, custom webhook, and email.

LANGUAGE: json
CODE:
POST _plugins/_alerting/destinations
{
  "name": "my-destination",
  "type": "slack",
  "slack": {
    "url": "http://www.example.com"
  }
}

----------------------------------------

TITLE: Register Custom Local Model
DESCRIPTION: Example request showing how to register a custom local NLP sentence transformation model with detailed configuration.

LANGUAGE: json
CODE:
POST /_plugins/_ml/models/_register
{
    "name": "all-MiniLM-L6-v2",
    "version": "1.0.0",
    "description": "test model",
    "model_format": "TORCH_SCRIPT",
    "model_group_id": "FTNlQ4gBYW0Qyy5ZoxfR",
    "model_content_hash_value": "c15f0d2e62d872be5b5bc6c84d2e0f4921541e29fefbef51d59cc10a8ae30e0f",
    "model_config": {
        "model_type": "bert",
        "embedding_dimension": 384,
        "framework_type": "sentence_transformers",
       "all_config": "{\"_name_or_path\":\"nreimers/MiniLM-L6-H384-uncased\",\"architectures\":[\"BertModel\"],\"attention_probs_dropout_prob\":0.1,\"gradient_checkpointing\":false,\"hidden_act\":\"gelu\",\"hidden_dropout_prob\":0.1,\"hidden_size\":384,\"initializer_range\":0.02,\"intermediate_size\":1536,\"layer_norm_eps\":1e-12,\"max_position_embeddings\":512,\"model_type\":\"bert\",\"num_attention_heads\":12,\"num_hidden_layers\":6,\"pad_token_id\":0,\"position_embedding_type\":\"absolute\",\"transformers_version\":\"4.8.2\",\"type_vocab_size\":2,\"use_cache\":true,\"vocab_size\":30522}"
    },
    "url": "https://artifacts.opensearch.org/models/ml-models/huggingface/sentence-transformers/all-MiniLM-L6-v2/1.0.1/torch_script/sentence-transformers_all-MiniLM-L6-v2-1.0.1-torch_script.zip"
}

----------------------------------------

TITLE: Applying Russian Analyzer to Text Field in OpenSearch
DESCRIPTION: This snippet demonstrates how to apply the built-in Russian analyzer to a text field in an OpenSearch index mapping.

LANGUAGE: json
CODE:
PUT /russian-index
{
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "russian"
      }
    }
  }
}

----------------------------------------

TITLE: Analyzing Text with Delimited Payload Filter in OpenSearch
DESCRIPTION: This JSON request demonstrates how to use the _analyze API to test the custom analyzer with the delimited_payload filter. It processes the input text 'red|1.5 fast|2.0 car|1.0' to generate tokens with payloads.

LANGUAGE: json
CODE:
POST /my_index/_analyze
{
  "analyzer": "my_analyzer",
  "text": "red|1.5 fast|2.0 car|1.0"
}

----------------------------------------

TITLE: Complete S3 Pipeline Configuration with OpenSearch Sink
DESCRIPTION: Complete YAML configuration including source, processor, and sink configurations for S3 log processing pipeline.

LANGUAGE: yaml
CODE:
s3-log-pipeline:
   source:
     s3:
       notification_type: sqs
       compression: gzip
       codec:
         newline:
       sqs:
         queue_url: "arn:aws:sqs:<YOUR-REGION>:<123456789012>:<YOUR-SQS-QUEUE>"
         visibility_timeout: "2m"
       aws:
         region: "<YOUR-REGION>"
         sts_role_arn: "arn:aws:iam::<123456789012>:role/<DATA-PREPPER-ROLE>"
   processor:
   sink:
     - opensearch:
         hosts: [ "https://localhost:9200" ]
         username: "admin"
         password: "admin"
         index: s3_logs

----------------------------------------

TITLE: Multiple Indices Information Request
DESCRIPTION: Example request for retrieving information about multiple comma-separated indices

LANGUAGE: json
CODE:
GET _list/indices/index1,index2,index3?v&next_token=token

----------------------------------------

TITLE: Equivalent Search API Query
DESCRIPTION: Alternative approach using the search API to get document counts with size set to 0 and track_total_hits enabled.

LANGUAGE: json
CODE:
GET opensearch_dashboards_sample_data_logs/_search\n{\n  "query": {\n    "term": {\n      "response": "200"\n    }\n  },\n  "size": 0,\n  "track_total_hits": true\n}

----------------------------------------

TITLE: Running Basic RAG Search with Claude v2
DESCRIPTION: Executes a basic RAG search using the configured pipeline for Claude v2 without storing conversation history.

LANGUAGE: JSON
CODE:
GET /qa_demo/_search?search_pipeline=my-conversation-search-pipeline-claude2
{
  "query": {
    "match": {
      "text": "What's the population increase of New York City from 2021 to 2023?"
    }
  },
  "size": 1,
  "_source": [
    "text"
  ],
  "ext": {
    "generative_qa_parameters": {
      "llm_model": "bedrock/claude",
      "llm_question": "What's the population increase of New York City from 2021 to 2023?",
      "context_size": 5,
      "timeout": 15
    }
  }
}

----------------------------------------

TITLE: Creating Custom Bulgarian Analyzer in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a fully customized Bulgarian analyzer with specific token filters and tokenizer in OpenSearch.

LANGUAGE: json
CODE:
PUT /bulgarian-index
{
  "settings": {
    "analysis": {
      "filter": {
        "bulgarian_stop": {
          "type": "stop",
          "stopwords": "_bulgarian_"
        },
        "bulgarian_stemmer": {
          "type": "stemmer",
          "language": "bulgarian"
        },
        "bulgarian_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] 
        }
      },
      "analyzer": {
        "bulgarian_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "bulgarian_stop",
            "bulgarian_keywords",
            "bulgarian_stemmer"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "bulgarian_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Index Action in OpenSearch Bulk API
DESCRIPTION: Demonstrates the format for an index action in the bulk API. This action creates a document if it doesn't exist or replaces it if it does.

LANGUAGE: json
CODE:
{ "index": { "_index": "movies", "_id": "tt1979320" } }
{ "title": "Rush", "year": 2013}

----------------------------------------

TITLE: Creating Geopoint Field Mapping in OpenSearch
DESCRIPTION: Demonstrates how to create an index mapping with a geopoint field type.

LANGUAGE: json
CODE:
PUT testindex1
{
  "mappings": {
    "properties": {
      "point": {
        "type": "geo_point"
      }
    }
  }
}

----------------------------------------

TITLE: Creating a Mapping with Scaled Float Field in OpenSearch
DESCRIPTION: This example illustrates the creation of a mapping where 'scaled' is defined as a scaled_float field type with a scaling factor of 10.

LANGUAGE: json
CODE:
PUT testindex 
{
  "mappings" : {
    "properties" :  {
      "scaled" : {
        "type" : "scaled_float",
        "scaling_factor" : 10
      }
    }
  }
}

----------------------------------------

TITLE: Creating an Index with Reverse Token Filter in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a new index named 'my-reverse-index' with a custom analyzer that includes a reverse filter. The analyzer also applies lowercase transformation before reversing the tokens.

LANGUAGE: json
CODE:
PUT /my-reverse-index
{
  "settings": {
    "analysis": {
      "filter": {
        "reverse_filter": {
          "type": "reverse"
        }
      },
      "analyzer": {
        "my_reverse_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "reverse_filter"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Example Path Parameters Integration
DESCRIPTION: Example of how to insert path parameters documentation using the spec-insert plugin for the indices.create API.

LANGUAGE: markdown
CODE:
<!-- spec_insert_start
api: indices.create
component: path_parameters
-->
<!-- spec_insert_end -->

----------------------------------------

TITLE: Creating Amazon Bedrock Connector for Cohere Embeddings
DESCRIPTION: Creates a connector to Amazon Bedrock for accessing the Cohere Embed model with int8 quantized embeddings support.

LANGUAGE: json
CODE:
POST _plugins/_ml/connectors/_create
{
  "name": "Amazon Bedrock Connector: Cohere embed-multilingual-v3",
  "description": "Test connector for Amazon Bedrock Cohere embed-multilingual-v3",
  "version": 1,
  "protocol": "aws_sigv4",
  "credential": {
    "access_key": "your_aws_access_key",
    "secret_key": "your_aws_secret_key",
    "session_token": "your_aws_session_token"
  },
  "parameters": {
    "region": "your_aws_region",
    "service_name": "bedrock",
    "truncate": "END",
    "input_type": "search_document",
    "model": "cohere.embed-multilingual-v3",
    "embedding_types": ["int8"]
  },
  "actions": [
    {
      "action_type": "predict",
      "method": "POST",
      "headers": {
        "x-amz-content-sha256": "required",
        "content-type": "application/json"
      },
      "url": "https://bedrock-runtime.${parameters.region}.amazonaws.com/model/${parameters.model}/invoke",
      "request_body": "{ \"texts\": ${parameters.texts}, \"truncate\": \"${parameters.truncate}\", \"input_type\": \"${parameters.input_type}\", \"embedding_types\":  ${parameters.embedding_types} }"
    }
  ]
}

----------------------------------------

TITLE: Creating Model with TTL - OpenSearch ML Model Registration
DESCRIPTION: Request for registering a new model with TTL settings for automatic undeployment after specified duration of inactivity.

LANGUAGE: json
CODE:
POST /_plugins/_ml/models/_register
 {
   "name": "Sample Model Name",
   "function_name": "remote",
   "description": "test model",
   "connector_id": "-g1nOo8BOaAC5MIJ3_4R",
   "deploy_setting": {"model_ttl_minutes": 100}
 }

----------------------------------------

TITLE: Searching for Null Values in OpenSearch
DESCRIPTION: Demonstrates how to search for documents with null values that have been replaced by a specified 'null_value' in OpenSearch. This query searches for documents where the 'emergency_phone' field is set to 'NONE'.

LANGUAGE: json
CODE:
GET testindex/_search
{
  "query": {
    "term": {
      "emergency_phone": "NONE"
    }
  }
}

----------------------------------------

TITLE: Alternative Geo-bounding Box Query Syntax in OpenSearch
DESCRIPTION: Demonstrates an alternative way to specify the bounding box using 'top', 'left', 'bottom', and 'right' coordinates.

LANGUAGE: json
CODE:
GET testindex1/_search
{
  "query": {
    "bool": {
      "must": {
        "match_all": {}
      },
      "filter": {
        "geo_bounding_box": {
          "point": {
            "top": 75,
            "left": 28,
            "bottom": 73,
            "right": 41            
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Basic OpenSearch Connection Configuration
DESCRIPTION: Examples of creating OpenSearch client connections with different configurations including single node and connection pools.

LANGUAGE: csharp
CODE:
var client  = new OpenSearchLowLevelClient();

var nodeAddress = new Uri("http://myserver:9200");
var config = new ConnectionConfiguration(nodeAddress);
var client = new OpenSearchLowLevelClient(config);

var uri = new Uri("http://localhost:9200");
var connectionPool = new SingleNodeConnectionPool(uri);
var settings = new ConnectionConfiguration(connectionPool).PrettyJson();
var client = new OpenSearchLowLevelClient(settings);

----------------------------------------

TITLE: Registering Cohere Rerank Model in OpenSearch
DESCRIPTION: Registers the Cohere Rerank model using the previously created connector ID and deploys it.

LANGUAGE: json
CODE:
POST /_plugins/_ml/models/_register?deploy=true
{
    "name": "cohere rerank model",
    "function_name": "remote",
    "description": "test rerank model",
    "connector_id": "your_connector_id"
}

----------------------------------------

TITLE: Registering Cohere Rerank Connector in OpenSearch
DESCRIPTION: Creates a connector for the Cohere Rerank model, specifying the API key, model parameters, and request details.

LANGUAGE: json
CODE:
POST /_plugins/_ml/connectors/_create
{
    "name": "cohere-rerank",
    "description": "The connector to Cohere reanker model",
    "version": "1",
    "protocol": "http",
    "credential": {
        "cohere_key": "your_cohere_api_key"
    },
    "parameters": {
        "model": "rerank-english-v2.0"
    },
    "actions": [
        {
            "action_type": "predict",
            "method": "POST",
            "url": "https://api.cohere.ai/v1/rerank",
            "headers": {
                "Authorization": "Bearer ${credential.cohere_key}"
            },
            "request_body": "{ \"documents\": ${parameters.documents}, \"query\": \"${parameters.query}\", \"model\": \"${parameters.model}\", \"top_n\": ${parameters.top_n} }",
            "pre_process_function": "connector.pre_process.cohere.rerank",
            "post_process_function": "connector.post_process.cohere.rerank"
        }
    ]
}

----------------------------------------

TITLE: Enabling Text to Visualization in OpenSearch Dashboards Config
DESCRIPTION: YAML configuration setting to enable the text-to-visualization feature in OpenSearch Dashboards.

LANGUAGE: yaml
CODE:
assistant.text2viz.enabled: true

----------------------------------------

TITLE: Configuring Advanced Regexp Query Parameters in OpenSearch
DESCRIPTION: This example shows how to use advanced parameters in a regexp query. It includes options like 'value' for the regex pattern, 'boost' for relevance scoring, 'case_insensitive' for case sensitivity, 'flags' for Lucene regex options, 'max_determinized_states' for complexity control, and 'rewrite' for query rewriting method.

LANGUAGE: json
CODE:
GET _search
{
  "query": {
    "regexp": {
      "<field>": {
        "value": "[Ss]ample",
        ...
      }
    }
  }
}

----------------------------------------

TITLE: Querying Node Usage Endpoints in OpenSearch
DESCRIPTION: Example of the available REST endpoints for retrieving node usage information. Shows different variations for filtering by nodeId and metric.

LANGUAGE: json
CODE:
GET _nodes/usage
GET _nodes/<nodeId>/usage
GET _nodes/usage/<metric>
GET _nodes/<nodeId>/usage/<metric>

----------------------------------------

TITLE: Starting OpenSearch with Feature Flags
DESCRIPTION: Start OpenSearch with experimental features enabled using environment variables and command line options.

LANGUAGE: bash
CODE:
OPENSEARCH_JAVA_OPTS="-Dopensearch.experimental.feature.<feature_name>.enabled=true" ./opensearch-{{site.opensearch_version}}/bin/opensearch

LANGUAGE: bash
CODE:
export OPENSEARCH_JAVA_OPTS="-Dopensearch.experimental.feature.<feature_name>.enabled=true"

LANGUAGE: bash
CODE:
./bin/opensearch

----------------------------------------

TITLE: Retrieving Available Headers - OpenSearch List API
DESCRIPTION: Shows how to query all available headers for the List API operations using the help parameter.

LANGUAGE: json
CODE:
GET _list/<operation_name>?help

----------------------------------------

TITLE: Filtered Metrics Stats Query
DESCRIPTION: Retrieves specific metrics (refresh and flush) for an index

LANGUAGE: json
CODE:
GET /testindex/_stats/refresh,flush

----------------------------------------

TITLE: Starting Elasticsearch Service on Linux
DESCRIPTION: This bash command starts the Elasticsearch service on Linux distributions using systemd.

LANGUAGE: bash
CODE:
sudo systemctl start elasticsearch.service

----------------------------------------

TITLE: Multi-Index Reindex Operation
DESCRIPTION: Combines documents from multiple source indexes into a single destination index.

LANGUAGE: json
CODE:
POST _reindex
{
   "source":{
      "index":[
         "source_1",
         "source_2"
      ]
   },
   "dest":{
      "index":"destination"
   }
}

----------------------------------------

TITLE: Deleting Asynchronous Search in OpenSearch
DESCRIPTION: Illustrates the process of deleting an asynchronous search or its results using the search ID.

LANGUAGE: json
CODE:
DELETE _plugins/_asynchronous_search/<ID>?pretty

----------------------------------------

TITLE: Flushing OpenSearch Cluster
DESCRIPTION: Performs a flush operation to commit transaction log entries to the Lucene index.

LANGUAGE: json
CODE:
POST "/_flush?pretty"

----------------------------------------

TITLE: Geo-bounding Box Query for Entire Geohash Area in OpenSearch
DESCRIPTION: Demonstrates how to specify a bounding box that covers the entire area of a geohash by using the same geohash for both top_left and bottom_right parameters.

LANGUAGE: json
CODE:
GET testindex1/_search
{
  "query": {
    "bool": {
      "must": {
        "match_all": {}
      },
      "filter": {
        "geo_bounding_box": {
          "point": {
            "top_left": "ut",
            "bottom_right": "ut"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Basic CAT Count Query
DESCRIPTION: Basic request to get document count for all indices with verbose output enabled.

LANGUAGE: json
CODE:
GET _cat/count?v

----------------------------------------

TITLE: Creating an Index with Stored Payloads in OpenSearch
DESCRIPTION: This JSON request creates an index named 'visible_payloads' that stores term vectors with payloads. It configures a custom analyzer with a delimited_payload filter and sets the term_vector property to 'with_positions_payloads' for the text field.

LANGUAGE: json
CODE:
PUT /visible_payloads
{
  "mappings": {
    "properties": {
      "text": {
        "type": "text",
        "term_vector": "with_positions_payloads",
        "analyzer": "custom_analyzer"
      }
    }
  },
  "settings": {
    "analysis": {
      "filter": {
        "my_payload_filter": {
          "type": "delimited_payload",
          "delimiter": "|",
          "encoding": "float"
        }
      },
      "analyzer": {
        "custom_analyzer": {
          "tokenizer": "whitespace",
          "filter": [ "my_payload_filter" ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Running Lambda Integration Tests with Gradle
DESCRIPTION: Gradle command for executing integration tests for the AWS Lambda processor plugin, demonstrating how to specify required parameters like region, function name, and role ARN.

LANGUAGE: bash
CODE:
./gradlew :data-prepper-plugins:aws-lambda:integrationTest -Dtests.processor.lambda.region="us-east-1" -Dtests.processor.lambda.functionName="lambda_test_function"  -Dtests.processor.lambda.sts_role_arn="arn:aws:iam::123456789012:role/dataprepper-role

----------------------------------------

TITLE: External Model Pipeline Configuration
DESCRIPTION: Example configuration for using an externally hosted text embedding model in a search pipeline.

LANGUAGE: json
CODE:
PUT /_search/pipeline/ml_inference_pipeline
{
  "description": "Generate passage_embedding when search documents",
  "processors": [
    {
      "ml_inference": {
        "model_id": "<your model id>",
        "input_map": [
          {
            "input": "passage_text"
          }
        ],
        "output_map": [
          {
            "passage_embedding": "data"
          }
        ]
      }
    }
  ]
}

----------------------------------------

TITLE: Executing SQL Query in OpenSearch CLI
DESCRIPTION: Example of running a SQL query to select all records from the 'accounts' table using the OpenSearch SQL CLI.

LANGUAGE: sql
CODE:
SELECT * FROM accounts;

----------------------------------------

TITLE: Markdown Layout Configuration
DESCRIPTION: YAML frontmatter configuration for the documentation page, specifying layout, title, navigation order and redirect paths.

LANGUAGE: yaml
CODE:
---
layout: default
title: Operational panels
nav_order: 60
redirect_from:
  - /observing-your-data/operational-panels/
  - /observability-plugin/operational-panels/
---

----------------------------------------

TITLE: Handling Null Values in OpenSearch Mappings
DESCRIPTION: Demonstrates how to handle null values in OpenSearch by specifying a 'null_value' in the mapping. This example replaces null values in the 'emergency_phone' field with the string 'NONE'.

LANGUAGE: json
CODE:
PUT testindex
{
  "mappings": {
    "properties": {
      "name": {
        "type": "keyword"
      },
      "emergency_phone": {
        "type": "keyword",
        "null_value": "NONE" 
      }
    }
  }
}

----------------------------------------

TITLE: Example Response for Terms Aggregation on Response Codes
DESCRIPTION: This snippet shows the response structure for a terms aggregation, including buckets with keys and document counts, as well as error bounds and other document counts.

LANGUAGE: json
CODE:
{
  "aggregations": {
    "response_codes": {
      "doc_count_error_upper_bound": 0,
      "sum_other_doc_count": 0,
      "buckets": [
        {
          "key": "200",
          "doc_count": 12832
        },
        {
          "key": "404",
          "doc_count": 801
        },
        {
          "key": "503",
          "doc_count": 441
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Displaying OpenSearch Benchmark Help Information
DESCRIPTION: Shows the help information for OpenSearch Benchmark after installation is complete.

LANGUAGE: bash
CODE:
opensearch-benchmark -h

----------------------------------------

TITLE: Enabling Encryption at Rest in Linux
DESCRIPTION: Shows the command to enable encryption at rest using cryptsetup in most Linux distributions.

LANGUAGE: bash
CODE:
cryptsetup luksFormat --key-file <key> <partition>

----------------------------------------

TITLE: Setting up port forwarding for OpenSearch Dashboards
DESCRIPTION: This command sets up port forwarding to access OpenSearch Dashboards locally on port 5601.

LANGUAGE: bash
CODE:
$ kubectl port-forward deployment/opensearch-dashboards-1-1629223356 5601

----------------------------------------

TITLE: Analyzing Text with Custom Simple Analyzer in OpenSearch
DESCRIPTION: This snippet demonstrates how to use the _analyze API to examine tokens generated by the custom simple analyzer. It sends a POST request to analyze HTML text, showcasing how the analyzer handles HTML tags, special characters, and text content.

LANGUAGE: json
CODE:
POST /my_custom_simple_index/_analyze
{
  "analyzer": "my_custom_simple_analyzer",
  "text": "<p>The slow turtle swims over to dogs &copy; 2024!</p>"
}

----------------------------------------

TITLE: Field Value Substring Check in OpenSearch Pipeline
DESCRIPTION: Demonstrates using contains() function to check if a field named 'message' contains the substring 'abcd'. Returns true if the substring is found, false otherwise.

LANGUAGE: opensearch
CODE:
contains('/message', 'abcd')

----------------------------------------

TITLE: Enabling Tracer with Dynamic Setting
DESCRIPTION: Use this dynamic setting to enable the tracer in a running cluster.

LANGUAGE: yaml
CODE:
telemetry.tracer.enabled=true

----------------------------------------

TITLE: YAML Front Matter Configuration
DESCRIPTION: Page metadata configuration defining the layout, title, parent category and navigation order.

LANGUAGE: yaml
CODE:
---
layout: default
title: Alerting dashboards and visualizations 
parent: Alerting
nav_order: 50
---

----------------------------------------

TITLE: Testing Hungarian Analyzer Token Generation
DESCRIPTION: Shows how to analyze text using the Hungarian analyzer and view the generated tokens. Includes both the analysis request and example response.

LANGUAGE: json
CODE:
POST /hungarian-index/_analyze
{
  "field": "content",
  "text": "A dikok a magyar egyetemeken tanulnak. A szmaik 123456."
}

----------------------------------------

TITLE: Registering Flow Agent for SearchAnomalyDetectorsTool in OpenSearch
DESCRIPTION: This JSON snippet demonstrates how to register a flow agent that will run the SearchAnomalyDetectorsTool. It includes the agent configuration with name, type, description, memory settings, and tool parameters.

LANGUAGE: json
CODE:
POST /_plugins/_ml/agents/_register
{
  "name": "Test_Agent_For_Search_Anomaly_Detectors_Tool",
  "type": "flow",
  "description": "this is a test agent for the SearchAnomalyDetectorsTool",
  "memory": {
    "type": "demo"
  },
  "tools": [
      {
      "type": "SearchAnomalyDetectorsTool",
      "name": "DemoSearchAnomalyDetectorsTool",
      "parameters": {}
    }
  ]
}

----------------------------------------

TITLE: Registering Flow Agent for ConnectorTool
DESCRIPTION: JSON request for registering a flow agent that uses the ConnectorTool. Includes configuration for connector ID and response filter.

LANGUAGE: json
CODE:
POST /_plugins/_ml/agents/_register
{
  "name": "Demo agent of Lambda connector",
  "type": "flow",
  "description": "This is a demo agent",
  "app_type": "demo",
  "tools": [
    {
      "type": "ConnectorTool",
      "name": "lambda_function",
      "parameters": {
        "connector_id": "YOUR CONNECTOR ID",
        "response_filter": "$.result"
      }
    }
  ]
}

----------------------------------------

TITLE: Indexing Parent Document with Join Field
DESCRIPTION: Shows two methods of indexing a parent document using join field type - one with full object notation and another using shortcut notation.

LANGUAGE: json
CODE:
PUT testindex1/_doc/1
{
  "name": "Brand 1",
  "product_to_brand": {
    "name": "brand" 
  }
}

LANGUAGE: json
CODE:
PUT testindex1/_doc/1
{
  "name": "Brand 1",
  "product_to_brand" : "brand" 
}

----------------------------------------

TITLE: Querying Index Existence in OpenSearch
DESCRIPTION: This snippet demonstrates the endpoint for checking if an index exists in OpenSearch. It uses the HEAD HTTP method with the index name as the path.

LANGUAGE: json
CODE:
HEAD /<index-name>

----------------------------------------

TITLE: Health by Specific Awareness Attribute
DESCRIPTION: Request to get cluster health information for a specific awareness attribute (zone).

LANGUAGE: json
CODE:
GET _cluster/health?level=awareness_attributes&awareness_attribute=zone

----------------------------------------

TITLE: Downloading and Compressing Hugging Face Model for OpenSearch
DESCRIPTION: Commands for downloading the 'intfloat/multilingual-e5-small' model and compressing it for use in OpenSearch.

LANGUAGE: bash
CODE:
git lfs install
git clone https://huggingface.co/intfloat/multilingual-e5-small
zip -r intfloat-multilingual-e5-small-onnx.zip model.onnx tokenizer.json sentencepiece.bpe.model
shasum -a 256 intfloat-multilingual-e5-small-onnx.zip
python3 -m http.server 8080 --bind 0.0.0.0

----------------------------------------

TITLE: Verifying OpenSearch Operator Helm Repository
DESCRIPTION: This command checks if the OpenSearch Operator repository is listed in your Kubernetes cluster's Helm repositories.

LANGUAGE: bash
CODE:
helm repo list | grep opensearch

----------------------------------------

TITLE: GET Workflow Status Endpoint
DESCRIPTION: Base endpoint for retrieving workflow status information.

LANGUAGE: json
CODE:
GET /_plugins/_flow_framework/workflow/<workflow_id>/_status

----------------------------------------

TITLE: Basic Sampler Aggregation Syntax in OpenSearch
DESCRIPTION: Demonstrates the basic structure of a sampler aggregation in OpenSearch. The shard_size parameter specifies the maximum number of documents to collect from each shard.

LANGUAGE: json
CODE:
"aggs": {
  "SAMPLE": {
    "sampler": {
      "shard_size": 100
    },
    "aggs": {...}
  }
}

----------------------------------------

TITLE: Vector Search with Inner Hits on Nested Fields in OpenSearch
DESCRIPTION: This snippet shows how to perform a vector search on nested fields with inner hits in OpenSearch, returning specific fields of matching nested documents.

LANGUAGE: json
CODE:
GET my-knn-index-1/_search
{
  "_source": false,
  "query": {
    "nested": {
      "path": "nested_field",
      "query": {
        "knn": {
          "nested_field.my_vector": {
            "vector": [1,1,1],
            "k": 2
          }
        }
      },
      "inner_hits": {
        "_source": false,
        "fields":["nested_field.color"]
      }
    }
  }
}

----------------------------------------

TITLE: Unique Document Reindex Operation
DESCRIPTION: Reindexes only documents that don't exist in the destination index using op_type create.

LANGUAGE: json
CODE:
POST _reindex
{
   "conflicts":"proceed",
   "source":{
      "index":"source"
   },
   "dest":{
      "index":"destination",
      "op_type":"create"
   }
}

----------------------------------------

TITLE: Updating ISM Policy - JSON
DESCRIPTION: Updates an existing policy using sequence number and primary term for optimistic concurrency control.

LANGUAGE: json
CODE:
PUT _plugins/_ism/policies/policy_1?if_seq_no=7&if_primary_term=1
{
  "policy": {
    "description": "ingesting logs",
    "default_state": "ingest",
    "states": [...]
  }
}

----------------------------------------

TITLE: Whitespace Tokenizer Response Example
DESCRIPTION: Example response showing the tokens generated by the whitespace analyzer, including token positions and offsets.

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "OpenSearch",
      "start_offset": 0,
      "end_offset": 10,
      "type": "word",
      "position": 0
    },
    {
      "token": "is",
      "start_offset": 11,
      "end_offset": 13,
      "type": "word",
      "position": 1
    },
    {
      "token": "fast!",
      "start_offset": 14,
      "end_offset": 19,
      "type": "word",
      "position": 2
    },
    {
      "token": "Really",
      "start_offset": 20,
      "end_offset": 26,
      "type": "word",
      "position": 3
    },
    {
      "token": "fast.",
      "start_offset": 27,
      "end_offset": 32,
      "type": "word",
      "position": 4
    }
  ]
}

----------------------------------------

TITLE: Ingesting documents into OpenSearch index using bulk API
DESCRIPTION: This snippet shows how to ingest multiple documents into the previously created OpenSearch index using the bulk API. It includes sample data for four books with their titles, authors, genres, reviews, and descriptions.

LANGUAGE: json
CODE:
POST /_bulk
{ "index": { "_index": "book-index", "_id": "1" } }
{ "title": "The Lost City", "author": "Jane Doe", "genre": "Adventure Fiction", "reviews": { "stars": 4.2 }, "description": "An exhilarating journey through a hidden civilization in the Amazon rainforest." }
{ "index": { "_index": "book-index", "_id": "2" } }
{ "title": "Whispers of the Past", "author": "John Smith", "genre": "Historical Mystery", "reviews": { "stars": 4.7 }, "description": "A gripping tale set in Victorian England, unraveling a century-old mystery." }
{ "index": { "_index": "book-index", "_id": "3" } }
{ "title": "Starlit Dreams", "author": "Emily Clark", "genre": "Science Fiction", "reviews": { "stars": 4.5 }, "description": "In a future where dreams can be shared, one girl discovers her imaginations power." }
{ "index": { "_index": "book-index", "_id": "4" } }
{ "title": "The Enchanted Garden", "author": "Alice Green", "genre": "Fantasy", "reviews": { "stars": 4.8 }, "description": "A magical garden holds the key to a young girls destiny and friendship." }


----------------------------------------

TITLE: OpenSearch Minimum Aggregation Response
DESCRIPTION: This is an example response to the minimum aggregation query. It includes metadata about the query execution and the result of the aggregation, which is the minimum value of the 'taxful_total_price' field.

LANGUAGE: json
CODE:
{
  "took": 13,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 4675,
      "relation": "eq"
    },
    "max_score": null,
    "hits": []
  },
  "aggregations": {
    "min_taxful_total_price": {
      "value": 6.98828125
    }
  }
}

----------------------------------------

TITLE: Creating Index with Keyword Mapping in OpenSearch
DESCRIPTION: Shows how to create an index named 'students' with a 'student_id' field mapped as a keyword.

LANGUAGE: json
CODE:
PUT students
{
  "mappings": {
    "properties": {
      "student_id": { "type": "keyword" }
    }
  }
}

----------------------------------------

TITLE: Indexing xy point as WKT in OpenSearch
DESCRIPTION: This snippet demonstrates indexing an xy point as a well-known text (WKT) POINT in the 'POINT(x y)' format in OpenSearch.

LANGUAGE: json
CODE:
PUT testindex1/_doc/4
{
  "point": "POINT (0.5 4.5)"
}

----------------------------------------

TITLE: Ingesting a document with URL decode pipeline in OpenSearch
DESCRIPTION: Shows how to ingest a document into 'testindex1' using the url_decode_pipeline to process the encoded_url field.

LANGUAGE: json
CODE:
PUT testindex1/_doc/1?pipeline=url_decode_pipeline
{
  "encoded_url": "https://example.com/search?q=url%20decode%20test"
}

----------------------------------------

TITLE: Defining Student Class Model for OpenSearch Documents
DESCRIPTION: C# class definition representing a student document structure for OpenSearch indexing.

LANGUAGE: csharp
CODE:
public class Student
{
    public int Id { get; init; }
    public string FirstName { get; init; }
    public string LastName { get; init; }
    public int GradYear { get; init; }
    public double Gpa { get; init; }
}

----------------------------------------

TITLE: Global Aggregation Response Example
DESCRIPTION: Shows the response format for a global aggregation query, including the total document count and calculated average price across all documents in the index.

LANGUAGE: json
CODE:
{
  "aggregations": {
    "total_avg_amount": {
      "doc_count": 4675,
      "avg_price": {
        "value": 75.05542864304813
      }
    }
  }
}

----------------------------------------

TITLE: Running Workload in Test Mode
DESCRIPTION: Command to run a workload in test mode, which ingests only the first 1000 documents and runs query operations against them.

LANGUAGE: bash
CODE:
opensearch-benchmark execute-test \
--pipeline="benchmark-only"  \
--workload-path="<PATH OUTPUTTED IN THE OUTPUT OF THE CREATE-WORKLOAD COMMAND>" \
--target-host="<CLUSTER ENDPOINT>" \
--client-options"basic_auth_user:'<USERNAME>',basic_auth_password:'<PASSWORD>'" \
--test-mode

----------------------------------------

TITLE: Creating Mapping for Nested Field Type in OpenSearch
DESCRIPTION: This snippet shows how to create a mapping that defines a field as a nested type, preserving the structure of nested objects.

LANGUAGE: json
CODE:
PUT testindex1
{
  "mappings" : {
    "properties": {
      "patients": { 
        "type" : "nested"
      }
    }
  }
}

----------------------------------------

TITLE: Creating Index with Metrics Context in OpenSearch
DESCRIPTION: Example of creating an index with metrics context using the Index API. This applies predefined settings optimized for metric data storage.

LANGUAGE: json
CODE:
PUT /my-metrics-index
{
  "context": {
    "name": "metrics"
  }
}

----------------------------------------

TITLE: Basic Binary Quantization Index Configuration
DESCRIPTION: Creates an index with basic binary quantization settings using 1-bit compression and default ef_search and ef_construction values of 100.

LANGUAGE: json
CODE:
PUT my-vector-index
{
  "settings" : {
    "index": {
      "knn": true
    }
  },
  "mappings": {
    "properties": {
      "my_vector_field": {
        "type": "knn_vector",
        "dimension": 8,
        "space_type": "l2",
        "data_type": "float",
        "mode": "on_disk"
      }
    }
  }
}

----------------------------------------

TITLE: SVMRank Format for Training Set in Markdown
DESCRIPTION: Example of the SVMRank file format for a training set, showing how features are labeled with ordinals and queries are given IDs.

LANGUAGE: markdown
CODE:
```
4   qid:1   1:0.0   2:21.5  3:100,...
4   qid:1   1:42.5  2:21.5  3:95,...
3   qid:1   1:53.1  2:40.1  3:50,...
...
```

----------------------------------------

TITLE: Setting NODE_HOME for NVM Installation
DESCRIPTION: Commands to set NODE_HOME or NODE_OSD_HOME environment variables when Node.js is installed using NVM

LANGUAGE: bash
CODE:
export NODE_HOME=/Users/user/.nvm/versions/node/v18.19.0
# or, if NODE_HOME is used for something else:
export NODE_OSD_HOME=/Users/user/.nvm/versions/node/v18.19.0

----------------------------------------

TITLE: Decay Function Query for Geopoint Fields
DESCRIPTION: Uses an exponential decay function to score hotels based on their distance from a specified location.

LANGUAGE: json
CODE:
GET hotels/_search
{
  "query": {
    "function_score": {
      "functions": [
        {
          "exp": {
            "location": { 
              "origin": "40.71,74.00",
              "offset": "200ft",
              "scale":  "300ft",
              "decay": 0.25
            }
          }
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Retrieving Node Statistics in OpenSearch
DESCRIPTION: This HTTP GET request retrieves statistics for all nodes in the OpenSearch cluster.

LANGUAGE: http
CODE:
GET _nodes/stats

----------------------------------------

TITLE: Input JSON Example for Basic Truncation
DESCRIPTION: Sample JSON input showing the structure of data before truncation is applied.

LANGUAGE: json
CODE:
{"message1": "hello,world", "message2": "test message", "info", "new information", "log": "test log message"}

----------------------------------------

TITLE: Defining Judgment List for 'Rambo' Search in Markdown
DESCRIPTION: Example of a judgment list for the 'Rambo' search query, showing movie titles with relevance grades to establish an ideal ordering of search results.

LANGUAGE: markdown
CODE:
```
grade,keywords,movie
4,Rambo,First Blood     # Exactly Relevant
4,Rambo,Rambo
3,Rambo,Rambo III       # Fairly Relevant
3,Rambo,Rambo First Blood Part II
2,Rambo,Rocky           # Tangentially Relevant
2,Rambo,Cobra
0,Rambo,Bambi           # Not even close...
0,Rambo,First Daughter
```

----------------------------------------

TITLE: Cross Join SQL Query Example
DESCRIPTION: Shows a cross join that creates a cartesian product between accounts and employees_nested tables

LANGUAGE: sql
CODE:
SELECT
  a.account_number, a.firstname, a.lastname,
  e.id, e.name
FROM accounts a
JOIN employees_nested e

----------------------------------------

TITLE: Creating User Agent Pipeline in OpenSearch
DESCRIPTION: PUT request to create a pipeline named 'user_agent_pipeline' that uses the user_agent processor to extract information from the 'user_agent' field and store it in 'user_agent_info'.

LANGUAGE: json
CODE:
PUT _ingest/pipeline/user_agent_pipeline
{
  "description": "User agent pipeline",
  "processors": [
    {
      "user_agent": {
        "field": "user_agent",
        "target_field": "user_agent_info"
      }
    }
  ]
}

----------------------------------------

TITLE: Running First Benchmark with Percolator Workload
DESCRIPTION: Command to execute a test benchmark using the percolator workload against a local OpenSearch cluster with security enabled.

LANGUAGE: bash
CODE:
opensearch-benchmark execute-test --pipeline=benchmark-only --workload=percolator --target-host=https://localhost:9200 --client-options=basic_auth_user:admin,basic_auth_password:admin,verify_certs:false --test-mode

----------------------------------------

TITLE: Sample Flattened JSON Output with Removed List Indexes
DESCRIPTION: This JSON snippet shows the output of the flatten processor when configured to remove list indexes, converting nested objects into a flattened structure.

LANGUAGE: json
CODE:
{
  "key1": "val1",
  "key2.key3.key4": "val2",
  "list1[].list2[].name": ["name1","name2"],
  "list1[].list2[].value": ["value1","value2"]
}

----------------------------------------

TITLE: Running OpenSearch Installation Script on Windows
DESCRIPTION: This command runs the OpenSearch installation batch script on Windows to apply a generic configuration and start the service.

LANGUAGE: batch
CODE:
.\opensearch-windows-install.bat

----------------------------------------

TITLE: Testing OpenSearch Pipeline with Date Processor
DESCRIPTION: Example of testing the 'date-output-format' pipeline using the _simulate API to ensure it correctly processes date formats.

LANGUAGE: json
CODE:
POST _ingest/pipeline/date-output-format/_simulate
{
  "docs": [
    {
      "_index": "testindex1",
      "_id": "1",
      "_source": {
        "date_us": "06/30/2023",
        "date_european": "30/06/2023"
      }
    }
  ]
}

----------------------------------------

TITLE: Indexing Geoshape Documents in OpenSearch
DESCRIPTION: These snippets demonstrate how to index documents with geoshape data into the 'national_parks' index in OpenSearch. Each document represents a national park with its location as a geoshape.

LANGUAGE: json
CODE:
PUT national_parks/_doc/1
{
  "name": "Yellowstone National Park",
  "location":
  {"type": "envelope","coordinates": [ [-111.15, 45.12], [-109.83, 44.12] ]}
}

LANGUAGE: json
CODE:
PUT national_parks/_doc/2
{
  "name": "Yosemite National Park",
  "location": 
  {"type": "envelope","coordinates": [ [-120.23, 38.16], [-119.05, 37.45] ]}
}

LANGUAGE: json
CODE:
PUT national_parks/_doc/3
{
  "name": "Death Valley National Park",
  "location": 
  {"type": "envelope","coordinates": [ [-117.34, 37.01], [-116.38, 36.25] ]}
}

----------------------------------------

TITLE: LDAP Authorization Configuration
DESCRIPTION: YAML configuration for enabling LDAP authorization in OpenSearch

LANGUAGE: yaml
CODE:
authz:
  ldap:
    http_enabled: true
    transport_enabled: true
    authorization_backend:
      type: ldap
      config:
      ...

----------------------------------------

TITLE: Retrieving Agent Information with GET Request in OpenSearch
DESCRIPTION: This snippet demonstrates the endpoint for retrieving agent information using the agent_id. It uses a GET request to the /_plugins/_ml/agents/<agent_id> endpoint.

LANGUAGE: json
CODE:
GET /_plugins/_ml/agents/<agent_id>

----------------------------------------

TITLE: Reading Logs in OpenSearch Migration Console
DESCRIPTION: This command reads logs from Traffic Replayer, using jq to pretty-print each line of the tuple output before writing it to a file.

LANGUAGE: sh
CODE:
console tuples show --in /shared-logs-output/traffic-replayer-default/[NODE_ID]/tuples/console.log | jq > readable_tuples.json

----------------------------------------

TITLE: Registering and Deploying ML Model in OpenSearch
DESCRIPTION: This snippet shows how to register and deploy a machine learning model in OpenSearch using the connector created in the previous step. It requires the connector ID obtained from the connector creation response.

LANGUAGE: json
CODE:
POST /_plugins/_ml/models/_register?deploy=true
{
  "name": "remote-inferene",
  "function_name": "remote",
  "description": "test model",
  "connector_id": "eJATWo0BkIylWTeYToTn"
}

----------------------------------------

TITLE: Listing Dangling Indexes in OpenSearch
DESCRIPTION: This endpoint lists all dangling indexes in the OpenSearch cluster. It uses a GET request to the /_dangling endpoint.

LANGUAGE: json
CODE:
GET /_dangling

----------------------------------------

TITLE: Retrieving Available CAT API Operations in OpenSearch
DESCRIPTION: This snippet demonstrates how to get a list of all available CAT API operations in OpenSearch. It sends a GET request to the _cat endpoint.

LANGUAGE: json
CODE:
GET _cat

----------------------------------------

TITLE: Creating Model Group in OpenSearch
DESCRIPTION: Creates a model group in OpenSearch to organize the Bedrock embedding model.

LANGUAGE: json
CODE:
POST /_plugins/_ml/model_groups/_register
{
    "name": "Bedrock_embedding_model",
    "description": "Test model group for bedrock embedding model"
}

----------------------------------------

TITLE: Updating OpenSearch Cluster Settings
DESCRIPTION: Examples of updating cluster settings using the Cluster Settings API in both flat and expanded forms.

LANGUAGE: json
CODE:
PUT _cluster/settings
{
  "persistent" : {
    "action.auto_create_index" : false
  }
}

LANGUAGE: json
CODE:
PUT _cluster/settings
{
  "persistent": {
    "action": {
      "auto_create_index": false
    }
  }
}

----------------------------------------

TITLE: Example Explain Response Structure
DESCRIPTION: Shows the detailed response structure when using explain, including score calculations and normalizations.

LANGUAGE: json
CODE:
{
    "took": 54,
    "timed_out": false,
    "_shards": {
        "total": 2,
        "successful": 2,
        "skipped": 0,
        "failed": 0
    },
    "hits": {
        "total": {
            "value": 5,
            "relation": "eq"
        },
        "max_score": 0.9251075,
        "hits": [
            {
                "_shard": "[my-nlp-index][0]",
                "_node": "IsuzeVYdSqKUfy0qfqil2w",
                "_index": "my-nlp-index",
                "_id": "5",
                "_score": 0.9251075,
                "_source": {
                    "text": "A rodeo cowboy , wearing a cowboy hat , is being thrown off of a wild white horse .",
                    "id": "2691147709.jpg"
                },
                "_explanation": {
                    "value": 0.9251075,
                    "description": "arithmetic_mean combination of:",
                    "details": [...]
                }
            }
        ]
    }
}

----------------------------------------

TITLE: Minimal SAML Configuration Example for OpenSearch
DESCRIPTION: This YAML snippet provides a minimal configuration example for setting up SAML authentication in OpenSearch, including IdP metadata, entity IDs, and role key settings.

LANGUAGE: yaml
CODE:
_meta:
  type: "config"
  config_version: 2

config:
  dynamic:
    authc:
      saml_auth_domain:
        http_enabled: true
        transport_enabled: false
        order: 1
        http_authenticator:
          type: saml
          challenge: true
          config:
            idp:
              metadata_file: metadata.xml
              entity_id: http://idp.example.com/
            sp:
              entity_id: https://opensearch-dashboards.example.com
            kibana_url: https://opensearch-dashboards.example.com:5601/
            roles_key: Role
            exchange_key: 'peuvgOLrjzuhXf ...'
        authentication_backend:
          type: noop

----------------------------------------

TITLE: Defining Bytes Processor Syntax in JSON for OpenSearch
DESCRIPTION: This snippet shows the basic syntax for defining a bytes processor in an OpenSearch ingest pipeline. It specifies the field to be converted.

LANGUAGE: json
CODE:
{
    "bytes": {
        "field": "your_field_name"
    }
}

----------------------------------------

TITLE: Creating an Index with Group Parameter in Pattern Tokenizer
DESCRIPTION: This example demonstrates how to configure a pattern tokenizer with a group parameter that captures only the second group in the regular expression pattern.

LANGUAGE: json
CODE:
PUT /my_index_group2
{
  "settings": {
    "analysis": {
      "tokenizer": {
        "my_pattern_tokenizer": {
          "type": "pattern",
          "pattern": "([a-zA-Z]+)(\\d+)",
          "group": 2
        }
      },
      "analyzer": {
        "my_pattern_analyzer": {
          "type": "custom",
          "tokenizer": "my_pattern_tokenizer"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Registering DeepSeek-R1 Model in OpenSearch
DESCRIPTION: JSON request to register the DeepSeek-R1 model in OpenSearch using the created connector and model group.

LANGUAGE: json
CODE:
POST /_plugins/_ml/models/_register
{
  "name": "Bedrock DeepSeek R1 model",
  "function_name": "remote",
  "description": "DeepSeek R1 model on Bedrock",
  "model_group_id": "Vylgs5QBts7fa6bylR0v",
  "connector_id": "KHS7s5QBVQUimUskoZGp"
}

----------------------------------------

TITLE: Updating ML Commons monitoring request count in OpenSearch
DESCRIPTION: This snippet shows how to update the cluster setting to change the number of monitoring requests for the Profile API. By default, it monitors the last 100 requests.

LANGUAGE: json
CODE:
PUT _cluster/settings
{
  "persistent" : {
    "plugins.ml_commons.monitoring_request_count" : 1000000 
  }
}

----------------------------------------

TITLE: Ingesting Sample Data into OpenSearch Vector Index
DESCRIPTION: JSON bulk request to ingest sample data into the vector index for RAG testing.

LANGUAGE: json
CODE:
POST _bulk
{"index": {"_index": "my-nlp-index", "_id": "1"}}
{"text": "Chart and table of population level and growth rate for the Ogden-Layton metro area from 1950 to 2023. United Nations population projections are also included through the year 2035.\nThe current metro area population of Ogden-Layton in 2023 is 750,000, a 1.63% increase from 2022.\nThe metro area population of Ogden-Layton in 2022 was 738,000, a 1.79% increase from 2021.\nThe metro area population of Ogden-Layton in 2021 was 725,000, a 1.97% increase from 2020.\nThe metro area population of Ogden-Layton in 2020 was 711,000, a 2.16% increase from 2019."}
{"index": {"_index": "my-nlp-index", "_id": "2"}}
{"text": "Chart and table of population level and growth rate for the New York City metro area from 1950 to 2023. United Nations population projections are also included through the year 2035.\\nThe current metro area population of New York City in 2023 is 18,937,000, a 0.37% increase from 2022.\\nThe metro area population of New York City in 2022 was 18,867,000, a 0.23% increase from 2021.\\nThe metro area population of New York City in 2021 was 18,823,000, a 0.1% increase from 2020.\\nThe metro area population of New York City in 2020 was 18,804,000, a 0.01% decline from 2019."}
{"index": {"_index": "my-nlp-index", "_id": "3"}}
{"text": "Chart and table of population level and growth rate for the Chicago metro area from 1950 to 2023. United Nations population projections are also included through the year 2035.\\nThe current metro area population of Chicago in 2023 is 8,937,000, a 0.4% increase from 2022.\\nThe metro area population of Chicago in 2022 was 8,901,000, a 0.27% increase from 2021.\\nThe metro area population of Chicago in 2021 was 8,877,000, a 0.14% increase from 2020.\\nThe metro area population of Chicago in 2020 was 8,865,000, a 0.03% increase from 2019."}
{"index": {"_index": "my-nlp-index", "_id": "4"}}
{"text": "Chart and table of population level and growth rate for the Miami metro area from 1950 to 2023. United Nations population projections are also included through the year 2035.\\nThe current metro area population of Miami in 2023 is 6,265,000, a 0.8% increase from 2022.\\nThe metro area population of Miami in 2022 was 6,215,000, a 0.78% increase from 2021.\\nThe metro area population of Miami in 2021 was 6,167,000, a 0.74% increase from 2020.\\nThe metro area population of Miami in 2020 was 6,122,000, a 0.71% increase from 2019."}
{"index": {"_index": "my-nlp-index", "_id": "5"}}
{"text": "Chart and table of population level and growth rate for the Austin metro area from 1950 to 2023. United Nations population projections are also included through the year 2035.\\nThe current metro area population of Austin in 2023 is 2,228,000, a 2.39% increase from 2022.\\nThe metro area population of Austin in 2022 was 2,176,000, a 2.79% increase from 2021.\\nThe metro area population of Austin in 2021 was 2,117,000, a 3.12% increase from 2020.\\nThe metro area population of Austin in 2020 was 2,053,000, a 3.43% increase from 2019."}
{"index": {"_index": "my-nlp-index", "_id": "6"}}
{"text": "Chart and table of population level and growth rate for the Seattle metro area from 1950 to 2023. United Nations population projections are also included through the year 2035.\\nThe current metro area population of Seattle in 2023 is 3,519,000, a 0.86% increase from 2022.\\nThe metro area population of Seattle in 2022 was 3,489,000, a 0.81% increase from 2021.\\nThe metro area population of Seattle in 2021 was 3,461,000, a 0.82% increase from 2020.\\nThe metro area population of Seattle in 2020 was 3,433,000, a 0.79% increase from 2019."}

----------------------------------------

TITLE: Manual Rollover Operation
DESCRIPTION: Executes a manual rollover operation to create a new backing index for the data stream.

LANGUAGE: json
CODE:
POST logs-redis/_rollover

----------------------------------------

TITLE: Ingesting Document with Trim Pipeline
DESCRIPTION: Example of ingesting a document using the trim pipeline to process whitespace.

LANGUAGE: json
CODE:
PUT testindex1/_doc/1?pipeline=trim_pipeline
{
  "message": "   This is a test document.   "
}

----------------------------------------

TITLE: Creating a Custom Workload from Existing Cluster
DESCRIPTION: Command to create a custom OSB workload from an existing OpenSearch cluster using the opensearch-benchmark create-workload command.

LANGUAGE: bash
CODE:
opensearch-benchmark create-workload \
--workload="<WORKLOAD NAME>" \
--target-hosts="<CLUSTER ENDPOINT>" \
--client-options="basic_auth_user:'<USERNAME>',basic_auth_password:'<PASSWORD>'" \
--indices="<INDEXES TO GENERATE WORKLOAD FROM>" \
--output-path="<LOCAL DIRECTORY PATH TO STORE WORKLOAD>"

----------------------------------------

TITLE: Verifying the OpenSearch upgrade
DESCRIPTION: Commands to verify the cluster version, health, and data consistency after the upgrade.

LANGUAGE: bash
CODE:
curl -s "https://localhost:9201/_cat/nodes?v&h=name,version,node.role,master" \
   -ku admin:<custom-admin-password> | column -t

LANGUAGE: bash
CODE:
curl -s "https://localhost:9201/_cluster/health?pretty" -ku admin:<custom-admin-password>

LANGUAGE: bash
CODE:
curl -s "https://localhost:9201/_cat/shards" -ku admin:<custom-admin-password>

LANGUAGE: bash
CODE:
curl -H 'Content-Type: application/json' \
   -X GET "https://localhost:9201/ecommerce/_search?pretty=true&filter_path=hits.total" \
   -d'{"query":{"match":{"customer_first_name":"Sonya"}}}' \
   -ku admin:<custom-admin-password>

----------------------------------------

TITLE: Executing Vector Search Query
DESCRIPTION: Performs a neural search query using the configured vector index and embedding model to find semantically similar documents.

LANGUAGE: json
CODE:
POST /my_test_data/_search
{
  "query": {
    "neural": {
      "passage_embedding": {
        "query_text": "semantic search",
        "model_id": "your_embedding_model_id",
        "k": 100
      }
    }
  },
  "size": "1",
  "_source": ["passage_text"]
}

----------------------------------------

TITLE: Setting Salt for Field Masking in OpenSearch YAML Config
DESCRIPTION: Shows how to set the salt value in the opensearch.yml configuration file. The salt is used for hashing data in field masking.

LANGUAGE: yml
CODE:
plugins.security.compliance.salt: abcdefghijklmnopqrstuvqxyz1234567890

----------------------------------------

TITLE: Deleting a k-NN Model in OpenSearch
DESCRIPTION: Shows how to delete a specific k-NN model from the cluster using the DELETE operation.

LANGUAGE: json
CODE:
DELETE /_plugins/_knn/models/{model_id}

----------------------------------------

TITLE: Search Memory by Name Request
DESCRIPTION: Example request to search for a specific memory by its name using a term query.

LANGUAGE: json
CODE:
{
  "query": {
    "term": {
      "name": {
        "value": "conversation"
      }
    }
  }
}

----------------------------------------

TITLE: HNSW Memory Estimation Calculation
DESCRIPTION: Example calculation for estimating memory requirements for HNSW graph with 1 million vectors.

LANGUAGE: r
CODE:
1.1 * (256 + 8 * 16) * 1,000,000 ~= 0.4 GB

----------------------------------------

TITLE: Multi-get Request with Index in URL
DESCRIPTION: Example of a multi-get request in OpenSearch where the index is specified in the URL. Shows how to retrieve multiple documents from a single index with source field filtering.

LANGUAGE: json
CODE:
GET sample-index1/_mget
{
  "docs": [
    {
      "_id": "1",
      "_source": false
    },
    {
      "_id": "2",
      "_source": [ "Director", "Title" ]
    }
  ]
}

----------------------------------------

TITLE: Example workload.json structure for OpenSearch Benchmark
DESCRIPTION: Shows the essential elements of a workload.json file, including description, indices, corpora, and schedule sections. This example demonstrates how to define index creation, document ingestion, and search operations.

LANGUAGE: json
CODE:
{
  "description": "Tutorial benchmark for OpenSearch Benchmark",
  "indices": [
    {
      "name": "movies",
      "body": "index.json"
    }
  ],
  "corpora": [
    {
      "name": "movies",
      "documents": [
        {
          "source-file": "movies-documents.json",
          "document-count": 11658903,
          "uncompressed-bytes": 1544799789
        }
      ]
    }
  ],
  "schedule": [
    {
      "operation": {
        "operation-type": "create-index"
      }
    },
    {
      "operation": {
        "operation-type": "cluster-health",
        "request-params": {
          "wait_for_status": "green"
        },
        "retry-until-success": true
      }
    },
    {
      "operation": {
        "operation-type": "bulk",
        "bulk-size": 5000
      },
      "warmup-time-period": 120,
      "clients": 8
    },
    {
      "operation": {
        "name": "query-match-all",
        "operation-type": "search",
        "body": {
          "query": {
            "match_all": {}
          }
        }
      },
      "iterations": 1000,
      "target-throughput": 100
    }
  ]
}

----------------------------------------

TITLE: Configuring map_to_list Processor with Field to List Conversion in YAML
DESCRIPTION: Shows how to use the convert_field_to_list option in the map_to_list processor to convert map fields into lists.

LANGUAGE: yaml
CODE:
processor:
  - map_to_list:
      source: "my-map"
      target: "my-list"
      convert_field_to_list: true

----------------------------------------

TITLE: Ingesting Document with Copy Pipeline
DESCRIPTION: Example of ingesting a document using the copy_object pipeline to process the document during ingestion.

LANGUAGE: json
CODE:
{
  "content": {
    "foo": "bar",
    "zoo": [1, 2, 3]
  }
}

----------------------------------------

TITLE: Document Filter Query for Feature Logging
DESCRIPTION: Example query showing how to filter specific documents when logging feature scores.

LANGUAGE: json
CODE:
{
    "filter": [
        {"terms": {
                "_id": ["7555", "1370", "1369"]
        }}
    ]
}

----------------------------------------

TITLE: Example Node Usage API Request in OpenSearch
DESCRIPTION: Simple GET request to retrieve usage details for all nodes in the cluster.

LANGUAGE: json
CODE:
GET _nodes/usage

----------------------------------------

TITLE: Document Indexing Examples
DESCRIPTION: Examples showing how to index sample documents for testing match_phrase queries.

LANGUAGE: json
CODE:
PUT testindex/_doc/1
{
  "title": "The wind rises"
}

LANGUAGE: json
CODE:
PUT testindex/_doc/2
{
  "title": "Gone with the wind"
}

----------------------------------------

TITLE: Configuring Node Certificate DNs in OpenSearch
DESCRIPTION: Example YAML configuration for specifying allowed node certificate Distinguished Names (DNs) in OpenSearch, including support for wildcards and regular expressions.

LANGUAGE: yaml
CODE:
plugins.security.nodes_dn:
  - 'CN=node.other.com,OU=SSL,O=Test,L=Test,C=DE'
  - 'CN=*.example.com,OU=SSL,O=Test,L=Test,C=DE'
  - 'CN=elk-devcluster*'
  - '/CN=.*regex/'

----------------------------------------

TITLE: Configuring Node Certificate DNs in OpenSearch
DESCRIPTION: Example YAML configuration for specifying allowed node certificate Distinguished Names (DNs) in OpenSearch, including support for wildcards and regular expressions.

LANGUAGE: yaml
CODE:
plugins.security.nodes_dn:
  - 'CN=node.other.com,OU=SSL,O=Test,L=Test,C=DE'
  - 'CN=*.example.com,OU=SSL,O=Test,L=Test,C=DE'
  - 'CN=elk-devcluster*'
  - '/CN=.*regex/'

----------------------------------------

TITLE: OpenSearch Whitespace Analyzer Output
DESCRIPTION: Example showing how the Whitespace analyzer tokenizes text only on whitespace characters, preserving case and special characters.

LANGUAGE: markdown
CODE:
[`It's`, `fun`, `to`, `contribute`, `a`,`brand-new`, `PR`, `or`, `2`, `to`, `OpenSearch!`]

----------------------------------------

TITLE: JSON Pointer Syntax Examples in OpenSearch Data Prepper
DESCRIPTION: Examples of shorthand and escaped syntax for JSON pointers used to reference values within an event.

LANGUAGE: markdown
CODE:
# Shorthand syntax
/Hello/World/0

# Escaped syntax
# Path
# { "Hello - 'world/" : [{ "\"JsonPointer\"": true }] }
"/Hello - 'world\//0/\"JsonPointer\""

----------------------------------------

TITLE: Configuring BM25 Similarity Parameters in OpenSearch
DESCRIPTION: This snippet demonstrates how to configure BM25 similarity parameters at the index level in OpenSearch. It sets custom values for 'k1', 'b', and 'discount_overlaps' parameters.

LANGUAGE: json
CODE:
PUT /testindex
{
  "settings": {
    "index": {
      "similarity": {
        "custom_similarity": {
          "type": "BM25",
          "k1": 1.2,
          "b": 0.75,
          "discount_overlaps": "true"
        }
      }
    }
  }
}

----------------------------------------

TITLE: DELETE Query Explanation in OpenSearch
DESCRIPTION: JSON representation of how OpenSearch interprets and executes the DELETE query internally.

LANGUAGE: json
CODE:
{
  "size" : 1000,
  "query" : {
    "bool" : {
      "must" : [
        {
          "range" : {
            "age" : {
              "from" : 30,
              "to" : null,
              "include_lower" : false,
              "include_upper" : true,
              "boost" : 1.0
            }
          }
        }
      ],
      "adjust_pure_negative" : true,
      "boost" : 1.0
    }
  },
  "_source" : false
}

----------------------------------------

TITLE: Pipeline Processor Basic Syntax
DESCRIPTION: Shows the basic syntax for configuring a pipeline processor that references another pipeline.

LANGUAGE: json
CODE:
{
  "pipeline": {
    "name": "general-pipeline"
  }
}

----------------------------------------

TITLE: Deleting Replication Rule in OpenSearch
DESCRIPTION: This curl command deletes a specified replication rule from the follower cluster. It requires the leader cluster alias and the name of the rule to be deleted.

LANGUAGE: bash
CODE:
curl -XDELETE -k -H 'Content-Type: application/json' -u 'admin:<custom-admin-password>' 'https://localhost:9200/_plugins/_replication/_autofollow?pretty' -d '
{
   "leader_alias" : "my-connection-alias",
   "name": "my-replication-rule"
}'

----------------------------------------

TITLE: Multi-level Nested Index Creation
DESCRIPTION: Example of creating an index with multi-level nested fields for complex patient data structure.

LANGUAGE: json
CODE:
PUT /patients
{
  "mappings": {
    "properties": {
      "patient": {
        "type": "nested",
        "properties": {
          "name": {
            "type": "text"
          },
          "contacts": {
            "type": "nested",
            "properties": {
              "name": {
                "type": "text"
              },
              "relationship": {
                "type": "text"
              },
              "phone": {
                "type": "keyword"
              }
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Downloading OpenSearch Docker Compose File
DESCRIPTION: Commands to download the sample Docker Compose configuration file using curl or wget.

LANGUAGE: bash
CODE:
curl -O https://raw.githubusercontent.com/opensearch-project/documentation-website/{{site.opensearch_major_minor_version}}/assets/examples/docker-compose.yml

LANGUAGE: bash
CODE:
wget https://raw.githubusercontent.com/opensearch-project/documentation-website/{{site.opensearch_major_minor_version}}/assets/examples/docker-compose.yml

----------------------------------------

TITLE: Input JSON Event Example
DESCRIPTION: Sample JSON input event before processing, containing two message fields.

LANGUAGE: json
CODE:
{"message": "hello", "message2": "goodbye"}

----------------------------------------

TITLE: Creating Multiple Indices in OpenSearch Benchmark
DESCRIPTION: Example of creating all defined indices with custom shard settings and wait parameters.

LANGUAGE: yaml
CODE:
{
  "name": "create-all-indices",
  "operation-type": "create-index",
  "settings": {
    "index.number_of_shards": 1
  },
  "request-params": {
    "wait_for_active_shards": "true"
  }
}

----------------------------------------

TITLE: Registering Standard Value Source in Python
DESCRIPTION: Function to register a standard value source for range queries in the workload registry.

LANGUAGE: python
CODE:
def register(registry):
    registry.register_standard_value_source("range", "total_amount", range_query_standard_value_source)

----------------------------------------

TITLE: Creating OpenSearch Pipeline with Date Processor
DESCRIPTION: Example of creating an OpenSearch pipeline named 'date-output-format' that uses the date processor to convert European date format to US date format.

LANGUAGE: json
CODE:
PUT /_ingest/pipeline/date-output-format
{
  "description": "Pipeline that converts European date format to US date format",
  "processors": [
    {
      "date": {
        "field" : "date_european",
        "formats" : ["dd/MM/yyyy", "UNIX"],
        "target_field": "date_us",
        "output_format": "MM/dd/yyy",
        "timezone" : "UTC"
      }
    }
  ]
}

----------------------------------------

TITLE: Executing Weighted Average Aggregation in OpenSearch
DESCRIPTION: Performs a weighted average aggregation on the 'products' index, using the 'rating' field as the value and 'num_reviews' field as the weight. This query calculates the weighted average rating of products based on the number of reviews.

LANGUAGE: json
CODE:
GET /products/_search
{
  "size": 0,
  "aggs": {
    "weighted_rating": {
      "weighted_avg": {
        "value": {
          "field": "rating"
        },
        "weight": {
          "field": "num_reviews"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating Model Group in OpenSearch
DESCRIPTION: JSON request to create a model group for the DeepSeek-R1 model in OpenSearch.

LANGUAGE: json
CODE:
POST /_plugins/_ml/model_groups/_register
{
    "name": "Bedrock DeepSeek model",
    "description": "Test model group for Bedrock DeepSeek model"
}

----------------------------------------

TITLE: Registering External Model
DESCRIPTION: Example of registering an externally hosted model using a connector ID.

LANGUAGE: json
CODE:
{
    "name": "OpenAI model for realtime embedding and offline batch inference",
    "function_name": "remote",
    "description": "OpenAI text embedding model",
    "connector_id": "XU5UiokBpXT9icfOM0vt"
}

----------------------------------------

TITLE: Selecting Specific Fields in OpenSearch SQL
DESCRIPTION: Example of selecting only specific fields (firstname and lastname) from the 'accounts' index in OpenSearch.

LANGUAGE: sql
CODE:
SELECT firstname, lastname
FROM accounts

----------------------------------------

TITLE: Selecting Specific Fields in OpenSearch SQL
DESCRIPTION: Example of selecting only specific fields (firstname and lastname) from the 'accounts' index in OpenSearch.

LANGUAGE: sql
CODE:
SELECT firstname, lastname
FROM accounts

----------------------------------------

TITLE: Configuring OpenSearch AgentTool JSON Structure
DESCRIPTION: Example showing how to specify an AgentTool configuration with required type, description and parameters. The AgentTool requires an agent_id parameter to identify which agent to run.

LANGUAGE: json
CODE:
{
  "type": "AgentTool",
  "description": "A general agent to answer any question",
  "parameters": {
    "agent_id": "9X7xWI0Bpc3sThaJdY9i"
  }
}

----------------------------------------

TITLE: Defining an Action in an ISM Policy
DESCRIPTION: Example of how to define an action within a state, including timeout and retry configurations.

LANGUAGE: json
CODE:
"actions": {
  "timeout": "1h",
  "retry": {
    "count": 3,
    "backoff": "exponential",
    "delay": "10m"
  }
}

----------------------------------------

TITLE: Template with Metadata
DESCRIPTION: Example of adding metadata to an index template using the _meta parameter.

LANGUAGE: json
CODE:
PUT /_index_template/template_one
{
  "index_patterns": ["rom", "juliet"],
  "template": {
    "settings" : {
        "number_of_shards" : 2
    }
  },
  "_meta": {
    "description": "Where art thou",
    "serialization": {
      "class": "MyIndexTemplate",
      "id": 12
    }
  }
}

----------------------------------------

TITLE: Creating Custom Basque Analyzer
DESCRIPTION: Demonstrates how to create a custom Basque analyzer with specific token filters and configurations.

LANGUAGE: json
CODE:
PUT /basque-index
{
  "settings": {
    "analysis": {
      "filter": {
        "basque_stop": {
          "type": "stop",
          "stopwords": "_basque_"
        },
        "basque_stemmer": {
          "type": "stemmer",
          "language": "basque"
        },
        "basque_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] 
        }
      },
      "analyzer": {
        "basque_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "basque_stop",
            "basque_keywords",
            "basque_stemmer"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "basque_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Bulk Data Ingestion
DESCRIPTION: Ingests multiple documents into the index using the bulk API. Each document contains various fields including category, doc_keyword, doc_index, and doc_price.

LANGUAGE: json
CODE:
POST /_bulk
{ "index": { "_index": "my-nlp-index" } }
{ "category": "permission", "doc_keyword": "workable", "doc_index": 4976, "doc_price": 100}
{ "index": { "_index": "my-nlp-index" } }
{ "category": "sister", "doc_keyword": "angry", "doc_index": 2231, "doc_price": 200 }
{ "index": { "_index": "my-nlp-index" } }
{ "category": "hair", "doc_keyword": "likeable", "doc_price": 25 }
{ "index": { "_index": "my-nlp-index" } }
{ "category": "editor", "doc_index": 9871, "doc_price": 30 }
{ "index": { "_index": "my-nlp-index" } }
{ "category": "statement", "doc_keyword": "entire", "doc_index": 8242, "doc_price": 350  } 
{ "index": { "_index": "my-nlp-index" } }
{ "category": "statement", "doc_keyword": "idea", "doc_index": 5212, "doc_price": 200  } 
{ "index": { "_index": "index-test" } }
{ "category": "editor", "doc_keyword": "bubble", "doc_index": 1298, "doc_price": 130 } 
{ "index": { "_index": "index-test" } }
{ "category": "editor", "doc_keyword": "bubble", "doc_index": 521, "doc_price": 75  }

----------------------------------------

TITLE: Keep Original Structure with Regex Mappings
DESCRIPTION: Configuration for maintaining original index structure while handling type mappings using regex patterns.

LANGUAGE: json
CODE:
[
  {
    "TypeMappingSanitizationTransformerProvider": {
      "regexMappings": [
        {
          "sourceIndexPattern": "(.*)",
          "sourceTypePattern": ".*",
          "targetIndexPattern": "$1"
        }
      ],
      "sourceProperties": {
        "version": {
          "major": 6,
          "minor": 8
        }
      }
    }
  }
]

----------------------------------------

TITLE: Filtering Query Results by Time Range in OpenSearch
DESCRIPTION: This JSON query filters documents based on a time range using the 'period_start' and 'period_end' variables. It's useful for per query monitors that need to analyze data within specific time intervals, such as the last hour before the monitor runs.

LANGUAGE: json
CODE:
{
  "size": 0,
  "query": {
    "bool": {
      "filter": [{
        "range": {
          "timestamp": {
            "from": "{{period_end}}||-1h",
            "to": "{{period_end}}",
            "include_lower": true,
            "include_upper": true,
            "format": "epoch_millis",
            "boost": 1
          }
        }
      }],
      "adjust_pure_negative": true,
      "boost": 1
    }
  },
  "aggregations": {}
}

----------------------------------------

TITLE: Get Workflow YAML Request
DESCRIPTION: cURL command example for retrieving a workflow template in YAML format by specifying the appropriate Content-Type header.

LANGUAGE: bash
CODE:
curl -XGET "http://localhost:9200/_plugins/_flow_framework/workflow/8xL8bowB8y25Tqfenm50" -H 'Content-Type: application/yaml'

----------------------------------------

TITLE: Adding ISM Policy to Index - JSON
DESCRIPTION: Adds an existing policy to a specific index. The operation preserves any existing policy on the index.

LANGUAGE: json
CODE:
POST _plugins/_ism/add/index_1
{
  "policy_id": "policy_1"
}

----------------------------------------

TITLE: Renaming Fields to Avoid Conflicts in Dot Expander
DESCRIPTION: Shows how to use the rename processor in combination with dot_expander to avoid parse exceptions when field names conflict.

LANGUAGE: json
CODE:
PUT /_ingest/pipeline/dot-expander-pipeline
{
  "processors" : [
    {
      "rename" : {
        "field" : "user",
        "target_field" : "user.name"
      }
    },
    {
      "dot_expander": {
        "field": "user.name"
      }
    }
  ]
}

----------------------------------------

TITLE: Adding Metadata to Component Template in OpenSearch
DESCRIPTION: This example demonstrates how to add metadata to a component template using the _meta parameter, which is stored in the cluster state.

LANGUAGE: json
CODE:
PUT /_component_template/meta_template
{
  "template": {
    "settings" : {
        "number_of_shards" : 1
    }
  },
  "_meta": {
    "description": "Where art thou",
    "serialization": {
      "class": "MyIndexTemplate",
      "id": 12
    }
  }
}

----------------------------------------

TITLE: Creating Custom Sorani Analyzer in OpenSearch
DESCRIPTION: This snippet illustrates how to create a custom Sorani analyzer in OpenSearch. It defines custom token filters for stop words, stemming, and keyword marking, and combines them with standard tokenization and lowercase filtering.

LANGUAGE: json
CODE:
PUT /sorani-index
{
  "settings": {
    "analysis": {
      "filter": {
        "sorani_stop": {
          "type": "stop",
          "stopwords": "_sorani_"
        },
        "sorani_stemmer": {
          "type": "stemmer",
          "language": "sorani"
        },
        "sorani_keywords": {
          "type": "keyword_marker",
          "keywords": []
        }
      },
      "analyzer": {
        "sorani_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "decimal_digit",
            "sorani_stop",
            "sorani_keywords",
            "sorani_stemmer"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "sorani_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Marking OpenSearch API Search Endpoint Specification Insertion Point
DESCRIPTION: These HTML comments define the start and end points for inserting API specifications related to the search endpoint in OpenSearch. They include metadata about the API and component type.

LANGUAGE: HTML
CODE:
<!-- spec_insert_start
api: search
component: endpoints
-->
<!-- spec_insert_end -->

----------------------------------------

TITLE: Configuring On-Heap and Disk Store Tiers in YAML
DESCRIPTION: Sets the on-heap and disk store tiers for the tiered spillover cache implementation in OpenSearch.

LANGUAGE: yaml
CODE:
indices.requests.cache.tiered_spillover.onheap.store.name: opensearch_onheap
indices.requests.cache.tiered_spillover.disk.store.name: ehcache_disk

----------------------------------------

TITLE: Creating Cohere Rerank Connector - Self-managed OpenSearch
DESCRIPTION: POST request to create a connector for the Cohere Rerank model with authentication and configuration parameters.

LANGUAGE: json
CODE:
POST /_plugins/_ml/connectors/_create
{
    "name": "cohere-rerank",
    "description": "The connector to Cohere reanker model",
    "version": "1",
    "protocol": "http",
    "credential": {
        "cohere_key": "your_cohere_api_key"
    },
    "parameters": {
        "model": "rerank-english-v3.0",
        "return_documents": true
    },
    "actions": [
        {
            "action_type": "predict",
            "method": "POST",
            "url": "https://api.cohere.ai/v1/rerank",
            "headers": {
                "Authorization": "Bearer ${credential.cohere_key}"
            },
            "request_body": "{ \"documents\": ${parameters.documents}, \"query\": \"${parameters.query}\", \"model\": \"${parameters.model}\", \"top_n\": ${parameters.top_n},  \"return_documents\": ${parameters.return_documents} }"
        }
    ]
}

----------------------------------------

TITLE: Ingesting Document with Community ID Pipeline in OpenSearch
DESCRIPTION: This JSON query ingests a document into the 'testindex1' index using the community_id_pipeline. It provides network flow data that will be processed to generate a community ID hash.

LANGUAGE: json
CODE:
PUT testindex1/_doc/1?pipeline=commnity_id_pipeline
{
  "source_ip": "66.35.250.204",
  "source_port": 80,
  "destination_ip": "128.232.110.120",
  "destination_port": 34855,
  "iana_protocol_number": 6
}

----------------------------------------

TITLE: Configuring IP Range Mapping with Malformed Field Handling
DESCRIPTION: Example of configuring index mappings for IP range fields, showing how to set ignore_malformed flag to handle malformed IP addresses.

LANGUAGE: json
CODE:
{
  "mappings": {
    "properties": {
      "ips": {
        "type": "ip_range",
        "ignore_malformed": true
      }
    }
  }
}

----------------------------------------

TITLE: Checking Git Version for OpenSearch Benchmark
DESCRIPTION: Verifies Git 1.9 or later is installed, which is optional but required for fetching benchmark workload resources.

LANGUAGE: bash
CODE:
git --version

----------------------------------------

TITLE: Nested Aggregation Structure in OpenSearch
DESCRIPTION: This snippet illustrates the structure of nested aggregations in OpenSearch. It shows how to define multiple levels of aggregations, allowing for complex analysis by combining different aggregation types.

LANGUAGE: json
CODE:
{
  "aggs": {
    "name": {
      "type": {
        "data"
      },
      "aggs": {
        "nested": {
          "type": {
            "data"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating an Index with Simple Analyzer in OpenSearch
DESCRIPTION: This snippet demonstrates how to create an index named 'my_simple_index' with a simple analyzer applied to a field. The simple analyzer is used for basic text analysis, breaking text at non-letter characters and lowercasing terms.

LANGUAGE: json
CODE:
PUT /my_simple_index
{
  "mappings": {
    "properties": {
      "my_field": {
        "type": "text",
        "analyzer": "simple"
      }
    }
  }
}

----------------------------------------

TITLE: Executing Reranked Search Query
DESCRIPTION: Performs a search with reranking enabled using a match query and additional reranking context in the ext.rerank field.

LANGUAGE: json
CODE:
POST /my-index/_search
{
  "query": {
    "match": {
      "passage_text": "how to welcome in family"
    }
  },
  "ext": {
    "rerank": {
      "query_context": {
         "query_text": "how to welcome in family"
      }
    }
  }
}

----------------------------------------

TITLE: Drop Events Configuration Options
DESCRIPTION: Configuration table showing the options available for the drop_events processor. Includes drop_when for conditional filtering and handle_failed_events for exception handling.

LANGUAGE: markdown
CODE:
Option | Required | Type | Description
:--- | :--- | :--- | :---
drop_when | Yes | String | Accepts an OpenSearch Data Prepper expression string following the [expression syntax]. Configuring `drop_events` with `drop_when: true` drops all the events received.
handle_failed_events | No | Enum | Specifies how exceptions are handled when an exception occurs while evaluating an event. Default value is `drop`, which drops the event so that it is not sent to OpenSearch. Available options are `drop`, `drop_silently`, `skip`, and `skip_silently`.

----------------------------------------

TITLE: Creating and Monitoring Snapshots in OpenSearch
DESCRIPTION: Commands for creating and monitoring the progress of cluster snapshots for migration purposes.

LANGUAGE: shell
CODE:
console snapshot create

LANGUAGE: shell
CODE:
console snapshot status --deep-check

----------------------------------------

TITLE: Analyzing Text with OpenSearch _analyze Endpoint
DESCRIPTION: Demonstrates how to use the _analyze endpoint to check how a string is split into tokens using the default analyzer for a specific field.

LANGUAGE: json
CODE:
GET books/_analyze
{
  "text": "Design Patterns (Object-Oriented Software)",
  "field": "title"
}

----------------------------------------

TITLE: Configuring copy_values Processor in YAML
DESCRIPTION: This snippet demonstrates how to configure the copy_values processor to copy values and skip existing fields in a Data Prepper pipeline.

LANGUAGE: yaml
CODE:
processor:
  - copy_values:
      entries:
        - from_key: "message1"
          to_key: "message2"
        - from_key: "message1"
          to_key: "message3"

----------------------------------------

TITLE: Rewritten Search Request After ML Inference Processing in OpenSearch
DESCRIPTION: This snippet illustrates how the search request is rewritten after the ml_inference search request processor runs. The vector field now contains the generated embeddings, and the text_embedding field contains the processor output.

LANGUAGE: json
CODE:
GET /template-knn-1/_search
{
  "query": {
    "template": {
      "knn": {
        "text_embedding": {
          "vector": [0.6328125, 0.26953125, ...], 
          "k": 2
        }
      }
    }
  },
  "ext": {
    "ml_inference": {
      "text": "sneakers",
      "text_embedding": [0.6328125, 0.26953125, ...] 
    }
  }
}

----------------------------------------

TITLE: Creating Search Pipeline with Normalization Processor in OpenSearch
DESCRIPTION: Example of creating a search pipeline that uses min_max normalization and arithmetic_mean combination techniques with weighted scoring.

LANGUAGE: json
CODE:
PUT /_search/pipeline/nlp-search-pipeline
{
  "description": "Post processor for hybrid search",
  "phase_results_processors": [
    {
      "normalization-processor": {
        "normalization": {
          "technique": "min_max"
        },
        "combination": {
          "technique": "arithmetic_mean",
          "parameters": {
            "weights": [
              0.3,
              0.7
            ]
          }
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Configuring Root Agent for Text to Visualization
DESCRIPTION: JSON requests to configure the root agent and instruction-based agent for text-to-visualization functionality.

LANGUAGE: json
CODE:
POST /.plugins-ml-config/_doc/os_text2vega
{
  "type": "os_chat_root_agent",
  "configuration": {
    "agent_id": "<ROOT_AGENT_ID>"
  }
}

----------------------------------------

TITLE: Retrieving Index Cache Statistics in OpenSearch
DESCRIPTION: Shows how to retrieve cache statistics for a specific index using the Index Stats API.

LANGUAGE: json
CODE:
GET /my_index/_stats/request_cache

LANGUAGE: json
CODE:
{
  "_shards": {
    "total": 5,
    "successful": 5,
    "failed": 0
  },
  "_all": {
    "primaries": {
      "request_cache": {
        "memory_size_in_bytes": 2048,
        "evictions": 1,
        "hit_count": 30,
        "miss_count": 5
      }
    },
    "total": {
      "request_cache": {
        "memory_size_in_bytes": 4096,
        "evictions": 2,
        "hit_count": 60,
        "miss_count": 10
      }
    }
  },
  "indices": {
    "my_index": {
      "primaries": {
        "request_cache": {
          "memory_size_in_bytes": 2048,
          "evictions": 1,
          "hit_count": 30,
          "miss_count": 5
        }
      },
      "total":{
        "request_cache": {
          "memory_size_in_bytes": 4096,
          "evictions": 2,
          "hit_count": 60,
          "miss_count": 10
        }
      }
    }
  }
}

----------------------------------------

TITLE: Index Mapping Verification Error
DESCRIPTION: Example of verification exception when dealing with index patterns or multiple types.

LANGUAGE: json
CODE:
{
  "error": {
    "reason": "There was internal problem at backend",
    "details": "When using multiple indices, the mappings must be identical.",
    "type": "VerificationException"
  },
  "status": 503
}

----------------------------------------

TITLE: Defining Lowercase Processor Syntax in JSON
DESCRIPTION: Demonstrates the basic syntax for the lowercase processor in an OpenSearch ingest pipeline. The processor converts text in a specified field to lowercase.

LANGUAGE: json
CODE:
{
  "lowercase": {
    "field": "field_name"
  }
}

----------------------------------------

TITLE: Configuring OpenSearch Input Plugin in Logstash
DESCRIPTION: This YAML configuration demonstrates how to set up the OpenSearch input plugin in Logstash to read data from an OpenSearch cluster. It specifies the host, credentials, index, and query to execute.

LANGUAGE: yaml
CODE:
input {
  opensearch {
    hosts       => "https://hostname:port"
    user        => "admin"
    password    => "admin"
    index       => "logstash-logs-%{+YYYY.MM.dd}"
    query       => '{ "query": { "match_all": {}}}'
  }
}

filter {
}

output {
}

----------------------------------------

TITLE: Configuring DocumentDB Source Pipeline in YAML
DESCRIPTION: Example pipeline configuration showing how to set up a DocumentDB source with authentication, AWS role, and collection settings. The pipeline reads from a DocumentDB cluster and uses S3 as an intermediate storage.

LANGUAGE: yaml
CODE:
version: "2"
documentdb-pipeline:
  source:
    documentdb:
      host: "docdb-mycluster.cluster-random.us-west-2.docdb.amazonaws.com"
      port: 27017
      authentication:
        username: ${{aws_secrets:secret:username}}
        password: ${{aws_secrets:secret:password}}
      aws:
        sts_role_arn: "arn:aws:iam::123456789012:role/MyRole"
      s3_bucket: my-bucket
      s3_region: us-west-2
      collections:
        - collection: my-collection
          export: true
          stream: true
      acknowledgments: true

----------------------------------------

TITLE: Creating Single Index with Custom Settings
DESCRIPTION: Example of creating a single index with custom settings and mappings.

LANGUAGE: yaml
CODE:
{
  "name": "create-an-index",
  "operation-type": "create-index",
  "index": "people",
  "body": {
    "settings": {
      "index.number_of_shards": 0
    },
    "mappings": {
      "docs": {
        "properties": {
          "name": {
            "type": "text"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Ingesting Document with Dot Expander Pipeline in OpenSearch
DESCRIPTION: Demonstrates how to ingest a document into an index using the dot_expander pipeline.

LANGUAGE: json
CODE:
PUT testindex1/_doc/1?pipeline=dot-expander-pipeline
{
  "user.address.city": "Denver",
  "user.address.state": "CO"
}

----------------------------------------

TITLE: Installing Sycamore with Local Inference Support in Bash
DESCRIPTION: This command installs Sycamore with both the OpenSearch connector and local inference support. This setup allows for local processing of PDFs and embedding generation without relying on external services.

LANGUAGE: bash
CODE:
pip install sycamore-ai[opensearch,local-inference]

----------------------------------------

TITLE: Registering a Flow Agent for IndexMappingTool in OpenSearch
DESCRIPTION: This JSON snippet demonstrates how to register a flow agent that will run the IndexMappingTool. It specifies the agent type, description, and the tool configuration including parameters for index and input.

LANGUAGE: json
CODE:
{
  "name": "Test_Agent_For_IndexMapping_tool",
  "type": "flow",
  "description": "this is a test agent for the IndexMappingTool",
  "tools": [
      {
      "type": "IndexMappingTool",
      "name": "DemoIndexMappingTool",
      "parameters": {
        "index": "${parameters.index}",
        "input": "${parameters.question}"
      }
    }
  ]
}

----------------------------------------

TITLE: Creating/Updating Snapshot Policy
DESCRIPTION: API endpoints and example payload for creating or updating a snapshot management policy. The POST endpoint creates a new policy while PUT updates an existing one with sequence number and primary term parameters.

LANGUAGE: json
CODE:
POST _plugins/_sm/policies/<policy_name>

LANGUAGE: json
CODE:
PUT _plugins/_sm/policies/<policy_name>?if_seq_no=0&if_primary_term=1

----------------------------------------

TITLE: Register Restricted Model Group with Specific Roles
DESCRIPTION: Example request for registering a model group with restricted access mode and specific backend roles

LANGUAGE: json
CODE:
{
    "name": "model_group_test",
    "description": "This is an example description",
    "access_mode": "restricted",
    "backend_roles" : ["IT"]
}

----------------------------------------

TITLE: Multiple Matching Templates with Different Priorities
DESCRIPTION: Demonstrates creating two index templates with different priorities to control template precedence.

LANGUAGE: json
CODE:
PUT /_index_template/template_one
{
  "index_patterns" : ["h*"],
  "priority" : 0,
  "template": {
    "settings" : {
      "number_of_shards" : 1,
      "number_of_replicas": 0
    },
    "mappings" : {
      "_source" : { "enabled" : false }
    }
  }
}

PUT /_index_template/template_two
{
  "index_patterns" : ["ha*"],
  "priority" : 1,
  "template": {
    "settings" : {
      "number_of_shards" : 2
    },
    "mappings" : {
      "_source" : { "enabled" : true }
    }
  }
}

----------------------------------------

TITLE: Installing Ruby with OpenSSL on Apple Silicon
DESCRIPTION: Commands to install Ruby with a specific OpenSSL version on Apple Silicon machines, addressing potential version misalignment issues.

LANGUAGE: shell
CODE:
# Assumes Brew is installed
curl -sSL https://get.rvm.io | bash -s stable
rvm install 3.2.4 --with-openssl-dir=$(brew --prefix openssl@<openssl-version>)
ruby -v

----------------------------------------

TITLE: Starting OpenSearch with Docker Compose
DESCRIPTION: Command to start OpenSearch using Docker Compose with the security demo configuration

LANGUAGE: bash
CODE:
docker compose up

----------------------------------------

TITLE: Starting OpenSearch with Docker Compose
DESCRIPTION: Command to start OpenSearch using Docker Compose with the security demo configuration

LANGUAGE: bash
CODE:
docker compose up

----------------------------------------

TITLE: HTTP Endpoints for Render Template API
DESCRIPTION: Available HTTP paths and methods for accessing the Render Template API endpoints.

LANGUAGE: json
CODE:
GET /_render/template
POST /_render/template
GET /_render/template/<id>
POST /_render/template/<id>

----------------------------------------

TITLE: Configuring Search Relevance Metrics Interval in YAML
DESCRIPTION: Sets the interval for collecting search relevance metrics to one second in the OpenSearch Dashboards configuration file.

LANGUAGE: yaml
CODE:
searchRelevanceDashboards.metrics.metricInterval: 1000

----------------------------------------

TITLE: Testing Fingerprint Pipeline in OpenSearch
DESCRIPTION: Example of testing the fingerprint pipeline using the simulate API with a sample document.

LANGUAGE: json
CODE:
{
  "docs": [
    {
      "_index": "testindex1",
      "_id": "1",
      "_source": {
        "foo": "foo",
        "bar": "bar"
      }
    }
  ]
}

----------------------------------------

TITLE: Missing Allow Delete Parameter Response
DESCRIPTION: Response returned when the allow_delete parameter is required but not provided, with 403 FORBIDDEN status.

LANGUAGE: json
CODE:
{
    "error": "These resources require the allow_delete parameter to deprovision: [index_name my-index]."
}

----------------------------------------

TITLE: Deleting Notification Settings
DESCRIPTION: API requests to delete notification settings, including an example for removing reindex operation notifications.

LANGUAGE: json
CODE:
DELETE _plugins/_im/lron/LRON:indices:data%2Fwrite%2Freindex

----------------------------------------

TITLE: Accessing Migration Console via Bootstrap Box
DESCRIPTION: This code snippet demonstrates how to access the migration console through a Bootstrap box deployed by Migration Assistant. It sets environment variables for the stage and AWS region, then runs a script to access the container.

LANGUAGE: shell
CODE:
export STAGE=dev
export AWS_REGION=us-west-2
/opensearch-migrations/deployment/cdk/opensearch-service-migration/accessContainer.sh migration-console ${STAGE} ${AWS_REGION}

----------------------------------------

TITLE: Creating OpenAI Connector in YAML
DESCRIPTION: Creates a connector to an externally hosted OpenAI GPT-3.5 model, configuring the endpoint, credentials and prediction actions.

LANGUAGE: yaml
CODE:
nodes:
- id: create_connector_1
  type: create_connector
  user_inputs:
    name: OpenAI Chat Connector
    description: The connector to public OpenAI model service for GPT 3.5
    version: '1'
    protocol: http
    parameters:
      endpoint: api.openai.com
      model: gpt-3.5-turbo
    credential:
      openAI_key: '12345'
    actions:
    - action_type: predict
      method: POST
      url: https://${parameters.endpoint}/v1/chat/completions

----------------------------------------

TITLE: Handling Field Name Conflicts in Dot Expander
DESCRIPTION: Demonstrates how the dot_expander processor handles conflicts when a field already exists with the same path, merging values into an array.

LANGUAGE: json
CODE:
PUT /_ingest/pipeline/dot-expander-pipeline
{
  "description": "Dot expander processor",
  "processors": [
    {
      "dot_expander": {
        "field": "user.name"
      }
    }
  ]
}

----------------------------------------

TITLE: Ingesting Document with Set Pipeline
DESCRIPTION: Example of ingesting a document using the Set processor pipeline.

LANGUAGE: json
CODE:
POST testindex1/_doc?pipeline=set-pipeline
{
  "existing_field": "value"
}

----------------------------------------

TITLE: Analyzing Text with Stop Token Filter
DESCRIPTION: Example request to analyze text using the custom analyzer with stop token filter, showing how stopwords are removed from the input text.

LANGUAGE: json
CODE:
GET /my-stopword-index/_analyze
{
  "analyzer": "my_stop_analyzer",
  "text": "A quick dog jumps over the turtle"
}

----------------------------------------

TITLE: Network Log Field Mappings JSON Configuration
DESCRIPTION: Comprehensive mapping configuration that defines the relationship between raw network log fields and their standardized ECS (Elastic Common Schema) equivalents. Includes mappings for various network protocols including firewall events, DNS, HTTP, Kerberos, and SMB file operations.

LANGUAGE: json
CODE:
 "mappings": [
    {
      "raw_field":"action",
      "ecs":"netflow.firewall_event"
    },
    {
      "raw_field":"certificate.serial",
      "ecs":"zeek.x509.certificate.serial"
    },
    {
      "raw_field":"name",
      "ecs":"zeek.smb_files.name"
    },
    {
      "raw_field":"path",
      "ecs":"zeek.smb_files.path"
    },
    {
      "raw_field":"dst_port",
      "ecs":"destination.port"
    },
    {
      "raw_field":"qtype_name",
      "ecs":"zeek.dns.qtype_name"
    },
    {
      "raw_field":"operation",
      "ecs":"zeek.dce_rpc.operation"
    },
    {
      "raw_field":"endpoint",
      "ecs":"zeek.dce_rpc.endpoint"
    },
    {
      "raw_field":"zeek.dce_rpc.endpoint",
      "ecs":"zeek.dce_rpc.endpoint"
    },
    {
      "raw_field":"answers",
      "ecs":"zeek.dns.answers"
    },
    {
      "raw_field":"query",
      "ecs":"zeek.dns.query"
    },
    {
      "raw_field":"client_header_names",
      "ecs":"zeek.http.client_header_names"
    },
    {
      "raw_field":"resp_mime_types",
      "ecs":"zeek.http.resp_mime_types"
    },
    {
      "raw_field":"cipher",
      "ecs":"zeek.kerberos.cipher"
    },
    {
      "raw_field":"request_type",
      "ecs":"zeek.kerberos.request_type"
    },
    {
      "raw_field":"creationTime",
      "ecs":"timestamp"
    },
    {
      "raw_field":"method",
      "ecs":"http.request.method"
    },
    {
      "raw_field":"id.resp_p",
      "ecs":"id.resp_p"
    },
    {
      "raw_field":"blocked",
      "ecs":"blocked-flag"
    },
    {
      "raw_field":"id.orig_h",
      "ecs":"id.orig_h"
    },
    {
      "raw_field":"Z",
      "ecs":"Z-flag"
    },
    {
      "raw_field":"id.resp_h",
      "ecs":"id.resp_h"
    },
    {
      "raw_field":"uri",
      "ecs":"url.path"
    },
    {
      "raw_field":"c-uri",
      "ecs":"url.path"
    },
    {
      "raw_field":"c-useragent",
      "ecs":"user_agent.name"
    },
    {
      "raw_field":"status_code",
      "ecs":"http.response.status_code"
    },
    {
      "raw_field":"rejected",
      "ecs":"rejected"
    },
    {
      "raw_field":"dst_ip",
      "ecs":"destination.ip"
    },
    {
      "raw_field":"src_ip",
      "ecs":"source.ip"
    },
    {
      "raw_field":"user_agent",
      "ecs":"user_agent.name"
    },
    {
      "raw_field":"request_body_len",
      "ecs":"http.request.body.bytes"
    },
    {
      "raw_field":"service",
      "ecs":"service"
    }
  ]

----------------------------------------

TITLE: Installing OpenSearch.Net via Project Configuration
DESCRIPTION: XML configuration to add OpenSearch.Net package reference to a .NET project file.

LANGUAGE: xml
CODE:
<Project>
  ...
  <ItemGroup>
    <PackageReference Include="Opensearch.Net" Version="1.0.0" />
  </ItemGroup>
</Project>

----------------------------------------

TITLE: Registering Model Group
DESCRIPTION: API request to register a new model group for organizing local models

LANGUAGE: json
CODE:
POST /_plugins/_ml/model_groups/_register
{
  "name": "local_model_group",
  "description": "A model group for local models"
}

----------------------------------------

TITLE: Analyzing event type distribution
DESCRIPTION: SQL query to count the occurrences of different action types in the ubi_events table, useful for creating visualizations.

LANGUAGE: sql
CODE:
select 
	action_name, count(0) Total  
from ubi_events
group by action_name
order by Total desc

----------------------------------------

TITLE: Configuring IAM Policy for Kafka Access in OpenSearch Migration
DESCRIPTION: This JSON policy grants permissions for coordinator nodes to publish captured traffic to Kafka. It allows connecting to the Kafka cluster and performing operations like creating topics, describing topics, and writing data.

LANGUAGE: json
CODE:
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Action": "kafka-cluster:Connect",
            "Resource": "arn:aws:kafka:<REGION>:<ACCOUNT-ID>:cluster/migration-msk-cluster-<STAGE>/*",
            "Effect": "Allow"
        },
        {
            "Action": [
                "kafka-cluster:CreateTopic",
                "kafka-cluster:DescribeTopic",
                "kafka-cluster:WriteData"
            ],
            "Resource": "arn:aws:kafka:<REGION>:<ACCOUNT-ID>:topic/migration-msk-cluster-<STAGE>/*",
            "Effect": "Allow"
        }
    ]
}

----------------------------------------

TITLE: Get Tenancy Configuration API Call
DESCRIPTION: REST API endpoint to retrieve current multi-tenancy configuration settings from OpenSearch Dashboards.

LANGUAGE: json
CODE:
GET /_plugins/_security/api/tenancy/config

----------------------------------------

TITLE: Creating New OpenSearch Keystore
DESCRIPTION: Command to initialize a new keystore. Will overwrite existing keystore if one exists.

LANGUAGE: bash
CODE:
./bin/opensearch-keystore create

----------------------------------------

TITLE: Running SearchAnomalyDetectorsTool Agent in OpenSearch
DESCRIPTION: This JSON snippet shows how to execute the registered SearchAnomalyDetectorsTool agent. It includes the agent ID and a question parameter to query for anomaly detectors.

LANGUAGE: json
CODE:
POST /_plugins/_ml/agents/EuJYYo0B9RaBCvhuy1q8/_execute
{
  "parameters": {
    "question": "Do I have any anomaly detectors?"
  }
}

----------------------------------------

TITLE: Ingesting Document with Remove Pipeline in OpenSearch
DESCRIPTION: Example of ingesting a document using the remove pipeline to exclude the IP address field.

LANGUAGE: json
CODE:
PUT testindex1/_doc/1?pipeline=remove_ip
{
  "ip_address": "203.0.113.1",
  "name": "John Doe"
}

----------------------------------------

TITLE: Basic OpenSearch Search Query
DESCRIPTION: Example of a basic search query without using the search pipeline, requesting 5 documents.

LANGUAGE: json
CODE:
POST /my_index/_search
{
  "size": 5
}

----------------------------------------

TITLE: Performing Bool Prefix Query on Search-as-you-type Field in OpenSearch
DESCRIPTION: This snippet shows how to perform a bool_prefix query using a multi-match query on a search-as-you-type field and its subfields in OpenSearch.

LANGUAGE: json
CODE:
GET books/_search
{
  "query": {
    "multi_match": {
      "query": "tw one",
      "type": "bool_prefix",
      "fields": [
        "suggestions",
        "suggestions._2gram",
        "suggestions._3gram"
      ]
    }
  }
}

----------------------------------------

TITLE: Configuring Stem Exclusion for Romanian Analyzer in OpenSearch
DESCRIPTION: This snippet shows how to create an index with a custom Romanian analyzer that includes stem exclusion for specific words.

LANGUAGE: json
CODE:
PUT index_with_stem_exclusion_romanian_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "stem_exclusion_romanian_analyzer": {
          "type": "romanian",
          "stem_exclusion": ["autoritate", "aprobat"]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Split Index API Endpoints
DESCRIPTION: Available endpoints for the Split Index API operation, supporting both POST and PUT methods.

LANGUAGE: json
CODE:
POST /<source-index>/_split/<target-index>
PUT /<source-index>/_split/<target-index>

----------------------------------------

TITLE: Cardinality Aggregation with Execution Hint
DESCRIPTION: Demonstrates how to control aggregation execution using execution_hint parameter, specifically using ordinals for field value processing.

LANGUAGE: json
CODE:
GET opensearch_dashboards_sample_data_ecommerce/_search
{
  "size": 0,
  "aggs": {
    "unique_products": {
      "cardinality": {
        "field": "products.product_id",
        "execution_hint": "ordinals"
      }
    }
  }
}

----------------------------------------

TITLE: Custom Index Settings
DESCRIPTION: Example of creating an index with custom shard and replica settings before adding documents.

LANGUAGE: json
CODE:
PUT more-movies
{ "settings": { "number_of_shards": 6, "number_of_replicas": 2 } }

----------------------------------------

TITLE: Retrieving Top N Queries - API Endpoints
DESCRIPTION: Collection of GET requests for retrieving top N query data for different metrics.

LANGUAGE: json
CODE:
GET /_insights/top_queries

LANGUAGE: json
CODE:
GET /_insights/top_queries?type=latency

LANGUAGE: json
CODE:
GET /_insights/top_queries?type=cpu

LANGUAGE: json
CODE:
GET /_insights/top_queries?type=memory

----------------------------------------

TITLE: Running Logstash with Automatic Configuration Reload
DESCRIPTION: Demonstrates the command to start Logstash with automatic configuration reloading enabled.

LANGUAGE: bash
CODE:
bin/logstash -f config/pipeline.conf --config.reload.automatic

----------------------------------------

TITLE: Ingesting Document with Join Pipeline
DESCRIPTION: Example of ingesting a document using the join pipeline to process the URI array.

LANGUAGE: json
CODE:
POST testindex1/_doc/1?pipeline=example-join-pipeline  
{  
  "uri": [  
    "app",  
    "home",  
    "overview"
  ]  
}

----------------------------------------

TITLE: Advanced Function Usage in OpenSearch SQL
DESCRIPTION: Examples of using advanced functions in OpenSearch SQL queries. These functions provide conditional logic and null-checking capabilities.

LANGUAGE: SQL
CODE:
SELECT if(false, 0, 1),if(true, 0, 1)
SELECT ifnull(0, 1), ifnull(null, 1)
SELECT isnull(null), isnull(1)

----------------------------------------

TITLE: Configuring Compatibility Mode in opensearch.yml
DESCRIPTION: This YAML snippet demonstrates how to enable the compatibility mode by adding a configuration line to the opensearch.yml file. This setting makes OpenSearch return version 7.10.2 instead of its actual version.

LANGUAGE: yml
CODE:
compatibility.override_main_response_version: true

----------------------------------------

TITLE: Sample Log Entry for Grok Parsing
DESCRIPTION: Example of a raw log entry that will be parsed using the Grok filter.

LANGUAGE: bash
CODE:
184.252.108.229 - joe [20/Sep/2017:13:22:22 +0200] GET /products/view/123 200 12798

----------------------------------------

TITLE: Configuring Basic Trace Analytics Pipeline in YAML
DESCRIPTION: Example configuration showing the setup of entry-pipeline, raw-pipeline, and service-map-pipeline for trace analytics in Data Prepper.

LANGUAGE: yaml
CODE:
entry-pipeline:
  delay: "100"
  source:
    otel_traces_source:
      ssl: false
  buffer:
    bounded_blocking:
      buffer_size: 10240
      batch_size: 160
  sink:
    - pipeline:
        name: "raw-trace-pipeline"
    - pipeline:
        name: "service-map-pipeline"
raw-pipeline:
  source:
    pipeline:
      name: "entry-pipeline"
  buffer:
    bounded_blocking:
      buffer_size: 10240
      batch_size: 160
  processor:
    - otel_traces_raw:
  sink:
    - opensearch:
        hosts: ["https://localhost:9200"]
        insecure: true
        username: admin
        password: admin
        index_type: trace-analytics-raw
service-map-pipeline:
  delay: "100"
  source:
    pipeline:
      name: "entry-pipeline"
  buffer:
    bounded_blocking:
      buffer_size: 10240
      batch_size: 160
  processor:
    - service_map_stateful:
  sink:
    - opensearch:
        hosts: ["https://localhost:9200"]
        insecure: true
        username: admin
        password: admin
        index_type: trace-analytics-service-map

----------------------------------------

TITLE: Example test procedure in _test-procedures/searchable_snapshots.json
DESCRIPTION: Demonstrates a test procedure for searchable snapshots from the nyc_taxis workload. This procedure includes steps for index creation, data ingestion, snapshot creation, and various search operations.

LANGUAGE: json
CODE:
{
      "name": "searchable-snapshot",
      "description": "Measuring performance for Searchable Snapshot feature. Based on the default test procedure 'append-no-conflicts'.",
      "schedule": [
        {
          "operation": "delete-index"
        },
        {
          "operation": {
            "operation-type": "create-index",
            "settings": {% raw %}{%- if index_settings is defined %} {{ index_settings | tojson }} {%- else %}{
              "index.codec": "best_compression",
              "index.refresh_interval": "30s",
              "index.translog.flush_threshold_size": "4g"
            }{%- endif %}{% endraw %}
          }
        },
        {
          "name": "check-cluster-health",
          "operation": {
            "operation-type": "cluster-health",
            "index": "nyc_taxis",
            "request-params": {
              "wait_for_status": {% raw %}"{{ cluster_health | default('green') }}",
              "wait_for_no_relocating_shards": "true"
            },
            "retry-until-success": true
          }
        },
        {
          "operation": "index",
          "warmup-time-period": 240,
          "clients": {{ bulk_indexing_clients | default(8) }},
          "ignore-response-error-level": "{{ error_level | default('non-fatal') }}"{% endraw %}
        },
        {
          "name": "refresh-after-index",
          "operation": "refresh"
        },
        {
          "operation": {
            "operation-type": "force-merge",
            "request-timeout": 7200
            {% raw %}{%- if force_merge_max_num_segments is defined %}{% endraw %},
            "max-num-segments": {% raw %}{{ force_merge_max_num_segments | tojson }}{% endraw %}
            {% raw %}{%- endif %}{% endraw %}
          }
        },
        {
          "name": "refresh-after-force-merge",
          "operation": "refresh"
        },
        {
          "operation": "wait-until-merges-finish"
        },
        {
          "operation": "create-snapshot-repository"
        },
        {
          "operation": "delete-snapshot"
        },
        {
          "operation": "create-snapshot"
        },
        {
          "operation": "wait-for-snapshot-creation"
        },
        {
          "operation": {
            "name": "delete-local-index",
            "operation-type": "delete-index"
          }
        },
        {
          "operation": "restore-snapshot"
        },
        {
          "operation": "default",
          "warmup-iterations": 50,
          "iterations": 100
          {% raw %}{%- if not target_throughput %}{% endraw %}
          ,"target-throughput": 3
          {% raw %}{%- elif target_throughput is string and target_throughput.lower() == 'none' %}{% endraw %}
          {% raw %}{%- else %}{% endraw %}
          ,"target-throughput": {% raw %}{{ target_throughput | tojson }}{% endraw %}
          {% raw %}{%- endif %}{% endraw %}
          {% raw %}{%-if search_clients is defined and search_clients %}{% endraw %}
          ,"clients": {% raw %}{{ search_clients | tojson}}{% endraw %}
          {% raw %}{%- endif %}{% endraw %}
        },
        {
          "operation": "range",
          "warmup-iterations": 50,
          "iterations": 100
          {% raw %}{%- if not target_throughput %}{% endraw %}
          ,"target-throughput": 0.7
          {% raw %}{%- elif target_throughput is string and target_throughput.lower() == 'none' %}{% endraw %}
          {% raw %}{%- else %}{% endraw %}
          ,"target-throughput": {% raw %}{{ target_throughput | tojson }}{% endraw %}
          {% raw %}{%- endif %}{% endraw %}
          {% raw %}{%-if search_clients is defined and search_clients %}{% endraw %}
          ,"clients": {% raw %}{{ search_clients | tojson}}{% endraw %}
          {% raw %}{%- endif %}{% endraw %}
        }
      ]
    }

----------------------------------------

TITLE: Example Response for Model Search in OpenSearch
DESCRIPTION: This snippet shows an example response from a model search query. It includes metadata about the search and the matching model documents with their details.

LANGUAGE: json
CODE:
{
    "took" : 8,
    "timed_out" : false,
    "_shards" : {
      "total" : 1,
      "successful" : 1,
      "skipped" : 0,
      "failed" : 0
    },
    "hits" : {
      "total" : {
        "value" : 2,
        "relation" : "eq"
      },
      "max_score" : 2.4159138,
      "hits" : [
        {
          "_index" : ".plugins-ml-model",
          "_id" : "-QkKJX8BvytMh9aUeuLD",
          "_version" : 1,
          "_seq_no" : 12,
          "_primary_term" : 15,
          "_score" : 2.4159138,
          "_source" : {
            "name" : "FIT_RCF",
            "version" : 1,
            "content" : "xxx",
            "algorithm" : "FIT_RCF"
          }
        },
        {
          "_index" : ".plugins-ml-model",
          "_id" : "OxkvHn8BNJ65KnIpck8x",
          "_version" : 1,
          "_seq_no" : 2,
          "_primary_term" : 8,
          "_score" : 2.4159138,
          "_source" : {
            "name" : "FIT_RCF",
            "version" : 1,
            "content" : "xxx",
            "algorithm" : "FIT_RCF"
          }
        }
      ]
    }
  }

----------------------------------------

TITLE: Configuring k-NN Vector for Painless Scripting in OpenSearch
DESCRIPTION: This example demonstrates how to configure a k-NN vector field for use with Painless scripting or k-NN score script, specifying only the dimension.

LANGUAGE: json
CODE:
"my_vector": {
   "type": "knn_vector",
   "dimension": 128
 }

----------------------------------------

TITLE: Markdown Warning Block with GitHub Issue Reference
DESCRIPTION: A formatted warning block that informs users about the experimental nature of the feature and directs them to a GitHub issue for updates and feedback.

LANGUAGE: markdown
CODE:
This is an experimental feature and is not recommended for use in a production environment. For updates on the progress of the feature or if you want to leave feedback, see the associated [GitHub issue](https://example.issue.link).    
{: .warning}

----------------------------------------

TITLE: OpenSearch Dashboards OpenID Connection URL Configuration
DESCRIPTION: Configuration setting for specifying the IdP metadata endpoint URL in OpenSearch Dashboards.

LANGUAGE: yaml
CODE:
plugins.security.openid.connect_url: "http://keycloak.example.com:8080/auth/realms/master/.well-known/openid-configuration"

----------------------------------------

TITLE: Creating Connector with Execute Action in OpenSearch
DESCRIPTION: JSON request for creating a connector with an execute action to interface with AWS Lambda. Includes configuration for AWS credentials, region, and Lambda function URL.

LANGUAGE: json
CODE:
POST _plugins/_ml/connectors/_create
{
  "name": "Lambda connector of simple calculator",
  "description": "Demo connector of lambda function",
  "version": 1,
  "protocol": "aws_sigv4",
  "parameters": {
    "region": "YOUR AWS REGION",
    "service_name": "lambda"
  },
  "credential": {
    "access_key": "YOUR ACCESS KEY",
    "secret_key": "YOUR SECRET KEY",
    "session_token": "YOUR SESSION TOKEN"
  },
  "actions": [
    {
      "action_type": "execute",
      "method": "POST",
      "url": "YOUR LAMBDA FUNCTION URL",
      "headers": {
        "content-type": "application/json"
      },
      "request_body": "{ \"number1\":\"${parameters.number1}\", \"number2\":\"${parameters.number2}\" }"
    }
  ]
}

----------------------------------------

TITLE: Creating an Index with German Normalization Filter in OpenSearch
DESCRIPTION: This example creates a new index named 'german_normalizer_example' and configures an analyzer with a 'german_normalization' filter. It demonstrates how to set up custom analysis settings in OpenSearch.

LANGUAGE: json
CODE:
PUT /german_normalizer_example
{
  "settings": {
    "analysis": {
      "filter": {
        "german_normalizer": {
          "type": "german_normalization"
        }
      },
      "analyzer": {
        "german_normalizer_analyzer": {
          "tokenizer": "standard",
          "filter": [
            "lowercase", 
            "german_normalizer"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Search Model Groups by ID
DESCRIPTION: Example request showing how to search for model groups using specific model group IDs.

LANGUAGE: json
CODE:
{
  "query": {
    "bool": {
      "must": [
        {
          "terms": {
            "_id": [
              "HyPNK4gBwNxGowI0AtDk"
            ]
          }
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Defining Gsub Processor Syntax in JSON
DESCRIPTION: Shows the basic JSON syntax for defining a gsub processor in an OpenSearch pipeline. It specifies the field to process, the regex pattern to match, and the replacement string.

LANGUAGE: json
CODE:
"gsub": {
  "field": "field_name",
  "pattern": "regex_pattern",
  "replacement": "replacement_string"
}

----------------------------------------

TITLE: Delete Snapshot Repository Response - JSON
DESCRIPTION: Example response showing a successful deletion of a snapshot repository configuration.

LANGUAGE: json
CODE:
{
  "acknowledged" : true
}

----------------------------------------

TITLE: Performing Geohash Grid Aggregation on Geopoint Field in OpenSearch
DESCRIPTION: This snippet demonstrates how to perform a geohash grid aggregation on a geopoint field in OpenSearch. It uses the sample web logs data and sets a precision of 4 for the aggregation.

LANGUAGE: json
CODE:
GET opensearch_dashboards_sample_data_logs/_search
{
  "size": 0,
  "aggs": {
    "geo_hash": {
      "geohash_grid": {
        "field": "geo.coordinates",
        "precision": 4
      }
    }
  }
}

----------------------------------------

TITLE: Delete Workflow Endpoint
DESCRIPTION: The base endpoint for deleting a workflow template by its ID.

LANGUAGE: json
CODE:
DELETE /_plugins/_flow_framework/workflow/<workflow_id>

----------------------------------------

TITLE: Installing OpenSSL on macOS
DESCRIPTION: Command to install OpenSSL on macOS using Homebrew package manager.

LANGUAGE: bash
CODE:
brew install openssl

----------------------------------------

TITLE: Defining REST Endpoint in Java
DESCRIPTION: Code example showing how to configure a plugin's API endpoint by extending BaseRestHandler and defining the watch index URI.

LANGUAGE: java
CODE:
public class SampleExtensionRestHandler extends BaseRestHandler {
    public static final String WATCH_INDEX_URI = "/_plugins/scheduler_sample/watch";

----------------------------------------

TITLE: Sample Response for Retrieving Search Pipelines in OpenSearch
DESCRIPTION: This JSON response shows the structure of a retrieved search pipeline named 'my_pipeline'. It includes a request processor with a filter query that restricts results to publicly visible documents.

LANGUAGE: json
CODE:
{
  "my_pipeline" : {
    "request_processors" : [
      {
        "filter_query" : {
          "tag" : "tag1",
          "description" : "This processor is going to restrict to publicly visible documents",
          "query" : {
            "term" : {
              "visibility" : "public"
            }
          }
        }
      }
    ]
  }
}

----------------------------------------

TITLE: Creating Ingest Pipeline with Sparse Encoding
DESCRIPTION: Example of creating an ingest pipeline that uses the sparse_encoding processor with pruning configuration to convert text into embeddings.

LANGUAGE: json
CODE:
{
  "description": "A sparse encoding ingest pipeline",
  "processors": [
    {
      "sparse_encoding": {
        "model_id": "aP2Q8ooBpBj3wT4HVS8a",
        "prune_type": "max_ratio",
        "prune_ratio": 0.1,
        "field_map": {
          "passage_text": "passage_embedding"
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Indexing Child Documents in OpenSearch
DESCRIPTION: Examples of indexing child documents with routing parameter and parent reference.

LANGUAGE: json
CODE:
PUT testindex1/_doc/3?routing=1
{
  "name": "Product 1",
  "product_to_brand": {
    "name": "product", 
    "parent": "1" 
  }
}

LANGUAGE: json
CODE:
PUT testindex1/_doc/4?routing=1
{
  "name": "Product 2",
  "product_to_brand": {
    "name": "product", 
    "parent": "1" 
  }
}

----------------------------------------

TITLE: Missing Aggregation Response Example in OpenSearch
DESCRIPTION: Example response showing the aggregation results including the missing value bucket. Shows document counts for different response codes and the 'N/A' bucket.

LANGUAGE: json
CODE:
{
"aggregations": {
  "response_codes": {
    "doc_count_error_upper_bound": 0,
    "sum_other_doc_count": 0,
    "buckets": [
      {
        "key": "200",
        "doc_count": 12832
      },
      {
        "key": "404",
        "doc_count": 801
      },
      {
        "key": "503",
        "doc_count": 441
      },
      {
        "key": "N/A",
        "doc_count": 0
      }
    ]
  }
}
}

----------------------------------------

TITLE: Querying Rank Features Field in OpenSearch
DESCRIPTION: This snippet shows how to query documents using a rank feature query on a specific feature within a rank_features field in OpenSearch. It demonstrates querying the 'teens' feature.

LANGUAGE: json
CODE:
GET testindex1/_search
{
  "query": {
    "rank_feature": {
      "field": "correlations.teens"
    }
  }
}

----------------------------------------

TITLE: Endpoints for CAT Count API
DESCRIPTION: The available REST endpoints for accessing the CAT count functionality. Supports querying all indices or specific indices.

LANGUAGE: json
CODE:
GET /_cat/count
GET /_cat/count/{index}

----------------------------------------

TITLE: OpenSearch OpenID Authentication Domain Configuration
DESCRIPTION: Complete OpenID authentication domain configuration for OpenSearch including connection URL and authentication settings.

LANGUAGE: yaml
CODE:
openid_auth_domain:
  enabled: true
  order: 1
  http_authenticator:
    type: "openid"
    ...
    config:
      openid_connect_url: http://keycloak.examplesss.com:8080/auth/realms/master/.well-known/openid-configuration
    ...

----------------------------------------

TITLE: Creating a Lowercase Pipeline in OpenSearch
DESCRIPTION: Shows how to create an ingest pipeline named 'lowercase-title' that uses the lowercase processor to convert the 'title' field to lowercase.

LANGUAGE: json
CODE:
PUT _ingest/pipeline/lowercase-title
{
  "description" : "Pipeline that lowercases the title field",
  "processors" : [
    {
      "lowercase" : {
        "field" : "title"
      }
    }
  ]
}

----------------------------------------

TITLE: Ingesting Document with Drop Pipeline
DESCRIPTION: Example of ingesting a document using a pipeline with drop processor.

LANGUAGE: json
CODE:
{
  "user_info": "Sensitive information including credit card"
}

----------------------------------------

TITLE: Analyzer Response Example
DESCRIPTION: Shows the response from the analyze API, displaying the generated tokens after processing with the apostrophe filter. Demonstrates how apostrophes and following characters are removed.

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "john",
      "start_offset": 0,
      "end_offset": 6,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "car",
      "start_offset": 7,
      "end_offset": 10,
      "type": "<ALPHANUM>",
      "position": 1
    },
    {
      "token": "is",
      "start_offset": 11,
      "end_offset": 13,
      "type": "<ALPHANUM>",
      "position": 2
    },
    {
      "token": "faster",
      "start_offset": 14,
      "end_offset": 20,
      "type": "<ALPHANUM>",
      "position": 3
    },
    {
      "token": "than",
      "start_offset": 21,
      "end_offset": 25,
      "type": "<ALPHANUM>",
      "position": 4
    },
    {
      "token": "peter",
      "start_offset": 26,
      "end_offset": 33,
      "type": "<ALPHANUM>",
      "position": 5
    },
    {
      "token": "bike",
      "start_offset": 34,
      "end_offset": 38,
      "type": "<ALPHANUM>",
      "position": 6
    }
  ]
}

----------------------------------------

TITLE: Analyzing Text with Unique Token Filter in OpenSearch
DESCRIPTION: This example shows how to use the _analyze API to test the unique_analyzer created in the previous example. It demonstrates the effect of the unique token filter on a sample text containing duplicate words.

LANGUAGE: json
CODE:
GET /unique_example/_analyze
{
  "analyzer": "unique_analyzer",
  "text": "OpenSearch OpenSearch is powerful powerful and scalable"
}

----------------------------------------

TITLE: Example Hot Threads Request
DESCRIPTION: Sample request to retrieve hot threads information from all cluster nodes.

LANGUAGE: json
CODE:
GET /_nodes/hot_threads

----------------------------------------

TITLE: Creating Test Index on Leader Cluster in OpenSearch
DESCRIPTION: This curl command creates a test index on the leader cluster to demonstrate the auto-follow functionality. It creates an index named 'movies-0001' which matches the pattern specified in the replication rule.

LANGUAGE: bash
CODE:
curl -XPUT -k -H 'Content-Type: application/json' -u 'admin:<custom-admin-password>' 'https://localhost:9201/movies-0001?pretty'

----------------------------------------

TITLE: Registering Flow Agent with MLModelTool in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a flow agent that uses the MLModelTool. It requires the model ID obtained from the model registration response and includes a prompt template for the language model.

LANGUAGE: json
CODE:
POST /_plugins/_ml/agents/_register
{
  "name": "Test agent for embedding model",
  "type": "flow",
  "description": "this is a test agent",
  "tools": [
    {
      "type": "MLModelTool",
      "description": "A general tool to answer any question",
      "parameters": {
        "model_id": "h5AUWo0BkIylWTeYT4SU",
        "prompt": "\n\nHuman:You are a professional data analyst. You will always answer question based on the given context first. If the answer is not directly shown in the context, you will analyze the data and find the answer. If you don't know the answer, just say don't know. \n\nHuman:${parameters.question}\n\nAssistant:"
      }
    }
  ]
}

----------------------------------------

TITLE: Example Deprovision Workflow Request
DESCRIPTION: Sample request showing how to deprovision a workflow using a specific workflow ID.

LANGUAGE: json
CODE:
POST /_plugins/_flow_framework/workflow/8xL8bowB8y25Tqfenm50/_deprovision

----------------------------------------

TITLE: Opening iODBC Administrator on macOS
DESCRIPTION: Command to open the iODBC Administrator with sudo privileges on macOS for configuring the driver and DSN.

LANGUAGE: bash
CODE:
sudo /Applications/iODBC/iODBC\ Administrator64.app/Contents/MacOS/iODBC\ Administrator64

----------------------------------------

TITLE: Using Stem Exclusion with Swedish Analyzer in OpenSearch
DESCRIPTION: This example shows how to create an index with a custom Swedish analyzer that includes stem exclusion. It defines a 'stem_exclusion_swedish_analyzer' with specific words excluded from stemming.

LANGUAGE: json
CODE:
PUT index_with_stem_exclusion_swedish_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "stem_exclusion_swedish_analyzer": {
          "type": "swedish",
          "stem_exclusion": ["myndighet", "godknnande"]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating a Memory in OpenSearch ML Commons API (JSON)
DESCRIPTION: This snippet demonstrates how to create a new memory for conversational search using a POST request to the ML Commons API in OpenSearch.

LANGUAGE: json
CODE:
POST /_plugins/_ml/memory/
{
  "name": "Conversation for a RAG pipeline"
}

----------------------------------------

TITLE: Creating Legacy Index Template with ISM Policy in OpenSearch
DESCRIPTION: JSON configuration for creating an index template that automatically applies an ISM policy to matching indexes using the deprecated method. This approach uses the opendistro.index_state_management.policy_id setting.

LANGUAGE: json
CODE:
PUT _index_template/<template_name>
{
  "index_patterns": [
    "index_name-*"
  ],
  "template": {
    "settings": {
      "opendistro.index_state_management.policy_id": "policy_id"
    }
  }
}

----------------------------------------

TITLE: Creating Read Access Role for OpenSearch Observability
DESCRIPTION: Creates a basic read-only access role for Observability features that allows users to get/view Observability resources.

LANGUAGE: json
CODE:
PUT _plugins/_security/api/roles/observability_read_access
{
  "cluster_permissions": [
    "cluster:admin/opensearch/observability/get"
  ]
}

----------------------------------------

TITLE: Configuring Logstash Pipeline for HTTP Input
DESCRIPTION: Demonstrates a Logstash pipeline configuration that accepts HTTP input on localhost:8080 and writes output to a file.

LANGUAGE: yaml
CODE:
input {
  http {
    host => "127.0.0.1"
    port => 8080
  }
}

output {
  file {
    path => "output.txt"
  }
}

----------------------------------------

TITLE: Retrieving Processed Document in OpenSearch
DESCRIPTION: Shows how to retrieve the document that was processed by the gsub pipeline. This query fetches the document with ID 1 from the 'logs' index to verify the changes made by the processor.

LANGUAGE: json
CODE:
GET logs/_doc/1

----------------------------------------

TITLE: Verifying OpenSearch cluster setup
DESCRIPTION: Commands to check if the OpenSearch containers are running and to query the cluster's REST API.

LANGUAGE: bash
CODE:
docker container ls

LANGUAGE: bash
CODE:
curl -s "https://localhost:9201" -ku admin:<custom-admin-password>

----------------------------------------

TITLE: Configuring Basic Grok Processor in OpenSearch Data Prepper Pipeline
DESCRIPTION: This snippet shows a basic configuration for the grok processor in an OpenSearch Data Prepper pipeline. It matches IP addresses, timestamps, and response statuses in log messages.

LANGUAGE: json
CODE:
patten-matching-pipeline:
  source
    ...
  processor:
    - grok:
        match:
          message: ['%{IPORHOST:clientip} \[%{HTTPDATE:timestamp}\] %{NUMBER:response_status:int}']
  sink:
    - opensearch:
        # Provide an OpenSearch cluster endpoint

----------------------------------------

TITLE: Deleting Specific Indices in YAML for OpenSearch Benchmark
DESCRIPTION: Sets up a delete-index operation to remove all indices matching the pattern 'logs-*'. It includes various request parameters to control the deletion behavior and handle potential errors.

LANGUAGE: yaml
CODE:
{
  "name": "delete-logs",
  "operation-type": "delete-index",
  "index": "logs-*",
  "only-if-exists": false,
  "request-params": {
    "expand_wildcards": "all",
    "allow_no_indices": "true",
    "ignore_unavailable": "true"
  }
}

----------------------------------------

TITLE: Configuring k-NN Vector with Model ID in OpenSearch
DESCRIPTION: This example shows how to configure a k-NN vector field using a model ID for algorithms requiring a training step.

LANGUAGE: json
CODE:
"my_vector": {
  "type": "knn_vector",
  "model_id": "my-model"
}

----------------------------------------

TITLE: Searching Normalized Field - Basic Query
DESCRIPTION: Demonstrates a term query searching for an exact match in the normalized field.

LANGUAGE: json
CODE:
GET /sample-index/_search
{
  "query": {
    "term": {
      "approach": "naive"
    }
  }
}

----------------------------------------

TITLE: Analyzing Text with Stemmer Filter in OpenSearch
DESCRIPTION: Example request to analyze text using the custom stemmer analyzer, demonstrating how words are reduced to their root form. The example shows how 'running' and 'runs' are both stemmed to 'run'.

LANGUAGE: json
CODE:
GET /my-stemmer-index/_analyze
{
  "analyzer": "my_stemmer_analyzer",
  "text": "running runs"
}

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "run",
      "start_offset": 0,
      "end_offset": 7,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "run",
      "start_offset": 8,
      "end_offset": 12,
      "type": "<ALPHANUM>",
      "position": 1
    }
  ]
}

----------------------------------------

TITLE: Deleting a Model Group with ML Commons API in OpenSearch
DESCRIPTION: This API call deletes a specific model group identified by its ID. The model group must not contain any model versions for the deletion to be successful. The request is a DELETE operation to the _plugins/_ml/model_groups endpoint.

LANGUAGE: json
CODE:
DELETE _plugins/_ml/model_groups/<model_group_id>

----------------------------------------

TITLE: Defining and using derived object fields
DESCRIPTION: Creates an index with a derived object field and demonstrates how to search and highlight its subfields.

LANGUAGE: json
CODE:
PUT logs_object
{
  "mappings": {
    "properties": {
      "request_object": { "type": "text" }
    },
    "derived": {
      "derived_request_object": {
        "type": "object",
        "script": {
          "source": "emit(params._source[\"request_object\"])"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Defining and using derived object fields
DESCRIPTION: Creates an index with a derived object field and demonstrates how to search and highlight its subfields.

LANGUAGE: json
CODE:
PUT logs_object
{
  "mappings": {
    "properties": {
      "request_object": { "type": "text" }
    },
    "derived": {
      "derived_request_object": {
        "type": "object",
        "script": {
          "source": "emit(params._source[\"request_object\"])"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Comparing Benchmark Tests in OpenSearch Benchmark
DESCRIPTION: This command compares two benchmark tests using their TestExecution IDs, with one set as the baseline and the other as the contender.

LANGUAGE: bash
CODE:
opensearch-benchmark compare --baseline=417ed42-6671-9i79-11a1-e367636068ce --contender=beb154e4-0a05-4f45-ad9f-e34f9a9e51f7

----------------------------------------

TITLE: Adding Custom Certificates to OpenSearch Docker Image
DESCRIPTION: A Dockerfile example showing how to add custom certificates for use with the Security plugin in the OpenSearch Docker image.

LANGUAGE: Dockerfile
CODE:
FROM opensearchproject/opensearch:latest
COPY --chown=opensearch:opensearch opensearch.yml /usr/share/opensearch/config/
COPY --chown=opensearch:opensearch my-key-file.pem /usr/share/opensearch/config/
COPY --chown=opensearch:opensearch my-certificate-chain.pem /usr/share/opensearch/config/
COPY --chown=opensearch:opensearch my-root-cas.pem /usr/share/opensearch/config/

----------------------------------------

TITLE: Creating an Index with Geo Shape Mapping in OpenSearch
DESCRIPTION: This snippet shows how to create an index named 'national_parks' with a 'location' field mapped as a geo_shape type in OpenSearch.

LANGUAGE: json
CODE:
PUT national_parks
{
  "mappings": {
    "properties": {
      "location": {
        "type": "geo_shape"
      }
    }
  }
}

----------------------------------------

TITLE: Performing a Search Operation in YAML for OpenSearch Benchmark
DESCRIPTION: Defines a search operation that performs a match_all query. It includes request parameters to control the returned fields and wildcard analysis. This operation is used to benchmark search performance.

LANGUAGE: yaml
CODE:
{
  "name": "default",
  "operation-type": "search",
  "body": {
    "query": {
      "match_all": {}
    }
  },
  "request-params": {
    "_source_include": "some_field",
    "analyze_wildcard": "false"
  }
}

----------------------------------------

TITLE: Creating Index with Hyphenation Decompounder Filter in OpenSearch
DESCRIPTION: Example of creating a new index with a custom analyzer that includes the hyphenation_decompounder filter. The filter is configured with hyphenation patterns and a word list for decomposing compound words.

LANGUAGE: json
CODE:
PUT /test_index
{
  "settings": {
    "analysis": {
      "filter": {
        "my_hyphenation_decompounder": {
          "type": "hyphenation_decompounder",
          "hyphenation_patterns_path": "analysis/hyphenation_patterns.xml",
          "word_list": ["notebook", "note", "book"],
          "min_subword_size": 3,
          "min_word_size": 5,
          "only_longest_match": false
        }
      },
      "analyzer": {
        "my_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "my_hyphenation_decompounder"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Deleting a Specific Ingest Pipeline in OpenSearch
DESCRIPTION: This API request deletes a specific ingest pipeline in OpenSearch. The pipeline ID is passed as a parameter in the URL path.

LANGUAGE: json
CODE:
DELETE /_ingest/pipeline/<pipeline-id>

----------------------------------------

TITLE: Text Embedding Processor Basic Syntax
DESCRIPTION: Basic syntax structure for configuring the text_embedding processor, showing the required model_id and field_map parameters.

LANGUAGE: json
CODE:
{
  "text_embedding": {
    "model_id": "<model_id>",
    "field_map": {
      "<input_field>": "<vector_field>"
    }
  }
}

----------------------------------------

TITLE: Bounded Geohex Grid Query
DESCRIPTION: Shows a geohex grid aggregation using the bounds parameter with WKT point format.

LANGUAGE: json
CODE:
{
  "size": 0,
  "aggregations": {
    "grouped": {
      "geohex_grid": {
        "field": "location",
        "precision": 6,
        "bounds": {
            "top_left": "POINT (-120 38)",
            "bottom_right": "POINT (-116 36)"
        }
      }
    }
  }
}

----------------------------------------

TITLE: AWS Extension Configuration Example
DESCRIPTION: Complete example of AWS extension configuration including multiple secret configurations with region and role specifications.

LANGUAGE: json
CODE:
extensions:
  aws:
    secrets:
      host-secret-config:
        secret_id: <YOUR_SECRET_ID_1>
        region: <YOUR_REGION_1>
        sts_role_arn: <YOUR_STS_ROLE_ARN_1>
        refresh_interval: <YOUR_REFRESH_INTERVAL_1>
      credential-secret-config:
        secret_id: <YOUR_SECRET_ID_2>
        region: <YOUR_REGION_2>
        sts_role_arn: <YOUR_STS_ROLE_ARN_2>
        refresh_interval: <YOUR_REFRESH_INTERVAL_2>

----------------------------------------

TITLE: Setting Custom Admin Password in Windows Command Prompt
DESCRIPTION: This command sets a custom admin password for OpenSearch using an environment variable in the Windows Command Prompt.

LANGUAGE: batch
CODE:
> set OPENSEARCH_INITIAL_ADMIN_PASSWORD=<custom-admin-password>

----------------------------------------

TITLE: Creating an Index with Synonym Graph Filter (WordNet Format)
DESCRIPTION: This example demonstrates how to create a new index named 'my-wordnet-index' with a custom analyzer that includes a synonym_graph filter using the WordNet format for synonym rules.

LANGUAGE: json
CODE:
PUT /my-wordnet-index
{
  "settings": {
    "analysis": {
      "filter": {
        "my_synonym_graph_filter": {
          "type": "synonym_graph",
          "format": "wordnet",
          "synonyms": [
            "s(100000001, 1, 'sports car', n, 1, 0).",
            "s(100000001, 2, 'race car', n, 1, 0).",
            "s(100000001, 3, 'fast car', n, 1, 0).",
            "s(100000001, 4, 'speedy vehicle', n, 1, 0)."
          ]
        }
      },
      "analyzer": {
        "my_synonym_graph_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "my_synonym_graph_filter"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Converting file to base64 using Node.js
DESCRIPTION: TypeScript code to read a file and convert it to base64 encoding using Node.js.

LANGUAGE: typescript
CODE:
import * as fs from "node:fs/promises";
import path from "node:path";

const filePath = path.join(import.meta.dirname, "lorem.rtf");
const base64File = await fs.readFile(filePath, { encoding: "base64" });

console.log(base64File);

----------------------------------------

TITLE: Retrieving Processed Document
DESCRIPTION: Query to retrieve the document after processing with remove_by_pattern pipeline.

LANGUAGE: json
CODE:
GET testindex1/_doc/1

----------------------------------------

TITLE: Keyword Tokenizer with Pattern Replace Filter
DESCRIPTION: Shows how to combine the keyword tokenizer with a pattern_replace filter to remove non-alphanumeric characters from the input text.

LANGUAGE: json
CODE:
POST _analyze
{
  "tokenizer": "keyword",
  "filter": [
    {
      "type": "pattern_replace",
      "pattern": "[^a-zA-Z0-9]",
      "replacement": ""
    }
  ],
  "text": "Product#1234-XYZ"
}

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "Product1234XYZ",
      "start_offset": 0,
      "end_offset": 16,
      "type": "word",
      "position": 0
    }
  ]
}

----------------------------------------

TITLE: Retrieving All Search Pipelines in OpenSearch
DESCRIPTION: This GET request retrieves all search pipelines using the Search Pipeline API. It returns details of all existing pipelines in the system.

LANGUAGE: json
CODE:
GET /_search/pipeline

----------------------------------------

TITLE: Response from Keyword Analyzer in OpenSearch
DESCRIPTION: This snippet shows the response received when analyzing text with the keyword analyzer. It demonstrates that the entire input text is treated as a single token, with start and end offsets, type, and position information.

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "Just one token",
      "start_offset": 0,
      "end_offset": 14,
      "type": "word",
      "position": 0
    }
  ]
}

----------------------------------------

TITLE: Index Configuration with Custom Analyzer
DESCRIPTION: Complete index configuration example showing mappings and settings for using delimited term frequency with custom analyzers and scripts.

LANGUAGE: json
CODE:
{
  "settings": {
    "number_of_shards": 1,
    "analysis": {
      "tokenizer": {
        "keyword_tokenizer": {
          "type": "keyword"
        }
      },
      "filter": {
        "my_delimited_term_freq": {
          "type": "delimited_term_freq",
          "delimiter": "^"
        }
      },
      "analyzer": {
        "custom_delimited_analyzer": {
          "tokenizer": "keyword_tokenizer",
          "filter": ["my_delimited_term_freq"]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "f1": {
        "type": "keyword"
      },
      "f2": {
        "type": "text",
        "analyzer": "custom_delimited_analyzer",
        "index_options": "freqs"
      }
    }
  }
}

----------------------------------------

TITLE: Custom HTML Strip Analyzer Configuration in OpenSearch
DESCRIPTION: Creates a custom analyzer that removes HTML tags from text before tokenization using the html_strip character filter, whitespace tokenizer, and lowercase token filter.

LANGUAGE: json
CODE:
PUT simple_html_strip_analyzer_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "html_strip_analyzer": {
          "type": "custom",
          "char_filter": ["html_strip"],
          "tokenizer": "whitespace",
          "filter": ["lowercase"]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating Copy Pipeline
DESCRIPTION: Example of creating a pipeline named 'copy_object' that copies a nested object from message.content to the root level content field.

LANGUAGE: json
CODE:
{
  "description": "Pipeline that copies object.",
  "processors": [
    {
      "copy": {
        "source_field": "message.content", 
        "target_field":"content",
        "ignore_missing": true,
        "override_target": true,
        "remove_source": true
      }
    }
  ]
}

----------------------------------------

TITLE: Querying Hidden Alerting Indexes in OpenSearch
DESCRIPTION: API request to list all indices including hidden ones, which helps view alerting-related system indexes.

LANGUAGE: json
CODE:
GET _cat/indices?expand_wildcards=open,hidden

----------------------------------------

TITLE: Mapping Nested Type in OpenSearch
DESCRIPTION: Example of creating an index mapping with a nested type field 'pages'. This ensures that sub-documents are indexed separately, allowing for more accurate querying of nested objects.

LANGUAGE: json
CODE:
PUT logs
{
  "mappings": {
    "properties": {
      "pages": {
        "type": "nested",
        "properties": {
          "page": { "type": "text" },
          "load_time": { "type": "double" }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Galician Analyzer with Stem Exclusion
DESCRIPTION: Configuration for creating a Galician analyzer with specific terms excluded from stemming process.

LANGUAGE: json
CODE:
PUT index_with_stem_exclusion_galician_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "stem_exclusion_galician_analyzer": {
          "type": "galician",
          "stem_exclusion": ["autoridade", "aceptacin"]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Duplicate Saved Objects API Endpoint
DESCRIPTION: API endpoint to copy saved objects between workspaces with optional deep reference copying.

LANGUAGE: json
CODE:
POST <osd host>:<port>/api/workspaces/_duplicate_saved_objects

----------------------------------------

TITLE: Enabling Features in JVM Options
DESCRIPTION: Configure experimental features by adding JVM parameters to config/jvm.options file.

LANGUAGE: bash
CODE:
-Dopensearch.experimental.feature.<feature_name>.enabled=true

----------------------------------------

TITLE: Creating YUM Repository for OpenSearch
DESCRIPTION: Create a local YUM repository file for OpenSearch installation.

LANGUAGE: bash
CODE:
sudo curl -SL https://artifacts.opensearch.org/releases/bundle/opensearch/{{major_version_mask}}/opensearch-{{major_version_mask}}.repo -o /etc/yum.repos.d/opensearch-{{major_version_mask}}.repo

----------------------------------------

TITLE: Legacy Role Mapping Configuration in YAML
DESCRIPTION: Example showing how to map users to roles using the legacy format.

LANGUAGE: yaml
CODE:
abcplugin_read_access:
	 reserved: true
	 users:
		 - "user-A"

----------------------------------------

TITLE: Configuring CJK Analyzer with Stem Exclusion
DESCRIPTION: Shows how to create a CJK analyzer with stem exclusion rules for specific words.

LANGUAGE: json
CODE:
{
  "settings": {
    "analysis": {
      "analyzer": {
        "stem_exclusion_cjk_analyzer": {
          "type": "cjk",
          "stem_exclusion": ["example", "words"]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Searching with a truncate_hits pipeline in OpenSearch
DESCRIPTION: This snippet shows how to perform a search query on 'my_index' using the 'my_pipeline' search pipeline, which truncates results to 5 hits.

LANGUAGE: json
CODE:
POST /my_index/_search?search_pipeline=my_pipeline
{
  "size": 8
}

----------------------------------------

TITLE: Filtering Documents with Range Query in OpenSearch
DESCRIPTION: Example showing how to use a filter aggregation with a range query to calculate average price for items under $50. The filter narrows the document set before applying the avg aggregation on the taxful_total_price field.

LANGUAGE: json
CODE:
GET opensearch_dashboards_sample_data_ecommerce/_search
{
  "size": 0,
  "aggs": {
    "low_value": {
      "filter": {
        "range": {
          "taxful_total_price": {
            "lte": 50
          }
        }
      },
      "aggs": {
        "avg_amount": {
          "avg": {
            "field": "taxful_total_price"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Updateable Synonym Token Filter in OpenSearch
DESCRIPTION: This JSON configuration demonstrates how to set up an updateable synonym token filter. The 'updateable' flag must be set to true for the refresh API to work with this filter.

LANGUAGE: json
CODE:
{
  "analyzer": {
    "my_synonyms": {
      "tokenizer": "whitespace",
      "filter": [
        "synonym"
      ]
    }
  },
  "filter": {
    "synonym": {
      "type": "synonym_graph",
      "synonyms_path": "synonyms.txt",
      "updateable": true
    }
  }
}

----------------------------------------

TITLE: Defining Cron Expression for Weekday Scheduling in OpenSearch Alerting
DESCRIPTION: This cron expression configures a monitor to run every Monday through Friday at 11:30 AM. It demonstrates the use of specific values for minute and hour fields, and a range for the day of the week field.

LANGUAGE: cron
CODE:
30 11 * * 1-5

----------------------------------------

TITLE: Creating a Grok Processor Pipeline with Trace Matching in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a pipeline that traces which grok patterns matched during processing.

LANGUAGE: json
CODE:
PUT _ingest/pipeline/log_line  
{  
  "description": "Extract fields from a log line",  
  "processors": [  
    {  
      "grok": {  
        "field": "message",  
        "patterns": ["%{HTTPDATE:timestamp} %{IPORHOST:clientip}", "%{IPORHOST:clientip} %{HTTPDATE:timestamp} %{NUMBER:response_status:int}"],  
        "trace_match": true  
      }  
    }  
  ]  
}

----------------------------------------

TITLE: Creating a Fail Processor Pipeline in OpenSearch
DESCRIPTION: This example shows how to create an ingest pipeline named 'fail-log-pipeline' that uses the fail processor to prevent indexing of documents containing personally identifiable information.

LANGUAGE: json
CODE:
PUT _ingest/pipeline/fail-log-pipeline  
{  
  "description": "A pipeline to test the fail processor for log events",  
  "processors": [  
    {  
      "fail": {  
        "if": "ctx.user_info.contains('password') || ctx.user_info.contains('credit card')",  
        "message": "Document containing personally identifiable information (PII) cannot be indexed!"  
      }  
    }  
  ]  
}

----------------------------------------

TITLE: GET All PIT Segments Endpoint
DESCRIPTION: Endpoint to retrieve information about all PIT segments.

LANGUAGE: json
CODE:
GET /_cat/pit_segments/_all

----------------------------------------

TITLE: Sample Response from CAT Health API in OpenSearch
DESCRIPTION: This snippet shows a sample response from the CAT Health API. It includes various columns such as epoch, timestamp, cluster status, node counts, shard information, and active shards percentage.

LANGUAGE: json
CODE:
GET _cat/health?v&time=5d

epoch | timestamp | cluster | status | node.total | node.data | shards | pri | relo | init | unassign | pending_tasks | max_task_wait_time | active_shards_percent
1624248112 | 04:01:52 | odfe-cluster | green | 2 | 2 | 16 | 8 | 0 | 0 | 0 | 0 | - | 100.0%

----------------------------------------

TITLE: TAR Installation for Linux/MacOS
DESCRIPTION: Commands to install OpenSearch and set custom admin password for TAR distributions

LANGUAGE: bash
CODE:
./opensearch-tar-install.sh

LANGUAGE: bash
CODE:
export OPENSEARCH_INITIAL_ADMIN_PASSWORD=<custom-admin-password>

----------------------------------------

TITLE: Cloning OpenTelemetry Demo Repository
DESCRIPTION: Command to clone the OpenTelemetry Demo repository for testing the Trace Analytics plugin

LANGUAGE: bash
CODE:
git clone https://github.com/opensearch-project/opentelemetry-demo

----------------------------------------

TITLE: Single Neural Sparse Query in OpenSearch
DESCRIPTION: This example demonstrates a single neural sparse query using the neural_sparse_two_phase_processor.

LANGUAGE: json
CODE:
GET /my-nlp-index/_search
{
  "query": {
    "neural_sparse": {
      "passage_embedding": {
        "query_text": "Hi world"
        "model_id": <model-id>
      }
    }
  }
}

----------------------------------------

TITLE: Basic Significant Text Query with Sampler in OpenSearch
DESCRIPTION: Example query demonstrating how to use significant_text aggregation with a sampler to find significant terms related to 'breathe' in Shakespeare's works. Uses shard_size and min_doc_count parameters for optimization.

LANGUAGE: json
CODE:
GET shakespeare/_search
{
  "query": {
    "match": {
      "text_entry": "breathe"
    }
  },
  "aggregations": {
    "my_sample": {
      "sampler": {
        "shard_size": 100
      },
      "aggregations": {
        "keywords": {
          "significant_text": {
            "field": "text_entry",
            "min_doc_count": 4
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Indexing Documents with Text Fields in OpenSearch
DESCRIPTION: These snippets show how to index three documents with text fields into the previously created index. Each document contains a 'sentence' field with a different text value.

LANGUAGE: json
CODE:
PUT testindex/_doc/1
{ "sentence": "To be, or not to be: that is the question." }

LANGUAGE: json
CODE:
PUT testindex/_doc/2
{ "sentence": "All the world's a stage, and all the men and women are merely players." }

LANGUAGE: json
CODE:
PUT testindex/_doc/3
{ "sentence": "Now is the winter of our discontent." }

----------------------------------------

TITLE: Analyzing Text with Swedish Analyzer in OpenSearch
DESCRIPTION: This example shows how to use the _analyze API to examine tokens generated by the Swedish analyzer for a given text. It sends a POST request with sample Swedish text to be analyzed.

LANGUAGE: json
CODE:
POST /swedish-index/_analyze
{
  "field": "content",
  "text": "Studenter studerar vid svenska universitet. Deras nummer r 123456."
}

----------------------------------------

TITLE: Flushing All Indexes in OpenSearch
DESCRIPTION: An example request to flush all indexes in an OpenSearch cluster using the Flush API.

LANGUAGE: json
CODE:
POST /_flush

----------------------------------------

TITLE: Maximum ML Models Per Node
DESCRIPTION: Sets the maximum number of ML models that can be deployed to each node.

LANGUAGE: yaml
CODE:
plugins.ml_commons.max_model_on_node: 10

----------------------------------------

TITLE: Basic CSV Processor Syntax in OpenSearch
DESCRIPTION: Demonstrates the basic syntax structure for configuring a CSV processor in an OpenSearch ingest pipeline. Shows the required field and target_fields parameters.

LANGUAGE: json
CODE:
{
  "csv": {
    "field": "field_name",
    "target_fields": ["field1, field2, ..."]
  }
}

----------------------------------------

TITLE: Recording Ingest Pipeline Stats with Telemetry Device in OpenSearch
DESCRIPTION: Example JSON output from the ingest-pipeline-stats telemetry device, showing metrics for cluster, node, pipeline, and processor levels.

LANGUAGE: json
CODE:
{
    "name": "ingest_pipeline_cluster_count",
    "value": 1001,
    "meta": {
      "cluster_name": "docker-cluster"
    }
},
{
    "name": "ingest_pipeline_node_count",
    "value": 1001,
    "meta": {
      "cluster_name": "docker-cluster",
      "node_name": "node-001"
    }
},
{
    "name": "ingest_pipeline_pipeline_count",
    "value": 1001,
    "meta": {
      "cluster_name": "docker-cluster",
      "node_name": "node-001",
      "ingest_pipeline": "test-pipeline-1"
    }
},
{
    "name": "ingest_pipeline_processor_count",
    "value": 1001,
    "meta": {
      "cluster_name": "docker-cluster",
      "node_name": "node-001",
      "ingest_pipeline": "test-pipeline-1",
      "processor_name": "uppercase_1",
      "type": "uppercase"
    }
}

----------------------------------------

TITLE: Comparing Source and Target Cluster Indices
DESCRIPTION: Command to display and compare the indices and document counts of both source and target clusters.

LANGUAGE: bash
CODE:
console clusters cat-indices

----------------------------------------

TITLE: Creating YUM Repository for OpenSearch
DESCRIPTION: Create a local YUM repository file for OpenSearch installation.

LANGUAGE: bash
CODE:
sudo curl -SL https://artifacts.opensearch.org/releases/bundle/opensearch/{{major_version_mask}}/opensearch-{{major_version_mask}}.repo -o /etc/yum.repos.d/opensearch-{{major_version_mask}}.repo

----------------------------------------

TITLE: Creating Index with Stop Analyzer
DESCRIPTION: Creates an index named 'my_stop_index' using the default stop analyzer for text analysis.

LANGUAGE: json
CODE:
PUT /my_stop_index
{
  "mappings": {
    "properties": {
      "my_field": {
        "type": "text",
        "analyzer": "stop"
      }
    }
  }
}

----------------------------------------

TITLE: Generating Log Data for Ingestion Pipeline in Bash
DESCRIPTION: This command generates a sample log entry and appends it to the test.log file, which is then read by Fluent Bit for ingestion into the pipeline.

LANGUAGE: bash
CODE:
echo '63.173.168.120 - - [04/Nov/2021:15:07:25 -0500] "GET /search/tag/list HTTP/1.0" 200 5003' >> test.log

----------------------------------------

TITLE: Querying SQL Stats Endpoint in OpenSearch
DESCRIPTION: This snippet demonstrates how to query the SQL stats endpoint in OpenSearch to retrieve plugin metrics. It uses a curl command to send a GET request to the _plugins/_sql/stats endpoint.

LANGUAGE: console
CODE:
curl -H 'Content-Type: application/json' -X GET localhost:9200/_plugins/_sql/stats

----------------------------------------

TITLE: Geo Bounding Box Query Example in JSON
DESCRIPTION: Example of a geo_bounding_box query operation that can be randomized for spatial searches.

LANGUAGE: json
CODE:
{
  "name": "bbox", 
  "operation-type": "search", 
  "index": "nyc_taxis",
  "body": { 
    "size": 0,
    "query": {
      "geo_bounding_box": {
        "pickup_location": {
          "top_left": [-74.27, 40.92],
          "bottom_right": [-73.68, 40.49]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Registering Flow Agent with SearchIndexTool in OpenSearch
DESCRIPTION: Creates a flow agent that uses the SearchIndexTool to query an OpenSearch index. The agent is registered with a demo memory type and a single SearchIndexTool.

LANGUAGE: json
CODE:
POST /_plugins/_ml/agents/_register
{
  "name": "Test_Agent_For_Search_Index_Tool",
  "type": "flow",
  "description": "this is a test for search index tool",
  "memory": {
    "type": "demo"
  },
  "tools": [
    {
      "type": "SearchIndexTool"
    }
  ]
}

----------------------------------------

TITLE: Verifying OpenSearch Pod Status
DESCRIPTION: Command to check the status of OpenSearch pods after deployment.

LANGUAGE: bash
CODE:
kubectl get pods

----------------------------------------

TITLE: OpenSearch Percentile Aggregation Response Format
DESCRIPTION: Shows the response structure from a percentile aggregation query, displaying the calculated percentile values at different thresholds for the taxful_total_price field.

LANGUAGE: json
CODE:
{
  "aggregations": {
    "percentile_taxful_total_price": {
      "values": {
        "1.0": 21.984375,
        "5.0": 27.984375,
        "25.0": 44.96875,
        "50.0": 64.22061688311689,
        "75.0": 93.0,
        "95.0": 156.0,
        "99.0": 222.0
      }
    }
  }
}

----------------------------------------

TITLE: Analyzing Text with Keep Words Filter in OpenSearch
DESCRIPTION: Example request to analyze text using the custom analyzer with keep_words filter, showing how to test the analyzer's output with sample text.

LANGUAGE: json
CODE:
GET /my_index/_analyze
{
  "analyzer": "custom_keep_word",
  "text": "Hello, world! This is an OpenSearch example."
}

----------------------------------------

TITLE: Example JSON Response from Maps Stats API in OpenSearch
DESCRIPTION: Sample JSON response from the Maps Stats API, showing statistics about saved map objects including total maps, layer types, and individual map details.

LANGUAGE: json
CODE:
{
   "maps_total":4,  
   "layers_filters_total":4, 
   "layers_total":{ 
      "opensearch_vector_tile_map":2, 
      "documents":7, 
      "wms":1, 
      "tms":2 
   },
   "maps_list":[
      {
         "id":"88a24e6c-0216-4f76-8bc7-c8db6c8705da", 
         "layers_filters_total":4,
         "layers_total":{
            "opensearch_vector_tile_map":1,
            "documents":3,
            "wms":0,
            "tms":0
         }
      },
      {
         "id":"4ce3fe50-d309-11ed-a958-770756e00bcd",
         "layers_filters_total":0,
         "layers_total":{
            "opensearch_vector_tile_map":0,
            "documents":2,
            "wms":0,
            "tms":1
         }
      },
      {
         "id":"af5d3b90-d30a-11ed-a605-f7ad7bc98642",
         "layers_filters_total":0,
         "layers_total":{
            "opensearch_vector_tile_map":1,
            "documents":1,
            "wms":0,
            "tms":1
         }
      },
      {
         "id":"5ca1ec10-d30b-11ed-a042-93d8ff0f09ee",
         "layers_filters_total":0,
         "layers_total":{
            "opensearch_vector_tile_map":0,
            "documents":1,
            "wms":1,
            "tms":0
         }
      }
   ]
}

----------------------------------------

TITLE: Traffic Replayer Log Entry Example
DESCRIPTION: Sample JSON log entry showing request/response details for both source and target clusters

LANGUAGE: json
CODE:
{
    "sourceRequest": {
        "Request-URI": "/_cat/indices?v",
        "Method": "GET",
        "HTTP-Version": "HTTP/1.1",
        "Host": "capture-proxy:9200",
        "Authorization": "Basic YWRtaW46YWRtaW4=",
        "User-Agent": "curl/8.5.0",
        "Accept": "*/*",
        "body": ""
    },
    "sourceResponse": {
        "HTTP-Version": {"keepAliveDefault": true},
        "Status-Code": 200,
        "Reason-Phrase": "OK",
        "response_time_ms": 59,
        "content-type": "text/plain; charset=UTF-8",
        "content-length": "214",
        "body": "aGVhbHRoIHN0YXR1cyBpbmRleCAgICAgICB..."
    },
    "targetRequest": {
        "Request-URI": "/_cat/indices?v",
        "Method": "GET",
        "HTTP-Version": "HTTP/1.1",
        "Host": "opensearchtarget",
        "Authorization": "Basic YWRtaW46bXlTdHJvbmdQYXNzd29yZDEyMyE=",
        "User-Agent": "curl/8.5.0",
        "Accept": "*/*",
        "body": ""
    },
    "targetResponses": [{
        "HTTP-Version": {"keepAliveDefault": true},
        "Status-Code": 200,
        "Reason-Phrase": "OK",
        "response_time_ms": 721,
        "content-type": "text/plain; charset=UTF-8",
        "content-length": "484",
        "body": "aGVhbHRoIHN0YXR1cyBpbmRleCAgICAgICB..."
    }],
    "connectionId": "0242acfffe13000a-0000000a-00000005-1eb087a9beb83f3e-a32794b4.0",
    "numRequests": 1,
    "numErrors": 0
}

----------------------------------------

TITLE: Retrieving Document in OpenSearch
DESCRIPTION: Query to retrieve the processed document after applying the remove pipeline.

LANGUAGE: json
CODE:
GET testindex1/_doc/1

----------------------------------------

TITLE: Analyzing Text with Edge N-gram Tokenizer
DESCRIPTION: Demonstrates how to analyze text using the configured edge n-gram tokenizer to examine generated tokens.

LANGUAGE: json
CODE:
POST /edge_n_gram_index/_analyze
{
  "analyzer": "my_custom_analyzer",
  "text": "Code 42 rocks!"
}

----------------------------------------

TITLE: Creating an Index with Edge N-gram Filter in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a new index named 'edge_ngram_example' with a custom analyzer using the edge_ngram filter. The filter is configured with min_gram of 3 and max_gram of 4.

LANGUAGE: json
CODE:
PUT /edge_ngram_example
{
  "settings": {
    "analysis": {
      "filter": {
        "my_edge_ngram": {
          "type": "edge_ngram",
          "min_gram": 3,
          "max_gram": 4
        }
      },
      "analyzer": {
        "my_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": ["lowercase", "my_edge_ngram"]
        }
      }
    }
  }
}

----------------------------------------

TITLE: YAML Workflow Template Example
DESCRIPTION: Complete example of a workflow template in YAML format for registering and deploying an external model

LANGUAGE: bash
CODE:
curl -XPOST "http://localhost:9200/_plugins/_flow_framework/workflow" -H 'Content-Type: application/yaml'

LANGUAGE: yaml
CODE:
name: createconnector-registerremotemodel-deploymodel
description: This template creates a connector to a remote model, registers it, and
  deploys that model
use_case: REMOTE_MODEL_DEPLOYMENT
version:
  template: 1.0.0
  compatibility:
  - 2.12.0
  - 3.0.0
workflows:
  provision:
    nodes:
    - id: create_connector_1
      type: create_connector
      user_inputs:
        name: OpenAI Chat Connector
        description: The connector to public OpenAI model service for GPT 3.5
        version: '1'
        protocol: http
        parameters:
          endpoint: api.openai.com
          model: gpt-3.5-turbo
        credential:
          openAI_key: '12345'
        actions:
        - action_type: predict
          method: POST
          url: https://${parameters.endpoint}/v1/chat/completions
    - id: register_model_2
      type: register_remote_model
      previous_node_inputs:
        create_connector_1: connector_id
      user_inputs:
        name: openAI-gpt-3.5-turbo
        function_name: remote
        description: test model
    - id: deploy_model_3
      type: deploy_model
      previous_node_inputs:
        register_model_2: model_id
    edges:
    - source: create_connector_1
      dest: register_model_2
    - source: register_model_2
      dest: deploy_model_3

----------------------------------------

TITLE: Configuring select_entries Processor in YAML Pipeline
DESCRIPTION: Example configuration for the select_entries processor in a Data Prepper pipeline.yaml file. It demonstrates how to specify include_keys and select_when options.

LANGUAGE: yaml
CODE:
pipeline:
  source:
    ...
  ....  
  processor:
    - select_entries:
        include_keys: [ "key1", "key2" ]
        select_when: '/some_key == "test"'
  sink:

----------------------------------------

TITLE: Creating Custom Czech Analyzer in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a custom Czech analyzer with specific token filters in OpenSearch index settings and mappings.

LANGUAGE: json
CODE:
PUT /czech-index
{
  "settings": {
    "analysis": {
      "filter": {
        "czech_stop": {
          "type": "stop",
          "stopwords": "_czech_"
        },
        "czech_stemmer": {
          "type": "stemmer",
          "language": "czech"
        },
        "czech_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] 
        }
      },
      "analyzer": {
        "czech_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "czech_stop",
            "czech_keywords",
            "czech_stemmer"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "czech_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Creating SageMaker Connector for PPL Model in OpenSearch
DESCRIPTION: This JSON request creates a connector for a SageMaker-hosted model that translates natural language to PPL queries. It specifies the connector details, credentials, and the predict action configuration.

LANGUAGE: json
CODE:
POST /_plugins/_ml/connectors/_create
{
  "name": "sagemaker: t2ppl",
  "description": "Test connector for Sagemaker t2ppl model",
  "version": 1,
  "protocol": "aws_sigv4",
  "credential": {
    "access_key": "<YOUR ACCESS KEY>",
    "secret_key": "<YOUR SECRET KEY>"
  },
  "parameters": {
    "region": "us-east-1",
    "service_name": "sagemaker"
  },
  "actions": [
    {
      "action_type": "predict",
      "method": "POST",
      "headers": {
        "content-type": "application/json"
      },
      "url": "<YOUR SAGEMAKER ENDPOINT>",
      "request_body": "{\"prompt\":\"${parameters.prompt}\"}"
    }
  ]
}

----------------------------------------

TITLE: Sample UBI Event Logging Implementation
DESCRIPTION: Example functions showing how to use the UBI event structures to log different types of events including messages, dwell time, and item clicks. Demonstrates practical usage of the UbiEvent class.

LANGUAGE: javascript
CODE:
export function logUbiMessage(event_type, message_type, message){
  let e = new UbiEvent(event_type, {
    message_type:message_type,
    message:message
  });
  logEvent(e);
}

export function logDwellTime(action_name, page, seconds){
  console.log(`${page} => ${seconds}`);
  let e = new UbiEvent(action_name, {
    message:`On page ${page} for ${seconds} seconds`,
    event_attributes:{
      session_id: getSessionId()},
      dwell_seconds:seconds
      },
    data_object:TimeMe
  });
  logEvent(e);
}

export function logItemClick(item, ordinal){
  let e = new UbiEvent('item_click', {
    message:`Item ${item['object_id']} was clicked`,
    event_attributes:{session_id: getSessionId()},
    data_object:item,    
  });
  e.event_attributes.position.ordinal = ordinal;
  logEvent(e);
}

export function logEvent( event ){
  return client.index( index = 'ubi_events', body = event.toJson());
}

----------------------------------------

TITLE: Creating Index with Predicate Token Filter
DESCRIPTION: Creates a new index with a custom analyzer that uses a predicate token filter to keep only tokens longer than 7 characters. The example demonstrates configuration of analysis settings including filter and analyzer definitions.

LANGUAGE: json
CODE:
PUT /predicate_index
{
  "settings": {
    "analysis": {
      "filter": {
        "my_predicate_filter": {
          "type": "predicate_token_filter",
          "script": {
            "source": "token.term.length() > 7"
          }
        }
      },
      "analyzer": {
        "predicate_analyzer": {
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "my_predicate_filter"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Extracting OpenSearch Dashboards Tarball (Bash)
DESCRIPTION: These commands demonstrate how to extract the OpenSearch Dashboards tarball for both x64 and ARM64 architectures. The user is instructed to change into the extracted directory after extraction.

LANGUAGE: bash
CODE:
# x64
tar -zxf opensearch-dashboards-{{site.opensearch_version}}-linux-x64.tar.gz
cd opensearch-dashboards
# ARM64
tar -zxf opensearch-dashboards-{{site.opensearch_version}}-linux-arm64.tar.gz
cd opensearch-dashboards

----------------------------------------

TITLE: Extracting OpenSearch Dashboards Tarball (Bash)
DESCRIPTION: These commands demonstrate how to extract the OpenSearch Dashboards tarball for both x64 and ARM64 architectures. The user is instructed to change into the extracted directory after extraction.

LANGUAGE: bash
CODE:
# x64
tar -zxf opensearch-dashboards-{{site.opensearch_version}}-linux-x64.tar.gz
cd opensearch-dashboards
# ARM64
tar -zxf opensearch-dashboards-{{site.opensearch_version}}-linux-arm64.tar.gz
cd opensearch-dashboards

----------------------------------------

TITLE: External Model Pipeline Configuration
DESCRIPTION: Example of creating an ingest pipeline with an externally hosted text embedding model.

LANGUAGE: json
CODE:
{
  "description": "Generate passage_embedding for ingested documents",
  "processors": [
    {
      "ml_inference": {
        "model_id": "<your model id>",
        "input_map": [
          {
            "input": "passage_text"
          }
        ],
        "output_map": [
          {
            "passage_embedding": "data"
          }
        ]
      }
    }
  ]
}

----------------------------------------

TITLE: Enabling Shard Replication in OpenSearch
DESCRIPTION: This snippet shows how to re-enable shard replication in OpenSearch after the upgrade process by setting the cluster routing allocation back to 'all'.

LANGUAGE: json
CODE:
PUT "/_cluster/settings?pretty"
{
    "persistent": {
        "cluster.routing.allocation.enable": "all"
    }
}

----------------------------------------

TITLE: Testing Convert Pipeline with Simulate API
DESCRIPTION: Example of testing the convert pipeline using the simulate API with a sample document.

LANGUAGE: json
CODE:
POST _ingest/pipeline/convert-price/_simulate
{
  "docs": [
    {
      "_index": "testindex1",
      "_id": "1",
       "_source": {
        "price": "-10.5"
      }
    }
  ]
}

----------------------------------------

TITLE: Testing Append Processor Pipeline in OpenSearch
DESCRIPTION: Example of testing the append processor pipeline using the simulate API.

LANGUAGE: json
CODE:
POST _ingest/pipeline/user-behavior/_simulate
{
  "docs":[
    {
      "_source":{
      }
    }
  ]
}

----------------------------------------

TITLE: Updating Credentials for a Standalone Connector
DESCRIPTION: Example request to update the credentials for a standalone connector without affecting any models using it.

LANGUAGE: json
CODE:
PUT /_plugins/_ml/connectors/<connector_id>
{
  "credential": {
    "openAI_key": "YOUR NEW OPENAI KEY"
  }
}

----------------------------------------

TITLE: Searching for Documents in OpenSearch
DESCRIPTION: JavaScript code for searching documents in OpenSearch using a match query.

LANGUAGE: javascript
CODE:
var query = {
  query: {
    match: {
      title: {
        query: "The Outsider",
      },
    },
  },
};

var response = await client.search({
  index: index_name,
  body: query,
});

----------------------------------------

TITLE: Basic Search Without Pipeline
DESCRIPTION: Performs a basic search operation without using the rename field processor pipeline.

LANGUAGE: json
CODE:
GET /my_index/_search

----------------------------------------

TITLE: Delete Task Endpoint
DESCRIPTION: The endpoint specification for deleting an ML Commons task using the task ID.

LANGUAGE: json
CODE:
DELETE /_plugins/_ml/tasks/<task_id>

----------------------------------------

TITLE: Configuring Basic Persian Analyzer in OpenSearch
DESCRIPTION: Shows how to apply the built-in Persian analyzer to a text field in an index mapping.

LANGUAGE: json
CODE:
PUT /persian-index
{
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "persian"
      }
    }
  }
}

----------------------------------------

TITLE: Adding Trusted Endpoints in OpenSearch Cluster Settings
DESCRIPTION: JSON request to add trusted endpoints for ML connectors using regex patterns.

LANGUAGE: json
CODE:
PUT /_cluster/settings
{
    "persistent": {
        "plugins.ml_commons.trusted_connector_endpoints_regex": [
          "^https://runtime\\.sagemaker\\..*[a-z0-9-]\\.amazonaws\\.com/.*$",
          "^https://api\\.openai\\.com/.*$",
          "^https://api\\.cohere\\.ai/.*$",
          "^https://bedrock-runtime\\..*[a-z0-9-]\\.amazonaws\\.com/.*$"
        ]
    }
}

----------------------------------------

TITLE: Searching KMEANS Tasks Request Example
DESCRIPTION: Example request demonstrating how to search for tasks with function_name equal to KMEANS using a term filter.

LANGUAGE: json
CODE:
{
  "query": {
    "bool": {
      "filter": [
        {
          "term": {
            "function_name": "KMEANS"
          }
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Defining Operations and Schedule in OpenSearch Benchmark
DESCRIPTION: Example showing how to define operations separately and reference them in the schedule. Demonstrates force-merge and match-all query operations with specific client and iteration settings.

LANGUAGE: yaml
CODE:
{
  "operations": [
    {
      "name": "force-merge",
      "operation-type": "force-merge"
    },
    {
      "name": "match-all-query",
      "operation-type": "search",
      "body": {
        "query": {
          "match_all": {}
        }
      }
    }
  ],
  "schedule": [
    {
      "operation": "force-merge",
      "clients": 1
    },
    {
      "operation": "match-all-query",
      "clients": 4,
      "warmup-iterations": 1000,
      "iterations": 1000,
      "target-throughput": 100
    }
  ]
}

----------------------------------------

TITLE: Applying Security Configuration Changes
DESCRIPTION: Command to apply security configuration changes using securityadmin.sh script.

LANGUAGE: bash
CODE:
OPENSEARCH_JAVA_HOME=/usr/share/opensearch/jdk ./securityadmin.sh -cd /etc/opensearch/opensearch-security/ -cacert /etc/opensearch/root-ca.pem -cert /etc/opensearch/admin.pem -key /etc/opensearch/admin-key.pem -icl -nhnv

----------------------------------------

TITLE: Searching with Autocomplete
DESCRIPTION: Performs a search query using the configured autocomplete functionality with AND operator.

LANGUAGE: json
CODE:
GET my-autocomplete-index/_search
{
  "query": {
    "match": {
      "title": {
        "query": "lap pr",
        "operator": "and"
      }
    }
  }
}

----------------------------------------

TITLE: Pulling Data Prepper Docker Image
DESCRIPTION: Docker command to pull the latest OpenSearch Data Prepper image.

LANGUAGE: bash
CODE:
docker pull opensearchproject/data-prepper:latest

----------------------------------------

TITLE: Creating Index with Character Group Tokenizer
DESCRIPTION: Creates a new index with a custom analyzer using the char_group tokenizer configured to split text on whitespace, hyphen, and colon characters.

LANGUAGE: json
CODE:
PUT /my_index
{
  "settings": {
    "analysis": {
      "tokenizer": {
        "my_char_group_tokenizer": {
          "type": "char_group",
          "tokenize_on_chars": [
            "whitespace",
            "-",
            ":"
          ]
        }
      },
      "analyzer": {
        "my_char_group_analyzer": {
          "type": "custom",
          "tokenizer": "my_char_group_tokenizer"
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "my_char_group_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Disabling Shard Replication in OpenSearch
DESCRIPTION: Disables shard replication to prevent shard movement during migration using the Cluster Settings API.

LANGUAGE: json
CODE:
PUT "/_cluster/settings?pretty"
{
    "persistent": {
        "cluster.routing.allocation.enable": "primaries"
    }
}

----------------------------------------

TITLE: Agent Execution Response - JSON
DESCRIPTION: Response structure showing the inference results from the agent execution.

LANGUAGE: json
CODE:
{
  "inference_results": [
    {
      "output": [
        {
          "name": "response",
          "result": " I do not have direct data on the population increase of Seattle from 2021 to 2023 in the context provided. As a data analyst, I would need to research population statistics from credible sources like the US Census Bureau to analyze population trends and make an informed estimate. Without looking up actual data, I don't have enough information to provide a specific answer to the question."
        }
      ]
    }
  ]
}

----------------------------------------

TITLE: Average Aggregation on E-commerce Data in OpenSearch
DESCRIPTION: This example demonstrates how to perform an average aggregation on the 'taxful_total_price' field in a sample e-commerce dataset. It calculates the average price across all documents.

LANGUAGE: json
CODE:
GET opensearch_dashboards_sample_data_ecommerce/_search
{
  "size": 0,
  "aggs": {
    "avg_taxful_total_price": {
      "avg": {
        "field": "taxful_total_price"
      }
    }
  }
}

----------------------------------------

TITLE: Script Score Function Query
DESCRIPTION: Uses a custom script to calculate document scores based on views and likes.

LANGUAGE: json
CODE:
GET blogs/_search
{
  "query": {
    "function_score": {
      "query": {"match": {"name": "opensearch"}},
      "script_score": {
        "script": "_score * Math.log(1 + doc['likes'].value + doc['views'].value)"
      }
    }
  }
}

----------------------------------------

TITLE: Updating Model Interface in OpenSearch
DESCRIPTION: Example request to update the interface of an AI21 Labs Jurassic model by specifying the output schema.

LANGUAGE: json
CODE:
PUT /_plugins/_ml/models/IMcNB5UB7judm8f45nXo
{
    "interface": {
        "output": "{\n  \"type\": \"object\",\n  \"properties\": {\n    \"inference_results\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"output\": {\n            \"type\": \"array\",\n            \"items\": {\n              \"type\": \"object\",\n              \"properties\": {\n                \"name\": {\n                  \"type\": \"string\"\n                },\n                \"dataAsMap\": {\n                  \"type\": \"object\",\n                  \"properties\": {\n                    \"id\": {\n                      \"type\": \"number\"\n                    },\n                    \"prompt\": {\n                      \"type\": \"object\",\n                      \"properties\": {\n                        \"text\": {\n                          \"type\": \"string\"\n                        },\n                        \"tokens\": {\n                          \"type\": \"array\",\n                          \"items\": {\n                            \"type\": \"object\",\n                            \"properties\": {\n                              \"generatedToken\": {\n                                \"type\": \"object\",\n                                \"properties\": {\n                                  \"token\": {\n                                    \"type\": \"string\"\n                                  },\n                                  \"logprob\": {\n                                    \"type\": \"number\"\n                                  },\n                                  \"raw_logprob\": {\n                                    \"type\": \"number\"\n                                  }\n                                }\n                              },\n                              \"textRange\": {\n                                \"type\": \"object\",\n                                \"properties\": {\n                                  \"start\": {\n                                    \"type\": \"number\"\n                                  },\n                                  \"end\": {\n                                    \"type\": \"number\"\n                                  }\n                                }\n                              }\n                            }\n                          }\n                        }\n                      }\n                    },\n                    \"completions\": {\n                      \"type\": \"array\",\n                      \"items\": {\n                        \"type\": \"object\",\n                        \"properties\": {\n                          \"data\": {\n                            \"type\": \"object\",\n                            \"properties\": {\n                              \"text\": {\n                                \"type\": \"string\"\n                              },\n                              \"tokens\": {\n                                \"type\": \"array\",\n                                \"items\": {\n                                  \"type\": \"object\",\n                                  \"properties\": {\n                                    \"generatedToken\": {\n                                      \"type\": \"object\",\n                                      \"properties\": {\n                                        \"token\": {\n                                          \"type\": \"string\"\n                                        },\n                                        \"logprob\": {\n                                          \"type\": \"number\"\n                                        },\n                                        \"raw_logprob\": {\n                                          \"type\": \"number\"\n                                        }\n                                      }\n                                    },\n                                    \"textRange\": {\n                                      \"type\": \"object\",\n                                      \"properties\": {\n                                        \"start\": {\n                                          \"type\": \"number\"\n                                        },\n                                        \"end\": {\n                                          \"type\": \"number\"\n                                        }\n                                      }\n                                    }\n                                  }\n                                }\n                              }\n                            }\n                          },\n                          \"finishReason\": {\n                            \"type\": \"object\",\n                            \"properties\": {\n                              \"reason\": {\n                                \"type\": \"string\"\n                              },\n                              \"length\": {\n                                \"type\": \"number\"\n                              }\n                            }\n                          }\n                        }\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          },\n          \"status_code\": {\n            \"type\": \"integer\"\n          }\n        }\n      }\n    }\n  }\n}"
    }
}

----------------------------------------

TITLE: Creating Split Pipeline
DESCRIPTION: Example of creating a pipeline that splits a log_message field on comma characters into a log_parts array.

LANGUAGE: json
CODE:
PUT _ingest/pipeline/split_pipeline
{
  "description": "Split log messages by comma",
  "processors": [
    {
      "split": {
        "field": "log_message",
        "separator": ",",
        "target_field": "log_parts"
      }
    }
  ]
}

----------------------------------------

TITLE: Analyzing Text with Custom Keyword Analyzer in OpenSearch
DESCRIPTION: This snippet demonstrates how to use the _analyze API to examine the tokens generated by the custom keyword analyzer. It sends a POST request to analyze the text "Just one token" using the previously defined 'my_keyword_analyzer'.

LANGUAGE: json
CODE:
POST /my_custom_keyword_index/_analyze
{
  "analyzer": "my_keyword_analyzer",
  "text": "Just one token"
}

----------------------------------------

TITLE: DQL Range Queries
DESCRIPTION: Examples of numeric and date range queries using comparison operators.

LANGUAGE: python
CODE:
page_views > 100 and page_views <= 300

LANGUAGE: python
CODE:
date >= "2013-01-01" and date < "2024-01-01"

----------------------------------------

TITLE: Retrieving Metadata Values in OpenSearch Pipelines
DESCRIPTION: Example showing metadata structure and output format when using getMetadata(). The function can retrieve both string and numeric values from nested metadata objects. Keys can be specified using path notation with '/' for nested lookups.

LANGUAGE: json
CODE:
{
  "event": {
    "metadata": {
      "key1": "value2",
      "key2": 10
    },
    "data": {
      // ...
    }
  },
  "output": [
    {
      "key": "key1",
      "value": "value2"
    },
    {
      "key": "key2",
      "value": 10
    }
  ]
}

----------------------------------------

TITLE: Configuring Extensions in Data Prepper YAML
DESCRIPTION: Shows the YAML configuration block where extensions should be defined in the Data Prepper configuration file. Extensions provide additional functionality and configuration options beyond core pipeline components.

LANGUAGE: yaml
CODE:
extensions:

----------------------------------------

TITLE: Deploying Hidden Model in OpenSearch
DESCRIPTION: Bash command to deploy a hidden model using its model ID in OpenSearch.

LANGUAGE: bash
CODE:
curl -k --cert ./kirk.pem --key ./kirk-key.pem -X POST 'https://localhost:9200/_plugins/_ml/models/q7wLt4sBaDRBsUkl9BJV/_deploy'

----------------------------------------

TITLE: Custom Italian Analyzer Configuration
DESCRIPTION: Detailed configuration for a custom Italian analyzer with specific token filters including elision, stop words, and stemming settings.

LANGUAGE: json
CODE:
PUT /italian-index
{
  "settings": {
    "analysis": {
      "filter": {
        "italian_stop": {
          "type": "stop",
          "stopwords": "_italian_"
        },
        "italian_elision": {
          "type": "elision",
          "articles": [
                "c", "l", "all", "dall", "dell",
                "nell", "sull", "coll", "pell",
                "gl", "agl", "dagl", "degl", "negl",
                "sugl", "un", "m", "t", "s", "v", "d"
          ],
          "articles_case": true
        },
        "italian_stemmer": {
          "type": "stemmer",
          "language": "light_italian"
        },
        "italian_keywords": {
          "type": "keyword_marker",
          "keywords": []
        }
      },
      "analyzer": {
        "italian_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "italian_elision",
            "lowercase",
            "italian_stop",
            "italian_keywords",
            "italian_stemmer"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "italian_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Custom Stop Analyzer
DESCRIPTION: Creates an index with a custom stop analyzer that uses lowercase tokenizer and stop filter.

LANGUAGE: json
CODE:
PUT /my_custom_stop_analyzer_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_custom_stop_analyzer": {
          "tokenizer": "lowercase",
          "filter": [
            "stop"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "my_field": {
        "type": "text",
        "analyzer": "my_custom_stop_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Displaying Help for OpenSearch Migration Console
DESCRIPTION: This command displays help information for the entire console application, showing available commands and options.

LANGUAGE: bash
CODE:
$ console --help
Usage: console [OPTIONS] COMMAND [ARGS]...

Options:
  --config-file TEXT  Path to config file
  --json
  -v, --verbose       Verbosity level. Default is warn, -v is info, -vv is
                      debug.
  --help              Show this message and exit.

Commands:
  backfill    Commands related to controlling the configured backfill...
  clusters    Commands to interact with source and target clusters
  completion  Generate shell completion script and instructions for setup.
  kafka       All actions related to Kafka operations
  metadata    Commands related to migrating metadata to the target cluster.
  metrics     Commands related to checking metrics emitted by the capture...
  replay      Commands related to controlling the replayer.
  snapshot    Commands to create and check status of snapshots of the...
  tuples      All commands related to tuples.

----------------------------------------

TITLE: Deleting ML Controller Endpoint
DESCRIPTION: The REST endpoint for deleting a machine learning controller using the model ID parameter.

LANGUAGE: json
CODE:
DELETE /_plugins/_ml/controllers/<model_id>

----------------------------------------

TITLE: Finding users who logged out without queries
DESCRIPTION: SQL query to identify users who logged out without submitting any queries, grouped by client_id and session_id.

LANGUAGE: sql
CODE:
select 
    client_id, session_id, count(0) EventTotal
from ubi_events
where action_name='logout' and query_id is null
group by client_id, session_id
order by EventTotal desc

----------------------------------------

TITLE: Generated Tokens Response
DESCRIPTION: Response showing the tokens generated by the custom analyzer, demonstrating how words are transformed according to the stemming rules.

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "i",
      "start_offset": 0,
      "end_offset": 1,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "am",
      "start_offset": 2,
      "end_offset": 4,
      "type": "<ALPHANUM>",
      "position": 1
    },
    {
      "token": "a",
      "start_offset": 5,
      "end_offset": 6,
      "type": "<ALPHANUM>",
      "position": 2
    },
    {
      "token": "run",
      "start_offset": 7,
      "end_offset": 13,
      "type": "<ALPHANUM>",
      "position": 3
    },
    {
      "token": "and",
      "start_offset": 14,
      "end_offset": 17,
      "type": "<ALPHANUM>",
      "position": 4
    },
    {
      "token": "buy",
      "start_offset": 18,
      "end_offset": 24,
      "type": "<ALPHANUM>",
      "position": 5
    },
    {
      "token": "the",
      "start_offset": 25,
      "end_offset": 28,
      "type": "<ALPHANUM>",
      "position": 6
    },
    {
      "token": "good",
      "start_offset": 29,
      "end_offset": 33,
      "type": "<ALPHANUM>",
      "position": 7
    },
    {
      "token": "shoes",
      "start_offset": 34,
      "end_offset": 39,
      "type": "<ALPHANUM>",
      "position": 8
    }
  ]
}

----------------------------------------

TITLE: Querying Range Fields with Range Query in OpenSearch
DESCRIPTION: This example demonstrates how to use a range query on a range field in OpenSearch. It searches for graduation dates within the year 2019, specifying the date format and relation type.

LANGUAGE: json
CODE:
GET testindex1/_search
{
  "query": {
    "range": {
      "graduation_date": {
        "gte": "01/01/2019",
        "lte": "12/31/2019",
        "format": "MM/dd/yyyy",
        "relation" : "within"       
      }
    }
  }
}

----------------------------------------

TITLE: Trigonometric Function Usage in OpenSearch SQL
DESCRIPTION: Examples of using trigonometric functions in OpenSearch SQL queries. These functions perform various trigonometric operations on numeric data types.

LANGUAGE: SQL
CODE:
SELECT acos(0.5)
SELECT asin(0.5)
SELECT atan(0.5)
SELECT atan2(1, 0.5)
SELECT cos(0.5)
SELECT cosh(0.5)
SELECT cot(0.5)
SELECT degrees(0.5)
SELECT radians(0.5)
SELECT sin(0.5)
SELECT sinh(0.5)
SELECT tan(0.5)

----------------------------------------

TITLE: Creating Rename Pipeline in OpenSearch
DESCRIPTION: Example of creating an ingest pipeline that moves a field from within an object to the root level of the document.

LANGUAGE: json
CODE:
PUT /_ingest/pipeline/rename_field
{
  "description": "Pipeline that moves a field to the root level.",
  "processors": [
    {
      "rename": {
        "field": "message.content",
        "target_field": "content"
      }
    }
  ]
}

----------------------------------------

TITLE: Navigating to OpenSearch Dashboards Directory
DESCRIPTION: Command to change the current directory to the OpenSearch Dashboards installation location.

LANGUAGE: batch
CODE:
cd \path\to\opensearch-dashboards-{{site.opensearch_version}}

----------------------------------------

TITLE: Retrieving Document After Failed Ingestion in OpenSearch
DESCRIPTION: This snippet demonstrates how to attempt retrieval of a document that failed to index due to the fail processor. It shows the expected 'document not found' response.

LANGUAGE: json
CODE:
GET testindex1/_doc/1

----------------------------------------

TITLE: Simple Terms Query on _index Field - OpenSearch JSON
DESCRIPTION: Basic example of using a terms query to match documents from specific indexes using the _index field.

LANGUAGE: json
CODE:
 {
  "query": {
    "terms": {
      "_index": ["products", "customers"]
    }
  }
}

----------------------------------------

TITLE: Querying CAT Aliases Endpoints in OpenSearch
DESCRIPTION: The basic endpoints for accessing the CAT aliases API. Supports both retrieving all aliases and specific alias names.

LANGUAGE: json
CODE:
GET /_cat/aliases
GET /_cat/aliases/{name}

----------------------------------------

TITLE: Get Message Traces Endpoint
DESCRIPTION: The API endpoint for retrieving message trace information.

LANGUAGE: json
CODE:
GET /_plugins/_ml/memory/message/<message_id>/traces

----------------------------------------

TITLE: Configuring a Notification Action
DESCRIPTION: Example of how to set up a notification action for Chime in an ISM policy.

LANGUAGE: json
CODE:
{
  "notification": {
    "destination": {
      "chime": {
        "url": "<url>"
      }
    },
    "message_template": {
      "source": "the index is {{ctx.index}}"
    }
  }
}

----------------------------------------

TITLE: Registering Flow Agent
DESCRIPTION: Configuration for creating a flow agent that combines VectorDBTool and MLModelTool for RAG operations.

LANGUAGE: json
CODE:
{
  "name": "Test_Agent_For_RAG",
  "type": "flow",
  "description": "this is a test agent",
  "tools": [
    {
      "type": "VectorDBTool",
      "parameters": {
        "model_id": "aVeif4oB5Vm0Tdw8zYO2",
        "index": "my_test_data",
        "embedding_field": "embedding",
        "source_field": ["text"],
        "input": "${parameters.question}"
      }
    },
    {
      "type": "MLModelTool",
      "description": "A general tool to answer any question",
      "parameters": {
        "model_id": "NWR9YIsBUysqmzBdifVJ",
        "prompt": "\n\nHuman:You are a professional data analyst. You will always answer a question based on the given context first. If the answer is not directly shown in the context, you will analyze the data and find the answer. If you don't know the answer, just say you don't know. \n\n Context:\n${parameters.VectorDBTool.output}\n\nHuman:${parameters.question}\n\nAssistant:"
      }
    }
  ]
}

----------------------------------------

TITLE: Querying Cluster Manager Node Statistics in OpenSearch
DESCRIPTION: Demonstrates how to retrieve statistics specifically from the elected cluster manager node using the Nodes API.

LANGUAGE: json
CODE:
GET /_nodes/_cluster_manager/stats

----------------------------------------

TITLE: Searching for Models with Specific Algorithm in OpenSearch
DESCRIPTION: This example shows how to search for ML models that use the 'FIT_RCF' algorithm. It uses a term query to match the exact algorithm name.

LANGUAGE: json
CODE:
POST /_plugins/_ml/models/_search
{
  "query": {
    "term": {
      "algorithm": {
        "value": "FIT_RCF"
      }
    }
  }
}

----------------------------------------

TITLE: Analyzing Text with CJK Width Filter
DESCRIPTION: Demonstrates how to analyze text containing full-width ASCII characters and half-width katakana using the custom analyzer.

LANGUAGE: json
CODE:
POST /cjk_width_example_index/_analyze
{
  "analyzer": "cjk_width_analyzer",
  "text": " 2024 "
}

----------------------------------------

TITLE: Demonstrating Tenant URL Structure in OpenSearch Dashboards
DESCRIPTION: This snippet shows the URL structure for accessing a visualization in a specific tenant within OpenSearch Dashboards. It includes the host, port, tenant name, and visualization ID.

LANGUAGE: plaintext
CODE:
http://<opensearch_dashboards_host>:5601/app/opensearch-dashboards?security_tenant=analysts#/visualize/edit/c501fa50-7e52-11e9-ae4e-b5d69947d32e?_g=()

----------------------------------------

TITLE: Nested Fields k-NN Query
DESCRIPTION: Example showing how to perform k-NN search with nested fields, including expand_nested_docs parameter and inner hits configuration.

LANGUAGE: json
CODE:
GET /my-vector-index/_search
{
  "_source": false,
  "query": {
    "nested": {
      "path": "nested_field",
      "query": {
        "knn": {
          "nested_field.my_vector": {
            "vector": [1,1,1],
            "k": 2,
            "expand_nested_docs": true
          }
        }
      },
      "inner_hits": {
        "_source": false,
        "fields":["nested_field.color"]
      },
      "score_mode": "max"
    }
  }
}

----------------------------------------

TITLE: Configuring Unthrottled Bulk Indexing Workload in JSON
DESCRIPTION: This snippet demonstrates a workload configuration for an unthrottled bulk index operation running for 1 hour against the 'movies' index. It specifies the index, corpus details, and schedule for the benchmark.

LANGUAGE: json
CODE:
{
  "description": "Tutorial benchmark for OpenSearch Benchmark",
  "indices": [
    {
      "name": "movies",
      "body": "index.json"
    }
  ],
  "corpora": [
    {
      "name": "movies",
      "documents": [
        {
          "source-file": "movies-documents.json",
          "document-count": 11658903,
          "uncompressed-bytes": 1544799789
        }
      ]
    }
  ],
  "schedule": [
  {
    "operation": "bulk",
    "warmup-time-period": 120,
    "time-period": 3600,
    "clients": 8
  }
]
}

----------------------------------------

TITLE: Example Task Information Response
DESCRIPTION: Example response showing task details including model ID, task type, function name, state, input type, worker node, timestamps, and async status.

LANGUAGE: json
CODE:
{
  "model_id" : "l7lamX8BO5w8y8Ra2oty",
  "task_type" : "TRAINING",
  "function_name" : "KMEANS",
  "state" : "COMPLETED",
  "input_type" : "SEARCH_QUERY",
  "worker_node" : "54xOe0w8Qjyze00UuLDfdA",
  "create_time" : 1647545342556,
  "last_update_time" : 1647545342587,
  "is_async" : true
}

----------------------------------------

TITLE: Accessing OpenSearch Shell
DESCRIPTION: Command to access the shell of an OpenSearch pod for further operations.

LANGUAGE: bash
CODE:
kubectl exec -it opensearch-cluster-master-0 -- /bin/bash

----------------------------------------

TITLE: Checking Python Version for OpenSearch Benchmark Installation
DESCRIPTION: Verifies that Python 3.8 or later is installed, which is required for OpenSearch Benchmark.

LANGUAGE: bash
CODE:
python3 --version

----------------------------------------

TITLE: Search All Memories Request
DESCRIPTION: Example request to search for all memories with a size limit of 1000 results.

LANGUAGE: json
CODE:
{
  "query": {
    "match_all": {}
  },
  "size": 1000
}

----------------------------------------

TITLE: Manual Document ID Assignment
DESCRIPTION: Shows how to index a document with a specific ID using PUT instead of POST.

LANGUAGE: json
CODE:
PUT movies/_doc/1
{ "title": "Spirited Away" }

----------------------------------------

TITLE: Analyzing Text with Custom Whitespace Analyzer in OpenSearch
DESCRIPTION: This snippet shows how to use the _analyze API to examine the tokens generated by the custom whitespace analyzer. It sends a POST request to analyze the text 'The SLOW turtle swims away! 123' using the 'my_custom_whitespace_analyzer'.

LANGUAGE: json
CODE:
POST /my_custom_whitespace_index/_analyze
{
  "analyzer": "my_custom_whitespace_analyzer",
  "text": "The SLOW turtle swims away! 123"
}

----------------------------------------

TITLE: Setting Permissions for IAM Role in Account B
DESCRIPTION: Configures permissions for the IAM role in Account B, granting access to invoke the Bedrock Titan embedding model.

LANGUAGE: json
CODE:
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Action": [
                "bedrock:InvokeModel"
            ],
            "Effect": "Allow",
            "Resource": "arn:aws:bedrock:*::foundation-model/amazon.titan-embed-text-v1"
        }
    ]
}

----------------------------------------

TITLE: Rate Limiting Inference Calls for a Model in OpenSearch
DESCRIPTION: Example request to set a rate limit of 4 Predict API calls per minute for a specific model.

LANGUAGE: json
CODE:
PUT /_plugins/_ml/models/T_S-cY0BKCJ3ot9qr0aP
{
  "rate_limiter": {
    "limit": "4",
    "unit": "MINUTES"
  }
}

----------------------------------------

TITLE: Using _explain API for Query Debugging
DESCRIPTION: Shows how to use the _explain API to view the translated query for troubleshooting purposes.

LANGUAGE: json
CODE:
POST _plugins/_sql/_explain
{
  "query": "SELECT * FROM my-index LIMIT  50"
}

----------------------------------------

TITLE: Configuring a Custom Keyword Analyzer in OpenSearch
DESCRIPTION: This snippet shows how to configure an index with a custom analyzer that is equivalent to the built-in keyword analyzer. It creates a new index named 'my_custom_keyword_index' with a custom analyzer called 'my_keyword_analyzer'.

LANGUAGE: json
CODE:
PUT /my_custom_keyword_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_keyword_analyzer": {
          "tokenizer": "keyword"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Disabling Performance Analyzer
DESCRIPTION: Series of commands to disable and uninstall the Performance Analyzer plugin.

LANGUAGE: bash
CODE:
curl -XPOST localhost:9200/_plugins/_performanceanalyzer/rca/cluster/config -H 'Content-Type: application/json' -d '{"enabled": false}'

LANGUAGE: bash
CODE:
kill $(ps aux | grep -i 'PerformanceAnalyzerApp' | grep -v grep | awk '{print $2}')

LANGUAGE: bash
CODE:
curl -XPOST localhost:9200/_plugins/_performanceanalyzer/cluster/config -H 'Content-Type: application/json' -d '{"enabled": false}'

LANGUAGE: bash
CODE:
bin/opensearch-plugin remove opensearch-performance-analyzer

----------------------------------------

TITLE: Creating Index with Synonym Filter (WordNet Format) in OpenSearch
DESCRIPTION: This example creates a new index named 'my-wordnet-index' and configures an analyzer with a synonym filter using the WordNet rule format. It demonstrates how to set up synonym rules for words like 'fast', 'quick', and 'swift'.

LANGUAGE: json
CODE:
PUT /my-wordnet-index
{
  "settings": {
    "analysis": {
      "filter": {
        "my_wordnet_synonym_filter": {
          "type": "synonym",
          "format": "wordnet",
          "synonyms": [
            "s(100000001,1,'fast',v,1,0).",
            "s(100000001,2,'quick',v,1,0).",
            "s(100000001,3,'swift',v,1,0)."
          ]
        }
      },
      "analyzer": {
        "my_wordnet_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "my_wordnet_synonym_filter"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Specifying Search Analyzer for Field in OpenSearch Index Mapping (JSON)
DESCRIPTION: This snippet shows how to specify both an index analyzer and a search analyzer for a text field when creating index mappings in OpenSearch. It uses the 'simple' analyzer for indexing and the 'whitespace' analyzer for searching on the 'text_entry' field.

LANGUAGE: json
CODE:
PUT testindex
{
  "mappings": {
    "properties": {
      "text_entry": {
        "type": "text",
        "analyzer": "simple",
        "search_analyzer": "whitespace"
      }
    }
  }
}

----------------------------------------

TITLE: Get All Memories with Pagination Example
DESCRIPTION: Example request demonstrating pagination parameters for retrieving a subset of memories.

LANGUAGE: json
CODE:
GET /_plugins/_ml/memory?max_results=2&next_token=1

----------------------------------------

TITLE: Running OpenSearch Ansible Playbook
DESCRIPTION: Command to run the Ansible playbook with root privileges, setting passwords for reserved users.

LANGUAGE: bash
CODE:
ansible-playbook -i inventories/opensearch/hosts opensearch.yml --extra-vars "admin_password=Test@123 kibanaserver_password=Test@6789 logstash_password=Test@456"

----------------------------------------

TITLE: Configuring otel_trace_group Processor for OpenSearch in YAML
DESCRIPTION: Example YAML configuration for the otel_trace_group processor when connecting to an OpenSearch cluster using username and password authentication.

LANGUAGE: yaml
CODE:
pipeline:
  ...
  processor:
    - otel_trace_group:
        hosts: ["https://localhost:9200"]
        cert: path/to/cert
        username: YOUR_USERNAME_HERE
        password: YOUR_PASSWORD_HERE

----------------------------------------

TITLE: Example Response for Get Agent API in OpenSearch
DESCRIPTION: This snippet illustrates the response structure when retrieving agent information. It includes details such as the agent's name, type, description, tools, and timestamps for creation and last update.

LANGUAGE: json
CODE:
{
  "name": "Test_Agent_For_RAG",
  "type": "flow",
  "description": "this is a test agent",
  "tools": [
    {
      "type": "VectorDBTool",
      "parameters": {
        "input": "${parameters.question}",
        "source_field": """["text"]""",
        "embedding_field": "embedding",
        "index": "my_test_data",
        "model_id": "zBRyYIsBls05QaITo5ex"
      },
      "include_output_in_agent_response": false
    },
    {
      "type": "MLModelTool",
      "description": "A general tool to answer any question",
      "parameters": {
        "model_id": "ygAzT40Bdo8gePIqxk0H",
        "prompt": """

H:You are a professional data analyst. You will always answer question based on the given context first. If the answer is not directly shown in the context, you will analyze the data and find the answer. If you don't know the answer, just say don't know. 

 Context:
${parameters.VectorDBTool.output}

H:${parameters.question}

A:"""
      },
      "include_output_in_agent_response": false
    }
  ],
  "created_time": 1706821658743,
  "last_updated_time": 1706821658743
}

----------------------------------------

TITLE: Restoring All Shards from Remote Backup
DESCRIPTION: cURL command to restore all shards of a given index from remote backup using the REST API with authentication.

LANGUAGE: bash
CODE:
curl -X POST "https://localhost:9200/_remotestore/_restore?restore_all_shards=true" -ku admin:<custom-admin-password> -H 'Content-Type: application/json' -d'
{
  "indices": ["my-index"]
}
'

----------------------------------------

TITLE: Analyzing Windows-Style Paths
DESCRIPTION: Demonstrates analysis of Windows-style file paths using custom delimiter configuration.

LANGUAGE: json
CODE:
POST /my_index/_analyze
{
  "analyzer": "my_path_analyzer",
  "text": "C:\\users\\john\\documents\\report.txt"
}

----------------------------------------

TITLE: Example Response for Open Index API in OpenSearch
DESCRIPTION: This snippet shows the expected JSON response when successfully opening an index using the Open Index API in OpenSearch.

LANGUAGE: json
CODE:
{
  "acknowledged": true,
  "shards_acknowledged": true
}

----------------------------------------

TITLE: Creating Ingest Pipeline with Text/Image Embedding
DESCRIPTION: Example of creating an ingest pipeline that converts text from image_description and image from image_binary into vector embeddings stored in vector_embedding field.

LANGUAGE: json
CODE:
{
  "description": "A text/image embedding pipeline",
  "processors": [
    {
      "text_image_embedding": {
        "model_id": "bQ1J8ooBpBj3wT4HVUsb",
        "embedding": "vector_embedding",
        "field_map": {
          "text": "image_description",
          "image": "image_binary"
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Installing ingest-attachment plugin in OpenSearch
DESCRIPTION: Command to install the ingest-attachment plugin using the OpenSearch plugin installer.

LANGUAGE: sh
CODE:
./bin/opensearch-plugin install ingest-attachment

----------------------------------------

TITLE: Testing Uppercase Pipeline in OpenSearch
DESCRIPTION: Example of testing the uppercase pipeline using the simulate API with a sample document.

LANGUAGE: json
CODE:
{
  "docs": [
    {
      "_index": "testindex1",
      "_id": "1",
      "_source": {
        "name": "John"
      }
    }
  ]
}

----------------------------------------

TITLE: Multi-get Request with Index in Body
DESCRIPTION: Example of a multi-get request in OpenSearch where the index is specified in the request body. Demonstrates retrieving documents from multiple indexes with source field filtering.

LANGUAGE: json
CODE:
GET _mget
{
  "docs": [
  {
    "_index": "sample-index1",
    "_id": "1"
  },
  {
    "_index": "sample-index2",
    "_id": "1",
    "_source": {
      "include": ["Length"]
    }
  }
  ]
}

----------------------------------------

TITLE: Deleting a Model using OpenSearch ML Commons API
DESCRIPTION: This endpoint deletes a model based on the provided model_id. It returns details about the deletion operation including the index, version, and shard information.

LANGUAGE: json
CODE:
DELETE /_plugins/_ml/models/<model_id>

----------------------------------------

TITLE: Combined Static and Regex Mappings Configuration
DESCRIPTION: Advanced configuration demonstrating how to combine both static and regex-based mappings for different indexes in a single migration.

LANGUAGE: json
CODE:
[
  {
    "TypeMappingSanitizationTransformerProvider": {
      "staticMappings": {
        "activity": {
          "user": "users_activity",
          "post": "posts_activity"
        },
        "logs": {
          "error": "logs_error",
          "info": "logs_info"
        }
      },
      "regexMappings": [
        {
          "sourceIndexPattern": "orders.*",
          "sourceTypePattern": ".*",
          "targetIndexPattern": "all_orders"
        }
      ],
      "sourceProperties": {
        "version": {
          "major": 6,
          "minor": 8
        }
      }
    }
  }
]

----------------------------------------

TITLE: Creating New ML Controller
DESCRIPTION: Example request for creating a new controller with rate limits for multiple users.

LANGUAGE: json
CODE:
POST _plugins/_ml/controllers/mtw-ZI0B_1JGmyB068C0\n{\n  "user_rate_limiter": {\n    "user1": {\n      "limit": 4,\n      "unit": "MINUTES"\n    },\n    "user2": {\n      "limit": 4,\n      "unit": "MINUTES"\n    }\n  }\n}

----------------------------------------

TITLE: Get Memory by ID Example Request
DESCRIPTION: Example request for retrieving a specific memory using its ID.

LANGUAGE: json
CODE:
GET /_plugins/_ml/memory/N8AE1osB0jLkkocYjz7D

----------------------------------------

TITLE: ASCII Folding Analysis Response
DESCRIPTION: Shows the response from the analyze API, displaying both original and ASCII-folded tokens generated by the analyzer.

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "resume",
      "start_offset": 0,
      "end_offset": 6,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "rsum",
      "start_offset": 0,
      "end_offset": 6,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "cafe",
      "start_offset": 7,
      "end_offset": 11,
      "type": "<ALPHANUM>",
      "position": 1
    },
    {
      "token": "caf",
      "start_offset": 7,
      "end_offset": 11,
      "type": "<ALPHANUM>",
      "position": 1
    },
    {
      "token": "naive",
      "start_offset": 12,
      "end_offset": 17,
      "type": "<ALPHANUM>",
      "position": 2
    },
    {
      "token": "nave",
      "start_offset": 12,
      "end_offset": 17,
      "type": "<ALPHANUM>",
      "position": 2
    },
    {
      "token": "coordinate",
      "start_offset": 18,
      "end_offset": 28,
      "type": "<ALPHANUM>",
      "position": 3
    },
    {
      "token": "cordinate",
      "start_offset": 18,
      "end_offset": 28,
      "type": "<ALPHANUM>",
      "position": 3
    }
  ]
}

----------------------------------------

TITLE: Update Tenant Configuration API Call
DESCRIPTION: REST API endpoint to update multi-tenancy configuration settings with a PUT request.

LANGUAGE: json
CODE:
PUT /_plugins/_security/api/tenancy/config
{
    "default_tenant": "custom tenant 1",
    "private_tenant_enabled": false,
    "mulitenancy_enabled": true
}

----------------------------------------

TITLE: Querying with Delimited Identifiers in PPL (OpenSearch)
DESCRIPTION: This PPL query shows how to use delimited identifiers with back ticks. The index name 'accounts' and the field 'account_number' are enclosed in back ticks to handle special characters or reserved keywords.

LANGUAGE: sql
CODE:
source=`accounts` | fields `account_number`;

----------------------------------------

TITLE: Configuring In-Memory Metrics Storage in OpenSearch Benchmark
DESCRIPTION: Configuration settings for storing OpenSearch Benchmark metrics in memory. Defines parameters like host, port, security settings, and authentication details in the benchmark.ini file.

LANGUAGE: ini
CODE:
[results_publishing]
datastore.type = in-memory
datastore.host = <host-url>
datastore.port = <host-port>
datastore.secure = False
datastore.ssl.verification_mode = <ssl-verification-details>
datastore.user = <username>
datastore.password = <password>

----------------------------------------

TITLE: Accessing OpenSearch via curl
DESCRIPTION: Example curl command to access OpenSearch after deployment, using the admin credentials.

LANGUAGE: bash
CODE:
curl https://localhost:9200 -u 'admin:Test@123' --insecure

----------------------------------------

TITLE: Amazon OpenSearch Service Connection
DESCRIPTION: Configuration for connecting to Amazon OpenSearch Service using AWS SigV4 authentication

LANGUAGE: ruby
CODE:
require 'opensearch-aws-sigv4'
require 'aws-sigv4'

signer = Aws::Sigv4::Signer.new(service: 'es',
                                region: 'us-west-2',
                                access_key_id: 'key_id',
                                secret_access_key: 'secret')

client = OpenSearch::Aws::Sigv4Client.new({
    host: 'https://your.amz-managed-opensearch.domain',
    log: true
}, signer)

----------------------------------------

TITLE: Running OpenSearch Dashboards (Bash)
DESCRIPTION: This command starts the OpenSearch Dashboards application after installation and optional configuration.

LANGUAGE: bash
CODE:
./bin/opensearch-dashboards

----------------------------------------

TITLE: Ingesting a Document with Grok Processor Pipeline in OpenSearch
DESCRIPTION: This snippet demonstrates how to ingest a document into an index named 'testindex1' using the 'log_line' pipeline.

LANGUAGE: json
CODE:
PUT testindex1/_doc/1?pipeline=log_line
{
  "message": "127.0.0.1 198.126.12 10/Oct/2000:13:55:36 -0700 200"
}

----------------------------------------

TITLE: Configuring Basic Event Aggregation Pipeline in OpenSearch Data Prepper
DESCRIPTION: This snippet demonstrates a basic pipeline configuration that uses the grok processor to extract fields and the aggregate processor to combine events over a 30-second period. The aggregated logs are then sent to an OpenSearch sink.

LANGUAGE: json
CODE:
{
  "aggregate_pipeline": {
    "source": {
      "http": {
        "path": "/${pipelineName}/logs"
      }
    },
    "processor": [
      {
        "grok": {
          "match": {
            "log": ["%{IPORHOST:sourceIp} %{IPORHOST:destinationIp} %{NUMBER:port:int}"]
          }
        }
      },
      {
        "aggregate": {
          "group_duration": "30s",
          "identification_keys": ["sourceIp", "destinationIp", "port"],
          "action": {
            "put_all": null
          }
        }
      }
    ],
    "sink": [
      {
        "opensearch": {
          "index": "aggregated_logs"
        }
      }
    ]
  }
}

----------------------------------------

TITLE: Synchronous Training Response
DESCRIPTION: Example response for a synchronous training request, returning the model_id and completion status.

LANGUAGE: json
CODE:
{
  "model_id" : "lblVmX8BO5w8y8RaYYvN",
  "status" : "COMPLETED"
}

----------------------------------------

TITLE: Querying zero-result searches on server-side
DESCRIPTION: SQL query to find all searches that returned no results by checking for null query_response_hit_ids in the ubi_queries table.

LANGUAGE: sql
CODE:
select
   count(*)
from ubi_queries 
where query_response_hit_ids is null

----------------------------------------

TITLE: Analyzing Text with Standard Tokenizer - OpenSearch JSON
DESCRIPTION: Example request to analyze text using the configured standard analyzer, demonstrating how the tokenizer breaks down text into individual tokens.

LANGUAGE: json
CODE:
POST /my_index/_analyze
{
  "analyzer": "my_standard_analyzer",
  "text": "OpenSearch is powerful, fast, and scalable."
}

----------------------------------------

TITLE: Querying XY Shapes Using Envelope in OpenSearch
DESCRIPTION: Demonstrates how to search for documents using an envelope shape as the query boundary.

LANGUAGE: json
CODE:
GET testindex/_search
{
  "query": {
    "xy_shape": {
      "geometry": {
        "shape": {
          "type": "envelope",
          "coordinates": [ [ 0.0, 6.0], [ 4.0, 2.0] ]
        },
        "relation": "WITHIN"
      }
    }
  }
}

----------------------------------------

TITLE: Indexing Document with Custom Date Format
DESCRIPTION: Example showing how to index a document with a date using the custom MM/dd/yyyy format.

LANGUAGE: json
CODE:
PUT testindex/_doc/21 
{
  "release_date" : "03/21/2019"
}

----------------------------------------

TITLE: Analyzing Text with Latvian Analyzer in OpenSearch
DESCRIPTION: This snippet shows how to analyze a Latvian text using the Latvian analyzer and examine the generated tokens in OpenSearch.

LANGUAGE: json
CODE:
POST /latvian-index/_analyze
{
  "field": "content",
  "text": "Studenti mcs Latvijas universitts. Viu numuri ir 123456."
}

----------------------------------------

TITLE: Creating Security Detector
DESCRIPTION: Creates a new security detector with specified configuration including rules, triggers and alert actions. Requires detector type, name, schedule and input configuration.

LANGUAGE: json
CODE:
POST _plugins/_security_analytics/detectors
{
  "enabled": true,
  "schedule": {
    "period": {
      "interval": 1,
      "unit": "MINUTES"
    }
  },
  "detector_type": "WINDOWS",
  "type": "detector",
  "inputs": [
    {
      "detector_input": {
        "description": "windows detector for security analytics",
        "custom_rules": [
          {
            "id": "bc2RB4QBrbtylUb_1Pbm"
          }
        ],
        "indices": [
          "windows"
        ],
        "pre_packaged_rules": [
          {
            "id": "06724a9a-52fc-11ed-bdc3-0242ac120002"
          }
        ]
      }
    }
  ],
  "triggers": [
    {
      "ids": [
        "06724a9a-52fc-11ed-bdc3-0242ac120002"
      ],
      "types": [],
      "tags": [
        "attack.defense_evasion"
      ],
      "severity": "1",
      "actions": [{
          "id": "hVTLkZYzlA",
          "destination_id": "6r8ZBoQBKW_6dKriacQb",
          "subject_template": {
            "source": "Trigger: {{ctx.trigger.name}}",
            "lang": "mustache"
          },
          "name": "hello_world",
          "throttle_enabled": false,
          "message_template": {
            "source": "Detector {{ctx.detector.name}} just entered alert status. Please investigate the issue." +
            "- Trigger: {{ctx.trigger.name}}" +
            "- Severity: {{ctx.trigger.severity}}",
            "lang": "mustache"
          },
          "throttle": {
            "unit": "MINUTES",
            "value": 108
          }
        }
      ],
      "id": "8qhrBoQBYK1JzUUDzH-N",
      "sev_levels": [],
      "name": "test-trigger"
    }
  ],
  "name": "nbReFCjlfn"
}

----------------------------------------

TITLE: Basic Trim Processor Configuration
DESCRIPTION: Basic syntax for configuring the trim processor with required field parameters.

LANGUAGE: json
CODE:
{
  "trim": {
    "field": "field_to_trim",
    "target_field": "trimmed_field"
  }
}

----------------------------------------

TITLE: Creating Set Processor Pipeline
DESCRIPTION: Example of creating a pipeline with a Set processor to add a new field with a specified value.

LANGUAGE: json
CODE:
PUT _ingest/pipeline/set-pipeline
{
  "description": "Adds a new field 'new_field' with the value 'some_value'",
  "processors": [
    {
      "set": {
        "field": "new_field",
        "value": "some_value"
      }
    }
  ]
}

----------------------------------------

TITLE: Configuring Pipeline Source in YAML
DESCRIPTION: Example configuration for a pipeline source that reads from another named pipeline. The configuration shows how to set up a sample-pipeline that reads from a pipeline named 'movies'.

LANGUAGE: yaml
CODE:
sample-pipeline:
  source:
    - pipeline:
        name: "movies"

----------------------------------------

TITLE: Updating Model TTL Settings - OpenSearch ML Model Update
DESCRIPTION: Request for updating an existing undeployed model with new TTL settings.

LANGUAGE: json
CODE:
PUT /_plugins/_ml/models/COj7K48BZzNMh1sWedLK
{
    "deploy_setting": {"model_ttl_minutes" : 100}
}

----------------------------------------

TITLE: Executing a Search with Personalized Ranking Pipeline in OpenSearch
DESCRIPTION: This snippet shows how to perform a search using a pipeline with personalized ranking. It includes the search query for comedies and specifies additional parameters for Amazon Personalize, such as user ID and context information.

LANGUAGE: json
CODE:
GET /movies/_search?search_pipeline=my-pipeline
{
  "query": {
    "multi_match": {
      "query": "Comedy",
      "fields": ["GENRES"]
    }
  },
  "ext": {
    "personalize_request_parameters": {
      "user_id": "user ID",
      "context": { "DEVICE" : "mobile phone" }
    }
  }
}

----------------------------------------

TITLE: Executing ML Model Agent in OpenSearch
DESCRIPTION: This snippet shows how to execute the previously registered agent with a specific question. It demonstrates the use of the agent ID and the question parameter in the request body.

LANGUAGE: json
CODE:
POST /_plugins/_ml/agents/9X7xWI0Bpc3sThaJdY9i/_execute
{
  "parameters": {
    "question": "what's the population increase of Seattle from 2021 to 2023"
  }
}

----------------------------------------

TITLE: Configuring IAM Permissions for Data Prepper S3 Access
DESCRIPTION: IAM policy configuration that grants Data Prepper the necessary permissions to access S3 objects, SQS queues, and KMS encryption.

LANGUAGE: json
CODE:
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "s3-access",
            "Effect": "Allow",
            "Action": "s3:GetObject",
            "Resource": "arn:aws:s3:::<YOUR-BUCKET>/*"
        },
        {
            "Sid": "sqs-access",
            "Effect": "Allow",
            "Action": [
                "sqs:DeleteMessage",
                "sqs:ReceiveMessage"
            ],
            "Resource": "arn:aws:sqs:<YOUR-REGION>:<123456789012>:<YOUR-SQS-QUEUE>"
        },
        {
            "Sid": "kms-access",
            "Effect": "Allow",
            "Action": "kms:Decrypt",
            "Resource": "arn:aws:kms:<YOUR-REGION>:<123456789012>:key/<YOUR-KMS-KEY>"
        }
    ]
}

----------------------------------------

TITLE: Deploying an Externally Hosted Model in OpenSearch
DESCRIPTION: POST request to deploy a registered external model.

LANGUAGE: bash
CODE:
POST /_plugins/_ml/models/cleMb4kBJ1eYAeTMFFg4/_deploy

----------------------------------------

TITLE: Registering File System Repository via REST API
DESCRIPTION: JSON request to register a file system repository using the OpenSearch REST API.

LANGUAGE: json
CODE:
PUT /_snapshot/my-fs-repository
{
  "type": "fs",
  "settings": {
    "location": "/mnt/snapshots"
  }
}

----------------------------------------

TITLE: Expanded Wildcard Stats Query
DESCRIPTION: Retrieves stats with expanded wildcard options for open and hidden indexes

LANGUAGE: json
CODE:
GET /testindex*/_stats?expand_wildcards=open,hidden

----------------------------------------

TITLE: Example GET Request for Retrieving Specific Model in OpenSearch
DESCRIPTION: Shows a concrete example of a GET request to retrieve information for a specific model using its model_id. This request is used in the OpenSearch ML Commons API.

LANGUAGE: json
CODE:
GET /_plugins/_ml/models/N8AE1osB0jLkkocYjz7D

----------------------------------------

TITLE: Template Query with ML Inference for Vector Search
DESCRIPTION: Executes a template query that uses ML inference to generate vector embeddings and perform k-NN search.

LANGUAGE: json
CODE:
GET /template-knn-1/_search?search_pipeline=my_knn_pipeline
{
  "query": {
    "template": {
      "knn": {
        "text_embedding": {
          "vector": "${text_embedding}",
          "k": 2
        }
      }
    }
  },
  "ext": {
    "ml_inference": {
      "text": "sneakers"
    }
  }
}

----------------------------------------

TITLE: Testing Pipeline with Sample Document
DESCRIPTION: Example request to test the text/image embedding pipeline with a sample document containing image description and binary data.

LANGUAGE: json
CODE:
{
  "docs": [
    {
      "_index": "testindex1",
      "_id": "1",
      "_source":{
         "image_description": "Orange table",
         "image_binary": "bGlkaHQtd29rfx43..."
      }
    }
  ]
}

----------------------------------------

TITLE: Creating a Grok Processor Pipeline with Custom Patterns in OpenSearch
DESCRIPTION: This snippet shows how to create a pipeline with custom grok patterns for parsing specific log formats.

LANGUAGE: json
CODE:
PUT _ingest/pipeline/log_line
{
  "processors": [
    {
      "grok": {
        "field": "message",
        "patterns": ["The issue number %{NUMBER:issue_number} is %{STATUS:status}"],
        "pattern_definitions" : {
          "NUMBER" : "\\d{3,4}",
          "STATUS" : "open|closed"
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Indexing Spatial Data Documents
DESCRIPTION: Bulk indexes multiple restaurant documents with location data using geo_point coordinates.

LANGUAGE: json
CODE:
POST /restaurants/_bulk?refresh
{"index": {"_id": 1}}
{"name": "Cafe Delish", "location": "40.7128, -74.0059"}
{"index": {"_id": 2}}
{"name": "Tasty Bites", "location": "51.5074, -0.1278"}
{"index": {"_id": 3}}
{"name": "Sushi Palace", "location": "48.8566, 2.3522"}
{"index": {"_id": 4}}
{"name": "Burger Joint", "location": "34.0522, -118.2437"}

----------------------------------------

TITLE: Clearing Fields Cache in OpenSearch
DESCRIPTION: Example request to clear only the fields cache for a specific index in OpenSearch.

LANGUAGE: json
CODE:
POST /my-index/_cache/clear?fielddata=true

----------------------------------------

TITLE: Retrieving Specific Field Data in OpenSearch
DESCRIPTION: This request retrieves field data for a specific field with verbose output. Replace <field_name> with the desired field name.

LANGUAGE: json
CODE:
GET _cat/fielddata/<field_name>?v

----------------------------------------

TITLE: Executing OpenSearch Benchmark Test on External Cluster
DESCRIPTION: Template command for running nyc_taxis workload on an external OpenSearch cluster with customizable endpoint and authentication

LANGUAGE: bash
CODE:
opensearch-benchmark execute-test --pipeline=benchmark-only --workload=nyc_taxis --target-host=<OpenSearch Cluster Endpoint> --client-options=basic_auth_user:admin,basic_auth_password:admin

----------------------------------------

TITLE: Register Default Private Model Group
DESCRIPTION: Example request for registering a model group without specifying access mode, defaulting to private

LANGUAGE: json
CODE:
{
    "name": "model_group_test",
    "description": "This is an example description"
}

----------------------------------------

TITLE: Analyzing Text with Custom HTML Strip Analyzer Preserving Tags in OpenSearch
DESCRIPTION: This snippet demonstrates how to use the custom analyzer that preserves specific HTML tags while stripping others from the input text.

LANGUAGE: json
CODE:
GET /html_strip_preserve_analyzer/_analyze
{
  "analyzer": "html_strip_analyzer",
  "text": "<p>This is a <b>bold</b> and <i>italic</i> text.</p>"
}

----------------------------------------

TITLE: Adding Field to Additional Info - JSON
DESCRIPTION: Example request showing how to add a new field to the additional_info object of an existing message.

LANGUAGE: json
CODE:
PUT /_plugins/_ml/memory/message/WnA3cY0BfUsSoeNTI-_J
{
  "additional_info": {
    "feedback": "positive"
  }
}

----------------------------------------

TITLE: Basic Join Operation with Default Delimiter
DESCRIPTION: Demonstrates joining list elements using the default comma delimiter. The function accepts a JSON pointer to a list or map containing lists and joins the elements into strings.

LANGUAGE: json
CODE:
{"source": [1, 2, 3]}

----------------------------------------

TITLE: Group-Based ACL Permissions Example
DESCRIPTION: Shows how to grant specific permissions to different finance groups, with workspace management for finance managers and dashboard creation for analysts.

LANGUAGE: json
CODE:
{
  "permissions": {
    "write": {
        "groups": ["finance_manager"]
    },
    "library_write": {
        "groups": ["finance_analyst"]
    }
  } 
}

----------------------------------------

TITLE: Setting Throttling Limits in OpenSearch Cluster Settings
DESCRIPTION: This JSON request demonstrates how to set throttling limits for cluster manager tasks using the OpenSearch cluster settings API. It specifies the task type and the maximum number of tasks allowed in the pending queue.

LANGUAGE: json
CODE:
PUT _cluster/settings
{
  "persistent": {
    "cluster_manager.throttling.thresholds" : {
      "<task-type>" : {
          "value" : <threshold limit>
      }
    }
  }
}

----------------------------------------

TITLE: Setting Throttling Limits in OpenSearch Cluster Settings
DESCRIPTION: This JSON request demonstrates how to set throttling limits for cluster manager tasks using the OpenSearch cluster settings API. It specifies the task type and the maximum number of tasks allowed in the pending queue.

LANGUAGE: json
CODE:
PUT _cluster/settings
{
  "persistent": {
    "cluster_manager.throttling.thresholds" : {
      "<task-type>" : {
          "value" : <threshold limit>
      }
    }
  }
}

----------------------------------------

TITLE: Querying Cluster Allocation Endpoints
DESCRIPTION: Basic endpoints for retrieving cluster allocation explanations. Supports both GET and POST methods.

LANGUAGE: json
CODE:
GET _cluster/allocation/explain
POST _cluster/allocation/explain

----------------------------------------

TITLE: Sending Report via SMTP
DESCRIPTION: Command to send a report using SMTP transport with environment variables

LANGUAGE: bash
CODE:
opensearch-reporting-cli --url https://localhost:5601/app/dashboards#/view/7adfa750-4c81-11e8-b3d7-01146121b73d --transport smtp --from <sender_email_id> --to <recipient_email_id>

----------------------------------------

TITLE: Updating frame-ancestors in CSP rules using cURL
DESCRIPTION: cURL command to update the frame-ancestors directive in CSP rules. This allows dynamic configuration of site embedding for OpenSearch Dashboards without server restart.

LANGUAGE: bash
CODE:
curl '{osd endpoint}/api/appconfig/csp.rules.frame-ancestors' -X POST -H 'Accept: application/json' -H 'Content-Type: application/json' -H 'osd-xsrf: osd-fetch' -H 'Sec-Fetch-Dest: empty' --data-raw '{"newValue":"{new site}"}'

----------------------------------------

TITLE: Executing PPLTool Agent in OpenSearch
DESCRIPTION: This JSON request executes the PPLTool agent. It provides the agent ID, question, and index name for the query.

LANGUAGE: json
CODE:
POST /_plugins/_ml/agents/9X7xWI0Bpc3sThaJdY9i/_execute
{
  "parameters": {
    "verbose": true,
    "question": "what is the error rate yesterday",
    "index": "opensearch_dashboards_sample_data_logs"
  }
}

----------------------------------------

TITLE: Single File Batch Ingestion Request
DESCRIPTION: API request to ingest embeddings from a single S3 file into OpenSearch. Maps source file fields to index fields and includes AWS credentials for authentication.

LANGUAGE: json
CODE:
{
  "index_name": "my-nlp-index",
  "field_map": {
    "chapter": "$.content[0]",
    "title": "$.content[1]",
    "chapter_embedding": "$.SageMakerOutput[0]",
    "title_embedding": "$.SageMakerOutput[1]",
    "_id": "$.id"
  },
  "ingest_fields": ["$.id"],
  "credential": {
    "region": "us-east-1",
    "access_key": "<your access key>",
    "secret_key": "<your secret key>",
    "session_token": "<your session token>"
  },
  "data_source": {
    "type": "s3",
    "source": ["s3://offlinebatch/output/sagemaker_batch.json.out"]
  }
}

----------------------------------------

TITLE: Creating an Index with Pattern Replace Filter in OpenSearch
DESCRIPTION: This example creates a new index named 'text_index' with a custom analyzer that uses a pattern_replace filter to replace digits with '[NUM]'.

LANGUAGE: json
CODE:
PUT /text_index
{
  "settings": {
    "analysis": {
      "filter": {
        "number_replace_filter": {
          "type": "pattern_replace",
          "pattern": "\\d+",
          "replacement": "[NUM]"
        }
      },
      "analyzer": {
        "number_analyzer": {
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "number_replace_filter"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Searching Specific Fields With Pipeline
DESCRIPTION: Search query specifying fields to return while using the sort pipeline.

LANGUAGE: json
CODE:
POST /my_index/_search?pretty&search_pipeline=my_pipeline
{
    "fields": ["visibility", "message"]
}

----------------------------------------

TITLE: Creating SageMaker Model Connector in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a connector for a model hosted on Amazon SageMaker using the OpenSearch API. It includes configuration for AWS credentials, region, and the SageMaker endpoint.

LANGUAGE: json
CODE:
POST /_plugins/_ml/connectors/_create
{
  "name": "sagemaker model",
  "description": "Test connector for Sagemaker model",
  "version": 1,
  "protocol": "aws_sigv4",
  "credential": {
    "access_key": "<YOUR ACCESS KEY>",
    "secret_key": "<YOUR SECRET KEY>"
  },
  "parameters": {
    "region": "us-east-1",
    "service_name": "sagemaker"
  },
  "actions": [
    {
      "action_type": "predict",
      "method": "POST",
      "headers": {
        "content-type": "application/json"
      },
      "url": "<YOUR SAGEMAKER ENDPOINT>",
      "request_body": "{\"prompt\":\"${parameters.prompt}\"}"
    }
  ]
}

----------------------------------------

TITLE: RCA API JSON Response Structure for Performance Analyzer
DESCRIPTION: Example JSON response from the RCA API, showing the structure of RCA data. Includes cluster-level and node-level information about heap usage, resource summaries, and top consumers.

LANGUAGE: json
CODE:
{
  "HighHeapUsageClusterRca": [{
    "rca_name": "HighHeapUsageClusterRca",
    "state": "unhealthy",
    "timestamp": 1587426650942,
    "HotClusterSummary": [{
      "number_of_nodes": 2,
      "number_of_unhealthy_nodes": 1,
      "HotNodeSummary": [{
        "host_address": "192.168.144.2",
        "node_id": "JtlEoRowSI6iNpzpjlbp_Q",
        "HotResourceSummary": [{
          "resource_type": "old gen",
          "threshold": 0.65,
          "value": 0.81827232588145373,
          "avg": NaN,
          "max": NaN,
          "min": NaN,
          "unit_type": "heap usage in percentage",
          "time_period_seconds": 600,
          "TopConsumerSummary": [{
              "name": "CACHE_FIELDDATA_SIZE",
              "value": 590702564
            },
            {
              "name": "CACHE_REQUEST_SIZE",
              "value": 28375
            },
            {
              "name": "CACHE_QUERY_SIZE",
              "value": 12687
            }
          ],
        }]
      }]
    }]
  }]
}

----------------------------------------

TITLE: Mapping Okta Fields to ECS Schema in JSON
DESCRIPTION: Defines the mapping configuration between raw Okta event fields and their corresponding ECS (Elastic Common Schema) fields. Maps eventtype to okta.event_type and displaymessage to okta.display_message.

LANGUAGE: json
CODE:
  "mappings": [
    {
      "raw_field":"eventtype",
      "ecs":"okta.event_type"
    },
    {
      "raw_field":"displaymessage",
      "ecs":"okta.display_message"
    }
  ]

----------------------------------------

TITLE: Disabling PPL in OpenSearch Cluster Settings
DESCRIPTION: Shows an alternative format for updating cluster settings, specifically disabling the PPL (Piped Processing Language) plugin.

LANGUAGE: json
CODE:
PUT _cluster/settings
{
  "transient": {
    "plugins": {
      "ppl": {
        "enabled": "false"
      }
    }
  }
}

----------------------------------------

TITLE: Configuring cross-cluster search role in YAML
DESCRIPTION: Example YAML configuration for setting up a role with cross-cluster search permissions in OpenSearch.

LANGUAGE: yaml
CODE:
humanresources:
  cluster:
    - CLUSTER_COMPOSITE_OPS_RO
  indices:
    'humanresources':
      '*':
        - READ
        - indices:admin/shards/search_shards # needed when the search request includes parameter setting 'ccs_minimize_roundtrips=false'.

----------------------------------------

TITLE: Example Response for Get Model Request in OpenSearch
DESCRIPTION: Illustrates the structure and content of a typical response when retrieving model information using the ML Commons API in OpenSearch. It includes details such as model name, algorithm, state, and configuration.

LANGUAGE: json
CODE:
{
  "name" : "all-MiniLM-L6-v2_onnx",
  "algorithm" : "TEXT_EMBEDDING",
  "version" : "1",
  "model_format" : "TORCH_SCRIPT",
  "model_state" : "LOADED",
  "model_content_size_in_bytes" : 83408741,
  "model_content_hash_value" : "9376c2ebd7c83f99ec2526323786c348d2382e6d86576f750c89ea544d6bbb14",
  "model_config" : {
      "model_type" : "bert",
      "embedding_dimension" : 384,
      "framework_type" : "SENTENCE_TRANSFORMERS",
      "all_config" : "{\"_name_or_path\":\"nreimers/MiniLM-L6-H384-uncased\",\"architectures\":[\"BertModel\"],\"attention_probs_dropout_prob\":0.1,\"gradient_checkpointing\":false,\"hidden_act\":\"gelu\",\"hidden_dropout_prob\":0.1,\"hidden_size\":384,\"initializer_range\":0.02,\"intermediate_size\":1536,\"layer_norm_eps\":1e-12,\"max_position_embeddings\":512,\"model_type\":\"bert\",\"num_attention_heads\":12,\"num_hidden_layers\":6,\"pad_token_id\":0,\"position_embedding_type\":\"absolute\",\"transformers_version\":\"4.8.2\",\"type_vocab_size\":2,\"use_cache\":true,\"vocab_size\":30522}"
  },
  "created_time" : 1665961344044,
  "last_uploaded_time" : 1665961373000,
  "last_loaded_time" : 1665961815959,
  "total_chunks" : 9
}

----------------------------------------

TITLE: Configuring Basic Greek Analyzer in OpenSearch
DESCRIPTION: Shows how to apply the built-in Greek analyzer to a text field in an index mapping.

LANGUAGE: json
CODE:
PUT /greek-index
{
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "greek"
      }
    }
  }
}

----------------------------------------

TITLE: Filtered SQL Query
DESCRIPTION: Example of using the filter parameter to add additional query conditions.

LANGUAGE: json
CODE:
{
  "query" : "SELECT firstname, lastname, balance FROM accounts",
  "filter" : {
    "range" : {
      "balance" : {
        "lt" : 10000
      }
    }
  }
}

----------------------------------------

TITLE: Token Generation Result for Kuromoji Completion Filter in OpenSearch
DESCRIPTION: This snippet shows the response from the _analyze API, demonstrating the tokens generated by the kuromoji_completion filter. It includes the original Katakana words, their romanized versions, and variations of romanization for improved matching.

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "",
      "start_offset": 0,
      "end_offset": 7,
      "type": "word",
      "position": 0
    },
    {
      "token": "konpyuta",
      "start_offset": 0,
      "end_offset": 7,
      "type": "word",
      "position": 0
    },
    {
      "token": "konnpyuta",
      "start_offset": 0,
      "end_offset": 7,
      "type": "word",
      "position": 0
    },
    {
      "token": "",
      "start_offset": 7,
      "end_offset": 8,
      "type": "word",
      "position": 1
    },
    {
      "token": "wo",
      "start_offset": 7,
      "end_offset": 8,
      "type": "word",
      "position": 1
    },
    {
      "token": "o",
      "start_offset": 7,
      "end_offset": 8,
      "type": "word",
      "position": 1
    },
    {
      "token": "",
      "start_offset": 8,
      "end_offset": 10,
      "type": "word",
      "position": 2
    },
    {
      "token": "tukau",
      "start_offset": 8,
      "end_offset": 10,
      "type": "word",
      "position": 2
    },
    {
      "token": "tsukau",
      "start_offset": 8,
      "end_offset": 10,
      "type": "word",
      "position": 2
    }
  ]
}

----------------------------------------

TITLE: Sorting with Search After Parameter in OpenSearch
DESCRIPTION: This snippet demonstrates using the 'search_after' parameter for efficient pagination. It starts the search after the document with 'line_id' 3202 and 'speech_number' 8.

LANGUAGE: json
CODE:
GET shakespeare/_search
{
  "query": {
    "term": {
      "play_name": {
        "value": "Henry IV"
      }
    }
  },
  "sort": [
    {
      "line_id": {
        "order": "desc"
      }
    },
    {
      "speech_number": {
        "order": "desc"
      }
    }
  ],
  "search_after": [
    "3202",
    "8"
  ]
}

----------------------------------------

TITLE: Deploying Bedrock Model in OpenSearch
DESCRIPTION: Deploys the registered Bedrock model in OpenSearch, making it ready for use in embeddings generation.

LANGUAGE: json
CODE:
POST /_plugins/_ml/models/PEq3QY0BOhavBOmf1Sml/_deploy

----------------------------------------

TITLE: Configuring Jekyll 404 Page Front Matter
DESCRIPTION: YAML front matter configuration for a Jekyll-based 404 error page, setting up the page permalink, title, layout, and navigation options.

LANGUAGE: yaml
CODE:
---
permalink: /404.html
title: 404
layout: default
heading_anchors: false
nav_exclude: true
---

----------------------------------------

TITLE: Bulk Indexing Documents with Missing Values in OpenSearch
DESCRIPTION: Indexes five sample documents into the 'products' index using the bulk API. These documents have various combinations of missing values for 'rating' and 'num_reviews' fields to demonstrate handling of missing data in weighted average aggregation.

LANGUAGE: json
CODE:
POST /_bulk
{ "index": { "_index": "products" } }
{ "name": "Product A", "rating": 4.5, "num_reviews": 100 }
{ "index": { "_index": "products" } }
{ "name": "Product B", "rating": 3.8, "num_reviews": 50 }
{ "index": { "_index": "products" } }
{ "name": "Product C", "rating": null, "num_reviews": 20 }
{ "index": { "_index": "products" } }
{ "name": "Product D", "rating": 4.2, "num_reviews": null }
{ "index": { "_index": "products" } }
{ "name": "Product E", "rating": null, "num_reviews": null }

----------------------------------------

TITLE: Search Connector Endpoints
DESCRIPTION: The available REST endpoints for searching connectors in OpenSearch ML Commons.

LANGUAGE: json
CODE:
POST /_plugins/_ml/connectors/_search
GET /_plugins/_ml/connectors/_search

----------------------------------------

TITLE: Testing the URL decode pipeline in OpenSearch
DESCRIPTION: Demonstrates how to test the urldecode_pipeline using a sample document with an encoded URL.

LANGUAGE: json
CODE:
POST _ingest/pipeline/urldecode_pipeline/_simulate
{
  "docs": [
    {
      "_source": {
        "encoded_url": "https://example.com/search?q=hello%20world"
      }
    }
  ]
}

----------------------------------------

TITLE: Ingesting Document with Fail Processor Pipeline in OpenSearch
DESCRIPTION: This example shows how to ingest a document into an index named 'testindex1' using the 'fail-log-pipeline'. The ingestion is expected to fail due to the presence of sensitive information.

LANGUAGE: json
CODE:
PUT testindex1/_doc/1?pipeline=fail-log-pipeline  
{  
  "user_info": "Sensitive information including credit card"  
}

----------------------------------------

TITLE: Example Response for Reverse Nested Aggregation in OpenSearch
DESCRIPTION: This response shows the aggregation results for the reverse nested query. It displays the count of pages and their load times, grouped into buckets of 200ms and 500ms.

LANGUAGE: json
CODE:
...
"aggregations" : {
  "pages" : {
    "doc_count" : 2,
    "top_pages_per_load_time" : {
      "doc_count_error_upper_bound" : 0,
      "sum_other_doc_count" : 0,
      "buckets" : [
        {
          "key" : 200.0,
          "doc_count" : 1,
          "comment_to_logs" : {
            "doc_count" : 1,
            "min_load_time" : {
              "value" : null
            }
          }
        },
        {
          "key" : 500.0,
          "doc_count" : 1,
          "comment_to_logs" : {
            "doc_count" : 1,
            "min_load_time" : {
              "value" : null
            }
          }
        }
      ]
    }
  }
 }
}

----------------------------------------

TITLE: Defining Rollover Endpoints in OpenSearch
DESCRIPTION: Specifies the HTTP endpoints for the roll over index API operation in OpenSearch. These endpoints allow rolling over a data stream or index alias.

LANGUAGE: json
CODE:
POST /<rollover-target>/_rollover/
POST /<rollover-target>/_rollover/<target-index>

----------------------------------------

TITLE: Configuring OpenSearch Metrics Storage in OpenSearch Benchmark
DESCRIPTION: Configuration settings for storing OpenSearch Benchmark metrics in an external OpenSearch cluster. Includes settings for endpoint, security, authentication, and index replication.

LANGUAGE: ini
CODE:
[results_publishing]
datastore.type = opensearch
datastore.host = <opensearch endpoint>
datastore.port = 443
datastore.secure = true
datastore.ssl.verification_mode = none
datastore.user = <opensearch basic auth username>
datastore.password = <opensearch basic auth password>
datastore.number_of_replicas = 
datastore.number_of_shards = 

----------------------------------------

TITLE: Searching ML Tasks Endpoint Definition
DESCRIPTION: Base endpoint definition for searching ML tasks in OpenSearch.

LANGUAGE: json
CODE:
GET /_plugins/_ml/tasks/_search

----------------------------------------

TITLE: Authenticating with Admin Certificate in OpenSearch
DESCRIPTION: Bash command to authenticate with an admin certificate for accessing hidden models in OpenSearch.

LANGUAGE: bash
CODE:
curl -k --cert ./kirk.pem --key ./kirk-key.pem -XGET 'https://localhost:9200/.opendistro_security/_search'

----------------------------------------

TITLE: list_to_map Processor Without value_key
DESCRIPTION: YAML configuration showing the list_to_map processor usage without specifying a value_key, resulting in original objects being used as values.

LANGUAGE: yaml
CODE:
pipeline:
  source:
    file:
      path: "/full/path/to/logs_json.log"
      record_type: "event"
      format: "json"
  processor:
    - list_to_map:
        key: "name"
        source: "mylist"
        flatten: true
  sink:
    - stdout:

----------------------------------------

TITLE: DQL Boolean Operations
DESCRIPTION: Examples of complex boolean queries using AND, OR, NOT operators with parentheses grouping.

LANGUAGE: python
CODE:
title: wind and not (media_type: article or description: epic)

----------------------------------------

TITLE: Indexing Geo-Point Documents
DESCRIPTION: Examples of indexing documents with geo-point location data for national parks.

LANGUAGE: json
CODE:
{
  "name": "Yellowstone National Park",
  "location": "44.42, -110.59" 
}

----------------------------------------

TITLE: Retrieving Detailed Recovery Information in OpenSearch
DESCRIPTION: Example request for retrieving detailed recovery information with human-readable output formatting.

LANGUAGE: json
CODE:
GET _recovery?human&detailed=true

----------------------------------------

TITLE: Defining Internal Users in internal_users.yml
DESCRIPTION: Configures internal users with hashed passwords, roles, and attributes. This example defines a new user and includes demo users.

LANGUAGE: yaml
CODE:
---
_meta:
  type: "internalusers"
  config_version: 2

new-user:
  hash: "$2y$12$88IFVl6IfIwCFh5aQYfOmuXVL9j2hz/GusQb35o.4sdTDAEMTOD.K"
  reserved: false
  hidden: false
  opendistro_security_roles:
  - "specify-some-security-role-here"
  backend_roles:
  - "specify-some-backend-role-here"
  attributes:
    attribute1: "value1"
  static: false

admin:
  hash: "$2a$12$VcCDgh2NDk07JGN0rjGbM.Ad41qVR/YFJcgHp0UGns5JDymv..TOG"
  reserved: true
  backend_roles:
  - "admin"
  description: "Demo admin user"

----------------------------------------

TITLE: Get Memory by ID Example Response
DESCRIPTION: Example response showing the structure of a memory object including ID, timestamps, name, and user information.

LANGUAGE: json
CODE:
{
  "memory_id": "gW8Aa40BfUsSoeNTvOKI",
  "create_time": "2024-02-02T18:07:06.887061463Z",
  "updated_time": "2024-02-02T19:01:32.121444968Z",
  "name": "Conversation for a RAG pipeline",
  "user": "admin"
}

----------------------------------------

TITLE: Executing Match Phrase Query with SQL and PPL in OpenSearch
DESCRIPTION: Examples of using the MATCH_PHRASE function in SQL and PPL to search for exact phrases. Demonstrates syntax and basic usage.

LANGUAGE: sql
CODE:
SELECT account_number, address
FROM accounts
WHERE match_phrase(address, '880 Holmes Lane')

LANGUAGE: ppl
CODE:
SOURCE=accounts | WHERE match_phrase(address, '880 Holmes Lane') | FIELDS account_number, address

----------------------------------------

TITLE: Creating an Index with Delimited Payload Filter in OpenSearch
DESCRIPTION: This JSON request creates a new index named 'my_index' with a custom analyzer that includes a delimited_payload filter. The filter is configured to use a pipe character as a delimiter and interpret payloads as float values.

LANGUAGE: json
CODE:
PUT /my_index
{
  "settings": {
    "analysis": {
      "filter": {
        "my_payload_filter": {
          "type": "delimited_payload",
          "delimiter": "|",
          "encoding": "float"
        }
      },
      "analyzer": {
        "my_analyzer": {
          "type": "custom",
          "tokenizer": "whitespace",
          "filter": ["my_payload_filter"]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Lucene Scalar Quantization Index
DESCRIPTION: Example of creating a vector index with Lucene scalar quantization. Sets up a k-NN vector field using the HNSW algorithm with scalar quantization encoder.

LANGUAGE: json
CODE:
PUT /test-index
{
  "settings": {
    "index": {
      "knn": true
    }
  },
  "mappings": {
    "properties": {
      "my_vector1": {
        "type": "knn_vector",
        "dimension": 2,
        "space_type": "l2",
        "method": {
          "name": "hnsw",
          "engine": "lucene",
          "parameters": {
            "encoder": {
              "name": "sq"
            },
            "ef_construction": 256,
            "m": 8
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Custom Scoring for HTTP Status Codes in Groovy
DESCRIPTION: This Groovy script performs custom scoring based on HTTP status codes and returns true if the score exceeds a certain value.

LANGUAGE: groovy
CODE:
int score = 0;
for (int i = 0; i < ctx.results[0].hits.hits.length; i++) {
  // Weighs 500 errors 10 times as heavily as 503 errors
  if (ctx.results[0].hits.hits[i]._source.http_status_code == "500") {
    score += 10;
  } else if (ctx.results[0].hits.hits[i]._source.http_status_code == "503") {
    score += 1;
  }
}
if (score > 99) {
  return true;
} else {
  return false;
}

----------------------------------------

TITLE: Removing OpenSearch Keystore Setting
DESCRIPTION: Command to remove an existing setting from the keystore.

LANGUAGE: bash
CODE:
./bin/opensearch-keystore remove plugins.security.ssl.http.pemkey_password_secure

----------------------------------------

TITLE: Output JSON Event Example
DESCRIPTION: Sample JSON output event after type conversion showing response_status converted to an integer.

LANGUAGE: json
CODE:
{"message":"value","response_status":200}

----------------------------------------

TITLE: Querying Available Processor Types - OpenSearch API
DESCRIPTION: API endpoint to view all available processor types in the OpenSearch nodes. Returns search_pipelines object listing available request and response processors.

LANGUAGE: json
CODE:
GET /_nodes/search_pipelines

LANGUAGE: json
CODE:
{
  "_nodes" : {
    "total" : 1,
    "successful" : 1,
    "failed" : 0
  },
  "cluster_name" : "runTask",
  "nodes" : {
    "36FHvCwHT6Srbm2ZniEPhA" : {
      "name" : "runTask-0",
      "transport_address" : "127.0.0.1:9300",
      "host" : "127.0.0.1",
      "ip" : "127.0.0.1",
      "version" : "3.0.0",
      "build_type" : "tar",
      "build_hash" : "unknown",
      "roles" : [
        "cluster_manager",
        "data",
        "ingest",
        "remote_cluster_client"
      ],
      "attributes" : {
        "testattr" : "test",
        "shard_indexing_pressure_enabled" : "true"
      },
      "search_pipelines" : {
        "request_processors" : [
          {
            "type" : "filter_query"
          },
          {
            "type" : "script"
          }
        ],
        "response_processors" : [
          {
            "type" : "rename_field"
          }
        ]
      }
    }
  }
}

----------------------------------------

TITLE: Default Branding Configuration Template
DESCRIPTION: Base YAML configuration template showing all available branding customization options in OpenSearch Dashboards.

LANGUAGE: yaml
CODE:
# opensearchDashboards.branding:
  # logo:
    # defaultUrl: ""
    # darkModeUrl: ""
  # mark:
    # defaultUrl: ""
    # darkModeUrl: ""
  # loadingLogo:
    # defaultUrl: ""
    # darkModeUrl: ""
  # faviconUrl: ""
  # applicationTitle: ""

----------------------------------------

TITLE: Configuring Basic French Analyzer
DESCRIPTION: Demonstrates how to apply the built-in French analyzer to a text field in OpenSearch mappings.

LANGUAGE: json
CODE:
PUT /french-index
{
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "french"
      }
    }
  }
}

----------------------------------------

TITLE: Defining Geo Point in OpenSearch
DESCRIPTION: Example of how to represent a geographical point in OpenSearch using the geo_point field type.

LANGUAGE: json
CODE:
{
  "location": {
    "type": "point",
    "coordinates": {
      "lat": 83.76,
      "lon": -81.2
    }
  }
}

----------------------------------------

TITLE: Example response from Profile API in OpenSearch ML Commons
DESCRIPTION: This snippet shows an example response from the Profile API, including node information, model states, worker nodes, and prediction request statistics.

LANGUAGE: json
CODE:
{
  "nodes" : {
    "qTduw0FJTrmGrqMrxH0dcA" : {
      "models" : {
        "WWQI44MBbzI2oUKAvNUt" : {
          "worker_nodes" : [
            "KzONM8c8T4Od-NoUANQNGg"
          ]
        }
      }
    },
    "KzONM8c8T4Od-NoUANQNGg" : {
      "models" : {
        "WWQI44MBbzI2oUKAvNUt" : {
          "model_state" : "DEPLOYED",
          "predictor" : "org.opensearch.ml.engine.algorithms.text_embedding.TextEmbeddingModel@592814c9",
          "worker_nodes" : [
            "KzONM8c8T4Od-NoUANQNGg"
          ],
          "predict_request_stats" : {
            "count" : 2,
            "max" : 89.978681,
            "min" : 5.402,
            "average" : 47.6903405,
            "p50" : 47.6903405,
            "p90" : 81.5210129,
            "p99" : 89.13291418999998
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Update by Query Example Response in OpenSearch
DESCRIPTION: An example response from the Update by Query API, showing the number of documents processed, updated, and any errors or conflicts encountered during the operation.

LANGUAGE: json
CODE:
{
  "took": 21,
  "timed_out": false,
  "total": 1,
  "updated": 1,
  "deleted": 0,
  "batches": 1,
  "version_conflicts": 0,
  "noops": 0,
  "retries": {
    "bulk": 0,
    "search": 0
  },
  "throttled_millis": 0,
  "requests_per_second": -1.0,
  "throttled_until_millis": 0,
  "failures": []
}

----------------------------------------

TITLE: Indexing XY Geometry Collection - GeoJSON Format
DESCRIPTION: Indexes a collection of different geometry types using GeoJSON format.

LANGUAGE: json
CODE:
PUT testindex/_doc/7
{
  "location" : {
    "type": "geometrycollection",
    "geometries": [
      {
        "type": "point",
        "coordinates": [0.5, 4.5]
      },
      {
        "type": "linestring",
        "coordinates": [[2.5, 6.0], [1.5, 2.0]]
      }
    ]
  }
}

----------------------------------------

TITLE: Setting Permissions for IAM Role in Account A
DESCRIPTION: Defines permissions for the IAM role in Account A, allowing it to assume the role in Account B for cross-account access.

LANGUAGE: json
CODE:
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": "sts:AssumeRole",
            "Resource": "arn:aws:iam::<your_aws_account_B>:role/my_invoke_bedrock_role_accountB"
        }
    ]
}

----------------------------------------

TITLE: OpenSearch Dashboards Security Configuration
DESCRIPTION: YAML configuration for setting up security in OpenSearch Dashboards, including authentication and multitenancy settings.

LANGUAGE: yaml
CODE:
opensearch.hosts: [https://localhost:9200]
opensearch.ssl.verificationMode: none
opensearch.username: kibanaserver
opensearch.password: kibanaserver
opensearch.requestHeadersWhitelist: [authorization, securitytenant]

opensearch_security.multitenancy.enabled: true
opensearch_security.multitenancy.tenants.preferred: [Private, Global]
opensearch_security.readonly_mode.roles: [kibana_read_only]
opensearch_security.cookie.secure: false

----------------------------------------

TITLE: Example Request for Retrieving Connector in OpenSearch ML Commons
DESCRIPTION: This is an example GET request to retrieve a connector with the ID 'N8AE1osB0jLkkocYjz7D'.

LANGUAGE: json
CODE:
GET /_plugins/_ml/connectors/N8AE1osB0jLkkocYjz7D

----------------------------------------

TITLE: Neural Search with Max-Distance Filter in OpenSearch
DESCRIPTION: Example of a neural search query with a maximum distance threshold of 10 and combined filters

LANGUAGE: json
CODE:
GET /my-nlp-index/_search
{
  "query": {
    "neural": {
      "passage_embedding": {
        "query_text": "Hi world",
        "query_image": "iVBORw0KGgoAAAAN...",
        "max_distance": 10,
        "filter": {
          "bool": {
            "must": [
              {
                "range": {
                  "rating": {
                    "gte": 8,
                    "lte": 10
                  }
                }
              },
              {
                "term": {
                  "parking": "true"
                }
              }
            ]
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring gRPC Exporters for OpenTelemetry in OpenSearch
DESCRIPTION: This YAML configuration sets up gRPC exporters for OpenTelemetry traces and metrics in OpenSearch. It specifies the exporter classes for both span and metric data.

LANGUAGE: yaml
CODE:
telemetry.otel.tracer.span.exporter.class: io.opentelemetry.exporter.otlp.trace.OtlpGrpcSpanExporter
telemetry.otel.metrics.exporter.class: io.opentelemetry.exporter.otlp.metrics.OtlpGrpcMetricExporter

----------------------------------------

TITLE: Analyzing Text with Custom Abbreviation Mapping in OpenSearch
DESCRIPTION: This snippet demonstrates how to use a custom mapping character filter to expand common abbreviations in a text. It applies the custom_abbr_filter to replace abbreviations like FYI, IDK, and BTW with their full forms.

LANGUAGE: json
CODE:
GET /text-index/_analyze
{
  "tokenizer": "keyword",
  "char_filter": [ "custom_abbr_filter" ],
  "text": "FYI, updates to the workout schedule are posted. IDK when it takes effect, but we have some details. BTW, the finalized schedule will be released Monday."
}

----------------------------------------

TITLE: Basic Pipeline Aggregation Syntax
DESCRIPTION: Shows the basic buckets_path syntax used in pipeline aggregations to access results of other aggregations

LANGUAGE: text
CODE:
buckets_path = <AGG_NAME>[<AGG_SEPARATOR>,<AGG_NAME>]*[<METRIC_SEPARATOR>, <METRIC>];

----------------------------------------

TITLE: Creating IAM Trust Policy for OpenSearch
DESCRIPTION: JSON configuration for IAM trust policy allowing OpenSearch service to assume the role.

LANGUAGE: json
CODE:
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Principal": {
                "Service": "es.amazonaws.com"
            },
            "Action": "sts:AssumeRole"
        }
    ]
}

----------------------------------------

TITLE: Configuring Basic Audit Storage Type in OpenSearch
DESCRIPTION: Basic configuration for selecting the audit log storage type in OpenSearch's security plugin. The storage type can be set to debug, internal_opensearch, internal_opensearch_data_stream, external_opensearch, webhook, or log4j.

LANGUAGE: yaml
CODE:
plugins.security.audit.type: <debug|internal_opensearch|internal_opensearch_data_stream|external_opensearch|webhook|log4j>

----------------------------------------

TITLE: Metadata Migration Console Commands
DESCRIPTION: Commands for evaluating and executing metadata migration between clusters.

LANGUAGE: shell
CODE:
console metadata evaluate --help

LANGUAGE: shell
CODE:
console metadata migrate --help

LANGUAGE: shell
CODE:
console -v metadata migrate --help

----------------------------------------

TITLE: Using Append Modifier in Dissect Pattern
DESCRIPTION: Demonstrates the use of the append modifier to combine multiple values into a single output field.

LANGUAGE: json
CODE:
PUT /_ingest/pipeline/dissect-test
{
  "description": "Pipeline that dissects web server logs",
  "processors": [
    {
      "dissect": {
        "field": "message",
        "pattern": "%{+address}, %{+address} %{+address}",
        "append_separator": "|"
      }
    }
  ]
}

----------------------------------------

TITLE: Example Response for Terms Aggregation on Pre-aggregated Data
DESCRIPTION: This snippet shows the response structure for a terms aggregation on pre-aggregated data, including buckets with keys and aggregated document counts based on the _doc_count field.

LANGUAGE: json
CODE:
{
  "took": 20,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 3,
      "relation": "eq"
    },
    "max_score": null,
    "hits": []
  },
  "aggregations": {
    "response_codes": {
      "doc_count_error_upper_bound": 0,
      "sum_other_doc_count": 0,
      "buckets": [
        {
          "key": 200,
          "doc_count": 300
        },
        {
          "key": 404,
          "doc_count": 30
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Content Type Specification in OpenSearch
DESCRIPTION: Demonstrates how to specify JSON content type in the request header when retrieving script templates.

LANGUAGE: json
CODE:
curl -H "Content-type: application/json" -XGET localhost:9200/_scripts/<template_name>

----------------------------------------

TITLE: Executing CAT Snapshots Request in OpenSearch
DESCRIPTION: Example HTTP GET request to list all snapshots using the CAT API in OpenSearch. The 'v' parameter enables verbose mode to display column headers in the response.

LANGUAGE: http
CODE:
GET _cat/snapshots?v

----------------------------------------

TITLE: Basic Workflow Provisioning Response
DESCRIPTION: Example response containing the workflow ID after successful provisioning request.

LANGUAGE: json
CODE:
{
  "workflow_id" : "8xL8bowB8y25Tqfenm50"
}

----------------------------------------

TITLE: Creating Conversational Agent with Tools
DESCRIPTION: Defines a conversational agent with vector database tools for accessing population and stock price data.

LANGUAGE: json
CODE:
POST _plugins/_ml/agents/_register
{
  "name": "Chat Agent with Claude",
  "type": "conversational",
  "description": "this is a test agent",
  "app_type": "os_chat",
  "llm": {
    "model_id": "your_llm_model_id_from_step2",
    "parameters": {
      "max_iteration": 5,
      "response_filter": "$.completion",
      "message_history_limit": 5,
      "disable_trace": false
    }
  },
  "memory": {
    "type": "conversation_index"
  },
  "tools": [
    {
      "type": "PPLTool",
      "parameters": {
        "model_id": "your_llm_model_id_from_step2",
        "model_type": "CLAUDE",
        "execute": true
      },
      "include_output_in_agent_response": true
    },
    {
      "type": "VectorDBTool",
      "name": "population_data_knowledge_base",
      "description": "This tool provide population data of US cities.",
      "parameters": {
        "input": "${parameters.question}",
        "index": "test_population_data",
        "source_field": ["population_description"],
        "model_id": "your_embedding_model_id_from_step1",
        "embedding_field": "population_description_embedding",
        "doc_size": 3
      }
    }
  ]
}

----------------------------------------

TITLE: Creating Connector for Cohere Rerank Model
DESCRIPTION: JSON configuration for creating a connector to the Cohere Rerank model on Amazon Bedrock, including authentication and data transformation functions.

LANGUAGE: json
CODE:
{
  "name": "Amazon Bedrock Cohere rerank model",
  "description": "Test connector for Amazon Bedrock Cohere rerank model",
  "version": 1,
  "protocol": "aws_sigv4",
  "credential": {
    "access_key": "your_access_key",
    "secret_key": "your_secret_key",
    "session_token": "your_session_token"
  },
  "parameters": {
    "service_name": "bedrock",
    "endpoint": "bedrock-runtime",
    "region": "your_bedrock_model_region_like_us-west-2",
    "model_name": "cohere.rerank-v3-5:0",
    "api_version": 2
  },
  "actions": [...]
}

----------------------------------------

TITLE: Error Response for Non-existent Controller in OpenSearch ML Commons
DESCRIPTION: Example error response when attempting to retrieve information for a non-existent controller in OpenSearch ML Commons.

LANGUAGE: json
CODE:
{
  "error": {
    "root_cause": [
      {
        "type": "status_exception",
        "reason": "Failed to find model controller with the provided model ID: T_S-cY0BKCJ3ot9qr0aP"
      }
    ],
    "type": "status_exception",
    "reason": "Failed to find model controller with the provided model ID: T_S-cY0BKCJ3ot9qr0aP"
  },
  "status": 404
}

----------------------------------------

TITLE: Split Event Output Example in JSON
DESCRIPTION: Example JSON output showing the resulting split events after processing, where the original event is split into multiple events based on the space delimiter.

LANGUAGE: json
CODE:
{"query" : "open", "some_other_field" : "abc" }
{"query" : "source", "some_other_field" : "abc" }

----------------------------------------

TITLE: Creating Skipping Index with Internal Scheduler
DESCRIPTION: SQL query to create a skipping index using an internal scheduler with specified refresh settings.

LANGUAGE: sql
CODE:
CREATE SKIPPING INDEX example_index
WITH (
    auto_refresh = true,
    refresh_interval = '15 minutes',
    scheduler_mode = 'internal'
);

----------------------------------------

TITLE: Equivalent Direct Query in OpenSearch
DESCRIPTION: Shows the equivalent direct query that can be used to retrieve the same results as the SearchIndexTool query. This query retrieves 20 email addresses from the sample eCommerce dataset.

LANGUAGE: json
CODE:
GET opensearch_dashboards_sample_data_ecommerce/_search
{
  "size": 20,
  "_source": "email"
}

----------------------------------------

TITLE: Example Response for Index Rollover in OpenSearch
DESCRIPTION: Shows an example response from OpenSearch after a successful rollover operation, including the old and new index names, rollover status, and condition results.

LANGUAGE: json
CODE:
{
  "acknowledged": true,
  "shards_acknowledged": true,
  "old_index": ".ds-my-data-stream-2029.06.11-000001",
  "new_index": ".ds-my-data-stream-2029.06.12-000002",
  "rolled_over": true,
  "dry_run": false,
  "conditions": {
    "[max_age: 5d]": true,
    "[max_docs: 500]": true,
    "[max_primary_shard_size: 100gb]": false
  }
}

----------------------------------------

TITLE: Role Configuration - YAML Example
DESCRIPTION: Example YAML configuration showing how to set up field-level security exclusions in roles.yml file.

LANGUAGE: yaml
CODE:
someonerole:
  cluster: []
  indices:
    movies:
      '*':
      - "READ"
      _fls_:
      - "~actors"
      - "~title"
      - "~year"

----------------------------------------

TITLE: Running securityadmin.bat on Windows
DESCRIPTION: This command demonstrates how to run securityadmin.bat on Windows to load the initial configuration using PEM files.

LANGUAGE: bash
CODE:
.\securityadmin.bat -cd ..\..\..\config\opensearch-security\ -icl -nhnv ^
  -cacert ..\..\..\config\root-ca.pem ^
  -cert ..\..\..\config\kirk.pem ^
  -key ..\..\..\config\kirk-key.pem

----------------------------------------

TITLE: Intervals Query with Script Filter in OpenSearch
DESCRIPTION: An example of an Intervals query using a custom script filter to search for 'map' and 'hash' next to each other within a specific interval in the text.

LANGUAGE: json
CODE:
POST /testindex/_search
{
  "query": {
    "intervals" : {
      "title" : {
        "match" : {
          "query" : "map hash",
          "filter" : {
            "script" : {
              "source" : "interval.start > 5 && interval.end < 8 && interval.gaps == 0"
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: IAM Trust Policy Configuration
DESCRIPTION: JSON configuration for IAM trust policy allowing OpenSearch service to assume the role.

LANGUAGE: json
CODE:
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Principal": {
                "Service": "es.amazonaws.com"
            },
            "Action": "sts:AssumeRole"
        }
    ]
}

----------------------------------------

TITLE: Creating Search Pipeline with Rename Field Processor
DESCRIPTION: Creates a search pipeline that renames the 'message' field to 'notification' in search responses.

LANGUAGE: json
CODE:
PUT /_search/pipeline/my_pipeline
{
  "response_processors": [
    {
      "rename_field": {
        "field": "message",
        "target_field": "notification"
      }
    }
  ]
}

----------------------------------------

TITLE: Deleting a Document in OpenSearch using Rust
DESCRIPTION: Delete a document from OpenSearch using the delete() function.

LANGUAGE: rust
CODE:
let response = client
    .delete(DeleteParts::IndexId("movies", "2"))
    .send()
    .await?;

----------------------------------------

TITLE: Ingesting Test Data for Reranking in OpenSearch
DESCRIPTION: Ingests test data into the 'my-test-data' index using a bulk request for use in reranking examples.

LANGUAGE: json
CODE:
POST _bulk
{ "index": { "_index": "my-test-data" } }
{ "passage_text" : "Carson City is the capital city of the American state of Nevada." }
{ "index": { "_index": "my-test-data" } }
{ "passage_text" : "The Commonwealth of the Northern Mariana Islands is a group of islands in the Pacific Ocean. Its capital is Saipan." }
{ "index": { "_index": "my-test-data" } }
{ "passage_text" : "Washington, D.C. (also known as simply Washington or D.C., and officially as the District of Columbia) is the capital of the United States. It is a federal district." }
{ "index": { "_index": "my-test-data" } }
{ "passage_text" : "Capital punishment (the death penalty) has existed in the United States since beforethe United States was a country. As of 2017, capital punishment is legal in 30 of the 50 states." }

----------------------------------------

TITLE: Query Response Example
DESCRIPTION: Example response from the dis_max query showing matched documents with their scores and source data.

LANGUAGE: json
CODE:
{
  "took": 8,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 2,
      "relation": "eq"
    },
    "max_score": 1.3862942,
    "hits": [
      {
        "_index": "testindex1",
        "_id": "1",
        "_score": 1.3862942,
        "_source": {
          "title": " The Top 10 Shakespeare Poems",
          "description": "Top 10 sonnets of England's national poet and the Bard of Avon"
        }
      },
      {
        "_index": "testindex1",
        "_id": "2",
        "_score": 0.2876821,
        "_source": {
          "title": "Sonnets of the 16th Century",
          "body": "The poems written by various 16-th century poets"
        }
      }
    ]
  }
}

----------------------------------------

TITLE: Indexing Geopoint Data in OpenSearch
DESCRIPTION: Indexes three documents with geopoint data using latitude and longitude coordinates.

LANGUAGE: json
CODE:
PUT testindex1/_doc/1
{
  "point": { 
    "lat": 74.00,
    "lon": 40.71
  }
}

LANGUAGE: json
CODE:
PUT testindex1/_doc/2
{
  "point": { 
    "lat": 72.64,
    "lon": 22.62
  } 
}

LANGUAGE: json
CODE:
PUT testindex1/_doc/3
{
  "point": { 
    "lat": 75.00,
    "lon": 28.00
  }
}

----------------------------------------

TITLE: Copying Index Mappings and Settings with OpenSearch Reindex API
DESCRIPTION: This example shows how to use the reindex API to copy all field mappings and settings from one index to another.

LANGUAGE: json
CODE:
POST _reindex
{
   "source":{
      "index":"sample-index-1"
   },
   "dest":{
      "index":"sample-index-2"
   }
}

----------------------------------------

TITLE: Deleting OpenSearch Cluster from Kubernetes
DESCRIPTION: This command removes the OpenSearch cluster and all its resources from the Kubernetes cluster.

LANGUAGE: bash
CODE:
kubectl delete -f opensearch-cluster.yaml

----------------------------------------

TITLE: Terms Lookup Query in OpenSearch
DESCRIPTION: Illustrates how to use terms lookup to search for students enrolled in a specific class.

LANGUAGE: json
CODE:
GET students/_search
{
  "query": {
    "terms": {
      "student_id": {
        "index": "classes",
        "id": "101",
        "path": "enrolled"
      }
    }
  }
}

----------------------------------------

TITLE: Applying Finnish Analyzer to Text Field in OpenSearch
DESCRIPTION: This snippet demonstrates how to apply the built-in Finnish analyzer to a text field when creating an index in OpenSearch.

LANGUAGE: json
CODE:
PUT /finnish-index
{
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "finnish"
      }
    }
  }
}

----------------------------------------

TITLE: Analyzing Text with Dutch Analyzer in OpenSearch
DESCRIPTION: This snippet shows how to use the _analyze endpoint to examine tokens generated by the Dutch analyzer for a given text.

LANGUAGE: json
CODE:
POST /dutch-index/_analyze
{
  "field": "content",
  "text": "De studenten studeren in Nederland en bezoeken Amsterdam. Hun nummers zijn 123456."
}

----------------------------------------

TITLE: Creating an oversample, collapse, and truncate pipeline in OpenSearch
DESCRIPTION: This snippet demonstrates creating a complex search pipeline that oversamples results, collapses on the 'color' field, and then truncates the results.

LANGUAGE: json
CODE:
PUT /_search/pipeline/oversampling_collapse_pipeline
{
  "request_processors": [
    {
      "oversample": {
        "sample_factor": 3
      }
    }
  ],
  "response_processors": [
    {
      "collapse" : {
        "field": "color"
      }
    },
    {
      "truncate_hits": {
        "description": "Truncates back to the original size before oversample increased it."
      }
    }
  ]
}

----------------------------------------

TITLE: Setting Weighted Round Robin Search
DESCRIPTION: API request for creating a round robin shard allocation for search traffic using equal weights for zone_1 and zone_2, while excluding zone_3.

LANGUAGE: json
CODE:
{ 
      "weights":
      {
        "zone_1": "1", 
        "zone_2": "1", 
        "zone_3": "0"
      }
      "_version" : 1
}

----------------------------------------

TITLE: Creating OpenSearch Alias with Custom Routing
DESCRIPTION: Example request showing how to create an alias named 'sample-alias' for 'sample-index' with custom routing value 'test'.

LANGUAGE: json
CODE:
POST sample-index/_alias/sample-alias
{
  "routing":"test"
}

----------------------------------------

TITLE: Creating Bedrock Cohere Connector using Python
DESCRIPTION: This Python script creates a connector for the Cohere Embed model on Amazon Bedrock using the OpenSearch API.

LANGUAGE: python
CODE:
import boto3
import requests 
from requests_aws4auth import AWS4Auth

host = 'your_amazon_opensearch_domain_endpoint'
region = 'your_amazon_opensearch_domain_region'
service = 'es'

credentials = boto3.Session().get_credentials()
awsauth = AWS4Auth(credentials.access_key, credentials.secret_key, region, service, session_token=credentials.token)

path = '/_plugins/_ml/connectors/_create'
url = host + path

payload = {
  "name": "Amazon Bedrock Cohere Connector: embedding v3",
  "description": "The connector to Bedrock Cohere embedding model",
  "version": 1,
  "protocol": "aws_sigv4",
  "parameters": {
    "region": "your_bedrock_model_region",
    "service_name": "bedrock",
    "input_type":"search_document",
    "truncate": "END"
  },
  "credential": {
    "roleArn": "your_iam_role_arn_created_in_step1"
  },
  "actions": [
    {
      "action_type": "predict",
      "method": "POST",
      "url": "https://bedrock-runtime.your_bedrock_model_region.amazonaws.com/model/cohere.embed-english-v3/invoke",
      "headers": {
        "content-type": "application/json",
        "x-amz-content-sha256": "required"
      },
      "request_body": "{ \"texts\": ${parameters.texts}, \"truncate\": \"${parameters.truncate}\", \"input_type\": \"${parameters.input_type}\" }",
      "pre_process_function": "connector.pre_process.cohere.embedding",
      "post_process_function": "connector.post_process.cohere.embedding"
    }
  ]
}

headers = {"Content-Type": "application/json"}

r = requests.post(url, auth=awsauth, json=payload, headers=headers)
print(r.text)

----------------------------------------

TITLE: Analyzing Text with Dutch Analyzer in OpenSearch
DESCRIPTION: This snippet shows how to use the _analyze endpoint to examine tokens generated by the Dutch analyzer for a given text.

LANGUAGE: json
CODE:
POST /dutch-index/_analyze
{
  "field": "content",
  "text": "De studenten studeren in Nederland en bezoeken Amsterdam. Hun nummers zijn 123456."
}

----------------------------------------

TITLE: Grok Pattern Syntax Example
DESCRIPTION: Demonstrates the basic syntax format for Grok patterns used in parsing unstructured data.

LANGUAGE: bash
CODE:
%{SYNTAX:SEMANTIC}

----------------------------------------

TITLE: High-Precision Geohex Grid Query
DESCRIPTION: Executes a geohex grid aggregation with high precision (6) for more granular location grouping.

LANGUAGE: json
CODE:
{
  "aggregations": {
    "grouped": {
      "geohex_grid": {
        "field": "location",
        "precision": 6
      }
    }
  }
}

----------------------------------------

TITLE: Get All Messages in Memory Endpoint
DESCRIPTION: API endpoint for retrieving all messages associated with a specific memory ID.

LANGUAGE: json
CODE:
GET /_plugins/_ml/memory/<memory_id>/messages

----------------------------------------

TITLE: Retrieving Document with Community ID in OpenSearch
DESCRIPTION: This JSON query retrieves the document with ID 1 from the 'testindex1' index, which should now include the generated community ID hash.

LANGUAGE: json
CODE:
GET testindex1/_doc/1

----------------------------------------

TITLE: Get All Workflow Steps Request
DESCRIPTION: Example cURL request to fetch all workflow steps from the API.

LANGUAGE: json
CODE:
GET /_plugins/_flow_framework/workflow/_steps

----------------------------------------

TITLE: Basic Median Absolute Deviation Query in OpenSearch
DESCRIPTION: Demonstrates how to calculate the median absolute deviation of a numeric field in OpenSearch. This example queries the DistanceMiles field from the flights sample dataset.

LANGUAGE: json
CODE:
{
  "size": 0,
  "aggs": {
    "median_absolute_deviation_DistanceMiles": {
      "median_absolute_deviation": {
        "field": "DistanceMiles"
      }
    }
  }
}

----------------------------------------

TITLE: Advanced Binary Quantization Configuration
DESCRIPTION: Creates an index with custom compression level and ef_construction parameter for optimized binary quantization.

LANGUAGE: json
CODE:
PUT my-vector-index
{
  "settings" : {
    "index": {
      "knn": true
    }
  },
  "mappings": {
    "properties": {
      "my_vector_field": {
        "type": "knn_vector",
        "dimension": 8,
        "space_type": "l2",
        "data_type": "float",
        "mode": "on_disk",
        "compression_level": "16x",
        "method": {
          "name": "hnsw",
          "engine": "faiss",
          "parameters": {
              "ef_construction": 16
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating IAM Role Trust Policy in Account B
DESCRIPTION: Defines a trust policy for the IAM role in Account B, allowing it to be assumed by a role from Account A for invoking the Bedrock model.

LANGUAGE: json
CODE:
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "",
            "Effect": "Allow",
            "Principal": {
                "AWS": "arn:aws:iam::<your_aws_account_A>:role/my_cross_account_role_accountA"
            },
            "Action": "sts:AssumeRole"
        }
    ]
}

----------------------------------------

TITLE: Querying OpenSearch for Raw Trace Data
DESCRIPTION: This bash command demonstrates how to retrieve a raw document from the OpenSearch cluster containing trace data. It uses curl to send a GET request to the OpenSearch API.

LANGUAGE: bash
CODE:
curl -X GET -u 'admin:<custom-admin-password>' -k 'https://localhost:9200/otel-v1-apm-span-000001/_search?pretty&size=1'

----------------------------------------

TITLE: OpenSearch IAM Policy Configuration (JSON)
DESCRIPTION: Required IAM permissions policy for accessing Amazon OpenSearch Service domains.

LANGUAGE: json
CODE:
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "AWS": "arn:aws:iam::<AccountId>:user/data-prepper-user"
      },
      "Action": "es:ESHttpGet",
      "Resource": [
        "arn:aws:es:us-east-1:<AccountId>:domain/<domain-name>/",
        "arn:aws:es:us-east-1:<AccountId>:domain/<domain-name>/_cat/indices",
        "arn:aws:es:us-east-1:<AccountId>:domain/<domain-name>/_search",
        "arn:aws:es:us-east-1:<AccountId>:domain/<domain-name>/_search/scroll",
        "arn:aws:es:us-east-1:<AccountId>:domain/<domain-name>/*/_search"
      ]
    }
  ]
}

----------------------------------------

TITLE: Creating Docker Volume for Map Tiles
DESCRIPTION: This command creates a Docker volume to store the map tiles data.

LANGUAGE: bash
CODE:
docker volume create tiles-data

----------------------------------------

TITLE: Example Recovery API Response in OpenSearch
DESCRIPTION: Sample response showing detailed recovery information for an index named 'shakespeare', including shard details, file information, and recovery statistics.

LANGUAGE: json
CODE:
{
  "shakespeare": {
    "shards": [
      {
        "id": 0,
        "type": "EXISTING_STORE",
        "stage": "DONE",
        "primary": true,
        "start_time": "2024-07-01T18:06:47.415Z",
        "start_time_in_millis": 1719857207415,
        "stop_time": "2024-07-01T18:06:47.538Z",
        "stop_time_in_millis": 1719857207538,
        "total_time": "123ms",
        "total_time_in_millis": 123,
        "source": {
          "bootstrap_new_history_uuid": false
        },
        "target": {
          "id": "uerS7REgRQCbBF3ImY8wOQ",
          "host": "172.18.0.3",
          "transport_address": "172.18.0.3:9300",
          "ip": "172.18.0.3",
          "name": "opensearch-node2"
        },
        "index": {
          "size": {
            "total": "17.8mb",
            "total_in_bytes": 18708764,
            "reused": "17.8mb",
            "reused_in_bytes": 18708764,
            "recovered": "0b",
            "recovered_in_bytes": 0,
            "percent": "100.0%"
          },
          "files": {
            "total": 7,
            "reused": 7,
            "recovered": 0,
            "percent": "100.0%",
            "details": [...]
          }
        }
      }
    ]
  }
}

----------------------------------------

TITLE: Cleanup Snapshot Repository API Endpoint
DESCRIPTION: The endpoint for the Cleanup Snapshot Repository API. It uses a POST request to clear a snapshot repository of data no longer referenced by any existing snapshot.

LANGUAGE: json
CODE:
POST /_snapshot/<repository>/_cleanup

----------------------------------------

TITLE: Setting OpenSearch Keystore Password
DESCRIPTION: Command to set or update the keystore password. Will prompt for current password if one exists.

LANGUAGE: bash
CODE:
./bin/opensearch-keystore passwd

----------------------------------------

TITLE: Expanded Match Boolean Prefix Query
DESCRIPTION: Extended example showing match_bool_prefix query with additional parameters like analyzer specification.

LANGUAGE: json
CODE:
GET _search
{
  "query": {
    "match_bool_prefix": {
      "title": {
        "query": "the wind",
        "analyzer": "stop"
      }
    }
  }
}

----------------------------------------

TITLE: Creating Index with Lowercase Tokenizer in OpenSearch
DESCRIPTION: Example of creating a new index with a custom analyzer using the lowercase tokenizer. The analyzer is configured to break text at whitespace and convert all terms to lowercase in a single step.

LANGUAGE: json
CODE:
PUT /my-lowercase-index
{
  "settings": {
    "analysis": {
      "tokenizer": {
        "my_lowercase_tokenizer": {
          "type": "lowercase"
        }
      },
      "analyzer": {
        "my_lowercase_analyzer": {
          "type": "custom",
          "tokenizer": "my_lowercase_tokenizer"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating Cohere Rerank Connector - Amazon OpenSearch Service
DESCRIPTION: Python script to create a connector in Amazon OpenSearch Service using AWS credentials and configuration.

LANGUAGE: python
CODE:
import boto3
import requests 
from requests_aws4auth import AWS4Auth

host = 'your_amazon_opensearch_domain_endpoint_created_in_step0'
region = 'your_amazon_opensearch_domain_region'
service = 'es'

credentials = boto3.Session().get_credentials()
awsauth = AWS4Auth(credentials.access_key, credentials.secret_key, region, service, session_token=credentials.token)

path = '/_plugins/_ml/connectors/_create'
url = host + path

payload = {
    "name": "cohere-rerank",
    "description": "The connector to Cohere reanker model",
    "version": "1",
    "protocol": "http",
    "credential": {
        "secretArn": "your_secret_arn_created_in_step1",
        "roleArn": "your_iam_role_arn_created_in_step2"
    },
    "parameters": {
        "model": "rerank-english-v3.0",
        "return_documents": true
    },
    "actions": [
        {
            "action_type": "predict",
            "method": "POST",
            "url": "https://api.cohere.ai/v1/rerank",
            "headers": {
                "Authorization": "Bearer ${credential.secretArn.my_cohere_key}"
            },
            "request_body": "{ \"documents\": ${parameters.documents}, \"query\": \"${parameters.query}\", \"model\": \"${parameters.model}\", \"top_n\": ${parameters.top_n}, \"return_documents\": ${parameters.return_documents} }"
        }
    ]
}

headers = {"Content-Type": "application/json"}

r = requests.post(url, auth=awsauth, json=payload, headers=headers)
print(r.text)

----------------------------------------

TITLE: Configuring Logstash for Automatic Pipeline Reloading
DESCRIPTION: Shows how to configure Logstash to automatically reload the pipeline configuration when changes are detected in the input file.

LANGUAGE: yaml
CODE:
input {
  file {
    path => "/Users/<user>/Desktop/logstash7-12.1/events-data/input_file.log"
    start_position => "beginning"
  }
}

----------------------------------------

TITLE: Geoshape query using envelope in OpenSearch
DESCRIPTION: Searches for documents with geoshape fields that intersect with the provided envelope shape.

LANGUAGE: json
CODE:
GET /testindex/_search
{
  "query": {
    "geo_shape": {
      "location": {
        "shape": {
          "type": "envelope",
          "coordinates": [
            [
              71.0589,
              42.3601
            ],
            [
              74.006,
              40.7128
            ]
          ]
        },
        "relation": "WITHIN"
      }
    }
  }
}

----------------------------------------

TITLE: Creating Full Access Role for OpenSearch Observability
DESCRIPTION: Creates a full access role for Observability features that allows users to perform all Observability-related operations.

LANGUAGE: json
CODE:
PUT _plugins/_security/api/roles/observability_full_access
{
  "cluster_permissions": [
    "cluster:admin/opensearch/observability/*"
  ]
}

----------------------------------------

TITLE: Retrieving OpenSearch Index Settings
DESCRIPTION: This example demonstrates how to retrieve all settings for a specific index using the settings API.

LANGUAGE: json
CODE:
GET /sample-index1/_settings

----------------------------------------

TITLE: Custom Authentication Configuration
DESCRIPTION: Configuration example using the auth_type setting for basic authentication in Logstash.

LANGUAGE: yaml
CODE:
output {
    opensearch {
          hosts  => ["https://hostname:port"]
          auth_type => {
              type => 'basic'
              user => 'admin'
              password => 'admin'
          }
          index => "logstash-logs-%{+YYYY.MM.dd}"
   }
}

----------------------------------------

TITLE: Letter Tokenizer Response Example
DESCRIPTION: Shows the response format and token output from the letter tokenizer, including token positions, offsets, and types.

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "Cats",
      "start_offset": 0,
      "end_offset": 4,
      "type": "word",
      "position": 0
    },
    {
      "token": "EVER",
      "start_offset": 6,
      "end_offset": 10,
      "type": "word",
      "position": 1
    },
    {
      "token": "love",
      "start_offset": 11,
      "end_offset": 15,
      "type": "word",
      "position": 2
    },
    {
      "token": "chasing",
      "start_offset": 16,
      "end_offset": 23,
      "type": "word",
      "position": 3
    },
    {
      "token": "butterflies",
      "start_offset": 24,
      "end_offset": 35,
      "type": "word",
      "position": 4
    }
  ]
}

----------------------------------------

TITLE: Executing Conversational Search Query
DESCRIPTION: Performs a conversational search query using the configured pipeline and RAG processor.

LANGUAGE: json
CODE:
GET /qa_demo/_search?search_pipeline=my-conversation-search-pipeline-cohere
{
  "query": {
    "match": {
      "text": "What's the population increase of New York City from 2021 to 2023?"
    }
  },
  "size": 1,
  "_source": [
    "text"
  ],
  "ext": {
    "generative_qa_parameters": {
      "llm_model": "bedrock/claude",
      "llm_question": "What's the population increase of New York City from 2021 to 2023?",
      "context_size": 5,
      "timeout": 15
    }
  }
}

----------------------------------------

TITLE: Bitmap Generation for Terms Filter in Python
DESCRIPTION: Python script to create a roaring bitmap for terms filter, serialize it, and encode it in Base64.

LANGUAGE: python
CODE:
from pyroaring import BitMap
import base64

bm = BitMap([111, 222, 333])
encoded = base64.b64encode(BitMap.serialize(bm))

encoded_bm_str = encoded.decode('utf-8')

print(f"Encoded Bitmap: {encoded_bm_str}")

----------------------------------------

TITLE: Example Workspace Object in TypeScript
DESCRIPTION: This snippet demonstrates a typical Workspace configuration object. It creates an 'Analytics team' workspace with a specific use case feature.

LANGUAGE: typescript
CODE:
{
  id: "M5NqCu",
  name: "Analytics team",
  description: "Analytics team workspace",
  features: ["use-case-analytics"],
}

----------------------------------------

TITLE: Using Right Padding Modifier in Dissect Pattern
DESCRIPTION: Creates a pipeline using the right padding modifier to handle variable spacing in log entries.

LANGUAGE: json
CODE:
PUT /_ingest/pipeline/dissect-test
{
  "description": "Pipeline that dissects web server logs",
  "processors": [
    {
      "dissect": {
        "field": "message",
        "pattern": "[%{client_ip}]%{->}[%{timestamp}]" 
      }
    }
  ]
}

----------------------------------------

TITLE: Deploying BAAI/bge-reranker Model to SageMaker
DESCRIPTION: Python code to deploy the Hugging Face BAAI/bge-reranker-v2-m3 model to Amazon SageMaker with GPU instance configuration.

LANGUAGE: python
CODE:
import json
import sagemaker
import boto3
from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri
from sagemaker.serverless import ServerlessInferenceConfig

try:
	role = sagemaker.get_execution_role()
except ValueError:
	iam = boto3.client('iam')
	role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']

hub = {
	'HF_MODEL_ID':'BAAI/bge-reranker-v2-m3'
}

huggingface_model = HuggingFaceModel(
	image_uri=get_huggingface_llm_image_uri("huggingface-tei",version="1.2.3"),
	env=hub,
	role=role, 
)

predictor = huggingface_model.deploy(
	initial_instance_count=1,
	instance_type="ml.g5.2xlarge",
  )

----------------------------------------

TITLE: Creating Index Mappings in OpenSearch
DESCRIPTION: Sets up index mappings with a date field formatted as yyyy-MM-dd.

LANGUAGE: json
CODE:
PUT testindex
{
  "mappings" : {
    "properties" :  {
      "date" : {
        "type" : "date",
        "format" : "yyyy-MM-dd"
      }
    }
  }
}

----------------------------------------

TITLE: Installing OpenSearch Dashboards from YUM Repository
DESCRIPTION: These commands demonstrate how to install OpenSearch Dashboards from a YUM repository, including listing available versions and installing a specific version.

LANGUAGE: bash
CODE:
sudo yum clean all
sudo yum list opensearch-dashboards --showduplicates
sudo yum install opensearch-dashboards
sudo yum install 'opensearch-dashboards-{{site.opensearch_version}}'

----------------------------------------

TITLE: Executing Search Query with cURL in OpenSearch
DESCRIPTION: This snippet demonstrates how to execute a search query in OpenSearch using a cURL command. It searches for the phrase "To be, or not to be" in the 'shakespeare' index.

LANGUAGE: bash
CODE:
curl -XGET http://localhost:9200/shakespeare/_search?pretty -H 'Content-Type: application/json' -d'
{
  "query": {
    "match": {
      "text_entry": "To be, or not to be"
    }
  }
}'

----------------------------------------

TITLE: Creating Index with XY Shape Mapping in OpenSearch
DESCRIPTION: Creates an index with a geometry field mapped as xy_shape type.

LANGUAGE: json
CODE:
PUT testindex
{
  "mappings": {
    "properties": {
      "geometry": {
        "type": "xy_shape"
      }
    }
  }
}

----------------------------------------

TITLE: Using Stem Exclusion with Finnish Analyzer in OpenSearch
DESCRIPTION: This example shows how to use stem exclusion with the Finnish language analyzer when creating an index in OpenSearch. It excludes specific words from stemming.

LANGUAGE: json
CODE:
PUT index_with_stem_exclusion_finnish_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "stem_exclusion_finnish_analyzer": {
          "type": "finnish",
          "stem_exclusion": ["valta", "hyvksynt"]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Uninstalling OpenSearch Helm Deployment
DESCRIPTION: Command to delete or uninstall an OpenSearch deployment using Helm.

LANGUAGE: bash
CODE:
helm delete opensearch-1-1629223146

----------------------------------------

TITLE: Listing Installed OpenSearch Dashboards Plugins
DESCRIPTION: This command lists all installed OpenSearch Dashboards plugins using the opensearch-dashboards-plugin tool.

LANGUAGE: bash
CODE:
sudo bin/opensearch-dashboards-plugin list

----------------------------------------

TITLE: Configuring Full Amazon SNS Access Permissions
DESCRIPTION: IAM policy configuration to grant full access to Amazon SNS services. This policy allows all SNS-related actions on all resources.

LANGUAGE: json
CODE:
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Action": [
        "sns:*"
      ],
      "Effect": "Allow",
      "Resource": "*"
    }
  ]
}

----------------------------------------

TITLE: Deploying a Model to All Available ML Nodes in OpenSearch
DESCRIPTION: Example POST request to deploy a model to any available OpenSearch ML node using the model ID.

LANGUAGE: json
CODE:
POST /_plugins/_ml/models/WWQI44MBbzI2oUKAvNUt/_deploy

----------------------------------------

TITLE: Managing Multiple Alias Actions
DESCRIPTION: Example showing how to remove one index and add another to an alias in a single atomic operation.

LANGUAGE: json
CODE:
POST _aliases
{
  "actions": [
    {
      "remove": {
        "index": "index-1",
        "alias": "alias1"
      }
    },
    {
      "add": {
        "index": "index-2",
        "alias": "alias1"
      }
    }
  ]
}

----------------------------------------

TITLE: Searching Workflows by Use Case in OpenSearch
DESCRIPTION: This example demonstrates how to search for workflows with a specific use case using the Flow Framework API. It uses a GET request with a match query on the use_case field to find workflows for remote model deployment.

LANGUAGE: json
CODE:
GET /_plugins/_flow_framework/workflow/_search
{
  "query": {
    "match": {
      "use_case": "REMOTE_MODEL_DEPLOYMENT"
    }
  }
}

----------------------------------------

TITLE: Median Absolute Deviation Query with Missing Value Handling
DESCRIPTION: Shows how to handle missing or null values in median absolute deviation calculations by specifying a default value using the missing parameter.

LANGUAGE: json
CODE:
{
  "size": 0,
  "aggs": {
    "median_absolute_deviation_distanceMiles": {
      "median_absolute_deviation": {
        "field": "DistanceMiles",
        "missing": 1000
      }
    }
  }
}

----------------------------------------

TITLE: Querying Range Fields with Term Query in OpenSearch
DESCRIPTION: This snippet shows how to use a term query to search for a specific value within a range field in OpenSearch. It searches for a GPA value of 3.5 within the defined range.

LANGUAGE: json
CODE:
GET testindex/_search
{
  "query" : {
    "term" : {
      "gpa" : {
        "value" : 3.5
      }
    }
  }
}

----------------------------------------

TITLE: Performing Keyword Search in OpenSearch
DESCRIPTION: This snippet demonstrates how to perform a keyword search in OpenSearch using the 'match' query. It searches for the words 'long live king' in the 'shakespeare' index.

LANGUAGE: json
CODE:
GET shakespeare/_search
{
  "query": {
    "match": {
      "text_entry": "long live king"
    }
  }
}

----------------------------------------

TITLE: Creating Vector Index in OpenSearch
DESCRIPTION: JSON configuration for creating a vector index with KNN settings

LANGUAGE: json
CODE:
{
  "settings": {
    "index": {
      "knn.space_type": "cosinesimil",
      "default_pipeline": "my_cohere_embedding_pipeline",
      "knn": "true"
    }
  },
  "mappings": {
    "properties": {
      "text_knn": {
        "type": "knn_vector",
        "dimension": 1024
      }
    }
  }
}

----------------------------------------

TITLE: Searching derived fields defined in index mappings
DESCRIPTION: Searches for documents with the derived 'timestamp' field in a specified range and retrieves the field values.

LANGUAGE: json
CODE:
POST /logs/_search
{
  "query": {
    "range": {
      "timestamp": {
        "gte": "1970-01-11T08:20:30.400Z",   
        "lte": "1970-01-11T08:26:00.400Z"
      }
    }
  },
  "fields": ["timestamp"]
}

----------------------------------------

TITLE: Configuring Prometheus Data Source with AWS Authentication
DESCRIPTION: API request to configure a Prometheus data source using AWS Signature Version 4 authentication

LANGUAGE: json
CODE:
POST _plugins/_query/_datasources
{
    "name" : "my_prometheus",
    "connector": "prometheus",
    "properties" : {
        "prometheus.uri" : "http://localhost:8080",
        "prometheus.auth.type" : "awssigv4",
        "prometheus.auth.region" : "us-east-1",
        "prometheus.auth.access_key" : "{{accessKey}}"
        "prometheus.auth.secret_key" : "{{secretKey}}"
    }
}

----------------------------------------

TITLE: Testing Anomaly Detector Agent
DESCRIPTION: POST request to test the anomaly detector agent with a sample index payload.

LANGUAGE: json
CODE:
{
  "parameters": {
    "index":"sample_weblogs_test"
  }
}

----------------------------------------

TITLE: Running PPL Query in OpenSearch Notebooks
DESCRIPTION: Example of a PPL (Piped Processing Language) query to retrieve the first 20 records from the sample logs dataset.

LANGUAGE: ppl
CODE:
%ppl
source=opensearch_dashboards_sample_data_logs | head 20

----------------------------------------

TITLE: Profiling a non-global aggregation query
DESCRIPTION: Executes a search request with a non-global aggregation and profiling enabled to analyze the aggregation performance.

LANGUAGE: json
CODE:
GET /opensearch_dashboards_sample_data_ecommerce/_search
{
  "size": 0,
  "aggs": {
    "avg_taxful_total_price": {
      "avg": {
        "field": "taxful_total_price"
      }
    }
  }
}

----------------------------------------

TITLE: Delete Snapshot Repository Example Request - JSON
DESCRIPTION: Example request showing how to delete a repository named 'my-opensearch-repo'.

LANGUAGE: json
CODE:
DELETE _snapshot/my-opensearch-repo

----------------------------------------

TITLE: Configuring Debug Logging for OpenID Connect
DESCRIPTION: Configuration settings for enabling debug-level logging in OpenSearch to troubleshoot OpenID Connect issues. These settings should be added to the log4j2.properties file.

LANGUAGE: properties
CODE:
logger.securityjwt.name = com.amazon.dlic.auth.http.jwt
logger.securityjwt.level = trace

----------------------------------------

TITLE: Disabling Security Plugin in opensearch.yml (YAML)
DESCRIPTION: This snippet shows how to disable the Security plugin by adding a setting to the opensearch.yml file. This can be useful for testing or development environments where security is not required.

LANGUAGE: yaml
CODE:
plugins.security.disabled: true

----------------------------------------

TITLE: Creating Index with Default Pipeline
DESCRIPTION: Creates an OpenSearch index with the reranking pipeline set as the default search pipeline and defines mappings for the passage_text field.

LANGUAGE: json
CODE:
PUT /my-index
{
  "settings": {
    "index.search.default_pipeline" : "my_pipeline"
  },
  "mappings": {
    "properties": {
      "passage_text": {
        "type": "text"
      }
    }
  }
}

----------------------------------------

TITLE: Searching for a Threat Intelligence Monitor in OpenSearch
DESCRIPTION: This snippet shows how to search for an existing monitor using a POST request with a match query. It searches for a monitor by its ID in the request body.

LANGUAGE: json
CODE:
{
    "query": {
        "match": {
            "_id": "HMqq_5AB1vBjq44wpTIN"
        }
    }
}

----------------------------------------

TITLE: Mapping Users to Anomaly Detection Full Access Role
DESCRIPTION: This JSON snippet shows how to map multiple users to the 'anomaly_full_access' role for comprehensive permissions in anomaly detection.

LANGUAGE: json
CODE:
{
  "backend_roles": [],
  "hosts": [],
  "users": [
    "alice",
    "bob"
  ]
}

----------------------------------------

TITLE: Updating OpenSearch Index Settings to Disable Vector Data Structure Creation
DESCRIPTION: This snippet demonstrates how to update existing index settings in OpenSearch to disable vector data structure creation by setting index.knn.advanced.approximate_threshold to -1.

LANGUAGE: json
CODE:
PUT /test-index/_settings
{
  "index.knn.advanced.approximate_threshold": "-1"
}

----------------------------------------

TITLE: Defining an Ingest Pipeline Structure in JSON
DESCRIPTION: This snippet shows the basic structure of an ingest pipeline definition in JSON format. It includes the optional 'description' field and the required 'processors' array.

LANGUAGE: json
CODE:
{
    "description" : "..."
    "processors" : [...]
}

----------------------------------------

TITLE: Indexing Parent Documents - OpenSearch JSON
DESCRIPTION: Index requests to create parent (brand) documents with the join field type set to brand.

LANGUAGE: json
CODE:
PUT testindex1/_doc/1
{
  "name": "Luxury brand",
  "product_to_brand" : "brand" 
}

----------------------------------------

TITLE: Multiple File Batch Ingestion Request
DESCRIPTION: API request to ingest embeddings from multiple OpenAI files into OpenSearch. Includes field mapping for multiple sources and OpenAI authentication.

LANGUAGE: json
CODE:
{
  "index_name": "my-nlp-index-openai",
  "field_map": {
    "question": "source[1].$.body.input[0]",
    "answer": "source[1].$.body.input[1]",
    "question_embedding":"source[0].$.response.body.data[0].embedding",
    "answer_embedding":"source[0].$.response.body.data[1].embedding",
    "_id": ["source[0].$.custom_id", "source[1].$.custom_id"]
  },
  "ingest_fields": ["source[2].$.custom_field1", "source[2].$.custom_field2"],
  "credential": {
    "openAI_key": "<you openAI key>"
  },
  "data_source": {
    "type": "openAI",
    "source": ["file-<your output file id>", "file-<your input file id>", "file-<your other file>"]
  }
}

----------------------------------------

TITLE: Configuring YAML Front Matter for Migration Guide Page
DESCRIPTION: YAML front matter configuration for the migration guide page, including layout settings, title, navigation order, and redirect information.

LANGUAGE: yaml
CODE:
---
layout: default
title: Migrating from Open Distro
nav_order: 30
redirect_from:
  - /clients/data-prepper/migrate-open-distro/
---

----------------------------------------

TITLE: Creating Warm Node Index in JSON
DESCRIPTION: JSON request to create an index on a warm node in a hot-warm architecture.

LANGUAGE: json
CODE:
PUT oldindex
{
  "settings": {
    "index.routing.allocation.require.temp": "warm"
  }
}

----------------------------------------

TITLE: Sorting Child Documents by Parent Field using Function Score in OpenSearch
DESCRIPTION: This snippet demonstrates how to sort child documents (products) based on a field in their parent documents (brands) using a function_score query.

LANGUAGE: json
CODE:
GET testindex1/_search
{
  "query": {
    "has_parent": {
      "parent_type": "brand",
      "score": true,
      "query": {
        "function_score": {
          "script_score": {
            "script": "_score * doc['customer_satisfaction'].value"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Analyzing Text with Danish Analyzer
DESCRIPTION: Example of analyzing Danish text using the configured analyzer and viewing the generated tokens.

LANGUAGE: json
CODE:
{
  "field": "content",
  "text": "Studerende studerer p de danske universiteter. Deres numre er 123456."
}

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "stud",
      "start_offset": 0,
      "end_offset": 10,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "stud",
      "start_offset": 11,
      "end_offset": 19,
      "type": "<ALPHANUM>",
      "position": 1
    },
    {
      "token": "dansk",
      "start_offset": 26,
      "end_offset": 32,
      "type": "<ALPHANUM>",
      "position": 4
    },
    {
      "token": "universitet",
      "start_offset": 33,
      "end_offset": 46,
      "type": "<ALPHANUM>",
      "position": 5
    },
    {
      "token": "numr",
      "start_offset": 54,
      "end_offset": 59,
      "type": "<ALPHANUM>",
      "position": 7
    },
    {
      "token": "123456",
      "start_offset": 63,
      "end_offset": 69,
      "type": "<NUM>",
      "position": 9
    }
  ]
}

----------------------------------------

TITLE: Assuming IAM Role for Temporary Credentials
DESCRIPTION: Bash command to assume an IAM role and obtain temporary credentials for creating a connector.

LANGUAGE: bash
CODE:
aws sts assume-role --role-arn your_iam_role_arn_created_in_step2.1 --role-session-name your_session_name

----------------------------------------

TITLE: Creating an Ingest Pipeline for Sparse Encoding in OpenSearch
DESCRIPTION: This snippet shows how to set up an ingest pipeline that uses the sparse encoding model to process documents before indexing. It maps the 'passage_text' field to a 'passage_embedding' field.

LANGUAGE: json
CODE:
PUT /_ingest/pipeline/pipeline-sparse
{
  "description": "An sparse encoding ingest pipeline",
  "processors": [
    {
      "sparse_encoding": {
        "model_id": "Nf9KY40Bk4MTqirc6FO7",
        "field_map": {
          "passage_text": "passage_embedding"
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Configuring Key Overwriting in Grok Processor
DESCRIPTION: This snippet shows how to configure the grok processor to overwrite specific keys in the output, replacing existing values with new captures.

LANGUAGE: json
CODE:
processor:
  - grok:
      match:
        keys_to_overwrite: ["message"]
        message: ['%{IPORHOST:clientip} \[%{HTTPDATE:timestamp}\] %{NUMBER:message:int}']

----------------------------------------

TITLE: Listing Findings and Correlations API
DESCRIPTION: API endpoint for retrieving all findings and their correlations within a specified time window using start and end timestamps in milliseconds.

LANGUAGE: json
CODE:
GET /_plugins/_security_analytics/correlations?start_timestamp=1689289210000&end_timestamp=1689300010000

----------------------------------------

TITLE: Persian Analyzer Token Generation Response
DESCRIPTION: Sample response showing the tokens generated by the Persian analyzer.

LANGUAGE: json
CODE:
{
  "tokens": [
    {"token": "","start_offset": 0,"end_offset": 9,"type": "<ALPHANUM>","position": 0},
    {"token": "","start_offset": 13,"end_offset": 20,"type": "<ALPHANUM>","position": 2},
    {"token": "","start_offset": 25,"end_offset": 31,"type": "<ALPHANUM>","position": 4},
    {"token": "","start_offset": 32,"end_offset": 37,"type": "<ALPHANUM>","position": 5},
    {"token": "","start_offset": 47,"end_offset": 52,"type": "<ALPHANUM>","position": 8},
    {"token": "123456","start_offset": 63,"end_offset": 69,"type": "<NUM>","position": 12}
  ]
}

----------------------------------------

TITLE: Setting Environment Variables for Upgrade Tool
DESCRIPTION: These bash commands set the required environment variables for using the opensearch-upgrade tool.

LANGUAGE: bash
CODE:
export ES_HOME=/home/workspace/upgrade-demo/node1/elasticsearch-7.10.2
export ES_PATH_CONF=/home/workspace/upgrade-demo/node1/os-config
export OPENSEARCH_HOME=/home/workspace/upgrade-demo/node1/opensearch-1.0.0
export OPENSEARCH_PATH_CONF=/home/workspace/upgrade-demo/node1/opensearch-config

----------------------------------------

TITLE: Handling Missing Vector Fields in OpenSearch k-NN Search
DESCRIPTION: Example of a Painless script that safely handles documents without vector field values by checking field size before calculating distance.

LANGUAGE: json
CODE:
"source": "doc[params.field].size() == 0 ? 0 : 1 / (1 + l2Squared(params.query_value, doc[params.field]))"

----------------------------------------

TITLE: Deploying a Model to Specific Nodes in OpenSearch
DESCRIPTION: Example POST request to deploy a model to specific OpenSearch ML nodes by specifying node IDs in the request body.

LANGUAGE: json
CODE:
POST /_plugins/_ml/models/WWQI44MBbzI2oUKAvNUt/_deploy
{
    "node_ids": ["4PLK7KJWReyX0oWKnBA8nA"]
}

----------------------------------------

TITLE: Searching Data Stream
DESCRIPTION: Shows how to search across all backing indexes in a data stream using query matching.

LANGUAGE: json
CODE:
GET logs-redis/_search
{
  "query": {
    "match": {
      "message": "login"
    }
  }
}

----------------------------------------

TITLE: Searching for Workflows by Created Resources in OpenSearch
DESCRIPTION: This example shows how to search for workflows based on created resources. It uses a nested query to find workflows that have created a resource with a specific workflow_step_id.

LANGUAGE: json
CODE:
GET /_plugins/_flow_framework/workflow/state/_search
{
  "query": {
    "nested": {
      "path": "resources_created",
      "query": {
        "bool": {
          "must": [
            {
              "match": {
                "resources_created.workflow_step_id": "register_model_2"
              }
            }
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Sampler Aggregation with Terms Aggregation in OpenSearch
DESCRIPTION: Shows how to use a sampler aggregation with a terms aggregation on the opensearch_dashboards_sample_data_logs index. It limits the number of documents collected on each shard to 1,000 and then buckets the documents by the agent.keyword field.

LANGUAGE: json
CODE:
GET opensearch_dashboards_sample_data_logs/_search
{
  "size": 0,
  "aggs": {
    "sample": {
      "sampler": {
        "shard_size": 1000
      },
      "aggs": {
        "terms": {
          "terms": {
            "field": "agent.keyword"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring OpenSearch Systemd Service Environment
DESCRIPTION: Example of setting OpenSearch environment variables in a systemd service configuration file with reload commands.

LANGUAGE: bash
CODE:
# /etc/systemd/system/opensearch.service.d/override.conf
[Service]
Environment="OPENSEARCH_JAVA_OPTS=-Xms2g -Xmx2g"
Environment="OPENSEARCH_PATH_CONF=/etc/opensearch"

sudo systemctl daemon-reload
sudo systemctl restart opensearch

----------------------------------------

TITLE: Running Data Prepper 2.0+ with Docker
DESCRIPTION: Docker command to run Data Prepper 2.0 or later with mounted configuration files.

LANGUAGE: bash
CODE:
docker run --name data-prepper -p 4900:4900 -v ${PWD}/pipelines.yaml:/usr/share/data-prepper/pipelines/pipelines.yaml -v ${PWD}/data-prepper-config.yaml:/usr/share/data-prepper/config/data-prepper-config.yaml opensearchproject/data-prepper:latest

----------------------------------------

TITLE: Configuring Window Size for Top N Queries
DESCRIPTION: JSON request to set the monitoring window size to 60 minutes for latency metrics.

LANGUAGE: json
CODE:
PUT _cluster/settings
{
  "persistent" : {
    "search.insights.top_queries.latency.window_size" : "60m"
  }
}

----------------------------------------

TITLE: Indexing Linestring Geoshape
DESCRIPTION: Examples of indexing a linestring geometry in both GeoJSON and WKT formats.

LANGUAGE: json
CODE:
PUT testindex/_doc/2
{
  "location" : {
    "type" : "linestring",
    "coordinates" : [[74.0060, 40.7128], [71.0589, 42.3601]]
  }
}

LANGUAGE: json
CODE:
PUT testindex/_doc/2
{
  "location" : "LINESTRING (74.0060 40.7128, 71.0589 42.3601)"
}

----------------------------------------

TITLE: Configuring IAM Role Assumption Permissions
DESCRIPTION: IAM policy that enables users to assume roles with SNS permissions, including EC2 description, IAM role listing, and role assumption capabilities.

LANGUAGE: json
CODE:
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "ec2:Describe*",
        "iam:ListRoles",
        "sts:AssumeRole"
      ],
      "Resource": "*"
    }
  ]
}

----------------------------------------

TITLE: Auto_date_histogram aggregation with built-in date format
DESCRIPTION: Executes an auto_date_histogram aggregation using a built-in date format for the output.

LANGUAGE: json
CODE:
GET /blogs/_search
{
  "size": 0,
  "aggs": {
    "histogram": {
      "auto_date_histogram": {
        "field": "date_posted",
        "format": "basic_date_time_no_millis"
      }
    }
  }
}

----------------------------------------

TITLE: Deleting a Snapshot using DELETE HTTP Method in OpenSearch
DESCRIPTION: This snippet demonstrates the HTTP path and method for deleting a snapshot from a repository in OpenSearch. It requires specifying the repository and snapshot names as path parameters.

LANGUAGE: json
CODE:
DELETE _snapshot/<repository>/<snapshot>

----------------------------------------

TITLE: Configuring Log4j Audit Storage
DESCRIPTION: Configuration for Log4j audit storage type, including logger name and log level settings. This allows audit events to be stored using Log4j's logging infrastructure.

LANGUAGE: yaml
CODE:
plugins.security.audit.config.log4j.logger_name: audit
plugins.security.audit.config.log4j.level: INFO

----------------------------------------

TITLE: Extending a Point in Time (PIT) in OpenSearch
DESCRIPTION: Extends a PIT's lifetime by including a keep_alive parameter in the pit object during a search request.

LANGUAGE: json
CODE:
GET /_search
{
  "size": 10000,
  "query": {
    "match" : {
      "user.id" : "elkbee"
    }
  },
  "pit": {
    "id":  "46ToAwMDaWR5BXV1aWQyKwZub2RlXzMAAAAAAAAAACoBYwADaWR4BXV1aWQxAgZub2RlXzEAAAAAAAAAAAEBYQADaWR5BXV1aWQyKgZub2RlXzIAAAAAAAAAAAwBYgACBXV1aWQyAAAFdXVpZDEAAQltYXRjaF9hbGw_gAAAAA==", 
    "keep_alive": "100m"
  },
  "sort": [ 
    {"@timestamp": {"order": "asc"}}
  ],
  "search_after": [  
    "2021-05-20T05:30:04.832Z"
  ]
}

----------------------------------------

TITLE: Sample Cluster Health Response
DESCRIPTION: Example response showing cluster health metrics including status, node counts, and shard allocation details.

LANGUAGE: json
CODE:
{
  "cluster_name" : "opensearch-cluster",
  "status" : "green",
  "timed_out" : false,
  "number_of_nodes" : 2,
  "number_of_data_nodes" : 2,
  "discovered_master" : true,
  "active_primary_shards" : 6,
  "active_shards" : 12,
  "relocating_shards" : 0,
  "initializing_shards" : 0,
  "unassigned_shards" : 0,
  "delayed_unassigned_shards" : 0,
  "number_of_pending_tasks" : 0,
  "number_of_in_flight_fetch" : 0,
  "task_max_waiting_in_queue_millis" : 0,
  "active_shards_percent_as_number" : 100.0
}

----------------------------------------

TITLE: Excluding Vector Field from Source and Recovery Source in OpenSearch
DESCRIPTION: This snippet demonstrates how to exclude a vector field from both the _source and _recovery_source in OpenSearch index mappings for improved indexing speed and reduced disk space.

LANGUAGE: json
CODE:
PUT /<index_name>/_mappings
{
    "_source": {
    "excludes": ["location"],
    "recovery_source_excludes": ["location"]
    },
    "properties": {
        "location": {
            "type": "knn_vector",
            "dimension": 2,
        "space_type": "l2"
        }
    }
}

----------------------------------------

TITLE: Registering a Local Text Embedding Model in OpenSearch
DESCRIPTION: JSON request to register a local text embedding model, including model details and configuration.

LANGUAGE: json
CODE:
POST /_plugins/_ml/models/_register
{
  "name": "huggingface/sentence-transformers/msmarco-distilbert-base-tas-b",
  "version": "1.0.1",
  "model_group_id": "wlcnb4kBJ1eYAeTMHlV6",
  "description": "This is a port of the DistilBert TAS-B Model to sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and is optimized for the task of semantic search.",
  "function_name": "TEXT_EMBEDDING",
  "model_format": "TORCH_SCRIPT",
  "model_content_size_in_bytes": 266352827,
  "model_content_hash_value": "acdc81b652b83121f914c5912ae27c0fca8fabf270e6f191ace6979a19830413",
  "model_config": {
    "model_type": "distilbert",
    "embedding_dimension": 768,
    "framework_type": "sentence_transformers",
    "all_config": "{\"_name_or_path\":\"old_models/msmarco-distilbert-base-tas-b/0_Transformer\",\"activation\":\"gelu\",\"architectures\":[\"DistilBertModel\"],\"attention_dropout\":0.1,\"dim\":768,\"dropout\":0.1,\"hidden_dim\":3072,\"initializer_range\":0.02,\"max_position_embeddings\":512,\"model_type\":\"distilbert\",\"n_heads\":12,\"n_layers\":6,\"pad_token_id\":0,\"qa_dropout\":0.1,\"seq_classif_dropout\":0.2,\"sinusoidal_pos_embds\":false,\"tie_weights_\":true,\"transformers_version\":\"4.7.0\",\"vocab_size\":30522}"
  },
  "created_time": 1676073973126,
  "url": "https://artifacts.opensearch.org/models/ml-models/huggingface/sentence-transformers/msmarco-distilbert-base-tas-b/1.0.1/torch_script/sentence-transformers_msmarco-distilbert-base-tas-b-1.0.1-torch_script.zip"
}

----------------------------------------

TITLE: Registering External Model in OpenSearch
DESCRIPTION: API call to register an external model using previously created model group and connector.

LANGUAGE: json
CODE:
POST /_plugins/_ml/models/_register
{
    "name": "openAI-gpt-3.5-turbo",
    "function_name": "remote",
    "model_group_id": "wlcnb4kBJ1eYAeTMHlV6",
    "description": "test model",
    "connector_id": "a1eMb4kBJ1eYAeTMAljY"
}

----------------------------------------

TITLE: Configuring GeoIP Service in YAML
DESCRIPTION: Basic configuration example for the geoip_service extension showing how to set database refresh interval and cache count settings in the data-prepper-config.yaml file.

LANGUAGE: yaml
CODE:
extensions:
  geoip_service:
    maxmind:
      database_refresh_interval: PT1H
      cache_count: 16_384

----------------------------------------

TITLE: OpenSearch Search API Endpoints
DESCRIPTION: Defines the available REST endpoints for performing search operations in OpenSearch. Includes both GET and POST methods for searching across all indices or a specific index.

LANGUAGE: json
CODE:
GET  /_search
POST /_search
GET  /{index}/_search
POST /{index}/_search

----------------------------------------

TITLE: Invoking Custom Workload
DESCRIPTION: Command to invoke a custom workload and run a benchmark test against an OpenSearch cluster using the opensearch-benchmark execute-test command.

LANGUAGE: bash
CODE:
opensearch-benchmark execute-test \
--pipeline="benchmark-only" \
--workload-path="<PATH OUTPUTTED IN THE OUTPUT OF THE CREATE-WORKLOAD COMMAND>" \
--target-host="<CLUSTER ENDPOINT>" \
--client-options="basic_auth_user:'<USERNAME>',basic_auth_password:'<PASSWORD>'"

----------------------------------------

TITLE: Customizing Bulgarian Analyzer with Stem Exclusion in OpenSearch
DESCRIPTION: This snippet shows how to create a custom Bulgarian analyzer with stem exclusion for specific words in OpenSearch.

LANGUAGE: json
CODE:
PUT index_with_stem_exclusion_bulgarian_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "stem_exclusion_bulgarian_analyzer": {
          "type": "bulgarian",
          "stem_exclusion": ["", ""]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Combining Geohash_grid with Geo_centroid
DESCRIPTION: Shows how to use geo_centroid as a sub-aggregation of geohash_grid to analyze geographic clusters.

LANGUAGE: json
CODE:
GET /locations/_search
{
  "size": 0,
  "aggs": {
    "grid": {
      "geohash_grid": {
        "field": "coordinates",
        "precision": 3
      },
      "aggs": {
        "centroid": {
          "geo_centroid": {
            "field": "coordinates"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: SQL Query Explain Request
DESCRIPTION: Example of using the explain API to understand how an SQL query is executed.

LANGUAGE: json
CODE:
{
  "query": "SELECT firstname, lastname FROM accounts WHERE age > 20"
}

----------------------------------------

TITLE: Creating an email account in OpenSearch
DESCRIPTION: Sets up a new email account configuration for sending alert notifications via email.

LANGUAGE: json
CODE:
POST _plugins/_alerting/destinations/email_accounts
{
  "name": "example_account",
  "email": "example@email.com",
  "host": "smtp.email.com",
  "port": 465,
  "method": "ssl"
}

----------------------------------------

TITLE: Processing JSON Event with select_entries
DESCRIPTION: Example of how the select_entries processor transforms a JSON event by selecting specific keys. It shows the input event and the resulting output after processing.

LANGUAGE: json
CODE:
{"message": "hello", "key1" : "value1", "key2" : "value2", "some_key" : "test"}

LANGUAGE: json
CODE:
{"key1": "value1", "key2": "value2"}

----------------------------------------

TITLE: Configuring Processor Failure Handling in OpenSearch
DESCRIPTION: Demonstrates how to configure a processor to ignore failures and continue pipeline execution using the ignore_failure parameter.

LANGUAGE: json
CODE:
"filter_query" : {
  "tag" : "tag1",
  "description" : "This processor is going to restrict to publicly visible documents",
  "ignore_failure": true,
  "query" : {
    "term": {
      "visibility": "public"
    }
  }
}

----------------------------------------

TITLE: OpenSearch Constant Score Query Response
DESCRIPTION: Example response showing search results with constant score of 1.2 applied to all matches. Includes document metadata and source content.

LANGUAGE: json
CODE:
{
  "took": 8,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 96,
      "relation": "eq"
    },
    "max_score": 1.2,
    "hits": [
      {
        "_index": "shakespeare",
        "_id": "32535",
        "_score": 1.2,
        "_source": {
          "type": "line",
          "line_id": 32536,
          "play_name": "Hamlet",
          "speech_number": 48,
          "line_number": "1.1.97",
          "speaker": "HORATIO",
          "text_entry": "Dared to the combat; in which our valiant Hamlet--"
        }
      }
    ]
  }
}

----------------------------------------

TITLE: Reenabling Vector Data Structure Creation in OpenSearch Index Settings
DESCRIPTION: This snippet shows how to reenable vector data structure creation in OpenSearch by setting index.knn.advanced.approximate_threshold back to 0 after bulk indexing is complete.

LANGUAGE: json
CODE:
PUT /test-index/_settings
{
  "index.knn.advanced.approximate_threshold": "0"
}

----------------------------------------

TITLE: Adding Data for Faiss k-NN Filtering in OpenSearch
DESCRIPTION: This snippet demonstrates how to add multiple documents with shirt information to the index for k-NN filtering using the bulk API.

LANGUAGE: json
CODE:
POST /_bulk?refresh
{ "index": { "_index": "products-shirts", "_id": "1" } }
{ "item_vector": [5.2, 4.4, 8.4], "size" : "large", "rating" : 5 }
{ "index": { "_index": "products-shirts", "_id": "2" } }
{ "item_vector": [5.2, 3.9, 2.9], "size" : "small", "rating" : 4 }
{ "index": { "_index": "products-shirts", "_id": "3" } }
{ "item_vector": [4.9, 3.4, 2.2], "size" : "xlarge", "rating" : 9 }
{ "index": { "_index": "products-shirts", "_id": "4" } }
{ "item_vector": [4.2, 4.6, 5.5], "size" : "large", "rating" : 6}
{ "index": { "_index": "products-shirts", "_id": "5" } }
{ "item_vector": [3.3, 4.5, 8.8], "size" : "medium", "rating" : 8 }
{ "index": { "_index": "products-shirts", "_id": "6" } }
{ "item_vector": [6.4, 3.4, 6.6], "size" : "small", "rating" : 9 }
{ "index": { "_index": "products-shirts", "_id": "7" } }
{ "item_vector": [4.2, 6.2, 4.6], "size" : "small", "rating" : 5 }
{ "index": { "_index": "products-shirts", "_id": "8" } }
{ "item_vector": [2.4, 4.0, 3.0], "size" : "small", "rating" : 8 }
{ "index": { "_index": "products-shirts", "_id": "9" } }
{ "item_vector": [1.4, 3.2, 9.0], "size" : "small", "rating" : 5 }
{ "index": { "_index": "products-shirts", "_id": "10" } }
{ "item_vector": [7.0, 9.9, 9.0], "size" : "xlarge", "rating" : 9 }
{ "index": { "_index": "products-shirts", "_id": "11" } }
{ "item_vector": [3.0, 2.3, 2.0], "size" : "large", "rating" : 6 }
{ "index": { "_index": "products-shirts", "_id": "12" } }
{ "item_vector": [5.0, 1.0, 4.0], "size" : "large", "rating" : 3 }

----------------------------------------

TITLE: Script Feature Definition - JSON
DESCRIPTION: Example of defining a custom script feature for movie ranking with adjustable parameters.

LANGUAGE: json
CODE:
POST _ltr/_featureset/more_movie_features
{
  "featureset": {
    "features": [
      {
        "name": "title_query",
        "params": [
          "keywords"
        ],
        "template_language": "mustache",
        "template": {
          "match": {
            "title": "{{keywords}}"
          }
        }
      },
      {
        "name": "custom_title_query_boost",
        "params": [
          "some_multiplier",
          "ltr_param_foo"
        ],
        "template_language": "script_feature",
        "template": {
          "lang": "painless",
          "source": "(long)params.default_param * params.feature_vector.get('title_query') * (long)params.some_multiplier * (long) params.param_foo",
          "params": {
            "default_param": 10,
            "some_multiplier": "some_multiplier",
            "extra_script_params": {
              "ltr_param_foo": "param_foo"
            }
          }
        }
      }
    ]
  }
}

----------------------------------------

TITLE: Analyzing Text with Custom Analyzer
DESCRIPTION: Demonstrates how to analyze text using the custom analyzer with apostrophe filter. Shows the API call to analyze a sample text containing apostrophes.

LANGUAGE: json
CODE:
POST /custom_text_index/_analyze
{
  "analyzer": "custom_analyzer",
  "text": "John's car is faster than Peter's bike"
}

----------------------------------------

TITLE: Adding an Alias to an Index in OpenSearch
DESCRIPTION: This snippet demonstrates how to add an alias to an existing index using the OpenSearch API. It's useful for creating alternative names for indices.

LANGUAGE: bash
CODE:
POST _aliases
{
  "actions": [
    {
      "add": {
        "index": "<target_index>",
        "alias": "<index_alias>"
      }
    }
  ]
}

----------------------------------------

TITLE: Multiple Node Verification Response
DESCRIPTION: Example response showing successful verification with multiple connected nodes

LANGUAGE: json
CODE:
{
  "nodes" : {
    "lcfL6jv2jo6sMEtp4idMvg" : {
      "name" : "node-1"
    },
    "rEPtFT/B+cuuOHnQn0jy4s" : {
      "name" : "node-2"
  }
}

----------------------------------------

TITLE: Register Public Model Group
DESCRIPTION: Example request for registering a model group with public access mode that can be accessed by any user

LANGUAGE: json
CODE:
{
    "name": "test_model_group_public",
    "description": "This is a public model group",
    "access_mode": "public"
}

----------------------------------------

TITLE: Predicting with ML Commons API in OpenSearch
DESCRIPTION: This snippet demonstrates how to use the ML Commons Predict API endpoint. It requires a model_id and specifies the input query and index for prediction.

LANGUAGE: json
CODE:
POST /_plugins/_ml/_predict/kmeans/<model-id>
{
    "input_query": {
        "_source": ["petal_length_in_cm", "petal_width_in_cm"],
        "size": 10000
    },
    "input_index": [
        "iris_data"
    ]
}

----------------------------------------

TITLE: Configuring S3 Sink in Data Prepper Pipeline
DESCRIPTION: Demonstrates how to configure an S3 sink in a Data Prepper pipeline YAML file. It includes AWS settings, bucket configuration, object key formatting, thresholds, and codec selection.

LANGUAGE: yaml
CODE:
pipeline:
  ...
  sink:
    - s3:
        aws:
          region: us-east-1
          sts_role_arn: arn:aws:iam::123456789012:role/Data-Prepper
        max_retries: 5
        bucket: bucket_name
        object_key:
          path_prefix: my-logs/%{yyyy}/%{MM}/%{dd}/
        threshold:
          event_count: 10000
          maximum_size: 50mb
          event_collect_timeout: 15s
        codec:
          ndjson:
        buffer_type: in_memory

----------------------------------------

TITLE: Creating User with Human Resources Backend Role in OpenSearch
DESCRIPTION: This snippet shows how to create a user named 'bob' with a 'human-resources' backend role in OpenSearch using the Security plugin API.

LANGUAGE: json
CODE:
PUT _plugins/_security/api/internalusers/bob
{
  "password": "bob",
  "backend_roles": [
    "human-resources"
  ],
  "attributes": {}
}

----------------------------------------

TITLE: Example Request without Object
DESCRIPTION: Shows a simple POST request to the endpoint without a request body.

LANGUAGE: json
CODE:
POST /_example/endpoint/

----------------------------------------

TITLE: Creating Mapping with Percolator Field in OpenSearch
DESCRIPTION: This snippet shows how to create a mapping that includes a percolator field type for the 'query' field within the 'search' object. It also defines fields for 'price' and 'item'.

LANGUAGE: json
CODE:
PUT testindex1
{
  "mappings": {
    "properties": {
      "search": {
        "properties": {
          "query": { 
            "type": "percolator" 
          }
        }
      },
      "price": { 
        "type": "float" 
      },
      "item": { 
        "type": "text" 
      }
    }
  }
}

----------------------------------------

TITLE: Creating a Mapping with Token Count Field in OpenSearch
DESCRIPTION: This snippet demonstrates how to create an index mapping that includes a token count field. The 'sentence' field is defined as a text type with a nested 'num_words' field of type 'token_count' using the 'english' analyzer.

LANGUAGE: json
CODE:
PUT testindex
{
  "mappings": {
    "properties": {
      "sentence": { 
        "type": "text",
        "fields": {
          "num_words": { 
            "type":     "token_count",
            "analyzer": "english"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Add Entries Processor with Simple Values in YAML
DESCRIPTION: This snippet demonstrates how to configure the add_entries processor to add simple key-value pairs to an event.

LANGUAGE: yaml
CODE:
processor:
  - add_entries:
      entries:
        - key: "name"
          value: "John"
        - key: "age"
          value: 20

----------------------------------------

TITLE: Executing ConnectorTool Agent
DESCRIPTION: JSON request for executing the configured agent with input parameters for the Lambda function.

LANGUAGE: json
CODE:
POST /_plugins/_ml/agents/9X7xWI0Bpc3sThaJdY9i/_execute
{
  "parameters": {
    "number1": 2,
    "number2": 3
  }
}

----------------------------------------

TITLE: Starting OpenSearch with Distributed Tracing Enabled
DESCRIPTION: Command to start OpenSearch with the distributed tracing feature enabled using an environment variable.

LANGUAGE: bash
CODE:
OPENSEARCH_JAVA_OPTS="-Dopensearch.experimental.feature.telemetry.enabled=true" ./opensearch-2.9.0/bin/opensearch

----------------------------------------

TITLE: Rescoring Query with Quantized Vectors in OpenSearch
DESCRIPTION: Performs vector search with rescoring to improve recall while maintaining memory savings from quantization.

LANGUAGE: json
CODE:
GET /my-vector-index/_search
{
  "size": 2,
  "query": {
    "knn": {
      "target-field": {
        "vector": [2, 3, 5, 6],
        "k": 2,
        "rescore" : {
          "oversample_factor": 1.2
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Shard Allocation Awareness in YAML
DESCRIPTION: Sets zone attributes for shard allocation awareness on data nodes.

LANGUAGE: yaml
CODE:
node.attr.zone: zoneA

LANGUAGE: yaml
CODE:
node.attr.zone: zoneB

----------------------------------------

TITLE: Creating a role for cross-cluster search
DESCRIPTION: cURL command to create a role with appropriate permissions for cross-cluster search in OpenSearch.

LANGUAGE: bash
CODE:
curl -XPUT -k -u 'admin:<custom-admin-password>' -H 'Content-Type: application/json' 'https://localhost:9200/_plugins/_security/api/roles/booksrole' -d '{"index_permissions":[{"index_patterns":["books"],"allowed_actions":["indices:admin/shards/search_shards","indices:data/read/search"]}]}'

----------------------------------------

TITLE: Multi-Node Task Cancellation
DESCRIPTION: POST endpoint to cancel all cancelable tasks on multiple specified nodes.

LANGUAGE: json
CODE:
POST _tasks/_cancel?nodes=opensearch-node1,opensearch-node2

----------------------------------------

TITLE: Workflow API Endpoints
DESCRIPTION: Base REST endpoints for creating and updating workflows

LANGUAGE: json
CODE:
POST /_plugins/_flow_framework/workflow
PUT /_plugins/_flow_framework/workflow/<workflow_id>

----------------------------------------

TITLE: Configuring Session Management for SAML in OpenSearch Dashboards
DESCRIPTION: This YAML snippet demonstrates how to configure additional cookie settings for improved session management with SAML authentication in OpenSearch Dashboards.

LANGUAGE: yaml
CODE:
opensearch_security.saml.extra_storage.cookie_prefix: security_authentication_saml
opensearch_security.saml.extra_storage.additional_cookies: 3

----------------------------------------

TITLE: Finding-Specific Correlations API
DESCRIPTION: API endpoint for retrieving correlations for a specific finding and detector type, with parameters for nearby findings count and time window.

LANGUAGE: json
CODE:
GET /_plugins/_security_analytics/findings/correlate?finding=425dce0b-f5ee-4889-b0c0-7d15669f0871&detector_type=ad_ldap&nearby_findings=20&time_window=10m

----------------------------------------

TITLE: SQL DELETE Statement Example
DESCRIPTION: Example of a DELETE statement that removes documents where age is greater than 30.

LANGUAGE: sql
CODE:
DELETE FROM accounts
WHERE age > 30

----------------------------------------

TITLE: Creating Correlation Rules API
DESCRIPTION: API endpoint for creating correlation rules between different log types. Allows specifying multiple log sources with their indices, queries and categories for correlation.

LANGUAGE: json
CODE:
POST /_plugins/_security_analytics/correlation/rules
{
  "correlate": [
    {
      "index": "vpc_flow",
      "query": "dstaddr:4.5.6.7 or dstaddr:4.5.6.6",
      "category": "network"
    },
    {
      "index": "windows",
      "query": "winlog.event_data.SubjectDomainName:NTAUTHORI*",
      "category": "windows"
    },
    {
      "index": "ad_logs",
      "query": "ResultType:50126",
      "category": "ad_ldap"
    },
    {
      "index": "app_logs",
      "query": "endpoint:/customer_records.txt",
      "category": "others_application"
    }
  ]
}

----------------------------------------

TITLE: Enforcing Cluster-Level Replication Type in OpenSearch YAML Configuration
DESCRIPTION: This snippet shows how to enforce a cluster-level replication type by setting the cluster.index.restrict.replication.type parameter in the opensearch.yml file.

LANGUAGE: yaml
CODE:
cluster.index.restrict.replication.type: true

----------------------------------------

TITLE: OpenSearch Index Document Endpoints
DESCRIPTION: Available endpoints for indexing documents in OpenSearch. Includes PUT and POST methods for adding documents with specified or auto-generated IDs.

LANGUAGE: json
CODE:
PUT <index>/_doc/<_id>
POST <index>/_doc

PUT <index>/_create/<_id>
POST <index>/_create/<_id>

----------------------------------------

TITLE: Basic Search Without Pipeline
DESCRIPTION: Performs a search without applying the filter query pipeline.

LANGUAGE: json
CODE:
GET /my_index/_search

----------------------------------------

TITLE: Memory Search API Endpoints
DESCRIPTION: The base endpoints for searching memories in OpenSearch.

LANGUAGE: json
CODE:
GET /_plugins/_ml/memory/_search
POST /_plugins/_ml/memory/_search

----------------------------------------

TITLE: OpenSearch Top Hits Response Structure
DESCRIPTION: Example response showing the structure of top_hits aggregation results, including document metadata, scores, and source data for eCommerce products. The response includes detailed product information, customer details, and geographical data.

LANGUAGE: json
CODE:
{
  "aggregations": {
    "top_hits_products": {
      "hits": {
        "total": {
          "value": 4675,
          "relation": "eq"
        },
        "max_score": 1.0,
        "hits": [
          {
            "_index": "opensearch_dashboards_sample_data_ecommerce",
            "_type": "_doc",
            "_id": "glMlwXcBQVLeQPrkHPtI",
            "_score": 1.0,
            "_source": {
              "category": [
                "Women's Accessories",
                "Women's Clothing"
              ],
              "currency": "EUR",
              "customer_first_name": "rania",
              "customer_full_name": "rania Evans",
              "customer_gender": "FEMALE",
              "customer_id": 24,
              "customer_last_name": "Evans",
              "customer_phone": "",
              "day_of_week": "Sunday",
              "day_of_week_i": 6,
              "email": "rania@evans-family.zzz",
              "manufacturer": [
                "Tigress Enterprises"
              ],
              "order_date": "2021-02-28T14:16:48+00:00",
              "order_id": 583581,
              "products": [
                {
                  "base_price": 10.99,
                  "discount_percentage": 0,
                  "quantity": 1,
                  "manufacturer": "Tigress Enterprises",
                  "tax_amount": 0,
                  "product_id": 19024,
                  "category": "Women's Accessories",
                  "sku": "ZO0082400824",
                  "taxless_price": 10.99,
                  "unit_discount_amount": 0,
                  "min_price": 5.17,
                  "_id": "sold_product_583581_19024",
                  "discount_amount": 0,
                  "created_on": "2016-12-25T14:16:48+00:00",
                  "product_name": "Snood - white/grey/peach",
                  "price": 10.99,
                  "taxful_price": 10.99,
                  "base_unit_price": 10.99
                }
              ]
            }
          }
        ]
      }
    }
  }
}

----------------------------------------

TITLE: Update Workflow Fields Example
DESCRIPTION: Example of updating specific fields in an existing workflow

LANGUAGE: json
CODE:
PUT /_plugins/_flow_framework/workflow/<workflow_id>?update_fields=true
{
  "name": "new-template-name",
  "description": "A new description for the existing template"
}

----------------------------------------

TITLE: Installing Multiple OpenSearch Plugins
DESCRIPTION: Command syntax for installing multiple OpenSearch plugins in a single command.

LANGUAGE: bash
CODE:
bin/opensearch-plugin install <plugin-name> <plugin-name> ... <plugin-name>

----------------------------------------

TITLE: Accessing Event Fields in Logstash Configuration
DESCRIPTION: Demonstrates how to reference fields in a Logstash event, including nested fields and using string expansion syntax.

LANGUAGE: bash
CODE:
{
  "request": "/products/view/123",
  "verb": "GET",
  "response": 200,
  "headers": {
  "request_path" => "/"
  }
}

----------------------------------------

TITLE: Overwriting Existing Entries with Add Entries Processor in YAML
DESCRIPTION: This example demonstrates how to configure the add_entries processor to overwrite existing entries in an event.

LANGUAGE: yaml
CODE:
processor:
  - add_entries:
      entries:
        - key: "message"
          value: "bye"
          overwrite_if_key_exists: true

----------------------------------------

TITLE: Testing SSL-enabled Shutdown API
DESCRIPTION: Example of executing the shutdown API with SSL enabled and self-signed certificate

LANGUAGE: bash
CODE:
curl -k -X POST https://localhost:4900/shutdown

----------------------------------------

TITLE: Searching for Workflows by State in OpenSearch
DESCRIPTION: This example demonstrates how to search for all workflows with a specific state. It uses a match query to find workflows with the state 'NOT_STARTED'.

LANGUAGE: json
CODE:
GET /_plugins/_flow_framework/workflow/state/_search
{
  "query": {
    "match": {
      "state": "NOT_STARTED"
    }
  }
}

----------------------------------------

TITLE: Legacy Index-Level Concurrent Search Enable Setting
DESCRIPTION: Applies the deprecated concurrent segment search enabled setting for a specific index.

LANGUAGE: json
CODE:
PUT <index-name>/_settings
{
    "index.search.concurrent_segment_search.enabled": true
}

----------------------------------------

TITLE: Indexing a Document with Payloads in OpenSearch
DESCRIPTION: This JSON request indexes a document into the 'visible_payloads' index. The document contains text with delimited payloads that will be processed by the custom analyzer.

LANGUAGE: json
CODE:
PUT /visible_payloads/_doc/1
{
  "text": "red|1.5 fast|2.0 car|1.0"
}

----------------------------------------

TITLE: Clearing Cache for Specific Fields in OpenSearch
DESCRIPTION: Example request to clear the fields caches of specific fields ('fielda' and 'fieldb') in OpenSearch.

LANGUAGE: json
CODE:
POST /my-index/_cache/clear?fields=fielda,fieldb

----------------------------------------

TITLE: Bulk Indexing Configuration with BulkAll API
DESCRIPTION: Configuration of bulk indexing operations using OpenSearch.Client's BulkAll API with retry and parallelism settings.

LANGUAGE: csharp
CODE:
var bulkAll = osClient.BulkAll(ReadData(), r => r
            .Index(index)
            .BackOffRetries(2)
            .BackOffTime("30s")
            .MaxDegreeOfParallelism(4)
            .Size(100));

----------------------------------------

TITLE: Registering a Model Group in OpenSearch
DESCRIPTION: JSON request to register a new model group for organizing custom local models.

LANGUAGE: json
CODE:
POST /_plugins/_ml/model_groups/_register
{
  "name": "local_model_group",
  "description": "A model group for local models"
}

----------------------------------------

TITLE: Chained Rename Keys Pipeline Configuration
DESCRIPTION: Example pipeline configuration demonstrating sequential key renaming operations.

LANGUAGE: yaml
CODE:
pipeline:
  source:
    file:
      path: "/full/path/to/logs_json.log"
      record_type: "event"
      format: "json"
  processor:
    - rename_keys:
        entries:
        - from_key: "message"
          to_key: "message2"
        - from_key: "message2"
          to_key: "message3"
  sink:
    - stdout:

----------------------------------------

TITLE: Creating OpenSearch Client with Connection Pool in Rust
DESCRIPTION: Create an OpenSearch client with a custom URL and connection pool.

LANGUAGE: rust
CODE:
let url = Url::parse("http://localhost:9200")?
let conn_pool = SingleNodeConnectionPool::new(url);
let transport = TransportBuilder::new(conn_pool).disable_proxy().build()?
let client = OpenSearch::new(transport);

----------------------------------------

TITLE: Query Parameters Template with Global Parameters
DESCRIPTION: Template for query parameters documentation including global parameters, pretty printing, and custom column configuration.

LANGUAGE: html
CODE:
<!-- spec_insert_start
api: search
component: query_parameters
include_global: true
pretty: true
columns: Data type, Parameter, Description, Required, Default
-->
  THIS TEXT SHOULD BE REPLACED
<!-- spec_insert_end -->

----------------------------------------

TITLE: Setting Default Search Pipeline Settings in OpenSearch
DESCRIPTION: Configures the default search pipeline for an index by updating index settings.

LANGUAGE: json
CODE:
PUT /my_index/_settings
{
  "index.search.default_pipeline": "my_pipeline"
}

----------------------------------------

TITLE: Configuring map_to_list Processor with Custom Key and Value Names in YAML
DESCRIPTION: Shows how to configure the map_to_list processor with custom names for the key and value fields in the resulting list objects.

LANGUAGE: yaml
CODE:
processor:
  - map_to_list:
      source: "my-map"
      target: "my-list"
      key_name: "name"
      value_name: "data"

----------------------------------------

TITLE: Deleting Channel Configuration in OpenSearch
DESCRIPTION: Deletes a notification channel configuration using a DELETE request with the config_id.

LANGUAGE: json
CODE:
DELETE /_plugins/_notifications/configs/<config_id>

----------------------------------------

TITLE: Indexing xy point as GeoJSON in OpenSearch
DESCRIPTION: This snippet shows how to index an xy point in GeoJSON format in OpenSearch.

LANGUAGE: json
CODE:
PUT testindex1/_doc/5
{
  "point" : {
    "type" : "Point",
    "coordinates" : [0.5, 4.5]        
  }
}

----------------------------------------

TITLE: Connecting to OpenSearch without SSL
DESCRIPTION: Create an OpenSearch client with SSL disabled, suitable for environments not using the Security plugin.

LANGUAGE: python
CODE:
host = 'localhost'
port = 9200

# Create the client with SSL/TLS and hostname verification disabled.
client = OpenSearch(
    hosts = [{'host': host, 'port': port}],
    http_compress = True, # enables gzip compression for request bodies
    use_ssl = False,
    verify_certs = False,
    ssl_assert_hostname = False,
    ssl_show_warn = False
)

----------------------------------------

TITLE: Creating Search Pipeline for Vector Search
DESCRIPTION: Configures a search pipeline that uses ML inference to generate embeddings and perform vector search.

LANGUAGE: json
CODE:
PUT _search/pipeline/ml_inference_pipeline_cohere_search
{
  "request_processors": [
    {
      "ml_inference": {
        "model_id": "t64OPpUBX2k07okSZc2n",
        "input_map": [
          {
            "texts": "$..ext.ml_inference.text"
          }
        ],
        "output_map": [
          {
            "ext.ml_inference.vector": "embeddings.int8[0]"
          }
        ],
        "model_config": {
          "input_type": "search_query",
          "embedding_types": ["int8"]
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Querying CAT Recovery for Specific Index in OpenSearch
DESCRIPTION: Example request for retrieving recovery information for a specific index using the CAT recovery API in OpenSearch.

LANGUAGE: json
CODE:
GET _cat/recovery/<index>?v

----------------------------------------

TITLE: Enabling Query Metrics in OpenSearch YAML Configuration
DESCRIPTION: This YAML configuration enables query metrics and telemetry features in OpenSearch. It includes settings for the query metrics feature, telemetry, and OpenTelemetry tracer.

LANGUAGE: yaml
CODE:
# Enable query metrics feature
search.query.metrics.enabled: true
telemetry.feature.metrics.enabled: true

# OTel-related configuration
opensearch.experimental.feature.telemetry.enabled: true
telemetry.tracer.sampler.probability: 1.0
telemetry.feature.tracer.enabled: true

----------------------------------------

TITLE: Configuring Multiple Authentication Types in YAML
DESCRIPTION: These snippets demonstrate how to configure multiple authentication types (basic auth with OpenID Connect or SAML) in the opensearch_dashboards.yml file.

LANGUAGE: yaml
CODE:
opensearch_security.auth.type: ["basicauth","openid"]
opensearch_security.auth.multiple_auth_enabled: true

LANGUAGE: yaml
CODE:
opensearch_security.auth.type: ["basicauth","saml"]
opensearch_security.auth.multiple_auth_enabled: true

LANGUAGE: yaml
CODE:
opensearch_security.auth.type: ["basicauth","saml","openid"]
opensearch_security.auth.multiple_auth_enabled: true

----------------------------------------

TITLE: Configuring Multiple Authentication Types in YAML
DESCRIPTION: These snippets demonstrate how to configure multiple authentication types (basic auth with OpenID Connect or SAML) in the opensearch_dashboards.yml file.

LANGUAGE: yaml
CODE:
opensearch_security.auth.type: ["basicauth","openid"]
opensearch_security.auth.multiple_auth_enabled: true

LANGUAGE: yaml
CODE:
opensearch_security.auth.type: ["basicauth","saml"]
opensearch_security.auth.multiple_auth_enabled: true

LANGUAGE: yaml
CODE:
opensearch_security.auth.type: ["basicauth","saml","openid"]
opensearch_security.auth.multiple_auth_enabled: true

----------------------------------------

TITLE: Basic French Analyzer Configuration in OpenSearch
DESCRIPTION: Simple example showing how to specify the French language analyzer in field mapping.

LANGUAGE: json
CODE:
"analyzer": "french"

----------------------------------------

TITLE: Search Backpressure Stats Response in OpenSearch
DESCRIPTION: Example response from the nodes stats API showing detailed statistics about search backpressure including resource tracking and cancellation metrics.

LANGUAGE: json
CODE:
{
  "_nodes": {
    "total": 1,
    "successful": 1,
    "failed": 0
  },
  "cluster_name": "runTask",
  "nodes": {
    "T7aqO6zaQX-lt8XBWBYLsA": {
      "timestamp": 1667409521070,
      "name": "runTask-0",
      "transport_address": "127.0.0.1:9300",
      "host": "127.0.0.1",
      "ip": "127.0.0.1:9300",
      "roles": [
         
      ],
      "attributes": {
        "testattr": "test",
        "shard_indexing_pressure_enabled": "true"
      },
      "search_backpressure": {
        "search_task": {
          "resource_tracker_stats": {
            "heap_usage_tracker": {
              "cancellation_count": 57,
              "current_max_bytes": 5739204,
              "current_avg_bytes": 962465,
              "rolling_avg_bytes": 4009239
            },
            "elapsed_time_tracker": {
              "cancellation_count": 97,
              "current_max_millis": 15902,
              "current_avg_millis": 9705
            },
            "cpu_usage_tracker": {
              "cancellation_count": 64,
              "current_max_millis": 8483,
              "current_avg_millis": 7843
            }
          },
          "cancellation_stats": {
            "cancellation_count": 102,
            "cancellation_limit_reached_count": 25
          }
        },
        "search_shard_task": {
          "resource_tracker_stats": {
            "heap_usage_tracker": {
              "cancellation_count": 34,
              "current_max_bytes": 1203272,
              "current_avg_bytes": 700267,
              "rolling_avg_bytes": 1156270
            },
            "cpu_usage_tracker": {
              "cancellation_count": 318,
              "current_max_millis": 731,
              "current_avg_millis": 303
            },
            "elapsed_time_tracker": {
              "cancellation_count": 310,
              "current_max_millis": 1305,
              "current_avg_millis": 649
            }
          },
          "cancellation_stats": {
            "cancellation_count": 318,
            "cancellation_limit_reached_count": 97
          }
        },
        "mode": "enforced"
      }
    }
  }
}

----------------------------------------

TITLE: Enabling Features in Docker Environment
DESCRIPTION: Enable experimental features in Docker containers by setting JAVA_OPTS environment variable in docker-compose.yml.

LANGUAGE: bash
CODE:
OPENSEARCH_JAVA_OPTS="-Dopensearch.experimental.feature.<feature_name>.enabled=true"

----------------------------------------

TITLE: Search Specific Fields With Pipeline
DESCRIPTION: Performs a search for specific fields while applying the split processor pipeline.

LANGUAGE: json
CODE:
POST /my_index/_search?pretty&search_pipeline=my_pipeline
{
    "fields": ["visibility", "message"]
}

----------------------------------------

TITLE: Example Request for Deleting a Connector in OpenSearch
DESCRIPTION: This is an example DELETE request to remove a specific connector identified by its ID.

LANGUAGE: json
CODE:
DELETE /_plugins/_ml/connectors/KsAo1YsB0jLkkocY6j4U

----------------------------------------

TITLE: Index and Document Operations
DESCRIPTION: Examples of creating indices, adding mappings, and performing document operations

LANGUAGE: ruby
CODE:
index_body = {
    'settings': {
        'index': {
        'number_of_shards': 1,
        'number_of_replicas': 2 
        }
    }
} 

client.indices.create(
    index: 'students',
    body: index_body
)

----------------------------------------

TITLE: Get Workflow Example Request
DESCRIPTION: Example request showing how to retrieve a specific workflow using its ID.

LANGUAGE: json
CODE:
GET /_plugins/_flow_framework/workflow/8xL8bowB8y25Tqfenm50

----------------------------------------

TITLE: Indexing Document with Boolean Values
DESCRIPTION: Example showing how to index a document with different Boolean value formats including true, "true", and empty string representations.

LANGUAGE: json
CODE:
PUT testindex/_doc/1 
{
  "a" : true,
  "b" : "true",
  "c" : ""
}

----------------------------------------

TITLE: Verifying OpenSearch Kubernetes Operator Namespace
DESCRIPTION: This command checks if the OpenSearch and OpenSearch Operator namespaces are active in the Kubernetes cluster.

LANGUAGE: bash
CODE:
k get ns | grep opensearch

----------------------------------------

TITLE: Registering a Question Answering Model in OpenSearch
DESCRIPTION: JSON request to register a question answering model, including model details and configuration.

LANGUAGE: json
CODE:
POST /_plugins/_ml/models/_register
{
    "name": "question_answering",
    "version": "1.0.0",
    "function_name": "QUESTION_ANSWERING",
    "description": "test model",
    "model_format": "TORCH_SCRIPT",
    "model_group_id": "lN4AP40BKolAMNtR4KJ5",
    "model_content_hash_value": "e837c8fc05fd58a6e2e8383b319257f9c3859dfb3edc89b26badfaf8a4405ff6",
    "model_config": { 
        "model_type": "bert",
        "framework_type": "huggingface_transformers"
    },
    "url": "https://github.com/opensearch-project/ml-commons/blob/main/ml-algorithms/src/test/resources/org/opensearch/ml/engine/algorithms/question_answering/question_answering_pt.zip?raw=true"
}

----------------------------------------

TITLE: Python Connector Creation Script
DESCRIPTION: Python script to create a connector for the SageMaker model using AWS credentials and REST API.

LANGUAGE: python
CODE:
import boto3
import requests 
from requests_aws4auth import AWS4Auth

host = 'your_amazon_opensearch_domain_endpoint'
region = 'your_amazon_opensearch_domain_region'
service = 'es'

credentials = boto3.Session().get_credentials()
awsauth = AWS4Auth(credentials.access_key, credentials.secret_key, region, service, session_token=credentials.token)


path = '/_plugins/_ml/connectors/_create'
url = host + path

payload = {
  "name": "Sagemaker embedding model connector",
  "description": "Connector for my Sagemaker embedding model",
  "version": "1.0",
  "protocol": "aws_sigv4",
  "credential": {
    "roleArn": "your_iam_role_arn_created_in_step1"
  },
  "parameters": {
    "region": "your_sagemaker_model_region",
    "service_name": "sagemaker"
  },
  "actions": [
    {
      "action_type": "predict",
      "method": "POST",
      "headers": {
        "content-type": "application/json"
      },
      "url": "your_sagemaker_model_inference_endpoint",
      "request_body": "${parameters.input}",
      "pre_process_function": "connector.pre_process.default.embedding",
      "post_process_function": "connector.post_process.default.embedding"
    }
  ]
}

headers = {"Content-Type": "application/json"}

r = requests.post(url, auth=awsauth, json=payload, headers=headers)
print(r.status_code)
print(r.text)

----------------------------------------

TITLE: CAT Segments API Endpoints
DESCRIPTION: Available endpoints for the CAT segments operation. Allows retrieval of segment information for all indexes or specific indexes.

LANGUAGE: json
CODE:
GET /_cat/segments
GET /_cat/segments/{index}

----------------------------------------

TITLE: Creating Index with Dynamic Strict
DESCRIPTION: Creates an OpenSearch index with strict dynamic mapping that throws an exception when encountering unmapped fields during indexing.

LANGUAGE: json
CODE:
PUT testindex1
{
  "mappings": {
    "dynamic": strict,
    "properties": {
      "patient": {
        "properties": {
          "id": {
            "type": "keyword"
          },
          "name": {
            "type": "keyword"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Retrieving Sorted Document in OpenSearch
DESCRIPTION: This snippet shows how to retrieve a document that has been processed by the Sort pipeline. It uses the document ID returned from the ingestion step.

LANGUAGE: json
CODE:
GET testindex1/_doc/no-Py48BwFahnwl9KZzf

----------------------------------------

TITLE: Clear Cache API Endpoint in OpenSearch
DESCRIPTION: The main endpoint for the Clear Cache API in OpenSearch. It uses a POST request to clear caches for specified targets.

LANGUAGE: json
CODE:
POST /<target>/_cache/clear

----------------------------------------

TITLE: Registering Anthropic Claude v2 Model
DESCRIPTION: Registers the Anthropic Claude v2 model using the previously created connector ID.

LANGUAGE: JSON
CODE:
POST /_plugins/_ml/models/_register?deploy=true
{
    "name": "Bedrock Claude2 model",
    "function_name": "remote",
    "description": "Bedrock Claude2 model",
    "connector_id": "your_connector_id"
}

----------------------------------------

TITLE: Shard Level Stats Query
DESCRIPTION: Retrieves shard-level statistics for an index

LANGUAGE: json
CODE:
GET /testindex/_stats?level=shards

----------------------------------------

TITLE: Creating Parent-Join Index
DESCRIPTION: Creates an OpenSearch index with a parent-join field to establish relationships between documents of different types within the same index.

LANGUAGE: json
CODE:
PUT /my_index
{
  "mappings": {
    "properties": {
      "my_join_field": {
        "type": "join",
        "relations": {
          "parent": "child"
        }
      },
      "text": {
        "type": "text"
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Index with Trim Token Filter and Pattern Tokenizer
DESCRIPTION: Creates a new index with a custom analyzer that uses a trim filter and pattern tokenizer. The analyzer includes lowercase filtering and custom trim filtering to handle whitespace.

LANGUAGE: json
CODE:
PUT /my_pattern_trim_index
{
  "settings": {
    "analysis": {
      "filter": {
        "my_trim_filter": {
          "type": "trim"
        }
      },
      "tokenizer": {
        "my_pattern_tokenizer": {
          "type": "pattern",
          "pattern": ","
        }
      },
      "analyzer": {
        "my_pattern_trim_analyzer": {
          "type": "custom",
          "tokenizer": "my_pattern_tokenizer",
          "filter": [
            "lowercase",
            "my_trim_filter"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Get Snapshot Status API Response Example
DESCRIPTION: Example response showing detailed status information for a snapshot, including overall stats and per-index details.

LANGUAGE: json
CODE:
{
  "snapshots" : [
    {
      "snapshot" : "my-first-snapshot",
      "repository" : "my-opensearch-repo",
      "uuid" : "dCK4Qth-TymRQ7Tu7Iga0g",
      "state" : "SUCCESS",
      "include_global_state" : true,
      "shards_stats" : {
        "initializing" : 0,
        "started" : 0,
        "finalizing" : 0,
        "done" : 7,
        "failed" : 0,
        "total" : 7
      },
      "stats" : {
        "incremental" : {
          "file_count" : 31,
          "size_in_bytes" : 24488927
        },
        "total" : {
          "file_count" : 31,
          "size_in_bytes" : 24488927
        },
        "start_time_in_millis" : 1660666841667,
        "time_in_millis" : 14054
      },
      "indices" : {
        ".opensearch-observability" : {
          "shards_stats" : {
            "initializing" : 0,
            "started" : 0,
            "finalizing" : 0,
            "done" : 1,
            "failed" : 0,
            "total" : 1
          },
          "stats" : {
            "incremental" : {
              "file_count" : 1,
              "size_in_bytes" : 208
            },
            "total" : {
              "file_count" : 1,
              "size_in_bytes" : 208
            },
            "start_time_in_millis" : 1660666841868,
            "time_in_millis" : 201
          },
          "shards" : {
            "0" : {
              "stage" : "DONE",
              "stats" : {
                "incremental" : {
                  "file_count" : 1,
                  "size_in_bytes" : 208
                },
                "total" : {
                  "file_count" : 1,
                  "size_in_bytes" : 208
                },
                "start_time_in_millis" : 1660666841868,
                "time_in_millis" : 201
              }
            }
          }
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Configuring RAG Pipeline for Claude 3.5
DESCRIPTION: Creates a search pipeline with a RAG processor using the registered Claude 3.5 model.

LANGUAGE: JSON
CODE:
PUT /_search/pipeline/my-conversation-search-pipeline-claude
{
  "response_processors": [
    {
      "retrieval_augmented_generation": {
        "tag": "Demo pipeline",
        "description": "Demo pipeline Using Bedrock Claude",
        "model_id": "your_model_id",
        "context_field_list": [
          "text"
        ],
        "system_prompt": "You are a helpful assistant",
        "user_instructions": "Generate a concise and informative answer in less than 100 words for the given question"
      }
    }
  ]
}

----------------------------------------

TITLE: Running the IndexMappingTool Agent in OpenSearch
DESCRIPTION: This JSON snippet shows how to execute the registered IndexMappingTool agent. It specifies the index to query and the question to ask about the index fields.

LANGUAGE: json
CODE:
{
  "parameters": {
    "index": [ "sample-ecommerce" ],
    "question": "What fields are in the sample-ecommerce index?"
  }
}

----------------------------------------

TITLE: Ubuntu 20.04 Setup Script for AWS Inferentia
DESCRIPTION: Comprehensive setup script for configuring AWS Inferentia on Ubuntu 20.04, including package installation, Python environment setup, and system configuration.

LANGUAGE: bash
CODE:
. /etc/os-release
sudo tee /etc/apt/sources.list.d/neuron.list > /dev/null <<EOF
deb https://apt.repos.neuron.amazonaws.com ${VERSION_CODENAME} main
EOF
wget -qO - https://apt.repos.neuron.amazonaws.com/GPG-PUB-KEY-AMAZON-AWS-NEURON.PUB | sudo apt-key add -

# Update OS packages
sudo apt-get update -y

# Install OS headers
sudo apt-get install linux-headers-$(uname -r) -y

# Install Neuron Driver
sudo apt-get install aws-neuronx-dkms -y

# Install Neuron Tools
sudo apt-get install aws-neuronx-tools -y

# Install Python3.7
sudo add-apt-repository ppa:deadsnakes/ppa
sudo apt-get install python3.7

# Install Python venv and activate Python virtual environment
cd ~
sudo apt-get install -y python3.7-venv g++
python3.7 -m venv pytorch_venv
source pytorch_venv/bin/activate
pip install -U pip

# Set pip repository
pip config set global.extra-index-url https://pip.repos.neuron.amazonaws.com

# Install Neuron PyTorch
pip install torch-neuron torchvision

# Copy torch neuron lib to OpenSearch
PYTORCH_NEURON_LIB_PATH=~/pytorch_venv/lib/python3.7/site-packages/torch_neuron/lib/
mkdir -p $OPENSEARCH_HOME/lib/torch_neuron; cp -r $PYTORCH_NEURON_LIB_PATH/ $OPENSEARCH_HOME/lib/torch_neuron
export PYTORCH_EXTRA_LIBRARY_PATH=$OPENSEARCH_HOME/lib/torch_neuron/lib/libtorchneuron.so
echo "export PYTORCH_EXTRA_LIBRARY_PATH=$OPENSEARCH_HOME/lib/torch_neuron/lib/libtorchneuron.so" | tee -a ~/.bash_profile

# Configure system settings
echo "-Xss2m" | tee -a $OPENSEARCH_HOME/config/jvm.options
echo "$(whoami) - nofile 65535" | sudo tee -a /etc/security/limits.conf
sudo sysctl -w vm.max_map_count=262144

----------------------------------------

TITLE: Configuring Fluent Bit With SSL and Authentication
DESCRIPTION: Enhanced Fluent Bit configuration including SSL certificates and basic authentication for secure log forwarding to Data Prepper.

LANGUAGE: yaml
CODE:
[INPUT]
  name                  tail
  refresh_interval      5
  path                  test.log
  read_from_head        true

[OUTPUT]
  Name http
  Match *
  Host localhost
  http_User myuser
  http_Passwd mys3cret
  tls On
  tls.crt_file /full/path/to/certfile.crt
  tls.key_file /full/path/to/keyfile.key
  Port 2021
  URI /log/ingest
  Format json

----------------------------------------

TITLE: Defining Student Class Model in C#
DESCRIPTION: C# class definition for representing student documents in OpenSearch with properties for ID, name, graduation year and GPA.

LANGUAGE: csharp
CODE:
public class Student
{
    public int Id { get; init; }
    public string FirstName { get; init; }
    public string LastName { get; init; }
    public int GradYear { get; init; }
    public double Gpa { get; init; }
}

----------------------------------------

TITLE: Configuring Cross-Account S3 Bucket Access for Threat Intelligence
DESCRIPTION: This JSON defines a trust policy that allows an IAM role from one AWS account to access an S3 bucket in another account. It's used for setting up cross-account access to threat intelligence data stored in S3.

LANGUAGE: json
CODE:
{
    "Version": "2012-10-17",
    "Statement": [
     {
            "Effect": "Allow",
            "Principal": {
                "AWS": "arn:aws:iam::123456789012:role/account-1-threat-intel-role"
            },
          "Action": "s3:*",
            "Resource": "arn:aws:s3:::account-2-threat-intel-bucket/*"
     }
 ]
}

----------------------------------------

TITLE: Ingesting Document with Append Processor Pipeline in OpenSearch
DESCRIPTION: Example of ingesting a document using the append processor pipeline.

LANGUAGE: json
CODE:
PUT testindex1/_doc/1?pipeline=user-behavior
{
}

----------------------------------------

TITLE: Removing Model Interface in OpenSearch
DESCRIPTION: Example request to remove both input and output schemas from a model's interface to bypass model schema validation.

LANGUAGE: json
CODE:
PUT /_plugins/_ml/models/IMcNB5UB7judm8f45nXo
{
  "interface": {
    "input": null,
    "output": null
  }
}

----------------------------------------

TITLE: Configuring trim_string Processor in YAML
DESCRIPTION: Pipeline configuration for the trim_string processor that removes whitespace from the beginning and end of specified field values.

LANGUAGE: yaml
CODE:
pipeline:
  source:
    file:
      path: "/full/path/to/logs_json.log"
      record_type: "event"
      format: "json"
  processor:
    - trim_string:
        with_keys:
          - "trimField"
  sink:
    - stdout:

----------------------------------------

TITLE: Searching multiple fields
DESCRIPTION: Example of searching multiple fields using the fields parameter in a query_string query.

LANGUAGE: json
CODE:
GET testindex/_search
{
  "query": {
    "query_string": {
      "fields": [ "title", "description" ],
      "query": "wind AND film"
    }
  }
}

----------------------------------------

TITLE: Basic Wildcard Query in OpenSearch
DESCRIPTION: Example of a case-sensitive wildcard query searching for terms that start with 'H' and end with 'Y' in the shakespeare index.

LANGUAGE: json
CODE:
GET shakespeare/_search
{
  "query": {
    "wildcard": {
      "speaker": {
        "value": "H*Y",
        "case_insensitive": false
      }
    }
  }
}

----------------------------------------

TITLE: Creating Index Template for Data Stream
DESCRIPTION: Creates an index template that configures indexes as a data stream. The template includes pattern matching and requires an @timestamp field.

LANGUAGE: json
CODE:
PUT _index_template/logs-template
{
  "index_patterns": [
    "my-data-stream",
    "logs-*"
  ],
  "data_stream": {},
  "priority": 100
}

----------------------------------------

TITLE: Configuring Custom Patterns in Grok Processor
DESCRIPTION: This snippet demonstrates how to define and use custom patterns in the grok processor configuration for more specific text matching needs.

LANGUAGE: json
CODE:
processor:
  - grok:
      pattern_definitions:
        CUSTOM_PATTERN_1: 'this-is-regex-1'
        CUSTOM_PATTERN_2: '%{CUSTOM_PATTERN_1} REGEX'
      match:
        message: ["%{CUSTOM_PATTERN_2:my_pattern_key}"]

----------------------------------------

TITLE: Deleting a Threat Intelligence Monitor in OpenSearch
DESCRIPTION: This snippet demonstrates how to delete an existing threat intelligence monitor using a DELETE request with the monitor ID specified in the URL.

LANGUAGE: json
CODE:
DELETE /_plugins/_security_analytics/threat_intel/monitors/B8p88ZAB1vBjq44wkjEy

----------------------------------------

TITLE: Response for No Active Replications
DESCRIPTION: Sample response showing metrics when no active segment replications are occurring.

LANGUAGE: bash
CODE:
shardId target_node target_host checkpoints_behind bytes_behind current_lag last_completed_lag rejected_requests
[index-1][0] runTask-1 127.0.0.1 0 0b 0s 7ms 0

----------------------------------------

TITLE: Get Specific Workflow Steps Request
DESCRIPTION: Example cURL request to fetch specific workflow steps by providing step names as query parameters.

LANGUAGE: json
CODE:
GET /_plugins/_flow_framework/workflow/_step?workflow_step=create_connector,delete_model,deploy_model

----------------------------------------

TITLE: Installing Query Insights Plugin in OpenSearch
DESCRIPTION: Command to install the query-insights plugin in OpenSearch using the opensearch-plugin installation tool.

LANGUAGE: bash
CODE:
bin/opensearch-plugin install query-insights

----------------------------------------

TITLE: Vector Index Creation
DESCRIPTION: JSON configuration for creating a vector index with KNN settings and embedding pipeline.

LANGUAGE: json
CODE:
{
  "settings": {
    "index": {
      "knn.space_type": "cosinesimil",
      "default_pipeline": "my_sagemaker_embedding_pipeline",
      "knn": "true"
    }
  },
  "mappings": {
    "properties": {
      "text_knn": {
        "type": "knn_vector",
        "dimension": your_sagemake_model_embedding_dimension
      }
    }
  }
}

----------------------------------------

TITLE: Retrieving Processed Document
DESCRIPTION: Query to retrieve a document that has been processed by the trim pipeline.

LANGUAGE: json
CODE:
GET testindex1/_doc/1

----------------------------------------

TITLE: Configuring S3 DLQ Writer in OpenSearch Data Prepper
DESCRIPTION: Configuration snippet for setting up an S3 dead-letter queue writer in the pipeline.yaml file. Specifies the bucket, key path prefix, region, and optional STS role ARN for AWS authentication.

LANGUAGE: yaml
CODE:
  sink:
    opensearch:
      dlq:
        s3:
          bucket: "my-dlq-bucket"
          key_path_prefix: "dlq-files/"
          region: "us-west-2"
          sts_role_arn: "arn:aws:iam::123456789012:role/dlq-role"

----------------------------------------

TITLE: Continuing Conversation with Memory
DESCRIPTION: Continues the conversation by providing the same memory ID in a follow-up search request.

LANGUAGE: JSON
CODE:
GET /qa_demo/_search?search_pipeline=my-conversation-search-pipeline-claude
{
"query": {
    "match": {
    "text": "What's the population increase of Chicago from 2021 to 2023?"
    }
},
"size": 1,
"_source": [
    "text"
],
"ext": {
    "generative_qa_parameters": {
    "llm_model": "bedrock-converse/anthropic.claude-3-sonnet-20240229-v1:0",
    "llm_question": "can you compare the population increase of Chicago with New York City",
    "context_size": 5,
    "memory_id": "sBAqY5UBSzdNxlHvrSJK"
    }
}
}

----------------------------------------

TITLE: Code Formatting Example - Triple Backticks
DESCRIPTION: Shows how to format code blocks using triple backticks in Markdown.

LANGUAGE: markdown
CODE:
```
code block content
```

----------------------------------------

TITLE: Indexing Nested JSON Data in OpenSearch
DESCRIPTION: Bulk operation to index sample employee data with nested project information using OpenSearch bulk API.

LANGUAGE: json
CODE:
POST employees_nested/_bulk?refresh
{"index":{"_id":"1"}}
{"id":3,"name":"Bob Smith","title":null,"projects":[{"name":"SQL Spectrum querying","started_year":1990},{"name":"SQL security","started_year":1999},{"name":"OpenSearch security","started_year":2015}]}
{"index":{"_id":"2"}}
{"id":4,"name":"Susan Smith","title":"Dev Mgr","projects":[]}
{"index":{"_id":"3"}}
{"id":6,"name":"Jane Smith","title":"Software Eng 2","projects":[{"name":"SQL security","started_year":1998},{"name":"Hello security","started_year":2015,"address":[{"city":"Dallas","state":"TX"}]}]}

----------------------------------------

TITLE: Registering a Flow Agent for Retrieval-Augmented Generation in OpenSearch
DESCRIPTION: This snippet demonstrates how to register a flow agent for retrieval-augmented generation (RAG) using the VectorDBTool and MLModelTool. The agent queries a k-NN index and passes the result to an LLM model for processing.

LANGUAGE: json
CODE:
{
  "name": "Test_Agent_For_RAG",
  "type": "flow",
  "description": "this is a test agent",
  "tools": [
    {
      "type": "VectorDBTool",
      "parameters": {
        "model_id": "YOUR_TEXT_EMBEDDING_MODEL_ID",
        "index": "my_test_data",
        "embedding_field": "embedding",
        "source_field": ["text"],
        "input": "${parameters.question}"
      }
    },
    {
      "type": "MLModelTool",
      "description": "A general tool to answer any question",
      "parameters": {
        "model_id": "YOUR_LLM_MODEL_ID",
        "prompt": "\n\nHuman:You are a professional data analyst. You will always answer a question based on the given context first. If the answer is not directly shown in the context, you will analyze the data and find the answer. If you don't know the answer, just say you don't know. \n\n Context:\n${parameters.VectorDBTool.output}\n\nHuman:${parameters.question}\n\nAssistant:"
      }
    }
  ]
}

----------------------------------------

TITLE: Creating Semantic Search Workflow with Cohere Embedding
DESCRIPTION: API request to create and provision a workflow using the semantic_search_with_cohere_embedding_query_enricher template. Requires Cohere API key as input.

LANGUAGE: json
CODE:
POST /_plugins/_flow_framework/workflow?use_case=semantic_search_with_cohere_embedding_query_enricher&provision=true
{
    "create_connector.credential.key" : "<YOUR API KEY>"
}

----------------------------------------

TITLE: Retrieving Inner Hits with Has Parent Query in OpenSearch
DESCRIPTION: This snippet demonstrates how to retrieve parent documents that matched the query using the inner_hits parameter in a Has Parent query.

LANGUAGE: json
CODE:
GET testindex1/_search
{
  "query" : {
    "has_parent": {
      "parent_type":"brand",
      "query": {
        "match" : {
          "name": "economy"
        }
      },
      "inner_hits": {}
    }
  }
}

----------------------------------------

TITLE: Creating Text Embedding Pipeline
DESCRIPTION: Example of creating an ingest pipeline that converts text from passage_text field into embeddings stored in passage_embedding field.

LANGUAGE: json
CODE:
{
  "description": "A text embedding pipeline",
  "processors": [
    {
      "text_embedding": {
        "model_id": "bQ1J8ooBpBj3wT4HVUsb",
        "field_map": {
          "passage_text": "passage_embedding"
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Querying Index Template Endpoint - JSON
DESCRIPTION: Basic endpoint for retrieving information about specific index templates using template names.

LANGUAGE: json
CODE:
GET /_index_template/<template-name>

----------------------------------------

TITLE: Basic Drop Processor Syntax in OpenSearch
DESCRIPTION: Basic syntax example showing how to configure a drop processor with a conditional statement.

LANGUAGE: json
CODE:
{
  "drop": {
    "if": "ctx.foo == 'bar'"
  }
}

----------------------------------------

TITLE: Analyzing Text with UAX URL Email Tokenizer in OpenSearch
DESCRIPTION: This snippet shows how to use the _analyze API to examine the tokens generated by the custom analyzer with the UAX URL email tokenizer.

LANGUAGE: json
CODE:
POST /my_index/_analyze
{
  "analyzer": "my_uax_analyzer",
  "text": "Contact us at support@example.com or visit https://example.com for details."
}

----------------------------------------

TITLE: Adding OpenSearch Dependency to Cargo.toml
DESCRIPTION: Add the OpenSearch crate to the Cargo.toml file for a new Rust project.

LANGUAGE: rust
CODE:
[dependencies]
opensearch = "1.0.0"

----------------------------------------

TITLE: Configuring copy_values Processor for Lists in YAML
DESCRIPTION: This configuration demonstrates how to use the copy_values processor to selectively copy values between two lists of objects in a Data Prepper pipeline.

LANGUAGE: yaml
CODE:
processor:
  - copy_values:
      from_list: mylist
      to_list: newlist
      entries:
        - from_key: name
          to_key: fruit_name

----------------------------------------

TITLE: Creating a Standalone Amazon Bedrock Connector in OpenSearch
DESCRIPTION: Example request to create a standalone Amazon Bedrock connector using the _plugins/_ml/connectors/_create endpoint. This connector uses AWS SigV4 authentication to access the Bedrock Titan embedding model.

LANGUAGE: json
CODE:
POST /_plugins/_ml/connectors/_create
{
  "name": "Amazon Bedrock Connector: embedding",
  "description": "The connector to the Bedrock Titan embedding model",
  "version": 1,
  "protocol": "aws_sigv4",
  "parameters": {
    "region": "<YOUR AWS REGION>",
    "service_name": "bedrock"
  },
  "credential": {
    "access_key": "<YOUR AWS ACCESS KEY>",
    "secret_key": "<YOUR AWS SECRET KEY>",
    "session_token": "<YOUR AWS SECURITY TOKEN>"
  },
  "actions": [
    {
      "action_type": "predict",
      "method": "POST",
      "url": "https://bedrock-runtime.us-east-1.amazonaws.com/model/amazon.titan-embed-text-v1/invoke",
      "headers": {
        "content-type": "application/json",
        "x-amz-content-sha256": "required"
      },
      "request_body": "{ \"inputText\": \"${parameters.inputText}\" }",
      "pre_process_function": "\n    StringBuilder builder = new StringBuilder();\n    builder.append(\"\\\"\");\n    String first = params.text_docs[0];\n    builder.append(first);\n    builder.append(\"\\\"\");\n    def parameters = \"{\" +\"\\\"inputText\\\":\" + builder + \"}\";\n    return  \"{\" +\"\\\"parameters\\\":\" + parameters + \"}\";\n",
      "post_process_function": "\n      def name = \"sentence_embedding\";\n      def dataType = \"FLOAT32\";\n      if (params.embedding == null || params.embedding.length == 0) {\n        return params.message;\n      }\n      def shape = [params.embedding.length];\n      def json = \"{\" +\n                 \"\\\"name\\\":\\\"\" + name + \"\\\",\" +\n                 \"\\\"data_type\\\":\\\"\" + dataType + \"\\\",\" +\n                 \"\\\"shape\\\":\" + shape + \",\" +\n                 \"\\\"data\\\":\" + params.embedding +\n                 \"}\";\n      return json;\n    "
    }
  ]
}

----------------------------------------

TITLE: Performing Bulk Operations in OpenSearch
DESCRIPTION: Use the client's bulk() method to perform multiple operations in a single API call. This example demonstrates indexing, creating, and updating documents in bulk.

LANGUAGE: python
CODE:
movies = '{ "index" : { "_index" : "my-dsl-index", "_id" : "2" } } \n { "title" : "Interstellar", "director" : "Christopher Nolan", "year" : "2014"} \n { "create" : { "_index" : "my-dsl-index", "_id" : "3" } } \n { "title" : "Star Trek Beyond", "director" : "Justin Lin", "year" : "2015"} \n { "update" : {"_id" : "3", "_index" : "my-dsl-index" } } \n { "doc" : {"year" : "2016"} }'

client.bulk(movies)

----------------------------------------

TITLE: Processing Events with Remove Duplicates Action in JSON
DESCRIPTION: Example of how the remove_duplicates action processes events based on identification keys, showing which events are processed and which are dropped.

LANGUAGE: json
CODE:
{ "sourceIp": "127.0.0.1", "destinationIp": "192.168.0.1", "status": 200 }
{ "sourceIp": "127.0.0.1", "destinationIp": "192.168.0.1", "bytes": 1000 }
{ "sourceIp": "127.0.0.2", "destinationIp": "192.168.0.1", "bytes": 1000 }

----------------------------------------

TITLE: Updating a Threat Intelligence Monitor in OpenSearch
DESCRIPTION: This snippet shows how to update an existing threat intelligence monitor using a PUT request. The structure is similar to the create request, allowing modification of monitor properties.

LANGUAGE: json
CODE:
{
    "name": "Threat intel monitor",
    "schedule": {
        "period": {
            "interval": 1,
            "unit": "MINUTES"
        }
    },
    "enabled": false,
    "user": {
        "name": "",
        "backend_roles": [],
        "roles": [],
        "custom_attribute_names": [],
        "user_requested_tenant": null
    },
    "indices": [
        "windows"
    ],
    "per_ioc_type_scan_input_list": [
        {
            "ioc_type": "hashes",
            "index_to_fields_map": {
                "windows": [
                    "file_hash"
                ]
            }
        }
    ],
  "triggers": [
        {
            "data_sources": [
                "windows",
                "random"
            ],
            "name": "regwarg",
            "severity": "high"
        }
    ]
}

----------------------------------------

TITLE: Associating Dashboard with Workspace in TypeScript
DESCRIPTION: This snippet shows how to associate a dashboard saved object with a specific workspace using the 'workspaces' attribute.

LANGUAGE: typescript
CODE:
{
  type: "dashboard",
  id: "da123f20-6680-11ee-93fa-df944ec23359",
  workspaces: ["M5NqCu"]
}

----------------------------------------

TITLE: Sample Input Document JSON Structure
DESCRIPTION: Example document showing fields that will be obfuscated including a phone number and log message with sensitive data.

LANGUAGE: json
CODE:
{
  "id": 1,
  "phone": "(555) 555 5555",
  "log": "My name is Bob and my email address is abc@example.com"
}

----------------------------------------

TITLE: Creating Index Mapping for Terms Set Query
DESCRIPTION: Sets up an index mapping with fields for student names, classes, and minimum required matches. Includes keyword fields for exact matching and an integer field for match requirements.

LANGUAGE: json
CODE:
PUT students
{
  "mappings": {
    "properties": {
      "name": {
        "type": "keyword"
      },
      "classes": {
        "type": "keyword"
      },
      "min_required": {
        "type": "integer"
      }
    }
  }
}

----------------------------------------

TITLE: Creating Data Streams
DESCRIPTION: Initializes data streams for Redis and Nginx logs using the data stream API.

LANGUAGE: json
CODE:
PUT _data_stream/logs-redis
PUT _data_stream/logs-nginx

----------------------------------------

TITLE: OpenTelemetry Source Configuration with SSL and Authentication
DESCRIPTION: Example showing how to configure otel-trace-source with SSL and basic authentication enabled.

LANGUAGE: yaml
CODE:
source:
  otel_traces_source:
    ssl: true
    sslKeyCertChainFile: "/full/path/to/certfile.crt"
    sslKeyFile: "/full/path/to/keyfile.key"
    authentication:
      http_basic:
        username: "my-user"
        password: "my_s3cr3t"

----------------------------------------

TITLE: Node-Level Memory Limit Settings
DESCRIPTION: Settings that control memory usage thresholds at the node level. Defines soft limits for memory usage as a percentage of the node's capacity.

LANGUAGE: yaml
CODE:
shard_indexing_pressure.primary_parameter.node.soft_limit: 70%

----------------------------------------

TITLE: Querying Multiple Specific Thread Pools in OpenSearch
DESCRIPTION: This example shows how to retrieve information for multiple specific thread pools by separating their names with commas in the request URL.

LANGUAGE: json
CODE:
GET _cat/thread_pool/thread_pool_name_1,thread_pool_name_2,thread_pool_name_3

----------------------------------------

TITLE: Example Query Structure in OpenSearch
DESCRIPTION: Demonstrates the simplified query structure used for grouping similar queries.

LANGUAGE: c
CODE:
bool
  must
    exists
  query_string

----------------------------------------

TITLE: Configuring Username Rate Limiting in OpenSearch
DESCRIPTION: Configuration settings for username-based rate limiting in OpenSearch Security plugin. This configuration limits login attempts by username across the entire network, with settings for attempt limits, time windows, and blocking periods.

LANGUAGE: yml
CODE:
auth_failure_listeners:
  internal_authentication_backend_limiting:
    type: username
    authentication_backend: internal
    allowed_tries: 3
    time_window_seconds: 60
    block_expiry_seconds: 60
    max_blocked_clients: 100000
    max_tracked_clients: 100000

----------------------------------------

TITLE: Configuring Username Rate Limiting in OpenSearch
DESCRIPTION: Configuration settings for username-based rate limiting in OpenSearch Security plugin. This configuration limits login attempts by username across the entire network, with settings for attempt limits, time windows, and blocking periods.

LANGUAGE: yml
CODE:
auth_failure_listeners:
  internal_authentication_backend_limiting:
    type: username
    authentication_backend: internal
    allowed_tries: 3
    time_window_seconds: 60
    block_expiry_seconds: 60
    max_blocked_clients: 100000
    max_tracked_clients: 100000

----------------------------------------

TITLE: Specifying Similarity Algorithm in OpenSearch Mappings
DESCRIPTION: This snippet shows how to specify different similarity algorithms for fields when configuring mappings in OpenSearch. It sets 'boolean' similarity for one field and uses the default 'BM25' for another.

LANGUAGE: json
CODE:
PUT /testindex
{
  "mappings": {
    "properties": {
      "bm25_field": { 
        "type": "text"
      },
      "boolean_field": {
        "type": "text",
        "similarity": "boolean" 
      }
    }
  }
}

----------------------------------------

TITLE: Testing the Registered Claude 3.5 Model
DESCRIPTION: Sends a test query to the registered Claude 3.5 model to verify its functionality.

LANGUAGE: JSON
CODE:
POST /_plugins/_ml/models/your_model_id/_predict
{
  "parameters": {
    "messages": [
      {
        "role": "user",
        "content": [
          {
            "text": "hello"
          }
        ]
      }
    ]
  }
}

----------------------------------------

TITLE: Running Jekyll spec-insert Commands
DESCRIPTION: Shell commands for running the spec-insert plugin with various options including watch mode and error handling.

LANGUAGE: shell
CODE:
bundle exec jekyll spec-insert

LANGUAGE: shell
CODE:
bundle exec jekyll spec-insert -W

LANGUAGE: shell
CODE:
bundle exec jekyll spec-insert -F

LANGUAGE: shell
CODE:
bundle exec jekyll spec-insert --refresh-spec

----------------------------------------

TITLE: Enabling Anonymous Authentication in OpenSearch Dashboards
DESCRIPTION: Configuration setting for enabling anonymous authentication in OpenSearch Dashboards' opensearch_dashboards.yml file.

LANGUAGE: yaml
CODE:
opensearch_security.auth.anonymous_auth_enabled: true

----------------------------------------

TITLE: Installing Sycamore with OpenSearch Connector in Bash
DESCRIPTION: This command installs the Sycamore library using pip, including the OpenSearch connector. It's the recommended method for installing Sycamore for use with OpenSearch.

LANGUAGE: bash
CODE:
pip install sycamore-ai[opensearch]

----------------------------------------

TITLE: Executing Painless Stored Script in OpenSearch Search Request
DESCRIPTION: This snippet demonstrates how to execute a stored Painless script named 'my-first-script' within a search request to the 'books' index. The script calculates the total ratings for each book.

LANGUAGE: json
CODE:
{
  "script_fields": {
    "total_ratings": {
      "script": {
        "id": "my-first-script" 
      }
    }
  }
}

----------------------------------------

TITLE: RankLib Model Upload Request
DESCRIPTION: POST request example for uploading a trained RankLib model to the Learning to Rank plugin.

LANGUAGE: json
CODE:
{
    "model": {
        "name": "my_ranklib_model",
        "model": {
            "type": "model/ranklib",
            "definition": "## LambdaMART\n## No. of trees = 1000\n## No. of leaves = 10\n## No. of threshold candidates = 256\n## Learning rate = 0.1\n## Stop early = 100\n\n<ensemble>\n   <tree id=\"1\" weight=\"0.1\">\n       <split>\n           <feature> 2 </feature>\n           ..."
        }
    }
}

----------------------------------------

TITLE: Getting Snapshot Policies
DESCRIPTION: API endpoints for retrieving snapshot management policies, supporting both listing all policies and getting specific policies by name. Includes support for pagination and query string filtering.

LANGUAGE: json
CODE:
GET _plugins/_sm/policies

LANGUAGE: json
CODE:
GET _plugins/_sm/policies?from=0&size=20&sortField=sm_policy.name&sortOrder=desc&queryString=*

LANGUAGE: json
CODE:
GET _plugins/_sm/policies/<policy_name>

----------------------------------------

TITLE: Italian Analyzer with Stem Exclusion
DESCRIPTION: Configuration for Italian analyzer with stem exclusion to prevent specific words from being stemmed.

LANGUAGE: json
CODE:
PUT index_with_stem_exclusion_italian_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "stem_exclusion_italian_analyzer": {
          "type": "italian",
          "stem_exclusion": ["autorit", "approvazione"]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Building OpenSearch Documentation with Docker Compose
DESCRIPTION: Command to build and run the OpenSearch documentation website using Docker Compose, which sets up the necessary environment in a container.

LANGUAGE: shell
CODE:
docker compose -f docker-compose.dev.yml up

----------------------------------------

TITLE: Basic Remove_by_pattern Syntax
DESCRIPTION: Basic JSON syntax for the remove_by_pattern processor showing the field_pattern parameter structure.

LANGUAGE: json
CODE:
{
    "remove_by_pattern": {
        "field_pattern": "field_name_prefix*"
    }
}

----------------------------------------

TITLE: Creating Geo Point Mapping in OpenSearch
DESCRIPTION: Creates an index mapping with a field of type geo_point to store geographical coordinates.

LANGUAGE: json
CODE:
PUT /testindex1
{
  "mappings": {
    "properties": {
      "point": {
        "type": "geo_point"
      }
    }
  }
}

----------------------------------------

TITLE: Ingesting Test Data for Conversational Search
DESCRIPTION: Bulk ingests sample population data for various metro areas into an OpenSearch index named 'qa_demo'.

LANGUAGE: JSON
CODE:
POST _bulk
{"index": {"_index": "qa_demo", "_id": "1"}}
{"text": "Chart and table of population level and growth rate for the Ogden-Layton metro area from 1950 to 2023. United Nations population projections are also included through the year 2035.\nThe current metro area population of Ogden-Layton in 2023 is 750,000, a 1.63% increase from 2022.\nThe metro area population of Ogden-Layton in 2022 was 738,000, a 1.79% increase from 2021.\nThe metro area population of Ogden-Layton in 2021 was 725,000, a 1.97% increase from 2020.\nThe metro area population of Ogden-Layton in 2020 was 711,000, a 2.16% increase from 2019."}
{"index": {"_index": "qa_demo", "_id": "2"}}
{"text": "Chart and table of population level and growth rate for the New York City metro area from 1950 to 2023. United Nations population projections are also included through the year 2035.\nThe current metro area population of New York City in 2023 is 18,937,000, a 0.37% increase from 2022.\nThe metro area population of New York City in 2022 was 18,867,000, a 0.23% increase from 2021.\nThe metro area population of New York City in 2021 was 18,823,000, a 0.1% increase from 2020.\nThe metro area population of New York City in 2020 was 18,804,000, a 0.01% decline from 2019."}
{"index": {"_index": "qa_demo", "_id": "3"}}
{"text": "Chart and table of population level and growth rate for the Chicago metro area from 1950 to 2023. United Nations population projections are also included through the year 2035.\nThe current metro area population of Chicago in 2023 is 8,937,000, a 0.4% increase from 2022.\nThe metro area population of Chicago in 2022 was 8,901,000, a 0.27% increase from 2021.\nThe metro area population of Chicago in 2021 was 8,877,000, a 0.14% increase from 2020.\nThe metro area population of Chicago in 2020 was 8,865,000, a 0.03% increase from 2019."}
{"index": {"_index": "qa_demo", "_id": "4"}}
{"text": "Chart and table of population level and growth rate for the Miami metro area from 1950 to 2023. United Nations population projections are also included through the year 2035.\nThe current metro area population of Miami in 2023 is 6,265,000, a 0.8% increase from 2022.\nThe metro area population of Miami in 2022 was 6,215,000, a 0.78% increase from 2021.\nThe metro area population of Miami in 2021 was 6,167,000, a 0.74% increase from 2020.\nThe metro area population of Miami in 2020 was 6,122,000, a 0.71% increase from 2019."}
{"index": {"_index": "qa_demo", "_id": "5"}}
{"text": "Chart and table of population level and growth rate for the Austin metro area from 1950 to 2023. United Nations population projections are also included through the year 2035.\nThe current metro area population of Austin in 2023 is 2,228,000, a 2.39% increase from 2022.\nThe metro area population of Austin in 2022 was 2,176,000, a 2.79% increase from 2021.\nThe metro area population of Austin in 2021 was 2,117,000, a 3.12% increase from 2020.\nThe metro area population of Austin in 2020 was 2,053,000, a 3.43% increase from 2019."}
{"index": {"_index": "qa_demo", "_id": "6"}}
{"text": "Chart and table of population level and growth rate for the Seattle metro area from 1950 to 2023. United Nations population projections are also included through the year 2035.\nThe current metro area population of Seattle in 2023 is 3,519,000, a 0.86% increase from 2022.\nThe metro area population of Seattle in 2022 was 3,489,000, a 0.81% increase from 2021.\nThe metro area population of Seattle in 2021 was 3,461,000, a 0.82% increase from 2020.\nThe metro area population of Seattle in 2020 was 3,433,000, a 0.79% increase from 2019."}

----------------------------------------

TITLE: Applying Dutch Analyzer to Text Field in OpenSearch
DESCRIPTION: This snippet demonstrates how to apply the built-in Dutch analyzer to a text field in an OpenSearch index mapping.

LANGUAGE: json
CODE:
PUT /dutch-index
{
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "dutch"
      }
    }
  }
}

----------------------------------------

TITLE: Using OpenSearch Keystore Base Command
DESCRIPTION: Basic command syntax for using the opensearch-keystore utility script with commands and options.

LANGUAGE: bash
CODE:
opensearch-keystore [command] [options]

----------------------------------------

TITLE: Multiple Indices CAT Count Query
DESCRIPTION: Request to get document count for multiple indices or aliases.

LANGUAGE: json
CODE:
GET _cat/count/index_or_alias_1,index_or_alias_2,index_or_alias_3

----------------------------------------

TITLE: Configuration - YAML Frontend Matter
DESCRIPTION: YAML configuration block defining the page layout, navigation, redirects and tutorial content structure for RAG implementations and conversational search examples.

LANGUAGE: yaml
CODE:
---
layout: default
title: RAG
parent: Generative AI
has_children: true
has_toc: false
nav_order: 10
redirect_from:
  - /vector-search/tutorials/rag/
  - /vector-search/tutorials/conversational-search/
  - /tutorials/vector-search/rag/
  - /tutorials/gen-ai/rag/
rag:
  - heading: Retrieval-augmented generation (RAG) using the DeepSeek Chat API
    link: /tutorials/gen-ai/rag/rag-deepseek-chat/
    list:
      - "<b>Platform:</b> OpenSearch, Amazon OpenSearch Service"
      - "<b>Model:</b> DeepSeek Chat"
      - '<b>Deployment:</b> Provider API'
  # Additional rag and conversational_search configurations...
---

----------------------------------------

TITLE: Executing Auto-Aggregation in OpenSearch Benchmark
DESCRIPTION: This command demonstrates how to use auto-aggregation to run the 'geonames' workload twice and automatically aggregate the results.

LANGUAGE: bash
CODE:
opensearch-benchmark execute --test-iterations=2 --aggregate=true --workload=geonames --target-hosts=127.0.0.1:9200

----------------------------------------

TITLE: Jekyll Front Matter Configuration
DESCRIPTION: YAML front matter configuration for the Jekyll documentation page, defining layout, navigation, redirects and content structure.

LANGUAGE: yaml
CODE:
---
layout: default
title: Getting started
nav_order: 1
has_children: false
has_toc: false
nav_exclude: true
permalink: /about/
redirect_from:
  - /docs/opensearch/
  - /opensearch/
  - /opensearch/index/
why_use:
  - heading: "Vector database"
    description: "Use OpenSearch as a vector database to combine the power of traditional search, analytics, and vector search"
    link: "/vector-search/"
[...]
---

----------------------------------------

TITLE: Registering Model Group for Guardrails
DESCRIPTION: Creates a model group to organize and manage models with guardrail configuration

LANGUAGE: json
CODE:
{
    "name": "bedrock",
    "description": "This is a public model group."
}

----------------------------------------

TITLE: Configuring Maximum Retries in OpenSearch C# Client
DESCRIPTION: Shows how to set the maximum number of retry attempts for OpenSearch client requests using the ConnectionSettings object.

LANGUAGE: csharp
CODE:
var settings = new ConnectionSettings(connectionPool).MaximumRetries(5);

----------------------------------------

TITLE: Creating Histograms with Histogram Action in JSON
DESCRIPTION: Demonstration of how the histogram action aggregates events and generates a new event with histogram data based on a configured key.

LANGUAGE: json
CODE:
{"max":0.55,"kind":"HISTOGRAM","buckets":[{"min":-3.4028234663852886E38,"max":0.0,"count":0},{"min":0.0,"max":0.25,"count":2},{"min":0.25,"max":0.50,"count":1},{"min":0.50,"max":3.4028234663852886E38,"count":1}],"count":4,"bucketCountsList":[0,2,1,1],"description":"Histogram of latency in the events","sum":1.15,"unit":"seconds","aggregationTemporality":"AGGREGATION_TEMPORALITY_DELTA","min":0.15,"bucketCounts":4,"name":"histogram","startTime":"2022-12-14T06:43:40.848762215Z","explicitBoundsCount":3,"time":"2022-12-14T06:44:04.852564623Z","explicitBounds":[0.0,0.25,0.5],"request":"/index.html","sourceIp": "127.0.0.1", "destinationIp": "192.168.0.1", "key": "latency"}

----------------------------------------

TITLE: Testing Drop Pipeline with Simulate API
DESCRIPTION: Example showing how to test a drop processor pipeline using the simulate API.

LANGUAGE: json
CODE:
{
  "docs": [
    {
      "_index": "testindex1",
      "_id": "1",
      "_source": {
        "user_info": "Sensitive information including credit card"
      }
    }
  ]
}

----------------------------------------

TITLE: Documenting Query Parameters for OpenSearch Cat Health API
DESCRIPTION: This snippet defines a markdown table for query parameters in the OpenSearch cat health API. It includes details on 'expand_wildcard', 'pretty', and 'human' parameters, along with their requirements, data types, and descriptions.

LANGUAGE: markdown
CODE:
## Query parameters

The following table lists the available query parameters.

| Parameter | Required | Data type | Description | Default |
| :--- | :--- | :--- | :--- | :--- |
| `expand_wildcard` | **Required** | String | Whether to expand wildcard expression to concrete indices that are open, closed, or both. For more information, see [cat health API]({{site.url}}{{site.baseurl}}/api-reference/cat/health/). <br> Valid values are: <br> - `open`: Expand wildcards to open indices only. <br> - `closed`: Expand wildcards to closed indices only. <br> - `master`: Expand wildcards for cluster manager nodes only. | N/A |
| `pretty` | _Optional_ | Boolean | Whether to pretty format the returned JSON response. | N/A |
| `human` <br> _DEPRECATED_ | _Optional_ | Boolean | _(Deprecated since 3.0: Use the `format` parameter instead.)_ Whether to return human readable values for statistics. | `true` |

----------------------------------------

TITLE: Configuring IAM Permissions for S3 Source
DESCRIPTION: JSON configuration for IAM permissions to grant Data Prepper access to Amazon S3, SQS, and optionally KMS.

LANGUAGE: json
CODE:
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "s3-access",
            "Effect": "Allow",
            "Action": [
              "s3:GetObject",
              "s3:ListBucket",
              "s3:DeleteObject"
            ],
            "Resource": "arn:aws:s3:::<YOUR-BUCKET>/*"
        },
        {
            "Sid": "sqs-access",
            "Effect": "Allow",
            "Action": [
                "sqs:ChangeMessageVisibility",
                "sqs:DeleteMessage",
                "sqs:ReceiveMessage"
            ],
            "Resource": "arn:aws:sqs:<YOUR-REGION>:<123456789012>:<YOUR-SQS-QUEUE>"
        },
        {
            "Sid": "kms-access",
            "Effect": "Allow",
            "Action": "kms:Decrypt",
            "Resource": "arn:aws:kms:<YOUR-REGION>:<123456789012>:key/<YOUR-KMS-KEY>"
        }
    ]
}

----------------------------------------

TITLE: Registering Model Group in OpenSearch
DESCRIPTION: API call to register a new model group for external models in OpenSearch.

LANGUAGE: json
CODE:
POST /_plugins/_ml/model_groups/_register
{
  "name": "remote_model_group",
  "description": "A model group for external models"
}

----------------------------------------

TITLE: Sample Response for Geodistance Query in OpenSearch
DESCRIPTION: This example shows a typical response from a geodistance query in OpenSearch. It includes metadata about the search and the matching document with its geopoint data.

LANGUAGE: json
CODE:
{
  "took": 5,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 1,
      "relation": "eq"
    },
    "max_score": 1,
    "hits": [
      {
        "_index": "testindex1",
        "_id": "1",
        "_score": 1,
        "_source": {
          "point": {
            "lat": 74,
            "lon": 40.71
          }
        }
      }
    ]
  }
}

----------------------------------------

TITLE: Setting an Index as Write Index in OpenSearch
DESCRIPTION: This snippet shows how to set an index as a write index using the OpenSearch API. It's useful when an index needs to be explicitly designated as writable.

LANGUAGE: bash
CODE:
PUT <index>
{
  "aliases": {
    "<index_alias>" : {
        "is_write_index" : true
    }
  }
}

----------------------------------------

TITLE: IAM Permissions for S3 Sink in Data Prepper
DESCRIPTION: Provides an example IAM policy JSON configuration that grants the necessary permissions for Data Prepper to write to an S3 bucket.

LANGUAGE: json
CODE:
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "s3-access",
            "Effect": "Allow",
            "Action": [
              "s3:PutObject"
            ],
            "Resource": "arn:aws:s3:::<YOUR-BUCKET>/*"
        }
    ]
}

----------------------------------------

TITLE: API Endpoint Definition
DESCRIPTION: Defines the available POST endpoints for the Example API with optional path parameters.

LANGUAGE: json
CODE:
POST /_example/endpoint/
POST /_example/endpoint/<path_parameter>

----------------------------------------

TITLE: Creating Index with Mapping for Score Context in OpenSearch
DESCRIPTION: This snippet shows how to create an index with a mapping for a test document to be used in the score context of the Execute Painless script API.

LANGUAGE: json
CODE:
PUT /testindex1
{
  "mappings": {
    "properties": {
      "gpa_4_0": {
        "type": "float"
      }
    }
  }
}

----------------------------------------

TITLE: Testing an Externally Hosted Model in OpenSearch
DESCRIPTION: JSON request to test a deployed external model using the Predict API.

LANGUAGE: json
CODE:
POST /_plugins/_ml/models/cleMb4kBJ1eYAeTMFFg4/_predict
{
  "parameters": {
    "messages": [
      {
        "role": "system",
        "content": "You are a helpful assistant."
      },
      {
        "role": "user",
        "content": "Hello!"
      }
    ]
  }
}

----------------------------------------

TITLE: Indexing Document with Message Field
DESCRIPTION: Creates an index and adds a document containing a message field that will be split later.

LANGUAGE: json
CODE:
POST /my_index/_doc/1
{
  "message": "ingest, search, visualize, and analyze data",
  "visibility": "public"
}

----------------------------------------

TITLE: Registering S3 Repository via REST API
DESCRIPTION: JSON request to register an Amazon S3 repository using the OpenSearch REST API.

LANGUAGE: json
CODE:
PUT /_snapshot/my-s3-repository
{
  "type": "s3",
  "settings": {
    "bucket": "my-s3-bucket",
    "base_path": "my/snapshot/directory"
  }
}

----------------------------------------

TITLE: Existential Subquery with Nested Collections
DESCRIPTION: SQL query showing how to use EXISTS clause with nested collections to filter parent documents based on nested field conditions.

LANGUAGE: sql
CODE:
SELECT e.name AS employeeName
FROM employees_nested AS e
WHERE EXISTS (
    SELECT *
    FROM e.projects AS p
    WHERE p.name LIKE '%security%'
)

----------------------------------------

TITLE: Listing OpenSearch Keystore Settings
DESCRIPTION: Command to display all settings currently stored in the keystore.

LANGUAGE: bash
CODE:
./bin/opensearch-keystore list

----------------------------------------

TITLE: Defining Endpoints for Streaming Bulk API in OpenSearch
DESCRIPTION: Specifies the endpoints for the Streaming Bulk API, allowing POST requests to _bulk/stream or <index>/_bulk/stream.

LANGUAGE: json
CODE:
POST _bulk/stream
POST <index>/_bulk/stream

----------------------------------------

TITLE: Creating IAM Trust Policy for SageMaker Access
DESCRIPTION: JSON configuration for IAM trust policy allowing OpenSearch service to assume a role for SageMaker access.

LANGUAGE: json
CODE:
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Principal": {
                "Service": "es.amazonaws.com"
            },
            "Action": "sts:AssumeRole"
        }
    ]
}

----------------------------------------

TITLE: Indexing Document with Title and Description
DESCRIPTION: Example of indexing a document with both title and description fields into OpenSearch.

LANGUAGE: json
CODE:
PUT testindex/_doc/2
{
  "title": "Gone with the wind",
  "description": "A 1939 American epic historical film"
}

----------------------------------------

TITLE: Querying Segment Replication Status - Bash
DESCRIPTION: API endpoint to retrieve segment replication backpressure metrics showing shard status, checkpoints, and lag information.

LANGUAGE: bash
CODE:
GET _cat/segment_replication

----------------------------------------

TITLE: Term Statistics Query - JSON
DESCRIPTION: Example of using the experimental TermStat query to retrieve term statistics with custom expressions.

LANGUAGE: json
CODE:
POST tmdb/_search
{
    "query": {
        "term_stat": {
            "expr": "df",
            "aggr": "max",
            "terms": ["rambo", "rocky"],
            "fields": ["title"]
        }
    }
}

----------------------------------------

TITLE: Indexing a Document with Text for Vector Embedding
DESCRIPTION: Indexes a document into OpenSearch that will be processed by the ML inference pipeline to generate vector embeddings.

LANGUAGE: json
CODE:
PUT /template-knn-1/_doc/1
{
  "text": "red shoes"
}

----------------------------------------

TITLE: Retrieving Multiple Field Data in OpenSearch
DESCRIPTION: This request retrieves field data for multiple specific fields. Replace field_name_1, field_name_2, field_name_3 with the desired field names.

LANGUAGE: json
CODE:
GET _cat/fielddata/field_name_1,field_name_2,field_name_3

----------------------------------------

TITLE: Registering the OpenAI GPT-4o Model in OpenSearch
DESCRIPTION: This snippet shows how to register the OpenAI GPT-4o model in OpenSearch using the connector created in the previous step. It includes the model name, function, and connector ID.

LANGUAGE: json
CODE:
POST /_plugins/_ml/models/_register?deploy=true
{
    "name": "OpenAI GPT-4o model",
    "function_name": "remote",
    "description": "OpenAI GPT-4o model",
    "connector_id": "your_connector_id"
}

----------------------------------------

TITLE: Creating a SageMaker Text Embedding Connector with Default Post-Processing
DESCRIPTION: This JSON snippet shows how to create a SageMaker text embedding connector using the OpenSearch API. It includes AWS credentials, region settings, and uses the default post-processing function for embedding models.

LANGUAGE: json
CODE:
{
  "name": "Sagemaker text embedding connector",
  "description": "The connector to Sagemaker",
  "version": 1,
  "protocol": "aws_sigv4",
  "credential": {
    "access_key": "<YOUR SAGEMAKER ACCESS KEY>",
    "secret_key": "<YOUR SAGEMAKER SECRET KEY>",
    "session_token": "<YOUR AWS SECURITY TOKEN>"
  },
  "parameters": {
    "region": "ap-northeast-1",
    "service_name": "sagemaker"
  },
  "actions": [
    {
      "action_type": "predict",
      "method": "POST",
      "url": "sagemaker.ap-northeast-1.amazonaws.com/endpoints/",
      "headers": {
        "content-type": "application/json"
      },
      "post_process_function": "connector.post_process.default.embedding",
      "request_body": "${parameters.input}"
    }
  ]
}

----------------------------------------

TITLE: Enabling Metrics Framework in OpenSearch YAML
DESCRIPTION: Adds the setting to enable the metrics framework feature in the OpenSearch YAML configuration file.

LANGUAGE: yaml
CODE:
telemetry.feature.metrics.enabled=true

----------------------------------------

TITLE: Sorting Search Results using Painless Stored Script in OpenSearch
DESCRIPTION: This example demonstrates how to use a Painless stored script for sorting search results. It calculates total ratings, applies a multiplier, and sorts the results in descending order.

LANGUAGE: json
CODE:
{
   "query": {
    "match_all": {}
  },
  "script_fields": {
    "total_ratings": {
      "script": {
        "id": "multiplier-script",
        "params": {
          "multiplier": 2
        }
      }
    }
  },
  "sort": {
    "_script": {
       "type": "number",
       "script": {
         "id": "multiplier-script",
         "params": {
           "multiplier": 2
          }
       },
       "order": "desc"
    }
  }
}

----------------------------------------

TITLE: Configuring User Agent Processor in YAML
DESCRIPTION: Basic configuration example showing how to set up the user_agent processor with source and target fields.

LANGUAGE: yaml
CODE:
  processor:
    - user_agent:
        source: "ua"
        target: "user_agent"

----------------------------------------

TITLE: Health API Query Parameters Template
DESCRIPTION: Template for cat.health API query parameters including global parameters.

LANGUAGE: html
CODE:
<!-- spec_insert_start
api: cat.health
component: query_parameters
include_global: true
-->
<!-- spec_insert_end -->

----------------------------------------

TITLE: Parsing Metric Units Response in Performance Analyzer API for OpenSearch
DESCRIPTION: Shows the JSON structure of the response when querying for metric units, providing a mapping of metric names to their corresponding units of measurement.

LANGUAGE: json
CODE:
{
  "Disk_Utilization": "%",
  "Cache_Request_Hit": "count",
  "HTTP_RequestDocs": "count",
  "Net_TCP_Lost": "segments/flow",
  "Refresh_Time": "ms",
  "GC_Collection_Event": "count",
  "Merge_Time": "ms",
  "Sched_CtxRate": "count/s",
  "Cache_Request_Size": "B",
  "ThreadPool_QueueSize": "count",
  "Sched_Runtime": "s/ctxswitch",
  "Disk_ServiceRate": "MB/s",
  "Heap_AllocRate": "B/s",
  "Heap_Max": "B",
  "Sched_Waittime": "s/ctxswitch",
  "ShardBulkDocs": "count",
  "Thread_Blocked_Time": "s/event",
  "VersionMap_Memory": "B",
  "Master_Task_Queue_Time": "ms",
  "Merge_CurrentEvent": "count",
  "Indexing_Buffer": "B",
  "Bitset_Memory": "B",
  "Net_PacketDropRate4": "packets/s",
  "Heap_Committed": "B",
  "Net_PacketDropRate6": "packets/s",
  "Thread_Blocked_Event": "count",
  "GC_Collection_Time": "ms",
  "Cache_Query_Miss": "count",
  "IO_TotThroughput": "B/s",
  "Latency": "ms",
  "Net_PacketRate6": "packets/s",
  "Cache_Query_Hit": "count",
  "IO_ReadSyscallRate": "count/s",
  "Net_PacketRate4": "packets/s",
  "Cache_Request_Miss": "count",
  "CB_ConfiguredSize": "B",
  "CB_TrippedEvents": "count",
  "ThreadPool_RejectedReqs": "count",
  "Disk_WaitTime": "ms",
  "Net_TCP_TxQ": "segments/flow",
  "Master_Task_Run_Time": "ms",
  "IO_WriteSyscallRate": "count/s",
  "IO_WriteThroughput": "B/s",
  "Flush_Event": "count",
  "Net_TCP_RxQ": "segments/flow",
  "Refresh_Event": "count",
  "Flush_Time": "ms",
  "Heap_Init": "B",
  "CPU_Utilization": "cores",
  "HTTP_TotalRequests": "count",
  "ThreadPool_ActiveThreads": "count",
  "Cache_Query_Size": "B",
  "Paging_MinfltRate": "count/s",
  "Merge_Event": "count",
  "Net_TCP_SendCWND": "B/flow",
  "Cache_Request_Eviction": "count",
  "Segments_Total": "count",
  "Heap_Used": "B",
  "Cache_FieldData_Eviction": "count",
  "IO_TotalSyscallRate": "count/s",
  "CB_EstimatedSize": "B",
  "Net_Throughput": "B/s",
  "Paging_RSS": "pages",
  "Indexing_ThrottleTime": "ms",
  "IndexWriter_Memory": "B",
  "Master_PendingQueueSize": "count",
  "Net_TCP_SSThresh": "B/flow",
  "Cache_FieldData_Size": "B",
  "Paging_MajfltRate": "count/s",
  "ThreadPool_TotalThreads": "count",
  "IO_ReadThroughput": "B/s",
  "ShardEvents": "count",
  "Net_TCP_NumFlows": "count"
}

----------------------------------------

TITLE: Multiple Inner Hits Query
DESCRIPTION: Advanced search query that returns multiple inner hits for each collapsed result, showing both price and date-based groupings.

LANGUAGE: json
CODE:
GET /bakery-items/_search
{
  "query": {
    "match": {
      "category": "cakes"
    }
  },
  "collapse": {
    "field": "item",
    "inner_hits": [
      {
        "name": "cheapest_items",
        "size": 1,
        "sort": ["price"]
      },
      {
        "name": "newest_items",
        "size": 3,
        "sort": [{ "baked_date": "desc" }]
      }
    ]
  },
  "sort": ["price"]
}

----------------------------------------

TITLE: Testing Bytes Processor Pipeline in OpenSearch
DESCRIPTION: This snippet shows how to test the 'file_upload' pipeline using the _simulate API. It processes a sample document to convert a human-readable file size to bytes.

LANGUAGE: json
CODE:
POST _ingest/pipeline/file_upload/_simulate
{
  "docs": [
    {
      "_index": "testindex1",
      "_id": "1",
      "_source": {
        "file_size_bytes": "10485760",
        "file_size": "10MB"
      }
    }
  ]
}

----------------------------------------

TITLE: Creating IP2Geo Data Source in OpenSearch
DESCRIPTION: This snippet demonstrates how to create an IP2Geo data source in OpenSearch. It specifies the endpoint for downloading GeoIP data and the update interval.

LANGUAGE: json
CODE:
PUT /_plugins/geospatial/ip2geo/datasource/my-datasource
{
    "endpoint" : "https://geoip.maps.opensearch.org/v1/geolite2-city/manifest.json",
    "update_interval_in_days" : 3
}

----------------------------------------

TITLE: Using WHERE Clause in OpenSearch SQL
DESCRIPTION: Example of using the WHERE clause to filter results based on a specific condition (account_number = 1) in OpenSearch SQL.

LANGUAGE: sql
CODE:
SELECT account_number
FROM accounts
WHERE account_number = 1

----------------------------------------

TITLE: Executing Streaming Bulk Request in OpenSearch using cURL
DESCRIPTION: Demonstrates how to send a streaming bulk request using cURL, including multiple operations like delete, index, create, and update.

LANGUAGE: bash
CODE:
curl -X POST "http://localhost:9200/_bulk/stream" -H "Transfer-Encoding: chunked" -H "Content-Type: application/json" -d'
{ "delete": { "_index": "movies", "_id": "tt2229499" } }
{ "index": { "_index": "movies", "_id": "tt1979320" } }
{ "title": "Rush", "year": 2013 }
{ "create": { "_index": "movies", "_id": "tt1392214" } }
{ "title": "Prisoners", "year": 2013 }
{ "update": { "_index": "movies", "_id": "tt0816711" } }
{ "doc" : { "title": "World War Z" } }
'

----------------------------------------

TITLE: Basic ML Inference Processor Syntax
DESCRIPTION: Base syntax template for configuring the ML inference processor showing all available parameters.

LANGUAGE: json
CODE:
{
  "ml_inference": {
    "model_id": "<model_id>",
    "function_name": "<function_name>",
    "full_response_path": "<full_response_path>",
    "model_config":{
      "<model_config_field>": "<config_value>"
    },
    "model_input": "<model_input>",
    "input_map": [
      {
        "<model_input_field>": "<document_field>"
      }
    ],
    "output_map": [
      {
        "<new_document_field>": "<model_output_field>"
      }
    ],
    "override": "<override>"
  }
}

----------------------------------------

TITLE: Shard-Level Memory Control Settings
DESCRIPTION: Configuration for managing memory quotas and operational thresholds at the shard level. Includes settings for minimum limits and various operational factors for memory allocation.

LANGUAGE: yaml
CODE:
shard_indexing_pressure.primary_parameter.shard.min_limit: 0.001d
shard_indexing_pressure.operating_factor.lower: 75%
shard_indexing_pressure.operating_factor.optimal: 85%
shard_indexing_pressure.operating_factor.upper: 95%

----------------------------------------

TITLE: Backing up OpenSearch Security settings
DESCRIPTION: Commands to create backups of OpenSearch Security settings using securityadmin.sh.

LANGUAGE: bash
CODE:
docker exec -it os-node-01 bash

LANGUAGE: bash
CODE:
mkdir /usr/share/opensearch/backups && cd /usr/share/opensearch/backups

LANGUAGE: bash
CODE:
/usr/share/opensearch/plugins/opensearch-security/tools/securityadmin.sh \
   -backup /usr/share/opensearch/backups \
   -icl \
   -nhnv \
   -cacert /usr/share/opensearch/config/root-ca.pem \
   -cert /usr/share/opensearch/config/admin.pem \
   -key /usr/share/opensearch/config/admin-key.pem

LANGUAGE: bash
CODE:
mkdir /usr/share/opensearch/backups/certs && cp /usr/share/opensearch/config/*pem /usr/share/opensearch/backups/certs/

LANGUAGE: bash
CODE:
exit

LANGUAGE: bash
CODE:
docker cp os-node-01:/usr/share/opensearch/backups ~/deploy/

----------------------------------------

TITLE: Admin Certificate Error Output
DESCRIPTION: Error message shown when the TLS certificate used with securityadmin.sh lacks admin privileges.

LANGUAGE: bash
CODE:
Connected as CN=node-0.example.com,OU=SSL,O=Test,L=Test,C=DE
ERR: CN=node-0.example.com,OU=SSL,O=Test,L=Test,C=DE is not an admin user

----------------------------------------

TITLE: Configuring Shared File System Repository in OpenSearch YAML
DESCRIPTION: Configuration snippet for adding a shared file system as a snapshot repository in the opensearch.yml file.

LANGUAGE: yaml
CODE:
path.repo: ["/mnt/snapshots"]

----------------------------------------

TITLE: Example Workflow Step JSON Response
DESCRIPTION: Shows the structure of a workflow step response, including inputs, outputs, and required plugins for the 'register_remote_model' step.

LANGUAGE: json
CODE:
{
  "register_remote_model": {
    "inputs": [
      "name",
      "connector_id"
    ],
    "outputs": [
      "model_id",
      "register_model_status"
    ],
    "required_plugins": [
      "opensearch-ml"
    ]
  }
}

----------------------------------------

TITLE: Creating a URL decode pipeline in OpenSearch
DESCRIPTION: Shows how to create a pipeline named 'urldecode_pipeline' that uses the urldecode processor to decode the 'encoded_url' field and store the result in 'decoded_url'.

LANGUAGE: json
CODE:
PUT _ingest/pipeline/urldecode_pipeline
{
  "description": "Decode URL-encoded strings",
  "processors": [
    {
      "urldecode": {
        "field": "encoded_url",
        "target_field": "decoded_url"
      }
    }
  ]
}

----------------------------------------

TITLE: Creating an ingest pipeline
DESCRIPTION: Creates an ingest pipeline with a text embedding processor to generate vector embeddings during ingestion.

LANGUAGE: json
CODE:
PUT /_ingest/pipeline/nlp-ingest-pipeline
{
  "description": "An NLP ingest pipeline",
  "processors": [
    {
      "text_embedding": {
        "model_id": "aVeif4oB5Vm0Tdw8zYO2",
        "field_map": {
          "text": "passage_embedding"
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Executing Batch Prediction
DESCRIPTION: Example of calling the Batch Predict API with model parameters.

LANGUAGE: json
CODE:
{
  "parameters": {
    "model": "text-embedding-3-large"
  }
}

----------------------------------------

TITLE: Calculating Sum Aggregation in OpenSearch
DESCRIPTION: This query demonstrates how to use a sum aggregation to calculate the total sum of the 'taxful_total_price' field across all documents in the 'opensearch_dashboards_sample_data_ecommerce' index. The size is set to 0 to exclude individual document hits from the response.

LANGUAGE: json
CODE:
{
  "size": 0,
  "aggs": {
    "sum_taxful_total_price": {
      "sum": {
        "field": "taxful_total_price"
      }
    }
  }
}

----------------------------------------

TITLE: Delete Workflow Example Request
DESCRIPTION: Example request showing how to delete a workflow using a specific workflow ID.

LANGUAGE: json
CODE:
DELETE /_plugins/_flow_framework/workflow/8xL8bowB8y25Tqfenm50

----------------------------------------

TITLE: Docker Compose Commands for Cluster Management
DESCRIPTION: Basic Docker Compose commands for starting and stopping the OpenSearch cluster with Jaeger integration

LANGUAGE: bash
CODE:
docker compose up -d

LANGUAGE: bash
CODE:
docker compose down

----------------------------------------

TITLE: Creating a vector index
DESCRIPTION: Creates an index with a text field and a knn_vector field for storing embeddings, using the ingest pipeline.

LANGUAGE: json
CODE:
PUT /my-nlp-index
{
  "settings": {
    "index.knn": true,
    "default_pipeline": "nlp-ingest-pipeline"
  },
  "mappings": {
    "properties": {
      "id": {
        "type": "text"
      },
      "passage_embedding": {
        "type": "knn_vector",
        "dimension": 768,
        "space_type": "l2"
      },
      "text": {
        "type": "text"
      }
    }
  }
}

----------------------------------------

TITLE: Doc as Upsert Operation
DESCRIPTION: Example of using doc_as_upsert to use the doc field content for upserting.

LANGUAGE: json
CODE:
{
  "doc": {
    "first_name": "Martha",
    "last_name": "Oliveira",
    "age": "31"
  },
  "doc_as_upsert": true
}

----------------------------------------

TITLE: Ingesting Sample Document into Vector Index
DESCRIPTION: Adds a sample document to the vector index, which will automatically generate embeddings using the ingest pipeline.

LANGUAGE: json
CODE:
POST /my_index/_doc/1000001
{
    "text": "hello world."
}

----------------------------------------

TITLE: Retrieving Threat Intelligence Findings in OpenSearch
DESCRIPTION: This endpoint returns threat intelligence indicator of compromise (IOC) findings. Findings are automatically generated when the threat intelligence monitor detects a malicious IOC during a data scan.

LANGUAGE: json
CODE:
GET /_plugins/_security_analytics/threat_intel/findings/

----------------------------------------

TITLE: Parsing Hot Shard Identification Response in OpenSearch
DESCRIPTION: This JSON response contains the results of the hot shard identification RCA. It includes cluster-level summaries, node-level details, and specific resource metrics for CPU usage and heap allocation that indicate hot shards.

LANGUAGE: json
CODE:
{
  "HotShardClusterRca": [{
    "rca_name": "HotShardClusterRca",
    "timestamp": 1680721367563,
    "state": "unhealthy",
    "HotClusterSummary": [
      {
        "number_of_nodes": 3,
        "number_of_unhealthy_nodes": 1,
        "HotNodeSummary": [
          {
            "node_id": "7kosAbpASsqBoHmHkVXxmw",
            "host_address": "192.168.80.4",
            "HotResourceSummary": [
              {
                "resource_type": "cpu usage",
                "resource_metric": "cpu usage(num of cores)",
                "threshold": 0.027397981341796683,
                "value": 0.034449630200405396,
                "time_period_seconds": 60,
                "meta_data": "ssZw1WRUSHS5DZCW73BOJQ index9 4"
              },
              {
                "resource_type": "heap",
                "resource_metric": "heap alloc rate(heap alloc rate in bytes per second)",
                "threshold": 7605441.367010161,
                "value": 10872119.748328414,
                "time_period_seconds": 60,
                "meta_data": "ssZw1WRUSHS5DZCW73BOJQ index9 4"
              },
              {
                "resource_type": "heap",
                "resource_metric": "heap alloc rate(heap alloc rate in bytes per second)",
                "threshold": 7605441.367010161,
                "value": 8019622.354388569,
                "time_period_seconds": 60,
                "meta_data": "QRF4rBM7SNCDr1g3KU6HyA index9 0"
              }
            ]
          }
        ]
      }
    ]
  }]
}

----------------------------------------

TITLE: Render Template Request Using Template ID
DESCRIPTION: Example request to render a template using a predefined template ID with parameters.

LANGUAGE: json
CODE:
{
  "id": "play_search_template",
  "params": {
    "play_name": "Henry IV"
  }
}

----------------------------------------

TITLE: Configuring Parquet Codec with Schema in Data Prepper S3 Sink
DESCRIPTION: Demonstrates how to configure the S3 sink to write Parquet data using a custom schema for VPC Flow Logs. It includes AWS settings, bucket configuration, codec settings, and threshold configurations.

LANGUAGE: yaml
CODE:
pipeline:
  ...
  sink:
    - s3:
        aws:
          region: us-east-1
          sts_role_arn: arn:aws:iam::123456789012:role/Data-Prepper
        bucket: mys3bucket
        object_key:
          path_prefix: vpc-flow-logs/%{yyyy}/%{MM}/%{dd}/%{HH}/
        codec:
          parquet:
            schema: >
              {
                "type" : "record",
                "namespace" : "org.opensearch.dataprepper.examples",
                "name" : "VpcFlowLog",
                "fields" : [
                  { "name" : "version", "type" : ["null", "string"]},
                  { "name" : "srcport", "type": ["null", "int"]},
                  { "name" : "dstport", "type": ["null", "int"]},
                  { "name" : "accountId", "type" : ["null", "string"]},
                  { "name" : "interfaceId", "type" : ["null", "string"]},
                  { "name" : "srcaddr", "type" : ["null", "string"]},
                  { "name" : "dstaddr", "type" : ["null", "string"]},
                  { "name" : "start", "type": ["null", "int"]},
                  { "name" : "end", "type": ["null", "int"]},
                  { "name" : "protocol", "type": ["null", "int"]},
                  { "name" : "packets", "type": ["null", "int"]},
                  { "name" : "bytes", "type": ["null", "int"]},
                  { "name" : "action", "type": ["null", "string"]},
                  { "name" : "logStatus", "type" : ["null", "string"]}
                ]
              }
        threshold:
          event_count: 500000000
          maximum_size: 20mb
          event_collect_timeout: PT15M
        buffer_type: in_memory

----------------------------------------

TITLE: Executing PIT Search Query with Sort in OpenSearch
DESCRIPTION: Example of performing a Point in Time search query with sorting by timestamp. The query includes PIT ID, size limit, and sorting parameters.

LANGUAGE: json
CODE:
{
  "size": 10000,
  "query": {
    "match" : {
      "user.id" : "elkbee"
    }
  },
  "pit": {
    "id":  "46ToAwMDaWR5BXV1aWQyKwZub2RlXzMAAAAAAAAAACoBYwADaWR4BXV1aWQxAgZub2RlXzEAAAAAAAAAAAEBYQADaWR5BXV1aWQyKgZub2RlXzIAAAAAAAAAAAwBYgACBXV1aWQyAAAFdXVpZDEAAQltYXRjaF9hbGw_gAAAAA==", 
    "keep_alive": "100m"
  },
  "sort": [ 
    {"@timestamp": {"order": "asc"}}
  ]
}

----------------------------------------

TITLE: Testing Gsub Pipeline in OpenSearch
DESCRIPTION: Shows how to test the gsub_pipeline using the _simulate endpoint. It processes a sample document to verify that the pipeline replaces 'error' with 'warning' in the message field.

LANGUAGE: json
CODE:
POST _ingest/pipeline/gsub_pipeline/_simulate
{
  "docs": [
    {
      "_source": {
        "message": "This is an error message"
      }
    }
  ]
}

----------------------------------------

TITLE: Limiting Monitored Query Groups in OpenSearch
DESCRIPTION: Configures the maximum number of tracked query groups to 100, excluding top N queries.

LANGUAGE: json
CODE:
PUT _cluster/settings
{
  "persistent" : {
    "search.insights.top_queries.max_groups_excluding_topn" : 100
  }
}

----------------------------------------

TITLE: Sample Input Message for Grok Processor
DESCRIPTION: This snippet shows an example of an input message that the grok processor would parse. It contains an IP address, timestamp, and response status.

LANGUAGE: json
CODE:
{"message": "127.0.0.1 198.126.12 [10/Oct/2000:13:55:36 -0700] 200"}

----------------------------------------

TITLE: Field Exclusion Example - JSON Response
DESCRIPTION: Example JSON response showing remaining fields when specific fields (actors, title, year) are excluded through field-level security.

LANGUAGE: json
CODE:
{
  "_index": "movies",
  "_source": {
    "directors": [
      "Ron Howard"
    ],
    "plot": "A re-creation of the merciless 1970s rivalry between Formula One rivals James Hunt and Niki Lauda.",
    "genres": [
      "Action",
      "Biography",
      "Drama",
      "Sport"
    ]
  }
}

----------------------------------------

TITLE: Retrieving Processed Document
DESCRIPTION: Query to retrieve the document after processing by the join pipeline.

LANGUAGE: json
CODE:
GET testindex1/_doc/1

----------------------------------------

TITLE: Local Model Pipeline Configuration
DESCRIPTION: Example of creating an ingest pipeline with a local sentence transformer model.

LANGUAGE: json
CODE:
{
  "description": "ingests reviews and generates embeddings",
  "processors": [
    {
      "ml_inference": {
        "function_name": "text_embedding",
        "full_response_path": true,
        "model_id": "<your model id>",
        "model_config": {
          "return_number": true,
          "target_response": ["sentence_embedding"]
        },
        "model_input": "{ \"text_docs\": ${input_map.text_docs}, \"return_number\": ${model_config.return_number}, \"target_response\": ${model_config.target_response} }",
        "input_map": [
          {
            "text_docs": "book.*.chunk.text.*.context"
          }
        ],
        "output_map": [
          {
            "book.*.chunk.text.*.context_embedding": "$.inference_results.*.output.*.data"
          }
        ],
        "ignore_missing": true,
        "ignore_failure": true
      }
    }
  ]
}

----------------------------------------

TITLE: Jekyll Front Matter Configuration for Reranking Documentation
DESCRIPTION: YAML front matter configuration for a Jekyll documentation page that defines the structure and navigation for OpenSearch reranking tutorials. Includes redirect rules and card-based layout definitions for various reranking implementation methods.

LANGUAGE: yaml
CODE:
---
layout: default
title: Reranking search results
has_children: true
has_toc: false
nav_order: 20
redirect_from:
  - /vector-search/tutorials/reranking/
  - /tutorials/reranking/
reranking:
  - heading: Reranking search results using Cohere Rerank
    link: /tutorials/reranking/reranking-cohere/
    list:
      - "<b>Platform:</b> OpenSearch"
      - "<b>Model:</b> Cohere Rerank"  
      - "<b>Deployment:</b> Provider API"  
  - heading: Reranking search results using Cohere Rerank on Amazon Bedrock
    link: /tutorials/reranking/reranking-cohere-bedrock/
    list:
      - "<b>Platform:</b> OpenSearch, Amazon OpenSearch Service"
      - "<b>Model:</b> Cohere Rerank"  
      - "<b>Deployment:</b> Amazon Bedrock" 
  - heading: Reranking search results using Amazon Bedrock models
    link: /tutorials/reranking/reranking-bedrock/
    list:
      - "<b>Platform:</b> OpenSearch"
      - "<b>Model:</b> Amazon Bedrock reranker models"  
      - "<b>Deployment:</b> Amazon Bedrock"  
  - heading: Reranking search results using a cross-encoder in Amazon SageMaker
    link: /tutorials/reranking/reranking-cross-encoder/
    list:
      - "<b>Platform:</b> OpenSearch"
      - "<b>Model:</b> Hugging Face MS MARCO"  
      - "<b>Deployment:</b> Amazon SageMaker" 
  - heading: Reranking search results using a reranker in Amazon SageMaker
    link: /tutorials/reranking/reranking-sagemaker/
    list:
      - "<b>Platform:</b> OpenSearch, Amazon OpenSearch Service"
      - "<b>Model:</b> Hugging Face BAAI/bge-reranker"  
      - "<b>Deployment:</b> Amazon SageMaker" 
  - heading: Reranking search results by a field
    link: /tutorials/reranking/reranking-by-field/
    list:
      - "<b>Platform:</b> OpenSearch, Amazon OpenSearch Service"
      - "<b>Model:</b> Cohere Rerank"  
      - "<b>Deployment:</b> Provider API" 
---

----------------------------------------

TITLE: Updating Transform Job in OpenSearch
DESCRIPTION: REST API request for updating an existing transform job using sequence number and primary term for concurrency control.

LANGUAGE: json
CODE:
PUT _plugins/_transform/sample?if_seq_no=13&if_primary_term=1
{
  "transform": {
    "enabled": true,
    "schedule": {
      "interval": {
        "period": 1,
        "unit": "Minutes",
        "start_time": 1602100553
      }
    },
    "description": "Sample transform job",
    "source_index": "sample_index",
    "target_index": "sample_target",
    "data_selection_query": {
      "match_all": {}
    },
    "page_size": 1,
    "groups": [
      {
        "terms": {
          "source_field": "customer_gender",
          "target_field": "gender"
        }
      },
      {
        "terms": {
          "source_field": "day_of_week",
          "target_field": "day"
        }
      }
    ],
    "aggregations": {
      "quantity": {
        "sum": {
          "field": "total_quantity"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Ingesting Document with KV Pipeline in OpenSearch
DESCRIPTION: Example of ingesting a document using the KV pipeline to process key-value pairs.

LANGUAGE: json
CODE:
{  
  "message": "goodbye=everybody hello=world"  
}

----------------------------------------

TITLE: Filter Aggregation Response Example
DESCRIPTION: Example response showing the results of a filter aggregation, including the document count and calculated average value for the filtered subset of documents.

LANGUAGE: json
CODE:
"aggregations" : {
  "low_value" : {
    "doc_count" : 1633,
    "avg_amount" : {
      "value" : 38.363175998928355
    }
  }
}

----------------------------------------

TITLE: Sample Node Information Response - OpenSearch REST API
DESCRIPTION: Example response showing node information including IP address, heap usage, RAM usage, CPU load, node roles, and cluster manager status.

LANGUAGE: json
CODE:
ip       |   heap.percent | ram.percent | cpu load_1m | load_5m | load_15m | node.role | node.roles |     cluster_manager |  name
10.11.1.225  |         31   |    32  | 0  |  0.00  |  0.00   | di  | data,ingest,ml  | - |  data-e5b89ad7

----------------------------------------

TITLE: Complete OpenSearch Rust Client Sample Program
DESCRIPTION: A comprehensive sample program demonstrating various OpenSearch operations using the Rust client.

LANGUAGE: rust
CODE:
use opensearch::{DeleteParts, OpenSearch, IndexParts, http::request::JsonBody, BulkParts, SearchParts};
use opensearch::{indices::{IndicesDeleteParts, IndicesCreateParts}};
use serde_json::{json, Value};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let client = OpenSearch::default();

    // Create an index
    let mut response = client
    .indices()
    .create(IndicesCreateParts::Index("movies"))
    .body(json!({
        "mappings" : {
            "properties" : {
                "title" : { "type" : "text" }
            }
        }
    }))
    .send()
    .await?;

    let mut successful = response.status_code().is_success();
    
    if successful {
        println!("Successfully created an index");
    }
    else {
        println!("Could not create an index");
    }

    // Index a single document
    println!("Indexing a single document...");
    response = client
    .index(IndexParts::IndexId("movies", "1"))
    .body(json!({
        "id": 1,
        "title": "Moneyball",
        "director": "Bennett Miller",
        "year": "2011"
    }))
    .send()
    .await?;

    successful = response.status_code().is_success();
    
    if successful {
        println!("Successfully indexed a document");
    }
    else {
        println!("Could not index document");
    }

    // Index multiple documents using the bulk operation

    println!("Indexing multiple documents...");

    let mut body: Vec<JsonBody<_>> = Vec::with_capacity(4);

    // add the first operation and document
    body.push(json!({"index": {"_id": "2"}}).into());
    body.push(json!({
        "id": 2,
        "title": "Interstellar",
        "director": "Christopher Nolan",
        "year": "2014"
    }).into());

    // add the second operation and document
    body.push(json!({"index": {"_id": "3"}}).into());
    body.push(json!({
        "id": 3,
        "title": "Star Trek Beyond",
        "director": "Justin Lin",
        "year": "2015"
    }).into());

    response = client
        .bulk(BulkParts::Index("movies"))
        .body(body)
        .send()
        .await?;

    let mut response_body = response.json::<Value>().await?;
    successful = response_body["errors"].as_bool().unwrap() == false;

    if successful {
        println!("Successfully performed bulk operations");
    }
    else {
        println!("Could not perform bulk operations");
    }

    // Search for a document

    println!("Searching for a document...");
    response = client
    .search(SearchParts::Index(&["movies"]))
    .from(0)
    .size(10)
    .body(json!({
        "query": {
            "multi_match": {
                "query": "miller",
                "fields": ["title^2", "director"]
            }           
        }
    }))
    .send()
    .await?;

    response_body = response.json::<Value>().await?;
    for hit in response_body["hits"]["hits"].as_array().unwrap() {
        // print the source document
        println!("{}", serde_json::to_string_pretty(&hit["_source"]).unwrap());
    }

    // Delete a document

    response = client
    .delete(DeleteParts::IndexId("movies", "2"))
    .send()
    .await?;

    successful = response.status_code().is_success();
    
    if successful {
        println!("Successfully deleted a document");
    }
    else {
        println!("Could not delete document");
    }

    // Delete the index

    response = client
    .indices()
    .delete(IndicesDeleteParts::Index(&["movies"]))
    .send()
    .await?;

    successful = response.status_code().is_success();

    if successful {
        println!("Successfully deleted the index");
    }
    else {
        println!("Could not delete the index");
    }
    
    Ok(())
}

----------------------------------------

TITLE: Creating Basic Disk-based Vector Index
DESCRIPTION: Creates an OpenSearch index configured for disk-based vector search with default settings using the on_disk mode.

LANGUAGE: json
CODE:
PUT my-vector-index
{
  "settings" : {
    "index": {
      "knn": true
    }
  },
  "mappings": {
    "properties": {
      "my_vector_field": {
        "type": "knn_vector",
        "dimension": 8,
        "space_type": "innerproduct",
        "data_type": "float",
        "mode": "on_disk"
      }
    }
  }
}

----------------------------------------

TITLE: Example Performance Analyzer API Request in OpenSearch
DESCRIPTION: Provides an example of a complete Performance Analyzer API request, querying for Latency and CPU_Utilization metrics with average and maximum aggregations, dimensioned by ShardID for all nodes.

LANGUAGE: http
CODE:
GET localhost:9600/_plugins/_performanceanalyzer/metrics?metrics=Latency,CPU_Utilization&agg=avg,max&dim=ShardID&nodes=all

----------------------------------------

TITLE: Sample JSON Log Input for Dissect Processor
DESCRIPTION: Example of a JSON log entry that can be processed by the dissect processor configured in the pipeline.

LANGUAGE: json
CODE:
{"log": "07-25-2023 10:00:00 ERROR: error message"}

----------------------------------------

TITLE: Using Scalar Functions in GROUP BY Clause in OpenSearch SQL
DESCRIPTION: Example of using a scalar function (ABS) in the GROUP BY clause in OpenSearch SQL.

LANGUAGE: sql
CODE:
SELECT ABS(age) AS a
FROM accounts
GROUP BY ABS(age)

----------------------------------------

TITLE: Setting OpenSearch Compatibility Mode
DESCRIPTION: This YAML snippet shows how to set the compatibility mode in opensearch.yml for legacy clients.

LANGUAGE: yaml
CODE:
compatibility.override_main_response_version: true

----------------------------------------

TITLE: Sample Nested JSON Input for Flatten Processor
DESCRIPTION: This JSON snippet represents a sample input event with nested objects that can be processed by the flatten processor.

LANGUAGE: json
CODE:
{
  "key1": "val1",
  "key2": {
    "key3": {
      "key4": "val2"
    }
  },
  "list1": [
    {
      "list2": [
        {
          "name": "name1",
          "value": "value1"
        },
        {
          "name": "name2",
          "value": "value2"
        }
      ]
    }
  ]
}

----------------------------------------

TITLE: Force Merge Single Index
DESCRIPTION: Example request showing how to force merge a specific index.

LANGUAGE: json
CODE:
POST /testindex1/_forcemerge

----------------------------------------

TITLE: Model Input Format JSON Example
DESCRIPTION: Example of the required input format for the SageMaker model, showing an array of strings.

LANGUAGE: json
CODE:
["hello world", "how are you"]

----------------------------------------

TITLE: Configuring Jekyll Front Matter for OpenSearch Search Results Page
DESCRIPTION: Sets up the Jekyll front matter for the OpenSearch documentation search results page. It defines the layout, title, navigation order, and permalink for the page.

LANGUAGE: yaml
CODE:
---
layout: search_layout
title: OpenSearch Documentation Search Results Page
nav_order: 1
has_children: false
nav_exclude: true
permalink: /search.html
---

----------------------------------------

TITLE: Creating a comment on an alert in OpenSearch
DESCRIPTION: Adds a comment to a specific alert, providing additional context or notes.

LANGUAGE: json
CODE:
POST _plugins/_alerting/comments/<alert-id>
{
  "content": "sample comment"
}

----------------------------------------

TITLE: Deleting Indexes by Pattern in OpenSearch
DESCRIPTION: This HTTP DELETE request shows how to delete all indexes that match a specific pattern in OpenSearch.

LANGUAGE: http
CODE:
DELETE my-logs*

----------------------------------------

TITLE: Enabling Multiple Data Sources in YAML Configuration
DESCRIPTION: Set the data_source.enabled flag to true in the opensearch_dashboards.yml configuration file to enable multiple data sources.

LANGUAGE: yaml
CODE:
data_source.enabled: true

----------------------------------------

TITLE: Creating Index with Nested Objects
DESCRIPTION: Creates an OpenSearch index mapping with a nested object structure for user data containing name and age fields.

LANGUAGE: json
CODE:
PUT /my_index
{
  "mappings": {
    "properties": {
      "user": {
        "type": "nested",
        "properties": {
          "name": { "type": "text" },
          "age": { "type": "integer" }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring Distributed Tracing in run.gradle
DESCRIPTION: Add these properties to run.gradle to enable the distributed tracing feature for OpenSearch development.

LANGUAGE: json
CODE:
testClusters {
  runTask {
    testDistribution = 'archive'
 if (numZones > 1) numberOfZones = numZones
    if (numNodes > 1) numberOfNodes = numNodes
    systemProperty 'opensearch.experimental.feature.telemetry.enabled', 'true'
    }
 }

----------------------------------------

TITLE: Testing LDAP Authentication with cURL
DESCRIPTION: Example cURL commands to test LDAP authentication by indexing and searching documents

LANGUAGE: bash
CODE:
curl -XPUT 'https://localhost:9200/new-index/_doc/1' -H 'Content-Type: application/json' -d '{"title": "Spirited Away"}' -u 'psantos:password' -k

LANGUAGE: bash
CODE:
curl -XGET 'https://localhost:9200/new-index/_search?pretty' -u 'jroe:password' -k

----------------------------------------

TITLE: Creating Pipeline with Remove_by_pattern
DESCRIPTION: Example of creating a pipeline named 'remove_fields_by_pattern' that removes fields matching the pattern 'foo*'.

LANGUAGE: json
CODE:
PUT /_ingest/pipeline/remove_fields_by_pattern
{
  "description": "Pipeline that removes the fields by patterns.",
  "processors": [
    {
      "remove_by_pattern": {
        "field_pattern": "foo*"
      }
    }
  ]
}

----------------------------------------

TITLE: Defining URL decode processor syntax in JSON
DESCRIPTION: Demonstrates the basic syntax for the urldecode processor, specifying the field to decode and the target field for the decoded result.

LANGUAGE: json
CODE:
{
  "urldecode": {
    "field": "field_to_decode",
    "target_field": "decoded_field"
  }
}

----------------------------------------

TITLE: Overriding Template Default Values
DESCRIPTION: Example of overriding default template values when creating a workflow

LANGUAGE: json
CODE:
POST /_plugins/_flow_framework/workflow?use_case=semantic_search_with_cohere_embedding
{
    "create_connector.model" : "embed-multilingual-v3.0",
    "text_embedding.field_map.output": "book_embedding",
    "create_index.name": "sparse-book-index"
}

----------------------------------------

TITLE: Index Template Context Response
DESCRIPTION: Sample response showing the template configuration with applied context settings.

LANGUAGE: json
CODE:
{
    "index_templates": [
        {
            "name": "my-logs2",
            "index_template": {
                "index_patterns": [
                    "my-logs1-*"
                ],
                "context": {
                    "name": "logs",
                    "version": "1"
                }
            }
        }
    ]
}

----------------------------------------

TITLE: Creating Pipeline with Dot Expander Processor in OpenSearch
DESCRIPTION: Example of creating an ingest pipeline with two dot_expander processors to expand user.address.city and user.address.state fields into nested objects.

LANGUAGE: json
CODE:
PUT /_ingest/pipeline/dot-expander-pipeline
{
  "description": "Dot expander processor",
  "processors": [
    {
      "dot_expander": {
        "field": "user.address.city"
      }
    },
    {
      "dot_expander":{
       "field": "user.address.state"
      }
    }
  ]
}

----------------------------------------

TITLE: Custom Synonym Mapping Analyzer Configuration in OpenSearch
DESCRIPTION: Creates a custom analyzer that replaces specific characters and patterns before applying synonym filters, using mapping character filters and synonym token filters.

LANGUAGE: json
CODE:
PUT mapping_analyzer_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "synonym_mapping_analyzer": {
          "type": "custom",
          "char_filter": ["underscore_to_space"],
          "tokenizer": "standard",
          "filter": ["lowercase", "stop", "synonym_filter"]
        }
      },
      "char_filter": {
        "underscore_to_space": {
          "type": "mapping",
          "mappings": ["_ => ' '"]
        }
      },
      "filter": {
        "synonym_filter": {
          "type": "synonym",
          "synonyms": [
            "quick, fast, speedy",
            "big, large, huge"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating Disk-based Vector Index with Custom Compression
DESCRIPTION: Creates a vector index with custom compression level of 16x for optimized memory usage.

LANGUAGE: json
CODE:
PUT my-vector-index
{
  "settings" : {
    "index": {
      "knn": true
    }
  },
  "mappings": {
    "properties": {
      "my_vector_field": {
        "type": "knn_vector",
        "dimension": 8,
        "space_type": "innerproduct",
        "data_type": "float",
        "mode": "on_disk",
        "compression_level": "16x"
      }
    }
  }
}

----------------------------------------

TITLE: Querying Recovery API Endpoints in OpenSearch
DESCRIPTION: Basic endpoint definitions for querying recovery information from OpenSearch. Supports both cluster-wide and index-specific recovery information retrieval.

LANGUAGE: json
CODE:
GET /_recovery
GET /<index>/_recovery/

----------------------------------------

TITLE: Creating Ingest Pipeline for Vector Processing
DESCRIPTION: Creates an ingest pipeline that processes incoming documents and generates vector embeddings using the Cohere model.

LANGUAGE: json
CODE:
PUT /_ingest/pipeline/pipeline-cohere
{
  "description": "Cohere embedding ingest pipeline",
  "processors": [
    {
      "text_embedding": {
        "model_id": "your_embedding_model_id_created_in_step1",
        "field_map": {
          "passage_text": "passage_embedding"
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Using GROUP BY with Field Alias in OpenSearch SQL
DESCRIPTION: Example of using the GROUP BY clause with a field alias in OpenSearch SQL.

LANGUAGE: sql
CODE:
SELECT account_number AS num
FROM accounts
GROUP BY num

----------------------------------------

TITLE: Using length() Function with JSON Pointer in OpenSearch Pipelines
DESCRIPTION: This example demonstrates how to use the length() function in OpenSearch Pipelines. It takes a JSON pointer as an argument and returns the length of the value at that pointer. In this case, it returns the length of the 'message' field.

LANGUAGE: json
CODE:
{
  "event": {
    "/message": "1234567890"
  },
  "expression": "length(/message)",
  "expected_output": 10
}

----------------------------------------

TITLE: Configuring Unprotected Metrics Store in INI Format
DESCRIPTION: This snippet demonstrates how to configure an unprotected metrics store in the local network using the INI format. It sets the datastore type to OpenSearch and specifies the host, port, and security settings.

LANGUAGE: ini
CODE:
[results_publishing]
datastore.type = opensearch
datastore.host = 192.168.10.17
datastore.port = 9200
datastore.secure = false
datastore.user =
datastore.password =

----------------------------------------

TITLE: Arithmetic Expression Examples in OpenSearch Data Prepper
DESCRIPTION: Examples of using arithmetic operators for basic mathematical operations and in conditional statements.

LANGUAGE: markdown
CODE:
/value + length(/message)
/bytes / 1024
/value1 - /value2
/TimeInSeconds * 1000

----------------------------------------

TITLE: Installing Bundler for OpenSearch Documentation Dependencies
DESCRIPTION: Command to install Bundler, a package manager for Ruby, which is used to manage dependencies for the OpenSearch documentation project.

LANGUAGE: shell
CODE:
gem install bundler

----------------------------------------

TITLE: Querying Remote Cluster Information in OpenSearch
DESCRIPTION: This GET request retrieves connection information for remote OpenSearch clusters configured for the local cluster. It provides details such as the remote cluster alias, connection mode, seed node IP addresses, and timeout settings.

LANGUAGE: json
CODE:
GET _remote/info

----------------------------------------

TITLE: Creating Embedding Pipeline in OpenSearch
DESCRIPTION: Creates an ingest pipeline for generating embeddings from individual array elements using text_embedding processor.

LANGUAGE: json
CODE:
PUT _ingest/pipeline/bedrock_embedding_pipeline
{
  "processors": [
    {
      "set": {
        "field": "title_tmp",
        "value": "{{_ingest._value.title}}"
      }
    },
    {
      "text_embedding": {
        "model_id": "your_embedding_model_id",
        "field_map": {
          "title_tmp": "_ingest._value.title_embedding"
        }
      }
    },
    {
      "remove": {
        "field": "title_tmp"
      }
    }
  ]
}

----------------------------------------

TITLE: Setting Log Level for OpenSearch Module in JSON
DESCRIPTION: Demonstrates how to change the log level for a specific OpenSearch module (index.reindex) using the cluster settings API.

LANGUAGE: json
CODE:
PUT /_cluster/settings
{
  "persistent" : {
    "logger.org.opensearch.index.reindex" : "DEBUG"
  }
}

----------------------------------------

TITLE: Setting Log Level for OpenSearch Module in JSON
DESCRIPTION: Demonstrates how to change the log level for a specific OpenSearch module (index.reindex) using the cluster settings API.

LANGUAGE: json
CODE:
PUT /_cluster/settings
{
  "persistent" : {
    "logger.org.opensearch.index.reindex" : "DEBUG"
  }
}

----------------------------------------

TITLE: Listing All Notification Channels in OpenSearch
DESCRIPTION: Retrieves a list of all configured notification channels using a GET request to the channels endpoint.

LANGUAGE: json
CODE:
GET /_plugins/_notifications/channels

----------------------------------------

TITLE: API Endpoints for Reloading Secure Settings
DESCRIPTION: The available POST endpoints for reloading secure settings on nodes, allowing both cluster-wide and node-specific operations.

LANGUAGE: json
CODE:
POST _nodes/reload_secure_settings
POST _nodes/<nodeId>/reload_secure_settings

----------------------------------------

TITLE: Starting or Stopping an Index Rollup Job in OpenSearch
DESCRIPTION: This snippet shows how to start or stop an index rollup job using POST requests with the rollup_id and the appropriate action (_start or _stop).

LANGUAGE: json
CODE:
POST _plugins/_rollup/jobs/<rollup_id>/_start
POST _plugins/_rollup/jobs/<rollup_id>/_stop

----------------------------------------

TITLE: Custom Highlighting Tags Query
DESCRIPTION: Search query showing how to customize the HTML tags used for highlighting matches

LANGUAGE: json
CODE:
{
  "query": {
    "match": {
      "play_name": "Henry IV"
    }
  },
  "size": 3,
  "highlight": {
    "pre_tags": [
      "<strong>"
    ],
    "post_tags": [
      "</strong>"
    ],
    "fields": {
      "play_name": {}
    }
  }
}

----------------------------------------

TITLE: Creating Pipeline with IP2Geo Processor in OpenSearch
DESCRIPTION: This snippet demonstrates how to create an ingest pipeline that includes the IP2Geo processor for converting IP addresses to geographical information.

LANGUAGE: json
CODE:
PUT /_ingest/pipeline/my-pipeline
{
   "description":"convert ip to geo",
   "processors":[
    {
        "ip2geo":{
            "field":"ip",
            "datasource":"my-datasource"
        }
    }
   ] 
}

----------------------------------------

TITLE: Handling SQL Query Errors in OpenSearch
DESCRIPTION: Shows how OpenSearch handles errors in SQL queries, returning an error message with details about the cause of the error.

LANGUAGE: json
CODE:
POST /_plugins/_sql
{
  "query" : "SELECT unknown FROM accounts"
}

LANGUAGE: json
CODE:
{
  "error": {
    "reason": "Invalid SQL query",
    "details": "Field [unknown] cannot be found or used here.",
    "type": "SemanticAnalysisException"
  },
  "status": 400
}

----------------------------------------

TITLE: Term Query Response Example in OpenSearch
DESCRIPTION: Example of a response from a term query showing matched documents with their details.

LANGUAGE: json
CODE:
"hits": {
  "total": {
    "value": 1582,
    "relation": "eq"
  },
  "max_score": 2,
  "hits": [
    {
      "_index": "shakespeare",
      "_id": "32700",
      "_score": 2,
      "_source": {
        "type": "line",
        "line_id": 32701,
        "play_name": "Hamlet",
        "speech_number": 9,
        "line_number": "1.2.66",
        "speaker": "HAMLET",
        "text_entry": "[Aside]  A little more than kin, and less than kind."
      }
    }
  ]
}

----------------------------------------

TITLE: Create Mappings API Request/Response
DESCRIPTION: API endpoint to create new field mappings. Supports partial mapping updates and alias mapping definitions.

LANGUAGE: json
CODE:
POST /_plugins/_security_analytics/mappings

{
   "index_name": "windows",
   "rule_topic": "windows",
   "partial": true,
   "alias_mappings": {
        "properties": {
            "event_uid": {
            "type": "alias",
            "path": "EventID"
          }
       }
   }
}

LANGUAGE: json
CODE:
{
    "acknowledged": true
}

----------------------------------------

TITLE: Ingesting Document with Sort Pipeline in OpenSearch
DESCRIPTION: This snippet demonstrates how to ingest a document into an index named 'testindex1' using the 'sort-pipeline'. The pipeline will sort the 'my_array_field' in descending order.

LANGUAGE: json
CODE:
POST testindex1/_doc?pipeline=sort-pipeline
{
  "my_array_field": [3, 1, 4, 1, 5, 9, 2, 6, 5]
}

----------------------------------------

TITLE: Ingesting Document with Split Pipeline
DESCRIPTION: Example of ingesting a document using the split pipeline to process the log_message field.

LANGUAGE: json
CODE:
PUT testindex1/_doc/1?pipeline=split_pipeline
{
  "log_message": "error,warning,info"
}

----------------------------------------

TITLE: Extracting Key-Value Pairs from Query Strings in YAML
DESCRIPTION: This example combines the split_string and key_value processors to extract query parameters from an Apache log line, demonstrating how to parse complex string data.

LANGUAGE: yaml
CODE:
pipeline:
 ...
  processor:
    - grok:
        match:
          message: [ "%{COMMONAPACHELOG_DATATYPED}" ]
    - split_string:
        entries:
          - source: request
            delimiter: "?"
    - key_value:
        source: "/request/1"
        field_split_characters: "&"
        value_split_characters: "="
        destination: query_params

----------------------------------------

TITLE: Creating Notification Settings in OpenSearch
DESCRIPTION: API request to configure notifications for a reindex task failure. Demonstrates setting up notifications for a specific task ID with multiple notification channels.

LANGUAGE: json
CODE:
POST /_plugins/_im/lron
{
  "lron_config": {
      "task_id":"dQlcQ0hQS2mwF-AQ7icCMw:12354",
      "action_name":"indices:data/write/reindex",
      "lron_condition": {
        "success": false,
        "failure": true
      },
      "channels":[
          {"id":"channel1"},
          {"id":"channel2"}
      ]
  }
}

----------------------------------------

TITLE: Creating an Ingest Pipeline with Ignore Failure in OpenSearch
DESCRIPTION: This snippet demonstrates how to create an ingest pipeline that renames a field and ignores failures. The 'ignore_failure' parameter is set to true, allowing the pipeline to continue even if the rename processor fails.

LANGUAGE: json
CODE:
PUT _ingest/pipeline/my-pipeline/
{
  "description": "Rename 'provider' field to 'cloud.provider'",
  "processors": [
    {
      "rename": {
        "field": "provider",
        "target_field": "cloud.provider",
        "ignore_failure": true
      }
    }
  ]
}

----------------------------------------

TITLE: Creating OpenSearch Node in C#
DESCRIPTION: Demonstrates how to create a new OpenSearch node by passing a URI object to the Node constructor. The node is created as master eligible with HoldsData set to true by default.

LANGUAGE: csharp
CODE:
var uri = new Uri("http://example.org/opensearch");
var node = new Node(uri);

----------------------------------------

TITLE: Filtered Response Request in OpenSearch
DESCRIPTION: Demonstrates how to filter response fields using the filter_path parameter.

LANGUAGE: json
CODE:
GET _search?filter_path=<field_name>.*,-<field_name>

----------------------------------------

TITLE: Creating a Search Pipeline with ML OpenSearch Rerank Processor
DESCRIPTION: This snippet demonstrates how to create a search pipeline with a rerank response processor using the ml_opensearch rerank type. It specifies a model ID and document fields for context.

LANGUAGE: json
CODE:
PUT /_search/pipeline/rerank_pipeline
{
  "response_processors": [
    {
      "rerank": {
        "ml_opensearch": {
          "model_id": "gnDIbI0BfUsSoeNT_jAw"
        },
        "context": {
          "document_fields": [ "title", "text_representation"]
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Specifying Fields to Retrieve
DESCRIPTION: Demonstrates how to use the fields parameter to retrieve specific fields including wildcard patterns.

LANGUAGE: json
CODE:
{
    "_source": false,
    "fields": ["age", "nam*"],
    "query": {
        "match_all": {}
  }
}

----------------------------------------

TITLE: Verifying OpenSearch Installation
DESCRIPTION: Curl command to verify OpenSearch is running by querying the local endpoint.

LANGUAGE: bash
CODE:
curl -X GET https://localhost:9200 -u 'admin:<custom-admin-password>' --insecure

----------------------------------------

TITLE: Update Query Group Response Example
DESCRIPTION: Example response when successfully updating an existing query group, showing the modified configuration.

LANGUAGE: json
CODE:
{
  "_id":"preXpc67RbKKeCyka72_Gw",
  "name":"analytics",
  "resiliency_mode":"monitor",
  "resource_limits":{
    "cpu":0.41,
    "memory":0.21
  },
  "updated_at":1726270333804
}

----------------------------------------

TITLE: Render Template Request Using Source Parameter
DESCRIPTION: Example request demonstrating inline template rendering with default values and Mustache variables.

LANGUAGE: json
CODE:
{
  "source": {
     "from": "{{from}}{{^from}}0{{/from}}",
     "size": "{{size}}{{^size}}10{{/size}}",
    "query": {
      "match": {
        "play_name": "{{play_name}}"
      }
    }
  },
  "params": {
    "play_name": "Henry IV"
  }
}

----------------------------------------

TITLE: Deploying Cross-Encoder Model on SageMaker
DESCRIPTION: Python code to deploy the Hugging Face ms-marco-MiniLM-L-6-v2 model on Amazon SageMaker for reranking purposes.

LANGUAGE: python
CODE:
import sagemaker
import boto3
from sagemaker.huggingface import HuggingFaceModel
sess = sagemaker.Session()
role = sagemaker.get_execution_role()

hub = {
    'HF_MODEL_ID':'cross-encoder/ms-marco-MiniLM-L-6-v2',
    'HF_TASK':'text-classification'
}
huggingface_model = HuggingFaceModel(
    transformers_version='4.37.0',
    pytorch_version='2.1.0',
    py_version='py310',
    env=hub,
    role=role, 
)
predictor = huggingface_model.deploy(
    initial_instance_count=1,
    instance_type='ml.m5.xlarge'
)

----------------------------------------

TITLE: Removing Fields with Logstash Mutate Filter
DESCRIPTION: Shows how to use the mutate filter to remove specific fields from the event data.

LANGUAGE: yaml
CODE:
input {
  http {
    host => "127.0.0.1"
    port => 8080
  }
}

filter {
  mutate {
    remove_field => {"host"}
  }
}

output {
  file {
    path => "output.txt"
  }
}

----------------------------------------

TITLE: Field Boosting Query
DESCRIPTION: Query demonstrating field boosting where matches in first_name field are given higher relevance.

LANGUAGE: json
CODE:
GET /customers/_search
{
  "query": {
    "simple_query_string" : {
      "query": "Amber",
      "fields": [ "first_name^2", "last_name" ] 
    }
  }
}

----------------------------------------

TITLE: Wildcard Index Stats Query
DESCRIPTION: Retrieves stats for indexes matching a wildcard pattern

LANGUAGE: json
CODE:
GET /testindex*/_stats

----------------------------------------

TITLE: Sample Search Request for Transformed Flight Data
DESCRIPTION: Demonstrates how to search for specific airport destinations (SFO) in transformed flight data using a match query.

LANGUAGE: json
CODE:
GET finished_flight_job/_search
{
  "query": {
    "match": {
      "DestAirportID_terms" : "SFO"
    }
  }
}

----------------------------------------

TITLE: Neural Search with K-Value Filter in OpenSearch
DESCRIPTION: Example of a neural search query with a k value of 100 and combined range and term filters

LANGUAGE: json
CODE:
GET /my-nlp-index/_search
{
  "query": {
    "neural": {
      "passage_embedding": {
        "query_text": "Hi world",
        "query_image": "iVBORw0KGgoAAAAN...",
        "k": 100,
        "filter": {
          "bool": {
            "must": [
              {
                "range": {
                  "rating": {
                    "gte": 8,
                    "lte": 10
                  }
                }
              },
              {
                "term": {
                  "parking": "true"
                }
              }
            ]
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Sample Search Response from Transformed Index
DESCRIPTION: Shows the response structure from a transformed index search, including metadata and matched documents with their transformed fields.

LANGUAGE: json
CODE:
{
  "took" : 3,
  "timed_out" : false,
  "_shards" : {
    "total" : 5,
    "successful" : 5,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : {
      "value" : 4,
      "relation" : "eq"
    },
    "max_score" : 3.845883,
    "hits" : [
      {
        "_index" : "finished_flight_job",
        "_id" : "dSNKGb8U3OJOmC4RqVCi1Q",
        "_score" : 3.845883,
        "_source" : {
          "transform._id" : "sample_flight_job",
          "transform._doc_count" : 14,
          "Carrier_terms" : "Dashboards Airlines",
          "DestAirportID_terms" : "SFO"
        }
      },
      {
        "_index" : "finished_flight_job",
        "_id" : "_D7oqOy7drx9E-MG96U5RA",
        "_score" : 3.845883,
        "_source" : {
          "transform._id" : "sample_flight_job",
          "transform._doc_count" : 14,
          "Carrier_terms" : "Logstash Airways",
          "DestAirportID_terms" : "SFO"
        }
      },
      {
        "_index" : "finished_flight_job",
        "_id" : "YuZ8tOt1OsBA54e84WuAEw",
        "_score" : 3.6988301,
        "_source" : {
          "transform._id" : "sample_flight_job",
          "transform._doc_count" : 11,
          "Carrier_terms" : "ES-Air",
          "DestAirportID_terms" : "SFO"
        }
      },
      {
        "_index" : "finished_flight_job",
        "_id" : "W_-e7bVmH6eu8veJeK8ZxQ",
        "_score" : 3.6988301,
        "_source" : {
          "transform._id" : "sample_flight_job",
          "transform._doc_count" : 10,
          "Carrier_terms" : "JetBeats",
          "DestAirportID_terms" : "SFO"
        }
      }
    ]
  }
}

----------------------------------------

TITLE: Basic OpenSearch Output Plugin Configuration
DESCRIPTION: Basic configuration for the OpenSearch output plugin in Logstash pipeline configuration. Defines host connection and authentication details.

LANGUAGE: yaml
CODE:
output {
  opensearch {
    hosts       => "https://localhost:9200"
    user        => "admin"
    password    => "admin"
    index       => "logstash-logs-%{+YYYY.MM.dd}"
    ssl_certificate_verification => false
  }
}

----------------------------------------

TITLE: Creating a Text Chunking Ingest Pipeline in OpenSearch
DESCRIPTION: Example of creating an ingest pipeline with a text chunking processor using the fixed_token_length algorithm.

LANGUAGE: json
CODE:
PUT _ingest/pipeline/text-chunking-ingest-pipeline
{
  "description": "A text chunking ingest pipeline",
  "processors": [
    {
      "text_chunking": {
        "algorithm": {
          "fixed_token_length": {
            "token_limit": 10,
            "overlap_rate": 0.2,
            "tokenizer": "standard"
          }
        },
        "field_map": {
          "passage_text": "passage_chunk"
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Creating Uppercase Pipeline in OpenSearch
DESCRIPTION: Shows how to create an ingest pipeline that uses the uppercase processor to convert the 'name' field to uppercase.

LANGUAGE: json
CODE:
{
  "processors": [
    {
      "uppercase": {
        "field": "name"
      }
    }
  ]
}

----------------------------------------

TITLE: Analyzing Text with CJK Analyzer
DESCRIPTION: Shows how to analyze CJK text and view the generated tokens.

LANGUAGE: json
CODE:
{
  "field": "content",
  "text": "123456"
}

LANGUAGE: json
CODE:
{
  "tokens": [
    {"token": "","start_offset": 0,"end_offset": 2,"type": "<DOUBLE>","position": 0},
    {"token": "","start_offset": 1,"end_offset": 3,"type": "<DOUBLE>","position": 1},
    {"token": "","start_offset": 2,"end_offset": 4,"type": "<DOUBLE>","position": 2},
    {"token": "","start_offset": 3,"end_offset": 5,"type": "<DOUBLE>","position": 3},
    {"token": "","start_offset": 4,"end_offset": 6,"type": "<DOUBLE>","position": 4},
    {"token": "","start_offset": 7,"end_offset": 9,"type": "<DOUBLE>","position": 5},
    {"token": "","start_offset": 8,"end_offset": 10,"type": "<DOUBLE>","position": 6},
    {"token": "","start_offset": 9,"end_offset": 11,"type": "<DOUBLE>","position": 7},
    {"token": "","start_offset": 10,"end_offset": 12,"type": "<DOUBLE>","position": 8},
    {"token": "","start_offset": 11,"end_offset": 13,"type": "<DOUBLE>","position": 9},
    {"token": "","start_offset": 12,"end_offset": 14,"type": "<DOUBLE>","position": 10},
    {"token": "","start_offset": 13,"end_offset": 15,"type": "<DOUBLE>","position": 11},
    {"token": "","start_offset": 14,"end_offset": 16,"type": "<DOUBLE>","position": 12},
    {"token": "","start_offset": 15,"end_offset": 17,"type": "<DOUBLE>","position": 13},
    {"token": "123456","start_offset": 18,"end_offset": 24,"type": "<NUM>","position": 14}
  ]
}

----------------------------------------

TITLE: Remote Cluster Reindex Operation
DESCRIPTION: Reindexes documents from a remote cluster by specifying host and authentication details.

LANGUAGE: json
CODE:
POST _reindex
{
   "source":{
      "remote":{
         "host":"https://<REST_endpoint_of_remote_cluster>:9200",
         "username":"YOUR_USERNAME",
         "password":"YOUR_PASSWORD"
      },
      "index": "source"
   },
   "dest":{
      "index":"destination"
   }
}

----------------------------------------

TITLE: Input JSON Event Example
DESCRIPTION: Sample JSON input event before type conversion showing response_status as a string.

LANGUAGE: json
CODE:
{"message": "value", "response_status":"200"}

----------------------------------------

TITLE: Adding a Query to workload.json
DESCRIPTION: Example of adding a match_all query to the workload.json file for custom workloads.

LANGUAGE: json
CODE:
{
      "operation": {
        "name": "query-match-all",
        "operation-type": "search",
        "body": {
          "query": {
            "match_all": {}
          }
        }
      },
      "clients": 8,
      "warmup-iterations": 1000,
      "iterations": 1000,
      "target-throughput": 100
    }

----------------------------------------

TITLE: Listing All Points in Time (PITs) in OpenSearch
DESCRIPTION: Retrieves a list of all PITs in the OpenSearch cluster using a GET request.

LANGUAGE: json
CODE:
GET /_search/point_in_time/_all

----------------------------------------

TITLE: HTTP Response Type Analysis using Scripted Metric Aggregation
DESCRIPTION: Example of using scripted_metric aggregation to count different types of HTTP responses (error, success, other) in web log data. The script uses four stages: init_script to initialize counters, map_script to categorize responses, combine_script to aggregate shard results, and reduce_script to combine all results.

LANGUAGE: json
CODE:
{
  "size": 0,
  "aggregations": {
    "responses.counts": {
      "scripted_metric": {
        "init_script": "state.responses = ['error':0L,'success':0L,'other':0L]",
        "map_script": """
              def code = doc['response.keyword'].value;
                 if (code.startsWith('5') || code.startsWith('4')) {
                  state.responses.error += 1 ;
                  } else if(code.startsWith('2')) {
                   state.responses.success += 1;
                  } else {
                  state.responses.other += 1;
                }
             """,
        "combine_script": "state.responses",
        "reduce_script": """
            def counts = ['error': 0L, 'success': 0L, 'other': 0L];
                for (responses in states) {
                 counts.error += responses['error'];
                  counts.success += responses['success'];
                counts.other += responses['other'];
        }
        return counts;
        """
      }
    }
  }
}

LANGUAGE: json
CODE:
{
  "aggregations": {
    "responses.counts": {
      "value": {
        "other": 0,
        "success": 12832,
        "error": 1242
      }
    }
  }
}

----------------------------------------

TITLE: Creating Root Agent for Data Summary
DESCRIPTION: JSON request to create a root agent for the data summary feature using the previously created agent ID.

LANGUAGE: json
CODE:
POST /.plugins-ml-config/_doc/os_data2summary
{
  "type": "os_root_agent",
  "configuration": {
    "agent_id": "<DATA_SUMMARY_AGENT_ID>"
  }
}

----------------------------------------

TITLE: Running OpenSearch Benchmark with Docker Volume Persistence
DESCRIPTION: Executes a test benchmark using the geonames workload with volume persistence for data and logs.

LANGUAGE: bash
CODE:
docker run -v $HOME/benchmarks:/opensearch-benchmark/.benchmark opensearchproject/opensearch-benchmark execute-test --target-hosts https://198.51.100.25:9200 --pipeline benchmark-only --workload geonames --client-options basic_auth_user:admin,basic_auth_password:admin,verify_certs:false --test-mode

----------------------------------------

TITLE: Updating ML cluster settings
DESCRIPTION: Updates cluster settings to enable running ML models without dedicated ML nodes.

LANGUAGE: json
CODE:
PUT _cluster/settings
{
  "persistent": {
    "plugins.ml_commons.only_run_on_ml_node": "false",
    "plugins.ml_commons.model_access_control_enabled": "true",
    "plugins.ml_commons.native_memory_threshold": "99"
  }
}

----------------------------------------

TITLE: Executing SQL Query in OpenSearch Notebooks
DESCRIPTION: Sample SQL query to fetch flight data from the OpenSearch Dashboards sample dataset with a limit of 20 records.

LANGUAGE: sql
CODE:
%sql
Select * from opensearch_dashboards_sample_data_flights limit 20;

----------------------------------------

TITLE: Decay Functions Example - OpenSearch JSON
DESCRIPTION: Demonstrates using decay functions with different field types (numeric, geo, date) for proximity-based scoring.

LANGUAGE: json
CODE:
GET articles/_search
{
  "query": {
    "script_score": {
      "query": {
        "match": {
          "article_name": "neural search"
        }
      },
      "script": {
        "source": "decayNumericExp(params.origin, params.scale, params.offset, params.decay, doc['article_rank'].value)",
        "params": {
          "origin": 50,
          "scale": 20,
          "offset": 30,
          "decay": 0.5
        }
      }
    }
  }
}

----------------------------------------

TITLE: Requesting Index Information for a Specific Index in OpenSearch
DESCRIPTION: This example shows how to request information for a specific index named 'sample-index' using the GET method. It demonstrates the basic usage of the Get Index API.

LANGUAGE: json
CODE:
GET /sample-index

----------------------------------------

TITLE: Creating a pipeline with character limit in OpenSearch
DESCRIPTION: JSON command to create an attachment pipeline with a character limit for content extraction, including a field to override the limit per document.

LANGUAGE: json
CODE:
PUT _ingest/pipeline/attachment
{
  "description" : "Extract attachment information",
  "processors" : [
    {
      "attachment" : {
        "field" : "data",
        "indexed_chars" : 10,
        "indexed_chars_field" : "max_chars",
      }
    }
  ]
}

----------------------------------------

TITLE: Creating test index and documents
DESCRIPTION: Creates a test index with a custom mapping and inserts sample documents for testing query_string queries.

LANGUAGE: json
CODE:
PUT /testindex
{
  "mappings": {
    "properties": {
      "title": { 
        "type": "text",
        "fields": {
          "english": { 
            "type": "text",
            "analyzer": "english"
          }
        }
      }
    }
  }
}

LANGUAGE: json
CODE:
PUT /testindex/_doc/1
{
  "title": "The wind rises"
}

LANGUAGE: json
CODE:
PUT /testindex/_doc/2
{
  "title": "Gone with the wind",
  "description": "A 1939 American epic historical film"
}

LANGUAGE: json
CODE:
PUT /testindex/_doc/3
{
  "title": "Windy city"
}

LANGUAGE: json
CODE:
PUT /testindex/_doc/4
{
  "article title": "Wind turbines"
}

----------------------------------------

TITLE: Testing Pipeline with Simulate API
DESCRIPTION: Demonstrates how to test the pipeline using the simulate API before actual document ingestion.

LANGUAGE: json
CODE:
{
  "docs": [
    {
      "_source": {
        "protocol": "https",
        "name":"test"
      }
    }
  ]
}

----------------------------------------

TITLE: Query-Based Reindex Operation
DESCRIPTION: Reindexes a subset of documents that match a specific query condition.

LANGUAGE: json
CODE:
POST _reindex
{
   "source":{
      "index":"source",
      "query": {
        "match": {
           "field_name": "text"
         }
      }
   },
   "dest":{
      "index":"destination"
   }
}

----------------------------------------

TITLE: Configuring XSRF Allowlist for SAML in OpenSearch Dashboards YAML
DESCRIPTION: This configuration adds the SAML assertion consumer service endpoint to the XSRF allowlist in OpenSearch Dashboards. This is necessary for the SAML authentication to function properly.

LANGUAGE: yaml
CODE:
server.xsrf.allowlist: [/_opendistro/_security/saml/acs]

----------------------------------------

TITLE: Starting OpenSearch Dashboards with Docker Compose
DESCRIPTION: Command to start OpenSearch Dashboards using Docker Compose. This assumes a docker-compose.yml file has been created with the necessary configuration.

LANGUAGE: bash
CODE:
docker compose up

----------------------------------------

TITLE: Modifying Java Memory Heap Size in Ansible Variables
DESCRIPTION: Example of modifying the Java memory heap size in the inventories/opensearch/group_vars/all/all.yml file.

LANGUAGE: bash
CODE:
xms_value: 8
xmx_value: 8

----------------------------------------

TITLE: Basic DQL Search Syntax
DESCRIPTION: Examples of basic search terms and phrase searching in DQL.

LANGUAGE: python
CODE:
rises wind

LANGUAGE: python
CODE:
"wind rises"

----------------------------------------

TITLE: Installing OpenSearch Plugin from ZIP File
DESCRIPTION: Command syntax for installing an OpenSearch plugin from a local or remote ZIP file.

LANGUAGE: bash
CODE:
bin/opensearch-plugin install <zip-file>

----------------------------------------

TITLE: Starting OpenSearch Cluster
DESCRIPTION: Commands to start the OpenSearch cluster and verify its status using Docker Compose.

LANGUAGE: bash
CODE:
docker compose up -d

LANGUAGE: bash
CODE:
curl https://localhost:9200 -ku admin:<custom-admin-password>

----------------------------------------

TITLE: Enabling Experimental Features for OpenSearch Assistant in YAML Configuration
DESCRIPTION: Configure the opensearch_dashboards.yml file to enable experimental features like text to visualization for OpenSearch Assistant.

LANGUAGE: yaml
CODE:
assistant.next.enabled: true

----------------------------------------

TITLE: AWS IAM Authentication Configuration
DESCRIPTION: Configuration for AWS IAM authentication with the OpenSearch output plugin, including required AWS credentials and region settings.

LANGUAGE: yaml
CODE:
output {
   opensearch {
          hosts => ["https://hostname:port"]
          auth_type => {
              type => 'aws_iam'
              aws_access_key_id => 'ACCESS_KEY'
              aws_secret_access_key => 'SECRET_KEY'
              region => 'us-west-2'
              service_name => 'es'
          }
          index  => "logstash-logs-%{+YYYY.MM.dd}"
   }
}

----------------------------------------

TITLE: Basic LTR Search Query Using SLTR
DESCRIPTION: Example of using the sltr query to execute a trained model for ranking search results. The query applies the 'my_model' model with 'rambo' as the keyword parameter.

LANGUAGE: json
CODE:
    POST tmdb/_search
    {
        "query": {
            "sltr": {
                    "params": {
                        "keywords": "rambo"
                    },
                    "model": "my_model"
                }
        }
    }

----------------------------------------

TITLE: Example Response for Deleting a Connector in OpenSearch
DESCRIPTION: This is an example response after successfully deleting a connector. It includes details such as the index, ID, version, and shard information.

LANGUAGE: json
CODE:
{
  "_index" : ".plugins-ml-connector",
  "_id" : "KsAo1YsB0jLkkocY6j4U",
  "_version" : 1,
  "result" : "deleted",
  "_shards" : {
    "total" : 2,
    "successful" : 2,
    "failed" : 0
  },
  "_seq_no" : 27,
  "_primary_term" : 18
}

----------------------------------------

TITLE: Registering a tokenizer for doc-only mode
DESCRIPTION: Registers the amazon/neural-sparse/opensearch-neural-sparse-tokenizer-v1 tokenizer for use in doc-only mode neural sparse search.

LANGUAGE: json
CODE:
POST /_plugins/_ml/models/_register?deploy=true
{
  "name": "amazon/neural-sparse/opensearch-neural-sparse-tokenizer-v1",
  "version": "1.0.1",
  "model_format": "TORCH_SCRIPT"
}

----------------------------------------

TITLE: Connecting to Amazon OpenSearch Service
DESCRIPTION: Establishes connection to Amazon OpenSearch Service using SigV4 authentication

LANGUAGE: php
CODE:
$client = (new \OpenSearch\ClientBuilder())
    ->setSigV4Region('us-east-2')
    ->setSigV4Service('es')
    ->setSigV4CredentialProvider(true)
    ->setSigV4CredentialProvider([
      'key' => 'awskeyid',
      'secret' => 'awssecretkey',
    ])
    ->build();

----------------------------------------

TITLE: Creating Vector Index with Pipeline
DESCRIPTION: Creates a vector index configured with the text embedding ingest pipeline as the default pipeline

LANGUAGE: json
CODE:
PUT /my-nlp-index
{
  "settings": {
    "index.knn": true,
    "default_pipeline": "nlp-ingest-pipeline"
  },
  "mappings": {
    "properties": {
      "id": {
        "type": "text"
      },
      "passage_embedding": {
        "type": "knn_vector",
        "dimension": 768,
        "method": {
          "engine": "lucene",
          "space_type": "l2",
          "name": "hnsw",
          "parameters": {}
        }
      },
      "passage_text": {
        "type": "text"
      }
    }
  }
}

----------------------------------------

TITLE: Deleting Threat Intelligence Source
DESCRIPTION: Deletes a specific threat intelligence source by ID.

LANGUAGE: json
CODE:
DELETE /_plugins/_security_analytics/threat_intel/sources/2c0u7JAB9IJUg27gcjUp

----------------------------------------

TITLE: Executing Template k-NN Query with ML Inference in OpenSearch
DESCRIPTION: This snippet demonstrates a template k-NN query with a placeholder for vector embeddings. The placeholder will be replaced with embeddings generated by the ml_inference search request processor from the text input field.

LANGUAGE: json
CODE:
GET /template-knn-index/_search?search_pipeline=my_knn_pipeline
{
  "query": {
    "template": {
      "knn": {
        "text_embedding": {
          "vector": "${text_embedding}",
          "k": 2
        }
      }
    }
  },
  "ext": {
    "ml_inference": {
      "text": "sneakers"
    }
  }
}

----------------------------------------

TITLE: Querying All Index Templates - JSON
DESCRIPTION: Example request showing how to retrieve information about all index templates in the system.

LANGUAGE: json
CODE:
GET /_index_template

----------------------------------------

TITLE: Reopening an Index in OpenSearch
DESCRIPTION: This snippet shows how to reopen a previously closed index named 'testindex' using a POST request.

LANGUAGE: json
CODE:
POST /testindex/_open

----------------------------------------

TITLE: Function Score Query with Subset Matching
DESCRIPTION: Applies the scoring function to a subset of documents by providing a query within the function score.

LANGUAGE: json
CODE:
GET shakespeare/_search
{
  "query": {
    "function_score": {
      "query": { 
        "match": {
          "play_name": "Hamlet"
        } 
      },
      "weight": "2"
    }
  }
}

----------------------------------------

TITLE: Assigning Security Analytics Full Access Role in OpenSearch
DESCRIPTION: This JSON snippet shows how to assign the 'security_analytics_full_access' role to users 'alice' and 'bob' using the OpenSearch Security API. This grants full access to Security Analytics features.

LANGUAGE: json
CODE:
PUT /_plugins/_security/api/rolesmapping/security_analytics_full_access
{
  "backend_roles": [],
  "hosts": [],
  "users": [
    "alice",
    "bob"
  ]
}

----------------------------------------

TITLE: Configuring Remote Cluster State in OpenSearch YAML
DESCRIPTION: Basic configuration settings to enable remote cluster state and specify repository settings for S3 storage. Includes mandatory static settings for cluster and repository configuration.

LANGUAGE: yaml
CODE:
# Enable Remote cluster state cluster setting
cluster.remote_store.state.enabled: true

# Remote cluster state repository settings
node.attr.remote_store.state.repository: my-remote-state-repo
node.attr.remote_store.repository.my-remote-state-repo.type: s3
node.attr.remote_store.repository.my-remote-state-repo.settings.bucket: <Bucket Name 3>
node.attr.remote_store.repository.my-remote-state-repo.settings.base_path: <Bucket Base Path 3>
node.attr.remote_store.repository.my-remote-state-repo.settings.region: <Bucket region>

----------------------------------------

TITLE: Disabling Security Plugin in OpenSearch Configuration
DESCRIPTION: This YAML configuration snippet disables the Security plugin in OpenSearch by adding a line to the opensearch.yml file.

LANGUAGE: yaml
CODE:
plugins.security.disabled: true

----------------------------------------

TITLE: Updating Anomaly Detection Plugin
DESCRIPTION: This set of commands demonstrates how to update the Anomaly Detection plugin by removing the old version, deleting the optimized bundle, and reinstalling the new version.

LANGUAGE: bash
CODE:
sudo bin/opensearch-dashboards-plugin remove anomalyDetectionDashboards
sudo rm /usr/share/opensearch-dashboards/optimize/bundles/opensearch-anomaly-detection-opensearch-dashboards.*
sudo bin/opensearch-dashboards-plugin install <AD OpenSearch Dashboards plugin artifact URL>

----------------------------------------

TITLE: Using GROUP BY Clause in OpenSearch SQL
DESCRIPTION: Example of using the GROUP BY clause to group documents with the same 'age' value into buckets in OpenSearch SQL.

LANGUAGE: sql
CODE:
SELECT age
FROM accounts
GROUP BY age

----------------------------------------

TITLE: Querying Index with Size Field in OpenSearch
DESCRIPTION: cURL command to search the index and retrieve documents with their size information.

LANGUAGE: sh
CODE:
curl -XGET example-index/_search -H "Content-Type: application/json" -d '{
  "query": {
    "match_all": {}
  },
  "stored_fields": ["_size", "_source"]
}'

----------------------------------------

TITLE: Jekyll Front Matter Configuration for OpenSearch Homepage
DESCRIPTION: YAML front matter configuration for the OpenSearch documentation homepage. Defines layout settings, navigation properties, and URL permalink.

LANGUAGE: yaml
CODE:
---
layout: home
title: Home
nav_order: 1
has_children: false
nav_exclude: true
permalink: /
---

----------------------------------------

TITLE: Example S3 Object Key in Data Prepper
DESCRIPTION: Shows an example of how a batched object would be formatted when written to S3, including the path prefix and various time-based components.

LANGUAGE: plaintext
CODE:
my-logs/2023/06/09/06/events-2023-06-09T06-00-01-1686290401871214927-ae15b8fa-512a-59c2-b917-295a0eff97c8.json

----------------------------------------

TITLE: Creating Feature Set for Movie Search
DESCRIPTION: Defines a feature set with body and title query features for movie search functionality using the hello-ltr demo schema.

LANGUAGE: json
CODE:
PUT _ltr/_featureset/more_movie_features
{
    "name": "more_movie_features",
    "features": [
        {
            "name": "body_query",
            "params": [
                "keywords"
                ],
            "template": {
                "match": {
                    "overview": "{% raw %}{{keywords}}{% endraw %}"
                }
            }
        },
        {
            "name": "title_query",
            "params": [
                "keywords"
            ],
            "template": {
                "match": {
                    "title": "{% raw %}{{keywords}}{% endraw %}"
                }
            }
        }
    ]
}

----------------------------------------

TITLE: Connecting to Amazon OpenSearch Service with HTTP Authentication
DESCRIPTION: Create an OpenSearch client to connect to Amazon OpenSearch Service using HTTP authentication with a username and password. This method is suitable for testing purposes.

LANGUAGE: python
CODE:
from opensearchpy import OpenSearch

auth = ('admin', 'admin') # For testing only. Don't store credentials in code.

client = OpenSearch(
    hosts=[{"host": host, "port": 443}],
    http_auth=auth,
    http_compress=True,  # enables gzip compression for request bodies
    use_ssl=True,
    verify_certs=True,
    ssl_assert_hostname=False,
    ssl_show_warn=False,
)

----------------------------------------

TITLE: Configuring Bengali Analyzer with Stem Exclusion in OpenSearch
DESCRIPTION: This snippet shows how to create a Bengali analyzer with stem exclusion for specific words in OpenSearch index settings.

LANGUAGE: json
CODE:
PUT index_with_stem_exclusion_bengali_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "stem_exclusion_bengali_analyzer": {
          "type": "bengali",
          "stem_exclusion": ["", ""]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Local Assets Configuration Example
DESCRIPTION: Configuration example for using locally stored images as branding elements in OpenSearch Dashboards.

LANGUAGE: yaml
CODE:
logo:
  defaultUrl: "https://localhost:5601/ui/assets/my-own-image.svg"
  darkModeUrl: "https://localhost:5601/ui/assets/dark-mode-my-own-image.svg"
mark:
  defaultUrl: "https://localhost:5601/ui/assets/my-own-image2.svg"
  darkModeUrl: "https://localhost:5601/ui/assets/dark-mode-my-own-image2.svg"
# loadingLogo:
#   defaultUrl: ""
#   darkModeUrl: ""
# faviconUrl: ""
applicationTitle: "My custom application"

----------------------------------------

TITLE: Disabling Default Pipeline for a Search Request
DESCRIPTION: This example demonstrates how to disable the default pipeline for a specific search request by setting the 'search_pipeline' parameter to '_none'.

LANGUAGE: json
CODE:
GET /my_index/_search?search_pipeline=_none

----------------------------------------

TITLE: Basic KV Processor Configuration in OpenSearch
DESCRIPTION: Basic syntax example for configuring the KV processor with field, field_split, and value_split parameters.

LANGUAGE: json
CODE:
{
  "kv": {
    "field": "message",
    "field_split": " ",
    "value_split": " "
  }
}

----------------------------------------

TITLE: Indexing Document with Title Only
DESCRIPTION: Example of indexing a document with just a title field into OpenSearch.

LANGUAGE: json
CODE:
PUT testindex/_doc/1
{
  "title": "The wind rises"
}

----------------------------------------

TITLE: Querying CAT Pending Tasks Endpoint in OpenSearch
DESCRIPTION: This snippet shows the endpoint for the CAT pending tasks API in OpenSearch. It allows retrieval of information about pending tasks in the cluster.

LANGUAGE: json
CODE:
GET /_cat/pending_tasks

----------------------------------------

TITLE: Setting Up OpenSearch Dashboards APT Repository
DESCRIPTION: Commands to set up the OpenSearch Dashboards APT repository, including importing the GPG key and creating the repository file.

LANGUAGE: bash
CODE:
sudo apt-get update && sudo apt-get -y install lsb-release ca-certificates curl gnupg2
curl -o- https://artifacts.opensearch.org/publickeys/opensearch.pgp | sudo gpg --dearmor --batch --yes -o /usr/share/keyrings/opensearch-keyring
echo "deb [signed-by=/usr/share/keyrings/opensearch-keyring] https://artifacts.opensearch.org/releases/bundle/opensearch-dashboards/2.x/apt stable main" | sudo tee /etc/apt/sources.list.d/opensearch-dashboards-2.x.list
sudo apt-get update

----------------------------------------

TITLE: Implementing Job Parameter Methods in Java
DESCRIPTION: Implementation of required methods for job parameters including constructor and getters for various job properties.

LANGUAGE: java
CODE:
public SampleJobParameter(String id, String name, String indexToWatch, Schedule schedule, Long lockDurationSeconds, Double jitter) {
        this.jobName = name;
        this.indexToWatch = indexToWatch;
        this.schedule = schedule;

        Instant now = Instant.now();
        this.isEnabled = true;
        this.enabledTime = now;
        this.lastUpdateTime = now;
        this.lockDurationSeconds = lockDurationSeconds;
        this.jitter = jitter;
    }

    @Override
    public String getName() {
        return this.jobName;
    }

    @Override
    public Instant getLastUpdateTime() {
        return this.lastUpdateTime;
    }

    @Override
    public Instant getEnabledTime() {
        return this.enabledTime;
    }

    @Override
    public Schedule getSchedule() {
        return this.schedule;
    }

    @Override
    public boolean isEnabled() {
        return this.isEnabled;
    }

    @Override
    public Long getLockDurationSeconds() {
        return this.lockDurationSeconds;
    }

    @Override public Double getJitter() {
        return jitter;
    }

----------------------------------------

TITLE: Testing Script Pipeline
DESCRIPTION: Example of testing the script pipeline using the simulate API with a sample document.

LANGUAGE: json
CODE:
{
  "docs": [
    {
      "_source": {
        "message": "hello, world!"
      }
    }
  ]
}

----------------------------------------

TITLE: Example Response from UBI Events Aggregation Query
DESCRIPTION: Sample response showing aggregated counts of different UBI event types. Includes metadata about the query execution and bucketed results showing count of each action_name like brand_filter, product_hover, etc.

LANGUAGE: json
CODE:
{
  "took": 1,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 10000,
      "relation": "gte"
    },
    "max_score": null,
    "hits": []
  },
  "aggregations": {
    "event_types": {
      "doc_count_error_upper_bound": 0,
      "sum_other_doc_count": 0,
      "buckets": [
        {
          "key": "brand_filter",
          "doc_count": 3084
        },
        {
          "key": "product_hover",
          "doc_count": 3068
        },
        {
          "key": "button_click",
          "doc_count": 3054
        },
        {
          "key": "product_sort",
          "doc_count": 3012
        },
        {
          "key": "on_search",
          "doc_count": 3010
        },
        {
          "key": "type_filter",
          "doc_count": 2925
        },
        {
          "key": "login",
          "doc_count": 2433
        },
        {
          "key": "logout",
          "doc_count": 1447
        },
        {
          "key": "new_user_entry",
          "doc_count": 207
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Querying Cluster Health in OpenSearch
DESCRIPTION: Uses the Cluster Health API to check the status of an OpenSearch cluster before migration.

LANGUAGE: json
CODE:
GET "/_cluster/health?pretty"

----------------------------------------

TITLE: Searching for All Agents in OpenSearch
DESCRIPTION: This snippet demonstrates how to search for all agents using a match_all query. The size parameter is set to 1000 to retrieve a large number of results.

LANGUAGE: json
CODE:
POST /_plugins/_ml/agents/_search
{
  "query": {
    "match_all": {}
  },
  "size": 1000
}

----------------------------------------

TITLE: Configuring Logger in YAML
DESCRIPTION: Shows how to set the log level for an OpenSearch module by adding a line to the opensearch.yml configuration file.

LANGUAGE: yaml
CODE:
logger.org.opensearch.index.reindex: debug

----------------------------------------

TITLE: Creating kNN Index for Embeddings in OpenSearch
DESCRIPTION: Creates a k-NN index with specific fields for document titles, chapters, and their corresponding embeddings. Configures FAISS HNSW algorithm for vector search with cosine similarity.

LANGUAGE: json
CODE:
{
  "settings": {
    "index.knn": true
  },
  "mappings": {
    "properties": {
      "id": {
        "type": "text"
      },
      "chapter_embedding": {
        "type": "knn_vector",
        "dimension": 384,
        "method": {
          "engine": "faiss",
          "space_type": "cosinesimil",
          "name": "hnsw",
          "parameters": {
            "ef_construction": 512,
            "m": 16
          }
        }
      },
      "chapter": {
        "type": "text"
      },
      "title_embedding": {
        "type": "knn_vector",
        "dimension": 384,
        "method": {
          "engine": "faiss",
          "space_type": "cosinesimil",
          "name": "hnsw",
          "parameters": {
            "ef_construction": 512,
            "m": 16
          }
        }
      },
      "title": {
        "type": "text"
      }
    }
  }
}

----------------------------------------

TITLE: Adding OpenSearch Operator Helm Repository
DESCRIPTION: This command adds the OpenSearch Kubernetes Operator Helm repository from Artifact Hub to your Kubernetes cluster.

LANGUAGE: bash
CODE:
helm repo add opensearch-operator https://opensearch-project.github.io/opensearch-k8s-operator/

----------------------------------------

TITLE: Querying Completion Field Types in OpenSearch
DESCRIPTION: This snippet demonstrates how to query completion field types in OpenSearch. It searches for suggestions that start with the word 'chess' in the 'suggestions' field.

LANGUAGE: json
CODE:
GET chess_store/_search
{
  "suggest": {
    "product-suggestions": {
      "prefix": "chess",        
      "completion": {         
          "field": "suggestions"
      }
    }
  }
}

----------------------------------------

TITLE: Installing OpenSearch Phone Number Plugin
DESCRIPTION: Command to install the analysis-phonenumber plugin in OpenSearch

LANGUAGE: sh
CODE:
./bin/opensearch-plugin install analysis-phonenumber

----------------------------------------

TITLE: Enable Inline Scripting Configuration
DESCRIPTION: YAML configuration to enable inline scripting for bucket script aggregations

LANGUAGE: yaml
CODE:
script.inline: on

----------------------------------------

TITLE: Collapsed Search with Inner Hits
DESCRIPTION: Advanced search query that collapses results by item and includes inner hits to show both cheapest and newest items for each group.

LANGUAGE: json
CODE:
GET /bakery-items/_search
{
  "query": {
    "match": {
      "category": "cakes"
    }
  },
  "collapse": {
    "field": "item",
    "inner_hits": [
      {
        "name": "cheapest_items",
        "size": 1,
        "sort": ["price"]
      },
      {
        "name": "newest_items",
        "size": 1,
        "sort": [{ "baked_date": "desc" }]
      }
    ]
  },
  "sort": ["price"]
}

----------------------------------------

TITLE: Delete Workflow with Status Clear Request
DESCRIPTION: Example request showing how to delete a workflow and its status using the clear_status parameter.

LANGUAGE: json
CODE:
DELETE /_plugins/_flow_framework/workflow/8xL8bowB8y25Tqfenm50?clear_status=true

----------------------------------------

TITLE: Example YAML Configuration
DESCRIPTION: Example of OpenSearch Dashboards configuration values from opensearch_dashboards.yml file

LANGUAGE: yaml
CODE:
defaultIndex: null
defaultRoute: "/app/home"
metaFields: ["_source", "_id", "_type", "_index", "_score"]
query:queryString:options: { "analyze_wildcard": true }
timepicker:refreshIntervalDefaults: 0

----------------------------------------

TITLE: Specifying Search Pipeline in Request Body
DESCRIPTION: This example shows how to include a search pipeline ID in the body of a GET request to OpenSearch. The 'search_pipeline' field is added to the JSON body along with the query parameters.

LANGUAGE: json
CODE:
GET /my-index/_search
{
    "query": {
        "match_all": {}
    },
    "from": 0,
    "size": 10,
    "search_pipeline": "my_pipeline"
}

----------------------------------------

TITLE: Setting Default Search Pipeline for an Index in OpenSearch
DESCRIPTION: This snippet shows how to set the default search pipeline for an index to use the previously created two-phase pipeline.

LANGUAGE: json
CODE:
PUT /index-name/_settings 
{
  "index.search.default_pipeline" : "two_phase_search_pipeline"
}

----------------------------------------

TITLE: Querying Documents by IDs in OpenSearch
DESCRIPTION: Example query demonstrating how to search for documents using specific ID values (34229 and 91296) in the shakespeare index. The query uses the ids query type to match documents based on their _id field.

LANGUAGE: json
CODE:
GET shakespeare/_search
{
  "query": {
    "ids": {
      "values": [
        34229,
        91296
      ]
    }
  }
}

----------------------------------------

TITLE: Retrieving Threat Intelligence Source Details
DESCRIPTION: Retrieves configuration details for a specific threat intelligence source by ID.

LANGUAGE: json
CODE:
GET /_plugins/_security_analytics/threat_intel/sources/<source-id>

----------------------------------------

TITLE: Configuring No Authentication for Cluster in AWS CDK
DESCRIPTION: JSON configuration snippet for setting up a cluster with no authentication in AWS CDK for OpenSearch Migration Assistant.

LANGUAGE: json
CODE:
    "sourceCluster": {
        "endpoint": <SOURCE_CLUSTER_ENDPOINT>,
        "version": "ES 7.10",
        "auth": {"type": "none"}
    }

----------------------------------------

TITLE: Configuring TTL Sync Job Interval - OpenSearch Cluster Settings
DESCRIPTION: Cluster settings configuration to update the synchronization job interval for TTL-based model undeployment.

LANGUAGE: json
CODE:
PUT /_cluster/settings
{
    "persistent": {
        "plugins.ml_commons.sync_up_job_interval_in_seconds": 10
    }
}

----------------------------------------

TITLE: Excluding Vector Field from Source in OpenSearch Index Mappings
DESCRIPTION: This code shows how to exclude a vector field from the _source field in OpenSearch index mappings to save disk space. It also demonstrates setting up a knn_vector field.

LANGUAGE: json
CODE:
PUT /<index_name>/_mappings
{
    "_source": {
    "excludes": ["location"]
    },
    "properties": {
        "location": {
            "type": "knn_vector",
            "dimension": 2,
        "space_type": "l2"
        }
    }
}

----------------------------------------

TITLE: Register Sparse Encoding Model
DESCRIPTION: Example request to register a pretrained sparse encoding model with required parameters and model specifications.

LANGUAGE: json
CODE:
POST /_plugins/_ml/models/_register
{
    "name": "amazon/neural-sparse/opensearch-neural-sparse-encoding-doc-v2-distill",
    "version": "1.0.0",
    "model_group_id": "Z1eQf4oB5Vm0Tdw8EIP2",
    "model_format": "TORCH_SCRIPT"
}

----------------------------------------

TITLE: Flushing OpenSearch Cluster
DESCRIPTION: This snippet demonstrates how to perform a flush operation on the OpenSearch cluster, which commits transaction log entries to the Lucene index. This is an important step in the upgrade process.

LANGUAGE: json
CODE:
POST "/_flush?pretty"

----------------------------------------

TITLE: Copy Processor Basic Syntax
DESCRIPTION: Basic JSON syntax for configuring the copy processor in OpenSearch ingest pipelines. Demonstrates the structure and available parameters.

LANGUAGE: json
CODE:
{
    "copy": {
      "source_field": "source_field", 
      "target_field": "target_field",
      "ignore_missing": true,
      "override_target": true,
      "remove_source": true
    }
}

----------------------------------------

TITLE: Including Tutorial Cards Template in Markdown
DESCRIPTION: Markdown content that includes a title and template reference to render the tutorial cards defined in the page front matter.

LANGUAGE: markdown
CODE:
# Tutorials

Follow our step-by-step tutorials to learn how to use OpenSearch features.

{% include cards.html cards=page.cards %}

----------------------------------------

TITLE: Default Routing Formula in OpenSearch
DESCRIPTION: The default formula used by OpenSearch to route documents to specific shards in an index. It uses the document's _id as the routing value.

LANGUAGE: json
CODE:
shard_num = hash(_routing) % num_primary_shards

----------------------------------------

TITLE: Creating User with Analyst Backend Role in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a user named 'alice' with an 'analyst' backend role in OpenSearch using the Security plugin API.

LANGUAGE: json
CODE:
PUT _plugins/_security/api/internalusers/alice
{
  "password": "alice",
  "backend_roles": [
    "analyst"
  ],
  "attributes": {}
}

----------------------------------------

TITLE: Tenant Configuration in YAML
DESCRIPTION: Example of tenant configuration in tenants.yml showing how to define a custom tenant with metadata.

LANGUAGE: yaml
CODE:
---
_meta:
  type: "tenants"
  config_version: 2

## Demo tenants
admin_tenant:
  reserved: false
  description: "Demo tenant for admin user"

----------------------------------------

TITLE: Configuring Basic parse_json Processor in YAML
DESCRIPTION: A basic YAML configuration for the parse_json processor in a Data Prepper pipeline. This setup parses JSON data from the default 'message' field and adds it to the root of the event.

LANGUAGE: yaml
CODE:
parse-json-pipeline:
  source:
    ...
  ....  
  processor:
    - parse_json:

----------------------------------------

TITLE: Starting OpenSearch Maps Server with Generated Tiles
DESCRIPTION: This command starts the OpenSearch Maps Server using a locally generated raster tiles set.

LANGUAGE: bash
CODE:
docker run \
    -v /absolute/path/to/tiles/:/usr/src/app/dist/public/tiles/data/ \
    -p 8080:8080 \
    opensearch/opensearch-maps-server \
    run

----------------------------------------

TITLE: Searching without a pipeline in OpenSearch
DESCRIPTION: This snippet demonstrates a search query on 'my_index' without using a search pipeline, requesting 8 results.

LANGUAGE: json
CODE:
POST /my_index/_search
{
  "size": 8
}

----------------------------------------

TITLE: Document Indexing Examples
DESCRIPTION: Example documents being indexed to demonstrate match_bool_prefix query behavior.

LANGUAGE: json
CODE:
PUT testindex/_doc/1
{
  "title": "The wind rises"
}

LANGUAGE: json
CODE:
PUT testindex/_doc/2
{
  "title": "Gone with the wind"
}

----------------------------------------

TITLE: Creating a Search Pipeline with By-Field Rerank Processor
DESCRIPTION: This example shows how to create a search pipeline with a rerank processor using the by_field rerank type. It specifies a target field for reranking and includes the original document score.

LANGUAGE: json
CODE:
PUT /_search/pipeline/rerank_byfield_pipeline
{
  "response_processors": [
    {
      "rerank": {
        "by_field": {
          "target_field": "reviews.stars",
          "keep_previous_score" : true
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Creating IOC_UPLOAD Threat Intelligence Source
DESCRIPTION: Creates a new threat intelligence source using IOC_UPLOAD type. Includes configuration for STIX2 format IOCs with hash indicators.

LANGUAGE: json
CODE:
POST _plugins/_security_analytics/threat_intel/sources/
{
  "type": "IOC_UPLOAD",
  "name": "my_custom_feed",
  "format": "STIX2",
  "description": "this is the description",
  "store_type": "OS",
  "enabled": "false",
  "ioc_types": [
    "hashes"
  ],
  "source": {
    "ioc_upload": {
      "file_name": "test",
      "iocs": [
        {
          "id": "1",
          "name": "uldzafothwgik",
          "type": "hashes",
          "value": "gof",
          "severity": "thvvz",
          "created": 1719519073,
          "modified": 1719519073,
          "description": "first one here",
          "labels": [
            "ik"
          ],
          "feed_id": "jl",
          "spec_version": "gavvnespe",
          "version": -4356924786557562654
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Creating Snapshot in OpenSearch Migration Console
DESCRIPTION: This command creates a snapshot of the source cluster and stores it in a preconfigured Amazon S3 bucket.

LANGUAGE: sh
CODE:
console snapshot create

----------------------------------------

TITLE: Delete ML Controller Example Request
DESCRIPTION: Example request showing how to delete a controller using a specific model ID.

LANGUAGE: json
CODE:
DELETE /_plugins/_ml/controllers/MzcIJX8BA7mbufL6DOwl

----------------------------------------

TITLE: Creating Index with Keep Types Filter Configuration
DESCRIPTION: Example of creating a new index with a custom analyzer that uses the keep_types filter to only include ALPHANUM tokens. The analyzer combines the standard tokenizer with lowercase and keep_types filters.

LANGUAGE: json
CODE:
PUT /test_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "custom_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": ["lowercase", "keep_types_filter"]
        }
      },
      "filter": {
        "keep_types_filter": {
          "type": "keep_types",
          "types": ["<ALPHANUM>"]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Query Specific Index with Verbose Output
DESCRIPTION: Example request to get information about a specific index with verbose output enabled.

LANGUAGE: json
CODE:
GET _cat/indices/<index>?v

----------------------------------------

TITLE: Ingesting a document with sparse vector embeddings in OpenSearch
DESCRIPTION: This snippet shows how to ingest a document containing sparse vector embeddings into the previously created index in OpenSearch.

LANGUAGE: json
CODE:
PUT /my-nlp-index/_doc/1
{
  "passage_text": "Hello world",
  "id": "s1",
  "passage_embedding": {
    "hi" : 4.338913,
    "planets" : 2.7755864,
    "planet" : 5.0969057,
    "mars" : 1.7405145,
    "earth" : 2.6087382,
    "hello" : 3.3210192
  }
}

----------------------------------------

TITLE: Basic CAT Segments Query
DESCRIPTION: Basic query to retrieve segment information with verbose output enabled.

LANGUAGE: json
CODE:
GET _cat/segments?v

----------------------------------------

TITLE: CloudWatch Logs Query for Failed Documents
DESCRIPTION: Query to identify failed document operations in CloudWatch Logs Insights during migration verification process.

LANGUAGE: bash
CODE:
fields @message
| filter @message like "Bulk request succeeded, but some operations failed."
| sort @timestamp desc
| limit 10000

----------------------------------------

TITLE: Configuring SSL Disabled State
DESCRIPTION: Basic YAML configuration to disable SSL for development environments

LANGUAGE: yaml
CODE:
ssl: false

----------------------------------------

TITLE: Configuring SSL Disabled State
DESCRIPTION: Basic YAML configuration to disable SSL for development environments

LANGUAGE: yaml
CODE:
ssl: false

----------------------------------------

TITLE: Creating SageMaker Connector in OpenSearch
DESCRIPTION: JSON configuration for creating a connector to integrate the SageMaker model with OpenSearch, including pre and post-processing functions.

LANGUAGE: json
CODE:
{
  "name": "Sagemaker cross-encoder model",
  "description": "Test connector for Sagemaker cross-encoder model",
  "version": 1,
  "protocol": "aws_sigv4",
  "credential": {
    "access_key": "your_access_key",
    "secret_key": "your_secret_key",
    "session_token": "your_session_token"
  },
  "parameters": {
    "region": "your_sagemkaer_model_region_like_us-west-2",
    "service_name": "sagemaker"
  },
  "actions": [
    {
      "action_type": "predict",
      "method": "POST",
      "url": "your_sagemaker_model_inference_endpoint",
      "headers": {
        "content-type": "application/json"
      },
      "request_body": "{ \"inputs\": ${parameters.inputs} }"
    }
  ]
}

----------------------------------------

TITLE: Complex Index-based Query with Aggregations - OpenSearch JSON
DESCRIPTION: Comprehensive search query that demonstrates filtering by index, aggregating results by index, sorting by index name, and adding a script field to show index names.

LANGUAGE: json
CODE:
GET products,customers/_search
{
  "query": {
    "terms": {
      "_index": ["products", "customers"]
    }
  },
  "aggs": {
    "index_groups": {
      "terms": {
        "field": "_index",
        "size": 10
      }
    }
  },
  "sort": [
    {
      "_index": {
        "order": "desc"
      }
    }
  ],
  "script_fields": {
    "index_name": {
      "script": {
        "lang": "painless",
        "source": "doc['_index'].value"
      }
    }
  }
}

----------------------------------------

TITLE: Querying OpenSearch with Minimum Should Match
DESCRIPTION: This snippet demonstrates a basic OpenSearch query using the 'minimum_should_match' parameter. It searches the 'shakespeare' index for documents that match at least two out of three specified terms.

LANGUAGE: json
CODE:
GET /shakespeare/_search
{
  "query": {
    "match": {
      "text_entry": {
        "query": "prince king star",
        "minimum_should_match": "2"
      }
    }
  }
}

----------------------------------------

TITLE: Configuring admin certificate in opensearch.yml
DESCRIPTION: This YAML snippet shows how to add the distinguished name of an admin certificate to the OpenSearch configuration file.

LANGUAGE: yaml
CODE:
plugins.security.authcz.admin_dn:
  - CN=kirk,OU=client,O=client,L=test,C=DE

----------------------------------------

TITLE: Example index.json structure for OpenSearch Benchmark
DESCRIPTION: Demonstrates the structure of an index.json file, which defines data mappings, indexing parameters, and index settings for workload documents. This example is from the nyc_taxis workload and shows various field types and settings.

LANGUAGE: json
CODE:
{
  "settings": {
    "index.number_of_shards": {% raw %}{{number_of_shards | default(1)}}{% endraw %},
    "index.number_of_replicas": {% raw %}{{number_of_replicas | default(0)}}{% endraw %},
    "index.queries.cache.enabled": {% raw %}{{query_cache_enabled | default(false) | tojson}}{% endraw %},
    "index.requests.cache.enable": {% raw %}{{requests_cache_enabled | default(false) | tojson}}{% endraw %}
  },
  "mappings": {
    "_source": {
      "enabled": {% raw %}{{ source_enabled | default(true) | tojson }}{% endraw %}
    },
    "properties": {
      "surcharge": {
        "scaling_factor": 100,
        "type": "scaled_float"
      },
      "dropoff_datetime": {
        "type": "date",
        "format": "yyyy-MM-dd HH:mm:ss"
      },
      "trip_type": {
        "type": "keyword"
      },
      "mta_tax": {
        "scaling_factor": 100,
        "type": "scaled_float"
      },
      "rate_code_id": {
        "type": "keyword"
      },
      "passenger_count": {
        "type": "integer"
      },
      "pickup_datetime": {
        "type": "date",
        "format": "yyyy-MM-dd HH:mm:ss"
      },
      "tolls_amount": {
        "scaling_factor": 100,
        "type": "scaled_float"
      },
      "tip_amount": {
        "type": "half_float"
      },
      "payment_type": {
        "type": "keyword"
      },
      "extra": {
        "scaling_factor": 100,
        "type": "scaled_float"
      },
      "vendor_id": {
        "type": "keyword"
      },
      "store_and_fwd_flag": {
        "type": "keyword"
      },
      "improvement_surcharge": {
        "scaling_factor": 100,
        "type": "scaled_float"
      },
      "fare_amount": {
        "scaling_factor": 100,
        "type": "scaled_float"
      },
      "ehail_fee": {
        "scaling_factor": 100,
        "type": "scaled_float"
      },
      "cab_color": {
        "type": "keyword"
      },
      "dropoff_location": {
        "type": "geo_point"
      },
      "vendor_name": {
        "type": "text"
      },
      "total_amount": {
        "scaling_factor": 100,
        "type": "scaled_float"
      },
      "trip_distance": {% raw %}{%- if trip_distance_mapping is defined %} {{ trip_distance_mapping | tojson }} {%- else %}{% endraw %} {
        "scaling_factor": 100,
        "type": "scaled_float"
      }{% raw %}{%- endif %}{% endraw %},
      "pickup_location": {
        "type": "geo_point"
      }
    },
    "dynamic": "strict"
  }
}

----------------------------------------

TITLE: Indexing a Document with Binary Value in OpenSearch
DESCRIPTION: This example shows how to index a document with a binary value into the previously created index. The binary value is represented as a Base64 encoded string.

LANGUAGE: json
CODE:
PUT testindex/_doc/1 
{
  "binary_value" : "bGlkaHQtd29rfx4="
}

----------------------------------------

TITLE: Configuring TLS Hot Reload
DESCRIPTION: YAML configuration to enable hot reloading of TLS certificates in OpenSearch, allowing certificate updates without cluster restart.

LANGUAGE: yaml
CODE:
plugins.security.ssl.certificates_hot_reload.enabled: true

----------------------------------------

TITLE: Creating a Search Pipeline with Score Ranker Processor in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a search pipeline containing a score-ranker-processor that uses the RRF (Reciprocal Rank Fusion) combination technique.

LANGUAGE: json
CODE:
PUT /_search/pipeline/<rrf-pipeline>
{
  "description": "Post processor for hybrid RRF search",
  "phase_results_processors": [
    {
      "score-ranker-processor": {
        "combination": {
          "technique": "rrf"
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Creating User with Backend Role in OpenSearch Security
DESCRIPTION: These JSON snippets demonstrate how to create users 'alice' and 'bob' with different backend roles using the OpenSearch Security API. This is part of setting up fine-grained access control.

LANGUAGE: json
CODE:
PUT /_plugins/_security/api/internalusers/alice
{
  "password": "alice",
  "backend_roles": [
    "analyst"
  ],
  "attributes": {}
}

LANGUAGE: json
CODE:
PUT /_plugins/_security/api/internalusers/bob
{
  "password": "bob",
  "backend_roles": [
    "human-resources"
  ],
  "attributes": {}
}

----------------------------------------

TITLE: CatIndexTool Execution Response in OpenSearch
DESCRIPTION: Response containing detailed index information including health status, document counts, and storage sizes for all indices in the cluster.

LANGUAGE: json
CODE:
{
  "inference_results": [
    {
      "output": [
        {
          "name": "response",
          "result": """health    status    index    uuid    pri    rep    docs.count    docs.deleted    store.size    pri.store.size
green    open    .plugins-ml-model-group    lHgGEgJhT_mpADyOZoXl2g    1    1    9    2    33.4kb    16.7kb
green    open    .plugins-ml-memory-meta    b2LEpv0QS8K60QBjXtRm6g    1    1    13    0    95.1kb    47.5kb
green    open    .ql-datasources    9NXm_tMXQc6s_4uRToSNkQ    1    1    0    0    416b    208b"""
        }
      ]
    }
  ]
}

----------------------------------------

TITLE: Agent Execution Endpoint
DESCRIPTION: The endpoint for executing an ML agent in OpenSearch.

LANGUAGE: json
CODE:
POST /_plugins/_ml/agents/<agent_id>/_execute

----------------------------------------

TITLE: Querying CAT nodeattrs Endpoint in OpenSearch
DESCRIPTION: This snippet shows the endpoint for the CAT nodeattrs operation. It is used to list the attributes of custom nodes in OpenSearch.

LANGUAGE: json
CODE:
GET /_cat/nodeattrs

----------------------------------------

TITLE: Checking and Resetting Rollover Skip Settings in OpenSearch
DESCRIPTION: These snippets show how to check if rollover skip is enabled for an index and how to reset it. This is useful for managing rollover behavior in ISM.

LANGUAGE: bash
CODE:
GET <target_index>/_settings?pretty

LANGUAGE: json
CODE:
{
  "index": {
    "opendistro.index_state_management.rollover_skip": true
  }
}

LANGUAGE: bash
CODE:
PUT <target_index>/_settings
{
    "index": {
      "index_state_management.rollover_skip": false
  }
}

----------------------------------------

TITLE: Recommissioning a Zone in OpenSearch using JSON
DESCRIPTION: This API endpoint recommissions a previously decommissioned zone. It uses the DELETE method to remove the decommission status for all zones.

LANGUAGE: json
CODE:
DELETE /_cluster/decommission/awareness

----------------------------------------

TITLE: Viewing Cron Manual in Bash
DESCRIPTION: This command displays the manual page for the cron utility, providing information on its usage and syntax.

LANGUAGE: bash
CODE:
man cron

----------------------------------------

TITLE: Installing OpenSearch Dashboards using Helm
DESCRIPTION: This set of commands demonstrates how to package and install the OpenSearch Dashboards Helm chart. It includes steps to change directory, package the chart, and deploy it using Helm.

LANGUAGE: bash
CODE:
cd opensearch-dashboards
helm package .
helm install --generate-name opensearch-dashboards-1.0.0.tgz

----------------------------------------

TITLE: Testing Cohere Rerank Model in OpenSearch
DESCRIPTION: Tests the registered Cohere Rerank model by calling the Predict API with a sample query and documents.

LANGUAGE: json
CODE:
POST _plugins/_ml/models/your_model_id/_predict
{
  "parameters": {
    "query": "What is the capital of the United States?",
    "documents": [
      "Carson City is the capital city of the American state of Nevada.",
      "The Commonwealth of the Northern Mariana Islands is a group of islands in the Pacific Ocean. Its capital is Saipan.",
      "Washington, D.C. (also known as simply Washington or D.C., and officially as the District of Columbia) is the capital of the United States. It is a federal district.",
      "Capital punishment (the death penalty) has existed in the United States since beforethe United States was a country. As of 2017, capital punishment is legal in 30 of the 50 states."
    ],
    "top_n": 4
  }
}

----------------------------------------

TITLE: Extracting Raw Term Statistics with match_explorer Query in OpenSearch
DESCRIPTION: Demonstrates how to use the match_explorer query to get raw term statistics like document frequency. This example finds the highest document frequency between the terms 'rambo' and 'rocky' in the 'title' field.

LANGUAGE: json
CODE:
{
    "query": {
        "match_explorer": {
            "type": "max_raw_df",
            "query": {
                "match": {
                    "title": "rambo rocky"
                }
            }
        }
    }
}

----------------------------------------

TITLE: Performing a rolling upgrade of OpenSearch nodes
DESCRIPTION: Commands to upgrade each OpenSearch node from version 1.3.7 to 2.5.0.

LANGUAGE: bash
CODE:
docker stop os-node-01 && docker container rm os-node-01

LANGUAGE: bash
CODE:
docker run -d \
   -p 9201:9200 -p 9601:9600 \
   -e "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m" \
   --ulimit nofile=65536:65536 --ulimit memlock=-1:-1 \
   -v data-01:/usr/share/opensearch/data \
   -v repo-01:/usr/share/opensearch/snapshots \
   -v ~/deploy/opensearch-01.yml:/usr/share/opensearch/config/opensearch.yml \
   -v ~/deploy/root-ca.pem:/usr/share/opensearch/config/root-ca.pem \
   -v ~/deploy/admin.pem:/usr/share/opensearch/config/admin.pem \
   -v ~/deploy/admin-key.pem:/usr/share/opensearch/config/admin-key.pem \
   -v ~/deploy/os-node-01.pem:/usr/share/opensearch/config/os-node-01.pem \
   -v ~/deploy/os-node-01-key.pem:/usr/share/opensearch/config/os-node-01-key.pem \
   --network opensearch-dev-net \
   --ip 172.20.0.11 \
   --name os-node-01 \
   opensearchproject/opensearch:2.5.0

----------------------------------------

TITLE: JWT Header Structure Example
DESCRIPTION: Example of a typical JWT header showing the algorithm and token type.

LANGUAGE: json
CODE:
{
  "alg": "HS256",
  "typ": "JWT"
}

----------------------------------------

TITLE: Retrieving k-NN Stats in OpenSearch
DESCRIPTION: Demonstrates how to fetch comprehensive k-NN plugin statistics across all nodes in the cluster using the stats API.

LANGUAGE: json
CODE:
GET /_plugins/_knn/stats?pretty

----------------------------------------

TITLE: NMSLIB HNSW Configuration
DESCRIPTION: Example of configuring HNSW method using the deprecated NMSLIB engine.

LANGUAGE: json
CODE:
"method": {
    "name": "hnsw",
    "engine": "nmslib",
    "space_type": "l2",
    "parameters": {
        "ef_construction": 100,
        "m": 16
    }
}

----------------------------------------

TITLE: Basic Sigma Detection Rule Structure in YAML
DESCRIPTION: Example of a basic detection rule showing key-value pair mappings for detection conditions

LANGUAGE: yaml
CODE:
detection:
  selection:
    selection_schtasks:
      Image|endswith: \schtasks.exe
      CommandLine|contains: '/Create '

----------------------------------------

TITLE: Multiple Roles Interaction - JSON Response
DESCRIPTION: Example JSON response showing the result when multiple roles with conflicting field-level security settings are applied.

LANGUAGE: json
CODE:
{
  "_index": "movies",
  "_source": {
    "year": 2013,
    "directors": [
      "Ron Howard"
    ],
    "plot": "A re-creation of the merciless 1970s rivalry between Formula One rivals James Hunt and Niki Lauda."
  }
}

----------------------------------------

TITLE: Checking OpenSearch Operator Pod Status
DESCRIPTION: This command displays the status of the OpenSearch Operator pods in the operator system namespace.

LANGUAGE: bash
CODE:
k get pod -n opensearch-operator-system

----------------------------------------

TITLE: Delete Task Example Response
DESCRIPTION: Example response showing the successful deletion of an ML Commons task, including shards information and version details.

LANGUAGE: json
CODE:
{
  "_index" : ".plugins-ml-task",
  "_id" : "xQRYLX8BydmmU1x6nuD3",
  "_version" : 4,
  "result" : "deleted",
  "_shards" : {
    "total" : 2,
    "successful" : 2,
    "failed" : 0
  },
  "_seq_no" : 42,
  "_primary_term" : 7
}

----------------------------------------

TITLE: Pipeline Creation for Reindex
DESCRIPTION: Creates an ingest pipeline with processors to transform data during reindexing.

LANGUAGE: json
CODE:
PUT _ingest/pipeline/pipeline-test
{
"description": "Splits the text field into a list. Computes the length of the 'word' field and stores it in a new 'word_count' field. Removes the 'test' field.",
"processors": [
 {
   "split": {
     "field": "text",
     "separator": "\\s+",
     "target_field": "word"
   }
 },
 {
   "script": {
     "lang": "painless",
     "source": "ctx.word_count = ctx.word.length"
   }
 },
 {
   "remove": {
     "field": "test"
   }
 }
]
}

----------------------------------------

TITLE: Creating an Index with KStem Filter in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a new index named 'my_kstem_index' with a custom analyzer that includes the KStem filter. It configures the analyzer and maps it to a text field named 'content'.

LANGUAGE: json
CODE:
PUT /my_kstem_index
{
  "settings": {
    "analysis": {
      "filter": {
        "kstem_filter": {
          "type": "kstem"
        }
      },
      "analyzer": {
        "my_kstem_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "kstem_filter"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "my_kstem_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Decommissioning a Zone in OpenSearch using JSON
DESCRIPTION: This API endpoint decommissions a specific zone based on the awareness attribute name and value. It uses the PUT method to initiate the decommission process.

LANGUAGE: json
CODE:
PUT /_cluster/decommission/awareness/<zone>/<zone-a>

----------------------------------------

TITLE: Uninstalling OpenSearch Dashboards using Helm
DESCRIPTION: This command demonstrates how to uninstall a specific OpenSearch Dashboards deployment using Helm.

LANGUAGE: bash
CODE:
helm delete opensearch-dashboards-1-1629223356

----------------------------------------

TITLE: Cloning an Index with Custom Settings and Aliases in OpenSearch
DESCRIPTION: Demonstrates how to clone an index named 'sample-index1' to 'cloned-index1' with custom shard settings and an alias.

LANGUAGE: json
CODE:
PUT /sample-index1/_clone/cloned-index1
{
  "settings": {
    "index": {
      "number_of_shards": 2,
      "number_of_replicas": 1
    }
  },
  "aliases": {
    "sample-alias1": {}
  }
}

----------------------------------------

TITLE: OpenSearch Security Plugin Removal Command
DESCRIPTION: Bash command to remove the Security plugin from OpenSearch.

LANGUAGE: bash
CODE:
./bin/opensearch-plugin remove opensearch-security

----------------------------------------

TITLE: Updating SQL Settings via Query Plugin Endpoint
DESCRIPTION: Illustrates how to update SQL settings using the _plugins/_query/settings endpoint, disabling the SQL plugin.

LANGUAGE: json
CODE:
PUT _plugins/_query/settings
{
  "transient" : {
    "plugins.sql.enabled" : false
  }
}

----------------------------------------

TITLE: Creating IAM Role Trust Policy in Account A
DESCRIPTION: Establishes a trust policy for the IAM role in Account A, allowing it to be assumed by the OpenSearch service.

LANGUAGE: json
CODE:
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Principal": {
                "Service": "es.amazonaws.com"
            },
            "Action": "sts:AssumeRole"
        }
    ]
}

----------------------------------------

TITLE: Caching Specific Search Requests in OpenSearch
DESCRIPTION: Demonstrates how to enable request caching for a specific search query using the request_cache parameter.

LANGUAGE: json
CODE:
GET /students/_search?request_cache=true
{
  "query": {
    "match": {
      "name": "doe john"
    }
  }
}

----------------------------------------

TITLE: Creating Custom Norwegian Analyzer in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a custom Norwegian analyzer by defining token filters and combining them into a custom analyzer configuration.

LANGUAGE: json
CODE:
PUT /norwegian-index
{
  "settings": {
    "analysis": {
      "filter": {
        "norwegian_stop": {
          "type": "stop",
          "stopwords": "_norwegian_"
        },
        "norwegian_stemmer": {
          "type": "stemmer",
          "language": "norwegian"
        },
        "norwegian_keywords": {
          "type": "keyword_marker",
          "keywords": []
        }
      },
      "analyzer": {
        "norwegian_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "norwegian_stop",
            "norwegian_keywords",
            "norwegian_stemmer"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "norwegian_analyzer"
      }
    }
  }
}

----------------------------------------

TITLE: Mapping WAF Log Fields to ECS in JSON
DESCRIPTION: This JSON snippet defines the mappings between raw WAF log fields and their corresponding ECS (Elastic Common Schema) fields. It covers various aspects of HTTP requests and responses, including methods, URIs, headers, and status codes.

LANGUAGE: json
CODE:
  "mappings": [
    {
      "raw_field":"cs-method",
      "ecs":"waf.request.method"
    },
    {
      "raw_field":"httpRequest.httpMethod",
      "ecs":"waf.request.method"
    },
    {
      "raw_field":"cs-uri-query",
      "ecs":"waf.request.uri_query"
    },
    {
      "raw_field":"httpRequest.uri",
      "ecs":"waf.request.uri_query"
    },
    {
      "raw_field":"httpRequest.args",
      "ecs":"waf.request.uri_query"
    },
    {
      "raw_field":"cs-user-agent",
      "ecs":"waf.request.headers.user_agent"
    },
    {
      "raw_field":"httpRequest.headers",
      "ecs":"waf.request.headers"
    },
    {
      "raw_field":"sc-status",
      "ecs":"waf.response.code"
    },
    {
      "raw_field":"responseCodeSent",
      "ecs":"waf.response.code"
    },
    {
      "raw_field":"timestamp",
      "ecs":"timestamp"
    },
    {
      "raw_field":"httpRequest.headers.value",
      "ecs":"waf.request.headers.value"
    },
    {
      "raw_field":"httpRequest.headers.name",
      "ecs":"waf.request.headers.name"
    }
  ]

----------------------------------------

TITLE: Force Merge Multiple Indexes
DESCRIPTION: Example request demonstrating force merge operation on multiple indexes simultaneously.

LANGUAGE: json
CODE:
POST /testindex1,testindex2/_forcemerge

----------------------------------------

TITLE: Indexing Document with New Field in Dynamic Object in OpenSearch
DESCRIPTION: This snippet demonstrates indexing a document with a new field in a dynamic object in OpenSearch. It adds an 'id' field to the 'patient' object that wasn't in the original mapping.

LANGUAGE: json
CODE:
PUT testindex1/_doc/1
{ 
  "patient": { 
    "name" : "John Doe",
    "id" : "123456"
  } 
}

----------------------------------------

TITLE: Viewing Console Logs for Trace Analytics in OpenSearch
DESCRIPTION: This code snippet shows the console logs generated when a request is sent through the Jaeger HotROD demo application. It demonstrates how trace IDs and span IDs are used to track operations across services.

LANGUAGE: plaintext
CODE:
jaeger-hot-rod  | http://0.0.0.0:8081/customer?customer=392
jaeger-hot-rod  | 2020-11-19T16:29:53.425Z	INFO	frontend/server.go:92	HTTP request received	{"service": "frontend", "trace_id": "12091bd60f45ea2c", "span_id": "12091bd60f45ea2c", "method": "GET", "url": "/dispatch?customer=392&nonse=0.6509021735471818"}
jaeger-hot-rod  | 2020-11-19T16:29:53.426Z	INFO	customer/client.go:54	Getting customer{"service": "frontend", "component": "customer_client", "trace_id": "12091bd60f45ea2c", "span_id": "12091bd60f45ea2c", "customer_id": "392"}
jaeger-hot-rod  | 2020-11-19T16:29:53.430Z	INFO	customer/server.go:67	HTTP request received	{"service": "customer", "trace_id": "12091bd60f45ea2c", "span_id": "252ff7d0e1ac533b", "method": "GET", "url": "/customer?customer=392"}
jaeger-hot-rod  | 2020-11-19T16:29:53.430Z	INFO	customer/database.go:73	Loading customer{"service": "customer", "component": "mysql", "trace_id": "12091bd60f45ea2c", "span_id": "252ff7d0e1ac533b", "customer_id": "392"}

----------------------------------------

TITLE: JWT Authentication Domain Configuration
DESCRIPTION: YAML configuration for setting up JWT authentication in OpenSearch, including HTTP authenticator settings and backend configuration.

LANGUAGE: yaml
CODE:
jwt_auth_domain:
  http_enabled: true
  transport_enabled: true
  order: 0
  http_authenticator:
    type: jwt
    challenge: false
    config:
      signing_key: "base64 encoded key"
      jwt_header: "Authorization"
      jwt_url_parameter: null
      subject_key: null
      roles_key: null
      required_audience: null
      required_issuer: null
      jwt_clock_skew_tolerance_seconds: 20
  authentication_backend:
    type: noop

----------------------------------------

TITLE: Node Availability Error Output
DESCRIPTION: Error message displayed when securityadmin.sh can reach the cluster but cannot update the configuration due to node availability issues.

LANGUAGE: bash
CODE:
Contacting opensearch cluster 'opensearch' and wait for YELLOW clusterstate ...
Cannot retrieve cluster state due to: None of the configured nodes are available: [{#transport#-1}{mr2NlX3XQ3WvtVG0Dv5eHw}{localhost}{127.0.0.1:9300}]. This is not an error, will keep on trying ...

----------------------------------------

TITLE: Enabling Connector Access Control in OpenSearch
DESCRIPTION: JSON request to enable granular access control for ML connectors.

LANGUAGE: json
CODE:
PUT /_cluster/settings
{
    "persistent": {
        "plugins.ml_commons.connector_access_control_enabled": true
    }
}

----------------------------------------

TITLE: Adding Rollover Alias to Index Template in OpenSearch
DESCRIPTION: This snippet shows how to add a rollover_alias setting to an index template. This is necessary for proper functioning of rollover policies in ISM.

LANGUAGE: bash
CODE:
PUT _index_template/ism_rollover
{
  "index_patterns": ["<index_patterns_in_rollover_policy>"],
  "template": {
   "settings": {
    "plugins.index_state_management.rollover_alias": "<rollover_alias>"
   }
 }
}

----------------------------------------

TITLE: Reindex API Response in OpenSearch
DESCRIPTION: This snippet shows an example response from the reindex API operation. It includes various statistics about the reindex process, such as the number of documents processed, created, and updated, as well as timing information.

LANGUAGE: json
CODE:
{
    "took": 28829,
    "timed_out": false,
    "total": 111396,
    "updated": 0,
    "created": 111396,
    "deleted": 0,
    "batches": 112,
    "version_conflicts": 0,
    "noops": 0,
    "retries": {
        "bulk": 0,
        "search": 0
    },
    "throttled_millis": 0,
    "requests_per_second": -1.0,
    "throttled_until_millis": 0,
    "failures": []
}

----------------------------------------

TITLE: Querying OpenSearch cluster status using cURL
DESCRIPTION: This snippet demonstrates how to send a GET request to the OpenSearch cluster to verify its status and retrieve version information. It uses basic authentication and disables SSL verification.

LANGUAGE: bash
CODE:
$ curl -XGET https://localhost:9200 -u 'admin:<custom-admin-password>' --insecure

LANGUAGE: json
CODE:
{
  "name" : "opensearch-cluster-master-1",
  "cluster_name" : "opensearch-cluster",
  "cluster_uuid" : "hP2gq5bPS3SLp8Z7wXm8YQ",
  "version" : {
    "distribution" : "opensearch",
    "number" : "1.0.0",
    "build_type" : "tar",
    "build_hash" : "34550c5b17124ddc59458ef774f6b43a086522e3",
    "build_date" : "2021-07-02T23:22:21.383695Z",
    "build_snapshot" : false,
    "lucene_version" : "8.8.2",
    "minimum_wire_compatibility_version" : "6.8.0",
    "minimum_index_compatibility_version" : "6.0.0-beta1"
  },
  "tagline" : "The OpenSearch Project: https://opensearch.org/"
}

----------------------------------------

TITLE: Force Merge All Indexes
DESCRIPTION: Example request showing how to force merge all indexes in the cluster.

LANGUAGE: json
CODE:
POST /_forcemerge

----------------------------------------

TITLE: Formatting Dates in Logstash Output Configuration
DESCRIPTION: Shows how to include formatted date strings in Logstash output configurations using string expansion syntax.

LANGUAGE: yaml
CODE:
file {
  path => "%{[type]}_%{+yyyy_MM_dd}.log"
}

----------------------------------------

TITLE: Creating an Ingest Pipeline with On Failure Handling in OpenSearch
DESCRIPTION: This example shows how to create an ingest pipeline that adds a timestamp to a document and includes an 'on_failure' handler. If the date processor fails, it sets an 'ingest_error' field to 'failed'.

LANGUAGE: json
CODE:
PUT _ingest/pipeline/my-pipeline/
{
  "description": "Add timestamp to the document",
  "processors": [
    {
      "date": {
        "field": "timestamp_field",
        "formats": ["yyyy-MM-dd HH:mm:ss"],
        "target_field": "@timestamp",
        "on_failure": [
          {
            "set": {
              "field": "ingest_error",
              "value": "failed"
            }
          }
        ]
      }
    }
  ]
}

----------------------------------------

TITLE: Executing k-NN Search with Hamming Distance in OpenSearch
DESCRIPTION: This snippet demonstrates how to perform a k-NN search using Hamming distance on binary data in OpenSearch. It includes pre-filtering and uses the knn_score script with the hammingbit space type.

LANGUAGE: json
CODE:
GET my-index/_search
{
  "size": 2,
  "query": {
    "script_score": {
      "query": {
        "bool": {
          "filter": {
            "term": {
              "color": "BLUE"
            }
          }
        }
      },
      "script": {
        "lang": "knn",
        "source": "knn_score",
        "params": {
          "field": "my_binary",
          "query_value": "U29tZXRoaW5nIEltIGxvb2tpbmcgZm9y",
          "space_type": "hammingbit"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Executing k-NN Search with Hamming Distance in OpenSearch
DESCRIPTION: This snippet demonstrates how to perform a k-NN search using Hamming distance on binary data in OpenSearch. It includes pre-filtering and uses the knn_score script with the hammingbit space type.

LANGUAGE: json
CODE:
GET my-index/_search
{
  "size": 2,
  "query": {
    "script_score": {
      "query": {
        "bool": {
          "filter": {
            "term": {
              "color": "BLUE"
            }
          }
        }
      },
      "script": {
        "lang": "knn",
        "source": "knn_score",
        "params": {
          "field": "my_binary",
          "query_value": "U29tZXRoaW5nIEltIGxvb2tpbmcgZm9y",
          "space_type": "hammingbit"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Assigning Full Asynchronous Search Access to Users in OpenSearch
DESCRIPTION: This snippet demonstrates how to assign full access to asynchronous search functionality for users 'judy' and 'elon' using the OpenSearch Security API.

LANGUAGE: json
CODE:
PUT _plugins/_security/api/rolesmapping/async_full_access
{
  "backend_roles": [],
  "hosts": [],
  "users": [
    "judy",
    "elon"
  ]
}

----------------------------------------

TITLE: Example Endpoints Component Integration
DESCRIPTION: Example of how to insert API endpoints documentation using the spec-insert plugin for the search API.

LANGUAGE: markdown
CODE:
<!-- spec_insert_start
api: search
component: endpoints
-->
<!-- spec_insert_end -->

----------------------------------------

TITLE: Configuring GitHub Actions Field Mappings in JSON
DESCRIPTION: Defines the field mapping between raw GitHub Actions log fields and Elastic Common Schema (ECS) format. This mapping configuration specifies how the 'action' field from raw logs should be mapped to the 'github.action' field in ECS.

LANGUAGE: json
CODE:
  "mappings": [
    {
      "raw_field":"action",
      "ecs":"github.action"
    }
  ]

----------------------------------------

TITLE: Analyzing Text with Flatten Graph Filter in OpenSearch
DESCRIPTION: Example of analyzing text using the custom analyzer with flatten_graph filter, showing how tokens are generated and positioned in the resulting output.

LANGUAGE: json
CODE:
POST /test_index/_analyze
{
  "analyzer": "my_index_analyzer",
  "text": "OpenSearch helped many employers"
}

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "OpenSearch",
      "start_offset": 0,
      "end_offset": 10,
      "type": "<ALPHANUM>",
      "position": 0,
      "positionLength": 2
    },
    {
      "token": "Open",
      "start_offset": 0,
      "end_offset": 4,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "Search",
      "start_offset": 4,
      "end_offset": 10,
      "type": "<ALPHANUM>",
      "position": 1
    },
    {
      "token": "helped",
      "start_offset": 11,
      "end_offset": 17,
      "type": "<ALPHANUM>",
      "position": 2
    },
    {
      "token": "many",
      "start_offset": 18,
      "end_offset": 22,
      "type": "<ALPHANUM>",
      "position": 3
    },
    {
      "token": "employers",
      "start_offset": 23,
      "end_offset": 32,
      "type": "<ALPHANUM>",
      "position": 4
    }
  ]
}

----------------------------------------

TITLE: Document Deletion in OpenSearch
DESCRIPTION: Shows how to delete a document using its ID while maintaining version tracking.

LANGUAGE: json
CODE:
DELETE movies/_doc/1

----------------------------------------

TITLE: Configuring Prometheus Data Source without Authentication
DESCRIPTION: API request to configure a basic Prometheus data source connection without authentication settings

LANGUAGE: json
CODE:
POST _plugins/_query/_datasources 
{
    "name" : "my_prometheus",
    "connector": "prometheus",
    "properties" : {
        "prometheus.uri" : "http://localhost:9090"
    }
}

----------------------------------------

TITLE: RPM Package Installation
DESCRIPTION: Commands to install OpenSearch using RPM package with optional custom admin password

LANGUAGE: bash
CODE:
sudo yum install opensearch-{{site.opensearch_version}}-linux-x64.rpm

LANGUAGE: bash
CODE:
sudo env OPENSEARCH_INITIAL_ADMIN_PASSWORD=<custom-admin-password> yum install opensearch-{{site.opensearch_version}}-linux-x64.rpm

----------------------------------------

TITLE: Docker Compose Configuration for Searchable Snapshots
DESCRIPTION: Docker compose configuration for creating a node with search role and cache size settings for searchable snapshots.

LANGUAGE: yaml
CODE:
version: '3'
services:
  opensearch-node1:
    image: opensearchproject/opensearch:2.7.0
    container_name: opensearch-node1
    environment:
      - cluster.name=opensearch-cluster
      - node.name=opensearch-node1
      - node.roles=search
      - node.search.cache.size=50gb

----------------------------------------

TITLE: Indexing Documents for Intervals Query in OpenSearch
DESCRIPTION: Examples of indexing documents into OpenSearch for use with the Intervals query. These documents contain 'key-value pairs' and 'hash table/map' phrases for demonstration.

LANGUAGE: json
CODE:
PUT testindex/_doc/1 
{
  "title": "key-value pairs are efficiently stored in a hash table"
}

LANGUAGE: json
CODE:
PUT /testindex/_doc/2
{
  "title": "store key-value pairs in a hash map"
}

----------------------------------------

TITLE: Terms Aggregation on Unsigned Long Field
DESCRIPTION: Demonstrates how to perform terms aggregation on unsigned_long fields.

LANGUAGE: json
CODE:
POST _search
{
  "query": {
    "match_all": {}
  },
  "aggs": {
    "counters": {
      "terms": { 
         "field": "counter" 
      }
    }
  }
}

----------------------------------------

TITLE: Analyzing Text with Custom Analyzer
DESCRIPTION: Analyzes the string 'Slower turtle' using the custom analyzer to demonstrate token generation.

LANGUAGE: json
CODE:
GET /example-index/_analyze
{
  "analyzer": "custom_analyzer",
  "text": "Slower turtle"
}

----------------------------------------

TITLE: Sample Response for Successful Alias Operation in OpenSearch
DESCRIPTION: This snippet shows the expected response from OpenSearch after successfully executing alias operations. The 'acknowledged' field indicates whether the operation was successful.

LANGUAGE: json
CODE:
{
    "acknowledged": true
}

----------------------------------------

TITLE: Enabling Performance Analyzer Plugin
DESCRIPTION: cURL command to enable the Performance Analyzer plugin via the OpenSearch API.

LANGUAGE: bash
CODE:
curl -XPOST localhost:9200/_plugins/_performanceanalyzer/cluster/config -H 'Content-Type: application/json' -d '{"enabled": true}'

----------------------------------------

TITLE: Example Request for Cleanup Snapshot Repository API
DESCRIPTION: An example request to remove all stale data from the repository named 'my_backup' using the Cleanup Snapshot Repository API.

LANGUAGE: json
CODE:
POST /_snapshot/my_backup/_cleanup

----------------------------------------

TITLE: Retrieving Security Detector
DESCRIPTION: Gets detector details using its ID.

LANGUAGE: json
CODE:
GET /_plugins/_security_analytics/detectors/x-dwFIYBT6_n8WeuQjo4

----------------------------------------

TITLE: Creating Index with Word Delimiter Filter Configuration
DESCRIPTION: Example of creating a new index with a custom analyzer using the word_delimiter filter. The configuration demonstrates setting up basic splitting rules for case changes, numerics, and English possessives.

LANGUAGE: json
CODE:
PUT /my-custom-index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "custom_analyzer": {
          "tokenizer": "keyword",
          "filter": [ "custom_word_delimiter_filter" ]
        }
      },
      "filter": {
        "custom_word_delimiter_filter": {
          "type": "word_delimiter",
          "split_on_case_change": true,
          "split_on_numerics": true,
          "stem_english_possessive": true
        }
      }
    }
  }
}

----------------------------------------

TITLE: Paginating Hybrid Query Results in OpenSearch
DESCRIPTION: This snippet shows how to paginate through hybrid query results by adjusting the from parameter while keeping the pagination_depth constant. It retrieves the next set of results after the first five entries.

LANGUAGE: json
CODE:
GET /my-nlp-index/_search?search_pipeline=nlp-search-pipeline
{
  "size":5,      
  "from":6,      
  "query": {
    "hybrid": {
      "pagination_depth":10,  
      "queries": [
        {
          "term": {
            "category": "permission"
          }
        },
        {
          "bool": {
            "should": [
              {
                "term": {
                  "category": "editor"
                }
              },
              {
                "term": {
                  "category": "statement"
                }
              }
            ]
          }
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Creating User with IT Backend Role in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a user named 'judy' with an IT backend role using the OpenSearch Security API.

LANGUAGE: json
CODE:
PUT _plugins/_security/api/internalusers/judy
{
  "password": "judy",
  "backend_roles": [
    "IT"
  ],
  "attributes": {}
}

----------------------------------------

TITLE: Text to Visualization API Request
DESCRIPTION: Example JSON request format for the text-to-visualization API endpoint.

LANGUAGE: json
CODE:
POST /api/assistant/text2vega
{
  "input_instruction": "<input_instruction>",
  "input_question": "<input_question>",
  "ppl": "<ppl_query>",
  "dataSchema": "<data_schema_of_ppl_response>",
  "sampleData": "<sample_data_of_ppl_response>"
}

----------------------------------------

TITLE: Searching Custom Log Types in OpenSearch Security Analytics
DESCRIPTION: This API request searches for log types in the system. It uses a POST request to the /_plugins/_security_analytics/logtype/_search endpoint with a match_all query.

LANGUAGE: json
CODE:
POST /_plugins/_security_analytics/logtype/_search
{
    "query": {
        "match_all": {}
    }
}

----------------------------------------

TITLE: Executing Impersonation Request with cURL
DESCRIPTION: Example cURL command demonstrating how to make an authenticated request with user impersonation using the opendistro_security_impersonate_as header.

LANGUAGE: bash
CODE:
curl -XGET -u 'admin:<custom-admin-password>' -k -H "opendistro_security_impersonate_as: user_1" https://localhost:9200/_plugins/_security/authinfo?pretty

----------------------------------------

TITLE: Creating a pipeline with specific properties in OpenSearch
DESCRIPTION: JSON command to create an attachment pipeline that extracts only specific properties from attachments.

LANGUAGE: json
CODE:
PUT _ingest/pipeline/attachment
{
  "description" : "Extract attachment information",
  "processors" : [
    {
      "attachment" : {
        "field" : "data",
        "properties": ["content", "title", "author"]
      }
    }
  ]
}

----------------------------------------

TITLE: Creating an OpenAI Connector in OpenSearch
DESCRIPTION: JSON request to create a connector for OpenAI's GPT-3.5-turbo model.

LANGUAGE: json
CODE:
POST /_plugins/_ml/connectors/_create
{
    "name": "OpenAI Chat Connector",
    "description": "The connector to public OpenAI model service for GPT 3.5",
    "version": 1,
    "protocol": "http",
    "parameters": {
        "endpoint": "api.openai.com",
        "model": "gpt-3.5-turbo"
    },
    "credential": {
        "openAI_key": "..."
    },
    "actions": [
        {
            "action_type": "predict",
            "method": "POST",
            "url": "https://${parameters.endpoint}/v1/chat/completions",
            "headers": {
                "Authorization": "Bearer ${credential.openAI_key}"
            },
            "request_body": "{ \"model\": \"${parameters.model}\", \"messages\": ${parameters.messages} }"
        }
    ]
}

----------------------------------------

TITLE: Update Tenant Configuration Response
DESCRIPTION: Example response showing the updated multi-tenancy configuration settings after a successful PUT request.

LANGUAGE: json
CODE:
{
    "mulitenancy_enabled": true,
    "private_tenant_enabled": false,
    "default_tenant": "custom tenant 1"
}

----------------------------------------

TITLE: Creating Vector Index with Byte Vector Support
DESCRIPTION: Creates an OpenSearch index configured for byte-quantized vectors with HNSW algorithm settings and pipeline integration.

LANGUAGE: json
CODE:
PUT my_test_data
{
  "settings": {
    "index": {
      "knn": true,
      "knn.algo_param.ef_search": 100,
      "default_pipeline": "pipeline-cohere"
    }
  },
  "mappings": {
    "properties": {
      "passage_text": {
        "type": "text"
      },
      "passage_embedding": {
        "type": "knn_vector",
        "dimension": 1024,
        "data_type": "byte",
        "method": {
          "name": "hnsw",
          "space_type": "l2",
          "engine": "lucene",
          "parameters": {
            "ef_construction": 128,
            "m": 24
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Basic Match Boolean Prefix Query
DESCRIPTION: Simple example of a match_bool_prefix query searching for terms in a title field.

LANGUAGE: json
CODE:
GET _search
{
  "query": {
    "match_bool_prefix": {
      "title": "the wind"
    }
  }
}

----------------------------------------

TITLE: Field Capabilities API Query with Alias
DESCRIPTION: Example demonstrating how to query field capabilities using an alias field name

LANGUAGE: json
CODE:
GET movies/_field_caps?fields=release_date

----------------------------------------

TITLE: Sample Delete Request for a Dangling Index in OpenSearch
DESCRIPTION: This is an example of how to delete a dangling index using a DELETE request. It includes the index UUID in the path and sets the accept_data_loss parameter to true.

LANGUAGE: bash
CODE:
DELETE /_dangling/msdjernajxAT23RT-BupMB?accept_data_loss=true

----------------------------------------

TITLE: Downloading OpenSearch Distribution with Benchmark CLI
DESCRIPTION: This snippet demonstrates how to use the 'download' command to fetch a specific version of OpenSearch. It shows the command syntax and the expected output format.

LANGUAGE: bash
CODE:
opensearch-benchmark download --distribution-version=2.7.0

LANGUAGE: json
CODE:
{
  "opensearch": "/Users/.benchmark/benchmarks/distributions/opensearch-2.7.0.tar.gz" 
}

----------------------------------------

TITLE: Example Response from Cleanup Snapshot Repository API
DESCRIPTION: An example response from the Cleanup Snapshot Repository API, showing the number of bytes and blobs deleted during the cleanup operation.

LANGUAGE: json
CODE:
{
	"results":{
		"deleted_bytes":40,
		"deleted_blobs":8
	}
}

----------------------------------------

TITLE: Multi-search Template API Endpoints
DESCRIPTION: Available HTTP endpoints for the Multi-search Template API supporting both GET and POST methods with optional index specification.

LANGUAGE: json
CODE:
GET /_msearch/template
POST /_msearch/template
GET /{index}/_msearch/template
POST /{index}/_msearch/template

----------------------------------------

TITLE: Executing Has Parent Query in OpenSearch
DESCRIPTION: This snippet shows how to use the Has Parent query to find child documents (products) whose parent documents (brands) match a specific criterion.

LANGUAGE: json
CODE:
GET testindex1/_search
{
  "query" : {
    "has_parent": {
      "parent_type":"brand",
      "query": {
        "match" : {
          "name": "economy"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating an ingest pipeline with sparse encoding
DESCRIPTION: Creates an ingest pipeline that uses a sparse encoding processor to generate embeddings from text fields.

LANGUAGE: json
CODE:
PUT /_ingest/pipeline/nlp-ingest-pipeline-sparse
{
  "description": "An sparse encoding ingest pipeline",
  "processors": [
    {
      "sparse_encoding": {
        "model_id": "<model ID>",
        "prune_type": "max_ratio",
        "prune_ratio": 0.1,
        "field_map": {
          "passage_text": "passage_embedding"
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Retrieving Threat Intelligence Alerts in OpenSearch
DESCRIPTION: This endpoint retrieves alerts related to threat intelligence monitors. It supports various query parameters for filtering and sorting the results.

LANGUAGE: json
CODE:
GET /_plugins/_security_analytics/threat_intel/alerts

----------------------------------------

TITLE: Testing Trim Pipeline
DESCRIPTION: Example of testing the trim pipeline with a sample document containing whitespace.

LANGUAGE: json
CODE:
POST _ingest/pipeline/trim_pipeline/_simulate
{
  "docs": [
    {
      "_source": {
        "raw_text": "   Hello, world!   "
      }
    }
  ]
}

----------------------------------------

TITLE: Generating CSV Report with OpenSearch CLI
DESCRIPTION: Command to generate a CSV report containing table content using basic authentication and Amazon SES for email delivery. Requires admin credentials and email addresses for sender and recipient.

LANGUAGE: bash
CODE:
opensearch-reporting-cli -u https://localhost:5601/app/dashboards#/view/7adfa750-4c81-11e8-b3d7-01146121b73d -f csv -a basic -c admin:Test@1234 -e ses -s <email address> -r <email address>

----------------------------------------

TITLE: Configuring Flatten Processor to Remove Processed Fields in YAML
DESCRIPTION: This example demonstrates how to configure the flatten processor to remove all processed fields from the source when flattening nested objects.

LANGUAGE: yaml
CODE:
processor:
  - flatten:
      source: ""   # empty string represents root of event
      target: ""   # empty string represents root of event
      remove_processed_fields: true

----------------------------------------

TITLE: Creating and populating an OpenSearch index
DESCRIPTION: Commands to create an index, add data using the Bulk API, and verify the data was indexed correctly.

LANGUAGE: bash
CODE:
curl -H "Content-Type: application/json" \
   -X PUT "https://localhost:9201/ecommerce?pretty" \
   --data-binary "@ecommerce-field_mappings.json" \
   -ku admin:<custom-admin-password>

LANGUAGE: bash
CODE:
curl -H "Content-Type: application/x-ndjson" \
   -X PUT "https://localhost:9201/ecommerce/_bulk?pretty" \
   --data-binary "@ecommerce.ndjson" \
   -ku admin:<custom-admin-password>

LANGUAGE: bash
CODE:
curl -H 'Content-Type: application/json' \
   -X GET "https://localhost:9201/ecommerce/_search?pretty=true&filter_path=hits.total" \
   -d'{"query":{"match":{"customer_first_name":"Sonya"}}}' \
   -ku admin:<custom-admin-password>

----------------------------------------

TITLE: Train and Predict Response Format
DESCRIPTION: Example response showing the prediction results with cluster assignments for each input data point. The response includes the status and cluster IDs for all input rows.

LANGUAGE: json
CODE:
{
  "status" : "COMPLETED",
  "prediction_result" : {
    "column_metas" : [
      {
        "name" : "ClusterID",
        "column_type" : "INTEGER"
      }
    ],
    "rows" : [
      {
        "values" : [
          {
            "column_type" : "INTEGER",
            "value" : 1
          }
        ]
      },
      {
        "values" : [
          {
            "column_type" : "INTEGER",
            "value" : 1
          }
        ]
      },
      {
        "values" : [
          {
            "column_type" : "INTEGER",
            "value" : 1
          }
        ]
      },
      {
        "values" : [
          {
            "column_type" : "INTEGER",
            "value" : 0
          }
        ]
      },
      {
        "values" : [
          {
            "column_type" : "INTEGER",
            "value" : 0
          }
        ]
      },
      {
        "values" : [
          {
            "column_type" : "INTEGER",
            "value" : 0
          }
        ]
      }
    ]
  }
}

----------------------------------------

TITLE: Markdown Front Matter Configuration
DESCRIPTION: YAML front matter configuration for the documentation page, specifying layout, title, navigation order, and redirect settings.

LANGUAGE: yaml
CODE:
---
layout: default
title: Setting up Security Analytics
nav_order: 10
has_children: true
has_toc: false
redirect_from:
  - /security-analytics/sec-analytics-config/
---

----------------------------------------

TITLE: Calculating SHA256 Checksum for Model File in UNIX
DESCRIPTION: Command to generate a SHA256 checksum for a model zip file, which is required for model registration.

LANGUAGE: bash
CODE:
shasum -a 256 sentence-transformers_paraphrase-mpnet-base-v2-1.0.0-onnx.zip

----------------------------------------

TITLE: Customer Document Indexing
DESCRIPTION: Series of requests to index sample customer documents with name and address information.

LANGUAGE: json
CODE:
PUT /customers/_doc/1
{
  "first_name":"Amber",
  "last_name":"Duke",
  "address":"880 Holmes Lane"
}

LANGUAGE: json
CODE:
PUT /customers/_doc/2
{
  "first_name":"Hattie",
  "last_name":"Bond",
  "address":"671 Bristol Street"
}

LANGUAGE: json
CODE:
PUT /customers/_doc/3
{
  "first_name":"Nanette",
  "last_name":"Bates",
  "address":"789 Madison St"
}

LANGUAGE: json
CODE:
PUT /customers/_doc/4
{
  "first_name":"Dale",
  "last_name":"Amber",
  "address":"467 Hutchinson Court"
}

----------------------------------------

TITLE: OpenSearch Admin Security Credentials
DESCRIPTION: Example showing how to specify admin security credentials for an OpenSearch cluster

LANGUAGE: yaml
CODE:
sink:
  - opensearch:
      username: "admin"
      password: "admin"
      ...

----------------------------------------

TITLE: Analyzing Text with Custom Stemmer
DESCRIPTION: Request to analyze text using the custom analyzer with stemmer_override filter, demonstrating how the custom stemming rules are applied to the input text.

LANGUAGE: json
CODE:
GET /my-index/_analyze
{
  "analyzer": "my_custom_analyzer",
  "text": "I am a runner and bought the best shoes"
}

----------------------------------------

TITLE: Flushing a Specific Index in OpenSearch
DESCRIPTION: An example request to flush a specific index named 'shakespeare' using the Flush API in OpenSearch.

LANGUAGE: json
CODE:
POST /shakespeare/_flush

----------------------------------------

TITLE: Indexing blog documents with dates
DESCRIPTION: Indexes multiple blog documents into the 'blogs' index with different 'date_posted' values.

LANGUAGE: json
CODE:
PUT blogs/_doc/1
{
  "name": "Semantic search in OpenSearch",
  "date_posted": "2022-04-17"
}

LANGUAGE: json
CODE:
PUT blogs/_doc/2
{
  "name": "Sparse search in OpenSearch",
  "date_posted": "2022-05-02"
}

LANGUAGE: json
CODE:
PUT blogs/_doc/3
{
  "name": "Distributed tracing with Data Prepper",
  "date_posted": "2022-04-25"
}

LANGUAGE: json
CODE:
PUT blogs/_doc/4
{
  "name": "Observability in OpenSearch",
  "date_posted": "2023-03-23"
}

----------------------------------------

TITLE: Multi-level Nested Query
DESCRIPTION: Example of performing a multi-level nested query to search nested fields within nested fields.

LANGUAGE: json
CODE:
GET /patients/_search
{
  "query": {
    "nested": {
      "path": "patient",
      "query": {
        "nested": {
          "path": "patient.contacts",
          "query": {
            "bool": {
              "must": [
                { "match": { "patient.contacts.relationship": "mother" } },
                { "match": { "patient.contacts.name": "Jane" } }
              ]
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Excluding Cluster Manager Node Statistics in OpenSearch
DESCRIPTION: Demonstrates how to retrieve statistics from all nodes except the cluster manager node using sequential resolution mechanisms.

LANGUAGE: json
CODE:
GET /_nodes/_all,cluster_manager:false/stats

----------------------------------------

TITLE: Example Response for Secure Settings Reload
DESCRIPTION: Sample response showing the result of a successful secure settings reload operation, including node status and cluster information.

LANGUAGE: json
CODE:
{
  "_nodes" : {
    "total" : 1,
    "successful" : 1,
    "failed" : 0
  },
  "cluster_name" : "opensearch-cluster",
  "nodes" : {
    "t7uqHu4SSuWObK3ElkCRfw" : {
      "name" : "opensearch-node1"
    }
  }
}

----------------------------------------

TITLE: Memory Estimation Calculations
DESCRIPTION: Demonstrates memory requirement calculations for different quantization levels using the HNSW graph.

LANGUAGE: r
CODE:
Memory = 1.1 * ((256 * 1 / 8) + 8 * 16) * 1,000,000
       ~= 0.176 GB

----------------------------------------

TITLE: Deleting Custom Security Rule in OpenSearch
DESCRIPTION: API endpoint for deleting a custom security rule. Takes rule ID parameter and can be forced with forced=true if rule is in use.

LANGUAGE: json
CODE:
DELETE /_plugins/_security_analytics/rules/ZaFv1IMBdLpXWBiBa1XI?forced=true

----------------------------------------

TITLE: Opening Crontab Editor in Bash
DESCRIPTION: This command opens the crontab editor, allowing users to add, modify, or delete cron jobs for scheduling tasks.

LANGUAGE: bash
CODE:
crontab -e

----------------------------------------

TITLE: Conditional Expression Examples in OpenSearch Data Prepper
DESCRIPTION: Examples of using conditional operators (and, or, not) to create complex evaluation criteria.

LANGUAGE: markdown
CODE:
/status_code == 200 and /message == "Hello world"
/status_code == 200 or /status_code == 202
not /status_code in {200, 202}
/response == null
/response != null

----------------------------------------

TITLE: Configuring Live Capture Migration with C&R in AWS CDK
DESCRIPTION: JSON configuration for performing a live capture migration with Capture and Replay (C&R) using AWS CDK. Includes source and target cluster configurations, VPC settings, and C&R-specific options for Capture Proxy and Traffic Replayer services.

LANGUAGE: json
CODE:
{
  "live-capture-migration": {
    "stage": "dev",
    "vpcId": <VPC_ID>,
    "sourceCluster": {
        "endpoint": <SOURCE_CLUSTER_ENDPOINT>,
        "version": "ES 7.10",
        "auth": {"type": "none"}
    },
    "targetCluster": {
        "endpoint": <TARGET_CLUSTER_ENDPOINT>,
        "auth": {
            "type": "basic",
            "username": <TARGET_CLUSTER_USERNAME>,
            "passwordFromSecretArn": <TARGET_CLUSTER_PASSWORD_SECRET>
        }
    },
    "captureProxyServiceEnabled": true,
    "captureProxyExtraArgs": "",
    "trafficReplayerServiceEnabled": true,
    "trafficReplayerExtraArgs": "",
    "artifactBucketRemovalPolicy": "DESTROY"
  }
}

----------------------------------------

TITLE: Train and Predict with K-means Using Indexed Data
DESCRIPTION: Example request showing how to train a k-means model and predict using indexed data. Uses COSINE distance with 2 centroids and 10 iterations.

LANGUAGE: json
CODE:
POST /_plugins/_ml/_train_predict/kmeans
{
    "parameters": {
        "centroids": 2,
        "iterations": 10,
        "distance_type": "COSINE"
    },
    "input_query": {
        "query": {
            "bool": {
                "filter": [
                    {
                        "range": {
                            "k1": {
                                "gte": 0
                            }
                        }
                    }
                ]
            }
        },
        "size": 10
    },
    "input_index": [
        "test_data"
    ]
}

----------------------------------------

TITLE: Clearing Remote Store Compatibility Settings in OpenSearch
DESCRIPTION: Clears the remote store compatibility mode and migration direction settings after migration.

LANGUAGE: json
CODE:
PUT "/_cluster/settings?pretty"
{
    "persistent": {
        "cluster.remote_store.compatibility_mode": null,
         "cluster.migration.direction" :  null
    }
}

----------------------------------------

TITLE: Using ORDER BY Clause in OpenSearch SQL
DESCRIPTION: Example of using the ORDER BY clause to sort results in descending order based on the 'account_number' field in OpenSearch SQL.

LANGUAGE: sql
CODE:
SELECT account_number
FROM accounts
ORDER BY account_number DESC

----------------------------------------

TITLE: Response for Missing Fields Query
DESCRIPTION: Sample response showing a document that lacks the description field.

LANGUAGE: json
CODE:
{
  "took": 19,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 1,
      "relation": "eq"
    },
    "max_score": 0,
    "hits": [
      {
        "_index": "testindex",
        "_id": "1",
        "_score": 0,
        "_source": {
          "title": "The wind rises"
        }
      }
    ]
  }
}

----------------------------------------

TITLE: Configuring AWS Lambda Sink in YAML
DESCRIPTION: Example configuration for setting up an AWS Lambda sink with custom parameters including function name, invocation type, AWS region, role ARN, batch settings, and DLQ configuration.

LANGUAGE: yaml
CODE:
sink:
  - aws_lambda:
      function_name: "my-lambda-sink"
      invocation_type: "event"
      aws:
        region: "us-west-2"
        sts_role_arn: "arn:aws:iam::123456789012:role/my-lambda-sink-role"
      max_retries: 5
      batch:
        key_name: "events"
        threshold:
          event_count: 50
          maximum_size: "3mb"
          event_collect_timeout: PT5S
      lambda_when: "event['type'] == 'log'"
      dlq:
        region: "us-east-1"
        sts_role_arn: "arn:aws:iam::123456789012:role/my-sqs-role"
        bucket: "<<your-dlq-bucket-name>>"

----------------------------------------

TITLE: Updating a Document in OpenSearch
DESCRIPTION: JavaScript code for updating a document in OpenSearch using the client's update method.

LANGUAGE: javascript
CODE:
var response = await client.update({
  index: index_name,
  id: id,
  body: {
    doc: {
      genre: "Detective fiction",
      tv_adapted: true
    }
  },
  refresh: true
});

----------------------------------------

TITLE: Querying eCommerce Data with Adjacency Matrix Aggregation in OpenSearch
DESCRIPTION: This query uses the adjacency_matrix aggregation to analyze relationships between different manufacturing companies in the OpenSearch Dashboards sample eCommerce dataset. It defines three filter expressions for different manufacturers and returns a matrix of intersecting filters.

LANGUAGE: json
CODE:
{
  "size": 0,
  "aggs": {
    "interactions": {
      "adjacency_matrix": {
        "filters": {
          "grpA": {
            "match": {
              "manufacturer.keyword": "Low Tide Media"
            }
          },
          "grpB": {
            "match": {
              "manufacturer.keyword": "Elitelligence"
            }
          },
          "grpC": {
            "match": {
              "manufacturer.keyword": "Oceanavigations"
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Indexing Point and Polygon Documents in OpenSearch
DESCRIPTION: Examples of indexing documents containing xy point and polygon shapes.

LANGUAGE: json
CODE:
PUT testindex/_doc/1
{
  "geometry": { 
    "type": "point",
    "coordinates": [0.5, 3.0]
  }
}

LANGUAGE: json
CODE:
PUT testindex/_doc/2
{
  "geometry" : {
    "type" : "polygon",
    "coordinates" : [
      [[2.5, 6.0],
      [0.5, 4.5], 
      [1.5, 2.0], 
      [3.5, 3.5],
      [2.5, 6.0]]
    ]
  }
}

----------------------------------------

TITLE: Querying CAT Shards Endpoints - JSON
DESCRIPTION: Basic endpoint definitions for the CAT shards API showing the available HTTP GET requests.

LANGUAGE: json
CODE:
GET /_cat/shards
GET /_cat/shards/{index}

----------------------------------------

TITLE: Internal Users Configuration in OpenSearch
DESCRIPTION: YAML configuration for adding a test user with specific roles and permissions in OpenSearch.

LANGUAGE: yaml
CODE:
test-user:
  hash: "$2y$12$CkxFoTAJKsZaWv/m8VoZ6ePG3DBeBTAvoo4xA2P21VCS9w2RYumsG"
  backend_roles:
  - "test-backend-role"
  - "kibanauser"
  description: "test user user"

----------------------------------------

TITLE: Named Route Role Permission with Multiple Routes in YAML
DESCRIPTION: Example showing how to configure a role with multiple named route permissions for different operations.

LANGUAGE: yaml
CODE:
abcplugin_read_access_nr:
   reserved: true
   cluster_permissions:
     - 'abcplugin:routeGet'
     - 'abcplugin:routePut'
     - 'abcplugin:routeDelete'

----------------------------------------

TITLE: Updating Custom Security Rule in OpenSearch
DESCRIPTION: API endpoint for updating an existing custom security rule. Takes rule ID and category parameters. Can be forced with forced=true parameter if rule is in use by detectors.

LANGUAGE: json
CODE:
PUT /_plugins/_security_analytics/rules/ZaFv1IMBdLpXWBiBa1XI?category=windows&forced=true

----------------------------------------

TITLE: Retrieving Document After HTML Strip Processing
DESCRIPTION: Retrieves a document that has been processed by the HTML strip pipeline.

LANGUAGE: json
CODE:
GET products/_doc/1

----------------------------------------

TITLE: Asynchronous Training Response
DESCRIPTION: Example response for an asynchronous training request, returning the task_id and initial status.

LANGUAGE: json
CODE:
{
  "task_id" : "lrlamX8BO5w8y8Ra2otd",
  "status" : "CREATED"
}

----------------------------------------

TITLE: Detailed Query Structure with Field Information in OpenSearch
DESCRIPTION: Shows a more detailed query structure including field names and types for grouping.

LANGUAGE: c
CODE:
bool []
  must:
    term [field1, keyword]
  filter:
    match [field2, text]
    range [field4, long]
  should:
    regexp [field3, text]

----------------------------------------

TITLE: Accessing Migration Console via AWS CLI and Session Manager
DESCRIPTION: This code snippet shows how to directly connect to the migration console using AWS CLI and Session Manager plugin. It sets environment variables, retrieves the task ARN, and uses the execute-command to access the container interactively.

LANGUAGE: shell
CODE:
export STAGE=dev
export SERVICE_NAME=migration-console
export TASK_ARN=$(aws ecs list-tasks --cluster migration-${STAGE}-ecs-cluster --family "migration-${STAGE}-${SERVICE_NAME}" | jq --raw-output '.taskArns[0]')
aws ecs execute-command --cluster "migration-${STAGE}-ecs-cluster" --task "${TASK_ARN}" --container "${SERVICE_NAME}" --interactive --command "/bin/bash"

----------------------------------------

TITLE: Example Response for Memory Message Search in OpenSearch
DESCRIPTION: This snippet shows an example response from the search message API. It includes metadata about the search operation and details of the matched message, including its content and associated information.

LANGUAGE: json
CODE:
{
  "took": 5,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 1,
      "relation": "eq"
    },
    "max_score": 0.47000366,
    "hits": [
      {
        "_index": ".plugins-ml-memory-message",
        "_id": "BW8ha40BfUsSoeNT8-i3",
        "_version": 1,
        "_seq_no": 0,
        "_primary_term": 1,
        "_score": 0.47000366,
        "_source": {
          "input": "How do I make an interaction?",
          "memory_id": "gW8Aa40BfUsSoeNTvOKI",
          "trace_number": null,
          "create_time": "2024-02-02T18:43:23.566994302Z",
          "additional_info": {
            "suggestion": "api.openai.com"
          },
          "response": "Hello, this is OpenAI. Here is the answer to your question.",
          "origin": "MyFirstOpenAIWrapper",
          "parent_message_id": null,
          "prompt_template": "Hello OpenAI, can you answer this question?"
        }
      }
    ]
  }
}

----------------------------------------

TITLE: Configuring Hot-Warm Architecture in YAML
DESCRIPTION: Sets temperature attributes for hot-warm node configuration.

LANGUAGE: yaml
CODE:
node.attr.temp: hot

LANGUAGE: yaml
CODE:
node.attr.temp: warm

----------------------------------------

TITLE: Populating Bakery Items Index
DESCRIPTION: Bulk indexes sample bakery items with different prices and dates using the _bulk API.

LANGUAGE: json
CODE:
POST /bakery-items/_bulk
{ "index": {} }
{ "item": "Chocolate Cake", "category": "cakes", "price": 15, "baked_date": "2023-07-01T00:00:00Z" }
{ "index": {} }
{ "item": "Chocolate Cake", "category": "cakes", "price": 18, "baked_date": "2023-07-04T00:00:00Z" }
{ "index": {} }
{ "item": "Vanilla Cake", "category": "cakes", "price": 12, "baked_date": "2023-07-02T00:00:00Z" }

----------------------------------------

TITLE: Bulk Indexing Documents for Collapse Processing
DESCRIPTION: Creates multiple test documents with color fields to demonstrate collapse functionality.

LANGUAGE: json
CODE:
POST /_bulk
{ "create":{"_index":"my_index","_id":1}}
{ "title" : "document 1", "color":"blue" }
{ "create":{"_index":"my_index","_id":2}}
{ "title" : "document 2", "color":"blue" }
{ "create":{"_index":"my_index","_id":3}}
{ "title" : "document 3", "color":"red" }
{ "create":{"_index":"my_index","_id":4}}
{ "title" : "document 4", "color":"red" }
{ "create":{"_index":"my_index","_id":5}}
{ "title" : "document 5", "color":"yellow" }
{ "create":{"_index":"my_index","_id":6}}
{ "title" : "document 6", "color":"yellow" }
{ "create":{"_index":"my_index","_id":7}}
{ "title" : "document 7", "color":"orange" }
{ "create":{"_index":"my_index","_id":8}}
{ "title" : "document 8", "color":"orange" }
{ "create":{"_index":"my_index","_id":9}}
{ "title" : "document 9", "color":"green" }
{ "create":{"_index":"my_index","_id":10}}
{ "title" : "document 10", "color":"green" }

----------------------------------------

TITLE: Configuring otel_trace_group Processor for Amazon OpenSearch Service in YAML
DESCRIPTION: Example YAML configuration for the otel_trace_group processor when connecting to an Amazon OpenSearch Service domain using AWS SigV4 authentication.

LANGUAGE: yaml
CODE:
pipeline:
  ...
  processor:
    - otel_trace_group:
        hosts: ["https://your-amazon-opensearch-service-endpoint"]
        aws_sigv4: true
        cert: path/to/cert
        insecure: false

----------------------------------------

TITLE: Analyzing Text with Whitespace Tokenizer
DESCRIPTION: Example request to analyze text using the configured whitespace analyzer, demonstrating how the text is split into tokens.

LANGUAGE: json
CODE:
POST /my_index/_analyze
{
  "analyzer": "my_whitespace_analyzer",
  "text": "OpenSearch is fast! Really fast."
}

----------------------------------------

TITLE: Installing OpenSearch Python Client
DESCRIPTION: Use pip to install the opensearch-dsl package, which provides the high-level Python client for OpenSearch.

LANGUAGE: bash
CODE:
pip install opensearch-dsl

----------------------------------------

TITLE: Analyzing Text with Normalizer
DESCRIPTION: Demonstrates how to analyze text using a normalizer to see its effect on the input.

LANGUAGE: json
CODE:
GET /sample-index/_analyze
{
  "normalizer" : "normalized_keyword",
  "text" : "Nave"
}

----------------------------------------

TITLE: Executing Match None Query in OpenSearch
DESCRIPTION: Shows how to use the match_none query which returns no documents. This query is rarely used but can be helpful in specific testing scenarios or as a placeholder.

LANGUAGE: json
CODE:
GET _search
{
  "query": {
    "match_none": {}
  }
}

----------------------------------------

TITLE: Retrieving Information for a Single Thread Pool in OpenSearch
DESCRIPTION: This example demonstrates how to query information for a single specific thread pool by including its name in the request URL.

LANGUAGE: json
CODE:
GET _cat/thread_pool/<thread_pool_name>?v

----------------------------------------

TITLE: Force Merging OpenSearch Index Segments
DESCRIPTION: This code demonstrates how to force merge OpenSearch index segments into a single segment, which is useful for creating vector data structures only once after bulk indexing.

LANGUAGE: json
CODE:
POST test-index/_forcemerge?max_num_segments=1

----------------------------------------

TITLE: Configuring External OpenSearch Endpoints
DESCRIPTION: Example of configuring multiple HTTP endpoints for external OpenSearch audit storage. Shows various formats for specifying cluster endpoints including HTTPS, HTTP, and IP addresses.

LANGUAGE: yaml
CODE:
plugins.security.audit.config.http_endpoints: ['https://my-opensearch-cluster.company.com:9200', 'http://my-opensearch-cluster.company.com:9200', 'my-opensearch-cluster.company.com:9200', '192.168.178.1:9200', '192.168.178.2:9200']

----------------------------------------

TITLE: Get Message by ID Example Request
DESCRIPTION: Example request demonstrating how to retrieve a specific message using its ID.

LANGUAGE: json
CODE:
GET /_plugins/_ml/memory/message/0m8ya40BfUsSoeNTj-pU

----------------------------------------

TITLE: Testing Brazilian Analyzer Token Generation
DESCRIPTION: Shows how to analyze text using the Brazilian analyzer and view the generated tokens.

LANGUAGE: json
CODE:
POST /brazilian-index/_analyze
{
  "field": "content",
  "text": "Estudantes estudam em universidades brasileiras. Seus nmeros so 123456."
}

LANGUAGE: json
CODE:
{
  "tokens": [
    {"token": "estudant","start_offset": 0,"end_offset": 10,"type": "<ALPHANUM>","position": 0},
    {"token": "estud","start_offset": 11,"end_offset": 18,"type": "<ALPHANUM>","position": 1},
    {"token": "univers","start_offset": 22,"end_offset": 35,"type": "<ALPHANUM>","position": 3},
    {"token": "brasileir","start_offset": 36,"end_offset": 47,"type": "<ALPHANUM>","position": 4},
    {"token": "numer","start_offset": 54,"end_offset": 61,"type": "<ALPHANUM>","position": 6},
    {"token": "sao","start_offset": 62,"end_offset": 65,"type": "<ALPHANUM>","position": 7},
    {"token": "123456","start_offset": 66,"end_offset": 72,"type": "<NUM>","position": 8}
  ]
}

----------------------------------------

TITLE: Retrieving Task Information Endpoint
DESCRIPTION: The GET endpoint used to retrieve information about a specific ML task using its task_id.

LANGUAGE: json
CODE:
GET /_plugins/_ml/tasks/<task_id>

----------------------------------------

TITLE: Ingesting Document with Fingerprint Pipeline
DESCRIPTION: Example of ingesting a document using the fingerprint pipeline to generate a hash value.

LANGUAGE: json
CODE:
{
  "foo": "foo",
  "bar": "bar"
}

----------------------------------------

TITLE: Validating OpenSearch Backfill with Refresh API
DESCRIPTION: Command to check the backfill status by displaying the number of documents in each index of the target cluster.

LANGUAGE: bash
CODE:
console clusters cat-indices --refresh

----------------------------------------

TITLE: Memory Deletion Response Example - JSON
DESCRIPTION: Example response returned after successful memory deletion.

LANGUAGE: json
CODE:
{
  "success": true
}

----------------------------------------

TITLE: Starting Index Replication Request
DESCRIPTION: API endpoint to initiate replication of an index from leader to follower cluster. Requires leader alias, index name, and optional security roles.

LANGUAGE: json
CODE:
{
   "leader_alias":"<connection-alias-name>",
   "leader_index":"<index-name>",
   "use_roles":{
      "leader_cluster_role":"<role-name>",
      "follower_cluster_role":"<role-name>"
   }
}

----------------------------------------

TITLE: Requesting Email Report with SES Transport
DESCRIPTION: Command to request an email with report attachment using Amazon SES transport

LANGUAGE: bash
CODE:
opensearch-reporting-cli --url https://localhost:5601/app/dashboards#/view/7adfa750-4c81-11e8-b3d7-01146121b73d --transport ses --from <sender_email_id> --to <recipient_email_id>

----------------------------------------

TITLE: Creating Search Pipeline with Sort Processor
DESCRIPTION: Defines a search pipeline that includes a sort processor to sort the message field and store results in a new field.

LANGUAGE: json
CODE:
PUT /_search/pipeline/my_pipeline
{
  "response_processors": [
    {
      "sort": {
        "field": "message",
        "target_field": "sorted_message"
      }
    }
  ]
}

----------------------------------------

TITLE: Configuring Static Discovery Mode in YAML
DESCRIPTION: Example YAML configuration for setting up static discovery mode in peer forwarder.

LANGUAGE: yaml
CODE:
peer_forwarder:
  discovery_mode: static
  static_endpoints: ["data-prepper1", "data-prepper2"]

----------------------------------------

TITLE: Docker Run Command Example
DESCRIPTION: Example command showing how to run OpenSearch in Docker with specific configuration options.

LANGUAGE: bash
CODE:
docker run -d -p 9200:9200 -p 9600:9600 -e "discovery.type=single-node" opensearchproject/opensearch:latest

----------------------------------------

TITLE: Analyzing Text with Path Hierarchy Tokenizer
DESCRIPTION: Demonstrates how to analyze a file path using the configured path hierarchy analyzer.

LANGUAGE: json
CODE:
POST /my_index/_analyze
{
  "analyzer": "my_path_analyzer",
  "text": "/users/john/documents/report.txt"
}

----------------------------------------

TITLE: Basic Fuzzy Query in OpenSearch
DESCRIPTION: Simple example of a fuzzy query searching for the term 'HALET' (misspelled 'HAMLET') using default AUTO edit distance.

LANGUAGE: json
CODE:
GET shakespeare/_search
{
  "query": {
    "fuzzy": {
      "speaker": {
        "value": "HALET"
      }
    }
  }
}

----------------------------------------

TITLE: Single Node Verification Response
DESCRIPTION: Example response showing successful verification with one connected node

LANGUAGE: json
CODE:
{
  "nodes" : {
    "by1kztwTRoeCyg4iGU5Y8A" : {
      "name" : "opensearch-node1"
    }
  }
}

----------------------------------------

TITLE: Creating Index with copy_to Mapping
DESCRIPTION: Creates a product index with copy_to parameter that copies name and description fields into a product_info field. Includes example documents for wireless headphones and bluetooth speaker.

LANGUAGE: json
CODE:
PUT my-products-index
{
  "mappings": {
    "properties": {
      "name": {
        "type": "text",
        "copy_to": "product_info"
      },
      "description": {
        "type": "text",
        "copy_to": "product_info" 
      },
      "product_info": {
        "type": "text"
      },
      "price": {
        "type": "float"
      }
    }
  }
}

PUT my-products-index/_doc/1
{
  "name": "Wireless Headphones",
  "description": "High-quality wireless headphones with noise cancellation",
  "price": 99.99
}

PUT my-products-index/_doc/2
{
  "name": "Bluetooth Speaker",
  "description": "Portable Bluetooth speaker with long battery life",
  "price": 49.99
}

----------------------------------------

TITLE: Authenticating with Admin Certificate to Access Security Index in OpenSearch
DESCRIPTION: This command demonstrates how to use curl with an admin certificate to access the .opendistro_security system index in OpenSearch. It requires the kirk.pem certificate and kirk-key.pem key file for authentication.

LANGUAGE: bash
CODE:
curl -k --cert ./kirk.pem --key ./kirk-key.pem -XGET 'https://localhost:9200/.opendistro_security/_search'

----------------------------------------

TITLE: Search Connector Request
DESCRIPTION: Example request body for searching connectors, using match_all query to retrieve all connectors with a size limit of 1000.

LANGUAGE: json
CODE:
{
  "query": {
    "match_all": {}
  },
  "size": 1000
}

----------------------------------------

TITLE: Analyzing Text with Irish Analyzer
DESCRIPTION: Example of analyzing Irish text and viewing the generated tokens.

LANGUAGE: json
CODE:
POST /irish-index/_analyze
{
  "field": "content",
  "text": "T mic linn ag staidar in ollscoileanna na hireann. Is iad a gcuid uimhreacha n 123456."
}

LANGUAGE: json
CODE:
{
  "tokens": [
    {"token": "t","start_offset": 0,"end_offset": 2,"type": "<ALPHANUM>","position": 0},
    {"token": "mic","start_offset": 3,"end_offset": 6,"type": "<ALPHANUM>","position": 1},
    {"token": "linn","start_offset": 7,"end_offset": 12,"type": "<ALPHANUM>","position": 2},
    {"token": "staidar","start_offset": 16,"end_offset": 24,"type": "<ALPHANUM>","position": 4},
    {"token": "ollscoileanna","start_offset": 28,"end_offset": 41,"type": "<ALPHANUM>","position": 6},
    {"token": "hireann","start_offset": 45,"end_offset": 53,"type": "<ALPHANUM>","position": 8},
    {"token": "cuid","start_offset": 64,"end_offset": 69,"type": "<ALPHANUM>","position": 12},
    {"token": "uimhreacha","start_offset": 70,"end_offset": 80,"type": "<ALPHANUM>","position": 13},
    {"token": "123456","start_offset": 84,"end_offset": 90,"type": "<NUM>","position": 15}
  ]
}

----------------------------------------

TITLE: Search Model Groups API Endpoints
DESCRIPTION: The base endpoints for searching model groups, supporting both POST and GET methods.

LANGUAGE: json
CODE:
POST /_plugins/_ml/model_groups/_search
GET /_plugins/_ml/model_groups/_search

----------------------------------------

TITLE: Segment Replication Response Format - JSON
DESCRIPTION: Example response showing segment replication metrics including shard ID, node information, checkpoint status, and lag measurements.

LANGUAGE: json
CODE:
shardId       target_node    target_host   checkpoints_behind bytes_behind   current_lag   last_completed_lag   rejected_requests
[index-1][0]     runTask-1    127.0.0.1              0              0b           0s              7ms                    0

----------------------------------------

TITLE: Configuring Bedrock Claude Connector with Guardrails
DESCRIPTION: Creates a connector for the Anthropic Claude model on Amazon Bedrock with authentication and request parameters

LANGUAGE: json
CODE:
{
  "name": "BedRock test claude Connector",
  "description": "The connector to BedRock service for claude model",
  "version": 1,
  "protocol": "aws_sigv4",
  "parameters": {
      "region": "us-east-1",
      "service_name": "bedrock",
      "anthropic_version": "bedrock-2023-05-31",
      "endpoint": "bedrock.us-east-1.amazonaws.com",
      "auth": "Sig_V4",
      "content_type": "application/json",
      "max_tokens_to_sample": 8000,
      "temperature": 0.0001,
      "response_filter": "$.completion"
  },
  "credential": {
      "access_key": "<YOUR_ACCESS_KEY>",
      "secret_key": "<YOUR_SECRET_KEY>"
  },
  "actions": [
    {
      "action_type": "predict",
      "method": "POST",
      "url": "https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-v2/invoke",
      "headers": { 
        "content-type": "application/json",
        "x-amz-content-sha256": "required"
      },
      "request_body": "{\"prompt\":\"${parameters.prompt}\", \"max_tokens_to_sample\":${parameters.max_tokens_to_sample}, \"temperature\":${parameters.temperature},  \"anthropic_version\":\"${parameters.anthropic_version}\" }"
    }
  ]
}

----------------------------------------

TITLE: Updating Connector Endpoint in OpenSearch ML Commons
DESCRIPTION: The HTTP PUT endpoint for updating a connector in OpenSearch ML Commons. The connector_id is a required parameter in the URL path.

LANGUAGE: json
CODE:
PUT /_plugins/_ml/connectors/<connector_id>

----------------------------------------

TITLE: Setting IAM Role Permissions for Amazon Bedrock Access
DESCRIPTION: JSON policy that grants permissions to invoke the DeepSeek-R1 model on Amazon Bedrock.

LANGUAGE: json
CODE:
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Action": [
                "bedrock:InvokeModel"
            ],
            "Effect": "Allow",
            "Resource": "your_DeepSeek_R1_model_ARN"
        }
    ]
}

----------------------------------------

TITLE: Querying Root Cause Analysis Data
DESCRIPTION: API queries to retrieve RCA data from Performance Analyzer.

LANGUAGE: bash
CODE:
GET localhost:9600/_plugins/_performanceanalyzer/rca

LANGUAGE: bash
CODE:
GET localhost:9600/_plugins/_performanceanalyzer/rca?name=HighHeapUsageClusterRCA

----------------------------------------

TITLE: Configuring External OpenSearch Audit Storage
DESCRIPTION: Configuration for external OpenSearch audit storage including HTTP endpoints, index name, and document type settings. This allows audit logs to be stored in a separate OpenSearch cluster.

LANGUAGE: yaml
CODE:
plugins.security.audit.type: external_opensearch
plugins.security.audit.config.http_endpoints: [<endpoints>]
plugins.security.audit.config.index: <indexname>
plugins.security.audit.config.type: _doc

----------------------------------------

TITLE: Configuring OpenSearch Data Prepper Pipeline with SSL and Authentication
DESCRIPTION: Example configuration for a log pipeline with SSL and basic authentication enabled for the HTTP source. Includes Grok processor for Apache log parsing and OpenSearch sink configuration with security options.

LANGUAGE: yaml
CODE:
log-pipeline:
  source:
    http:
      ssl_certificate_file: "/full/path/to/certfile.crt"
      ssl_key_file: "/full/path/to/keyfile.key"
      authentication:
        http_basic:
          username: "myuser"
          password: "mys3cret"
  processor:
    - grok:
        match:
          log: [ "%{COMMONAPACHELOG}" ]
  sink:
    - opensearch:
        hosts: [ "https://localhost:9200" ]
        username: "admin"
        password: "admin"
        index: apache_logs

----------------------------------------

TITLE: Adding Metadata with Add Entries Processor in YAML
DESCRIPTION: This example illustrates how to add metadata to events using the add_entries processor.

LANGUAGE: yaml
CODE:
processor:
  - add_entries:
      entries:
        - metadata_key: "length"
          value_expression: "length(/message)"

----------------------------------------

TITLE: Example Request with Object
DESCRIPTION: Demonstrates a POST request to the endpoint with an example object containing required and optional fields.

LANGUAGE: json
CODE:
POST /_example/endpoint/
{
    "example_object": {
        "required_request_field": "example value",
        "optional_request_field": "example value"
    }
}

----------------------------------------

TITLE: N-gram Analysis Response
DESCRIPTION: Example response showing the tokens generated by the N-gram analyzer for the word 'Search'. Demonstrates how the text is broken down into N-grams of lengths 2 and 3.

LANGUAGE: json
CODE:
{
  "tokens": [
    {
      "token": "se",
      "start_offset": 0,
      "end_offset": 6,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "sea",
      "start_offset": 0,
      "end_offset": 6,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "ea",
      "start_offset": 0,
      "end_offset": 6,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "ear",
      "start_offset": 0,
      "end_offset": 6,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "ar",
      "start_offset": 0,
      "end_offset": 6,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "arc",
      "start_offset": 0,
      "end_offset": 6,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "rc",
      "start_offset": 0,
      "end_offset": 6,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "rch",
      "start_offset": 0,
      "end_offset": 6,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "ch",
      "start_offset": 0,
      "end_offset": 6,
      "type": "<ALPHANUM>",
      "position": 0
    }
  ]
}

----------------------------------------

TITLE: Search With Filter Pipeline
DESCRIPTION: Performs a search using the filter query pipeline to return only public documents.

LANGUAGE: json
CODE:
GET /my_index/_search?search_pipeline=my_pipeline

----------------------------------------

TITLE: Setting Environment Variables for IAM User in Bash
DESCRIPTION: Exports the necessary environment variables for AWS Signature Version 4 authentication using an IAM user. This includes the access key ID, secret access key, region, and service name.

LANGUAGE: bash
CODE:
export OSB_AWS_ACCESS_KEY_ID=<IAM USER AWS ACCESS KEY ID>
export OSB_AWS_SECRET_ACCESS_KEY=<IAM USER AWS SECRET ACCESS KEY>
export OSB_REGION=<YOUR REGION>
export OSB_SERVICE=es

----------------------------------------

TITLE: Creating Index with Basic Space Type Configuration in OpenSearch
DESCRIPTION: Example of creating an OpenSearch index with a k-NN vector field using basic space type configuration. Demonstrates how to set up a vector field with dimension and space type parameters.

LANGUAGE: json
CODE:
{
  "settings": {
    "index": {
      "knn": true
    }
  },
  "mappings": {
    "properties": {
      "my_vector1": {
        "type": "knn_vector",
        "dimension": 3,
        "space_type": "l2"
      }
    }
  }
}

----------------------------------------

TITLE: Evaluating Query Results in Groovy
DESCRIPTION: This Groovy script evaluates to true if the query returned any documents.

LANGUAGE: groovy
CODE:
ctx.results[0].hits.total.value > 0

----------------------------------------

TITLE: Enabling Backend Role Filtering for Index Management in OpenSearch
DESCRIPTION: This JSON snippet demonstrates how to use the REST API to enable filtering of index management policies and actions by backend roles. It sets the 'plugins.index_management.filter_by_backend_roles' setting to 'true' in the cluster settings.

LANGUAGE: json
CODE:
PUT _cluster/settings
{
  "transient": {
    "plugins.index_management.filter_by_backend_roles": "true"
  }
}

----------------------------------------

TITLE: Analyzing Text with Phonetic Analyzer in OpenSearch
DESCRIPTION: JSON requests to analyze the names 'Stephen' and 'Steven' using the previously created phonetic analyzer. Both names are expected to generate the same phonetic token.

LANGUAGE: json
CODE:
POST /names_index/_analyze
{
  "text": "Stephen",
  "analyzer": "phonetic_analyzer"
}

LANGUAGE: json
CODE:
POST /names_index/_analyze
{
  "text": "Steven",
  "analyzer": "phonetic_analyzer"
}

----------------------------------------

TITLE: Checking Model Deployment Status in OpenSearch
DESCRIPTION: GET request to retrieve the status of a model deployment using the Tasks API with the task ID.

LANGUAGE: json
CODE:
GET /_plugins/_ml/tasks/hA8P44MBhyWuIwnfvTKP

----------------------------------------

TITLE: GET PIT Segments Endpoint
DESCRIPTION: Basic endpoint to retrieve information about PIT segments.

LANGUAGE: json
CODE:
GET /_cat/pit_segments

----------------------------------------

TITLE: Querying Query Insights Health Stats API in OpenSearch
DESCRIPTION: This snippet demonstrates how to use the Health Stats API endpoint to retrieve health metrics for nodes running the Query Insights plugin. The API provides detailed information about thread pools, query processing, and resource usage.

LANGUAGE: json
CODE:
GET _insights/health_stats

----------------------------------------

TITLE: OpenSearch Batch Ingestion Response Format
DESCRIPTION: Example response showing the task ID, type, and status of a batch ingestion request.

LANGUAGE: json
CODE:
{
  "task_id": "cbsPlpEBMHcagzGbOQOx",
  "task_type": "BATCH_INGEST",
  "status": "CREATED"
}

----------------------------------------

TITLE: Generating Embeddings with Deployed Model in OpenSearch
DESCRIPTION: JSON requests to generate embeddings for passages and queries using the deployed model.

LANGUAGE: json
CODE:
POST /_plugins/_ml/_predict/text_embedding/your_model_id
{
  "parameters": {
    "content_type": "passage"
  },
  "text_docs": [
    "Today is Friday, tomorrow will be my break day. After that, I will go to the library. When is lunch?"
  ],
  "target_response": ["sentence_embedding"]
}

POST /_plugins/_ml/_predict/text_embedding/your_model_id
{
  "parameters": {
    "content_type": "query"
  },
  "text_docs": ["What day is it today?"],
  "target_response": ["sentence_embedding"]
}

----------------------------------------

TITLE: Registering S3 Snapshot Repository
DESCRIPTION: cURL command to register a new S3 snapshot repository on the source cluster. Requires the Elasticsearch S3 repository plugin to be installed and configured.

LANGUAGE: shell
CODE:
curl -X PUT "http://<your-source-cluster>:9200/_snapshot/test_s3_repository" -H "Content-Type: application/json" -d '{
  "type": "s3",
  "settings": {
    "bucket": "<your-bucket-name>",
    "region": "<your-aws-region>"
  }
}'

----------------------------------------

TITLE: Querying All Shards with Active and Previous Write Operations in OpenSearch
DESCRIPTION: This request retrieves stats for all shards with both active and previous write operations. It includes the 'include_all' parameter to get a comprehensive view of shard indexing pressure.

LANGUAGE: json
CODE:
GET _nodes/_local/stats/shard_indexing_pressure?include_all

----------------------------------------

TITLE: Deleting a Document from OpenSearch
DESCRIPTION: Use the client's delete() method to remove a specific document from an OpenSearch index. This example deletes a document with ID '1'.

LANGUAGE: python
CODE:
response = client.delete(
    index = 'python-test-index',
    id = '1'
)

----------------------------------------

TITLE: Dynamic Mapping Configuration
DESCRIPTION: Example showing how to configure strict dynamic mapping behavior.

LANGUAGE: json
CODE:
{
  "dynamic": "strict",
  "properties":{
    "color":{
      "type": "text"
    }
  }
}

----------------------------------------

TITLE: Creating a Search Pipeline with Neural Sparse Two-Phase Processor in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a search pipeline using the neural_sparse_two_phase_processor. It includes custom parameters for prune_ratio, expansion_rate, and max_window_size.

LANGUAGE: json
CODE:
PUT /_search/pipeline/two_phase_search_pipeline
{
  "request_processors": [
    {
      "neural_sparse_two_phase_processor": {
        "tag": "neural-sparse",
        "description": "This processor is making two-phase processor.",
        "enabled": true,
        "two_phase_parameter": {
          "prune_ratio": custom_prune_ratio,
          "expansion_rate": custom_expansion_rate,
          "max_window_size": custom_max_window_size
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Configuring HTTP Basic Authentication
DESCRIPTION: YAML configuration for setting up HTTP basic authentication with username and password

LANGUAGE: yaml
CODE:
authentication:
  http_basic:
    username: "myuser"
    password: "mys3cr3t"

----------------------------------------

TITLE: Disabling Top N Query Monitoring in OpenSearch
DESCRIPTION: JSON request to disable monitoring of top N queries by latency using cluster settings.

LANGUAGE: json
CODE:
PUT _cluster/settings
{
  "persistent" : {
    "search.insights.top_queries.latency.enabled" : false
  }
}

----------------------------------------

TITLE: Creating a Cluster Health Monitor with Painless Trigger
DESCRIPTION: This JSON example shows how to create a cluster health monitor that checks the status of two clusters and triggers an alert when either cluster's status is not green. It uses a Painless script to define the trigger condition.

LANGUAGE: json
CODE:
{
  "name": "Cluster Health Monitor",
  "type": "monitor",
  "monitor_type": "query_level_monitor",
  "enabled": true,
  "schedule": {
    "period": {
      "unit": "MINUTES",
      "interval": 1
    }
  },
  "inputs": [
    {
      "uri": {
        "api_type": "CLUSTER_HEALTH",
        "path": "_cluster/health/",
        "path_params": "",
        "url": "http://localhost:9200/_cluster/health/",
        "clusters": ["cluster-1", "cluster-2"]
      }
    }
  ],
  "triggers": [
    {
      "query_level_trigger": {
        "id": "Tf_L_nwBti6R6Bm-18qC",
        "name": "Yellow status trigger",
        "severity": "1",
        "condition": {
          "script": {
            "source": "for (cluster in ctx.results[0].keySet()) if (ctx.results[0][cluster].status != \"green\") return true",
            "lang": "painless"
          }
        },
        "actions": []
      }
    }
  ]
}

----------------------------------------

TITLE: Deleting an Index Rollup Job in OpenSearch
DESCRIPTION: This snippet demonstrates how to delete an index rollup job using a DELETE request with the rollup_id.

LANGUAGE: json
CODE:
DELETE _plugins/_rollup/jobs/<rollup_id>

----------------------------------------

TITLE: Removing Optimized Bundle for Anomaly Detection Plugin
DESCRIPTION: This command removes the optimized bundle for the Anomaly Detection plugin. This step is necessary for some plugins after removal.

LANGUAGE: bash
CODE:
sudo rm /usr/share/opensearch-dashboards/optimize/bundles/opensearch-anomaly-detection-opensearch-dashboards.*

----------------------------------------

TITLE: Getting Agent ID Response - JSON
DESCRIPTION: Example response showing the agent ID after initial agent setup.

LANGUAGE: json
CODE:
{
  "agent_id": "9X7xWI0Bpc3sThaJdY9i"
}

----------------------------------------

TITLE: Configuring ML Node Role in OpenSearch
DESCRIPTION: Defines a dedicated ML node role in the OpenSearch cluster configuration.

LANGUAGE: yaml
CODE:
node.roles: [ ml ]

----------------------------------------

TITLE: Indexing Child Documents - OpenSearch JSON
DESCRIPTION: Index requests to create child (product) documents with routing and parent references. Each product is linked to its parent brand.

LANGUAGE: json
CODE:
PUT testindex1/_doc/3?routing=1
{
  "name": "Mechanical watch",
  "sales_count": 150,
  "product_to_brand": {
    "name": "product", 
    "parent": "1" 
  }
}

----------------------------------------

TITLE: Delete Agent Request Example
DESCRIPTION: Example of a DELETE request to remove a specific agent using its ID.

LANGUAGE: json
CODE:
DELETE /_plugins/_ml/agents/MzcIJX8BA7mbufL6DOwl

----------------------------------------

TITLE: Testing Bedrock Model in OpenSearch
DESCRIPTION: Tests the deployed Bedrock model by generating embeddings for a sample input text.

LANGUAGE: json
CODE:
POST /_plugins/_ml/models/PEq3QY0BOhavBOmf1Sml/_predict
{
  "parameters": {
    "inputText": "hello world"
  }
}

----------------------------------------

TITLE: Retrieving All ML Commons Stats for All Nodes in OpenSearch
DESCRIPTION: This request retrieves all ML Commons statistics for all nodes in the OpenSearch cluster. It returns a JSON object with node IDs as keys and their corresponding statistics as values.

LANGUAGE: json
CODE:
GET /_plugins/_ml/stats

----------------------------------------

TITLE: Create Query Group Response Example
DESCRIPTION: Example response when successfully creating a new query group, showing the assigned ID and configuration details.

LANGUAGE: json
CODE:
{
  "_id":"preXpc67RbKKeCyka72_Gw",
  "name":"analytics",
  "resiliency_mode":"enforced",
  "resource_limits":{
    "cpu":0.4,
    "memory":0.2
  },
  "updated_at":1726270184642
}

----------------------------------------

TITLE: Successful Repository Registration Response in OpenSearch
DESCRIPTION: This JSON response indicates a successful registration of a snapshot repository in OpenSearch.

LANGUAGE: json
CODE:
{
  "acknowledged": true
}

----------------------------------------

TITLE: Configuring Dissect Processor in YAML Pipeline
DESCRIPTION: Demonstrates how to set up a basic pipeline using the dissect processor to extract fields from log messages.

LANGUAGE: yaml
CODE:
dissect-pipeline:
  source:
    file:
      path: "/full/path/to/logs_json.log"
      record_type: "event"
      format: "json"
  processor:
    - dissect:
        map:
          log: "%{Date} %{Time} %{Log_Type}: %{Message}"
  sink:
    - stdout:

----------------------------------------

TITLE: Index Metrics Query Example
DESCRIPTION: Example query retrieving docs and search statistics for indices metric.

LANGUAGE: json
CODE:
GET _nodes/stats/indices/docs,search

----------------------------------------

TITLE: Search With Pipeline
DESCRIPTION: Executes a search using the rename field processor pipeline to transform field names in the response.

LANGUAGE: json
CODE:
GET /my_index/_search?search_pipeline=my_pipeline

----------------------------------------

TITLE: Installing Jekyll and Dependencies for OpenSearch Documentation
DESCRIPTION: Command to install Jekyll and all required dependencies for building the OpenSearch documentation website using Bundler.

LANGUAGE: shell
CODE:
bundle install

----------------------------------------

TITLE: Installing OpenSearch Go Client
DESCRIPTION: Adds the OpenSearch Go client to the project dependencies

LANGUAGE: go
CODE:
go get github.com/opensearch-project/opensearch-go

----------------------------------------

TITLE: Creating Index with Bulk Documents in OpenSearch
DESCRIPTION: Example of creating an index named 'my_index' with 10 sample documents using the bulk API.

LANGUAGE: json
CODE:
POST /_bulk
{ "create":{"_index":"my_index","_id":1}}
{ "doc": { "title" : "document 1" }}
{ "create":{"_index":"my_index","_id":2}}
{ "doc": { "title" : "document 2" }}
{ "create":{"_index":"my_index","_id":3}}
{ "doc": { "title" : "document 3" }}
{ "create":{"_index":"my_index","_id":4}}
{ "doc": { "title" : "document 4" }}
{ "create":{"_index":"my_index","_id":5}}
{ "doc": { "title" : "document 5" }}
{ "create":{"_index":"my_index","_id":6}}
{ "doc": { "title" : "document 6" }}
{ "create":{"_index":"my_index","_id":7}}
{ "doc": { "title" : "document 7" }}
{ "create":{"_index":"my_index","_id":8}}
{ "doc": { "title" : "document 8" }}
{ "create":{"_index":"my_index","_id":9}}
{ "doc": { "title" : "document 9" }}
{ "create":{"_index":"my_index","_id":10}}
{ "doc": { "title" : "document 10" }}

----------------------------------------

TITLE: Configuring Cross-Account S3 Access
DESCRIPTION: YAML configuration for setting up cross-account S3 access when ingesting data from multiple S3 buckets associated with different accounts.

LANGUAGE: yaml
CODE:
s3:
  sqs:
      queue_url: "https://sqs.us-east-1.amazonaws.com/000000000000/MyQueue"
  bucket_owners:
    my-bucket-01: 123456789012
    my-bucket-02: 999999999999

----------------------------------------

TITLE: Geo Distance Range Query Example
DESCRIPTION: Complete example showing how to query documents within specific distance ranges from a geographical point.

LANGUAGE: json
CODE:
GET opensearch_dashboards_sample_data_logs/_search
{
  "size": 0,
  "aggs": {
    "position": {
      "geo_distance": {
        "field": "geo.coordinates",
        "origin": {
          "lat": 83.76,
          "lon": -81.2
        },
        "ranges": [
          {
            "to": 10
          },
          {
            "from": 10,
            "to": 20
          },
          {
            "from": 20,
            "to": 50
          },
          {
            "from": 50,
            "to": 100
          },
          {
            "from": 100
          }
        ]
      }
    }
  }
}

----------------------------------------

TITLE: Refreshing Search Analyzers API Call in OpenSearch
DESCRIPTION: This API call refreshes search analyzers in real-time for a specified index, alias, or wildcard. It requires the Index State Management (ISM) plugin to be installed.

LANGUAGE: json
CODE:
POST /_plugins/_refresh_search_analyzers/<index or alias or wildcard>

----------------------------------------

TITLE: Installing OpenSearch RPM Package
DESCRIPTION: Install OpenSearch using the RPM package with a custom admin password for versions 2.12 and later.

LANGUAGE: bash
CODE:
sudo env OPENSEARCH_INITIAL_ADMIN_PASSWORD=<custom-admin-password> yum install opensearch-{{site.opensearch_version}}-linux-x64.rpm

----------------------------------------

TITLE: Neural Search with Min-Score Filter in OpenSearch
DESCRIPTION: Example of a neural search query with a minimum score threshold of 0.95 and combined filters

LANGUAGE: json
CODE:
GET /my-nlp-index/_search
{
  "query": {
    "neural": {
      "passage_embedding": {
        "query_text": "Hi world",
        "query_image": "iVBORw0KGgoAAAAN...",
        "min_score": 0.95,
        "filter": {
          "bool": {
            "must": [
              {
                "range": {
                  "rating": {
                    "gte": 8,
                    "lte": 10
                  }
                }
              },
              {
                "term": {
                  "parking": "true"
                }
              }
            ]
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Creating a Pipeline with Date Index Name Processor in OpenSearch
DESCRIPTION: Demonstrates how to create an ingest pipeline named 'date-index-name1' that uses the date_index_name processor to index logs into weekly indexes.

LANGUAGE: json
CODE:
PUT /_ingest/pipeline/date-index-name1
{
  "description": "Create weekly index pipeline",
  "processors": [
    {
      "date_index_name": {
        "field": "date_field",
        "index_name_prefix": "week_index-",
        "date_rounding": "w",
        "date_formats": ["YYYY-MM-DD"]
      }
    }
  ]
}

----------------------------------------

TITLE: Creating Ingest Pipeline for Embeddings
DESCRIPTION: Sets up an ingest pipeline in OpenSearch that uses the Bedrock model to generate embeddings from input text.

LANGUAGE: json
CODE:
PUT /_ingest/pipeline/my_bedrock_embedding_pipeline
{
    "description": "text embedding pipeline",
    "processors": [
        {
            "text_embedding": {
                "model_id": "your_bedrock_embedding_model_id_created_in_step4",
                "field_map": {
                    "text": "text_knn"
                }
            }
        }
    ]
}

----------------------------------------

TITLE: OpenSearch Vector Quantization Configuration
DESCRIPTION: YAML front matter configuration for the vector quantization documentation page, including navigation settings and card definitions for different quantization methods.

LANGUAGE: yaml
CODE:
---
layout: default
title: Vector quantization
parent: Optimizing vector storage
nav_order: 10
has_children: true
has_toc: false
redirect_from:
  - /search-plugins/knn/knn-vector-quantization/
outside_cards:
  - heading: "Byte vectors"
    description: "Quantize vectors into byte vectors"
    link: "/field-types/supported-field-types/knn-memory-optimized/#byte-vectors"
  - heading: "Binary vectors"
    description: "Quantize vectors into binary vector"
    link: "/field-types/supported-field-types/knn-memory-optimized/#binary-vectors"
inside_cards:
  - heading: "Lucene scalar quantization"
    description: "Use built-in scalar quantization for the Lucene engine"
    link: "/vector-search/optimizing-storage/lucene-scalar-quantization/"
  - heading: "Faiss 16-bit scalar quantization"
    description: "Use built-in scalar quantization for the Faiss engine"
    link: "/vector-search/optimizing-storage/faiss-16-bit-quantization/"
  - heading: "Faiss product quantization"
    description: "Use built-in product quantization for the Faiss engine"
    link: "/vector-search/optimizing-storage/faiss-product-quantization/"
  - heading: "Binary quantization"
    description: "Use built-in binary quantization for the Faiss engine"
    link: "/vector-search/optimizing-storage/binary-quantization/"
---

----------------------------------------

TITLE: Creating Replication Rule Request
DESCRIPTION: API endpoint to create automatic replication rules based on index patterns. Includes connection alias, pattern name, and optional security roles.

LANGUAGE: json
CODE:
{
   "leader_alias" : "<connection-alias-name>",
   "name": "<auto-follow-pattern-name>",
   "pattern": "<pattern>",
   "use_roles":{
      "leader_cluster_role": "<role-name>",
      "follower_cluster_role": "<role-name>"
   }
}

----------------------------------------

TITLE: Example Response from OpenSearch Nodes Info API
DESCRIPTION: Sample response from the Nodes Info API, showing 'process' and 'transport' metrics for a single node in the cluster.

LANGUAGE: json
CODE:
{
  "_nodes": {
    "total": 1,
    "successful": 1,
    "failed": 0
  },
  "cluster_name": "opensearch",
  "nodes": {
    "VC0d4RgbTM6kLDwuud2XZQ": {
      "name": "node-m1-23",
      "transport_address": "127.0.0.1:9300",
      "host": "127.0.0.1",
      "ip": "127.0.0.1",
      "version": "1.3.1",
      "build_type": "tar",
      "build_hash": "c4c0672877bf0f787ca857c7c37b775967f93d81",
      "roles": [
        "data",
        "ingest",
        "master",
        "remote_cluster_client"
      ],
      "attributes": {
        "shard_indexing_pressure_enabled": "true"
      },
      "process" : {
        "refresh_interval_in_millis": 1000,
        "id": 44584,
        "mlockall": false
      },
      "transport": {
        "bound_address": [
          "[::1]:9300",
          "127.0.0.1:9300"
        ],
        "publish_address": "127.0.0.1:9300",
        "profiles": { }
      }
    }
  }
}

----------------------------------------

TITLE: Requesting Specific Metrics from Cluster Manager Node in OpenSearch
DESCRIPTION: Example request to retrieve 'process' and 'transport' metrics from the cluster manager node using the Nodes Info API.

LANGUAGE: json
CODE:
GET /_nodes/cluster_manager:true/process,transport

----------------------------------------

TITLE: Creating Search Pipeline with Script Processor in OpenSearch
DESCRIPTION: Example of creating a search pipeline that uses a script processor to limit score explanation to one document. The script checks the size parameter and sets explain to true only when size is 1 or less.

LANGUAGE: json
CODE:
PUT /_search/pipeline/explain_one_result
{
  "description": "A pipeline to limit the explain operation to one result only",
  "request_processors": [
    {
      "script": {
        "lang": "painless",
        "source": "if (ctx._source['size'] > 1) { ctx._source['explain'] = false } else { ctx._source['explain'] = true }"
      }
    }
  ]
}

----------------------------------------

TITLE: Code Formatting Example - Single Backticks
DESCRIPTION: Demonstrates how to format inline code using single backticks in Markdown.

LANGUAGE: markdown
CODE:
`discovery.type`

----------------------------------------

TITLE: Executing Value Count Aggregation in OpenSearch
DESCRIPTION: This snippet demonstrates how to perform a value_count aggregation on the 'taxful_total_price' field in the OpenSearch Dashboards sample e-commerce data. It uses a search query with size set to 0 to focus only on the aggregation results.

LANGUAGE: json
CODE:
GET opensearch_dashboards_sample_data_ecommerce/_search
{
  "size": 0,
   "aggs": {
    "number_of_values": {
      "value_count": {
        "field": "taxful_total_price"
      }
    }
  }
}

----------------------------------------

TITLE: Executing Search Query in OpenSearch Dev Tools Console
DESCRIPTION: This snippet shows the simplified syntax used in the OpenSearch Dev Tools console to execute the same search query as the cURL example. It searches for "To be, or not to be" in the 'shakespeare' index.

LANGUAGE: json
CODE:
GET shakespeare/_search
{
  "query": {
    "match": {
      "text_entry": "To be, or not to be"
    }
  }
}

----------------------------------------

TITLE: Executing CatIndexTool Agent in OpenSearch
DESCRIPTION: Request to execute the registered CatIndexTool agent with a specific question parameter.

LANGUAGE: json
CODE:
{
  "parameters": {
    "question": "How many indices do I have?"
  }
}

----------------------------------------

TITLE: Detailed OTel Metrics Processor Configuration
DESCRIPTION: Complete configuration example showing all available parameters for the otel_metrics processor including histogram calculation settings.

LANGUAGE: yaml
CODE:
processor:
    - otel_metrics_raw_processor:
        calculate_histogram_buckets: true
        calculate_exponential_histogram_buckets: true
        exponential_histogram_max_allowed_scale: 10
        flatten_attributes: false

----------------------------------------

TITLE: ISM Configuration Settings Table in YAML
DESCRIPTION: A comprehensive list of ISM configuration settings available through OpenSearch's _cluster/settings operation. These settings control ISM behavior, history management, and job scheduling parameters.

LANGUAGE: yaml
CODE:
plugins.index_state_management.enabled: true
plugins.index_state_management.job_interval: 5m
plugins.index_state_management.jitter: 0.6
plugins.index_state_management.coordinator.sweep_period: 10m
plugins.index_state_management.coordinator.backoff_millis: 50ms
plugins.index_state_management.coordinator.backoff_count: 2
plugins.index_state_management.history.enabled: true
plugins.index_state_management.history.max_docs: 2500000
plugins.index_state_management.history.max_age: 24h
plugins.index_state_management.history.rollover_check_period: 8h
plugins.index_state_management.history.rollover_retention_period: 30d
plugins.index_state_management.allow_list: "*"

----------------------------------------

TITLE: Dockerfile for OpenSearch with S3 Plugin and AWS Credentials
DESCRIPTION: Dockerfile configuration for setting up OpenSearch with the S3 plugin and AWS credentials for snapshot repository.

LANGUAGE: dockerfile
CODE:
FROM opensearchproject/opensearch:{{site.opensearch_version}}

ENV AWS_ACCESS_KEY_ID <access-key>
ENV AWS_SECRET_ACCESS_KEY <secret-key>

# Optional
ENV AWS_SESSION_TOKEN <optional-session-token>

RUN /usr/share/opensearch/bin/opensearch-plugin install --batch repository-s3
RUN /usr/share/opensearch/bin/opensearch-keystore create

RUN echo $AWS_ACCESS_KEY_ID | /usr/share/opensearch/bin/opensearch-keystore add --stdin s3.client.default.access_key
RUN echo $AWS_SECRET_ACCESS_KEY | /usr/share/opensearch/bin/opensearch-keystore add --stdin s3.client.default.secret_key

# Optional
RUN echo $AWS_SESSION_TOKEN | /usr/share/opensearch/bin/opensearch-keystore add --stdin s3.client.default.session_token

----------------------------------------

TITLE: Term Query Parameter Structure in OpenSearch
DESCRIPTION: Shows the basic structure for specifying term query parameters with field name.

LANGUAGE: json
CODE:
GET _search
{
  "query": {
    "term": {
      "<field>": {
        "value": "sample",
        ...
      }
    }
  }
}

----------------------------------------

TITLE: Indexing Document with Search-as-you-type Field in OpenSearch
DESCRIPTION: This snippet demonstrates how to index a document with a search-as-you-type field in OpenSearch.

LANGUAGE: json
CODE:
PUT books/_doc/1
{
  "suggestions": "one two three four"
}

----------------------------------------

TITLE: Stopping Elasticsearch Service on Linux
DESCRIPTION: This bash command stops the Elasticsearch service on Linux distributions using systemd.

LANGUAGE: bash
CODE:
sudo systemctl stop elasticsearch.service

----------------------------------------

TITLE: Executing k-NN Search with Cosine Similarity in OpenSearch
DESCRIPTION: Example of performing k-NN search using the cosineSimilarity function in a Painless script. The query filters for blue-colored items and calculates similarity scores between the query vector and document vectors.

LANGUAGE: json
CODE:
GET my-knn-index-2/_search
{
  "size": 2,
  "query": {
    "script_score": {
      "query": {
        "bool": {
          "filter": {
            "term": {
              "color": "BLUE"
            }
          }
        }
      },
      "script": {
        "source": "1.0 + cosineSimilarity(params.query_value, doc[params.field])",
        "params": {
          "field": "my_vector",
          "query_value": [9.9, 9.9]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Custom Analyzer with Currency Pattern Replace
DESCRIPTION: Creates an index with a custom analyzer that removes currency signs and thousands separators from numbers using pattern_replace filter.

LANGUAGE: json
CODE:
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "standard",
          "char_filter": [
            "pattern_char_filter"
          ]
        }
      },
      "char_filter": {
        "pattern_char_filter": {
          "type": "pattern_replace",
          "pattern": "[$,.]",
          "replacement": ""
        }
      }
    }
  }
}

----------------------------------------

TITLE: Listing Test Executions in OpenSearch Benchmark
DESCRIPTION: This command lists recent test executions in OpenSearch Benchmark, showing TestExecution IDs and other relevant information.

LANGUAGE: bash
CODE:
opensearch-benchmark list test_executions

----------------------------------------

TITLE: Configuring Advanced Geoip Processor in YAML
DESCRIPTION: Advanced configuration for the geoip processor that excludes ASN fields and stores geolocation data in a field named 'clientlocation'.

LANGUAGE: yaml
CODE:
my-pipeline:
  processor:
    - geoip:
        entries:
          - source: clientip
            target: clientlocation
            include_fields: [asn, asn_organization, network]

----------------------------------------

TITLE: Sample Response from CAT Thread Pool API in OpenSearch
DESCRIPTION: This is an example response from the CAT thread pool API, showing active, queued, and rejected threads for different thread pools on a node.

LANGUAGE: json
CODE:
node_name  name                      active queue rejected
odfe-node2 ad-batch-task-threadpool    0     0        0
odfe-node2 ad-threadpool               0     0        0
odfe-node2 analyze                     0     0        0s

----------------------------------------

TITLE: Creating Custom Log Type in OpenSearch Security Analytics
DESCRIPTION: This API request creates a new custom log type with a name, description, and source. It uses a POST request to the /_plugins/_security_analytics/logtype endpoint.

LANGUAGE: json
CODE:
POST /_plugins/_security_analytics/logtype
{
  "description": "custom-log-type-desc",
  "name": "custom-log-type4",
  "source": "Custom"
}

----------------------------------------

TITLE: Limited Operator Query
DESCRIPTION: Example of restricting available operators to OR, AND, and FUZZY only.

LANGUAGE: json
CODE:
GET /customers/_search
{
  "query": {
    "simple_query_string": {
      "fields": [ "address" ],
      "query": "bristol | madison +stre~2",
      "flags": "OR|AND|FUZZY"
    }
  }
}

----------------------------------------

TITLE: Creating Index with Phonetic Analyzer in OpenSearch
DESCRIPTION: JSON request to create a new index named 'names_index' with a custom analyzer using the phonetic filter. The filter is configured to use the double_metaphone encoder and replace the original token.

LANGUAGE: json
CODE:
PUT /names_index
{
  "settings": {
    "analysis": {
      "filter": {
        "my_phonetic_filter": {
          "type": "phonetic",
          "encoder": "double_metaphone",
          "replace": true
        }
      },
      "analyzer": {
        "phonetic_analyzer": {
          "tokenizer": "standard",
          "filter": [
            "my_phonetic_filter"
          ]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Create Workspace API Endpoint
DESCRIPTION: API endpoint to create a new workspace with specified attributes and optional permissions.

LANGUAGE: json
CODE:
POST <osd host>:<port>/api/workspaces

----------------------------------------

TITLE: Enabling Distributed Tracing in Docker Environment
DESCRIPTION: Add this line to docker-compose.yml under the environment section to enable distributed tracing in a Docker container.

LANGUAGE: yaml
CODE:
OPENSEARCH_JAVA_OPTS="-Dopensearch.experimental.feature.telemetry.enabled=true"

----------------------------------------

TITLE: Creating Trim Pipeline
DESCRIPTION: Example of creating a pipeline that uses the trim processor to remove whitespace from raw_text field.

LANGUAGE: json
CODE:
PUT _ingest/pipeline/trim_pipeline
{
  "description": "Trim leading and trailing white space",
  "processors": [
    {
      "trim": {
        "field": "raw_text",
        "target_field": "trimmed_text"
      }
    }
  ]
}

----------------------------------------

TITLE: Generating Node and Client Certificates for OpenSearch
DESCRIPTION: Commands to create node and client certificates with Subject Alternative Name (SAN) extensions.

LANGUAGE: bash
CODE:
openssl genrsa -out node1-key-temp.pem 2048
openssl pkcs8 -inform PEM -outform PEM -in node1-key-temp.pem -topk8 -nocrypt -v1 PBE-SHA1-3DES -out node1-key.pem
openssl req -new -key node1-key.pem -out node1.csr
echo 'subjectAltName=DNS:node1.dns.a-record' > node1.ext
openssl x509 -req -in node1.csr -CA root-ca.pem -CAkey root-ca-key.pem -CAcreateserial -sha256 -out node1.pem -days 730 -extfile node1.ext

----------------------------------------

TITLE: Creating a collapse pipeline in OpenSearch
DESCRIPTION: This snippet shows how to create a search pipeline that collapses results based on the 'color' field.

LANGUAGE: json
CODE:
PUT /_search/pipeline/collapse_pipeline
{
  "response_processors": [
    {
      "collapse" : {
        "field": "color"
      }
    }
  ]
}

----------------------------------------

TITLE: Lucene HNSW Configuration
DESCRIPTION: Example of configuring HNSW method parameters using the Lucene engine.

LANGUAGE: json
CODE:
"method": {
    "name": "hnsw",
    "engine": "lucene",
    "parameters": {
        "m": 2048,
        "ef_construction": 245
    }
}

----------------------------------------

TITLE: Ingesting Vector Data with Faiss Scalar Quantization in OpenSearch
DESCRIPTION: This snippet shows how to ingest vector data into an index using Faiss scalar quantization in OpenSearch. The vector dimensions must be within the supported range of [-65504.0, 65504.0].

LANGUAGE: json
CODE:
PUT test-index/_doc/1
{
  "my_vector1": [-65504.0, 65503.845, 55.82]
}

----------------------------------------

TITLE: Custom Stopwords Configuration
DESCRIPTION: Creates an index with a custom stop analyzer using specific stopwords list.

LANGUAGE: json
CODE:
PUT /my_new_custom_stop_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_custom_stop_analyzer": {
          "type": "stop",                     
          "stopwords": ["is", "and", "was"]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "description": {
        "type": "text",
        "analyzer": "my_custom_stop_analyzer" 
      }
    }
  }
}

----------------------------------------

TITLE: Adding Test Procedures to workload.json
DESCRIPTION: Example of adding test procedures to the workload.json file to provide variance in workload operations.

LANGUAGE: json
CODE:
"test_procedures": [
    {
      "name": "index-and-query",
      "default": true,
      "schedule": [
        {
          "operation": {
            "operation-type": "delete-index"
          }
        },
        {
          "operation": {
            "operation-type": "create-index"
          }
        },
        {
          "operation": {
            "operation-type": "cluster-health",
            "request-params": {
              "wait_for_status": "green"
            },
            "retry-until-success": true
          }
        },
        {
          "operation": {
            "operation-type": "bulk",
            "bulk-size": 5000
          },
          "warmup-time-period": 120,
          "clients": 8
        },
        {
          "operation": {
            "operation-type": "force-merge"
          }
        },
        {
          "operation": {
            "name": "query-match-all",
            "operation-type": "search",
            "body": {
              "query": {
                "match_all": {}
              }
            }
          },
          "clients": 8,
          "warmup-iterations": 1000,
          "iterations": 1000,
          "target-throughput": 100
        }
      ]
    }
  ]

----------------------------------------

TITLE: Configuring Multi-tenancy with Remote OpenSearch Cluster
DESCRIPTION: Example configuration for enabling multi-tenancy in an OpenSearch plugin using a remote OpenSearch cluster as the metadata store. Demonstrates basic settings including endpoint, region, and service name configuration.

LANGUAGE: yaml
CODE:
plugins.<plugin_name>.multi_tenancy_enabled: true
plugins.<plugin_name>.remote_metadata_type: "opensearch"
plugins.<plugin_name>.remote_metadata_endpoint: "https://remote-store.example.com"
plugins.<plugin_name>.remote_metadata_region: "us-west-2"
plugins.<plugin_name>.remote_metadata_service_name: "remote-store-service"

----------------------------------------

TITLE: Checking Certificate Expiration Date
DESCRIPTION: Demonstrates how to check the expiration date of a certificate using the openssl command.

LANGUAGE: bash
CODE:
openssl x509 -enddate -noout -in <certificate>

----------------------------------------

TITLE: Executing Geopolygon Query in OpenSearch
DESCRIPTION: Performs a search query to find documents with geopoints that fall within a specified polygon defined by multiple coordinate pairs.

LANGUAGE: json
CODE:
GET /testindex1/_search
{
  "query": {
    "bool": {
      "must": {
        "match_all": {}
      },
      "filter": {
        "geo_polygon": {
          "point": {
            "points": [
              { "lat": 74.5627, "lon": 41.8645 },
              { "lat": 73.7562, "lon": 42.6526 },
              { "lat": 73.3245, "lon": 41.6189 },
              { "lat": 74.0060, "lon": 40.7128 }
           ]
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Executing Match All Query in OpenSearch
DESCRIPTION: Demonstrates how to use the match_all query to return all documents in an OpenSearch index. This query is particularly useful when testing large document sets or when you need to retrieve the entire dataset.

LANGUAGE: json
CODE:
GET _search
{
  "query": {
    "match_all": {}
  }
}

----------------------------------------

TITLE: Altering Materialized View Auto-refresh Settings
DESCRIPTION: SQL query to disable auto-refresh for a materialized view.

LANGUAGE: sql
CODE:
ALTER MATERIALIZED VIEW myglue_test.default.count_by_status_v9 WITH (auto_refresh = false);

----------------------------------------

TITLE: Executing a Neural Sparse Search Query in OpenSearch
DESCRIPTION: This snippet shows how to execute the registered agent to perform a neural sparse search query. It demonstrates passing a question as a parameter to the agent.

LANGUAGE: json
CODE:
POST /_plugins/_ml/agents/9X7xWI0Bpc3sThaJdY9i/_execute
{
  "parameters": {
    "question":"how many employees does AAA have?"
  }
}

----------------------------------------

TITLE: Ingesting Document with User Agent Pipeline in OpenSearch
DESCRIPTION: PUT request to ingest a document into 'testindex1' using the 'user_agent_pipeline'. This processes the user agent string and adds the extracted information to the document.

LANGUAGE: json
CODE:
PUT testindex1/_doc/1?pipeline=user_agent_pipeline
{
  "user_agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36"
}

----------------------------------------

TITLE: Creating Ingest Pipeline for Text and Image Embedding in OpenSearch
DESCRIPTION: PUT request to create an ingest pipeline with a text_image_embedding processor for converting text and image data to vector embeddings.

LANGUAGE: json
CODE:
PUT /_ingest/pipeline/nlp-ingest-pipeline
{
  "description": "A text/image embedding pipeline",
  "processors": [
    {
      "text_image_embedding": {
        "model_id": "-fYQAosBQkdnhhBsK593",
        "embedding": "vector_embedding",
        "field_map": {
          "text": "image_description",
          "image": "image_binary"
        }
      }
    }
  ]
}

----------------------------------------

TITLE: Performing a match_all query with reranking in OpenSearch
DESCRIPTION: This snippet demonstrates how to perform a match_all query on the book index. The search results will be reranked based on the previously configured search pipeline, sorting by the 'reviews.stars' field.

LANGUAGE: json
CODE:
POST /book-index/_search
{
  "query": {
     "match_all": {}
  }
}

----------------------------------------

TITLE: Using use_source_key and extract_value in list_to_map
DESCRIPTION: YAML configuration demonstrating the use of use_source_key and extract_value set to true in the list_to_map processor.

LANGUAGE: yaml
CODE:
pipeline:
  source:
    file:
      path: "/full/path/to/logs_json.log"
      record_type: "event"
      format: "json"
  processor:
    - list_to_map:
        source: "mylist"
        use_source_key: true
        extract_value: true
  sink:
    - stdout:

----------------------------------------

TITLE: Configuring Lucene Scalar Quantization with Confidence Interval
DESCRIPTION: Example showing how to create a vector index with custom confidence interval settings for the scalar quantization encoder.

LANGUAGE: json
CODE:
PUT /test-index
{
  "settings": {
    "index": {
      "knn": true
    }
  },
  "mappings": {
    "properties": {
      "my_vector1": {
        "type": "knn_vector",
        "dimension": 2,
        "space_type": "l2",
        "method": {
          "name": "hnsw",
          "engine": "lucene",
          "parameters": {
            "encoder": {
              "name": "sq",
              "parameters": {
                "confidence_interval": 1.0
              }
            },
            "ef_construction": 256,
            "m": 8
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Bulk API Request Example
DESCRIPTION: Example of a bulk API request that requires specific index permissions to execute successfully.

LANGUAGE: json
CODE:
POST _bulk
{ "delete": { "_index": "test-index", "_id": "tt2229499" } }
{ "index": { "_index": "test-index", "_id": "tt1979320" } }
{ "title": "Rush", "year": 2013 }
{ "create": { "_index": "test-index", "_id": "tt1392214" } }
{ "title": "Prisoners", "year": 2013 }
{ "update": { "_index": "test-index", "_id": "tt0816711" } }
{ "doc" : { "title": "World War Z" } }

----------------------------------------

TITLE: Creating Index with Kuromoji Completion Filter in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a new index named 'kuromoji_sample' with a custom analyzer that includes the kuromoji_completion filter. It configures the analyzer to use the kuromoji_tokenizer and applies a custom Katakana stemmer filter.

LANGUAGE: json
CODE:
PUT kuromoji_sample
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "my_analyzer": {
            "tokenizer": "kuromoji_tokenizer",
            "filter": [
              "my_katakana_stemmer"
            ]
          }
        },
        "filter": {
          "my_katakana_stemmer": {
            "type": "kuromoji_completion"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Configuring OpenSearch Reranking Pipeline
DESCRIPTION: JSON configuration for setting up a search pipeline with reranking capabilities using the deployed model.

LANGUAGE: json
CODE:
{
    "description": "Pipeline for reranking with Sagemaker cross-encoder model",
    "response_processors": [
        {
            "rerank": {
                "ml_opensearch": {
                    "model_id": "your_model_id_created_in_step1"
                },
                "context": {
                    "document_fields": ["passage_text"]
                }
            }
        }
    ]
}

----------------------------------------

TITLE: Setting Target for list_to_map Processor Output
DESCRIPTION: YAML configuration demonstrating how to set a specific target (mymap) for the list_to_map processor output.

LANGUAGE: yaml
CODE:
pipeline:
  source:
    file:
      path: "/full/path/to/logs_json.log"
      record_type: "event"
      format: "json"
  processor:
    - list_to_map:
        key: "name"
        source: "mylist"
        target: "mymap"
        value_key: "value"
        flatten: true
  sink:
    - stdout:

----------------------------------------

TITLE: Disabling Adaptive Replica Selection in OpenSearch
DESCRIPTION: Updates cluster settings to disable adaptive replica selection for search shard routing. This causes OpenSearch to use round-robin routing instead.

LANGUAGE: json
CODE:
PUT /_cluster/settings
{
  "persistent": {
    "cluster.routing.use_adaptive_replica_selection": false
  }
}

----------------------------------------

TITLE: Vector Search with Filtering on Nested Fields in OpenSearch
DESCRIPTION: This snippet shows how to perform a vector search with filtering on nested fields in OpenSearch, applying a filter to a top-level field.

LANGUAGE: json
CODE:
GET my-knn-index-1/_search
{
  "query": {
    "nested": {
      "path": "nested_field",
      "query": {
        "knn": {
          "nested_field.my_vector": {
            "vector": [
              1,
              1,
              1
            ],
            "k": 3,
            "filter": {
              "term": {
                "parking": true
              }
            }
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Showing Flint Indexes
DESCRIPTION: SQL query to display all Flint indexes in a specific catalog.

LANGUAGE: sql
CODE:
SHOW FLINT INDEXES IN spark_catalog.default;

----------------------------------------

TITLE: Creating an Index for RAG Data
DESCRIPTION: This request creates an index for storing RAG data and sets the default search pipeline.

LANGUAGE: json
CODE:
PUT /my_rag_test_data
{
  "settings": {
    "index.search.default_pipeline" : "rag_pipeline"
  },
  "mappings": {
    "properties": {
      "text": {
        "type": "text"
      }
    }
  }
}

----------------------------------------

TITLE: Associating Data Source with Multiple Workspaces in TypeScript
DESCRIPTION: This snippet demonstrates how to link a data source object to multiple workspaces, facilitating cross-team collaboration and resource sharing.

LANGUAGE: typescript
CODE:
{
  type: "data-source",
  id: "da123f20-6680-11ee-93fa-df944ec23359",
  workspaces: ["M5NqCu", "<TeamA-workspace-id>", "<Analytics-workspace-id>"]
}

----------------------------------------

TITLE: Associating Data Source with Multiple Workspaces in TypeScript
DESCRIPTION: This snippet demonstrates how to link a data source object to multiple workspaces, facilitating cross-team collaboration and resource sharing.

LANGUAGE: typescript
CODE:
{
  type: "data-source",
  id: "da123f20-6680-11ee-93fa-df944ec23359",
  workspaces: ["M5NqCu", "<TeamA-workspace-id>", "<Analytics-workspace-id>"]
}

----------------------------------------

TITLE: Querying Specific Headers - OpenSearch List API
DESCRIPTION: Demonstrates how to limit the response to specific headers using the h parameter.

LANGUAGE: json
CODE:
GET _list/<operation_name>?h=<header_name_1>,<header_name_2>&v

----------------------------------------

TITLE: Paginated SQL Query
DESCRIPTION: Example showing how to use fetch_size parameter for pagination in SQL queries.

LANGUAGE: json
CODE:
{
  "fetch_size" : 5,
  "query" : "SELECT firstname, lastname FROM accounts WHERE age > 20 ORDER BY state ASC"
}

----------------------------------------

TITLE: Detailed Exponential Histogram Format
DESCRIPTION: OpenTelemetry representation of exponential histograms showing negative and positive bucket counts, scale, and offsets.

LANGUAGE: json
CODE:
"negative": [
        1,
        2,
        3
    ],
    "positive": [
        1,
        2,
        3
    ],
    "scale" : -3,
    "negativeOffset" : 0,
    "positiveOffset" : 1

----------------------------------------

TITLE: Simplified Query Parameters Template
DESCRIPTION: Minimal query parameters template showing only Parameter and Description columns with header omitted.

LANGUAGE: html
CODE:
<!-- spec_insert_start
api: search
component: query_parameters
columns: Parameter, Description
omit_header: true
-->
THIS
TEXT
SHOULD
BE
REPLACED
<!-- spec_insert_end -->

----------------------------------------

TITLE: Disabling _source in Search Query
DESCRIPTION: Example of how to disable _source field retrieval in a search request to minimize data transfer.

LANGUAGE: json
CODE:
{
    "_source": false,
    "query": {
        "match_all": {}
  }
}

----------------------------------------

TITLE: Defining a Document Corpus in JSON for OpenSearch Benchmark
DESCRIPTION: This snippet demonstrates how to define a single corpus named 'movies' with 11,658,903 documents and 1,544,799,789 uncompressed bytes in the JSON configuration for an OpenSearch Benchmark workload.

LANGUAGE: json
CODE:
  "corpora": [
    {
      "name": "movies",
      "documents": [
        {
          "source-file": "movies-documents.json",
          "document-count": 11658903,
          "uncompressed-bytes": 1544799789
        }
      ]
    }
  ]

----------------------------------------

TITLE: Creating a connector for Amazon Bedrock Rerank API in OpenSearch
DESCRIPTION: This JSON request creates a connector in OpenSearch for the Amazon Bedrock Rerank API, specifying the necessary credentials, parameters, and actions.

LANGUAGE: json
CODE:
POST /_plugins/_ml/connectors/_create
{
  "name": "Amazon Bedrock Rerank API",
  "description": "Test connector for Amazon Bedrock Rerank API",
  "version": 1,
  "protocol": "aws_sigv4",
  "credential": {
    "access_key": "your_access_key",
    "secret_key": "your_secret_key",
    "session_token": "your_session_token"
  },
  "parameters": {
    "service_name": "bedrock",
    "endpoint": "bedrock-agent-runtime",
    "region": "your_bedrock_model_region_like_us-west-2",
    "api_name": "rerank",
    "model_id": "amazon.rerank-v1:0"
  },
  "actions": [
    {
      "action_type": "PREDICT",
      "method": "POST",
      "url": "https://${parameters.endpoint}.${parameters.region}.amazonaws.com/${parameters.api_name}",
      "headers": {
        "x-amz-content-sha256": "required",
        "content-type": "application/json"
      },
      "pre_process_function": "connector.pre_process.bedrock.rerank",
      "request_body": """
        {
          "queries": ${parameters.queries},
          "rerankingConfiguration": {
            "bedrockRerankingConfiguration": {
              "modelConfiguration": {
                "modelArn": "arn:aws:bedrock:${parameters.region}::foundation-model/${parameters.model_id}"
              }
            },
            "type": "BEDROCK_RERANKING_MODEL"
          },
          "sources": ${parameters.sources}
        }
      """,
      "post_process_function": "connector.post_process.bedrock.rerank"
    }
  ]
}

----------------------------------------

TITLE: Inserting Vector Data into OpenSearch Index
DESCRIPTION: This code snippet shows how to insert multiple documents with vector data into the previously created OpenSearch index using the bulk API.

LANGUAGE: json
CODE:
POST _bulk
{ "index": { "_index": "my-knn-index-1", "_id": "1" } }
{ "my_vector1": [1.5, 2.5], "price": 12.2 }
{ "index": { "_index": "my-knn-index-1", "_id": "2" } }
{ "my_vector1": [2.5, 3.5], "price": 7.1 }
{ "index": { "_index": "my-knn-index-1", "_id": "3" } }
{ "my_vector1": [3.5, 4.5], "price": 12.9 }
{ "index": { "_index": "my-knn-index-1", "_id": "4" } }
{ "my_vector1": [5.5, 6.5], "price": 1.2 }
{ "index": { "_index": "my-knn-index-1", "_id": "5" } }
{ "my_vector1": [4.5, 5.5], "price": 3.7 }
{ "index": { "_index": "my-knn-index-1", "_id": "6" } }
{ "my_vector2": [1.5, 5.5, 4.5, 6.4], "price": 10.3 }
{ "index": { "_index": "my-knn-index-1", "_id": "7" } }
{ "my_vector2": [2.5, 3.5, 5.6, 6.7], "price": 5.5 }
{ "index": { "_index": "my-knn-index-1", "_id": "8" } }
{ "my_vector2": [4.5, 5.5, 6.7, 3.7], "price": 4.4 }
{ "index": { "_index": "my-knn-index-1", "_id": "9" } }
{ "my_vector2": [1.5, 5.5, 4.5, 6.4], "price": 8.9 }

----------------------------------------

TITLE: Updating Custom Log Type in OpenSearch Security Analytics
DESCRIPTION: This API request updates an existing custom log type. It uses a PUT request to the /_plugins/_security_analytics/logtype/<log_type_id> endpoint, specifying the log type ID in the URL.

LANGUAGE: json
CODE:
PUT /_plugins/_security_analytics/logtype/m98uk4kBlb9cbROIpEj2
{
  "name": "custom-log-type4",
  "description": "custom-log-type-updated-desc",
  "source": "Custom"
}

----------------------------------------

TITLE: Post-filter Parameter with k-NN Search in OpenSearch
DESCRIPTION: Demonstrates using the post_filter parameter with a k-NN search to filter results based on price range. The query shows how post-filtering can reduce the number of returned results from the initial k-NN search.

LANGUAGE: json
CODE:
GET my-knn-index-1/_search
{
  "size": 2,
  "query": {
    "knn": {
      "my_vector2": {
        "vector": [2, 3, 5, 6],
        "k": 2
      }
    }
  },
  "post_filter": {
    "range": {
      "price": {
        "gte": 5,
        "lte": 10
      }
    }
  }
}

----------------------------------------

TITLE: Installing Ruby using RVM for OpenSearch Documentation
DESCRIPTION: Commands to install Ruby using RVM (Ruby Version Manager) for the OpenSearch documentation project. This sets up the required Ruby environment for building the documentation website.

LANGUAGE: shell
CODE:
curl -sSL https://get.rvm.io | bash -s stable
rvm install 3.3.2
ruby -v

----------------------------------------

TITLE: Using function_score Query for Document-Specific Features in OpenSearch
DESCRIPTION: Shows how to incorporate document-specific features like popularity using the function_score query. This example uses the 'vote_average' field as a feature to influence the document score.

LANGUAGE: json
CODE:
{
    "query": {
        "function_score": {
            "functions": [{
                "field_value_factor": {
                    "field": "vote_average",
                    "missing": 0
                }
            }],
            "query": {
                "match_all": {}
            }
        }
    }
}

----------------------------------------

TITLE: Configuring OpenSearch CLI Profiles
DESCRIPTION: This YAML snippet shows how to configure multiple profiles for OpenSearch CLI in the config.yaml file, including basic authentication and AWS IAM authentication.

LANGUAGE: yaml
CODE:
profiles:
    - name: docker-local
      endpoint: https://localhost:9200
      user: admin
      password: foobar
    - name: aws
      endpoint: https://some-cluster.us-east-1.es.amazonaws.com
      aws_iam:
        profile: ""
        service: es

----------------------------------------

TITLE: Output JSON Event Example
DESCRIPTION: Sample JSON output event after the delete_entries processor removes the specified message field.

LANGUAGE: json
CODE:
{"message2": "goodbye"}

----------------------------------------

TITLE: Analyzing Text with WordNet Synonym Analyzer in OpenSearch
DESCRIPTION: This request examines the tokens generated using the previously defined WordNet synonym analyzer. It analyzes the text 'I have a fast car' to showcase how WordNet synonyms are applied.

LANGUAGE: json
CODE:
GET /my-wordnet-index/_analyze
{
  "analyzer": "my_wordnet_analyzer",
  "text": "I have a fast car"
}

----------------------------------------

TITLE: Inline Operations Definition in OpenSearch Benchmark Schedule
DESCRIPTION: Example demonstrating how to define operations directly within the schedule element instead of using separate operation definitions.

LANGUAGE: yaml
CODE:
{
  "schedule": [
    {
      "operation": {
        "name": "force-merge",
        "operation-type": "force-merge"
      },
      "clients": 1
    },
    {
      "operation": {
        "name": "match-all-query",
        "operation-type": "search",
        "body": {
          "query": {
            "match_all": {}
          }
        }
      },
      "clients": 4,
      "warmup-iterations": 1000,
      "iterations": 1000,
      "target-throughput": 100
    }
  ]
}

----------------------------------------

TITLE: Configuring ML Cluster Settings
DESCRIPTION: Updates OpenSearch cluster settings to enable ML capabilities and agent framework

LANGUAGE: json
CODE:
{
    "persistent": {
        "plugins.ml_commons.only_run_on_ml_node": false,
        "plugins.ml_commons.native_memory_threshold": 100,
        "plugins.ml_commons.agent_framework_enabled": true
    }
}

----------------------------------------

TITLE: Disabling Flatten in list_to_map Processor
DESCRIPTION: YAML configuration showing how to set flatten to false in the list_to_map processor, resulting in list outputs for values.

LANGUAGE: yaml
CODE:
pipeline:
  source:
    file:
      path: "/full/path/to/logs_json.log"
      record_type: "event"
      format: "json"
  processor:
    - list_to_map:
        key: "name"
        source: "mylist"
        target: "mymap"
        value_key: "value"
        flatten: false
  sink:
    - stdout:

----------------------------------------

TITLE: Inserting Binary Data into OpenSearch Index
DESCRIPTION: This code inserts documents with base64-encoded binary data and keyword data into the OpenSearch index using the bulk API.

LANGUAGE: json
CODE:
POST _bulk
{ "index": { "_index": "my-index", "_id": "1" } }
{ "my_binary": "SGVsbG8gV29ybGQh", "color" : "RED" }
{ "index": { "_index": "my-index", "_id": "2" } }
{ "my_binary": "ay1OTiBjdXN0b20gc2NvcmluZyE=", "color" : "RED" }
{ "index": { "_index": "my-index", "_id": "3" } }
{ "my_binary": "V2VsY29tZSB0byBrLU5O", "color" : "RED" }
{ "index": { "_index": "my-index", "_id": "4" } }
{ "my_binary": "SSBob3BlIHRoaXMgaXMgaGVscGZ1bA==", "color" : "BLUE" }
{ "index": { "_index": "my-index", "_id": "5" } }
{ "my_binary": "QSBjb3VwbGUgbW9yZSBkb2NzLi4u", "color" : "BLUE" }
{ "index": { "_index": "my-index", "_id": "6" } }
{ "my_binary":  "TGFzdCBvbmUh", "color" : "BLUE" }

----------------------------------------

TITLE: Adding sample documents to the logs index
DESCRIPTION: Adds sample log documents to the 'logs' index using bulk API, containing request and client IP information.

LANGUAGE: json
CODE:
POST _bulk
{ "index" : { "_index" : "logs", "_id" : "1" } }
{ "request": "894030400 GET /english/images/france98_venues.gif HTTP/1.0 200 778", "clientip": "61.177.2.0" }
{ "index" : { "_index" : "logs", "_id" : "2" } }
{ "request": "894140400 GET /french/playing/mascot/mascot.html HTTP/1.1 200 5474", "clientip": "185.92.2.0" }
{ "index" : { "_index" : "logs", "_id" : "3" } }
{ "request": "894250400 POST /english/venues/images/venue_header.gif HTTP/1.0 200 711", "clientip": "61.177.2.0" }
{ "index" : { "_index" : "logs", "_id" : "4" } }
{ "request": "894360400 POST /images/home_fr_button.gif HTTP/1.1 200 2140", "clientip": "129.178.2.0" }
{ "index" : { "_index" : "logs", "_id" : "5" } }
{ "request": "894470400 DELETE /images/102384s.gif HTTP/1.0 200 785", "clientip": "227.177.2.0" }

----------------------------------------

TITLE: Creating RAG Search Pipeline in OpenSearch
DESCRIPTION: JSON configuration for creating a search pipeline with RAG processor that uses the DeepSeek model for query augmentation.

LANGUAGE: json
CODE:
{
  "response_processors": [
    {
      "retrieval_augmented_generation": {
        "tag": "Demo pipeline",
        "description": "Demo pipeline Using DeepSeek Chat",
        "model_id": "VSlKsZQBts7fa6bypR02",
        "context_field_list": [
          "text"
        ],
        "system_prompt": "You are a helpful assistant.",
        "user_instructions": "Generate a concise and informative answer in less than 100 words for the given question"
      }
    }
  ]
}

----------------------------------------

TITLE: Register Conversational Flow Agent - Example Request
DESCRIPTION: Example request body for registering a conversational flow agent for population data analysis with vector database and ML model tools.

LANGUAGE: json
CODE:
{
  "name": "population data analysis agent",
  "type": "conversational_flow",
  "description": "This is a demo agent for population data analysis",
  "app_type": "rag",
  "memory": {
    "type": "conversation_index"
  },
  "tools": [
    {
      "type": "VectorDBTool",
      "name": "population_knowledge_base",
      "parameters": {
        "model_id": "your_text_embedding_model_id",
        "index": "test_population_data",
        "embedding_field": "population_description_embedding",
        "source_field": [
          "population_description"
        ],
        "input": "${parameters.question}"
      }
    },
    {
      "type": "MLModelTool",
      "name": "bedrock_claude_model",
      "description": "A general tool to answer any question",
      "parameters": {
        "model_id": "your_LLM_model_id",
        "prompt": "\n\nH:You are a professional data analysist. You will always answer question based on the given context first. If the answer is not directly shown in the context, you will analyze the data and find the answer. If you don't know the answer, just say don't know. \n\nContext:\n${parameters.population_knowledge_base.output:-}\n\n${parameters.chat_history:-}\n\nH:${parameters.question}\n\nA:"
      }
    }
  ]
}

----------------------------------------

TITLE: Markdown Front Matter Configuration
DESCRIPTION: YAML front matter configuration for the documentation page, defining layout, title, navigation order, and redirect paths.

LANGUAGE: yaml
CODE:
---
layout: default
title: Time filter
parent: Analyzing data
nav_order: 20
redirect_from:
  - /dashboards/get-started/time-filter/
  - /dashboards/discover/time-filter/
---

----------------------------------------

TITLE: Testing Copy Pipeline
DESCRIPTION: Example request to test the copy pipeline with a sample document containing nested content.

LANGUAGE: json
CODE:
{
  "docs": [
    {
      "_index": "testindex1",
      "_id": "1",
      "_source":{
         "message": {
          "content": {
            "foo": "bar",
            "zoo": [1, 2, 3]
          }
         }
      }
    }
  ]
}

----------------------------------------

TITLE: Running a Basic RAG Search in OpenSearch
DESCRIPTION: This snippet demonstrates how to perform a basic RAG search without storing conversation history. It uses the search pipeline created earlier and includes generative QA parameters.

LANGUAGE: json
CODE:
GET /qa_demo/_search?search_pipeline=my-conversation-search-pipeline-openai
{
  "query": {
    "match": {
      "text": "What's the population increase of New York City from 2021 to 2023?"
    }
  },
  "size": 1,
  "_source": [
    "text"
  ],
  "ext": {
    "generative_qa_parameters": {
      "llm_model": "gpt-4o",
      "llm_question": "What's the population increase of New York City from 2021 to 2023?",
      "context_size": 5,
      "timeout": 15
    }
  }
}

----------------------------------------

TITLE: Checking Cluster Health in YAML for OpenSearch Benchmark
DESCRIPTION: Defines a cluster-health operation to check the health status of 'logs-*' indices. It waits for a green status and no relocating shards, with retry functionality enabled.

LANGUAGE: yaml
CODE:
{
  "name": "check-cluster-green",
  "operation-type": "cluster-health",
  "index": "logs-*",
  "request-params": {
    "wait_for_status": "green",
    "wait_for_no_relocating_shards": "true"
  },
  "retry-until-success": true
}

----------------------------------------

TITLE: Executing Terms Set Query with Script-Based Matching
DESCRIPTION: Shows how to use a script to determine minimum matching terms in a terms set query. Demonstrates dynamic calculation of match requirements.

LANGUAGE: json
CODE:
GET students/_search
{
  "query": {
    "terms_set": {
      "classes": {
        "terms": [ "CS101", "CS102", "MATH101" ],
        "minimum_should_match_script": {
          "source": "Math.min(params.num_terms, doc['min_required'].value)"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Markdown Page Configuration with YAML Frontmatter
DESCRIPTION: Jekyll page configuration that defines the structure and navigation properties of the generative AI tutorials landing page, including card definitions for different tutorial sections.

LANGUAGE: yaml
CODE:
---
layout: default
title: Generative AI
has_children: true
has_toc: false
nav_order: 30
redirect_from:
  - /tutorials/gen-ai/
cards:
  - heading: "RAG"
    description: "Build retrieval-augmented generation and conversational search applications"
    link: "/tutorials/gen-ai/rag/"
  - heading: "Chatbots and agents"
    description: "Build your generative AI application using chatbots and agents"
    link: "/tutorials/gen-ai/chatbots/"
  - heading: "AI search workflows"
    link: "/tutorials/gen-ai/ai-search-flows/"
    description: "Build and configure AI search applications visually in OpenSearch Dashboards"   
  - heading: "Model guardrails"
    description: "Add safety boundaries to your models to ensure controlled responses"
    link: "/tutorials/gen-ai/model-controls/"
---

----------------------------------------

TITLE: Creating RAG Search Pipeline in OpenSearch
DESCRIPTION: JSON request to create a search pipeline with a RAG processor using the DeepSeek-R1 model.

LANGUAGE: json
CODE:
PUT /_search/pipeline/my-conversation-search-pipeline-deepseek
{
  "response_processors": [
    {
      "retrieval_augmented_generation": {
        "tag": "Demo pipeline",
        "description": "Demo pipeline Using DeepSeek R1",
        "model_id": "heS7s5QBFSAM-Wczv7Kb",
        "context_field_list": [
          "text"
        ],
        "system_prompt": "You are a helpful assistant.",
        "user_instructions": "Generate a concise and informative answer in less than 100 words for the given question"
      }
    }
  ]
}

----------------------------------------

TITLE: Querying All Workflows in OpenSearch
DESCRIPTION: This snippet shows how to retrieve all created workflows using the Flow Framework API. It uses a GET request with a match_all query to return all workflows.

LANGUAGE: json
CODE:
GET /_plugins/_flow_framework/workflow/_search
{
  "query": {
    "match_all": {}
  }
}

----------------------------------------

TITLE: Assuming IAM Role for Connector Creation
DESCRIPTION: Uses AWS CLI to assume the IAM role created for connector creation, obtaining temporary credentials.

LANGUAGE: bash
CODE:
aws sts assume-role --role-arn arn:aws:iam::<your_aws_account_A>:role/my_create_connector_role_accountA --role-session-name your_session_name

----------------------------------------

TITLE: Get Workflow JSON Request
DESCRIPTION: cURL command example for retrieving a workflow template in JSON format by specifying the appropriate Content-Type header.

LANGUAGE: bash
CODE:
curl -XGET "http://localhost:9200/_plugins/_flow_framework/workflow/8xL8bowB8y25Tqfenm50" -H 'Content-Type: application/json'

----------------------------------------

TITLE: Configuring Search Backpressure Mode in OpenSearch
DESCRIPTION: Example request to configure search backpressure mode using the cluster settings API. Shows how to set the mode to 'monitor_only' using a PUT request.

LANGUAGE: json
CODE:
PUT /_cluster/settings
{
  "persistent": {
    "search_backpressure": {
      "mode": "monitor_only"
    }
  }
}

----------------------------------------

TITLE: Creating Vector Index and Ingest Pipeline for Semantic Search
DESCRIPTION: JSON requests to create a vector index and an ingest pipeline for generating document embeddings.

LANGUAGE: json
CODE:
PUT nyc_facts
{
  "settings": {
    "index": {
      "default_pipeline": "asymmetric_embedding_ingest_pipeline",
      "knn": true,
      "knn.algo_param.ef_search": 100
    }
  },
  "mappings": {
    "properties":  {
      "fact_embedding": {
        "type": "knn_vector",
        "dimension": 384,
        "method": {
          "name": "hnsw",
          "space_type": "l2",
          "engine": "nmslib",
          "parameters": {
            "ef_construction": 128,
            "m": 24
          }
        } 
      }
    }
  }
}

PUT _ingest/pipeline/asymmetric_embedding_ingest_pipeline
{
	"description": "ingest passage text and generate a embedding using an asymmetric model",
	"processors": [
		{
			"ml_inference": {

				"model_input": "{\"text_docs\":[\"${input_map.text_docs}\"],\"target_response\":[\"sentence_embedding\"],\"parameters\":{\"content_type\":\"query\"}}",
				"function_name": "text_embedding",
				"model_id": "{{ _.model_id }}",
				"input_map": [
					{
						"text_docs": "description"
					}
				],
				"output_map": [
					{
						"fact_embedding": "$.inference_results[0].output[0].data",
						"embedding_size": "$.inference_results.*.output.*.shape[0]"
					}
				]
			}
		}
	]
}

----------------------------------------

TITLE: Execute Benchmark Test with Expanded Corpus - Bash
DESCRIPTION: Command to run OpenSearch Benchmark test using the newly generated corpus, with the generated_corpus parameter set to true.

LANGUAGE: bash
CODE:
opensearch-benchmark execute-test --workload http_logs --workload-params=generated_corpus:t [other_options]

----------------------------------------

TITLE: Example Response for OpenSearch Index Settings API
DESCRIPTION: This snippet shows a sample response from the index settings API, including creation date, number of shards and replicas, and version information.

LANGUAGE: json
CODE:
{
  "sample-index1": {
    "settings": {
      "index": {
        "creation_date": "1622672553417",
        "number_of_shards": "1",
        "number_of_replicas": "1",
        "uuid": "GMEA0_TkSaamrnJSzNLzwg",
        "version": {
          "created": "135217827",
          "upgraded": "135238227"
        },
        "provided_name": "sample-index1"
      }
    }
  }
}

----------------------------------------

TITLE: Creating Ingest Pipeline for Text Embedding
DESCRIPTION: This JSON request creates an ingest pipeline in OpenSearch that uses the Bedrock Cohere model to generate embeddings from input text.

LANGUAGE: json
CODE:
PUT /_ingest/pipeline/my_bedrock_cohere_embedding_pipeline
{
    "description": "text embedding pipeline",
    "processors": [
        {
            "text_embedding": {
                "model_id": "your_bedrock_embedding_model_id_created_in_step4",
                "field_map": {
                    "text": "text_knn"
                }
            }
        }
    ]
}

----------------------------------------

TITLE: Configuring YAML Frontmatter for OpenSearch Model Guardrails Page
DESCRIPTION: YAML configuration for the Jekyll-based documentation page. It sets the layout, title, parent category, navigation order, and redirects for the model guardrails tutorials page in OpenSearch documentation.

LANGUAGE: yaml
CODE:
---
layout: default
title: Model guardrails
parent: Generative AI
has_children: true
has_toc: false
nav_order: 40
redirect_from:
  - /vector-search/tutorials/model-controls/
  - /tutorials/gen-ai/model-controls/
model_controls:
  - heading: Amazon Bedrock guardrails
    link: /tutorials/gen-ai/model-controls/bedrock-guardrails/
    list:
      - "<b>Platform:</b> OpenSearch"
      - "<b>Model:</b> Anthropic Claude"
      - "<b>Deployment:</b> Amazon Bedrock"
---

----------------------------------------

TITLE: OpenTelemetry Histogram Representation
DESCRIPTION: JSON structure showing the OpenTelemetry-specific representation of histogram data with explicit bounds and bucket counts.

LANGUAGE: json
CODE:
"explicitBounds": [
    5.0,
    10.0
  ],
   "bucketCountsList": [
    2,
    5
  ]

----------------------------------------

TITLE: Update Query Group Request Example
DESCRIPTION: Example request for updating an existing query group named 'analytics' with modified resiliency mode and resource limits.

LANGUAGE: json
CODE:
PUT _wlm/query_group/analytics
{
  "resiliency_mode": "monitor",
  "resource_limits": {
    "cpu": 0.41,
    "memory": 0.21
  }
}

----------------------------------------

TITLE: Human-Readable Output Request in OpenSearch
DESCRIPTION: Makes a GET request to search an index with human-readable output enabled using the human=true parameter.

LANGUAGE: json
CODE:
GET <index_name>/_search?human=true

----------------------------------------

TITLE: Configuring Stem Exclusion for Norwegian Analyzer in OpenSearch
DESCRIPTION: This snippet shows how to use stem exclusion with the Norwegian analyzer by creating a custom analyzer with specific words excluded from stemming.

LANGUAGE: json
CODE:
PUT index_with_stem_exclusion_norwegian_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "stem_exclusion_norwegian_analyzer": {
          "type": "norwegian",
          "stem_exclusion": ["autoritet", "godkjenning"]
        }
      }
    }
  }
}

----------------------------------------

TITLE: Querying Basic Stats in OpenSearch
DESCRIPTION: Demonstrates how to perform a stats aggregation on the taxful_total_price field to get basic statistical metrics. The query returns min, max, sum, average, and count values in a single request.

LANGUAGE: json
CODE:
GET opensearch_dashboards_sample_data_ecommerce/_search
{
  "size": 0,
  "aggs": {
    "stats_taxful_total_price": {
      "stats": {
        "field": "taxful_total_price"
      }
    }
  }
}

LANGUAGE: json
CODE:
"aggregations" : {
  "stats_taxful_total_price" : {
    "count" : 4675,
    "min" : 6.98828125,
    "max" : 2250.0,
    "avg" : 75.05542864304813,
    "sum" : 350884.12890625
  }
}

----------------------------------------

TITLE: Example Request for Index Existence Check in OpenSearch
DESCRIPTION: This example shows how to make a request to check if an index named 'sample-index' exists in OpenSearch using the HEAD method.

LANGUAGE: json
CODE:
HEAD /sample-index

----------------------------------------

TITLE: Creating IAM Role Trust Policy for Bedrock Access
DESCRIPTION: This JSON snippet defines the trust policy for an IAM role that allows the OpenSearch service to assume the role for accessing Bedrock.

LANGUAGE: json
CODE:
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Principal": {
                "Service": "es.amazonaws.com"
            },
            "Action": "sts:AssumeRole"
        }
    ]
}

----------------------------------------

TITLE: Pulling OpenSearch Benchmark Docker Image from Docker Hub
DESCRIPTION: Downloads the latest OpenSearch Benchmark Docker image from Docker Hub.

LANGUAGE: bash
CODE:
docker pull opensearchproject/opensearch-benchmark:latest

----------------------------------------

TITLE: Retrieving OpenSearch Cat Aliases with Query Parameter
DESCRIPTION: This example shows how to use a query parameter with the cat aliases API to get verbose output of alias information.

LANGUAGE: json
CODE:
GET _cat/aliases?v

----------------------------------------

TITLE: Cache Statistics Query Example
DESCRIPTION: Example query retrieving request cache statistics from the caches metric.

LANGUAGE: json
CODE:
GET _nodes/stats/caches/request_cache

----------------------------------------

TITLE: Simple Term Query for Semantic Search
DESCRIPTION: Basic term query structure for searching items based on text matches.

LANGUAGE: json
CODE:
{
    "query": {
        "term": {
            "item_text": {
                "value": "shoes"
            }
        }
    }
}

----------------------------------------

TITLE: Stopping OpenSearch Backfill Process
DESCRIPTION: Command to stop the backfill process and shut down all workers after data migration is complete.

LANGUAGE: bash
CODE:
console backfill stop

----------------------------------------

TITLE: Page Configuration in YAML Front Matter
DESCRIPTION: YAML configuration block defining the page layout, navigation, redirects and storage optimization cards for the documentation.

LANGUAGE: yaml
CODE:
---
layout: default
title: Optimizing vector storage
nav_order: 60
has_children: true
has_toc: false
redirect_from:
  - /vector-search/optimizing-storage/
storage_cards:
  - heading: "Vector quantization"
    description: "Reduce vector storage space by quantizing vectors"
    link: "/vector-search/optimizing-storage/knn-vector-quantization/"
  - heading: "Disk-based vector search"
    description: "Uses binary quantization to reduce the operational costs of vector workloads"
    link: "/vector-search/optimizing-storage/disk-based-vector-search/"
---

----------------------------------------

TITLE: Filtered Geohex Grid Query
DESCRIPTION: Demonstrates a geohex grid aggregation with geographical boundary filtering using geo_bounding_box.

LANGUAGE: json
CODE:
{
  "size" : 0,  
  "aggregations": {
    "filtered": {
      "filter": {
        "geo_bounding_box": {
          "location": {
            "top_left": "38, -120",
            "bottom_right": "36, -116"
          }
        }
      },
      "aggregations": {
        "grouped": {
          "geohex_grid": {
            "field": "location",
            "precision": 6
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Matrix Stats Query Example in OpenSearch
DESCRIPTION: Example query demonstrating how to calculate matrix statistics for taxful_total_price and products.base_price fields using the matrix_stats aggregation.

LANGUAGE: json
CODE:
{
  "size": 0,
  "aggs": {
    "matrix_stats_taxful_total_price": {
      "matrix_stats": {
        "fields": ["taxful_total_price", "products.base_price"]
      }
    }
  }
}

----------------------------------------

TITLE: Training Model-based Vector Index
DESCRIPTION: Creates a model-based vector index using the training API with disk-based optimization.

LANGUAGE: json
CODE:
POST /_plugins/_knn/models/test-model/_train
{
    "training_index": "train-index-name",
    "training_field": "train-field-name",
    "dimension": 8,
    "max_training_vector_count": 1200,
    "search_size": 100,
    "description": "My model",
    "space_type": "innerproduct",
    "mode": "on_disk"
}

----------------------------------------

TITLE: Recording Data Stream Stats with Telemetry Device in OpenSearch
DESCRIPTION: Example JSON output from the data-stream-stats telemetry device, showing cluster-level stats and individual data stream metrics.

LANGUAGE: json
CODE:
{
  "data_streams" : [
    {
      "name" : "logs-nginx",
      "timestamp_field" : {
        "name" : "request_time"
      },
      "indices" : [
        {
          "index_name" : ".ds-logs-nginx-000001",
          "index_uuid" : "-VhmuhrQQ6ipYCmBhn6vLw"
        }
      ],
      "generation" : 1,
      "status" : "GREEN",
      "template" : "logs-template-nginx"
    }
  ]
},
{
  "name": "data-stream-stats",
  "data_stream": "my-data-stream-1",
  "backing_indices": 1,
  "store_size_bytes": 439137,
  "maximum_timestamp": 1579936446448
},
{
  "name": "data-stream-stats",
  "data_stream": "my-data-stream-2",
  "backing_indices": 1,
  "store_size_bytes": 439199,
  "maximum_timestamp": 1579936446448
}

----------------------------------------

TITLE: Configuring IAM Trust Policy for OpenSearch
DESCRIPTION: JSON policy defining trust relationship allowing OpenSearch service to assume the role

LANGUAGE: json
CODE:
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Principal": {
                "Service": "es.amazonaws.com"
            },
            "Action": "sts:AssumeRole"
        }
    ]
}

----------------------------------------

TITLE: Configuring parse_json Processor with JSON Pointer in YAML
DESCRIPTION: YAML configuration for the parse_json processor using a JSON pointer. This setup extracts a specific nested field ('inner_key') from the JSON data in the 'message' field.

LANGUAGE: yaml
CODE:
parse-json-pipeline:
  source:
    ...
  ....  
  processor:
    - parse_json:
        pointer: "outer_key/inner_key"

----------------------------------------

TITLE: Checking Snapshot Status in OpenSearch Migration Console
DESCRIPTION: This command runs a detailed check on the snapshot creation status, including estimated completion time.

LANGUAGE: sh
CODE:
console snapshot status --deep-check

----------------------------------------

TITLE: Example Response for OpenSearch Reindex API
DESCRIPTION: This snippet demonstrates a sample response from the reindex API, including statistics about the reindexing operation such as documents processed and time taken.

LANGUAGE: json
CODE:
{
  "took" : 4,
  "timed_out" : false,
  "total" : 0,
  "updated" : 0,
  "created" : 0,
  "deleted" : 0,
  "batches" : 0,
  "version_conflicts" : 0,
  "noops" : 0,
  "retries" : {
    "bulk" : 0,
    "search" : 0
  },
  "throttled_millis" : 0,
  "requests_per_second" : -1.0,
  "throttled_until_millis" : 0,
  "failures" : [ ]
}

----------------------------------------

TITLE: Script Language Response Structure in OpenSearch
DESCRIPTION: Example response showing the supported script types and language contexts, including available contexts for expression, mustache, opensearch_query_expression, and painless languages.

LANGUAGE: json
CODE:
{
  "types_allowed" : [
    "inline",
    "stored"
  ],
  "language_contexts" : [
    {
      "language" : "expression",
      "contexts" : [
        "aggregation_selector",
        "aggs",
        "bucket_aggregation",
        "field",
        "filter",
        "number_sort",
        "score",
        "terms_set"
      ]
    },
    {
      "language" : "mustache",
      "contexts" : [
        "template"
      ]
    },
    {
      "language" : "opensearch_query_expression",
      "contexts" : [
        "aggs",
        "filter"
      ]
    },
    {
      "language" : "painless",
      "contexts" : [
        "aggregation_selector",
        "aggs",
        "aggs_combine",
        "aggs_init",
        "aggs_map",
        "aggs_reduce",
        "analysis",
        "bucket_aggregation",
        "field",
        "filter",
        "ingest",
        "interval",
        "moving-function",
        "number_sort",
        "painless_test",
        "processor_conditional",
        "score",
        "script_heuristic",
        "similarity",
        "similarity_weight",
        "string_sort",
        "template",
        "terms_set",
        "trigger",
        "update"
      ]
    }
  ]
}

----------------------------------------

TITLE: Registering Model with Connector
DESCRIPTION: Registers a model using the previously created connector, requiring the connector_id from the previous step.

LANGUAGE: yaml
CODE:
- id: register_model_2
  type: register_remote_model
  previous_node_inputs:
    create_connector_1: connector_id
  user_inputs:
    name: openAI-gpt-3.5-turbo
    function_name: remote
    description: test model

----------------------------------------

TITLE: Port Forwarding for OpenSearch Dashboards
DESCRIPTION: This command sets up port forwarding to access the OpenSearch Dashboards interface on localhost:5601.

LANGUAGE: bash
CODE:
kubectl port-forward svc/my-cluster-dashboards 5601

----------------------------------------

TITLE: Port Forwarding for OpenSearch Dashboards
DESCRIPTION: This command sets up port forwarding to access the OpenSearch Dashboards interface on localhost:5601.

LANGUAGE: bash
CODE:
kubectl port-forward svc/my-cluster-dashboards 5601

----------------------------------------

TITLE: OpenSearch Subject and Roles Configuration
DESCRIPTION: Configuration settings for specifying subject and roles keys in OpenSearch OpenID authentication.

LANGUAGE: yaml
CODE:
openid_auth_domain:
  enabled: true
  order: 1
  http_authenticator:
    type: "openid"
    ...
    config:
      subject_key: <subject key>
      roles_key: <roles key>
    ...

----------------------------------------

TITLE: Script for Converting PEM Certificates to Keystore and Truststore
DESCRIPTION: Bash script to convert PEM certificates to Java keystore and truststore files for use with OpenSearch.

LANGUAGE: bash
CODE:
#!/bin/sh

# Convert node certificate
cat root-ca.pem node1.pem node1-key.pem > combined-node1.pem
echo "Enter password for node1-cert.p12"
openssl pkcs12 -export -in combined-node1.pem -out node1-cert.p12 -name node1
echo "Enter password for keystore.jks"
keytool -importkeystore -srckeystore node1-cert.p12 -srcstoretype pkcs12 -destkeystore keystore.jks

# Convert admin certificate
cat root-ca.pem admin.pem admin-key.pem > combined-admin.pem
echo "Enter password for admin-cert.p12"
openssl pkcs12 -export -in combined-admin.pem -out admin-cert.p12 -name admin
echo "Enter password for keystore.jks"
keytool -importkeystore -srckeystore admin-cert.p12 -srcstoretype pkcs12 -destkeystore keystore.jks

# Import certificates to truststore
keytool -importcert -keystore truststore.jks -file root-ca.cer -storepass changeit -trustcacerts -deststoretype pkcs12

# Cleanup
rm combined-admin.pem
rm combined-node1.pem

----------------------------------------

TITLE: Tracking user events for a specific query
DESCRIPTION: SQL query to retrieve all events associated with a particular query_id from the ubi_events table, ordered by timestamp.

LANGUAGE: sql
CODE:
select 
 application, query_id, action_name, message_type, message, client_id, timestamp
from ubi_events
where query_id = '7ae52966-4fd4-4ab1-8152-0fd0b52bdadf'
order by timestamp

----------------------------------------

TITLE: Implementing UBI Event Data Structures in JavaScript
DESCRIPTION: Core classes for creating UBI-compliant event objects. Includes UbiEventData for object metadata, UbiPosition for tracking event positions, UbiEventAttributes for event context, and UbiEvent for the main event structure.

LANGUAGE: javascript
CODE:
export class UbiEventData {
  constructor(object_type, id=null, description=null, details=null) {
    this.object_id_field = object_type;
    this.object_id = id;
    this.description = description;
    this.object_detail = details;
  }
}
export class UbiPosition{
  constructor({ordinal=null, x=null, y=null, trail=null}={}) {
    this.ordinal = ordinal;
    this.x = x;
    this.y = y;
    if(trail)
      this.trail = trail;
    else {
      const trail = getTrail();
      if(trail && trail.length > 0)
        this.trail = trail;
    }
  }
}


export class UbiEventAttributes {
  constructor({attributes={}, object=null, position=null}={}) {
    if(attributes != null){
      Object.assign(this, attributes);
    }
    if(object != null && Object.keys(object).length > 0){
      this.object = object;
    }
    if(position != null && Object.keys(position).length > 0){
      this.position = position;
    }
    this.setDefaultValues();
  }

  setDefaultValues(){
    try{
        if(!this.hasOwnProperty('dwell_time') && typeof TimeMe !== 'undefined'){
          this.dwell_time = TimeMe.getTimeOnPageInSeconds(window.location.pathname);
        }

        if(!this.hasOwnProperty('browser')){
          this.browser = window.navigator.userAgent;
        }

        if(!this.hasOwnProperty('page_id')){
          this.page_id = window.location.pathname;
        }
        if(!this.hasOwnProperty('session_id')){
          this.session_id = getSessionId();
        }

        if(!this.hasOwnProperty('page_id')){
          this.page_id = getPageId();
        }

        if(!this.hasOwnProperty('position') || this.position == null){
          const trail = getTrail();
          if(trail.length > 0){
            this.position = new UbiPosition({trail:trail});
          }
        } 
    }
    catch(error){
      console.log(error);
    }
  }
}



export class UbiEvent {
  constructor(action_name, {message_type='INFO', message=null, event_attributes={}, data_object={}}={}) {
    this.action_name = action_name;
    this.client_id = getClientId();
    this.query_id = getQueryId();
    this.timestamp = Date.now();

    this.message_type = message_type;
    if( message )
      this.message = message;

    this.event_attributes = new UbiEventAttributes({attributes:event_attributes, object:data_object});
  }

  static replacer(key, value){
    if(value == null || 
      (value.constructor == Object && Object.keys(value).length === 0)) {
      return undefined;
    }
    return value;
  }

  toJson() {
    return JSON.stringify(this, UbiEvent.replacer);
  }
}

----------------------------------------

TITLE: Advanced OpenSearch Source Configuration (YAML)
DESCRIPTION: Complete configuration example including indices filtering, scheduling, search options and connection settings.

LANGUAGE: yaml
CODE:
opensearch-source-pipeline:
  source:
    opensearch:
      hosts: [ "https://localhost:9200" ]
      username: "username"
      password: "password"
      indices:
        include:
          - index_name_regex: "test-index-.*"
        exclude:
          - index_name_regex: "\..*"
      scheduling:
        interval: "PT1H"
        index_read_count: 2
        start_time: "2023-06-02T22:01:30.00Z"
      search_options:
        search_context_type: "none"
        batch_size: 1000
      connection:
        insecure: false
        cert: "/path/to/cert.crt"
  ...

----------------------------------------

TITLE: Documenting Query Parameters for OpenSearch Search API (Simplified)
DESCRIPTION: This snippet presents a simplified markdown table for query parameters in the OpenSearch search API, focusing only on the parameter names and descriptions. It includes information on 'analyze_wildcard', 'analyzer', and 'expand_wildcards'.

LANGUAGE: markdown
CODE:
| Parameter | Description |
| :--- | :--- |
| `analyze_wildcard` | **(Required)** If true, wildcard and prefix queries are analyzed. This parameter can only be used when the q query string parameter is specified. _(Default: `false`)_ |
| `analyzer` | Analyzer to use for the query string. This parameter can only be used when the q query string parameter is specified. |
| `expand_wildcards` | Comma-separated list of expand wildcard options. <br> Valid values are: `open`, `closed`, `none`, `all` |

----------------------------------------

TITLE: Highlighting Suggestions in OpenSearch Phrase Suggester
DESCRIPTION: Shows how to set up highlighting for suggestions in the phrase suggester response using pre_tag and post_tag options.

LANGUAGE: json
CODE:
GET books2/_search
{
  "suggest": {
    "phrase-check": {
      "text": "design paterns",
      "phrase": {
        "field": "title.trigram",
        "gram_size": 3,
        "highlight": {
          "pre_tag": "<em>",
          "post_tag": "</em>"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Sample Response with Alerts
DESCRIPTION: Example response from the SearchAlertsTool showing alert details including monitor information, trigger status, and timing details.

LANGUAGE: json
CODE:
{
  "inference_results": [
    {
      "output": [
        {
          "name": "response",
          "result": "Alerts=[Alert(id=rv9nYo0Bk4MTqirc_DkW, version=394, schemaVersion=5, monitorId=ZuJnYo0B9RaBCvhuEVux, workflowId=, workflowName=, monitorName=test-monitor-2, monitorVersion=1, monitorUser=User[name=admin, backend_roles=[admin], roles=[own_index, all_access], custom_attribute_names=[], user_requested_tenant=null], triggerId=ZeJnYo0B9RaBCvhuEVul, triggerName=t-1, findingIds=[], relatedDocIds=[], state=ACTIVE, startTime=2024-02-01T02:03:18.420Z, endTime=null, lastNotificationTime=2024-02-01T08:36:18.409Z, acknowledgedTime=null, errorMessage=null, errorHistory=[], severity=1, actionExecutionResults=[], aggregationResultBucket=null, executionId=ZuJnYo0B9RaBCvhuEVux_2024-02-01T02:03:18.404853331_51c18f2c-5923-47c3-b476-0f5a66c6319b, associatedAlertIds=[])]TotalAlerts=1"
        }
      ]
    }
  ]
}

----------------------------------------

TITLE: Creating Notification Channel Configuration in OpenSearch
DESCRIPTION: Creates a new notification channel configuration by sending a POST request with channel details including name, type, and configuration settings.

LANGUAGE: json
CODE:
POST /_plugins/_notifications/configs/
{
  "config_id": "sample-id",
  "name": "sample-name",
  "config": {
    "name": "Sample Slack Channel",
    "description": "This is a Slack channel",
    "config_type": "slack",
    "is_enabled": true,
    "slack": {
      "url": "https://sample-slack-webhook"
    }
  }
}

----------------------------------------

TITLE: Starting Traffic Replayer Commands
DESCRIPTION: Basic commands for starting, checking status, and stopping Traffic Replayer

LANGUAGE: bash
CODE:
console replay start
console replay status
console replay stop

----------------------------------------

TITLE: Querying Indices in Dev Tools Console
DESCRIPTION: Use this GET request in the Dev Tools console to retrieve a list of indices from a selected data source.

LANGUAGE: json
CODE:
GET /_cat/indices

----------------------------------------

TITLE: Configuring Uncompressed Logs with SQS
DESCRIPTION: YAML configuration for reading uncompressed newline-delimited logs using SQS notifications.

LANGUAGE: yaml
CODE:
source:
  s3:
    notification_type: sqs
    codec:
      newline:
    compression: none
    sqs:
      queue_url: "https://sqs.us-east-1.amazonaws.com/123456789012/MyQueue"
    aws:
      region: "us-east-1"
      sts_role_arn: "arn:aws:iam::123456789012:role/Data-Prepper"

----------------------------------------

TITLE: Configuring WMS Defaults in OpenSearch Dashboards JSON Settings
DESCRIPTION: This JSON snippet shows the configuration for enabling a custom Web Map Service (WMS) in OpenSearch Dashboards. It sets the 'enabled' flag to true and specifies the URL of the WMS server along with options for the image format and transparency.

LANGUAGE: json
CODE:
{
  "enabled": true,
  "url": "<wms-map-server-url>",
  "options": {
    "format": "image/png",
    "transparent": true
  }
}

----------------------------------------

TITLE: Getting Remote Store Stats for a Single Shard
DESCRIPTION: API endpoint to retrieve remote store statistics for a specific shard within an index. Returns detailed metrics about segment and translog transfers for the specified shard.

LANGUAGE: json
CODE:
GET _remotestore/stats/<index_name>/<shard_id>

----------------------------------------

TITLE: Downloading Sample Data Files for OpenSearch
DESCRIPTION: These bash commands use cURL to download sample e-commerce data files for OpenSearch. The first command downloads the field mappings JSON file, and the second downloads the NDJSON data file.

LANGUAGE: bash
CODE:
curl -O https://raw.githubusercontent.com/opensearch-project/documentation-website/{{site.opensearch_major_minor_version}}/assets/examples/ecommerce-field_mappings.json

LANGUAGE: bash
CODE:
curl -O https://raw.githubusercontent.com/opensearch-project/documentation-website/{{site.opensearch_major_minor_version}}/assets/examples/ecommerce.ndjson

----------------------------------------

TITLE: Querying Data in OpenSearch
DESCRIPTION: This JSON snippet shows how to use the Search API to query the 'ecommerce' index in OpenSearch. It demonstrates a match query to find documents where the 'customer_first_name' field is 'Sonya'.

LANGUAGE: json
CODE:
GET ecommerce/_search
{
  "query": {
    "match": {
      "customer_first_name": "Sonya"
    }
  }
}

----------------------------------------

TITLE: Importing OpenSearch GPG Key
DESCRIPTION: Import the public GNU Privacy Guard (GPG) key to verify the OpenSearch installation.

LANGUAGE: bash
CODE:
sudo rpm --import https://artifacts.opensearch.org/publickeys/opensearch.pgp

----------------------------------------

TITLE: Registering Flow Agent with CatIndexTool in OpenSearch
DESCRIPTION: Creates a flow agent that will execute the CatIndexTool to retrieve index information. The agent requires a name, type, description and tool configuration.

LANGUAGE: json
CODE:
{
  "name": "Test_Agent_For_CatIndex_tool",
  "type": "flow",
  "description": "this is a test agent for the CatIndexTool",
  "tools": [
    {
      "type": "CatIndexTool",
      "name": "DemoCatIndexTool",
      "parameters": {
        "input": "${parameters.question}"
      }
    }
  ]
}

----------------------------------------

TITLE: Frontmatter Configuration in Jekyll Markdown
DESCRIPTION: Jekyll frontmatter configuration for the ML Commons APIs documentation page, specifying layout settings, navigation properties, and redirect rules.

LANGUAGE: markdown
CODE:
---
layout: default
title: ML Commons APIs
has_children: false
nav_order: 130
has_children: true
has_toc: false
redirect_from:
  - /ml-commons-plugin/api/
---

----------------------------------------

TITLE: Get All Memories Example Response
DESCRIPTION: Example response showing the structure of multiple memory objects in a paginated response.

LANGUAGE: json
CODE:
{
  "memories": [
    {
      "memory_id": "gW8Aa40BfUsSoeNTvOKI",
      "create_time": "2024-02-02T18:07:06.887061463Z",
      "updated_time": "2024-02-02T19:01:32.121444968Z",
      "name": "Conversation for a RAG pipeline",
      "user": "admin"
    }
  ]
}

----------------------------------------

TITLE: Using minimum_should_match
DESCRIPTION: Example of using the minimum_should_match parameter in a query_string query.

LANGUAGE: json
CODE:
GET /testindex/_search
{
  "query": {
    "query_string": {
      "fields": [
        "description"
      ],
      "query": "historical epic film",
      "minimum_should_match": 2
    }
  }
}

----------------------------------------

TITLE: Method Parameters Search Query
DESCRIPTION: Example showing how to include method_parameters in a k-NN search query for fine-tuning search behavior.

LANGUAGE: json
CODE:
GET /my-vector-index/_search
{
  "size": 2,
  "query": {
    "knn": {
      "target-field": {
        "vector": [2, 3, 5, 6],
        "k": 2,
        "method_parameters" : {
          "ef_search": 100
        }
      }
    }
  }
}

----------------------------------------

TITLE: Indexing Documents for Terms Set Query
DESCRIPTION: Examples of indexing student documents with class lists and minimum match requirements. Shows how to structure documents with arrays and numeric fields.

LANGUAGE: json
CODE:
PUT students/_doc/1
{
  "name": "Mary Major",
  "classes": [ "CS101", "CS102", "MATH101" ],
  "min_required": 2
}

LANGUAGE: json
CODE:
PUT students/_doc/2
{
  "name": "John Doe",
  "classes": [ "CS101", "MATH101", "ENG101" ],
  "min_required": 2
}

----------------------------------------

TITLE: Building Docker Container for OpenSearch Reporting CLI
DESCRIPTION: Dockerfile configuration to create a container image for running the OpenSearch Reporting CLI in AWS Lambda. Sets up Node.js environment with necessary dependencies and Chrome for report generation.

LANGUAGE: dockerfile
CODE:
# Define function directory
ARG FUNCTION_DIR="/function"

# Base image of the docker container
FROM node:lts-slim as build-image

# Include global arg in this stage of the build
ARG FUNCTION_DIR

# AWS Lambda runtime dependencies
RUN apt-get update && \
    apt-get install -y \
        g++ \
        make \
        unzip \
        libcurl4-openssl-dev \
        autoconf \
        automake \
        libtool \
        cmake \
        python3 \
        libkrb5-dev \
        curl

# Copy function code
WORKDIR ${FUNCTION_DIR}
RUN npm install @opensearch-project/reporting-cli && npm install aws-lambda-ric

# Build Stage 2: Copy Build Stage 1 files in to Stage 2. Install chrome, then remove chrome to keep the dependencies.
FROM node:lts-slim
# Include global arg in this stage of the build
ARG FUNCTION_DIR
# Set working directory to function root directory
WORKDIR ${FUNCTION_DIR}
# Copy in the build image dependencies
COPY --from=build-image ${FUNCTION_DIR} ${FUNCTION_DIR}

# Install latest chrome dev package and fonts to support major char sets (Chinese, Japanese, Arabic, Hebrew, Thai and a few others)
# Note: this installs the necessary libs to make the bundled version of Chromium that Puppeteer installs, work.
RUN apt-get update \
    && apt-get install -y wget gnupg \
    && wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | apt-key add - \
    && sh -c 'echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google.list' \
    && apt-get update \
    && apt-get install -y google-chrome-stable fonts-ipafont-gothic fonts-wqy-zenhei fonts-thai-tlwg fonts-kacst fonts-freefont-ttf libxss1 \
      --no-install-recommends \
    && apt-get remove -y google-chrome-stable \
    && rm -rf /var/lib/apt/lists/*

ENTRYPOINT ["/usr/local/bin/npx", "aws-lambda-ric"]

ENV HOME="/tmp"
CMD [ "/function/node_modules/@opensearch-project/reporting-cli/src/index.handler" ]

----------------------------------------

TITLE: Creating an Electronics Index with Mappings in OpenSearch
DESCRIPTION: This snippet demonstrates how to create an index named 'electronics' with specific mappings for brand, category, price, and features fields.

LANGUAGE: json
CODE:
PUT /electronics
{
  "mappings": {
    "properties": {
      "brand": { "type": "keyword" },
      "category": { "type": "keyword" },
      "price": { "type": "float" },
      "features": { "type": "keyword" }
    }
  }
}

----------------------------------------

TITLE: Creating Collapse Pipeline
DESCRIPTION: Creates a search pipeline that collapses results based on the color field.

LANGUAGE: json
CODE:
PUT /_search/pipeline/collapse_pipeline
{
  "response_processors": [
    {
      "collapse" : {
        "field": "color"
      }
    }
  ]
}

----------------------------------------

TITLE: Sample Document Indexing
DESCRIPTION: Example of indexing documents with passage text, language, label and embedding fields.

LANGUAGE: json
CODE:
POST /my_index/_doc/1
{
  "passage_text": "I am excited",
  "passage_language": "en",
  "label": "POSITIVE",
  "passage_embedding": [
    2.3886719,
    0.032714844,
    -0.22229004
    ...]
}

----------------------------------------

TITLE: Executing Hybrid Search with Normalization Pipeline in OpenSearch
DESCRIPTION: Example of performing a hybrid search query using a normalization pipeline that combines text matching and neural search results.

LANGUAGE: json
CODE:
GET /my-nlp-index/_search?search_pipeline=nlp-search-pipeline
{
  "_source": {
    "exclude": [
      "passage_embedding"
    ]
  },
  "query": {
    "hybrid": {
      "queries": [
        {
          "match": {
            "text": {
              "query": "horse"
            }
          }
        },
        {
          "neural": {
            "passage_embedding": {
              "query_text": "wild west",
              "model_id": "aVeif4oB5Vm0Tdw8zYO2",
              "k": 5
            }
          }
        }
      ]
    }
  }
}

----------------------------------------

TITLE: Setting Up Phrase Suggester with Custom Analyzer in OpenSearch
DESCRIPTION: Demonstrates how to set up a phrase suggester by creating a custom analyzer with a shingle filter and configuring the field mapping to use this analyzer.

LANGUAGE: json
CODE:
PUT books2
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "trigram": {
            "type": "custom",
            "tokenizer": "standard",
            "filter": [
              "lowercase",
              "shingle"
            ]
          }
        },
        "filter": {
          "shingle": {
            "type": "shingle",
            "min_shingle_size": 2,
            "max_shingle_size": 3
          }
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "title": {
        "type": "text",
        "fields": {
          "trigram": {
            "type": "text",
            "analyzer": "trigram"
          }
        }
      }
    }
  }
}

----------------------------------------

TITLE: Finding trending queries on server-side
DESCRIPTION: SQL query to identify the most common search queries by counting occurrences in the ubi_queries table.

LANGUAGE: sql
CODE:
select 
	user_query, count(0) Total  
from ubi_queries
group by user_query
order by Total desc

----------------------------------------

TITLE: Analyzing user sessions
DESCRIPTION: SQL query to retrieve detailed session information for a specific client_id from the ubi_events table, including action types and object details.

LANGUAGE: sql
CODE:
select
 application, event_attributes.session_id, query_id, 
 action_name, message_type, event_attributes.dwell_time,
 event_attributes.object.object_id, 
 event_attributes.object.description,
 timestamp
from ubi_events
where client_id = 'a15f1ef3-6bc6-4959-9b83-6699a4d29845'
order by query_id, timestamp

----------------------------------------

TITLE: Setting Event Timestamp in Logstash Filter
DESCRIPTION: Demonstrates how to use the 'date' filter plugin to set the event timestamp from a field in the log entry.

LANGUAGE: yaml
CODE:
date {
  match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
  remove_field => [ "timestamp" ]
}

----------------------------------------

TITLE: Setting Translog Flush Threshold in OpenSearch
DESCRIPTION: API operation to modify the translog flush threshold size for an index, which can improve indexing performance by reducing flush frequency.

LANGUAGE: json
CODE:
PUT /<index>/_settings 
{
  "index":
  {
    "translog.flush_threshold_size" : "1024MB"
  }
}

----------------------------------------

TITLE: Filtering Bulk Response Fields in OpenSearch
DESCRIPTION: Example of using filter_path parameter to reduce response size by excluding specific fields from bulk API responses.

LANGUAGE: json
CODE:
POST /_bulk?pretty&filter_path=-took,-items.index._index,-items.index._type
{ "index" : { "_index" : "test2", "_id" : "1" } }
{ "user" : "testuser" }
{ "update" : {"_id" : "1", "_index" : "test2"} }
{ "doc" : {"user" : "example"} }

----------------------------------------

TITLE: Docker Compose Setup for OpenSearch Replication
DESCRIPTION: Docker Compose configuration for setting up two OpenSearch nodes for replication testing, defining leader and follower clusters with appropriate network and volume settings.

LANGUAGE: yaml
CODE:
version: '3'
services:
  replication-node1:
    image: opensearchproject/opensearch:{{site.opensearch_version}}
    container_name: replication-node1
    environment:
      - cluster.name=leader-cluster
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - opensearch-data2:/usr/share/opensearch/data
    ports:
      - 9201:9200
      - 9700:9600
    networks:
      - opensearch-net
  replication-node2:
    image: opensearchproject/opensearch:{{site.opensearch_version}}
    container_name: replication-node2
    environment:
      - cluster.name=follower-cluster
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - opensearch-data1:/usr/share/opensearch/data
    ports:
      - 9200:9200
      - 9600:9600
    networks:
      - opensearch-net

volumes:
  opensearch-data1:
  opensearch-data2:

networks:
  opensearch-net:

----------------------------------------

TITLE: Updating Follower Cluster Poll Interval in OpenSearch
DESCRIPTION: Example of updating a persistent cluster setting to modify how frequently the follower cluster polls the leader cluster for updates. This demonstrates the syntax for changing dynamic cluster settings.

LANGUAGE: json
CODE:
PUT _cluster/settings
{
  "persistent": {
    "plugins.replication.follower.metadata_sync_interval": "30s"
  }
}

----------------------------------------

TITLE: Registering a sparse encoding model for bi-encoder mode
DESCRIPTION: Registers the amazon/neural-sparse/opensearch-neural-sparse-encoding-v2-distill model for use in bi-encoder mode neural sparse search.

LANGUAGE: json
CODE:
POST /_plugins/_ml/models/_register?deploy=true
{
  "name": "amazon/neural-sparse/opensearch-neural-sparse-encoding-v2-distill",
  "version": "1.0.0",
  "model_format": "TORCH_SCRIPT"
}

----------------------------------------

TITLE: Defining Dynamic Mapping Template in OpenSearch
DESCRIPTION: This snippet demonstrates how to create a dynamic mapping template that maps fields starting with 'status' to the 'short' data type if the initial value is a string.

LANGUAGE: json
CODE:
PUT index
{
  "mappings": {
    "dynamic_templates": [
        {
          "fields": {
            "mapping": {
              "type": "short"
            },
            "match_mapping_type": "string",
            "path_match": "status*"
          }
        }
    ]
  }
}

----------------------------------------

TITLE: Creating Transform Job in OpenSearch
DESCRIPTION: REST API request for creating a new transform job with configuration for continuous execution, scheduling, source/target indices, and aggregations.

LANGUAGE: json
CODE:
PUT _plugins/_transform/sample
{
  "transform": {
    "enabled": true,
    "continuous": true,
    "schedule": {
      "interval": {
        "period": 1,
        "unit": "Minutes",
        "start_time": 1602100553
      }
    },
    "description": "Sample transform job",
    "source_index": "sample_index",
    "target_index": "sample_target",
    "data_selection_query": {
      "match_all": {}
    },
    "page_size": 1,
    "groups": [
      {
        "terms": {
          "source_field": "customer_gender",
          "target_field": "gender"
        }
      },
      {
        "terms": {
          "source_field": "day_of_week",
          "target_field": "day"
        }
      }
    ],
    "aggregations": {
      "quantity": {
        "sum": {
          "field": "total_quantity"
        }
      }
    }
  }
}

----------------------------------------

TITLE: Example Query Results with Size Field
DESCRIPTION: Sample JSON response showing query results including the _size field which indicates document size in bytes.

LANGUAGE: json
CODE:
{
  "took": 2,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 1,
      "relation": "eq"
    },
    "max_score": 1.0,
    "hits": [
      {
        "_index": "example_index",
        "_id": "Pctw0I8BLto8I5f_NLKK",
        "_score": 1.0,
        "_size": 37,
        "_source": {
          "name": "John Doe",
          "age": 30
        }
      }
    ]
  }
}

----------------------------------------

TITLE: Cleaning up Docker resources
DESCRIPTION: A command to stop and remove OpenSearch containers, volumes, and network.

LANGUAGE: bash
CODE:
docker container stop $(docker container ls -aqf name=os-); \
	docker container rm $(docker container ls -aqf name=os-); \
	docker volume rm -f $(docker volume ls -q | egrep 'data-0|repo-0'); \
	docker network rm opensearch-dev-net

----------------------------------------

TITLE: Retrieving Workflow Status
DESCRIPTION: API request to check the status of a provisioned workflow

LANGUAGE: json
CODE:
GET /_plugins/_flow_framework/workflow/8xL8bowB8y25Tqfenm50/_status

----------------------------------------

TITLE: Configuring AWS Cloud Map Discovery Mode in YAML
DESCRIPTION: Example YAML configuration for setting up AWS Cloud Map discovery mode in peer forwarder.

LANGUAGE: yaml
CODE:
peer_forwarder:
  discovery_mode: aws_cloud_map
  aws_cloud_map_namespace_name: "my-namespace"
  aws_cloud_map_service_name: "data-prepper-cluster"
  aws_cloud_map_query_parameters:
    instance_type: "r5.xlarge"
  aws_region: "us-east-1"

----------------------------------------

TITLE: Enabling OpenSearch Assistant in OpenSearch Dashboards YAML Configuration
DESCRIPTION: Configure the opensearch_dashboards.yml file to enable OpenSearch Assistant by setting the assistant.chat.enabled option to true.

LANGUAGE: yaml
CODE:
assistant.chat.enabled: true

----------------------------------------

TITLE: Checking Cluster Connection in OpenSearch Migration Console
DESCRIPTION: This command reports whether both the source and target clusters can be reached and provides their versions.

LANGUAGE: sh
CODE:
console clusters connection-check

----------------------------------------

TITLE: Reloading Secure Settings in OpenSearch
DESCRIPTION: REST API call to reload secure settings after updating credentials in the OpenSearch keystore.

LANGUAGE: json
CODE:
{
  "secure_settings_password": "1234"
}

----------------------------------------

TITLE: Querying Historical Top N Data
DESCRIPTION: GET request demonstrating how to retrieve historical top N query data for a specific time range.

LANGUAGE: json
CODE:
GET /_insights/top_queries?from=2024-08-25T15:00:00.000Z&to=2024-08-30T17:00:00.000Z

----------------------------------------

TITLE: Get Dashboardsinfo API Call
DESCRIPTION: REST API endpoint to retrieve the status of multi-tenancy settings for the currently logged-in user.

LANGUAGE: json
CODE:
GET /_plugins/_security/dashboardsinfo

----------------------------------------

TITLE: Creating Amazon Bedrock Guardrail Connector
DESCRIPTION: Creates a connector configuration for interfacing with Amazon Bedrock guardrail endpoint, including authentication and communication parameters.

LANGUAGE: json
CODE:
{
  "name": "BedRock Guardrail Connector",
  "description": "BedRock Guardrail Connector",
  "version": 1,
  "protocol": "aws_sigv4",
  "parameters": {
    "region": "your_aws_region like us-east-1",
    "service_name": "bedrock",
    "source": "INPUT"
  },
  "credential": {
    "access_key": "your_aws_access_key",
    "secret_key": "your_aws_secret_key",
    "session_token": "your_aws_session_token"
  },
  "actions": [
    {
      "action_type": "predict",
      "method": "POST",
      "url": "https://bedrock-runtime.${parameters.region}.amazonaws.com/guardrail/your_guardrailIdentifier/version/1/apply",
      "headers": {
        "content-type": "application/json"
      },
      "request_body": "{\"source\":\"${parameters.source}\", \"content\":[ { \"text\":{\"text\": \"${parameters.question}\"} } ] }"
    }
  ]
}

----------------------------------------

TITLE: Rendering Model Guardrails Tutorial Cards in Markdown
DESCRIPTION: Markdown syntax for rendering a card layout of model guardrails tutorials. It uses a Jekyll include to generate cards based on the 'model_controls' data defined in the YAML frontmatter.

LANGUAGE: markdown
CODE:
# Model guardrails tutorials

The following tutorials show you how to implement model guardrails.

{% include cards.html cards=page.model_controls %}

----------------------------------------

TITLE: Registering Model Group and Model in OpenSearch
DESCRIPTION: JSON requests to register a model group and the asymmetric embedding model in OpenSearch.

LANGUAGE: json
CODE:
POST /_plugins/_ml/model_groups/_register
{
  "name": "Asymmetric Model Group",
  "description": "A model group for local asymmetric models"
}

POST /_plugins/_ml/models/_register
{
    "name": "e5-small-onnx",
    "version": "1.0.0",
    "description": "Asymmetric multilingual-e5-small model",
    "model_format": "ONNX",
    "model_group_id": "your_group_id",
    "model_content_hash_value": "your_model_zip_content_hash_value",
    "model_config": {
        "model_type": "bert",
        "embedding_dimension": 384,
        "framework_type": "sentence_transformers",
        "query_prefix": "query: ",
        "passage_prefix": "passage: ",
        "all_config": "{ \"_name_or_path\": \"intfloat/multilingual-e5-small\", \"architectures\": [ \"BertModel\" ], \"attention_probs_dropout_prob\": 0.1, \"hidden_size\": 384, \"num_attention_heads\": 12, \"num_hidden_layers\": 12, \"tokenizer_class\": \"XLMRobertaTokenizer\" }"
    },
    "url": "http://localhost:8080/intfloat-multilingual-e5-small-onnx.zip"
}

----------------------------------------

TITLE: Deploying a Registered Model in OpenSearch
DESCRIPTION: cURL command to deploy a registered model using its model ID.

LANGUAGE: bash
CODE:
POST /_plugins/_ml/models/cleMb4kBJ1eYAeTMFFg4/_deploy

----------------------------------------

TITLE: Indexing a pre-indexed shape in OpenSearch
DESCRIPTION: Indexes a polygon shape named 'search_triangle' into the 'pre-indexed-shapes' index using WKT format.

LANGUAGE: json
CODE:
PUT /pre-indexed-shapes/_doc/search_triangle
{
  "boundaries": 
    "POLYGON ((74.0060 40.7128, 71.0589 42.3601, 73.7562 42.6526, 74.0060 40.7128))"
}

----------------------------------------

TITLE: Deleting All Search Pipelines in OpenSearch Cluster (JSON)
DESCRIPTION: This code snippet shows how to delete all search pipelines in an OpenSearch cluster using a wildcard character. The request uses the DELETE HTTP method and targets the /_search/pipeline/* endpoint.

LANGUAGE: json
CODE:
DELETE /_search/pipeline/*

----------------------------------------

TITLE: Executing Alias Operations in OpenSearch
DESCRIPTION: This snippet demonstrates how to use the POST _aliases endpoint to add and remove aliases in OpenSearch. It includes actions to add a new alias 'movies-alias1' to the 'movies' index and remove the 'old-index-alias' from 'old-index'.

LANGUAGE: json
CODE:
POST _aliases
{
  "actions": [
    {
      "add": {
        "index": "movies",
        "alias": "movies-alias1"
      }
    },
    {
      "remove": {
        "index": "old-index",
        "alias": "old-index-alias"
      }
    }
  ]
}

----------------------------------------

TITLE: Example Response for Dangling Indexes API in OpenSearch
DESCRIPTION: This is a sample JSON response from the Dangling Indexes API, showing the cluster name and a list of dangling index UUIDs.

LANGUAGE: json
CODE:
{
    "_nodes": {
        "total": 1,
        "successful": 1,
        "failed": 0
    },
    "cluster_name": "opensearch-cluster",
    "dangling_indices": [msdjernajxAT23RT-BupMB]
}

----------------------------------------

TITLE: API Response Format
DESCRIPTION: Example response showing successful script creation acknowledgment.

LANGUAGE: json
CODE:
{
  "acknowledged" : true
}

----------------------------------------

TITLE: Configuring Bengali Analyzer for Text Field in OpenSearch
DESCRIPTION: This snippet demonstrates how to apply the built-in Bengali analyzer to a text field in an OpenSearch index mapping.

LANGUAGE: json
CODE:
PUT /bengali-index
{
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "bengali"
      }
    }
  }
}

----------------------------------------

TITLE: Testing Galician Analyzer Token Generation
DESCRIPTION: Example of analyzing text using the Galician analyzer and viewing the generated tokens.

LANGUAGE: json
CODE:
POST /galician-index/_analyze
{
  "field": "content",
  "text": "Os estudantes estudan en Santiago e nas universidades galegas. Os seus nmeros son 123456."
}

LANGUAGE: json
CODE:
{
  "tokens": [
    {"token": "estud","start_offset": 3,"end_offset": 13,"type": "<ALPHANUM>","position": 1},
    {"token": "estud","start_offset": 14,"end_offset": 21,"type": "<ALPHANUM>","position": 2},
    {"token": "santiag","start_offset": 25,"end_offset": 33,"type": "<ALPHANUM>","position": 4},
    {"token": "univers","start_offset": 40,"end_offset": 53,"type": "<ALPHANUM>","position": 7},
    {"token": "galeg","start_offset": 54,"end_offset": 61,"type": "<ALPHANUM>","position": 8},
    {"token": "numer","start_offset": 71,"end_offset": 78,"type": "<ALPHANUM>","position": 11},
    {"token": "son","start_offset": 79,"end_offset": 82,"type": "<ALPHANUM>","position": 12},
    {"token": "123456","start_offset": 83,"end_offset": 89,"type": "<NUM>","position": 13}
  ]
}

----------------------------------------

TITLE: Configuring Basic Hungarian Analyzer in OpenSearch
DESCRIPTION: Creates an index with the built-in Hungarian analyzer applied to a text field. This provides basic Hungarian language analysis capabilities including stemming and stop word removal.

LANGUAGE: json
CODE:
PUT /hungarian-index
{
  "mappings": {
    "properties": {
      "content": {
        "type": "text",
        "analyzer": "hungarian"
      }
    }
  }
}