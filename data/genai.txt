TITLE: Creating a client for Vertex AI
DESCRIPTION: Code to initialize a client for Gemini on Vertex AI, specifying project ID and location.

LANGUAGE: python
CODE:
# Only run this block for Vertex AI API
client = genai.Client(
    vertexai=True, project='your-project-id', location='us-central1'
)

----------------------------------------

TITLE: Installing Google Gen AI SDK with pip
DESCRIPTION: Command to install the Google Gen AI Python SDK package using pip.

LANGUAGE: sh
CODE:
pip install google-genai

----------------------------------------

TITLE: Importing Google Gen AI modules
DESCRIPTION: Basic imports for the Google Gen AI Python SDK, including the main genai module and types submodule.

LANGUAGE: python
CODE:
from google import genai
from google.genai import types

----------------------------------------

TITLE: Generating Content with Function Calling in Gemini
DESCRIPTION: Basic example of generating content with a function tool. The function 'get_current_weather' is passed as a tool to the model, which can then call it to retrieve weather information.

LANGUAGE: python
CODE:
response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents='What is the weather like in Boston?',
    config=types.GenerateContentConfig(
        tools=[get_current_weather],
    ),
)

print(response.text)

----------------------------------------

TITLE: Using automatic function calling
DESCRIPTION: Example of defining a Python function and passing it to Gemini for automatic function calling.

LANGUAGE: python
CODE:
def get_current_weather(location: str) -> str:
    """Returns the current weather.

    Args:
      location: The city and state, e.g. San Francisco, CA
    """
    return 'sunny'


response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents='What is the weather like in Boston?',
    config=types.GenerateContentConfig(tools=[get_current_weather]),
)

print(response.text)

----------------------------------------

TITLE: Generating content with text input
DESCRIPTION: Code to generate content using the Gemini model with a simple text prompt.

LANGUAGE: python
CODE:
response = client.models.generate_content(
    model='gemini-2.0-flash-001', contents='Why is the sky blue?'
)
print(response.text)

----------------------------------------

TITLE: Processing Function Calls and Responses in Gemini
DESCRIPTION: Shows the full workflow of receiving a function call from the model, executing the function, and passing the result back to the model for a final response.

LANGUAGE: python
CODE:
user_prompt_content = types.Content(
    role='user',
    parts=[types.Part.from_text(text='What is the weather like in Boston?')],
)
function_call_part = response.function_calls[0]
function_call_content = response.candidates[0].content


try:
    function_result = get_current_weather(
        **function_call_part.function_call.args
    )
    function_response = {'result': function_result}
except (
    Exception
) as e:  # instead of raising the exception, you can let the model handle it
    function_response = {'error': str(e)}


function_response_part = types.Part.from_function_response(
    name=function_call_part.name,
    response=function_response,
)
function_response_content = types.Content(
    role='tool', parts=[function_response_part]
)

response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents=[
        user_prompt_content,
        function_call_content,
        function_response_content,
    ],
    config=types.GenerateContentConfig(
        tools=[tool],
    ),
)

print(response.text)

----------------------------------------

TITLE: Configuring generation with system instructions
DESCRIPTION: Example of using system instructions and other configuration parameters with generate_content.

LANGUAGE: python
CODE:
response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents='high',
    config=types.GenerateContentConfig(
        system_instruction='I say high, you say low',
        max_output_tokens=3,
        temperature=0.3,
    ),
)
print(response.text)

----------------------------------------

TITLE: Configuring safety settings
DESCRIPTION: Example of configuring safety settings to control model output filtering.

LANGUAGE: python
CODE:
response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents='Say something bad.',
    config=types.GenerateContentConfig(
        safety_settings=[
            types.SafetySetting(
                category='HARM_CATEGORY_HATE_SPEECH',
                threshold='BLOCK_ONLY_HIGH',
            )
        ]
    ),
)
print(response.text)

----------------------------------------

TITLE: Using Async API for Content Generation in Gemini
DESCRIPTION: Shows how to use the asynchronous API for content generation, allowing non-blocking operation in asynchronous applications.

LANGUAGE: python
CODE:
response = await client.aio.models.generate_content(
    model='gemini-2.0-flash-001', contents='Tell me a story in 300 words.'
)

print(response.text)

----------------------------------------

TITLE: Asynchronous Streaming in Gemini
DESCRIPTION: Demonstrates how to use asynchronous streaming for content generation, allowing non-blocking chunk-by-chunk processing.

LANGUAGE: python
CODE:
async for chunk in await client.aio.models.generate_content_stream(
    model='gemini-2.0-flash-001', contents='Tell me a story in 300 words.'
):
    print(chunk.text, end='')

----------------------------------------

TITLE: Creating multi-part content with text and image
DESCRIPTION: Example of creating content with both text and an image URI in a single request.

LANGUAGE: python
CODE:
contents = [
  types.Part.from_text('What is this image about?'),
  types.Part.from_uri(
    file_uri: 'gs://generativeai-downloads/images/scones.jpg',
    mime_type: 'image/jpeg',
  )
]

----------------------------------------

TITLE: Using Pydantic Models for Response Schema
DESCRIPTION: Demonstrates how to use Pydantic models to define the structure of the JSON response from the model.

LANGUAGE: python
CODE:
from pydantic import BaseModel


class CountryInfo(BaseModel):
    name: str
    population: int
    capital: str
    continent: str
    gdp: int
    official_language: str
    total_area_sq_mi: int


response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents='Give me information for the United States.',
    config=types.GenerateContentConfig(
        response_mime_type='application/json',
        response_schema=CountryInfo,
    ),
)
print(response.text)

----------------------------------------

TITLE: Using typed configuration with Pydantic models
DESCRIPTION: Example of using typed configuration parameters with Pydantic models for more control over generation.

LANGUAGE: python
CODE:
response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents=types.Part.from_text(text='Why is the sky blue?'),
    config=types.GenerateContentConfig(
        temperature=0,
        top_p=0.95,
        top_k=20,
        candidate_count=1,
        seed=5,
        max_output_tokens=100,
        stop_sequences=['STOP!'],
        presence_penalty=0.0,
        frequency_penalty=0.0,
    ),
)

print(response.text)

----------------------------------------

TITLE: Counting Tokens in Gemini
DESCRIPTION: Shows how to count the number of tokens in content before sending it to the model, which is useful for managing context length and costs.

LANGUAGE: python
CODE:
response = client.models.count_tokens(
    model='gemini-2.0-flash-001',
    contents='why is the sky blue?',
)
print(response)

----------------------------------------

TITLE: Creating a client for Gemini Developer API
DESCRIPTION: Code to initialize a client for the Gemini Developer API using an API key.

LANGUAGE: python
CODE:
# Only run this block for Gemini Developer API
client = genai.Client(api_key='GEMINI_API_KEY')

----------------------------------------

TITLE: Setting up environment variables for Gemini Developer API
DESCRIPTION: Bash command to set the GOOGLE_API_KEY environment variable for use with the Gemini Developer API.

LANGUAGE: bash
CODE:
export GOOGLE_API_KEY='your-api-key'

----------------------------------------

TITLE: Listing available base models
DESCRIPTION: Code to list all available base models in the Google Gen AI SDK.

LANGUAGE: python
CODE:
for model in client.models.list():
    print(model)

----------------------------------------

TITLE: Streaming Text Content from Gemini
DESCRIPTION: Demonstrates how to stream text responses from the Gemini model, receiving chunks of content as they are generated rather than waiting for the full response.

LANGUAGE: python
CODE:
for chunk in client.models.generate_content_stream(
    model='gemini-2.0-flash-001', contents='Tell me a story in 300 words.'
):
    print(chunk.text, end='')

----------------------------------------

TITLE: Generating content with an uploaded file
DESCRIPTION: Code to upload a file and generate content summarizing it using Gemini.

LANGUAGE: python
CODE:
file = client.files.upload(file='a11.txt')
response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents=['Could you summarize this file?', file]
)
print(response.text)

----------------------------------------

TITLE: Streaming with Cloud Storage Images in Gemini
DESCRIPTION: Shows how to stream content generation that includes an image stored in Google Cloud Storage as part of the request.

LANGUAGE: python
CODE:
for chunk in client.models.generate_content_stream(
    model='gemini-2.0-flash-001',
    contents=[
        'What is this image about?',
        types.Part.from_uri(
            file_uri='gs://generativeai-downloads/images/scones.jpg',
            mime_type='image/jpeg',
        ),
    ],
):
    print(chunk.text, end='')

----------------------------------------

TITLE: Streaming with Local Image Files in Gemini
DESCRIPTION: Demonstrates how to stream content generation while including an image from the local file system as part of the request.

LANGUAGE: python
CODE:
YOUR_IMAGE_PATH = 'your_image_path'
YOUR_IMAGE_MIME_TYPE = 'your_image_mime_type'
with open(YOUR_IMAGE_PATH, 'rb') as f:
    image_bytes = f.read()

for chunk in client.models.generate_content_stream(
    model='gemini-2.0-flash-001',
    contents=[
        'What is this image about?',
        types.Part.from_bytes(data=image_bytes, mime_type=YOUR_IMAGE_MIME_TYPE),
    ],
):
    print(chunk.text, end='')

----------------------------------------

TITLE: Disabling automatic function calling
DESCRIPTION: Example of disabling automatic function calling when providing a function as a tool.

LANGUAGE: python
CODE:
response = client.models.generate_content(
  model='gemini-2.0-flash-001',
  contents='What is the weather like in Boston?',
  config=types.GenerateContentConfig(
    tools=[get_current_weather],
    automatic_function_calling=types.AutomaticFunctionCallingConfig(
      disable=True
    ),
  ),
)

----------------------------------------

TITLE: Accessing function calls from response
DESCRIPTION: Code to access function calls returned in the response when automatic function calling is disabled.

LANGUAGE: python
CODE:
function_calls: Optional[List[types.FunctionCall]] = response.function_calls

----------------------------------------

TITLE: Creating a function call part
DESCRIPTION: Example of creating a function call part for the Gemini model to use.

LANGUAGE: python
CODE:
contents = types.Part.from_function_call(
  name='get_weather_by_location',
  args={'location': 'Boston'}
)

----------------------------------------

TITLE: Creating multiple function call parts
DESCRIPTION: Example of creating multiple function call parts in a list.

LANGUAGE: python
CODE:
contents = [
  types.Part.from_function_call(
    name='get_weather_by_location',
    args={'location': 'Boston'}
  ),
  types.Part.from_function_call(
    name='get_weather_by_location',
    args={'location': 'New York'}
  ),
]

----------------------------------------

TITLE: Listing models with pagination
DESCRIPTION: Code to list models with pagination, controlling page size and navigating between pages.

LANGUAGE: python
CODE:
pager = client.models.list(config={'page_size': 10})
print(pager.page_size)
print(pager[0])
pager.next_page()
print(pager[0])

----------------------------------------

TITLE: Listing models asynchronously
DESCRIPTION: Asynchronous code to list available models using async iteration.

LANGUAGE: python
CODE:
async for job in await client.aio.models.list():
    print(job)

----------------------------------------

TITLE: Listing models asynchronously with pagination
DESCRIPTION: Asynchronous code to list models with pagination, controlling page size and navigating between pages.

LANGUAGE: python
CODE:
async_pager = await client.aio.models.list(config={'page_size': 10})
print(async_pager.page_size)
print(async_pager[0])
await async_pager.next_page()
print(async_pager[0])

----------------------------------------

TITLE: Disabling Automatic Function Calling in Gemini
DESCRIPTION: Shows how to disable automatic function calling when providing tools to the model. This returns function call parts in the response that can be manually processed.

LANGUAGE: python
CODE:
response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents='What is the weather like in Boston?',
    config=types.GenerateContentConfig(
        tools=[get_current_weather],
        automatic_function_calling=types.AutomaticFunctionCallingConfig(
            disable=True
        ),
    ),
)

LANGUAGE: python
CODE:
function_calls: Optional[List[types.FunctionCall]] = response.function_calls

----------------------------------------

TITLE: Manually Declaring and Invoking Functions in Gemini
DESCRIPTION: Demonstrates how to manually declare a function and pass it as a tool to the model. This approach gives more control over function definition and handling.

LANGUAGE: python
CODE:
function = types.FunctionDeclaration(
    name='get_current_weather',
    description='Get the current weather in a given location',
    parameters=types.Schema(
        type='OBJECT',
        properties={
            'location': types.Schema(
                type='STRING',
                description='The city and state, e.g. San Francisco, CA',
            ),
        },
        required=['location'],
    ),
)

tool = types.Tool(function_declarations=[function])

response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents='What is the weather like in Boston?',
    config=types.GenerateContentConfig(
        tools=[tool],
    ),
)
print(response.function_calls[0])

----------------------------------------

TITLE: Configuring ANY Mode for Function Calling with Disabled Auto-Execution
DESCRIPTION: Configures function calling mode to 'ANY' while disabling automatic function execution, allowing the model to always return function call parts.

LANGUAGE: python
CODE:
def get_current_weather(location: str) -> str:
    """Returns the current weather.

    Args:
        location: The city and state, e.g. San Francisco, CA
    """
    return "sunny"

response = client.models.generate_content(
    model="gemini-2.0-flash-001",
    contents="What is the weather like in Boston?",
    config=types.GenerateContentConfig(
        tools=[get_current_weather],
        automatic_function_calling=types.AutomaticFunctionCallingConfig(
            disable=True
        ),
        tool_config=types.ToolConfig(
            function_calling_config=types.FunctionCallingConfig(mode='ANY')
        ),
    ),
)

----------------------------------------

TITLE: Limiting Automatic Function Calling Turns in ANY Mode
DESCRIPTION: Sets a limit on the number of automatic function calling turns by configuring the maximum remote calls parameter.

LANGUAGE: python
CODE:
def get_current_weather(location: str) -> str:
    """Returns the current weather.

    Args:
        location: The city and state, e.g. San Francisco, CA
    """
    return "sunny"

response = client.models.generate_content(
    model="gemini-2.0-flash-001",
    contents="What is the weather like in Boston?",
    config=types.GenerateContentConfig(
        tools=[get_current_weather],
        automatic_function_calling=types.AutomaticFunctionCallingConfig(
            maximum_remote_calls=2
        ),
        tool_config=types.ToolConfig(
            function_calling_config=types.FunctionCallingConfig(mode='ANY')
        ),
    ),
)

----------------------------------------

TITLE: Using Direct Schema Definition for JSON Response
DESCRIPTION: Shows how to define a JSON response schema directly using a dictionary structure instead of a Pydantic model.

LANGUAGE: python
CODE:
response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents='Give me information for the United States.',
    config=types.GenerateContentConfig(
        response_mime_type='application/json',
        response_schema={
            'required': [
                'name',
                'population',
                'capital',
                'continent',
                'gdp',
                'official_language',
                'total_area_sq_mi',
            ],
            'properties': {
                'name': {'type': 'STRING'},
                'population': {'type': 'INTEGER'},
                'capital': {'type': 'STRING'},
                'continent': {'type': 'STRING'},
                'gdp': {'type': 'INTEGER'},
                'official_language': {'type': 'STRING'},
                'total_area_sq_mi': {'type': 'INTEGER'},
            },
            'type': 'OBJECT',
        },
    ),
)
print(response.text)

----------------------------------------

TITLE: Using Enum for Text Response in Gemini
DESCRIPTION: Configures the model to return one of the predefined enum values as a plain text response when answering a question.

LANGUAGE: python
CODE:
from enum import Enum

class InstrumentEnum(Enum):
    PERCUSSION = 'Percussion'
    STRING = 'String'
    WOODWIND = 'Woodwind'
    BRASS = 'Brass'
    KEYBOARD = 'Keyboard'

response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents='What instrument plays multiple notes at once?',
    config={
        'response_mime_type': 'text/x.enum',
        'response_schema': InstrumentEnum,
    },
)
print(response.text)

----------------------------------------

TITLE: Using Enum for JSON Response in Gemini
DESCRIPTION: Similar to the text enum response, but configures the model to return the enum value as a JSON string.

LANGUAGE: python
CODE:
class InstrumentEnum(Enum):
    PERCUSSION = 'Percussion'
    STRING = 'String'
    WOODWIND = 'Woodwind'
    BRASS = 'Brass'
    KEYBOARD = 'Keyboard'

response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents='What instrument plays multiple notes at once?',
    config={
        'response_mime_type': 'application/json',
        'response_schema': InstrumentEnum,
    },
)
print(response.text)

----------------------------------------

TITLE: Setting up environment variables for Vertex AI
DESCRIPTION: Bash commands to set environment variables for using Gemini on Vertex AI, including project ID and location.

LANGUAGE: bash
CODE:
export GOOGLE_GENAI_USE_VERTEXAI=true
export GOOGLE_CLOUD_PROJECT='your-project-id'
export GOOGLE_CLOUD_LOCATION='us-central1'

----------------------------------------

TITLE: Creating a client using environment variables
DESCRIPTION: Code to initialize a client using the previously set environment variables without specifying parameters.

LANGUAGE: python
CODE:
client = genai.Client()

----------------------------------------

TITLE: Setting API version for Vertex AI
DESCRIPTION: Code to specify the API version (v1) when creating a client for Vertex AI.

LANGUAGE: python
CODE:
client = genai.Client(
    vertexai=True,
    project='your-project-id',
    location='us-central1',
    http_options=types.HttpOptions(api_version='v1')
)

----------------------------------------

TITLE: Setting API version for Gemini Developer API
DESCRIPTION: Code to specify the API version (v1alpha) when creating a client for the Gemini Developer API.

LANGUAGE: python
CODE:
client = genai.Client(
    api_key='GEMINI_API_KEY',
    http_options=types.HttpOptions(api_version='v1alpha')
)

----------------------------------------

TITLE: Downloading a file for use with Gemini
DESCRIPTION: Shell command to download a text file for processing with Gemini.

LANGUAGE: sh
CODE:
!wget -q https://storage.googleapis.com/generativeai-downloads/data/a11.txt

----------------------------------------

TITLE: Providing input as Content object
DESCRIPTION: Example of creating a Content object with a text part to pass to generate_content.

LANGUAGE: python
CODE:
contents = types.Content(
  role='user',
  parts=[types.Part.from_text(text='Why is the sky blue?')]
)

----------------------------------------

TITLE: Creating a non-function call part with URI
DESCRIPTION: Example of creating a part from a URI pointing to an image.

LANGUAGE: python
CODE:
contents = types.Part.from_uri(
  file_uri: 'gs://generativeai-downloads/images/scones.jpg',
  mime_type: 'image/jpeg',
)

----------------------------------------

TITLE: Computing Tokens in Vertex AI
DESCRIPTION: Demonstrates the compute_tokens method which is only available in Vertex AI, providing more detailed token information.

LANGUAGE: python
CODE:
response = client.models.compute_tokens(
    model='gemini-2.0-flash-001',
    contents='why is the sky blue?',
)
print(response)

----------------------------------------

TITLE: Asynchronous Token Counting in Gemini
DESCRIPTION: Shows how to count tokens asynchronously, which is useful for non-blocking operation in asynchronous applications.

LANGUAGE: python
CODE:
response = await client.aio.models.count_tokens(
    model='gemini-2.0-flash-001',
    contents='why is the sky blue?',
)
print(response)

----------------------------------------

TITLE: Setting up Sphinx toctree directive for GenAI documentation
DESCRIPTION: Configures a Sphinx toctree directive to organize the documentation hierarchy for the Google GenAI project. The directive is set to display a maximum depth of 4 levels and includes a reference to the 'genai' module documentation.

LANGUAGE: restructuredtext
CODE:
.. toctree::
   :maxdepth: 4

   genai

----------------------------------------

TITLE: GumshoeJS Library Header Comment
DESCRIPTION: Header comment for the GumshoeJS library v5.1.2, which is a simple framework-agnostic scrollspy script. The library is provided under MIT License and has been patched by @pradyunsg from the original created by Chris Ferdinandi.

LANGUAGE: JavaScript
CODE:
/*!
 * gumshoejs v5.1.2 (patched by @pradyunsg)
 * A simple, framework-agnostic scrollspy script.
 * (c) 2019 Chris Ferdinandi
 * MIT License
 * http://github.com/cferdinandi/gumshoe
 */