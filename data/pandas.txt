TITLE: Handling missing data in pandas
DESCRIPTION: Demonstrates methods to handle missing data in pandas, including reindexing, dropping NaN values, and filling missing values.

LANGUAGE: python
CODE:
df1 = df.reindex(index=dates[0:4], columns=list(df.columns) + ["E"])
df1.loc[dates[0] : dates[1], "E"] = 1
df1.dropna(how="any")
df1.fillna(value=5)

----------------------------------------

TITLE: Concatenating DataFrames with pandas.concat
DESCRIPTION: Demonstrates how to use pandas.concat to combine multiple DataFrame objects along an axis.

LANGUAGE: python
CODE:
df1 = pd.DataFrame({"A": ["A0", "A1", "A2", "A3"],
                  "B": ["B0", "B1", "B2", "B3"],
                  "C": ["C0", "C1", "C2", "C3"],
                  "D": ["D0", "D1", "D2", "D3"]},
                 index=[0, 1, 2, 3])

df2 = pd.DataFrame({"A": ["A4", "A5", "A6", "A7"],
                  "B": ["B4", "B5", "B6", "B7"],
                  "C": ["C4", "C5", "C6", "C7"],
                  "D": ["D4", "D5", "D6", "D7"]},
                 index=[4, 5, 6, 7])

df3 = pd.DataFrame({"A": ["A8", "A9", "A10", "A11"],
                  "B": ["B8", "B9", "B10", "B11"],
                  "C": ["C8", "C9", "C10", "C11"],
                  "D": ["D8", "D9", "D10", "D11"]},
                 index=[8, 9, 10, 11])

frames = [df1, df2, df3]
result = pd.concat(frames)

----------------------------------------

TITLE: Finding Maximum Age
DESCRIPTION: Demonstrates how to find the maximum value in both a DataFrame column and a Series using the max() method

LANGUAGE: python
CODE:
df["Age"].max()
ages.max()

----------------------------------------

TITLE: Creating a pandas Series in Python
DESCRIPTION: Demonstrates how to create a pandas Series by passing a list of values. The resulting Series uses a default RangeIndex.

LANGUAGE: python
CODE:
s = pd.Series([1, 3, 5, np.nan, 6, 8])
s

----------------------------------------

TITLE: Creating a pandas DataFrame from a dictionary in Python
DESCRIPTION: Demonstrates creating a DataFrame by passing a dictionary of objects where keys are column labels and values are column data.

LANGUAGE: python
CODE:
df2 = pd.DataFrame(
    {
        "A": 1.0,
        "B": pd.Timestamp("20130102"),
        "C": pd.Series(1, index=list(range(4)), dtype="float32"),
        "D": np.array([3] * 4, dtype="int32"),
        "E": pd.Categorical(["test", "train", "test", "train"]),
        "F": "foo",
    }
)
df2

----------------------------------------

TITLE: Displaying DataFrame Information in Pandas
DESCRIPTION: This snippet shows how to use the info() method to display technical information about a pandas DataFrame, including column names, non-null counts, and data types.

LANGUAGE: python
CODE:
titanic.info()

----------------------------------------

TITLE: Reading CSV File with Pandas in Python
DESCRIPTION: This code demonstrates how to read a CSV file named 'titanic.csv' into a pandas DataFrame using the read_csv() function.

LANGUAGE: python
CODE:
titanic = pd.read_csv("data/titanic.csv")

----------------------------------------

TITLE: Merging and joining DataFrames in pandas
DESCRIPTION: Demonstrates how to concatenate DataFrames and perform SQL-style joins.

LANGUAGE: python
CODE:
pieces = [df[:3], df[3:7], df[7:]]
pd.concat(pieces)

left = pd.DataFrame({"key": ["foo", "bar"], "lval": [1, 2]})
right = pd.DataFrame({"key": ["foo", "bar"], "rval": [4, 5]})
pd.merge(left, right, on="key")

----------------------------------------

TITLE: Installing pandas with conda
DESCRIPTION: Command to install pandas using conda package manager from the conda-forge channel.

LANGUAGE: bash
CODE:
conda install -c conda-forge pandas

----------------------------------------

TITLE: Enabling Copy-on-Write
DESCRIPTION: Shows different ways to enable the new Copy-on-Write functionality

LANGUAGE: python
CODE:
pd.set_option("mode.copy_on_write", True)

# Or
pd.options.mode.copy_on_write = True

# Or locally
with pd.option_context("mode.copy_on_write", True):
    ...

----------------------------------------

TITLE: Filtering Rows Based on a Condition
DESCRIPTION: Demonstrates how to filter rows based on a condition (Age > 35) using boolean indexing.

LANGUAGE: python
CODE:
above_35 = titanic[titanic["Age"] > 35]
above_35.head()

titanic["Age"] > 35

above_35.shape

----------------------------------------

TITLE: Creating a Basic Series
DESCRIPTION: Example of creating a pandas Series with random numbers and custom index

LANGUAGE: python
CODE:
s = pd.Series(np.random.randn(5), index=["a", "b", "c", "d", "e"])

----------------------------------------

TITLE: Viewing DataFrame data in pandas
DESCRIPTION: Shows various methods to view DataFrame data, including head(), tail(), index, columns, and to_numpy() for NumPy representation.

LANGUAGE: python
CODE:
df.head()
df.tail(3)
df.index
df.columns
df.to_numpy()

----------------------------------------

TITLE: Importing pandas and numpy in Python
DESCRIPTION: Standard import statements for pandas and numpy libraries, using common aliases.

LANGUAGE: python
CODE:
import numpy as np
import pandas as pd

----------------------------------------

TITLE: Basic pandas DataFrame GroupBy Example
DESCRIPTION: Demonstrates creating a basic GroupBy object from a DataFrame of animal speeds.

LANGUAGE: python
CODE:
speeds = pd.DataFrame(
    [
        ("bird", "Falconiformes", 389.0),
        ("bird", "Psittaciformes", 24.0),
        ("mammal", "Carnivora", 80.2),
        ("mammal", "Primates", np.nan),
        ("mammal", "Carnivora", 58),
    ],
    index=["falcon", "parrot", "lion", "monkey", "leopard"],
    columns=("class", "order", "max_speed"),
)
grouped = speeds.groupby("class")
grouped = speeds.groupby(["class", "order"])

----------------------------------------

TITLE: Importing Pandas Library
DESCRIPTION: Standard way to import pandas using the conventional pd alias

LANGUAGE: python
CODE:
import pandas as pd

----------------------------------------

TITLE: Merging DataFrames with pandas.merge
DESCRIPTION: Shows how to use pandas.merge to join DataFrame objects based on common columns or indexes.

LANGUAGE: python
CODE:
left = pd.DataFrame({"key": ["K0", "K1", "K2", "K3"],
                   "A": ["A0", "A1", "A2", "A3"],
                   "B": ["B0", "B1", "B2", "B3"]})

right = pd.DataFrame({"key": ["K0", "K1", "K2", "K3"],
                    "C": ["C0", "C1", "C2", "C3"],
                    "D": ["D0", "D1", "D2", "D3"]})

result = pd.merge(left, right, on="key")

----------------------------------------

TITLE: Grouped Statistics by Category
DESCRIPTION: Shows how to calculate statistics grouped by categorical variables

LANGUAGE: python
CODE:
titanic[["Sex", "Age"]].groupby("Sex").mean()

LANGUAGE: python
CODE:
titanic.groupby("Sex").mean(numeric_only=True)

LANGUAGE: python
CODE:
titanic.groupby("Sex")["Age"].mean()

----------------------------------------

TITLE: Initializing Pandas DataFrame from CSV in Python
DESCRIPTION: Reads a CSV file into a Pandas DataFrame, setting the index column and parsing dates. The data represents air quality measurements for NO2 concentrations.

LANGUAGE: python
CODE:
import pandas as pd

air_quality = pd.read_csv("data/air_quality_no2.csv", index_col=0, parse_dates=True)
air_quality.head()

----------------------------------------

TITLE: Binary Operations with Broadcasting
DESCRIPTION: Shows how to perform binary operations between DataFrames and Series with broadcasting behavior

LANGUAGE: python
CODE:
df = pd.DataFrame({
    "one": pd.Series(np.random.randn(3), index=["a", "b", "c"]),
    "two": pd.Series(np.random.randn(4), index=["a", "b", "c", "d"]),
    "three": pd.Series(np.random.randn(3), index=["b", "c", "d"]),
})
row = df.iloc[1]
column = df["two"]

df.sub(row, axis="columns")
df.sub(column, axis=0)

----------------------------------------

TITLE: NumPy Operations with DataFrame
DESCRIPTION: Demonstration of NumPy function compatibility with DataFrame

LANGUAGE: python
CODE:
np.exp(df)
np.asarray(df)

----------------------------------------

TITLE: Data selection in pandas DataFrame
DESCRIPTION: Demonstrates various ways to select data from a DataFrame, including label-based, position-based, and boolean indexing.

LANGUAGE: python
CODE:
df["A"]
df[0:3]
df.loc[dates[0]]
df.loc[:, ["A", "B"]]
df.iloc[3]
df[df["A"] > 0]

----------------------------------------

TITLE: Time series operations in pandas
DESCRIPTION: Shows time series-specific operations like resampling and time zone conversion.

LANGUAGE: python
CODE:
rng = pd.date_range("1/1/2012", periods=100, freq="s")
ts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng)
ts.resample("5Min").sum()

ts_utc = ts.tz_localize("UTC")
ts_utc.tz_convert("US/Eastern")

----------------------------------------

TITLE: Custom Aggregation with GroupBy
DESCRIPTION: Example of computing custom metrics using GroupBy aggregation.

LANGUAGE: python
CODE:
df = pd.DataFrame({
    "a": [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2],
    "b": [0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1],
    "c": [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0],
    "d": [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1],
})

def compute_metrics(x):
    result = {"b_sum": x["b"].sum(), "c_mean": x["c"].mean()}
    return pd.Series(result, name="metrics")

result = df.groupby("a").apply(compute_metrics)

----------------------------------------

TITLE: String Splitting and Replacement
DESCRIPTION: Shows how to split strings and replace text using various methods

LANGUAGE: python
CODE:
s2 = pd.Series(["a_b_c", "c_d_e", np.nan, "f_g_h"], dtype="string")
s2.str.split("_")
s2.str.split("_", expand=True)
s2.str.replace("^.a|dog", "XX-XX ", case=False, regex=True)

----------------------------------------

TITLE: Loading Air Quality NO2 Data with Pandas
DESCRIPTION: Loads NO2 air quality data from CSV file and selects specific columns. Uses parse_dates parameter to handle datetime values.

LANGUAGE: python
CODE:
air_quality_no2 = pd.read_csv("data/air_quality_no2_long.csv",
                                  parse_dates=True)
air_quality_no2 = air_quality_no2[["date.utc", "location",
                                       "parameter", "value"]]
air_quality_no2.head()

----------------------------------------

TITLE: Creating a pandas DataFrame with datetime index in Python
DESCRIPTION: Shows how to create a DataFrame using a NumPy array with a datetime index and labeled columns.

LANGUAGE: python
CODE:
dates = pd.date_range("20130101", periods=6)
dates
df = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=list("ABCD"))
df

----------------------------------------

TITLE: Getting Basic Statistics with describe()
DESCRIPTION: Shows how to get summary statistics of numerical data in a DataFrame using the describe() method

LANGUAGE: python
CODE:
df.describe()

----------------------------------------

TITLE: DataFrame Column Operations
DESCRIPTION: Examples of selecting, adding and deleting DataFrame columns

LANGUAGE: python
CODE:
df["one"]
df["three"] = df["one"] * df["two"]
del df["two"]
three = df.pop("three")

----------------------------------------

TITLE: Converting Wide to Long Format
DESCRIPTION: Reshaping data from wide to long format using melt() function with various parameters

LANGUAGE: python
CODE:
no2_pivoted = no2.pivot(columns="location", values="value").reset_index()

no_2 = no2_pivoted.melt(
    id_vars="date.utc",
    value_vars=["BETR801", "FR04014", "London Westminster"],
    value_name="NO_2",
    var_name="id_location"
)

----------------------------------------

TITLE: Working with Categories
DESCRIPTION: Shows common operations for manipulating categories like renaming, adding, removing and reordering

LANGUAGE: python
CODE:
s = pd.Series(["a", "b", "c", "a"], dtype="category")

# Rename categories
s = s.cat.rename_categories(["Group A", "Group B", "Group C"])

# Add new category
s = s.cat.add_categories(["Group D"])

# Remove category
s = s.cat.remove_categories(["Group D"])

----------------------------------------

TITLE: Joining DataFrames in Pandas
DESCRIPTION: Shows how to perform different types of joins (INNER, LEFT, RIGHT, FULL) using pandas merge() function. The example uses two sample DataFrames df1 and df2.

LANGUAGE: python
CODE:
# INNER JOIN
pd.merge(df1, df2, on="key")

# LEFT JOIN
pd.merge(df1, df2, on="key", how="left")

# RIGHT JOIN
pd.merge(df1, df2, on="key", how="right")

# FULL JOIN
pd.merge(df1, df2, on="key", how="outer")

----------------------------------------

TITLE: Creating a DataFrame with Pandas in Python
DESCRIPTION: This code snippet demonstrates how to create a simple DataFrame using pandas. It creates a DataFrame with two columns (num_legs and num_wings) and two rows indexed by 'falcon' and 'dog'.

LANGUAGE: Python
CODE:
import pandas as pd
df = pd.DataFrame({"num_legs": [2, 4], "num_wings": [2, 0]}, index=["falcon", "dog"])
df

----------------------------------------

TITLE: Filtering Rows Using the isin() Method
DESCRIPTION: Shows how to filter rows based on multiple values using the isin() method, selecting passengers from cabin classes 2 and 3.

LANGUAGE: python
CODE:
class_23 = titanic[titanic["Pclass"].isin([2, 3])]
class_23.head()

class_23 = titanic[(titanic["Pclass"] == 2) | (titanic["Pclass"] == 3)]
class_23.head()

----------------------------------------

TITLE: Replacing Values in Pandas Column
DESCRIPTION: Creates a new column 'Sex_short' by replacing 'male' with 'M' and 'female' with 'F' in the 'Sex' column.

LANGUAGE: python
CODE:
titanic["Sex_short"] = titanic["Sex"].replace({"male": "M", "female": "F"})
titanic["Sex_short"]

----------------------------------------

TITLE: Creating Sample DataFrame with Multiple Columns
DESCRIPTION: Creates a sample DataFrame with numerical and categorical columns for demonstration purposes

LANGUAGE: python
CODE:
df = pd.DataFrame({
    "AAA": [4, 5, 6, 7],
    "BBB": [10, 20, 30, 40],
    "CCC": [100, 50, -30, -50]
})

----------------------------------------

TITLE: Combining DataFrames with DataFrame.combine_first
DESCRIPTION: Shows how to use DataFrame.combine_first to update missing values in one DataFrame with values from another.

LANGUAGE: python
CODE:
df1 = pd.DataFrame([[np.nan, 3., 5.], [-4.6, np.nan, np.nan], [np.nan, 7., np.nan]])
df2 = pd.DataFrame([[-42.6, np.nan, -8.2], [-5., 1.6, 4]], index=[1, 2])
result = df1.combine_first(df2)

----------------------------------------

TITLE: Grouping and Aggregating Data in SQL and Pandas
DESCRIPTION: Demonstrates how to group data and perform aggregations in SQL and pandas. The pandas example uses groupby() and agg() methods to achieve the same result as the SQL query.

LANGUAGE: sql
CODE:
SELECT day, AVG(tip), COUNT(*)
FROM tips
GROUP BY day;

LANGUAGE: python
CODE:
tips.groupby("day").agg({"tip": "mean", "day": "size"})

----------------------------------------

TITLE: Grouping and aggregating data in pandas
DESCRIPTION: Shows how to group data and apply aggregation functions in pandas.

LANGUAGE: python
CODE:
df = pd.DataFrame(
    {
        "A": ["foo", "bar", "foo", "bar", "foo", "bar", "foo", "foo"],
        "B": ["one", "one", "two", "three", "two", "two", "one", "three"],
        "C": np.random.randn(8),
        "D": np.random.randn(8),
    }
)
df.groupby("A")[["C", "D"]].sum()

----------------------------------------

TITLE: Selecting Rows and Columns by Position Using iloc
DESCRIPTION: Demonstrates how to select rows and columns by their integer position using the iloc accessor.

LANGUAGE: python
CODE:
titanic.iloc[9:25, 2:5]

----------------------------------------

TITLE: Creating Sample Data with DateTimeIndex
DESCRIPTION: Creates series and dataframe objects with date ranges and random values for examples

LANGUAGE: python
CODE:
index = pd.date_range("1/1/2000", periods=8)
s = pd.Series(np.random.randn(5), index=["a", "b", "c", "d", "e"])
df = pd.DataFrame(np.random.randn(8, 3), index=index, columns=["A", "B", "C"])

----------------------------------------

TITLE: Assigning Values to a DataFrame Subset
DESCRIPTION: Shows how to assign new values to a subset of the DataFrame selected using iloc.

LANGUAGE: python
CODE:
titanic.iloc[0:3, 3] = "anonymous"
titanic.iloc[:5, 3]

----------------------------------------

TITLE: String Methods and Vectorized Operations
DESCRIPTION: Demonstrates vectorized string operations on Series objects using str accessor

LANGUAGE: python
CODE:
s = pd.Series(["A", "B", "C", "Aaba", "Baca", np.nan, "CABA", "dog", "cat"], dtype="string")
s.str.lower()

----------------------------------------

TITLE: Performing Inner Join on pandas DataFrames
DESCRIPTION: This snippet demonstrates how to perform an inner join on two DataFrames using the merge() method. It joins df1 and df2 on the 'key' column with the 'inner' join type.

LANGUAGE: python
CODE:
inner_join = df1.merge(df2, on=["key"], how="inner")
inner_join

----------------------------------------

TITLE: Initializing Pandas DataFrame using Dictionary - Python
DESCRIPTION: Creates a pandas DataFrame using a Python dictionary with two columns 'x' and 'y'. The dictionary keys become column names and the list values become the data in each column.

LANGUAGE: python
CODE:
df = pd.DataFrame({"x": [1, 3, 5], "y": [2, 4, 6]})
df

----------------------------------------

TITLE: Selecting Multiple Columns from a DataFrame
DESCRIPTION: Shows how to select multiple columns ('Age' and 'Sex') from the DataFrame using a list of column names within square brackets.

LANGUAGE: python
CODE:
age_sex = titanic[["Age", "Sex"]]
age_sex.head()

type(titanic[["Age", "Sex"]])

titanic[["Age", "Sex"]].shape

----------------------------------------

TITLE: Selecting a Single Column as Series
DESCRIPTION: Demonstrates how to extract a single column (Age) from the DataFrame, resulting in a Series object

LANGUAGE: python
CODE:
df["Age"]

----------------------------------------

TITLE: Detecting Missing Values with isna/notna
DESCRIPTION: Demonstrates how to detect missing values using pandas isna() and notna() functions.

LANGUAGE: python
CODE:
ser = pd.Series([pd.Timestamp("2020-01-01"), pd.NaT])
ser
pd.isna(ser)

----------------------------------------

TITLE: Merging DataFrames with Station Coordinates
DESCRIPTION: Demonstrates left join between air quality measurements and station coordinates using pd.merge() with a common 'location' column.

LANGUAGE: python
CODE:
stations_coord = pd.read_csv("data/air_quality_stations.csv")
air_quality = pd.merge(air_quality, stations_coord, how="left", on="location")
air_quality.head()

----------------------------------------

TITLE: Checking Data Types of DataFrame Columns in Pandas
DESCRIPTION: This code demonstrates how to check the data types of all columns in a pandas DataFrame using the dtypes attribute.

LANGUAGE: python
CODE:
titanic.dtypes

----------------------------------------

TITLE: Converting DataFrame to JSON using NTV format in Python
DESCRIPTION: This snippet demonstrates converting a pandas DataFrame to JSON using the proposed NTV format, which preserves type information.

LANGUAGE: python
CODE:
df_to_json = npd.to_json(df)
print(df_to_json)

----------------------------------------

TITLE: Basic Rolling Window Sum in Python
DESCRIPTION: Demonstrates a simple rolling window sum operation on a pandas Series.

LANGUAGE: python
CODE:
s = pd.Series(range(5))
s.rolling(window=2).sum()

----------------------------------------

TITLE: Interpolating Missing Values
DESCRIPTION: Shows various methods of interpolating missing values in pandas using different algorithms.

LANGUAGE: python
CODE:
df = pd.DataFrame({
    "A": [1, 2.1, np.nan, 4.7, 5.6, 6.8],
    "B": [0.25, np.nan, np.nan, 4, 12.2, 14.4]
})
df.interpolate()
df.interpolate(method="spline", order=2)

----------------------------------------

TITLE: Merging ordered data with merge_ordered
DESCRIPTION: Demonstrates how to use merge_ordered to combine ordered data with optional filling of missing values.

LANGUAGE: python
CODE:
left = pd.DataFrame({"k": ["K0", "K1", "K1", "K2"],
                   "lv": [1, 2, 3, 4],
                   "s": ["a", "b", "c", "d"]})

right = pd.DataFrame({"k": ["K1", "K2", "K4"],
                    "rv": [1, 2, 3]})

pd.merge_ordered(left, right, fill_method="ffill", left_by="s")

----------------------------------------

TITLE: Reading Excel File with Pandas in Python
DESCRIPTION: This code demonstrates how to read an Excel file named 'titanic.xlsx' into a pandas DataFrame using the read_excel() function, specifying a sheet name.

LANGUAGE: python
CODE:
titanic = pd.read_excel("titanic.xlsx", sheet_name="passengers")

----------------------------------------

TITLE: String Pattern Extraction
DESCRIPTION: Demonstrates extracting patterns from strings using regular expressions

LANGUAGE: python
CODE:
pd.Series(["a1", "b2", "c3"], dtype="string").str.extract(r"([ab])(\d)", expand=False)
pd.Series(["a1", "b2", "c3"], dtype="string").str.extract(r"(?P<letter>[ab])(?P<digit>\d)", expand=False)

----------------------------------------

TITLE: Converting Strings to Datetime in Pandas
DESCRIPTION: Converts string datetime values to pandas Timestamp objects using pd.to_datetime().

LANGUAGE: python
CODE:
air_quality["datetime"] = pd.to_datetime(air_quality["datetime"])
air_quality["datetime"]

----------------------------------------

TITLE: Creating and Using Boolean Mask for DataFrame Filtering in Python
DESCRIPTION: This snippet shows how to create a boolean mask for more complex filtering operations. It creates a mask for dinner times, displays the mask, counts its values, and then uses it to filter the DataFrame.

LANGUAGE: python
CODE:
is_dinner = tips["time"] == "Dinner"
is_dinner
is_dinner.value_counts()
tips[is_dinner]

----------------------------------------

TITLE: Creating DataFrame with Passenger Data
DESCRIPTION: Creates a DataFrame containing Titanic passenger information with name, age, and sex columns using a dictionary of lists

LANGUAGE: python
CODE:
df = pd.DataFrame(
    {
        "Name": [
            "Braund, Mr. Owen Harris",
            "Allen, Mr. William Henry",
            "Bonnell, Miss Elizabeth",
        ],
        "Age": [22, 35, 58],
        "Sex": ["male", "male", "female"],
    }
)
df

----------------------------------------

TITLE: Grouping and Summing Data with Pandas in Python
DESCRIPTION: This code snippet demonstrates how to use pandas to group data by multiple columns ('sex' and 'smoker') and sum the 'total_bill' and 'tip' columns. The result is stored in a new DataFrame called tips_summed.

LANGUAGE: python
CODE:
tips_summed = tips.groupby(["sex", "smoker"])[["total_bill", "tip"]].sum()
tips_summed

----------------------------------------

TITLE: Creating a Quick Line Plot of All Columns in Pandas DataFrame
DESCRIPTION: Generate a line plot for all numeric columns in the DataFrame using the default plot method.

LANGUAGE: python
CODE:
air_quality.plot()
plt.show()

----------------------------------------

TITLE: Creating Pivot Table with Multiple Values
DESCRIPTION: Example demonstrating how to create a pivot table with multiple value columns and aggregation functions using pandas pivot_table.

LANGUAGE: python
CODE:
pd.pivot_table(df, values=["D", "E"],
    index=["B"],
    columns=["A", "C"],
    aggfunc="sum")

----------------------------------------

TITLE: Basic operations in pandas
DESCRIPTION: Shows basic statistical operations and applying functions to DataFrame data.

LANGUAGE: python
CODE:
df.mean()
df.mean(axis=1)
df.apply(lambda x: x.max() - x.min())

----------------------------------------

TITLE: Loading Data into Pandas DataFrame
DESCRIPTION: Demonstrates how to load data from a CSV file into a pandas DataFrame using pd.read_csv(). The data is stored in a variable called 'tips'.

LANGUAGE: python
CODE:
url = (
    "https://raw.githubusercontent.com/pandas-dev"
    "/pandas/main/pandas/tests/io/data/csv/tips.csv"
)
tips = pd.read_csv(url)
tips

----------------------------------------

TITLE: Filling Missing Values
DESCRIPTION: Examples of filling missing values using different methods like fillna(), ffill(), and bfill().

LANGUAGE: python
CODE:
data = {"np": [1.0, np.nan, np.nan, 2], "arrow": pd.array([1.0, pd.NA, pd.NA, 2], dtype="float64[pyarrow]")}
df = pd.DataFrame(data)
df.fillna(0)
df.ffill()
df.bfill()

----------------------------------------

TITLE: Correcting GroupBy Mean Calculations with NaT Values in Python
DESCRIPTION: Fixed a bug in DataFrameGroupBy.mean and SeriesGroupBy.mean that was returning incorrect results for datetimelike values including NaT values.

LANGUAGE: Python
CODE:
DataFrameGroupBy.mean()
SeriesGroupBy.mean()

----------------------------------------

TITLE: Sorting DataFrame by Multiple Columns using sort_values()
DESCRIPTION: Example showing how to sort a DataFrame named 'tips' by two columns: 'sex' and 'total_bill'. The sort_values() method accepts a list of column names to define the sort order.

LANGUAGE: python
CODE:
tips = tips.sort_values(["sex", "total_bill"])
tips

----------------------------------------

TITLE: DataFrame GroupBy with Transformation
DESCRIPTION: Shows how to standardize data within groups using transformation.

LANGUAGE: python
CODE:
ts = pd.Series(np.random.normal(0.5, 2, 1100), index)
ts = ts.rolling(window=100, min_periods=100).mean().dropna()

transformed = ts.groupby(lambda x: x.year).transform(
    lambda x: (x - x.mean()) / x.std()
)

----------------------------------------

TITLE: Accelerating Operations with Libraries
DESCRIPTION: Configures use of numexpr and bottleneck libraries for optimizing numerical operations

LANGUAGE: python
CODE:
pd.set_option("compute.use_bottleneck", False)
pd.set_option("compute.use_numexpr", False)

----------------------------------------

TITLE: Initializing Series with Missing Values
DESCRIPTION: Examples showing how different types of missing values are represented in pandas Series with different data types.

LANGUAGE: python
CODE:
pd.Series([1, 2], dtype=np.int64).reindex([0, 1, 2])
pd.Series([True, False], dtype=np.bool_).reindex([0, 1, 2])

----------------------------------------

TITLE: Generating Fixed Frequency DatetimeIndex
DESCRIPTION: Shows how to create a sequence of dates with a specified frequency using pd.date_range

LANGUAGE: python
CODE:
dti = pd.date_range("2018-01-01", periods=3, freq="h")
dti

----------------------------------------

TITLE: Writing DataFrame to Excel File with Pandas in Python
DESCRIPTION: This snippet shows how to write a pandas DataFrame to an Excel file using the to_excel() method, specifying a sheet name and excluding the index.

LANGUAGE: python
CODE:
titanic.to_excel("titanic.xlsx", sheet_name="passengers", index=False)

----------------------------------------

TITLE: Descriptive Statistics
DESCRIPTION: Generates comprehensive descriptive statistics for Age and Fare columns

LANGUAGE: python
CODE:
titanic[["Age", "Fare"]].describe()

----------------------------------------

TITLE: Merging DataFrames with Parameter Metadata
DESCRIPTION: Shows how to merge air quality data with parameter metadata using different column names for the join key using left_on and right_on arguments.

LANGUAGE: python
CODE:
air_quality_parameters = pd.read_csv("data/air_quality_parameters.csv")
air_quality = pd.merge(air_quality, air_quality_parameters,
                           how='left', left_on='parameter', right_on='id')
air_quality.head()

----------------------------------------

TITLE: Creating a Sparse DataFrame in Python
DESCRIPTION: This code creates a large DataFrame with mostly NaN values, then converts it to a sparse DataFrame. It demonstrates the memory efficiency of sparse structures.

LANGUAGE: python
CODE:
df = pd.DataFrame(np.random.randn(10000, 4))
df.iloc[:9998] = np.nan
sdf = df.astype(pd.SparseDtype("float", np.nan))
sdf.head()
sdf.dtypes
sdf.sparse.density

----------------------------------------

TITLE: Creating DatetimeIndex with Multiple Input Formats
DESCRIPTION: Demonstrates converting different datetime formats into a DatetimeIndex using pd.to_datetime

LANGUAGE: python
CODE:
import datetime

dti = pd.to_datetime(["1/1/2018", np.datetime64("2018-01-01"), datetime.datetime(2018, 1, 1)])
dti

----------------------------------------

TITLE: Creating a sample DataFrame
DESCRIPTION: Creates a sample DataFrame with strings, integers and floats to demonstrate formatting.

LANGUAGE: python
CODE:
df = pd.DataFrame(
    {"strings": ["Adam", "Mike"], "ints": [1, 3], "floats": [1.123, 1000.23]}
)
df.style.format(precision=3, thousands=".", decimal=",").format_index(
    str.upper, axis=1
).relabel_index(["row 1", "row 2"], axis=0)

----------------------------------------

TITLE: Dropping NA Values in Pandas DataFrame
DESCRIPTION: Shows how to remove rows containing missing values from a DataFrame using the dropna() method

LANGUAGE: python
CODE:
outer_join.dropna()

----------------------------------------

TITLE: Renaming Columns in Pandas DataFrame
DESCRIPTION: Illustrates how to rename columns in a Pandas DataFrame using the rename() method with a dictionary mapping old column names to new ones.

LANGUAGE: python
CODE:
tips.rename(columns={"total_bill": "total_bill_2"})

----------------------------------------

TITLE: Basic SQL GROUP BY Example
DESCRIPTION: Shows a basic SQL GROUP BY statement demonstrating the fundamental concept behind pandas groupby functionality.

LANGUAGE: sql
CODE:
SELECT Column1, Column2, mean(Column3), sum(Column4)
FROM SomeTable
GROUP BY Column1, Column2

----------------------------------------

TITLE: Creating Pivot Tables from Long Format
DESCRIPTION: Converting data from long to wide format using pivot() and pivot_table() functions

LANGUAGE: python
CODE:
no2 = air_quality[air_quality["parameter"] == "no2"]
no2_subset = no2.sort_index().groupby(["location"]).head(2)

no2_subset.pivot(columns="location", values="value")

air_quality.pivot_table(
    values="value",
    index="location",
    columns="parameter",
    aggfunc="mean",
    margins=True
)

----------------------------------------

TITLE: Correcting GroupBy Rolling Operations in Python
DESCRIPTION: Fixed regressions in DataFrame.groupby.rolling iteration and DataFrame.groupby.rolling.cov and DataFrame.groupby.rolling.corr computations when input groupings were not sorted.

LANGUAGE: Python
CODE:
DataFrame.groupby.rolling()
DataFrame.groupby.rolling.cov()
DataFrame.groupby.rolling.corr()

----------------------------------------

TITLE: Extracting DateTime Components in Pandas
DESCRIPTION: Demonstrates how to extract month information from datetime column using dt accessor.

LANGUAGE: python
CODE:
air_quality["month"] = air_quality["datetime"].dt.month
air_quality.head()

----------------------------------------

TITLE: Performing operations on Timedelta Series in Python using pandas
DESCRIPTION: Demonstrates various operations that can be performed on Timedelta Series, including addition, subtraction, and comparison with datetime objects.

LANGUAGE: python
CODE:
s = pd.Series(pd.date_range("2012-1-1", periods=3, freq="D"))
td = pd.Series([pd.Timedelta(days=i) for i in range(3)])
df = pd.DataFrame({"A": s, "B": td})
df
df["C"] = df["A"] + df["B"]
df
df.dtypes

s - s.max()
s - datetime.datetime(2011, 1, 1, 3, 5)
s + datetime.timedelta(minutes=5)
s + pd.offsets.Minute(5)
s + pd.offsets.Minute(5) + pd.offsets.Milli(5)

----------------------------------------

TITLE: Melting DataFrame Example
DESCRIPTION: Example showing how to melt/unpivot a DataFrame from wide to long format using pandas melt function.

LANGUAGE: python
CODE:
cheese = pd.DataFrame({
    "first": ["John", "Mary"],
    "last": ["Doe", "Bo"],
    "height": [5.5, 6.0],
    "weight": [130, 150],
})

cheese.melt(id_vars=["first", "last"])

----------------------------------------

TITLE: DataFrame Operations with IntegerArray
DESCRIPTION: Shows how IntegerArray can be used within a DataFrame, including dtype information and basic operations.

LANGUAGE: python
CODE:
df = pd.DataFrame({"A": s, "B": [1, 1, 3], "C": list("aab")})
df
df.dtypes

----------------------------------------

TITLE: Performing Right Join on pandas DataFrames
DESCRIPTION: This snippet illustrates how to perform a right join on two DataFrames using the merge() method. It joins df1 and df2 on the 'key' column with the 'right' join type.

LANGUAGE: python
CODE:
right_join = df1.merge(df2, on=["key"], how="right")
right_join

----------------------------------------

TITLE: Importing Pandas and NumPy
DESCRIPTION: Basic imports needed to use pandas functionality

LANGUAGE: python
CODE:
import numpy as np
import pandas as pd

----------------------------------------

TITLE: Basic Series Indexing with Labels
DESCRIPTION: Demonstrates basic label-based indexing of a pandas Series using .loc and list selection

LANGUAGE: python
CODE:
ser = pd.Series(range(5), index=list("abcde"))
ser.loc[["a", "c", "e"]]

----------------------------------------

TITLE: Deleting Data in SQL and Pandas
DESCRIPTION: Shows how to delete rows based on a condition in SQL and the equivalent operation in pandas. The pandas example filters the DataFrame to keep only the desired rows.

LANGUAGE: sql
CODE:
DELETE FROM tips
WHERE tip > 9;

LANGUAGE: python
CODE:
tips = tips.loc[tips["tip"] <= 9]

----------------------------------------

TITLE: Creating a histogram
DESCRIPTION: Demonstrates creating a histogram from DataFrame columns.

LANGUAGE: python
CODE:
df4 = pd.DataFrame(
    {
        "a": np.random.randn(1000) + 1,
        "b": np.random.randn(1000),
        "c": np.random.randn(1000) - 1,
    },
    columns=["a", "b", "c"],
)

plt.figure()

df4.plot.hist(alpha=0.5);

----------------------------------------

TITLE: Basic indexing on MultiIndex
DESCRIPTION: Demonstrates how to perform basic indexing operations on a DataFrame with a MultiIndex.

LANGUAGE: python
CODE:
df["bar"]
df["bar", "one"]
df["bar"]["one"]
s["qux"]

----------------------------------------

TITLE: Parsing Timedeltas in Python using pandas
DESCRIPTION: Demonstrates various ways to construct Timedelta objects in pandas, including string parsing, keyword arguments, and conversion from other time delta types.

LANGUAGE: python
CODE:
import datetime

# strings
pd.Timedelta("1 days")
pd.Timedelta("1 days 00:00:00")
pd.Timedelta("1 days 2 hours")
pd.Timedelta("-1 days 2 min 3us")

# like datetime.timedelta
# note: these MUST be specified as keyword arguments
pd.Timedelta(days=1, seconds=1)

# integers with a unit
pd.Timedelta(1, unit="D")

# from a datetime.timedelta/np.timedelta64
pd.Timedelta(datetime.timedelta(days=1, seconds=1))
pd.Timedelta(np.timedelta64(1, "ms"))

# negative Timedeltas have this string repr
# to be more consistent with datetime.timedelta conventions
pd.Timedelta("-1us")

# a NaT
pd.Timedelta("nan")
pd.Timedelta("nat")

# ISO 8601 Duration strings
pd.Timedelta("P0DT0H1M0S")
pd.Timedelta("P0DT0H0M0.000000123S")

----------------------------------------

TITLE: Creating Categorical Series
DESCRIPTION: Shows different ways to create a Series with categorical data type including direct creation and conversion from existing Series

LANGUAGE: python
CODE:
s = pd.Series(["a", "b", "c", "a"], dtype="category")

df = pd.DataFrame({"A": ["a", "b", "c", "a"]})
df["B"] = df["A"].astype("category")

----------------------------------------

TITLE: Aggregating Data in R and pandas
DESCRIPTION: Demonstrates data aggregation in R using aggregate() and the equivalent operation in pandas using groupby().

LANGUAGE: r
CODE:
df <- data.frame(
  v1 = c(1,3,5,7,8,3,5,NA,4,5,7,9),
  v2 = c(11,33,55,77,88,33,55,NA,44,55,77,99),
  by1 = c("red", "blue", 1, 2, NA, "big", 1, 2, "red", 1, NA, 12),
  by2 = c("wet", "dry", 99, 95, NA, "damp", 95, 99, "red", 99, NA, NA))
aggregate(x=df[, c("v1", "v2")], by=list(mydf2$by1, mydf2$by2), FUN = mean)

LANGUAGE: python
CODE:
df = pd.DataFrame(
    {
        "v1": [1, 3, 5, 7, 8, 3, 5, np.nan, 4, 5, 7, 9],
        "v2": [11, 33, 55, 77, 88, 33, 55, np.nan, 44, 55, 77, 99],
        "by1": ["red", "blue", 1, 2, np.nan, "big", 1, 2, "red", 1, np.nan, 12],
        "by2": [
            "wet",
            "dry",
            99,
            95,
            np.nan,
            "damp",
            95,
            99,
            "red",
            99,
            np.nan,
            np.nan,
        ],
    }
)

g = df.groupby(["by1", "by2"])
g[["v1", "v2"]].mean()

----------------------------------------

TITLE: Selecting a Single Column from a DataFrame
DESCRIPTION: Demonstrates how to select a single column ('Age') from the DataFrame using square brackets. The result is a Pandas Series.

LANGUAGE: python
CODE:
ages = titanic["Age"]
ages.head()

type(titanic["Age"])

titanic["Age"].shape

----------------------------------------

TITLE: Creating a Scatter Plot Comparing Two Columns in Pandas
DESCRIPTION: Generate a scatter plot to compare NO2 values between London and Paris stations.

LANGUAGE: python
CODE:
air_quality.plot.scatter(x="station_london", y="station_paris", alpha=0.5)
plt.show()

----------------------------------------

TITLE: Reading CSV Data in pandas using read_csv
DESCRIPTION: This Python code snippet demonstrates how to read CSV data into a pandas DataFrame using the read_csv function.

LANGUAGE: python
CODE:
url = (
    "https://raw.githubusercontent.com/pandas-dev/"
    "pandas/main/pandas/tests/io/data/csv/tips.csv"
)
tips = pd.read_csv(url)
tips

----------------------------------------

TITLE: Highlighting maximum values
DESCRIPTION: Shows how to highlight the maximum values in a DataFrame.

LANGUAGE: python
CODE:
def highlight_max(s, props=""):
    return np.where(s == np.nanmax(s.values), props, "")


s2.apply(highlight_max, props="color:white;background-color:darkblue", axis=0)

----------------------------------------

TITLE: Selecting Specific Columns in Pandas DataFrame
DESCRIPTION: Demonstrates how to select and keep only certain columns from a Pandas DataFrame using double square bracket notation. Returns a new DataFrame with only the specified columns.

LANGUAGE: python
CODE:
tips[["sex", "total_bill", "tip"]]

----------------------------------------

TITLE: Implementing Chunked Processing for Large Datasets
DESCRIPTION: Example of processing large datasets by chunking, implementing an out-of-core value_counts operation across multiple Parquet files.

LANGUAGE: python
CODE:
files = pathlib.Path("data/timeseries/").glob("ts*.parquet")
counts = pd.Series(dtype=int)
for path in files:
    df = pd.read_parquet(path)
    counts = counts.add(df["name"].value_counts(), fill_value=0)

----------------------------------------

TITLE: Optimizing DataFrame Memory Usage with Efficient Data Types
DESCRIPTION: Examples of reducing memory usage by converting string columns to categorical type and downcasting numeric columns to smaller datatypes.

LANGUAGE: python
CODE:
ts2 = ts.copy()
ts2["name"] = ts2["name"].astype("category")
ts2["id"] = pd.to_numeric(ts2["id"], downcast="unsigned")
ts2[["x", "y"]] = ts2[["x", "y"]].apply(pd.to_numeric, downcast="float")

----------------------------------------

TITLE: Converting to Timedelta objects using pd.to_timedelta in Python
DESCRIPTION: Shows how to use pd.to_timedelta to convert various input types to Timedelta objects, including single strings, lists of strings, and numeric arrays with specified units.

LANGUAGE: python
CODE:
pd.to_timedelta("1 days 06:05:01.00003")
pd.to_timedelta("15.5us")

pd.to_timedelta(["1 days 06:05:01.00003", "15.5us", "nan"])

pd.to_timedelta(np.arange(5), unit="s")
pd.to_timedelta(np.arange(5), unit="D")

----------------------------------------

TITLE: Handling Categorical Data in R and pandas
DESCRIPTION: Shows how to work with categorical data in R using cut() and factor(), and the equivalent operations in pandas using pd.cut() and astype('category').

LANGUAGE: r
CODE:
cut(c(1,2,3,4,5,6), 3)
factor(c(1,2,3,2,2,3))

LANGUAGE: python
CODE:
pd.cut(pd.Series([1, 2, 3, 4, 5, 6]), 3)
pd.Series([1, 2, 3, 2, 2, 3]).astype("category")

----------------------------------------

TITLE: Creating a round-trippable JSON DataFrame with orient='table'
DESCRIPTION: A DataFrame can now be written to and read back from JSON while preserving metadata through usage of the orient='table' argument.

LANGUAGE: python
CODE:
df = pd.DataFrame({'foo': [1, 2, 3, 4],
                   'bar': ['a', 'b', 'c', 'd'],
                   'baz': pd.date_range('2018-01-01', freq='d', periods=4),
                   'qux': pd.Categorical(['a', 'b', 'c', 'c'])},
                  index=pd.Index(range(4), name='idx'))

df.to_json('test.json', orient='table')

new_df = pd.read_json('test.json', orient='table')

----------------------------------------

TITLE: Importing and exporting data in pandas
DESCRIPTION: Demonstrates reading from and writing to various file formats, including CSV, Parquet, and Excel.

LANGUAGE: python
CODE:
df.to_csv("foo.csv")
pd.read_csv("foo.csv")

df.to_parquet("foo.parquet")
pd.read_parquet("foo.parquet")

df.to_excel("foo.xlsx", sheet_name="Sheet1")
pd.read_excel("foo.xlsx", "Sheet1", index_col=None, na_values=["NA"])

----------------------------------------

TITLE: Pivot Table Creation in Pandas
DESCRIPTION: Shows how to create a pivot table in pandas to aggregate and reshape data, similar to Excel's PivotTable functionality.

LANGUAGE: python
CODE:
pd.pivot_table(tips, values="tip", index=["size"], columns=["sex"], aggfunc=np.average)

----------------------------------------

TITLE: Loading Selective Columns from Parquet File in Pandas
DESCRIPTION: Demonstrates two approaches to load specific columns from a Parquet file: loading all data then filtering vs. loading only required columns directly.

LANGUAGE: python
CODE:
columns = ["id_0", "name_0", "x_0", "y_0"]

# Option 1: Load all then filter
pd.read_parquet("timeseries_wide.parquet")[columns]

# Option 2: Load only needed columns
pd.read_parquet("timeseries_wide.parquet", columns=columns)

----------------------------------------

TITLE: Working with categorical data in pandas
DESCRIPTION: Demonstrates operations on categorical data, including category renaming and reordering.

LANGUAGE: python
CODE:
df = pd.DataFrame({"id": [1, 2, 3, 4, 5, 6], "raw_grade": ["a", "b", "b", "a", "a", "e"]})
df["grade"] = df["raw_grade"].astype("category")
df["grade"] = df["grade"].cat.rename_categories(["very good", "good", "very bad"])
df["grade"] = df["grade"].cat.set_categories(["very bad", "bad", "medium", "good", "very good"])
df.sort_values(by="grade")
df.groupby("grade", observed=False).size()

----------------------------------------

TITLE: Adding Calculated Columns in SQL and Pandas
DESCRIPTION: Demonstrates how to add a calculated column to the result set in SQL and pandas. The pandas example uses the assign() method to create a new 'tip_rate' column.

LANGUAGE: sql
CODE:
SELECT *, tip/total_bill as tip_rate
FROM tips;

LANGUAGE: python
CODE:
tips.assign(tip_rate=tips["tip"] / tips["total_bill"])

----------------------------------------

TITLE: Importing Pandas Library in Python
DESCRIPTION: This snippet shows how to import the pandas library, which is essential for data manipulation and analysis in Python.

LANGUAGE: python
CODE:
import pandas as pd

----------------------------------------

TITLE: Modifying and Removing DataFrame Columns in Python Using Pandas
DESCRIPTION: Demonstrates how to perform vector operations on DataFrame columns by subtracting a value from 'total_bill', creating a new column 'new_bill' with calculated values, and then removing the newly created column using the drop() method.

LANGUAGE: python
CODE:
tips["total_bill"] = tips["total_bill"] - 2
tips["new_bill"] = tips["total_bill"] / 2
tips

tips = tips.drop("new_bill", axis=1)

----------------------------------------

TITLE: Creating a New Column with Calculation in Pandas DataFrame
DESCRIPTION: Creates a new column 'london_mg_per_cubic' by multiplying the 'station_london' column by a conversion factor of 1.882 to convert NO2 concentration to mg/m^3.

LANGUAGE: python
CODE:
air_quality["london_mg_per_cubic"] = air_quality["station_london"] * 1.882
air_quality.head()

----------------------------------------

TITLE: Nested Datatype Example
DESCRIPTION: Demonstrates current behavior with nested datatypes using dictionaries in pandas Series.

LANGUAGE: python
CODE:
In [6]: pd.Series([{'a': 1, 'b': 2}, {'a': 2, 'b': 99}])
Out[6]:
0     {'a': 1, 'b': 2}
1    {'a': 2, 'b': 99}
dtype: object

----------------------------------------

TITLE: Creating DataFrame from Dictionary
DESCRIPTION: Example showing how to create a DataFrame from a dictionary of Series

LANGUAGE: python
CODE:
d = {
    "one": pd.Series([1.0, 2.0, 3.0], index=["a", "b", "c"]),
    "two": pd.Series([1.0, 2.0, 3.0, 4.0], index=["a", "b", "c", "d"]),
}
df = pd.DataFrame(d)

----------------------------------------

TITLE: Date Functionality in pandas
DESCRIPTION: Shows various date operations in pandas, equivalent to Stata's date functions.

LANGUAGE: python
CODE:
df = pd.DataFrame()
df["date1"] = pd.Timestamp("2013-01-15")
df["date2"] = pd.Timestamp("2015-02-15")
df["date1_year"] = df["date1"].dt.year
df["date2_month"] = df["date2"].dt.month
df["date1_next"] = df["date1"] + pd.offsets.MonthBegin()
df["months_between"] = (
    df["date2"].dt.to_period("M") - df["date1"].dt.to_period("M")
)
print(df)

----------------------------------------

TITLE: Selecting Columns in SQL and Pandas
DESCRIPTION: Shows how to select specific columns from a dataset in both SQL and pandas. The pandas example uses indexing with a list of column names.

LANGUAGE: sql
CODE:
SELECT total_bill, tip, smoker, time
FROM tips;

LANGUAGE: python
CODE:
tips[["total_bill", "tip", "smoker", "time"]]

----------------------------------------

TITLE: Subsetting Data in R and pandas
DESCRIPTION: Shows how to subset data in R using subset() and the equivalent operations in pandas using query() and boolean indexing.

LANGUAGE: r
CODE:
df <- data.frame(a=rnorm(10), b=rnorm(10))
subset(df, a <= b)
df[df$a <= df$b,]  # note the comma

LANGUAGE: python
CODE:
df = pd.DataFrame({"a": np.random.randn(10), "b": np.random.randn(10)})
df.query("a <= b")
df[df["a"] <= df["b"]]
df.loc[df["a"] <= df["b"]]

----------------------------------------

TITLE: Updating Data in SQL and Pandas
DESCRIPTION: Demonstrates how to update data based on a condition in SQL and pandas. The pandas example uses loc accessor to modify values in-place.

LANGUAGE: sql
CODE:
UPDATE tips
SET tip = tip*2
WHERE tip < 2;

LANGUAGE: python
CODE:
tips.loc[tips["tip"] < 2, "tip"] *= 2

----------------------------------------

TITLE: Using Modin as a Drop-in Replacement for Pandas
DESCRIPTION: Shows how to use Modin as a parallel and distributed drop-in replacement for pandas.

LANGUAGE: python
CODE:
# import pandas as pd
import modin.pandas as pd

df = pd.read_csv("big.csv")  # use all your cores!

----------------------------------------

TITLE: Time Series Resampling in Pandas
DESCRIPTION: Demonstrates monthly resampling of hourly time series data using resample() method.

LANGUAGE: python
CODE:
monthly_max = no_2.resample("MS").max()
monthly_max

----------------------------------------

TITLE: Windowed Partitions Demonstration in Python
DESCRIPTION: Shows how windowed partitions are created in a rolling window operation.

LANGUAGE: python
CODE:
for window in s.rolling(window=2):
    print(window)

----------------------------------------

TITLE: GroupBy Operations in pandas
DESCRIPTION: Shows how to perform groupby operations in pandas, similar to Stata's collapse and bysort commands.

LANGUAGE: python
CODE:
# Aggregation
tips.groupby(["sex", "smoker"]).agg({"total_bill": "sum", "tip": "sum"})

# Transformation
tips["adj_total_bill"] = tips["total_bill"] - tips.groupby("smoker")["total_bill"].transform("mean")

# First observation by group
tips.groupby(["sex", "smoker"]).first()

----------------------------------------

TITLE: Union Operations in SQL and Pandas
DESCRIPTION: Demonstrates how to perform UNION and UNION ALL operations in SQL and their equivalents in pandas using concat() and drop_duplicates() methods.

LANGUAGE: sql
CODE:
SELECT city, rank
FROM df1
UNION ALL
SELECT city, rank
FROM df2;

LANGUAGE: python
CODE:
pd.concat([df1, df2])

# UNION (remove duplicates)
pd.concat([df1, df2]).drop_duplicates()

----------------------------------------

TITLE: Filtering DataFrame with Direct Boolean Indexing in Python
DESCRIPTION: This snippet demonstrates how to filter a DataFrame using direct boolean indexing. It selects rows where the 'total_bill' column has values greater than 10.

LANGUAGE: python
CODE:
tips[tips["total_bill"] > 10]

----------------------------------------

TITLE: Applying Function to Rename Columns in Pandas DataFrame
DESCRIPTION: Demonstrates using a function (str.lower) with the rename method to convert all column names to lowercase.

LANGUAGE: python
CODE:
air_quality_renamed = air_quality_renamed.rename(columns=str.lower)
air_quality_renamed.head()

----------------------------------------

TITLE: Creating a MultiIndex from tuples
DESCRIPTION: Demonstrates how to create a MultiIndex object from a list of tuples and use it to index a Series.

LANGUAGE: python
CODE:
arrays = [
    ["bar", "bar", "baz", "baz", "foo", "foo", "qux", "qux"],
    ["one", "two", "one", "two", "one", "two", "one", "two"],
]
tuples = list(zip(*arrays))
index = pd.MultiIndex.from_tuples(tuples, names=["first", "second"])
s = pd.Series(np.random.randn(8), index=index)

----------------------------------------

TITLE: Manipulating Dates and Times with Pandas in Python
DESCRIPTION: This code snippet demonstrates various date and time operations using Pandas. It creates timestamps, extracts year and month components, performs date arithmetic, and calculates the number of months between dates. The operations are performed on a DataFrame called 'tips'.

LANGUAGE: python
CODE:
tips["date1"] = pd.Timestamp("2013-01-15")
tips["date2"] = pd.Timestamp("2015-02-15")
tips["date1_year"] = tips["date1"].dt.year
tips["date2_month"] = tips["date2"].dt.month
tips["date1_next"] = tips["date1"] + pd.offsets.MonthBegin()
tips["months_between"] = tips["date2"].dt.to_period("M") - tips[
    "date1"
].dt.to_period("M")

tips[
    ["date1", "date2", "date1_year", "date2_month", "date1_next", "months_between"]
]

----------------------------------------

TITLE: Option Context Management
DESCRIPTION: Shows how to temporarily modify pandas options within a context block using option_context

LANGUAGE: python
CODE:
with pd.option_context("display.max_rows", 10, "display.max_columns", 5):
    print(pd.get_option("display.max_rows"))
    print(pd.get_option("display.max_columns"))
print(pd.get_option("display.max_rows"))
print(pd.get_option("display.max_columns"))

----------------------------------------

TITLE: Resetting Index before Addition in Python
DESCRIPTION: Example demonstrating how to reset indices before adding Series to get expected results.

LANGUAGE: python
CODE:
ser1.reset_index(drop=True) + ser2.reset_index(drop=True)

----------------------------------------

TITLE: Controlling Category Behavior
DESCRIPTION: Demonstrates how to control category behavior using CategoricalDtype including ordering and category specification

LANGUAGE: python
CODE:
from pandas.api.types import CategoricalDtype

cat_type = CategoricalDtype(categories=["b", "c", "d"], ordered=True)
s_cat = s.astype(cat_type)

----------------------------------------

TITLE: Grouping and Summarizing Data in R and pandas
DESCRIPTION: Demonstrates grouping and summarizing operations in R (using dplyr) and pandas.

LANGUAGE: r
CODE:
summary(df)
gdf <- group_by(df, col1)
summarise(gdf, avg=mean(col1, na.rm=TRUE))
summarise(gdf, total=sum(col1))

LANGUAGE: python
CODE:
df.describe()
gdf = df.groupby('col1')
df.groupby('col1').agg({'col1': 'mean'})
df.groupby('col1').sum()

----------------------------------------

TITLE: Installing Pandas with Conda
DESCRIPTION: Commands to install pandas using the Conda package manager from conda-forge channel and create a virtual environment

LANGUAGE: shell
CODE:
conda install -c conda-forge pandas

LANGUAGE: shell
CODE:
conda create -c conda-forge -n name_of_my_env python pandas
# On Linux or MacOS
source activate name_of_my_env
# On Windows
activate name_of_my_env

----------------------------------------

TITLE: Creating a pie chart
DESCRIPTION: Shows how to create a pie chart from a Series.

LANGUAGE: python
CODE:
series = pd.Series(3 * np.random.rand(4), index=["a", "b", "c", "d"], name="series")

series.plot.pie(figsize=(6, 6));

----------------------------------------

TITLE: Converting Between Dense and Sparse DataFrames in Python
DESCRIPTION: This code shows how to convert data between sparse and dense formats using the .sparse accessor and astype() method with SparseDtype.

LANGUAGE: python
CODE:
sdf.sparse.to_dense()

dense = pd.DataFrame({"A": [1, 0, 0, 1]})
dtype = pd.SparseDtype(int, fill_value=0)
dense.astype(dtype)

----------------------------------------

TITLE: Creating Conditional Column with np.where in Pandas
DESCRIPTION: Creates a new 'bucket' column in the tips DataFrame using numpy's where method to categorize total_bill values as either 'low' or 'high' based on whether they are less than 10.

LANGUAGE: python
CODE:
tips["bucket"] = np.where(tips["total_bill"] < 10, "low", "high")
tips

----------------------------------------

TITLE: Time Series Aggregation with GroupBy
DESCRIPTION: Calculates average NO2 concentration by weekday and location using datetime properties.

LANGUAGE: python
CODE:
air_quality.groupby([air_quality["datetime"].dt.weekday, "location"])["value"].mean()

----------------------------------------

TITLE: String Methods Operations
DESCRIPTION: Demonstrates common string operations like lower(), upper() and len()

LANGUAGE: python
CODE:
s = pd.Series(["A", "B", "C", "Aaba", "Baca", np.nan, "CABA", "dog", "cat"], dtype="string")
s.str.lower()
s.str.upper()
s.str.len()

----------------------------------------

TITLE: New Resample API Example
DESCRIPTION: Shows the new groupby-like API for resampling operations

LANGUAGE: python
CODE:
r = df.resample('2s')
r.mean()

----------------------------------------

TITLE: Creating a bar plot
DESCRIPTION: Shows how to create a bar plot from a DataFrame row.

LANGUAGE: python
CODE:
plt.figure()

df.iloc[5].plot(kind="bar");

----------------------------------------

TITLE: Installing Pandas via PyPI
DESCRIPTION: Command to install Pandas library using pip package manager from PyPI

LANGUAGE: shell
CODE:
pip install pandas

----------------------------------------

TITLE: Creating a complex styled DataFrame
DESCRIPTION: Creates a DataFrame with multiple index levels and applies various styles.

LANGUAGE: python
CODE:
idx = pd.Index(["Tumour (Positive)", "Non-Tumour (Negative)"], name="Actual Label:")
cols = pd.MultiIndex.from_product(
    [["Decision Tree", "Regression", "Random"], ["Tumour", "Non-Tumour"]],
    names=["Model:", "Predicted:"],
)
df = pd.DataFrame(
    [[38.0, 2.0, 18.0, 22.0, 21, np.nan], [19, 439, 6, 452, 226, 232]],
    index=idx,
    columns=cols,
)
df.style

----------------------------------------

TITLE: Configuring Pandas Options API Functions
DESCRIPTION: Core functions for managing pandas global options and settings, including describing, resetting, getting, and setting options, plus context management.

LANGUAGE: python
CODE:
describe_option
reset_option
get_option
set_option
option_context

----------------------------------------

TITLE: Sorting Data in R and pandas
DESCRIPTION: Shows how to sort data in R (using dplyr) and pandas.

LANGUAGE: r
CODE:
arrange(df, col1, col2)
arrange(df, desc(col1))

LANGUAGE: python
CODE:
df.sort_values(['col1', 'col2'])
df.sort_values('col1', ascending=False)

----------------------------------------

TITLE: Concatenating DataFrames with Pandas
DESCRIPTION: Demonstrates vertical concatenation of NO2 and PM2.5 data tables using pd.concat(). Shows both basic concatenation and concatenation with keys for hierarchical indexing.

LANGUAGE: python
CODE:
air_quality = pd.concat([air_quality_pm25, air_quality_no2], axis=0)
air_quality.head()

air_quality_ = pd.concat([air_quality_pm25, air_quality_no2], keys=["PM25", "NO2"])
air_quality_.head()

----------------------------------------

TITLE: Demonstrating DataFrame.__dataframe__ bug fix for nullable boolean columns
DESCRIPTION: This snippet references a bug fix for the DataFrame.__dataframe__ method, which was producing incorrect data buffers for nullable boolean columns.

LANGUAGE: Python
CODE:
DataFrame.__dataframe__

----------------------------------------

TITLE: Pandas Startup Configuration
DESCRIPTION: Example startup script for configuring pandas options at environment initialization

LANGUAGE: python
CODE:
import pandas as pd

pd.set_option("display.max_rows", 999)
pd.set_option("display.precision", 5)

----------------------------------------

TITLE: DataFrame Assign Example
DESCRIPTION: Demonstrates the new DataFrame.assign method for creating new columns based on existing data

LANGUAGE: python
CODE:
iris = pd.read_csv('data/iris.data')
iris.assign(sepal_ratio=lambda x: x['SepalWidth'] / x['SepalLength']).head()

----------------------------------------

TITLE: Plotting a Single Column from Pandas DataFrame
DESCRIPTION: Create a line plot for a specific column (station_paris) from the DataFrame.

LANGUAGE: python
CODE:
air_quality["station_paris"].plot()
plt.show()

----------------------------------------

TITLE: Using Experimental NA Scalar
DESCRIPTION: Example showing how to create a Series using the new experimental pd.NA missing value indicator with the nullable integer dtype

LANGUAGE: python
CODE:
s = pd.Series([1, 2, None], dtype="Int64")
s
s[2]

----------------------------------------

TITLE: Listing Available Plot Methods in Pandas
DESCRIPTION: Display all available plotting methods for a Pandas DataFrame using list comprehension.

LANGUAGE: python
CODE:
[method_name for method_name in dir(air_quality.plot) if not method_name.startswith("_")]

----------------------------------------

TITLE: Registering Custom DataFrame Accessor in Python
DESCRIPTION: Shows how to create a custom 'geo' accessor for pandas DataFrames to add geography-related functionality. The accessor validates required columns and provides center point calculation and plotting capabilities.

LANGUAGE: python
CODE:
@pd.api.extensions.register_dataframe_accessor("geo")
class GeoAccessor:
    def __init__(self, pandas_obj):
        self._validate(pandas_obj)
        self._obj = pandas_obj

    @staticmethod
    def _validate(obj):
        # verify there is a column latitude and a column longitude
        if "latitude" not in obj.columns or "longitude" not in obj.columns:
            raise AttributeError("Must have 'latitude' and 'longitude'.")

    @property
    def center(self):
        # return the geographic center point of this DataFrame
        lat = self._obj.latitude
        lon = self._obj.longitude
        return (float(lon.mean()), float(lat.mean()))

    def plot(self):
        # plot this array's data on a map, e.g., using Cartopy
        pass

----------------------------------------

TITLE: Performing Left Join on pandas DataFrames
DESCRIPTION: This snippet shows how to perform a left join on two DataFrames using the merge() method. It joins df1 and df2 on the 'key' column with the 'left' join type.

LANGUAGE: python
CODE:
left_join = df1.merge(df2, on=["key"], how="left")
left_join

----------------------------------------

TITLE: Creating a scatter plot
DESCRIPTION: Demonstrates how to create a scatter plot using DataFrame columns.

LANGUAGE: python
CODE:
df3 = pd.DataFrame(np.random.randn(1000, 2), columns=["B", "C"]).cumsum()
df3["A"] = pd.Series(list(range(len(df))))

df3.plot(x="A", y="B");

----------------------------------------

TITLE: Using Series.str.get_dummies for indicator variables
DESCRIPTION: Demonstrates the new Series.str.get_dummies method for extracting dummy/indicator variables from separated string columns.

LANGUAGE: python
CODE:
s = pd.Series(["a", "a|b", np.nan, "a|c"])
s.str.get_dummies(sep="|")

----------------------------------------

TITLE: Creating DataFrame with Multiple Data Types in Python
DESCRIPTION: Demonstrates creating a DataFrame with various data types including int64, float64, datetime64, timedelta64, complex128, object, bool and categorical. Shows how to check memory usage of the DataFrame.

LANGUAGE: python
CODE:
dtypes = [
    "int64",
    "float64", 
    "datetime64[ns]",
    "timedelta64[ns]",
    "complex128",
    "object",
    "bool",
]
n = 5000
data = {t: np.random.randint(100, size=n).astype(t) for t in dtypes}
df = pd.DataFrame(data)
df["categorical"] = df["object"].astype("category")

df.info()

----------------------------------------

TITLE: DataFrame and Series Aggregation
DESCRIPTION: Example demonstrating the new .agg() API for Series/DataFrame which provides consistent interface across groupby-rolling-resample operations.

LANGUAGE: python
CODE:
df = pd.DataFrame(np.random.randn(10, 3), columns=['A', 'B', 'C'],
                     index=pd.date_range('1/1/2000', periods=10))
df.iloc[3:7] = np.nan
df

# Single function 
df.agg('sum')

# Multiple functions
df.agg(['sum', 'min'])

# Dict with column-specific aggregations 
df.agg({'A': ['sum', 'min'], 'B': ['min', 'max']})

----------------------------------------

TITLE: Importing matplotlib and setting up basic plot
DESCRIPTION: Imports matplotlib, sets up a random time series, and creates a basic line plot.

LANGUAGE: python
CODE:
import matplotlib.pyplot as plt

plt.close("all")

np.random.seed(123456)

ts = pd.Series(np.random.randn(1000), index=pd.date_range("1/1/2000", periods=1000))
ts = ts.cumsum()

ts.plot();

----------------------------------------

TITLE: Creating an area plot
DESCRIPTION: Demonstrates creating a stacked area plot from a DataFrame.

LANGUAGE: python
CODE:
df = pd.DataFrame(np.random.rand(10, 4), columns=["a", "b", "c", "d"])

df.plot.area();

----------------------------------------

TITLE: Creating a weather DataFrame
DESCRIPTION: Creates a DataFrame with random weather data and defines functions to style it.

LANGUAGE: python
CODE:
weather_df = pd.DataFrame(
    np.random.default_rng().random((10, 2)) * 5,
    index=pd.date_range(start="2021-01-01", periods=10),
    columns=["Tokyo", "Beijing"],
)


def rain_condition(v):
    if v < 1.75:
        return "Dry"
    elif v < 2.75:
        return "Rain"
    return "Heavy Rain"


def make_pretty(styler):
    styler.set_caption("Weather Conditions")
    styler.format(rain_condition)
    styler.format_index(lambda v: v.strftime("%A"))
    styler.background_gradient(axis=None, vmin=1, vmax=5, cmap="YlGnBu")
    return styler


weather_df

----------------------------------------

TITLE: Creating a Series from Scratch
DESCRIPTION: Shows how to create a pandas Series directly from a list of values with a name attribute

LANGUAGE: python
CODE:
ages = pd.Series([22, 35, 58], name="Age")
ages

----------------------------------------

TITLE: Fixing DataFrame Constructor Broadcasting in Python
DESCRIPTION: Fixed a regression where the DataFrame constructor failed to broadcast for a defined Index and a length-one list of Timestamp.

LANGUAGE: python
CODE:
DataFrame(data, index=defined_index)

----------------------------------------

TITLE: Creating a scatter plot with additional options
DESCRIPTION: Shows how to create a scatter plot with color mapping and size variation.

LANGUAGE: python
CODE:
df.plot.scatter(x="a", y="b", c="c", s=50);

----------------------------------------

TITLE: Creating MultiIndex from product of iterables
DESCRIPTION: Shows how to use the new MultiIndex.from_product convenience function to create a MultiIndex from the cartesian product of iterables.

LANGUAGE: python
CODE:
shades = ["light", "dark"]
colors = ["red", "green", "blue"]

pd.MultiIndex.from_product([shades, colors], names=["shade", "color"])

----------------------------------------

TITLE: Creating and manipulating TimedeltaIndex in Python using pandas
DESCRIPTION: Shows how to create a TimedeltaIndex using various methods, including string parsing and timedelta_range. Also demonstrates operations and selections on TimedeltaIndex.

LANGUAGE: python
CODE:
pd.TimedeltaIndex(
    [
        "1 days",
        "1 days, 00:00:05",
        np.timedelta64(2, "D"),
        datetime.timedelta(days=2, seconds=2),
    ]
)

pd.TimedeltaIndex(["0 days", "10 days", "20 days"], freq="infer")

pd.timedelta_range(start="1 days", periods=5)

s = pd.Series(
    np.arange(100),
    index=pd.timedelta_range("1 days", periods=100, freq="h"),
)
s

s["1 day":"2 day"]
s["1 day 01:00:00"]
s[pd.Timedelta("1 day 1h")]

----------------------------------------

TITLE: Groupby NA Support
DESCRIPTION: Example showing new dropna parameter in groupby() that allows NA values in group keys

LANGUAGE: ipython
CODE:
df_list = [[1, 2, 3], [1, None, 4], [2, 1, 3], [1, 2, 2]]
df_dropna = pd.DataFrame(df_list, columns=["a", "b", "c"])

df_dropna

# Default ``dropna`` is set to True, which will exclude NaNs in keys
df_dropna.groupby(by=["b"], dropna=True).sum()

# In order to allow NaN in keys, set ``dropna`` to False
df_dropna.groupby(by=["b"], dropna=False).sum()

----------------------------------------

TITLE: Creating a box plot
DESCRIPTION: Shows how to create a box plot from a DataFrame.

LANGUAGE: python
CODE:
df = pd.DataFrame(np.random.rand(10, 5), columns=["A", "B", "C", "D", "E"])

df.plot.box();

----------------------------------------

TITLE: Using PyArrow-backed string data type
DESCRIPTION: Shows how to create a Series with PyArrow-backed string data type

LANGUAGE: python
CODE:
pd.Series(['abc', None, 'def'], dtype=pd.StringDtype(storage="pyarrow"))

----------------------------------------

TITLE: Using groupby positional indexing
DESCRIPTION: Shows new capabilities for specifying positional ranges relative to the ends of each group in groupby operations.

LANGUAGE: python
CODE:
df = pd.DataFrame([["g", "g0"], ["g", "g1"], ["g", "g2"], ["g", "g3"],
                   ["h", "h0"], ["h", "h1"]], columns=["A", "B"])
df.groupby("A").head(-1)

df.groupby("A").nth(slice(1, -1))
df.groupby("A").nth([slice(None, 1), slice(-1, None)])

df.groupby("A").nth[1, -1]
df.groupby("A").nth[1:-1]
df.groupby("A").nth[:1, -1:]

----------------------------------------

TITLE: Accessing Scalar NA Value in IntegerArray
DESCRIPTION: Demonstrates that slicing a single missing element from an IntegerArray returns pandas.NA as the scalar missing value.

LANGUAGE: python
CODE:
a = pd.array([1, None], dtype="Int64")
a[1]

----------------------------------------

TITLE: Converting Dtypes in Pandas DataFrames
DESCRIPTION: This code demonstrates various methods of dtype conversion in pandas, including astype() for explicit conversion, convert_objects() for mixed conversion, and date coercion. It shows how different dtypes are handled and converted.

LANGUAGE: Python
CODE:
df3.values.dtype

df3.astype('float32').dtypes

df3['D'] = '1.'
df3['E'] = '1'
df3.convert_objects(convert_numeric=True).dtypes

# same, but specific dtype conversion
df3['D'] = df3['D'].astype('float16')
df3['E'] = df3['E'].astype('int32')
df3.dtypes

import datetime
s = pd.Series([datetime.datetime(2001, 1, 1, 0, 0), 'foo', 1.0, 1,
               pd.Timestamp('20010104'), '20010105'], dtype='O')
s.convert_objects(convert_dates='coerce')

----------------------------------------

TITLE: Handling NA-like Values in IntegerArray
DESCRIPTION: Demonstrates how various NA-like values (np.nan, None, pd.NA) are all replaced with pandas.NA in an IntegerArray.

LANGUAGE: python
CODE:
pd.array([1, 2, np.nan, None, pd.NA], dtype="Int64")

----------------------------------------

TITLE: Using tight dictionary format in DataFrame.to_dict
DESCRIPTION: Shows the new 'tight' dictionary format available in DataFrame.from_dict and DataFrame.to_dict methods, which preserves MultiIndex entries and names.

LANGUAGE: python
CODE:
df = pd.DataFrame.from_records(
    [[1, 3], [2, 4]],
    index=pd.MultiIndex.from_tuples([('a', 'b'), ('a', 'c')],
                                    names=['n1', 'n2']),
    columns=pd.MultiIndex.from_tuples([('x', 1), ('y', 2)],
                                      names=['z1', 'z2']),
)
df
df.to_dict(orient='tight')

----------------------------------------

TITLE: Creating a hexbin plot
DESCRIPTION: Demonstrates creating a hexbin plot from a DataFrame.

LANGUAGE: python
CODE:
df = pd.DataFrame(np.random.randn(1000, 2), columns=["a", "b"])
df["b"] = df["b"] + np.arange(1000)

df.plot.hexbin(x="a", y="b", gridsize=25);

----------------------------------------

TITLE: Creating a Series with IntegerArray
DESCRIPTION: Shows how to create a pandas Series using an IntegerArray, allowing for integer data with missing values in a Series.

LANGUAGE: python
CODE:
pd.Series(arr)

----------------------------------------

TITLE: Reading XML data with pandas
DESCRIPTION: Shows how to read XML data into a pandas DataFrame using pd.read_xml()

LANGUAGE: python
CODE:
xml = """<?xml version='1.0' encoding='utf-8'?>
<data>
 <row>
    <shape>square</shape>
    <degrees>360</degrees>
    <sides>4.0</sides>
 </row>
 <row>
    <shape>circle</shape>
    <degrees>360</degrees>
    <sides/>
 </row>
 <row>
    <shape>triangle</shape>
    <degrees>180</degrees>
    <sides>3.0</sides>
 </row>
 </data>"""

df = pd.read_xml(xml)
df

----------------------------------------

TITLE: By Group Processing in pandas
DESCRIPTION: This Python code snippet demonstrates the equivalent of SAS by group processing in pandas, using groupby and first() method.

LANGUAGE: python
CODE:
tips.groupby(["sex", "smoker"]).first()

----------------------------------------

TITLE: Concatenating Series with ignore_index in Python
DESCRIPTION: Example showing how concatenation with ignore_index=True still aligns on the index, producing unexpected results.

LANGUAGE: python
CODE:
pd.concat([ser1, ser2], axis=1, ignore_index=True)

----------------------------------------

TITLE: Explicit Dtype Specification for IntegerArray
DESCRIPTION: Demonstrates how to explicitly specify the Int64 dtype when creating arrays or series to avoid confusion in dtype inference.

LANGUAGE: python
CODE:
pd.array([1, None], dtype="Int64")
pd.Series([1, None], dtype="Int64")

----------------------------------------

TITLE: Selecting Data from Timestamp-Indexed Series and DataFrames in Pandas
DESCRIPTION: This code shows how to select data from Series and DataFrames with timestamp indices using string-based selection. It demonstrates selecting data for a specific year from both ordered and unordered timeseries.

LANGUAGE: Python
CODE:
idx = pd.date_range("2001-10-1", periods=5, freq='M')
ts = pd.Series(np.random.rand(len(idx)), index=idx)
ts['2001']
df = pd.DataFrame({'A': ts})
df['2001']

----------------------------------------

TITLE: Comparing Pandas Boolean and Object dtype Logical Operations
DESCRIPTION: Demonstrates the difference in behavior between pandas boolean dtype and object dtype when performing logical operations with np.nan values.

LANGUAGE: python
CODE:
pd.Series([True, False, np.nan], dtype="object") | True
pd.Series([True, False, np.nan], dtype="boolean") | True

LANGUAGE: python
CODE:
pd.Series([True, False, np.nan], dtype="object") & True
pd.Series([True, False, np.nan], dtype="boolean") & True

----------------------------------------

TITLE: Using dependent arguments with DataFrame.assign()
DESCRIPTION: The DataFrame.assign() method now accepts dependent keyword arguments for Python 3.6+. Later keyword arguments may refer to earlier ones if the argument is a callable.

LANGUAGE: python
CODE:
df = pd.DataFrame({'A': [1, 2, 3]})
df.assign(B=df.A, C=lambda x: x['A'] + x['B'])

----------------------------------------

TITLE: Basic Pandas DataFrame Setup in Python
DESCRIPTION: Creates a sample DataFrame with random data for performance testing.

LANGUAGE: python
CODE:
df = pd.DataFrame({
    "a": np.random.randn(1000),
    "b": np.random.randn(1000),
    "N": np.random.randint(100, 1000, (1000)),
    "x": "x",
})

----------------------------------------

TITLE: Implementing ExtensionArray Operator Support in Python
DESCRIPTION: Example showing how to implement operator support for custom ExtensionArrays by inheriting from ExtensionScalarOpsMixin and adding arithmetic and comparison operations.

LANGUAGE: python
CODE:
from pandas.api.extensions import ExtensionArray, ExtensionScalarOpsMixin

class MyExtensionArray(ExtensionArray, ExtensionScalarOpsMixin):
    pass

MyExtensionArray._add_arithmetic_ops()
MyExtensionArray._add_comparison_ops()

----------------------------------------

TITLE: Series.explode to split list-like values
DESCRIPTION: Demonstrates the new explode method to transform list-like values to individual rows.

LANGUAGE: python
CODE:
df = pd.DataFrame([{'var1': 'a,b,c', 'var2': 1},
                       {'var1': 'd,e,f', 'var2': 2}])

df.assign(var1=df.var1.str.split(',')).explode('var1')

----------------------------------------

TITLE: Arithmetic Operations with IntegerArray
DESCRIPTION: Demonstrates arithmetic operations on a Series with Int64 dtype, showing how missing values are propagated and data is coerced when needed.

LANGUAGE: python
CODE:
s = pd.Series([1, 2, None], dtype="Int64")

# arithmetic
s + 1

# comparison
s == 1

# slicing operation
s.iloc[1:3]

# operate with other dtypes
s + s.iloc[1:3].astype("Int8")

# coerce when needed
s + 0.01

----------------------------------------

TITLE: Using the Squeeze Method in Pandas to Remove Length 1 Dimensions
DESCRIPTION: This code demonstrates the use of the squeeze method in pandas to remove length 1 dimensions from Panel and DataFrame objects. It shows how squeeze can simplify the structure of the data when certain dimensions have only one element.

LANGUAGE: Python
CODE:
p = pd.Panel(np.random.randn(3, 4, 4), items=['ItemA', 'ItemB', 'ItemC'],
             major_axis=pd.date_range('20010102', periods=4),
             minor_axis=['A', 'B', 'C', 'D'])
p
p.reindex(items=['ItemA']).squeeze()
p.reindex(items=['ItemA'], minor=['B']).squeeze()

----------------------------------------

TITLE: Creating and Displaying a Sparse Series in Python
DESCRIPTION: This snippet demonstrates how to create a sparse Series from a numpy array with NaN values. It shows the resulting sparse dtype and how non-NaN elements are stored.

LANGUAGE: python
CODE:
arr = np.random.randn(10)
arr[2:-2] = np.nan
ts = pd.Series(pd.arrays.SparseArray(arr))
ts

----------------------------------------

TITLE: Changing imports for pandas-datareader
DESCRIPTION: The pandas.io.data package is deprecated and replaced by pandas-datareader. This code shows how to update imports.

LANGUAGE: python
CODE:
from pandas.io import data, wb

# becomes

from pandas_datareader import data, wb

----------------------------------------

TITLE: Dtype Inference in Pandas Array and Series
DESCRIPTION: Illustrates the different dtype inference rules between pandas.array and pandas.Series when dealing with integer data and missing values.

LANGUAGE: python
CODE:
pd.array([1, None])
pd.array([1, 2])
pd.Series([1, None])
pd.Series([1, 2])

----------------------------------------

TITLE: Creating Columns with NA Values in Pandas DataFrames
DESCRIPTION: Shows how creating a column of NA values affects the dtype, and provides a better approach for creating such columns with the appropriate dtype.

LANGUAGE: python
CODE:
df = pd.DataFrame()
df['objects'] = pd.NA
df.dtypes

----------------------------------------

TITLE: Creating IntegerArray with String Alias
DESCRIPTION: Shows how to create an IntegerArray using the string alias 'Int64' as the dtype. This differentiates from NumPy's 'int64' dtype.

LANGUAGE: python
CODE:
pd.array([1, 2, np.nan], dtype="Int64")

----------------------------------------

TITLE: Using rank function with rolling windows
DESCRIPTION: Demonstrates the new rank function added to Rolling and Expanding classes, supporting method, ascending, and pct flags of DataFrame.rank.

LANGUAGE: python
CODE:
s = pd.Series([1, 4, 2, 3, 5, 3])
s.rolling(3).rank()

s.rolling(3).rank(method='max')

----------------------------------------

TITLE: merge_asof Example
DESCRIPTION: Example demonstrating the new merge_asof function for asof-style joining of time-series data

LANGUAGE: python
CODE:
pd.merge_asof(trades, quotes, on='time', by='ticker')

----------------------------------------

TITLE: Defining a method with a well-structured docstring
DESCRIPTION: Example of a pandas Series method with a complete docstring including all recommended sections.

LANGUAGE: python
CODE:
class Series:
    def head(self, n=5):
        """
        Return the first elements of the Series.

        This function is mainly useful to preview the values of the
        Series without displaying all of it.

        Parameters
        ----------
        n : int
            Number of values to return.

        Return
        ------
        pandas.Series
            Subset of the original series with the n first values.

        See Also
        --------
        tail : Return the last n elements of the Series.

        Examples
        --------
        >>> ser = pd.Series(['Ant', 'Bear', 'Cow', 'Dog', 'Falcon',
        ...                'Lion', 'Monkey', 'Rabbit', 'Zebra'])
        >>> ser.head()
        0   Ant
        1   Bear
        2   Cow
        3   Dog
        4   Falcon
        dtype: object

        With the ``n`` parameter, we can change the number of returned rows:

        >>> ser.head(n=3)
        0   Ant
        1   Bear
        2   Cow
        dtype: object
        """
        return self.iloc[:n]

----------------------------------------

TITLE: Using PyTables with pandas HDFStore
DESCRIPTION: Demonstrates various operations with PyTables and pandas HDFStore, including appending DataFrames, selecting data with queries, storing Panels, and using hierarchical keys.

LANGUAGE: python
CODE:
store = pd.HDFStore('store.h5')

df = pd.DataFrame(np.random.randn(8, 3),
                  index=pd.date_range('1/1/2000', periods=8),
                  columns=['A', 'B', 'C'])

df

# appending data frames
df1 = df[0:4]
df2 = df[4:]
store.append('df', df1)
store.append('df', df2)
store

# selecting the entire store
store.select('df')

wp = pd.Panel(np.random.randn(2, 5, 4), items=['Item1', 'Item2'],
              major_axis=pd.date_range('1/1/2000', periods=5),
              minor_axis=['A', 'B', 'C', 'D'])

wp

# storing a panel
store.append('wp', wp)

# selecting via A QUERY
store.select('wp', [pd.Term('major_axis>20000102'),
                    pd.Term('minor_axis', '=', ['A', 'B'])])

# removing data from tables
store.remove('wp', pd.Term('major_axis>20000103'))
store.select('wp')

# deleting a store
del store['df']
store

# hierarchical keys
store.put('foo/bar/bah', df)
store.append('food/orange', df)
store.append('food/apple', df)
store

# remove all nodes under this level
store.remove('food')
store

# mixed-dtype support
df['string'] = 'string'
df['int'] = 1
store.append('df', df)
df1 = store.select('df')
df1
df1.get_dtype_counts()

----------------------------------------

TITLE: Using Sparse Accessor in pandas Series
DESCRIPTION: This code demonstrates the use of the .sparse accessor for Series with sparse data. It shows how to access sparse-specific attributes like density and fill_value.

LANGUAGE: python
CODE:
s = pd.Series([0, 0, 1, 2], dtype="Sparse[int]")
s.sparse.density
s.sparse.fill_value

----------------------------------------

TITLE: Using the new Categorical dtype
DESCRIPTION: Example of creating and manipulating data with the new Categorical dtype.

LANGUAGE: python
CODE:
cat = pd.Categorical(["C", "A", "B", "C"], categories=["A", "B", "C"], ordered=True)
cat
cat.unique()

cat = pd.Categorical(["C", "A", "B", "C"], categories=["A", "B", "C"])
cat
cat.unique()

----------------------------------------

TITLE: Reduction and Groupby Operations with IntegerArray
DESCRIPTION: Shows how reduction (sum) and groupby operations work with DataFrames containing IntegerArray columns.

LANGUAGE: python
CODE:
df.sum(numeric_only=True)
df.sum()
df.groupby("B").A.sum()

----------------------------------------

TITLE: Merging and Casting IntegerArray in DataFrames
DESCRIPTION: Demonstrates merging and casting operations with DataFrames containing IntegerArray columns.

LANGUAGE: python
CODE:
pd.concat([df[["A"]], df[["B", "C"]]], axis=1).dtypes
df["A"].astype(float)

----------------------------------------

TITLE: Registering Custom Extensions in Pandas
DESCRIPTION: Core registration methods available in pandas.api.extensions for registering custom data types and accessors for DataFrames, Series and Index objects. These methods allow extending pandas' functionality with custom implementations.

LANGUAGE: python
CODE:
api.extensions.register_extension_dtype
api.extensions.register_dataframe_accessor
api.extensions.register_series_accessor
api.extensions.register_index_accessor

----------------------------------------

TITLE: Setting Up Virtual Environment for Pandas Development on Unix/macOS
DESCRIPTION: Commands to create a virtual environment, activate it, and install development dependencies for Pandas on Unix/macOS systems.

LANGUAGE: bash
CODE:
python3 -m venv ~/virtualenvs/pandas-dev
. ~/virtualenvs/pandas-dev/bin/activate
python -m pip install -r requirements-dev.txt

----------------------------------------

TITLE: Handling infinity values in pandas isnull and fillna
DESCRIPTION: Demonstrates how infinity and negative infinity are no longer treated as NA by default in isnull and notnull functions. Shows how to re-enable the old behavior using the use_inf_as_null option.

LANGUAGE: python
CODE:
s = pd.Series([1.5, np.inf, 3.4, -np.inf])

pd.isnull(s)

s.fillna(0)

pd.set_option('use_inf_as_null', True)

pd.isnull(s)

s.fillna(0)

pd.reset_option('use_inf_as_null')

----------------------------------------

TITLE: Creating Sparse Series from scipy.sparse.coo_matrix in Python
DESCRIPTION: This snippet demonstrates how to create a Series with sparse values from a scipy.sparse.coo_matrix using the Series.sparse.from_coo() method.

LANGUAGE: python
CODE:
from scipy import sparse
A = sparse.coo_matrix(([3.0, 1.0, 2.0], ([1, 0, 0], [0, 2, 3])), shape=(3, 4))
A
A.todense()

ss = pd.Series.sparse.from_coo(A)
ss

ss_dense = pd.Series.sparse.from_coo(A, dense_index=True)
ss_dense

----------------------------------------

TITLE: Demonstrating New Behavior of dt Accessors in Pandas 0.15.1
DESCRIPTION: Shows how dt accessors like .dt.hour now return np.nan for missing values instead of -1 as in previous versions.

LANGUAGE: python
CODE:
s = pd.Series(pd.date_range("20130101", periods=5, freq="D"))
s.iloc[2] = np.nan
s

s.dt.hour

----------------------------------------

TITLE: Using Custom PyArrow Types
DESCRIPTION: Shows how to use custom PyArrow types with parameters by creating Series with list, time, and decimal types.

LANGUAGE: python
CODE:
import pyarrow as pa
list_str_type = pa.list_(pa.string())
ser = pd.Series([["hello"], ["there"]], dtype=pd.ArrowDtype(list_str_type))

from datetime import time
idx = pd.Index([time(12, 30), None], dtype=pd.ArrowDtype(pa.time64("us")))

from decimal import Decimal
decimal_type = pd.ArrowDtype(pa.decimal128(3, scale=2))
data = [[Decimal("3.19"), None], [None, Decimal("-1.23")]]
df = pd.DataFrame(data, dtype=decimal_type)

----------------------------------------

TITLE: Running Pandas Tests in Python
DESCRIPTION: Command to run the pandas test suite using pytest after setting up the development environment.

LANGUAGE: bash
CODE:
python -m pytest pandas

----------------------------------------

TITLE: Comparing Memory Usage of Dense and Sparse DataFrames in Python
DESCRIPTION: This snippet compares the memory usage of dense and sparse DataFrames, showing the significant memory savings of sparse structures for data with many repeated values.

LANGUAGE: python
CODE:
'dense : {:0.2f} bytes'.format(df.memory_usage().sum() / 1e3)
'sparse: {:0.2f} bytes'.format(sdf.memory_usage().sum() / 1e3)

----------------------------------------

TITLE: Numba JIT Compilation Example
DESCRIPTION: Example of using Numba's just-in-time compilation to speed up numerical operations.

LANGUAGE: python
CODE:
@numba.jit
def apply_integrate_f_numba(col_a, col_b, col_N):
    n = len(col_N)
    result = np.empty(n, dtype='float64')
    assert len(col_a) == len(col_b) == n
    for i in range(n):
        result[i] = integrate_f_numba(col_a[i], col_b[i], col_N[i])
    return result

----------------------------------------

TITLE: Fixing RangeIndex Methods in Python
DESCRIPTION: Resolved an issue where RangeIndex.where and RangeIndex.putmask were raising AssertionError when the result did not represent a RangeIndex.

LANGUAGE: python
CODE:
range_index.where(condition)

----------------------------------------

TITLE: Building Single Documentation Page
DESCRIPTION: Command to build a single documentation page using the make.py script.

LANGUAGE: bash
CODE:
python make.py --single development/contributing_gitpod.rst

----------------------------------------

TITLE: Demonstrating GroupBy Behavior with Categorical Data in Pandas
DESCRIPTION: Example showing the behavior change in pandas 1.5.1 regarding groupby operations with categorical groupers and NA values.

LANGUAGE: python
CODE:
df = pd.DataFrame(
    {
        "x": pd.Categorical([1, None], categories=[1, 2, 3]),
        "y": [3, 4],
    }
)

LANGUAGE: python
CODE:
# Incorrect behavior, NA values are dropped
df.groupby("x", observed=True, dropna=False).sum()

LANGUAGE: python
CODE:
# Correct behavior, unobserved categories present (NA values still dropped)
df.groupby("x", observed=False, dropna=False).sum()

----------------------------------------

TITLE: Group-by Operations in pandas
DESCRIPTION: Demonstrates how to perform group-by operations in pandas, which is equivalent to SPSS's split-file analysis using Data > Split File.

LANGUAGE: python
CODE:
tips.groupby("sex")[["total_bill", "tip"]].agg(["mean", "std", "min", "max"])

----------------------------------------

TITLE: PyArrow Array Operations
DESCRIPTION: Demonstrates operations with PyArrow-backed arrays including numeric operations, string operations, and datetime functionality.

LANGUAGE: python
CODE:
import pyarrow as pa
ser = pd.Series([-1.545, 0.211, None], dtype="float32[pyarrow]")
ser.mean()
ser + ser
ser > (ser + 1)

ser_str = pd.Series(["a", "b", None], dtype=pd.ArrowDtype(pa.string()))
ser_str.str.startswith("a")

from datetime import datetime
pa_type = pd.ArrowDtype(pa.timestamp("ns"))
ser_dt = pd.Series([datetime(2022, 1, 1), None], dtype=pa_type)
ser_dt.dt.strftime("%Y-%m")

----------------------------------------

TITLE: Querying and Filtering Data in R and pandas
DESCRIPTION: Demonstrates equivalent operations for querying, filtering, and sampling data in R (using dplyr) and pandas.

LANGUAGE: r
CODE:
dim(df)
head(df)
slice(df, 1:10)
filter(df, col1 == 1, col2 == 1)
df[df$col1 == 1 & df$col2 == 1,]
select(df, col1, col2)
select(df, col1:col3)
select(df, -(col1:col3))
distinct(select(df, col1))
distinct(select(df, col1, col2))
sample_n(df, 10)
sample_frac(df, 0.01)

LANGUAGE: python
CODE:
df.shape
df.head()
df.iloc[:9]
df.query('col1 == 1 & col2 == 1')
df[(df.col1 == 1) & (df.col2 == 1)]
df[['col1', 'col2']]
df.loc[:, 'col1':'col3']
df.drop(cols_to_drop, axis=1)
df[['col1']].drop_duplicates()
df[['col1', 'col2']].drop_duplicates()
df.sample(n=10)
df.sample(frac=0.01)

----------------------------------------

TITLE: Demonstrating SettingWithCopyWarning in pandas 1.4.0
DESCRIPTION: Shows how pandas 1.4.0 improves warning messages by reporting the first line outside of the pandas library that gave rise to the warning, making it easier to determine where warnings are generated from.

LANGUAGE: python
CODE:
import pandas as pd

df = pd.DataFrame({'a': [1, 2, 3]})
df[:2].loc[:, 'a'] = 5

----------------------------------------

TITLE: Building Pandas in Debug Docker Container
DESCRIPTION: Command to build pandas with debug configuration inside the Docker container.

LANGUAGE: sh
CODE:
python -m pip install -ve . --no-build-isolation -Cbuilddir="debug" -Csetup-args="-Dbuildtype=debug"

----------------------------------------

TITLE: Setting hvplot as Plotting Backend
DESCRIPTION: Shows how to set hvplot as the default plotting backend for pandas.

LANGUAGE: python
CODE:
pd.set_option("plotting.backend", "hvplot")

----------------------------------------

TITLE: Proposed behavior with Copy-on-Write for modifying subsets
DESCRIPTION: Example demonstrating how the proposed Copy-on-Write behavior would prevent modifications to the original DataFrame when modifying a subset.

LANGUAGE: python
CODE:
>>> df = pd.DataFrame({"A": [1, 2], "B": [3, 4], "C": [5, 6]})
>>> df2 = df[["A", "B"]]
>>> df2.loc[df2["A"] > 1, "A"] = 1
>>> df.iloc[1, 0]  # df was not mutated
2

----------------------------------------

TITLE: Illustrating Improved Memory Usage Reporting for MultiIndex in Pandas 0.15.1
DESCRIPTION: Demonstrates more accurate memory usage reporting for MultiIndex, which now utilizes memory based on the level size.

LANGUAGE: python
CODE:
dfi = pd.DataFrame(
    1, index=pd.MultiIndex.from_product([["a"], range(1000)]), columns=["A"]
)

dfi.memory_usage(index=True)

----------------------------------------

TITLE: PyArrow I/O Reading
DESCRIPTION: Shows how to use PyArrow engine for reading data with pandas I/O functions and how to return PyArrow-backed data using dtype_backend parameter.

LANGUAGE: python
CODE:
import io
data = io.StringIO("""a,b,c
   1,2.5,True
   3,4.5,False
""")
df = pd.read_csv(data, engine="pyarrow")

data = io.StringIO("""a,b,c,d,e,f,g,h,i
    1,2.5,True,a,,,,,
    3,4.5,False,b,6,7.5,True,a,
""")
df_pyarrow = pd.read_csv(data, dtype_backend="pyarrow")

----------------------------------------

TITLE: Git Bisect Command for Investigating Pandas Regressions
DESCRIPTION: This git bisect command helps investigate regressions in pandas by finding the first commit that introduced a bug between versions 1.4.0 and 1.5.0.

LANGUAGE: bash
CODE:
git bisect start
git bisect good v1.4.0
git bisect bad v1.5.0
git bisect run bash -c "python -m pip install -ve . --no-build-isolation -Ceditable-verbose=true; python t.py"

----------------------------------------

TITLE: Slicing with R's c() and pandas equivalent
DESCRIPTION: Shows how to slice data in R using c() and the equivalent operation in pandas.

LANGUAGE: r
CODE:
df <- data.frame(a=rnorm(5), b=rnorm(5), c=rnorm(5), d=rnorm(5), e=rnorm(5))
df[, c("a", "c", "e")]

df <- data.frame(matrix(rnorm(1000), ncol=100))
df[, c(1:10, 25:30, 40, 50:100)]

LANGUAGE: python
CODE:
df = pd.DataFrame(np.random.randn(10, 3), columns=list("abc"))
df[["a", "c"]]
df.loc[:, ["a", "c"]]

named = list("abcdefg")
n = 30
columns = named + np.arange(len(named), n).tolist()
df = pd.DataFrame(np.random.randn(n, n), columns=columns)

df.iloc[:, np.r_[:10, 24:30]]

----------------------------------------

TITLE: Using String Data Type
DESCRIPTION: Example demonstrating the new experimental string data type for storing text data

LANGUAGE: python
CODE:
pd.Series(['abc', None, 'def'], dtype=pd.StringDtype())

s = pd.Series(['abc', None, 'def'], dtype="string")
s

s.str.upper()

----------------------------------------

TITLE: UInt64Index Support
DESCRIPTION: Example demonstrating improved support for unsigned 64-bit integers including new UInt64Index type.

LANGUAGE: python
CODE:
idx = pd.UInt64Index([1, 2, 3])
df = pd.DataFrame({'A': ['a', 'b', 'c']}, index=idx)
df.index

----------------------------------------

TITLE: Git Commands for Creating Release Candidate Branch
DESCRIPTION: These git commands create a new branch and development tag for a pandas release candidate.

LANGUAGE: bash
CODE:
git checkout -b 1.4.x
git push upstream 1.4.x
git checkout main
git commit --allow-empty -m "Start 1.5.0"
git tag -a v1.5.0.dev0 -m "DEV: Start 1.5.0"
git push upstream main --follow-tags

----------------------------------------

TITLE: Visualizing Data with D-Tale
DESCRIPTION: Demonstrates how to use D-Tale to visualize pandas data structures.

LANGUAGE: python
CODE:
import dtale

dtale.show(df)

----------------------------------------

TITLE: Loading and Using Pandas I/O Plugins
DESCRIPTION: Example showing how to load third-party I/O plugins and use them with the standard pandas interface for reading from DuckDB and writing to Delta Lake.

LANGUAGE: python
CODE:
import pandas

pandas.load_io_plugins()

df = pandas.DataFrame.read_duckdb("SELECT * FROM 'my_dataset.parquet';")

df.to_deltalake('/delta/my_dataset')

----------------------------------------

TITLE: Python Type Hints Example
DESCRIPTION: Example showing proper type hint usage in pandas including handling of class variable shadowing builtins.

LANGUAGE: python
CODE:
str_type = str

class SomeClass2:
    str: str_type = None

----------------------------------------

TITLE: Detecting Duplicate Labels in pandas
DESCRIPTION: Shows methods for detecting duplicate labels using is_unique and duplicated() functions.

LANGUAGE: python
CODE:
df2.index.is_unique
df2.columns.is_unique
df2.index.duplicated()

----------------------------------------

TITLE: Matching and Filtering in R and pandas
DESCRIPTION: Shows how to match and filter data in R using %in% and match(), and the equivalent operations in pandas using isin().

LANGUAGE: r
CODE:
s <- 0:4
s %in% c(2,4)

s <- 0:4
match(s, c(2,4))

LANGUAGE: python
CODE:
s = pd.Series(np.arange(5), dtype=np.float32)
s.isin([2, 4])

----------------------------------------

TITLE: Named aggregation in GroupBy
DESCRIPTION: Demonstrates the new named aggregation feature for GroupBy objects, allowing naming of output columns when applying multiple aggregation functions.

LANGUAGE: python
CODE:
animals = pd.DataFrame({'kind': ['cat', 'dog', 'cat', 'dog'],
                           'height': [9.1, 6.0, 9.5, 34.0],
                           'weight': [7.9, 7.5, 9.9, 198.0]})

animals.groupby("kind").agg(
    min_height=pd.NamedAgg(column='height', aggfunc='min'),
    max_height=pd.NamedAgg(column='height', aggfunc='max'),
    average_weight=pd.NamedAgg(column='weight', aggfunc="mean"),
)

----------------------------------------

TITLE: Pandas Bug Fixes and Regression Corrections
DESCRIPTION: Collection of bug fix references in pandas 2.1.4 including fixes for Series construction, DataFrame operations, data type handling, and string operations.

LANGUAGE: text
CODE:
Fixed issues include:\n- DataFrame pickle compatibility with pandas 1.3\n- Series constructor DeprecationWarning with Series index\n- ArrowDtype casting for date-like strings\n- Timestamp construction unit consistency\n- Index slice operations with Arrow dtypes\n- read_csv object dtype handling\n- to_numeric conversion for string[pyarrow_numpy]\n- GroupBy operations preserving extension dtypes\n- DataFrame setitem casting behavior\n- HDF5 storage with StringDtype\n- Index insertion casting\n- NA comparison operations\n- Series mode and reset_index dtype preservation\n- String split operations with Arrow dtypes\n- String translate operation dtype handling

----------------------------------------

TITLE: Using ArcticDB for DataFrame Storage
DESCRIPTION: Shows how to use ArcticDB for storing and retrieving pandas DataFrames.

LANGUAGE: python
CODE:
import arcticdb as adb
import numpy as np
import pandas as pd

arctic = adb.Arctic("lmdb://arcticdb_test")
lib = arctic.get_library('sample', create_if_missing=True)

df = pd.DataFrame(
    {
        "a": list("abc"),
        "b": list(range(1, 4)),
        "c": np.arange(3, 6).astype("u1"),
        "d": np.arange(4.0, 7.0, dtype="float64"),
        "e": [True, False, True],
        "f": pd.date_range("20130101", periods=3)
    }
)

write_record = lib.write("test", df)
read_record = lib.read("test")
read_record.data

----------------------------------------

TITLE: PyArrow Integration Example
DESCRIPTION: Comparison of current and proposed APIs for PyArrow table conversion using the plugin system.

LANGUAGE: python
CODE:
# Current API
pyarrow.Table.from_pandas(table.to_pandas()
                               .query('my_col > 0'))

# Proposed API
(pandas.read_pyarrow(table)
       .query('my_col > 0')
       .to_pyarrow())

----------------------------------------

TITLE: Creating and Activating Conda Environment for Pandas Development
DESCRIPTION: Commands to create and activate a conda environment for Pandas development using the provided environment.yml file.

LANGUAGE: bash
CODE:
conda env create --file environment.yml
conda activate pandas-dev

----------------------------------------

TITLE: Showing specific rows and columns in a DataFrame
DESCRIPTION: Shows how to display only specific rows and columns of a DataFrame.

LANGUAGE: python
CODE:
show = [0, 2, 4]
df.style.hide([row for row in df.index if row not in show], axis=0).hide(
    [col for col in df.columns if col not in show], axis=1
)

----------------------------------------

TITLE: Index with numpy numeric dtypes
DESCRIPTION: Demonstrates using numpy numeric dtypes in an Index where previously only int64, uint64 & float64 were allowed

LANGUAGE: python
CODE:
# Previous behavior
In [1]: pd.Index([1, 2, 3], dtype=np.int8)
Out[1]: Int64Index([1, 2, 3], dtype="int64")
In [2]: pd.Index([1, 2, 3], dtype=np.uint16)
Out[2]: UInt64Index([1, 2, 3], dtype="uint64")
In [3]: pd.Index([1, 2, 3], dtype=np.float32)
Out[3]: Float64Index([1.0, 2.0, 3.0], dtype="float64")

LANGUAGE: python
CODE:
# New behavior
pd.Index([1, 2, 3], dtype=np.int8)
pd.Index([1, 2, 3], dtype=np.uint16)
pd.Index([1, 2, 3], dtype=np.float32)

----------------------------------------

TITLE: Defining a basic Python function with docstring
DESCRIPTION: Example of a simple function with a properly formatted docstring following the pandas conventions.

LANGUAGE: python
CODE:
def add(num1, num2):
    """
    Add up two integer numbers.

    This function simply wraps the ``+`` operator, and does not
    do anything interesting, except for illustrating what
    the docstring of a very simple function looks like.

    Parameters
    ----------
    num1 : int
        First number to add.
    num2 : int
        Second number to add.

    Returns
    -------
    int
        The sum of ``num1`` and ``num2``.

    See Also
    --------
    subtract : Subtract one integer from another.

    Examples
    --------
    >>> add(2, 2)
    4
    >>> add(25, 0)
    25
    >>> add(10, -10)
    0
    """
    return num1 + num2

----------------------------------------

TITLE: Constructing a DataFrame in SAS
DESCRIPTION: This SAS code snippet demonstrates how to construct a data set (equivalent to a pandas DataFrame) from specified values using the DATA step and datalines statement.

LANGUAGE: sas
CODE:
data df;
    input x y;
    datalines;
    1 2
    3 4
    5 6
    ;
run;

----------------------------------------

TITLE: Printing DataFrame with NoRowIndex in Python
DESCRIPTION: Example showing how a DataFrame with NoRowIndex would be printed, omitting row labels.

LANGUAGE: python
CODE:
df = pd.DataFrame({'a': [1,  2, 3], 'b': [4, 5, 6]}, index=NoRowIndex(3))

df

----------------------------------------

TITLE: DataFrame Resample Group Keys Example
DESCRIPTION: Example showing control of index with group_keys argument in DataFrame.resample

LANGUAGE: python
CODE:
df = pd.DataFrame(
    {'a': range(6)},
    index=pd.date_range("2021-01-01", periods=6, freq="8H")
)

df.resample("D", group_keys=True).apply(lambda x: x)

df.resample("D", group_keys=False).apply(lambda x: x)

----------------------------------------

TITLE: Using Cylon for Distributed DataFrame Operations
DESCRIPTION: Demonstrates how to use Cylon for distributed DataFrame operations.

LANGUAGE: python
CODE:
from pycylon import read_csv, DataFrame, CylonEnv
from pycylon.net import MPIConfig

# Initialize Cylon distributed environment
config: MPIConfig = MPIConfig()
env: CylonEnv = CylonEnv(config=config, distributed=True)

df1: DataFrame = read_csv('/tmp/csv1.csv')
df2: DataFrame = read_csv('/tmp/csv2.csv')

# Using 1000s of cores across the cluster to compute the join
df3: Table = df1.join(other=df2, on=[0], algorithm="hash", env=env)

print(df3)

----------------------------------------

TITLE: Converting DataFrame to Table Schema JSON in Python
DESCRIPTION: This snippet shows how to convert a pandas DataFrame with Table Schema data types to JSON while preserving type information.

LANGUAGE: python
CODE:
df_to_table = npd.to_json(df, table=True)
print(df_to_table)

----------------------------------------

TITLE: Block Reference Tracking Implementation in Pandas
DESCRIPTION: Describes the BlockValuesRefs reference tracking system used in pandas to manage shared memory between DataFrame blocks. The system uses weak references to track alive blocks and determines when copies are needed during write operations.

LANGUAGE: python
CODE:
block.copy(deep=False)

----------------------------------------

TITLE: Installing Pandas via Conda Package Manager
DESCRIPTION: Command to install Pandas library using Conda package manager from conda-forge channel

LANGUAGE: shell
CODE:
conda install -c conda-forge pandas

----------------------------------------

TITLE: Sharing docstrings between classes
DESCRIPTION: Example of how to share and customize docstrings between parent and child classes using the @doc decorator.

LANGUAGE: python
CODE:
class Parent:
    @doc(klass="Parent")
    def my_function(self):
        """Apply my function to {klass}."""
        ...


class ChildA(Parent):
    @doc(Parent.my_function, klass="ChildA")
    def my_function(self):
        ...


class ChildB(Parent):
    @doc(Parent.my_function, klass="ChildB")
    def my_function(self):
        ...

----------------------------------------

TITLE: Creating Integer NA Series Example
DESCRIPTION: Example showing how to create a Series with optional integer NA support using Int64 dtype

LANGUAGE: python
CODE:
s = pd.Series([1, 2, np.nan], dtype='Int64')
s

----------------------------------------

TITLE: Creating an Index with ExtensionArray in pandas 1.4.0
DESCRIPTION: Demonstrates how pandas 1.4.0 allows Index to directly hold arbitrary ExtensionArrays, preserving the original dtype instead of casting to object dtype.

LANGUAGE: python
CODE:
arr = pd.array([1, 2, pd.NA])
idx = pd.Index(arr)
idx

----------------------------------------

TITLE: Using Pandarallel for Parallel Operations
DESCRIPTION: Demonstrates how to use Pandarallel to parallelize pandas operations.

LANGUAGE: python
CODE:
from pandarallel import pandarallel

pandarallel.initialize(progress_bar=True)

# df.apply(func)
df.parallel_apply(func)

----------------------------------------

TITLE: Changed behavior in DataFrame.value_counts with sort=False
DESCRIPTION: DataFrame.value_counts and DataFrameGroupBy.value_counts with sort=False now maintain the order of the input rather than sorting by row labels.

LANGUAGE: python
CODE:
df = pd.DataFrame({
    "a": [2, 2, 2, 2, 1, 1, 1, 1],
    "b": [2, 1, 3, 1, 2, 3, 1, 1],
})
df.value_counts(sort=False)

----------------------------------------

TITLE: Subclassing pandas Series and DataFrame in Python
DESCRIPTION: Demonstrates how to create custom Series and DataFrame subclasses while preserving the subclass through data manipulations by overriding constructor properties.

LANGUAGE: python
CODE:
class SubclassedSeries(pd.Series):
    @property
    def _constructor(self):
        return SubclassedSeries

    @property
    def _constructor_expanddim(self):
        return SubclassedDataFrame


class SubclassedDataFrame(pd.DataFrame):
    @property
    def _constructor(self):
        return SubclassedDataFrame

    @property
    def _constructor_sliced(self):
        return SubclassedSeries

----------------------------------------

TITLE: Resolving Memory Leaks in Rolling Operations in Python
DESCRIPTION: Addressed memory leaks in Series.rolling.quantile and Series.rolling.median methods.

LANGUAGE: Python
CODE:
Series.rolling.quantile()
Series.rolling.median()

----------------------------------------

TITLE: Installing Pandas from Source
DESCRIPTION: Command to install Pandas from source code in the local directory

LANGUAGE: shell
CODE:
pip install .

----------------------------------------

TITLE: Resolving Memory Leaks in Rolling Operations in Python
DESCRIPTION: Addressed memory leaks in Series.rolling.quantile and Series.rolling.median methods.

LANGUAGE: Python
CODE:
Series.rolling.quantile()
Series.rolling.median()

----------------------------------------

TITLE: Using DataFrame.where() for Conditional Selection in Python
DESCRIPTION: Demonstrates the new where() method for conditional selection in pandas DataFrames, including alignment and replacement options.

LANGUAGE: python
CODE:
df = pd.DataFrame(np.random.randn(5, 3), columns=['A', 'B', 'C'])

df

df[df['A'] > 0]

df[df > 0]

df.where(df > 0)

df.where(df > 0, -df)

df2 = df.copy()
df2[df2[1:4] > 0] = 3
df2

df.mask(df <= 0)

----------------------------------------

TITLE: If/Then Logic in SAS for Creating New Columns
DESCRIPTION: This SAS code snippet demonstrates how to use if/then logic to create new columns in a SAS data set.

LANGUAGE: sas
CODE:
data tips;
    set tips;
    format bucket $4.;

    if total_bill < 10 then bucket = 'low';
    else bucket = 'high';
run;

----------------------------------------

TITLE: Fixing List-like Object Detection in Python
DESCRIPTION: Corrected the is_list_like function to properly handle objects with __iter__ set to None.

LANGUAGE: python
CODE:
is_list_like(obj)

----------------------------------------

TITLE: Resolving Unicode Decoding in CSV Reading with Memory Mapping in Python
DESCRIPTION: Fixed a regression where read_csv was raising a UnicodeDecodeError exception when memory_map=True.

LANGUAGE: Python
CODE:
read_csv(memory_map=True)

----------------------------------------

TITLE: Defining Parquet KeyValue Structure
DESCRIPTION: Apache Parquet format specification for key-value metadata storage at file and column level.

LANGUAGE: shell
CODE:
5: optional list<KeyValue> key_value_metadata

LANGUAGE: shell
CODE:
struct KeyValue {
  1: required string key
  2: optional string value
}

----------------------------------------

TITLE: Configuring PyArrow String Inference
DESCRIPTION: Setting the future.infer_string option to enable PyArrow-backed strings as the default string type for better memory efficiency and performance.

LANGUAGE: python
CODE:
pd.options.future.infer_string = True

----------------------------------------

TITLE: Creating and Inspecting a MultiIndex in Python
DESCRIPTION: Demonstrates how to create a MultiIndex using pd.MultiIndex.from_product() and inspect its components including levels, codes, and names.

LANGUAGE: python
CODE:
index = pd.MultiIndex.from_product(
    [range(3), ["one", "two"]], names=["first", "second"]
)
index
index.levels
index.codes
index.names

----------------------------------------

TITLE: Installing Pandas with Pip
DESCRIPTION: Commands to install pandas and optional dependencies using pip package manager from PyPI

LANGUAGE: shell
CODE:
pip install pandas

LANGUAGE: shell
CODE:
pip install "pandas[excel]"

----------------------------------------

TITLE: Accessing Period End Time in Python
DESCRIPTION: Shows how to get the last nanosecond of a time interval using the updated Period.end_time method.

LANGUAGE: python
CODE:
p = pd.Period('2012')

p.end_time

----------------------------------------

TITLE: Sorting Data in SAS using PROC SORT
DESCRIPTION: This SAS code snippet demonstrates how to sort data in SAS using the PROC SORT procedure.

LANGUAGE: sas
CODE:
proc sort data=tips;
    by sex total_bill;
run;

----------------------------------------

TITLE: Fixing Series Aggregation Argument Passing in Python
DESCRIPTION: Resolved a regression in Series.aggregate where it was attempting to pass args and kwargs multiple times to the user-supplied func in certain cases.

LANGUAGE: Python
CODE:
Series.aggregate()

----------------------------------------

TITLE: Defining Pandas DataFrame Metadata Structure
DESCRIPTION: JSON structure for storing pandas DataFrame metadata in Parquet format, including index columns, column indexes, and version information.

LANGUAGE: text
CODE:
{'index_columns': [<descr0>, <descr1>, ...],
 'column_indexes': [<ci0>, <ci1>, ..., <ciN>],
 'columns': [<c0>, <c1>, ...],
 'pandas_version': $VERSION,
 'creator': {
   'library': $LIBRARY,
   'version': $LIBRARY_VERSION
 }}

----------------------------------------

TITLE: DataFrame Stack with Future Implementation
DESCRIPTION: Example demonstrating the new implementation of DataFrame.stack() with future_stack=True parameter.

LANGUAGE: python
CODE:
columns = pd.MultiIndex.from_tuples([("B", "d"), ("A", "c")])
df = pd.DataFrame([[0, 2], [1, 3]], index=["z", "y"], columns=columns)
df
df.stack([0, 1], future_stack=True)

----------------------------------------

TITLE: Using NamedAgg for aggregation
DESCRIPTION: Shows how to use the NamedAgg helper class for aggregation operations on grouped data.

LANGUAGE: Python
CODE:
from pandas import NamedAgg

result = df.groupby('A').agg(
    min_B=('B', 'min'),
    max_B=('B', 'max'),
    avg_C=('C', 'mean')
)

----------------------------------------

TITLE: Building and Installing Pandas with Meson
DESCRIPTION: Command to build and install Pandas using the Meson build system, with verbose output for editable installs.

LANGUAGE: bash
CODE:
python -m pip install -ve . --no-build-isolation -Ceditable-verbose=true

----------------------------------------

TITLE: Enhancing GroupBy Operations with StringDtype in Python
DESCRIPTION: Fixed performance regressions in DataFrameGroupBy.first, SeriesGroupBy.first, DataFrameGroupBy.last, and SeriesGroupBy.last with StringDtype.

LANGUAGE: Python
CODE:
DataFrameGroupBy.first()
SeriesGroupBy.first()
DataFrameGroupBy.last()
SeriesGroupBy.last()

----------------------------------------

TITLE: Sorting DataFrame with Multiple Columns in Python
DESCRIPTION: Demonstrates how to sort a pandas DataFrame by multiple columns with different sort orders using the new sort functionality in pandas 0.9.1.

LANGUAGE: python
CODE:
df = pd.DataFrame(np.random.randint(0, 2, (6, 3)),
                  columns=['A', 'B', 'C'])

df.sort(['A', 'B'], ascending=[1, 0])

----------------------------------------

TITLE: Updating Pandas for NumPy 2.1 Compatibility
DESCRIPTION: Implements minor fixes to ensure Pandas 2.2.3 is compatible with NumPy 2.1. This update maintains interoperability between Pandas and the latest version of NumPy.

LANGUAGE: python
CODE:
# No specific code provided, but implies updates to Pandas internals for NumPy 2.1 compatibility

----------------------------------------

TITLE: Fixed regression in PeriodDtype comparison
DESCRIPTION: Corrects the behavior of PeriodDtype comparisons to its string representation, ensuring consistent results.

LANGUAGE: python
CODE:
pd.PeriodDtype(freq='D') == 'period[D]'

----------------------------------------

TITLE: Avoiding warnings in NumPy ufunc calls on DataFrames in Python
DESCRIPTION: Demonstrates how to avoid warnings and maintain current behavior when calling NumPy ufuncs on non-aligned DataFrames by converting one argument to a NumPy array.

LANGUAGE: python
CODE:
np.add(df1, np.asarray(df2))

----------------------------------------

TITLE: Python Deprecation Warning Example
DESCRIPTION: Example showing how to properly deprecate a function using deprecation warnings in pandas.

LANGUAGE: python
CODE:
import warnings
from pandas.util._exceptions import find_stack_level

def old_func():
    """
Summary of the function.

.. deprecated:: 1.1.0
   Use new_func instead.
"""
    warnings.warn(
        'Use new_func instead.',
        FutureWarning,
        stacklevel=find_stack_level(),
    )
    new_func()

def new_func():
    pass

----------------------------------------

TITLE: Centered datetime-like rolling windows
DESCRIPTION: Shows how to use centered datetime-like rolling windows on a DataFrame with a datetime index

LANGUAGE: python
CODE:
df = pd.DataFrame(
    {"A": [0, 1, 2, 3, 4]}, index=pd.date_range("2020", periods=5, freq="1D")
)
df
df.rolling("2D", center=True).mean()

----------------------------------------

TITLE: Importing Pandas Plotting Module
DESCRIPTION: This code snippet shows how to import the pandas.plotting module, which contains various plotting functions for data visualization in pandas.

LANGUAGE: python
CODE:
.. currentmodule:: pandas.plotting

----------------------------------------

TITLE: Installing Pandas Debug Build
DESCRIPTION: Command to install pandas from source with debug configuration. Uses pip to install in editable mode with custom build directory and debug buildtype.

LANGUAGE: shell
CODE:
pip install -ve . --no-build-isolation -Cbuilddir="debug" -Csetup-args="-Dbuildtype=debug"

----------------------------------------

TITLE: Creating CustomBusinessHour offset
DESCRIPTION: Demonstrates creating a CustomBusinessHour offset using the USFederalHolidayCalendar

LANGUAGE: python
CODE:
from pandas.tseries.offsets import CustomBusinessHour
from pandas.tseries.holiday import USFederalHolidayCalendar

bhour_us = CustomBusinessHour(calendar=USFederalHolidayCalendar())

----------------------------------------

TITLE: DateTime Index Type Handling in pandas 0.8.0
DESCRIPTION: Illustrates the changes in datetime handling between pandas versions, showing type conversions and potential issues when working with datetime64 arrays.

LANGUAGE: python
CODE:
import datetime

rng = pd.date_range("1/1/2000", periods=10)
rng[5]
isinstance(rng[5], datetime.datetime)
rng_asarray = np.asarray(rng)
scalar_val = rng_asarray[5]
type(scalar_val)

----------------------------------------

TITLE: Fixed regression in inplace Series arithmetic operations
DESCRIPTION: Ensures that inplace arithmetic operations (+=) on a Series properly update the parent DataFrame/Series.

LANGUAGE: python
CODE:
df['column'] += 1

----------------------------------------

TITLE: Running IPython Directive in Sphinx Documentation
DESCRIPTION: Demonstrates how to use the IPython directive in Sphinx to include executable code examples in the documentation.

LANGUAGE: restructuredtext
CODE:
.. ipython:: python

    x = 2
    x**3

----------------------------------------

TITLE: Fixed regression in DataFrame.agg with positional arguments
DESCRIPTION: Resolves a TypeError that occurred when passing positional arguments to be forwarded to the aggregation function in DataFrame.agg.

LANGUAGE: python
CODE:
df.agg(custom_function, arg1, arg2)

----------------------------------------

TITLE: Listing Available Plotting Functions in Pandas
DESCRIPTION: This code block lists the available plotting functions in the pandas.plotting module. These functions can be used for creating various types of plots and visualizations with pandas data structures.

LANGUAGE: python
CODE:
.. autosummary::
   :toctree: api/

   andrews_curves
   autocorrelation_plot
   bootstrap_plot
   boxplot
   deregister_matplotlib_converters
   lag_plot
   parallel_coordinates
   plot_params
   radviz
   register_matplotlib_converters
   scatter_matrix
   table

----------------------------------------

TITLE: Running Cython Debugger
DESCRIPTION: Commands to change directory to debug build folder and start the Cython debugger.

LANGUAGE: sh
CODE:
cd debug
cygdb

----------------------------------------

TITLE: Fixed regression in DataFrame.iloc setitem with boolean filtering
DESCRIPTION: Resolves an error that occurred when using DataFrame.iloc to set a value while filtering with a boolean list.

LANGUAGE: python
CODE:
df.iloc[boolean_list, column_index] = value

----------------------------------------

TITLE: Assembling datetimes from DataFrame
DESCRIPTION: Demonstrates using pd.to_datetime() to assemble datetimes from columns in a DataFrame

LANGUAGE: python
CODE:
df = pd.DataFrame(
    {"year": [2015, 2016], "month": [2, 3], "day": [4, 5], "hour": [2, 3]}
)

pd.to_datetime(df)

pd.to_datetime(df[["year", "month", "day"]])

----------------------------------------

TITLE: Column Operations in SAS using DATA Step
DESCRIPTION: This SAS code snippet demonstrates how to perform operations on columns in a SAS data set using the DATA step.

LANGUAGE: sas
CODE:
data tips;
    set tips;
    total_bill = total_bill - 2;
    new_bill = total_bill / 2;
run;

----------------------------------------

TITLE: Demonstrating new resample default behavior in pandas
DESCRIPTION: Illustrates the changed default behavior for resampling time series data to daily frequency, which now uses closed='left' and label='left' for D and higher frequencies.

LANGUAGE: python
CODE:
dates = pd.date_range('1/1/2000', '1/5/2000', freq='4h')

series = pd.Series(np.arange(len(dates)), index=dates)

series

series.resample('D', how='sum')

# old behavior
series.resample('D', how='sum', closed='right', label='right')

----------------------------------------

TITLE: Fixed regression in DataFrame.resample().apply() with partial evaluation
DESCRIPTION: Resolves an AttributeError that occurred when using DataFrame.resample().apply() on a DataFrame where only a Series was evaluated.

LANGUAGE: python
CODE:
df.resample('D').apply(lambda x: x['column'].mean())

----------------------------------------

TITLE: Enabling Copy-on-Write behavior in pandas
DESCRIPTION: Code snippet showing how to enable the Copy-on-Write behavior in pandas for testing and experimentation.

LANGUAGE: python
CODE:
>>> pd.options.mode.copy_on_write = True

----------------------------------------

TITLE: Setting DataFrame values with slice in pandas
DESCRIPTION: Fixed regression in DataFrame setting values with a slice (e.g. df[-4:] = 1) indexing by label instead of position.

LANGUAGE: python
CODE:
df[-4:] = 1

----------------------------------------

TITLE: NoRowIndex Append Operation in Python
DESCRIPTION: Example showing how NoRowIndex would work when appending DataFrames, preserving the NoRowIndex type.

LANGUAGE: python
CODE:
df1 = pd.DataFrame({'a': [1,  2], 'b': [4, 5]}, index=NoRowIndex(2))

df2 = pd.DataFrame({'a': [4], 'b': [0]}, index=NoRowIndex(1))

df1

df2

pd.concat([df1, df2])

pd.concat([df1, df2]).index

----------------------------------------

TITLE: Creating Series with Different Indices in Python
DESCRIPTION: Example showing how to create two pandas Series objects with different index values.

LANGUAGE: python
CODE:
ser1 = pd.Series([10, 15, 20, 25], index=[1, 2, 3, 5])

ser2 = pd.Series([10, 15, 20, 25], index=[1, 2, 3, 4])

----------------------------------------

TITLE: Resampling grouped data
DESCRIPTION: Shows the new syntax for resampling grouped time series data

LANGUAGE: python
CODE:
df = pd.DataFrame(
    {
        "date": pd.date_range(start="2016-01-01", periods=4, freq="W"),
        "group": [1, 1, 2, 2],
        "val": [5, 6, 7, 8],
    }
).set_index("date")

df.groupby("group").resample("1D").ffill()

----------------------------------------

TITLE: Creating a DataFrame with Various Data Types in Python
DESCRIPTION: This snippet creates a pandas DataFrame with multiple column types including dates, points, and custom types.

LANGUAGE: python
CODE:
from shapely.geometry import Point
from datetime import date
import pandas as pd
import ntv_pandas as npd

data = {'index':           [100, 200, 300, 400, 500, 600],
        'dates::date':     [date(1964,1,1), date(1985,2,5), date(2022,1,21), date(1964,1,1), date(1985,2,5), date(2022,1,21)],
        'value':           [10, 10, 20, 20, 30, 30],
        'value32':         pd.Series([12, 12, 22, 22, 32, 32], dtype='int32'),
        'res':             [10, 20, 30, 10, 20, 30],
        'coord::point':    [Point(1,2), Point(3,4), Point(5,6), Point(7,8), Point(3,4), Point(5,6)],
        'names':           pd.Series(['john', 'eric', 'judith', 'mila', 'hector', 'maria'], dtype='string'),
        'unique':          True }

df = pd.DataFrame(data).set_index('index')

print(df)

----------------------------------------

TITLE: DataFrame Compare Function
DESCRIPTION: Example showing DataFrame.compare() method for comparing two DataFrames and summarizing the differences

LANGUAGE: ipython
CODE:
df = pd.DataFrame(
    {
        "col1": ["a", "a", "b", "b", "a"],
        "col2": [1.0, 2.0, 3.0, np.nan, 5.0],
        "col3": [1.0, 2.0, 3.0, 4.0, 5.0]
    },
    columns=["col1", "col2", "col3"],
)
df

df2 = df.copy()
df2.loc[0, 'col1'] = 'c'
df2.loc[2, 'col3'] = 4.0
df2

df.compare(df2)

----------------------------------------

TITLE: Transpose Operation with NoRowIndex in Python
DESCRIPTION: Example demonstrating that transpose operation would not be allowed on DataFrames with NoRowIndex.

LANGUAGE: python
CODE:
df = pd.DataFrame({'a': [1,  2, 3], 'b': [4, 5, 6]}, index=NoRowIndex(3))

df.transpose()  # This would raise a ValueError

----------------------------------------

TITLE: Selecting single datetime64 or timedelta64 column in pandas
DESCRIPTION: Fixed regression in DataFrame.loc and DataFrame.iloc when selecting a row containing a single datetime64 or timedelta64 column.

LANGUAGE: python
CODE:
# Example not provided in the original text

----------------------------------------

TITLE: Slicing with NoRowIndex in Python
DESCRIPTION: Example demonstrating how slicing would work with NoRowIndex, including allowed and disallowed operations.

LANGUAGE: python
CODE:
df = pd.DataFrame({'a': [1,  2, 3], 'b': [4, 5, 6]}, index=NoRowIndex(3))

df.loc[df['a']>1, 'b']

df.loc[df['a']>1, 'b'].index

df.loc[0, 'b']  # This would raise an IndexError

----------------------------------------

TITLE: Demonstrating Current Behavior of Dtype Upcasting in pandas
DESCRIPTION: This snippet shows how the current pandas behavior allows dtype changes during setitem operations, potentially hiding bugs or breaking user expectations.

LANGUAGE: python
CODE:
In [1]: ser = pd.Series([1, 2, 3], dtype='int64')

In [2]: ser[2] = 'potage'

In [3]: ser  # dtype changed to 'object'!
Out[3]:
0         1
1         2
2    potage
dtype: object

----------------------------------------

TITLE: DataFrame apply with object dtype and non-reducing function in pandas
DESCRIPTION: Fixed regression in DataFrame.apply with object dtype and non-reducing function.

LANGUAGE: python
CODE:
# Example not provided in the original text

----------------------------------------

TITLE: Using CustomBusinessHour offset
DESCRIPTION: Shows how to use the CustomBusinessHour offset to add business hours, skipping holidays

LANGUAGE: python
CODE:
import datetime

dt = datetime.datetime(2014, 1, 17, 15)

dt + bhour_us
dt + bhour_us * 2

----------------------------------------

TITLE: String Startswith Performance Comparison
DESCRIPTION: Performance comparison between object dtype and pyarrow string dtype for string startswith operations.

LANGUAGE: python
CODE:
In[3]: %timeit ser_object.str.startswith("a")
136 ms  300 s per loop (mean  std. dev. of 7 runs, 10 loops each)

In[4]: %timeit ser_string.str.startswith("a")
11 ms  19.8 s per loop (mean  std. dev. of 7 runs, 100 loops each)

----------------------------------------

TITLE: Importing Pandas Namespace
DESCRIPTION: Suppressed import of all pandas components into the current namespace for documentation purposes.

LANGUAGE: python
CODE:
from pandas import *  # noqa F401, F403

----------------------------------------

TITLE: Quantile cut with nullable integer in pandas
DESCRIPTION: Fixed regression in qcut when passed a nullable integer.

LANGUAGE: python
CODE:
# Example not provided in the original text

----------------------------------------

TITLE: Demonstrating inconsistent datetime parsing in pandas
DESCRIPTION: This snippet shows how pandas currently parses dates inconsistently, potentially leading to errors in interpretation.

LANGUAGE: python
CODE:
pd.to_datetime(['12-01-2000 00:00:00', '13-01-2000 00:00:00'])

----------------------------------------

TITLE: Working with datetime and timedelta in pandas Python library
DESCRIPTION: Examples of datetime64 and timedelta operations in pandas that were improved in this release, including subtraction between Series objects and operations on TimedeltaIndex.

LANGUAGE: Python
CODE:
series1 - series2  # where series1 and series2 have datetime64[ns] dtype
np.sum(timedeltaindex)

----------------------------------------

TITLE: Showing GroupBy Column Inclusion Fix in Pandas 0.15.1
DESCRIPTION: Illustrates how groupby now correctly includes columns even if the column name conflicts with the grouper name.

LANGUAGE: python
CODE:
df = pd.DataFrame({"jim": range(5), "joe": range(5, 10)})
df
gr = df.groupby(df["jim"] < 2)

gr.apply("sum")

----------------------------------------

TITLE: Proposed Behavior for Dtype Preservation in pandas
DESCRIPTION: This snippet demonstrates the suggested behavior where attempting to set an incompatible value raises an error instead of changing the dtype.

LANGUAGE: python
CODE:
In [1]: ser = pd.Series([1, 2, 3])

In [2]: ser[2] = 'potage'  # raises!
---------------------------------------------------------------------------
ValueError: Invalid value 'potage' for dtype int64

----------------------------------------

TITLE: Demonstrating current chained assignment behavior in pandas
DESCRIPTION: Example showing how chained assignment currently works in pandas, which can lead to unexpected behavior and SettingWithCopyWarning.

LANGUAGE: python
CODE:
>>> df = pd.DataFrame({"A": [1, 2], "B": [3, 4], "C": [5, 6]})
>>> df2 = df[["A", "B"]]
>>> df2.loc[df2["A"] > 1, "A"] = 1

----------------------------------------

TITLE: Showing GroupBy Column Inclusion Fix in Pandas 0.15.1
DESCRIPTION: Illustrates how groupby now correctly includes columns even if the column name conflicts with the grouper name.

LANGUAGE: python
CODE:
df = pd.DataFrame({"jim": range(5), "joe": range(5, 10)})
df
gr = df.groupby(df["jim"] < 2)

gr.apply("sum")

----------------------------------------

TITLE: Polars Interoperability Example
DESCRIPTION: Shows potential interoperability between pandas and polars using PyArrow as the common backend.

LANGUAGE: python
CODE:
import pandas as pd
import polars as pl

df = pd.DataFrame(
  {
    'a': ['one', 'two'],
    'b': [{'name': 'Billy', 'age': 3}, {'name': 'Bob', 'age': 4}],
  }
)
pl.from_pandas(df)

----------------------------------------

TITLE: Assigning to Series with nullable integer dtype in pandas
DESCRIPTION: Fixed regression in assigning to a Series using a nullable integer dtype.

LANGUAGE: python
CODE:
# Example not provided in the original text

----------------------------------------

TITLE: Citing pandas Software in BibTeX Format
DESCRIPTION: BibTeX citation for the pandas software package. This citation should be used when referencing pandas in scientific publications, with the author list replaced by 'The pandas development team'.

LANGUAGE: bibtex
CODE:
@software{reback2020pandas,
    author       = {The pandas development team},
    title        = {pandas-dev/pandas: Pandas},
    month        = feb,
    year         = 2020,
    publisher    = {Zenodo},
    version      = {latest},
    doi          = {10.5281/zenodo.3509134},
    url          = {https://doi.org/10.5281/zenodo.3509134}
}

----------------------------------------

TITLE: Using I/O functions in pandas Python library
DESCRIPTION: Examples of pandas I/O functions that were fixed, including to_csv() for writing to files and reading from HDF5 and JSON formats. These functions had issues with specific file formats or compression methods.

LANGUAGE: Python
CODE:
df.to_csv(compression='gzip')
pd.read_hdf('file.h5', key='df')
pd.read_json('file.json', orient='table')

----------------------------------------

TITLE: Plugin Registration Configuration
DESCRIPTION: Example of registering a pandas I/O plugin using pyproject.toml entry points configuration for a DuckDB reader implementation.

LANGUAGE: toml
CODE:
[project.entry-points."dataframe.io"]
reader_duckdb = "pandas_duckdb:read_duckdb"

----------------------------------------

TITLE: Integer Series Reindexing with Traditional NaN Handling
DESCRIPTION: Demonstrates how integer series traditionally get cast to float when containing missing values after reindexing.

LANGUAGE: python
CODE:
>>> int_ser = pd.Series([1, 2], index=[0, 2])
>>> int_ser
0    1
2    2
dtype: int64

>>> int_ser.reindex([0, 1, 2])
0    1.0
1    NaN
2    2.0
dtype: float64

----------------------------------------

TITLE: GroupBy aggregations with categorical dtype in pandas
DESCRIPTION: Fixed regression in .groupby() aggregations with categorical dtype using Cythonized reduction functions (e.g. first).

LANGUAGE: python
CODE:
# Example not provided in the original text

----------------------------------------

TITLE: Illustrating GroupBy Behavior Change with as_index=False in Pandas 0.15.1
DESCRIPTION: Demonstrates how groupby with as_index=False no longer adds erroneous extra columns to the result.

LANGUAGE: python
CODE:
np.random.seed(2718281)
df = pd.DataFrame(np.random.randint(0, 100, (10, 2)), columns=["jim", "joe"])
df.head()

ts = pd.Series(5 * np.random.randint(0, 3, 10))

df.groupby(ts, as_index=False).max()

----------------------------------------

TITLE: Fixing DataFrame.convert_dtypes Regression in Python
DESCRIPTION: Fixed a regression where DataFrame.convert_dtypes incorrectly converted byte strings to strings.

LANGUAGE: Python
CODE:
DataFrame.convert_dtypes()

----------------------------------------

TITLE: Generating Pandas Accessor Method Documentation Template (RST)
DESCRIPTION: A Sphinx documentation template that generates documentation for pandas accessor methods. The template uses Jinja2 templating to insert the full method name, create underlines, set the current module context, and generate autodoc for accessor methods.

LANGUAGE: restructuredtext
CODE:
{{ fullname }}
{{ underline }}

.. currentmodule:: {{ module.split('.')[0] }}

.. autoaccessormethod:: {{ (module.split('.')[1:] + [objname]) | join('.') }}

----------------------------------------

TITLE: GroupBy min/max on period dtype columns in pandas
DESCRIPTION: Fixed regression in DataFrame.groupby whereby taking the minimum or maximum of a column with period dtype would raise a TypeError.

LANGUAGE: python
CODE:
# Example not provided in the original text

----------------------------------------

TITLE: Obfuscating Email Addresses with JavaScript
DESCRIPTION: This JavaScript snippet modifies email addresses to prevent spam. It removes the 'asp.' prefix from the displayed email and updates the href attribute of the email link.

LANGUAGE: javascript
CODE:
var mail_tag_id = '{{ workgroup.name|replace(' ', '-') }}';
var mail_tag_element = document.getElementById( mail_tag_id );
mail_tag_element.innerHTML = mail_tag_element.innerHTML.replace(/^asp./, "");
mail_tag_element.setAttribute('href', "mailto:"+mail_tag_element.innerHTML);

----------------------------------------

TITLE: DataFrame Join with MultiIndex Example
DESCRIPTION: Example showing how to join DataFrames with overlapping MultiIndex levels

LANGUAGE: python
CODE:
index_left = pd.MultiIndex.from_tuples([('K0', 'X0'), ('K0', 'X1'), ('K1', 'X2')], names=['key', 'X'])
left = pd.DataFrame({'A': ['A0', 'A1', 'A2'], 'B': ['B0', 'B1', 'B2']}, index=index_left)
index_right = pd.MultiIndex.from_tuples([('K0', 'Y0'), ('K1', 'Y1'), ('K2', 'Y2'), ('K2', 'Y3')], names=['key', 'Y'])
right = pd.DataFrame({'C': ['C0', 'C1', 'C2', 'C3'], 'D': ['D0', 'D1', 'D2', 'D3']}, index=index_right)
left.join(right)

----------------------------------------

TITLE: Creating DataFrame with Table Schema Data Types in Python
DESCRIPTION: This snippet creates a pandas DataFrame with columns using Table Schema data types like date, point, and email.

LANGUAGE: python
CODE:
df = pd.DataFrame({
    'end february::date': ['date(2023,2,28)', 'date(2024,2,29)', 'date(2025,2,28)'],
    'coordinates::point': ['Point([2.3, 48.9])', 'Point([5.4, 43.3])', 'Point([4.9, 45.8])'],
    'contact::email':     ['john.doe@table.com', 'lisa.minelli@schema.com', 'walter.white@breaking.com']
    })

print(df)

----------------------------------------

TITLE: Displaying Code of Conduct Team Members using HTML Template
DESCRIPTION: HTML template code for dynamically listing Code of Conduct working group members using template tags. Uses a for loop to iterate through maintainers.coc collection.

LANGUAGE: html
CODE:
<ul>
    {% for person in maintainers.coc %}
    <li>{{ person }}</li>
    {% endfor %}
</ul>

----------------------------------------

TITLE: Intelligent precision limit for datetime and timedelta
DESCRIPTION: Shows how ArrayFormatter now intelligently limits precision for datetime and timedelta64 based on the values in the array.

LANGUAGE: python
CODE:
df = pd.DataFrame(
    [pd.Timestamp("20010101"), pd.Timestamp("20040601")], columns=["age"]
)
df["today"] = pd.Timestamp("20130419")
df["diff"] = df["today"] - df["age"]
df

----------------------------------------

TITLE: Resolving GroupBy Aggregation for Object Columns in Python
DESCRIPTION: Fixed an issue where groupby aggregation was dropping results for columns with object types.

LANGUAGE: python
CODE:
df.groupby('column').agg(func)

----------------------------------------

TITLE: Parsing non-nanosecond resolution datetimes in pandas
DESCRIPTION: Fixed regression in to_datetime when parsing non-nanosecond resolution datetimes.

LANGUAGE: python
CODE:
# Example not provided in the original text

----------------------------------------

TITLE: Setting display.max_colwidth option in pandas
DESCRIPTION: Fixed regression where setting pd.options.display.max_colwidth was not accepting negative integer. This behavior has been deprecated in favor of using None.

LANGUAGE: python
CODE:
pd.options.display.max_colwidth = None  # New recommended way

----------------------------------------

TITLE: New Window Functions API Example
DESCRIPTION: Demonstrates the new method-based window functions API in pandas 0.18.0, using rolling mean as an example

LANGUAGE: python
CODE:
np.random.seed(1234)
df = pd.DataFrame({'A': range(10), 'B': np.random.randn(10)})
r = df.rolling(window=3)
r.mean()

----------------------------------------

TITLE: Loading Data from Hugging Face Dataset Hub
DESCRIPTION: Demonstrates how to load a dataset from Hugging Face Dataset Hub using pandas.

LANGUAGE: python
CODE:
import pandas as pd

# Load the IMDB dataset
df = pd.read_parquet("hf://datasets/stanfordnlp/imdb/plain_text/train-00000-of-00001.parquet")

----------------------------------------

TITLE: Rendering In-Kind Sponsors with Jinja2
DESCRIPTION: Template code for displaying in-kind sponsors that support pandas with goods or services. Uses Jinja2 templating to iterate through in-kind sponsor data.

LANGUAGE: jinja2
CODE:
<ul>
    {% for company in sponsors.inkind %}
        <li><a href="{{ company.url }}">{{ company.name }}</a>: {{ company.description }}</li>
    {% endfor %}
</ul>

----------------------------------------

TITLE: Fixing DataFrame To_CSV with IntervalIndex in Python
DESCRIPTION: This bug fix addresses a regression in DataFrame.to_csv() where writing a Series or DataFrame indexed by an IntervalIndex would incorrectly raise a TypeError.

LANGUAGE: Python
CODE:
DataFrame.to_csv(...)

----------------------------------------

TITLE: Plotting Time Series with Secondary Y-Axis in pandas
DESCRIPTION: Demonstrates how to create a plot with two time series where one uses a secondary y-axis. Uses the new plot functionality with secondary_y parameter.

LANGUAGE: python
CODE:
import pandas as pd

fx = pd.read_pickle("data/fx_prices")
import matplotlib.pyplot as plt

plt.figure()

fx["FR"].plot(style="g")

fx["IT"].plot(style="k--", secondary_y=True)

----------------------------------------

TITLE: Fixing CSV Reading for SpooledTemporaryFile in Python
DESCRIPTION: Resolved an AttributeError when reading CSV from a tempfile.SpooledTemporaryFile object.

LANGUAGE: python
CODE:
pd.read_csv(temp_file)

----------------------------------------

TITLE: Rendering Past Institutional Partners with Jinja2
DESCRIPTION: Template code for displaying past institutional partners. Uses Jinja2 templating to filter and display historical partner information.

LANGUAGE: jinja2
CODE:
<ul>
    {% for company in sponsors.past if company.kind == "partner" %}
        <li><a href="{{ company.url }}">{{ company.name }}</a></li>
    {% endfor %}
</ul>

----------------------------------------

TITLE: NumPy Compatibility Example Pre-0.23.2
DESCRIPTION: Shows how NumPy 1.15 with pandas 0.23.1 handled DataFrame reduction operations differently, returning a Series instead of a scalar.

LANGUAGE: python
CODE:
>>> # NumPy 1.15, pandas 0.23.1
>>> np.any(pd.DataFrame({"A": [False], "B": [False]}))
A    False
B    False
dtype: bool

----------------------------------------

TITLE: Reading CSV with encoding option in pandas
DESCRIPTION: Fixed regression in read_csv used in file like object RawIOBase is not recognize encoding option.

LANGUAGE: python
CODE:
# Example not provided in the original text

----------------------------------------

TITLE: New Range Index Example
DESCRIPTION: Demonstrates the memory-efficient RangeIndex for common index use cases

LANGUAGE: python
CODE:
s = pd.Series(range(1000))
s.index
s.index.nbytes

----------------------------------------

TITLE: Rendering Regular Sponsors with Jinja2
DESCRIPTION: Template code for displaying regular sponsors that provide funding to pandas. Uses Jinja2 templating to filter and display sponsor information.

LANGUAGE: jinja2
CODE:
<ul>
    {% for company in sponsors.active if company.kind == "regular" %}
        <li><a href="{{ company.url }}">{{ company.name }}</a>: {{ company.description }}</li>
    {% endfor %}
</ul>

----------------------------------------

TITLE: Building Pandas Website with Python Script
DESCRIPTION: Command to generate the Pandas website using a Python script. The script takes 'pandas' as an argument and has additional options available through the help command.

LANGUAGE: bash
CODE:
./pandas_web.py pandas

LANGUAGE: bash
CODE:
./pandas_web.py --help

----------------------------------------

TITLE: Kernel Density Estimation Plot in pandas
DESCRIPTION: Shows how to create a histogram with kernel density estimation overlay using the new 'kde' plot option in pandas plotting functionality.

LANGUAGE: python
CODE:
s = pd.Series(
    np.concatenate((np.random.randn(1000), np.random.randn(1000) * 0.5 + 3))
)
plt.figure()
s.hist(density=True, alpha=0.2)
s.plot(kind="kde")

----------------------------------------

TITLE: Fixed regression in read_csv with large datasets and index_col
DESCRIPTION: Resolves an issue where read_csv would fail for datasets with more than 1 million rows when specifying an index_col argument.

LANGUAGE: python
CODE:
read_csv(large_file, index_col='column_name')

----------------------------------------

TITLE: Rolling with Time Windows
DESCRIPTION: Example showing the new time-aware rolling window operations

LANGUAGE: python
CODE:
dft.rolling('2s').sum()

----------------------------------------

TITLE: GroupBy aggregation on object-dtype columns in pandas
DESCRIPTION: Fixed regression in .groupby().agg() raising an AssertionError for some reductions like min on object-dtype columns.

LANGUAGE: python
CODE:
# Example not provided in the original text

----------------------------------------

TITLE: Demonstrating Slicing with Monotonic Decreasing Indexes in Pandas 0.15.1
DESCRIPTION: Shows support for slicing with monotonic decreasing indexes, even if start or stop is not found in the index.

LANGUAGE: python
CODE:
s = pd.Series(["a", "b", "c", "d"], [4, 3, 2, 1])
s

s.loc[3.5:1.5]

----------------------------------------

TITLE: Installing JupyterLite Dependencies
DESCRIPTION: Commands for installing the required JupyterLite core and Pyodide kernel packages using pip.

LANGUAGE: bash
CODE:
python -m pip install jupyterlite-core
python -m pip install jupyterlite-pyodide-kernel

----------------------------------------

TITLE: Fixing DataFrame.__dataframe__ for pyarrow string columns
DESCRIPTION: This snippet addresses two bug fixes for the DataFrame.__dataframe__ method related to 'string[pyarrow]' columns, correcting issues with validity buffers and bitmasks.

LANGUAGE: Python
CODE:
DataFrame.__dataframe__

----------------------------------------

TITLE: Reading Categorical Data
DESCRIPTION: Example of parsing categorical data directly with read_csv

LANGUAGE: python
CODE:
pd.read_csv(StringIO(data), dtype='category').dtypes

----------------------------------------

TITLE: Parsing ISO8601-format Date Strings with DatetimeIndex in Pandas
DESCRIPTION: Demonstrates the improved performance of parsing ISO8601-format date strings using DatetimeIndex or to_datetime function in Pandas 0.8.1.

LANGUAGE: python
CODE:
DatetimeIndex(iso8601_strings)
to_datetime(iso8601_strings)

----------------------------------------

TITLE: Fixed regression in RollingGroupby respecting sort parameter
DESCRIPTION: Ensures that the sort=False parameter is properly respected in RollingGroupby operations.

LANGUAGE: python
CODE:
df.groupby('column').rolling(window=3, sort=False)

----------------------------------------

TITLE: Partial string indexing on DatetimeIndex in MultiIndex
DESCRIPTION: Shows how partial string indexing now works on DatetimeIndex when part of a MultiIndex

LANGUAGE: python
CODE:
dft2 = pd.DataFrame(
    np.random.randn(20, 1),
    columns=["A"],
    index=pd.MultiIndex.from_product(
        [pd.date_range("20130101", periods=10, freq="12H"), ["a", "b"]]
    ),
)

dft2.loc["2013-01-05"]

idx = pd.IndexSlice
dft2.loc[idx[:, "2013-01-05"], :]

----------------------------------------

TITLE: Fixed regression in RollingGroupby with object dtype Index
DESCRIPTION: Addresses a segmentation fault that occurred in RollingGroupby when using an Index with dtype object.

LANGUAGE: python
CODE:
df.groupby(pd.Index(['A', 'B'], dtype=object)).rolling(window=2)

----------------------------------------

TITLE: Working with TimedeltaIndex
DESCRIPTION: Demonstration of the new TimedeltaIndex functionality in pandas 0.15.0

LANGUAGE: Python
CODE:
pd.Timedelta('1 days 06:05:01.00003')
pd.Timedelta('15.5us')

td = pd.Timedelta('1 hour 3m 15.5us')
td.seconds
td.microseconds
td.nanoseconds

pd.timedelta_range('1 days', periods=5, freq='D')

----------------------------------------

TITLE: Building JupyterLite REPL
DESCRIPTION: Command to build the JupyterLite environment in the web/interactive_terminal directory.

LANGUAGE: bash
CODE:
jupyter lite build

----------------------------------------

TITLE: Correcting DataFrame.to_sql schema handling
DESCRIPTION: This snippet refers to a bug fix for the DataFrame.to_sql method, which was failing to find the correct table when using the schema argument.

LANGUAGE: Python
CODE:
DataFrame.to_sql

----------------------------------------

TITLE: Filtering NA Values in Boolean Operations
DESCRIPTION: Demonstrates a technique to filter out NA values when performing boolean operations on Series objects to avoid unexpected results.

LANGUAGE: python
CODE:
In [4]: mask = series == "Steve"

In [5]: series[mask & series.notnull()]
Out[5]:
0    Steve
Length: 1, dtype: object

----------------------------------------

TITLE: Fixed regression in Series setitem alignment
DESCRIPTION: Corrects the behavior of setitem with a Series to prevent unintended alignment before setting values.

LANGUAGE: python
CODE:
series[index] = other_series

----------------------------------------

TITLE: Memory Usage Analysis with DataFrame Info
DESCRIPTION: Example demonstrating deep memory usage analysis of a DataFrame with mixed data types including categorical data.

LANGUAGE: python
CODE:
df = pd.DataFrame({"A": ["foo"] * 1000})  # noqa: F821
df["B"] = df["A"].astype("category")

# shows the '+' as we have object dtypes
df.info()

# we have an accurate memory assessment (but can be expensive to compute this)
df.info(memory_usage="deep")

----------------------------------------

TITLE: Fixed regression in offset hashability
DESCRIPTION: Restores hashability for certain offsets (pd.offsets.Day() and below) that were no longer hashable.

LANGUAGE: python
CODE:
hash(pd.offsets.Day(1))

----------------------------------------

TITLE: Pandas Indexing Example with iloc
DESCRIPTION: Example showing new out-of-bounds indexing behavior with iloc where invalid slices are excluded rather than raising an error

LANGUAGE: python
CODE:
dfl = pd.DataFrame(np.random.randn(5, 2), columns=list('AB'))
dfl
dfl.iloc[:, 2:3]
dfl.iloc[:, 1:3]
dfl.iloc[4:6]

----------------------------------------

TITLE: Serving Pandas Website Locally with Python HTTP Server
DESCRIPTION: Command to start a local HTTP server using Python's built-in http.server module. This allows viewing the built website locally by serving files from the web/build/ directory.

LANGUAGE: bash
CODE:
python -m http.server

----------------------------------------

TITLE: Fixed Regressions in Pandas 2.0.2
DESCRIPTION: List of fixed regression issues including GroupBy.apply performance, merge operations on Windows, read_sql column handling, DataFrame.loc MultiIndex name preservation, DataFrame.to_string formatting, and MultiIndex.join level ordering.

LANGUAGE: python
CODE:
GroupBy.apply() # Performance improvements
merge() # Fixed Windows np.intc dtype handling
read_sql() # Fixed duplicate column handling
DataFrame.loc # Fixed MultiIndex name preservation
DataFrame.to_string() # Fixed backslash printing
MultiIndex.join() # Fixed level ordering

----------------------------------------

TITLE: Initializing DataFrame and Performing Modulo Operation
DESCRIPTION: Example showing how modulo and integer division on DataFrames now return np.nan or np.inf for zero division, consistent with float dtypes.

LANGUAGE: Python
CODE:
p = pd.DataFrame({"first": [4, 5, 8], "second": [0, 0, 3]})
p % 0
p % p
p / p
p / 0

----------------------------------------

TITLE: RST Documentation for Pandas 0.7.2 Release Notes
DESCRIPTION: ReStructuredText documentation detailing new features, performance improvements, and contributor information for Pandas version 0.7.2.

LANGUAGE: rst
CODE:
.. _whatsnew_0702:

Version 0.7.2 (March 16, 2012)
------------------------------

{{ header }}


This release targets bugs in 0.7.1, and adds a few minor features.

New features
~~~~~~~~~~~~

  - Add additional tie-breaking methods in DataFrame.rank (:issue:`874`)
  - Add ascending parameter to rank in Series, DataFrame (:issue:`875`)
  - Add coerce_float option to DataFrame.from_records (:issue:`893`)
  - Add sort_columns parameter to allow unsorted plots (:issue:`918`)
  - Enable column access via attributes on GroupBy (:issue:`882`)
  - Can pass dict of values to DataFrame.fillna (:issue:`661`)
  - Can select multiple hierarchical groups by passing list of values in .ix
    (:issue:`134`)
  - Add ``axis`` option to DataFrame.fillna (:issue:`174`)
  - Add level keyword to ``drop`` for dropping values from a level (:issue:`159`)

Performance improvements
~~~~~~~~~~~~~~~~~~~~~~~~

  - Use khash for Series.value_counts, add raw function to algorithms.py (:issue:`861`)
  - Intercept __builtin__.sum in groupby (:issue:`885`)



.. _whatsnew_0.7.2.contributors:

Contributors
~~~~~~~~~~~~

.. contributors:: v0.7.1..v0.7.2

----------------------------------------

TITLE: Fixed regression in MultiIndex.is_monotonic_increasing with NaN
DESCRIPTION: Corrects the results of MultiIndex.is_monotonic_increasing when NaN is present in at least one of the levels.

LANGUAGE: python
CODE:
multi_index_with_nan.is_monotonic_increasing

----------------------------------------

TITLE: Demonstrating DataFrame Creation with Different Numeric Dtypes in Python
DESCRIPTION: This code snippet shows how different numeric dtypes can coexist and propagate in pandas DataFrames. It creates DataFrames with float32, float16, float64, and uint8 dtypes and demonstrates upcasting when combining them.

LANGUAGE: Python
CODE:
df1 = pd.DataFrame(np.random.randn(8, 1), columns=['A'], dtype='float32')
df1
df1.dtypes
df2 = pd.DataFrame({'A': pd.Series(np.random.randn(8), dtype='float16'),
                   'B': pd.Series(np.random.randn(8)),
                   'C': pd.Series(range(8), dtype='uint8')})
df2
df2.dtypes

# here you get some upcasting
df3 = df1.reindex_like(df2).fillna(value=0.0) + df2
df3
df3.dtypes

----------------------------------------

TITLE: Resolving Parquet Reading with Fastparquet Engine in Python
DESCRIPTION: Fixed a compatibility issue between read_parquet and fastparquet 0.7.0.

LANGUAGE: python
CODE:
pd.read_parquet('file.parquet', engine='fastparquet')

----------------------------------------

TITLE: Handling NaN values in DataFrame assignment
DESCRIPTION: Demonstrates the correct way to assign NaN values to a DataFrame column, addressing a bug fix in pandas 0.13.1 related to chained indexing.

LANGUAGE: python
CODE:
df = pd.DataFrame({"A": np.array(["foo", "bar", "bah", "foo", "bar"])})
df.loc[0, "A"] = np.nan
df

----------------------------------------

TITLE: Handling NaN values in DataFrame assignment
DESCRIPTION: Demonstrates the correct way to assign NaN values to a DataFrame column, addressing a bug fix in pandas 0.13.1 related to chained indexing.

LANGUAGE: python
CODE:
df = pd.DataFrame({"A": np.array(["foo", "bar", "bah", "foo", "bar"])})
df.loc[0, "A"] = np.nan
df

----------------------------------------

TITLE: Package Dependencies List for Pandas
DESCRIPTION: Comprehensive list of Python package dependencies with specific version constraints required for the Pandas project. Includes development tools, test frameworks, documentation generators, and runtime dependencies.

LANGUAGE: plaintext
CODE:
pip
versioneer[toml]
cython~=3.0.5
meson[ninja]==1.2.1
meson-python==0.13.1
pytest>=7.3.2
pytest-cov
pytest-xdist>=3.4.0
pytest-qt>=4.4.0
pytest-localserver
PyQt5>=5.15.9
coverage
python-dateutil
numpy<2
beautifulsoup4>=4.11.2
blosc
bottleneck>=1.3.6
fastparquet>=2023.10.0
fsspec>=2022.11.0
html5lib>=1.1
hypothesis>=6.84.0
gcsfs>=2022.11.0
ipython
pickleshare
jinja2>=3.1.2
lxml>=4.9.2
matplotlib>=3.6.3
numba>=0.56.4
numexpr>=2.8.4
openpyxl>=3.1.0
odfpy>=1.4.1
py
psycopg2-binary>=2.9.6
pyarrow>=10.0.1
pymysql>=1.0.2
pyreadstat>=1.2.0
tables>=3.8.0
python-calamine>=0.1.7
pytz>=2023.4
pyxlsb>=1.0.10
s3fs>=2022.11.0
scipy>=1.10.0
SQLAlchemy>=2.0.0
tabulate>=0.9.0
xarray>=2022.12.0, <=2024.9.0
xlrd>=2.0.1
xlsxwriter>=3.0.5
zstandard>=0.19.0
dask
seaborn
moto
flask
asv>=0.6.1
flake8==7.1.0
mypy==1.13.0
tokenize-rt
pre-commit>=4.0.1
gitpython
gitdb
google-auth
natsort
numpydoc
pydata-sphinx-theme==0.16
pytest-cython
sphinx
sphinx-design
sphinx-copybutton
types-python-dateutil
types-PyMySQL
types-pytz
types-PyYAML
types-setuptools
nbconvert>=7.11.0
nbsphinx
pandoc
ipywidgets
nbformat
notebook>=7.0.6
ipykernel
markdown
feedparser
pyyaml
requests
pygments
jupyterlite-core
jupyterlite-pyodide-kernel
adbc-driver-postgresql>=0.10.0
adbc-driver-sqlite>=0.8.0
typing_extensions; python_version<"3.11"
tzdata>=2022.7

----------------------------------------

TITLE: PyArrow Backed Series Example
DESCRIPTION: Examples showing how to create and work with Series using PyArrow backed arrays

LANGUAGE: python
CODE:
import pyarrow as pa
ser_float = pd.Series([1.0, 2.0, None], dtype="float32[pyarrow]")
ser_float

list_of_int_type = pd.ArrowDtype(pa.list_(pa.int64()))
ser_list = pd.Series([[1, 2], [3, None]], dtype=list_of_int_type)
ser_list

ser_list.take([1, 0])
ser_float * 5
ser_float.mean()
ser_float.dropna()

----------------------------------------

TITLE: Creating Series from CSV in Python
DESCRIPTION: A new function Series.from_csv was added to create Series objects directly from CSV files.

LANGUAGE: python
CODE:
# Example usage (not provided in the original text)
Series.from_csv('filename.csv')

----------------------------------------

TITLE: Setting item in DataFrame with MultiIndex in pandas
DESCRIPTION: Fixed regression in DataFrame.__setitem__ raising an AttributeError with a MultiIndex and a non-monotonic indexer.

LANGUAGE: python
CODE:
# Example not provided in the original text

----------------------------------------

TITLE: Demonstrating DataFrame Creation with Default Int64 Dtype in Python
DESCRIPTION: This code snippet shows that DataFrame and Series construction in pandas 0.11.0 uses default dtypes of int64 and float64, regardless of platform. It demonstrates creating DataFrames with integer data in different ways.

LANGUAGE: Python
CODE:
pd.DataFrame([1, 2], columns=['a']).dtypes
pd.DataFrame({'a': [1, 2]}).dtypes
pd.DataFrame({'a': 1}, index=range(2)).dtypes

----------------------------------------

TITLE: Demonstrating DataFrame Attribute Access in Python with Pandas
DESCRIPTION: Shows how conflicting attribute/column names now behave consistently between getting and setting in DataFrames.

LANGUAGE: python
CODE:
data = pd.DataFrame({'x': [1, 2, 3]})
data.y = 2
data['y'] = [2, 4, 6]
data

# this assignment was inconsistent
data.y = 5

data.y
data['y'].values

----------------------------------------

TITLE: Controlling DataFrame info() output
DESCRIPTION: Shows how to use the max_info_rows option to control the display of null counts in DataFrame.info() output.

LANGUAGE: python
CODE:
max_info_rows = pd.get_option("max_info_rows")

df = pd.DataFrame(
    {
        "A": np.random.randn(10),
        "B": np.random.randn(10),
        "C": pd.date_range("20130101", periods=10),
    }
)
df.iloc[3:6, [0, 2]] = np.nan

# set to not display the null counts
pd.set_option("max_info_rows", 0)
df.info()

# this is the default (same as in 0.13.0)
pd.set_option("max_info_rows", max_info_rows)
df.info()

----------------------------------------

TITLE: Generating Accessor Attribute Documentation for Pandas in reStructuredText
DESCRIPTION: This snippet defines a template for documenting accessor attributes in Pandas. It uses Sphinx directives to set the current module and automatically generate documentation for the specified accessor attribute.

LANGUAGE: reStructuredText
CODE:
{{ fullname }}
{{ underline }}

.. currentmodule:: {{ module.split('.')[0] }}

.. autoaccessorattribute:: {{ (module.split('.')[1:] + [objname]) | join('.') }}

----------------------------------------

TITLE: Fixing Outer Merge with Integer and NaN Keys in Python
DESCRIPTION: Resolved a regression in the merge function that was failing with outer merge when using integer and NaN keys.

LANGUAGE: Python
CODE:
merge()

----------------------------------------

TITLE: Demonstrating deprecated DataFrame-TimeSeries operation in pandas
DESCRIPTION: Shows the deprecated behavior of binary operations between a DataFrame and a Series, which used to align on columns and broadcast down rows for time series. The new recommended approach using the sub() method is also demonstrated.

LANGUAGE: python
CODE:
import pandas as pd

df = pd.DataFrame(np.random.randn(6, 4), index=pd.date_range("1/1/2000", periods=6))
df
# deprecated now
df - df[0]
# Change your code to 
df.sub(df[0], axis=0)  # align on axis 0 (rows)

----------------------------------------

TITLE: Creating DataFrame from Items in Python
DESCRIPTION: A new alternate constructor DataFrame.from_items was implemented for creating DataFrames.

LANGUAGE: python
CODE:
# Example usage (not provided in the original text)
DataFrame.from_items([(key1, value1), (key2, value2)])

----------------------------------------

TITLE: GroupBy apply with non-pandas return types in pandas
DESCRIPTION: Fixed regression in .DataFrameGroupBy.apply and .SeriesGroupBy.apply if called with a function which returned a non-pandas non-scalar object (e.g. a list or numpy array).

LANGUAGE: python
CODE:
# Example not provided in the original text

----------------------------------------

TITLE: Using Accelerated 'median' GroupBy Option in Pandas
DESCRIPTION: Illustrates the usage of the new accelerated 'median' option for GroupBy operations in Pandas 0.8.1, which improves performance for this specific aggregation.

LANGUAGE: python
CODE:
GroupBy(median=True)

----------------------------------------

TITLE: Demonstrating Categorical Unique Behavior in Python with Pandas
DESCRIPTION: Shows how the unique() method on Categorical Series now only returns categories that actually occur in the data, instead of all defined categories.

LANGUAGE: python
CODE:
In [3]: cat = pd.Categorical(['a', 'b', 'a'], categories=['a', 'b', 'c'])

In [4]: cat
Out[4]: 
[a, b, a]
Categories (3, object): [a < b < c]

In [5]: cat.unique()
Out[5]: array(['a', 'b', 'c'], dtype=object)

cat = pd.Categorical(['a', 'b', 'a'], categories=['a', 'b', 'c'])
cat.unique()

----------------------------------------

TITLE: Controlling dimensions display in DataFrame repr
DESCRIPTION: Demonstrates how to use the show_dimensions option to control whether dimensions are printed in DataFrame representation.

LANGUAGE: python
CODE:
df = pd.DataFrame([[1, 2], [3, 4]])
pd.set_option("show_dimensions", False)
df

pd.set_option("show_dimensions", True)
df

----------------------------------------

TITLE: Updating Series Categories in Python
DESCRIPTION: Fixed regressions in Series.cat.reorder_categories and Series.cat.categories setter, which were failing to update the categories on the Series.

LANGUAGE: Python
CODE:
Series.cat.reorder_categories()
Series.cat.categories

----------------------------------------

TITLE: Correcting DataFrame Correlation Calculation on 32-bit Platforms in Python
DESCRIPTION: Fixed a regression where DataFrame.corr was raising a ValueError with method="spearman" on 32-bit platforms.

LANGUAGE: Python
CODE:
DataFrame.corr(method="spearman")

----------------------------------------

TITLE: Resolving GroupBy Quantile Method for pandas.NA in Python
DESCRIPTION: Fixed an issue where DataFrameGroupBy.quantile and SeriesGroupBy.quantile were failing with pandas.NA values.

LANGUAGE: python
CODE:
df.groupby('column').quantile()

----------------------------------------

TITLE: GroupBy on empty DataFrame with MultiIndex in pandas
DESCRIPTION: Fixed regression in DataFrame.groupby with an empty DataFrame grouping by a level of a MultiIndex.

LANGUAGE: python
CODE:
# Example not provided in the original text

----------------------------------------

TITLE: DateTime Object Conversion in pandas
DESCRIPTION: Shows different methods for converting DatetimeIndex to arrays of datetime objects, including using astype(object) and to_pydatetime().

LANGUAGE: python
CODE:
stamp_array = rng.astype(object)
stamp_array
stamp_array[5]

dt_array = rng.to_pydatetime()
dt_array
dt_array[5]

----------------------------------------

TITLE: Demonstrating MultiIndex Indexing in Python with Pandas
DESCRIPTION: Shows how indexing beyond lexsort depth is now supported in MultiIndex, with a performance warning. Also demonstrates lexically sorting the index to improve performance.

LANGUAGE: python
CODE:
In [1]: df = pd.DataFrame({'jim':[0, 0, 1, 1],
       ...:                    'joe':['x', 'x', 'z', 'y'],
       ...:                    'jolie':np.random.rand(4)}).set_index(['jim', 'joe'])
       ...: 

In [2]: df
Out[2]: 
                jolie
jim joe             
0   x    0.126970
    x    0.966718
1   z    0.260476
    y    0.897237

[4 rows x 1 columns]

In [3]: df.index.lexsort_depth
Out[3]: 1

# in prior versions this would raise a KeyError
# will now show a PerformanceWarning
In [4]: df.loc[(1, 'z')]
Out[4]: 
                jolie
jim joe             
1   z    0.260476

[1 rows x 1 columns]

# lexically sorting
In [5]: df2 = df.sort_index()

In [6]: df2
Out[6]: 
                jolie
jim joe             
0   x    0.126970
    x    0.966718
1   y    0.897237
    z    0.260476

[4 rows x 1 columns]

In [7]: df2.index.lexsort_depth
Out[7]: 2

In [8]: df2.loc[(1,'z')]
Out[8]: 
                jolie
jim joe             
1   z    0.260476

[1 rows x 1 columns]

----------------------------------------

TITLE: MultiIndex Level Selection
DESCRIPTION: Shows how to select and rename MultiIndex levels using the new set_levels and set_names methods instead of direct attribute access.

LANGUAGE: python
CODE:
# previously, you would have set levels or labels directly
>>> pd.index.levels = [[1, 2, 3, 4], [1, 2, 4, 4]]

# now, you use the set_levels or set_labels methods
>>> index = pd.index.set_levels([[1, 2, 3, 4], [1, 2, 4, 4]])

# similarly, for names, you can rename the object
# but setting names is not deprecated
>>> index = pd.index.set_names(["bob", "cranberry"])

# and all methods take an inplace kwarg - but return None
>>> pd.index.set_names(["bob", "cranberry"], inplace=True)

----------------------------------------

TITLE: Improving MultiIndex Equality Performance in Python
DESCRIPTION: Addressed a performance regression in the MultiIndex.equals method.

LANGUAGE: Python
CODE:
MultiIndex.equals()

----------------------------------------

TITLE: Correcting DataFrame Explode Operation in Python
DESCRIPTION: Addressed a regression where DataFrame.explode was raising an AssertionError when the column parameter was any scalar which is not a string.

LANGUAGE: Python
CODE:
DataFrame.explode()

----------------------------------------

TITLE: Creating Scatter Plot Matrix in Pandas
DESCRIPTION: Demonstrates how to create a scatter plot matrix using the new scatter_matrix function from pandas.tools.plotting. The alpha parameter is used to set the transparency of the points.

LANGUAGE: python
CODE:
from pandas.tools.plotting import scatter_matrix

scatter_matrix(df, alpha=0.2)  # noqa F821

----------------------------------------

TITLE: Fixing GroupBy Operations with Numba Engine in Python
DESCRIPTION: Corrected an issue where index data was not being properly passed to the function in DataFrameGroupBy.agg and DataFrameGroupBy.transform when using engine='numba'.

LANGUAGE: python
CODE:
df.groupby('column').agg(func, engine='numba')

----------------------------------------

TITLE: CSV export with na_rep in pandas
DESCRIPTION: Fixed regression in to_csv where specifying an na_rep might truncate the values written.

LANGUAGE: python
CODE:
# Example not provided in the original text

----------------------------------------

TITLE: Creating Stacked Bar Plots in Pandas
DESCRIPTION: Shows how to create vertical and horizontal stacked bar plots using the plot method of DataFrame with the 'stacked' argument set to True.

LANGUAGE: python
CODE:
df.plot(kind="bar", stacked=True)  # noqa F821

LANGUAGE: python
CODE:
df.plot(kind="barh", stacked=True)  # noqa F821

----------------------------------------

TITLE: Category Accessors for String and DateTime Operations
DESCRIPTION: Examples showing how to use string and datetime accessors on categorical Series objects.

LANGUAGE: python
CODE:
s = pd.Series(list("aabb")).astype("category")
s
s.str.contains("a")

date = pd.Series(pd.date_range("1/1/2015", periods=5)).astype("category")
date
date.dt.day

----------------------------------------

TITLE: Using HDFStore in Pandas for Data Storage and Retrieval
DESCRIPTION: This code demonstrates the use of HDFStore in pandas for storing and retrieving data. It shows how to write a DataFrame to an HDF5 file and read it back using conditions.

LANGUAGE: Python
CODE:
df = pd.DataFrame({'A': range(5), 'B': range(5)})
df.to_hdf('store.h5', key='table', append=True)
pd.read_hdf('store.h5', 'table', where=['index > 2'])

----------------------------------------

TITLE: Fixing GroupBy Apply Method for NaN Values in Python
DESCRIPTION: Corrected a regression where NaN values were being dropped in DataFrameGroupBy.apply and SeriesGroupBy.apply even with dropna=False.

LANGUAGE: python
CODE:
df.groupby('column').apply(func, dropna=False)

----------------------------------------

TITLE: Correcting DataFrame Loc Setitem Method in Python
DESCRIPTION: Addressed a ValueError being raised when setting an array as a cell value using DataFrame.loc.__setitem__.

LANGUAGE: python
CODE:
df.loc[row, col] = array_value

----------------------------------------

TITLE: Fixing DataFrame Reindex Limit Argument in Python
DESCRIPTION: This bug fix addresses a regression in DataFrame.reindex() method where the limit argument was not being followed correctly.

LANGUAGE: Python
CODE:
DataFrame.reindex(limit=...)

----------------------------------------

TITLE: Applying Functions to Grouped Series in Pandas
DESCRIPTION: Shows the new behavior of apply method on grouped Series, which now returns a Series instead of a DataFrame for consistency with DataFrame groupby operations.

LANGUAGE: python
CODE:
In [6]: df = pd.DataFrame(
   ...:     {
   ...:         "A": ["foo", "bar", "foo", "bar", "foo", "bar", "foo", "foo"],
   ...:         "B": ["one", "one", "two", "three", "two", "two", "one", "three"],
   ...:         "C": np.random.randn(8),
   ...:         "D": np.random.randn(8),
   ...:     }
   ...: )
   ...: 

In [7]: df
Out[7]:
   A      B         C         D
0  foo    one  0.469112 -0.861849
1  bar    one -0.282863 -2.104569
2  foo    two -1.509059 -0.494929
3  bar  three -1.135632  1.071804
4  foo    two  1.212112  0.721555
5  bar    two -0.173215 -0.706771
6  foo    one  0.119209 -1.039575
7  foo  three -1.044236  0.271860

[8 rows x 4 columns]

In [8]: grouped = df.groupby("A")["C"]

In [9]: grouped.describe()
Out[9]:
   count      mean       std       min       25%       50%       75%       max
A
bar    3.0 -0.530570  0.526860 -1.135632 -0.709248 -0.282863 -0.228039 -0.173215
foo    5.0 -0.150572  1.113308 -1.509059 -1.044236  0.119209  0.469112  1.212112

[2 rows x 8 columns]

In [10]: grouped.apply(lambda x: x.sort_values()[-2:])  # top 2 values
Out[10]:
A
bar  1   -0.282863
     5   -0.173215
foo  0    0.469112
     4    1.212112
Name: C, Length: 4, dtype: float64

----------------------------------------

TITLE: Installing Optional Dependencies with pip
DESCRIPTION: Shows how to install pandas with optional dependencies using pip extras

LANGUAGE: bash
CODE:
pip install "pandas[performance, aws]>=2.0.0"

----------------------------------------

TITLE: HDFStore Unique Value Retrieval in Python
DESCRIPTION: Shows how to retrieve unique values from indexable or data columns in an HDFStore. Note that this functionality is deprecated as of version 0.14.0.

LANGUAGE: python
CODE:
# note that this is deprecated as of 0.14.0
# can be replicated by: store.select_column('df','index').unique()
store.unique("df", "index")
store.unique("df", "string")

----------------------------------------

TITLE: Resolving DataFrame Getitem for Non-monotonic DatetimeIndex in Python
DESCRIPTION: Fixed an error being raised for slice operations on a DataFrame with a non-monotonic DatetimeIndex.

LANGUAGE: python
CODE:
df[start_date:end_date]

----------------------------------------

TITLE: Demonstrating NumPy ufunc behavior on non-aligned DataFrames in Python
DESCRIPTION: Shows how calling NumPy ufuncs on non-aligned DataFrames previously ignored indices and matched by shape, contrasting with pandas operations that align inputs first. This behavior is changing in future versions.

LANGUAGE: python
CODE:
df1 = pd.DataFrame({"a": [1, 2], "b": [3, 4]}, index=[0, 1])
df2 = pd.DataFrame({"a": [1, 2], "b": [3, 4]}, index=[1, 2])
df1
df2

np.add(df1, df2)

df1 + df2

----------------------------------------

TITLE: Applying Functions to DataFrame Columns in Python
DESCRIPTION: Demonstrates using DataFrame.apply() to apply a lambda function that calculates descriptive statistics for each column of a DataFrame containing random numbers.

LANGUAGE: python
CODE:
df = pd.DataFrame(np.random.randn(10, 4))
df.apply(lambda x: x.describe())

----------------------------------------

TITLE: Correcting Merge Operation for ExtensionDtype Columns in Python
DESCRIPTION: Addressed a regression where 'on' columns with ExtensionDtype or bool data types were being cast to object in right and outer merges.

LANGUAGE: python
CODE:
pd.merge(left, right, on='column', how='right')

----------------------------------------

TITLE: Using Series methods in pandas Python library
DESCRIPTION: Examples of pandas Series methods that were fixed, including min(), max(), and is_unique(). These methods had issues with specific data types or handling of NaN values that were addressed in this release.

LANGUAGE: Python
CODE:
series.min(numeric_only=True)
series.max(numeric_only=True)
series.is_unique

----------------------------------------

TITLE: Accessing DataFrame and Series Methods (Python)
DESCRIPTION: Examples of new DataFrame and Series methods introduced in Pandas 0.4.x including isnull(), notnull(), align(), get_level_values(), and DataFrame property access via .ix indexing.

LANGUAGE: python
CODE:
series.isnull()
series.notnull()
series.align(other_series)
multiindex.get_level_values()
dataframe.ix[]
dataframe.get_dtype_counts()
dataframe.dtypes

----------------------------------------

TITLE: Improved datetime resolution inference
DESCRIPTION: Converting sequences of datetime-like objects to datetime64 dtype now infers the appropriate resolution, matching scalar Timestamp behavior.

LANGUAGE: python
CODE:
dt = pd.Timestamp("2024-03-22 11:36").to_pydatetime()
pd.to_datetime([dt]).dtype
pd.Index([dt]).dtype
pd.DatetimeIndex([dt]).dtype
pd.Series([dt]).dtype

----------------------------------------

TITLE: HDFStore MultiIndex Serialization in Python
DESCRIPTION: Demonstrates HDFStore's ability to serialize and query MultiIndex dataframes when appending tables.

LANGUAGE: python
CODE:
index = pd.MultiIndex(levels=[['foo', 'bar', 'baz', 'qux'],
                              ['one', 'two', 'three']],
                      labels=[[0, 0, 0, 1, 1, 2, 2, 3, 3, 3],
                              [0, 1, 2, 0, 1, 1, 2, 0, 1, 2]],
                      names=['foo', 'bar'])

df = pd.DataFrame(np.random.randn(10, 3), index=index,
                  columns=['A', 'B', 'C'])

store.append('mi', df)

----------------------------------------

TITLE: Correcting Series Fillna Method for Float Series in Python
DESCRIPTION: Addressed a TypeError being raised when filling a float Series with a list-like fill value of a different precision.

LANGUAGE: python
CODE:
series.fillna(fill_value)

----------------------------------------

TITLE: Aligning DataFrames before NumPy ufunc calls in Python
DESCRIPTION: Shows how to manually align DataFrames before passing them to NumPy ufuncs to obtain future behavior and silence warnings.

LANGUAGE: python
CODE:
df1, df2 = df1.align(df2)
np.add(df1, df2)

----------------------------------------

TITLE: Correcting GroupBy Aggregation Behavior in Python
DESCRIPTION: Addressed issues with DataFrameGroupBy.agg and SeriesGroupBy.agg incorrectly raising errors in certain cases.

LANGUAGE: python
CODE:
df.groupby('column').agg(func)

----------------------------------------

TITLE: Importing pandas and using DataFrame methods in Python
DESCRIPTION: Examples of pandas DataFrame methods that were fixed in this release, including all(), any(), apply(), replace(), and duplicated(). These methods had regressions addressed in version 0.24.2.

LANGUAGE: Python
CODE:
df.all(bool_only=True)
df.any(bool_only=True)
df.apply(dict_like_function)
df.replace(regex=True)
df.duplicated()

----------------------------------------

TITLE: Direct mutation of original DataFrame with proposed behavior
DESCRIPTION: Example showing how to directly modify the original DataFrame under the proposed Copy-on-Write behavior.

LANGUAGE: python
CODE:
>>> df = pd.DataFrame({"A": [1, 2], "B": [3, 4], "C": [5, 6]})
>>> df.loc[df["A"] > 1, "A"] = 1  # need to directly mutate df instead

----------------------------------------

TITLE: Group Aggregation in SAS using PROC SUMMARY
DESCRIPTION: This SAS code snippet demonstrates how to perform group aggregations using PROC SUMMARY.

LANGUAGE: sas
CODE:
proc summary data=tips nway;
    class sex smoker;
    var total_bill tip;
    output out=tips_summed sum=;
run;

----------------------------------------

TITLE: Handling boolean values in pandas read_csv
DESCRIPTION: Demonstrates how 'Yes' and 'No' values are not interpreted as boolean by default in read_csv. Shows how to control this using the true_values and false_values arguments.

LANGUAGE: python
CODE:
print(data)

pd.read_csv(io.StringIO(data))

pd.read_csv(io.StringIO(data), true_values=["Yes"], false_values=["No"])

----------------------------------------

TITLE: Correcting Resampler Aggregate Method in Python
DESCRIPTION: Addressed an issue where Resampler.aggregate was raising an error when used after column selection with a list of aggregation functions.

LANGUAGE: python
CODE:
df.resample('D')['column'].aggregate([func1, func2])

----------------------------------------

TITLE: Fixed regression in read_csv with ValueError for dict_keys names
DESCRIPTION: Addresses a regression where read_csv would raise a ValueError when the 'names' parameter was of type dict_keys.

LANGUAGE: python
CODE:
read_csv(file, names=dict_keys_object)

----------------------------------------

TITLE: Defining Custom Function for Controlled Float to Integer Conversion
DESCRIPTION: This snippet provides a helper function to allow controlled conversion of float values to integers within a specified tolerance, which users can adapt to their needs.

LANGUAGE: python
CODE:
def maybe_convert_to_int(x: int | float, tolerance: float):
    if np.abs(x - round(x)) < tolerance:
        return round(x)
    return x

----------------------------------------

TITLE: Fixed regression in DatetimeIndex slicing
DESCRIPTION: Resolves an AssertionError that occurred when slicing DatetimeIndex on irregular time series with pd.NaT or unsorted indices.

LANGUAGE: python
CODE:
irregular_dti[start:end]

----------------------------------------

TITLE: Using roll_quantile with q between 0 and 1 in Python
DESCRIPTION: Fix for a memory leak when calling .rolling().quantile(q) with q values between 0 and 1.

LANGUAGE: python
CODE:
.rolling(...).quantile(q)

----------------------------------------

TITLE: Example of Current Behavior Hiding Typos in Date Assignments
DESCRIPTION: This code snippet illustrates how the current pandas behavior can potentially hide bugs by silently upcasting to object dtype when a typo is made in date assignment.

LANGUAGE: python
CODE:
In[9]: ser = pd.Series(pd.date_range("2000", periods=3))

In[10]: ser[2] = "2000-01-04"  # works, is converted to datetime64

In[11]: ser[2] = "2000-01-04x"  # typo - but pandas does not error, it upcasts to object

----------------------------------------

TITLE: By Group Processing in SAS
DESCRIPTION: This SAS code snippet shows how to perform by group processing in SAS, filtering to the first entry for each group.

LANGUAGE: sas
CODE:
proc sort data=tips;
   by sex smoker;
run;

data tips_first;
    set tips;
    by sex smoker;
    if FIRST.sex or FIRST.smoker then output;
run;

----------------------------------------

TITLE: Using apply with Series results in pandas
DESCRIPTION: Demonstrates how Series.apply now operates on returned values that are themselves Series, potentially upcasting the result to a DataFrame.

LANGUAGE: python
CODE:
def f(x):
    return pd.Series([x, x ** 2], index=["x", "x^2"])

s = pd.Series(np.random.rand(5))
s
s.apply(f)

----------------------------------------

TITLE: Fixed regression in StataReader requiring manual chunksize
DESCRIPTION: Removes the requirement to manually set chunksize when using an iterator to read a dataset with StataReader.

LANGUAGE: python
CODE:
pd.read_stata('file.dta', iterator=True)

----------------------------------------

TITLE: Enhanced pandas DataFrame Methods and Indexing
DESCRIPTION: Documentation of bug fixes in DataFrame methods including eval, apply, astype operations and indexing improvements.

LANGUAGE: python
CODE:
DataFrame.eval()  # Fixed object dtype column binary operations
DataFrame.apply(result_type="reduce")  # Fixed index handling
DataFrame.astype(errors="ignore")  # Fixed extension dtype handling

----------------------------------------

TITLE: Fixed regression in Series.astype handling of None values
DESCRIPTION: Corrects the behavior of Series.astype when converting None to string, preventing conversion to "nan".

LANGUAGE: python
CODE:
series.astype(str)

----------------------------------------

TITLE: DataFrame Logical Reduction Example
DESCRIPTION: Demonstrates the new functionality of DataFrame.all() and DataFrame.any() accepting axis=None to reduce over all axes to a scalar value.

LANGUAGE: python
CODE:
df = pd.DataFrame({"A": [1, 2], "B": [True, False]})
df.all(axis=None)

----------------------------------------

TITLE: Adding Series with Different Indices in Python
DESCRIPTION: Example demonstrating unexpected behavior when adding two Series with different indices, resulting in NaN values.

LANGUAGE: python
CODE:
ser1 + ser2

----------------------------------------

TITLE: Demonstrating NaN Behavior in Pandas Operations
DESCRIPTION: Example showing how NaN values behave in Pandas operations including outer joins, arithmetic operations, and aggregations. Shows that missing data propagates through numeric operations and is ignored in aggregations by default.

LANGUAGE: python
CODE:
outer_join
outer_join["value_x"] + outer_join["value_y"]
outer_join["value_x"].sum()

----------------------------------------

TITLE: Upsampling PeriodIndex Data in Python
DESCRIPTION: Demonstrates how upsampling data with a PeriodIndex results in a higher frequency TimeSeries that spans the original time window.

LANGUAGE: python
CODE:
prng = pd.period_range('2012Q1', periods=2, freq='Q')

s = pd.Series(np.random.randn(len(prng)), prng)

s.resample('M')

----------------------------------------

TITLE: Fixed regression in DataFrame.groupby().std() with nullable integer dtype
DESCRIPTION: Addresses an issue with DataFrame.groupby().std() when working with nullable integer dtypes.

LANGUAGE: python
CODE:
df['column'] = df['column'].astype('Int64')
df.groupby('group').std()

----------------------------------------

TITLE: Period Index Partial String Slicing
DESCRIPTION: Examples demonstrating non-monotonic PeriodIndex support for partial string slicing

LANGUAGE: ipython
CODE:
dti = pd.date_range("2014-01-01", periods=30, freq="30D")
pi = dti.to_period("D")
ser_monotonic = pd.Series(np.arange(30), index=pi)
shuffler = list(range(0, 30, 2)) + list(range(1, 31, 2))
ser = ser_monotonic.iloc[shuffler]
ser

ser["2014"]
ser.loc["May 2015"]

----------------------------------------

TITLE: Contributing Options HTML Layout
DESCRIPTION: HTML markup defining a 3-column layout that presents different ways to contribute to pandas: corporate support, individual contributions, and donations. Uses Bootstrap classes for responsive design and Font Awesome icons for visual elements.

LANGUAGE: html
CODE:
<section>
    <div class="container mt-5">
      <div class="row text-center">
        <div class="col-md-4">
          <span class="fa-stack fa-4x">
            <i class="fas fa-circle fa-stack-2x pink"></i>
            <i class="fas fa-building fa-stack-1x fa-inverse"></i>
          </span>
          <h4 class="service-heading mt-3 fw-bold blue">Corporate support</h4>
          <p class="text-muted">
            pandas depends on companies and institutions using the software to support its development. Hiring
            people to work on pandas, or letting existing employees to contribute to the
            software. Or sponsoring pandas with funds, so the project can hire people to
            progress on the <a href="{{ base_url }}about/roadmap.html">pandas roadmap</a>.
          </p>
          <p>More information in the <a href="{{ base_url }}about/sponsors.html">sponsors page</a></p>
        </div>
        <div class="col-md-4">
          <span class="fa-stack fa-4x">
            <i class="fas fa-circle fa-stack-2x pink"></i>
            <i class="fas fa-users fa-stack-1x fa-inverse"></i>
          </span>
          <h4 class="service-heading mt-3 fw-bold blue">Individual contributors</h4>
          <p class="text-muted">
            pandas is mostly developed by volunteers. All kind of contributions are welcome,
            such as contributions to the code, to the website (including graphical designers),
            to the documentation (including translators) and others. There are tasks for all
            levels, including beginners.
          </p>
          <p>More information in the <a href="{{ base_url }}docs/development/index.html">contributing page</a></p>
        </div>
        <div class="col-md-4">
          <span class="fa-stack fa-4x">
            <i class="fas fa-circle fa-stack-2x pink"></i>
            <i class="fas fa-dollar-sign fa-stack-1x fa-inverse"></i>
          </span>
          <h4 class="service-heading mt-3 fw-bold blue">Donations</h4>
          <p class="text-muted">
            Individual donations are appreciated, and are used for things like the project
            infrastructure, travel expenses for our volunteer contributors to attend
            the in-person sprints, or to give small grants to develop features.
          </p>
          <p>Make your donation in the <a href="https://opencollective.com/pandas">donate page</a></p>
        </div>
      </div>
    </div>
</section>

----------------------------------------

TITLE: Fixed regression in Series.rank for read-only data
DESCRIPTION: Resolves an issue where Series.rank would fail when operating on read-only data.

LANGUAGE: python
CODE:
read_only_series.rank()

----------------------------------------

TITLE: Comparing Series with datetime.date in Pandas 0.23.1
DESCRIPTION: Demonstrates the behavior change in comparing a Series of datetimes with datetime.date objects across pandas versions 0.22.0, 0.23.0, and 0.23.1. In 0.23.1, a warning is issued when coercing datetime.date to datetime for comparison.

LANGUAGE: python
CODE:
# 0.22.0... Silently coerce the datetime.date
>>> import datetime
>>> pd.Series(pd.date_range('2017', periods=2)) == datetime.date(2017, 1, 1)
0     True
1    False
dtype: bool

# 0.23.0... Do not coerce the datetime.date
>>> pd.Series(pd.date_range('2017', periods=2)) == datetime.date(2017, 1, 1)
0    False
1    False
dtype: bool

# 0.23.1... Coerce the datetime.date with a warning
>>> pd.Series(pd.date_range('2017', periods=2)) == datetime.date(2017, 1, 1)
/bin/python:1: FutureWarning: Comparing Series of datetimes with 'datetime.date'.  Currently, the
'datetime.date' is coerced to a datetime. In the future pandas will
not coerce, and the values not compare equal to the 'datetime.date'.
To retain the current behavior, convert the 'datetime.date' to a
datetime with 'pd.Timestamp'.
  #!/bin/python3
0     True
1    False
dtype: bool

----------------------------------------

TITLE: Using Bodo for Parallel Data Processing
DESCRIPTION: Shows how to use Bodo to parallelize pandas workloads.

LANGUAGE: python
CODE:
import pandas as pd
import bodo

@bodo.jit
def process_data():
    df = pd.read_parquet("my_data.pq")
    df2 = pd.DataFrame({"A": df.apply(lambda r: 0 if r.A == 0 else (r.B // r.A), axis=1)})
    df2.to_parquet("out.pq")

process_data()

----------------------------------------

TITLE: String Case Transformation using Pandas Series.str Methods
DESCRIPTION: Creates a DataFrame with names and demonstrates three string case transformation methods: upper(), lower(), and title(). Shows how to apply these transformations to a string column in a DataFrame using the Series.str accessor.

LANGUAGE: python
CODE:
firstlast = pd.DataFrame({"string": ["John Smith", "Jane Cook"]})
firstlast["upper"] = firstlast["string"].str.upper()
firstlast["lower"] = firstlast["string"].str.lower()
firstlast["title"] = firstlast["string"].str.title()
firstlast

----------------------------------------

TITLE: Custom Converters in CSV Parsing with Python
DESCRIPTION: Demonstrates how custom converters are now respected when parsing CSV files, without coercion to float or bool.

LANGUAGE: python
CODE:
import io

data = ('A,B,C\n'
        '00001,001,5\n'
        '00002,002,6')
pd.read_csv(io.StringIO(data), converters={'A': lambda x: x.strip()})

----------------------------------------

TITLE: Fixed regression in DateOffset object mutability
DESCRIPTION: Restores the behavior where attempting to mutate a DateOffset object raises an AttributeError.

LANGUAGE: python
CODE:
offset = pd.DateOffset(days=1)
offset.days = 2  # Should raise AttributeError

----------------------------------------

TITLE: Series multiplication with timedelta-like scalar in pandas
DESCRIPTION: Fixed regression in Series multiplication when multiplying a numeric Series with >10000 elements with a timedelta-like scalar.

LANGUAGE: python
CODE:
# Example not provided in the original text

----------------------------------------

TITLE: Indexing with MultiIndex using list of labels in pandas
DESCRIPTION: Fixed performance regression when indexing a DataFrame or Series with a MultiIndex for the index using a list of labels.

LANGUAGE: python
CODE:
# Example not provided in the original text

----------------------------------------

TITLE: Grouping by Categorical with New Sum Behavior in pandas 0.22.0
DESCRIPTION: Demonstrates how grouping by a Categorical and summing now returns 0 instead of NaN for categories with no observations.

LANGUAGE: python
CODE:
grouper = pd.Categorical(["a", "a"], categories=["a", "b"])
pd.Series([1, 2]).groupby(grouper, observed=False).sum()
pd.Series([1, 2]).groupby(grouper, observed=False).sum(min_count=1)

----------------------------------------

TITLE: Setting Web Crawler Access Rules using Robots.txt
DESCRIPTION: Configuration that defines permissions for web crawlers, allowing access to most content while blocking the /preview/ directory.

LANGUAGE: robotstxt
CODE:
User-agent: *
Disallow: /preview/

----------------------------------------

TITLE: Sorting DataFrame with Original Variable Overwrite
DESCRIPTION: Shows how to sort a DataFrame by overwriting the original DataFrame variable.

LANGUAGE: python
CODE:
df = df.sort_values("col1")

----------------------------------------

TITLE: Demonstrating New Default Column Names in Pandas read_csv
DESCRIPTION: This snippet shows how the default column naming behavior has changed when using read_csv with header=None. The new names are more Pythonic and amenable to attribute access.

LANGUAGE: python
CODE:
import io

data = """
0,0,1
1,1,0
0,1,0
"""
df = pd.read_csv(io.StringIO(data), header=None)
df

----------------------------------------

TITLE: Indexing with Nullable Boolean Arrays in Pandas 1.0.2
DESCRIPTION: Demonstrates the new behavior of indexing with nullable Boolean arrays where NA values are treated as False, unlike previous versions where it would raise a ValueError.

LANGUAGE: python
CODE:
s = pd.Series([1, 2, 3, 4])
mask = pd.array([True, True, False, None], dtype="boolean")
s
mask

LANGUAGE: python
CODE:
>>> s[mask]
Traceback (most recent call last):
...
ValueError: cannot mask with array containing NA / NaN values

LANGUAGE: python
CODE:
s[mask]

----------------------------------------

TITLE: Categorical construction with numpy.str_ categories in pandas
DESCRIPTION: Fixed regression in Categorical construction with numpy.str_ categories.

LANGUAGE: python
CODE:
# Example not provided in the original text

----------------------------------------

TITLE: Indexing DatetimeIndex with datetime.date in pandas
DESCRIPTION: Fixed regression when indexing a Series or DataFrame indexed by DatetimeIndex with a slice containing a datetime.date object.

LANGUAGE: python
CODE:
# Example not provided in the original text

----------------------------------------

TITLE: Demonstrating New Product Behavior in pandas 0.22.0
DESCRIPTION: Illustrates how the product of empty or all-NA Series now returns 1 instead of NaN, and shows the use of min_count parameter.

LANGUAGE: python
CODE:
pd.Series([]).prod()
pd.Series([np.nan]).prod()
pd.Series([]).prod(min_count=1)

----------------------------------------

TITLE: Creating Sample DataFrames for Merge Operations in Python
DESCRIPTION: Creates two Pandas DataFrames with 'key' and 'value' columns. The first DataFrame contains keys A-D, while the second contains keys B,D,E with some duplicates. Random values are generated using numpy's randn function.

LANGUAGE: python
CODE:
df1 = pd.DataFrame({"key": ["A", "B", "C", "D"], "value": np.random.randn(4)})
df1
df2 = pd.DataFrame({"key": ["B", "D", "D", "E"], "value": np.random.randn(4)})
df2

----------------------------------------

TITLE: Label-based Slicing with Series in Python
DESCRIPTION: Demonstrates label-based slicing using .ix[] on an unsorted Series, showing that it works when both start and end labels are in the index, but raises an error otherwise.

LANGUAGE: python
CODE:
s = pd.Series(np.random.randn(6), index=list('gmkaec'))
s.ix['k':'e']  # Works
s.ix['b':'h']  # Raises KeyError 'b'

----------------------------------------

TITLE: Calling DataFrameGroupBy.agg with ohlc function in Python
DESCRIPTION: Fix for a ValueError when using the ohlc function in a list of functions passed to DataFrameGroupBy.agg, where ohlc is not the first function in the list.

LANGUAGE: python
CODE:
DataFrameGroupBy.agg([func1, 'ohlc', func2])

----------------------------------------

TITLE: Fixing DataFrameGroupBy.quantile Bug in pandas
DESCRIPTION: This snippet addresses a bug in the DataFrameGroupBy.quantile method where NA values in the grouping could cause segfaults or incorrect results. The fix is part of the pandas 0.25.3 release.

LANGUAGE: python
CODE:
DataFrameGroupBy.quantile

----------------------------------------

TITLE: Accessing Timestamp.timestamp method in Python 2.7
DESCRIPTION: This code snippet demonstrates the availability of the Timestamp.timestamp method in Python 2.7, which was added in pandas 0.21.1.

LANGUAGE: python
CODE:
Timestamp.timestamp

----------------------------------------

TITLE: Demonstrating New Sum Behavior in pandas 0.22.0
DESCRIPTION: Shows how the sum of empty or all-NA Series now returns 0 instead of NaN, and introduces the min_count parameter to control this behavior.

LANGUAGE: python
CODE:
pd.Series([]).sum()
pd.Series([np.nan]).sum()
pd.Series([]).sum(min_count=1)

----------------------------------------

TITLE: Dropping Columns in Pandas DataFrame
DESCRIPTION: Shows how to remove a column from a Pandas DataFrame using the drop() method. The axis=1 parameter specifies that we're dropping a column rather than a row.

LANGUAGE: python
CODE:
tips.drop("sex", axis=1)

----------------------------------------

TITLE: Setting Pandas-Bokeh as Plotting Backend
DESCRIPTION: Demonstrates how to set Pandas-Bokeh as the default plotting backend for pandas.

LANGUAGE: python
CODE:
pd.set_option("plotting.backend", "pandas_bokeh")

----------------------------------------

TITLE: NumPy Compatibility Example Post-0.23.2
DESCRIPTION: Demonstrates the corrected behavior in pandas 0.23.2 where NumPy reduction operations properly return a scalar boolean value.

LANGUAGE: python
CODE:
np.any(pd.DataFrame({"A": [False], "B": [False]}))

----------------------------------------

TITLE: Correcting DataFrameGroupBy Quantile with List of Quantiles in Python
DESCRIPTION: This fix resolves an issue where passing a list of quantiles to DataFrameGroupBy.quantile() would incorrectly raise an IndexError.

LANGUAGE: Python
CODE:
DataFrameGroupBy.quantile([...])

----------------------------------------

TITLE: Semi-Month Date Offset Example
DESCRIPTION: Example of the new SemiMonthEnd and SemiMonthBegin date offset functionality

LANGUAGE: python
CODE:
pd.date_range('2015-01-01', freq='SMS', periods=4)

----------------------------------------

TITLE: Renaming pandas.tseries.register function
DESCRIPTION: This code snippet shows the renaming of the pandas.tseries.register function to pandas.plotting.register_matplotlib_converters in pandas 0.21.1.

LANGUAGE: python
CODE:
pandas.plotting.register_matplotlib_converters

----------------------------------------

TITLE: Importing Pandas and NumPy Libraries in Python
DESCRIPTION: This code snippet shows the standard way to import pandas and NumPy libraries in Python. It uses the conventional aliases 'pd' for pandas and 'np' for NumPy, which are widely used in the data science community.

LANGUAGE: Python
CODE:
import pandas as pd
import numpy as np

----------------------------------------

TITLE: Using Lux for Automated Data Visualization
DESCRIPTION: Shows how to import and use Lux alongside pandas for automated data visualization.

LANGUAGE: python
CODE:
import lux
import pandas as pd

df = pd.read_csv("data.csv")
df  # discover interesting insights!

----------------------------------------

TITLE: Basic IPython Setup and DataFrame Creation
DESCRIPTION: Importing pandas and creating a sample DataFrame with numeric data.

LANGUAGE: python
CODE:
from pandas import * # noqa F401, F403

----------------------------------------

TITLE: Series Array Property Access Example
DESCRIPTION: Example showing how to use the new Series.array property to access the underlying array

LANGUAGE: python
CODE:
idx = pd.period_range('2000', periods=4)
idx.array
pd.Series(idx).array

----------------------------------------

TITLE: Illustrating Series Creation Behavior Change in Pandas
DESCRIPTION: This code demonstrates how creating a Series from another Series while passing an index now causes reindexing to occur, rather than treating the Series like an ndarray.

LANGUAGE: python
CODE:
s1 = pd.Series([1, 2, 3])
s1

s2 = pd.Series(s1, index=["foo", "bar", "baz"])
s2

----------------------------------------

TITLE: Suppressing pandas import side effects in IPython
DESCRIPTION: This code snippet suppresses the side effects of importing pandas in an IPython environment. It is used to avoid polluting the namespace when generating documentation.

LANGUAGE: python
CODE:
from pandas import *  # noqa F401, F403

----------------------------------------

TITLE: Loading Air Quality PM2.5 Data with Pandas
DESCRIPTION: Loads PM2.5 air quality data from CSV file and selects specific columns. Uses parse_dates parameter to handle datetime values.

LANGUAGE: python
CODE:
air_quality_pm25 = pd.read_csv("data/air_quality_pm25_long.csv",
                                   parse_dates=True)
air_quality_pm25 = air_quality_pm25[["date.utc", "location",
                                         "parameter", "value"]]
air_quality_pm25.head()

----------------------------------------

TITLE: Rendering Active Maintainers Cards in HTML
DESCRIPTION: This snippet generates HTML cards for active maintainers of the Pandas project. It uses a loop to create a card for each maintainer, displaying their avatar, name, and GitHub username.

LANGUAGE: html
CODE:
<div class="card-group maintainers">
    {% for username in maintainers.active %}
        {% set person = maintainers.github_info.get(username) %}
        <div class="card">
            <img class="card-img-top" alt="" src="{{ person.avatar_url }}"/>
            <div class="card-body">
                <h6 class="card-title">
                    {% if person.blog %}
                        <a href="{{ person.blog }}">
                            {{ person.name or person.login }}
                        </a>
                    {% else %}
                        {{ person.name or person.login }}
                    {% endif %}
                </h6>
                <p class="card-text small"><a href="{{ person.html_url }}">{{ person.login }}</a></p>
            </div>
        </div>
    {% endfor %}
</div>

----------------------------------------

TITLE: DataFrame Drop Method Example
DESCRIPTION: Example demonstrating DataFrame drop functionality with axis specification.

LANGUAGE: python
CODE:
df = pd.DataFrame(np.arange(8).reshape(2, 4),
                      columns=['A', 'B', 'C', 'D'])
df
df.drop(['B', 'C'], axis=1)
# the following is now equivalent
df.drop(columns=['B', 'C'])

----------------------------------------

TITLE: Importing Pandas Modules
DESCRIPTION: Suppressed import of all pandas modules for documentation generation purposes.

LANGUAGE: python
CODE:
from pandas import *  # noqa F401, F403

----------------------------------------

TITLE: Correcting RangeIndex Get_Indexer for Decreasing Indices in Python
DESCRIPTION: This fix resolves a regression in RangeIndex.get_indexer() for decreasing RangeIndex where target values may have been improperly identified as missing or present.

LANGUAGE: Python
CODE:
RangeIndex.get_indexer(...)

----------------------------------------

TITLE: Importing Pandas - Release Notes Suppression
DESCRIPTION: IPython directive to import pandas and suppress output in release notes documentation

LANGUAGE: python
CODE:
from pandas import *  # noqa F401, F403

----------------------------------------

TITLE: Creating a Ratio Column in Pandas DataFrame
DESCRIPTION: Calculates the ratio of values between 'station_paris' and 'station_antwerp' columns, storing the result in a new 'ratio_paris_antwerp' column.

LANGUAGE: python
CODE:
air_quality["ratio_paris_antwerp"] = (
    air_quality["station_paris"] / air_quality["station_antwerp"]
)
air_quality.head()

----------------------------------------

TITLE: Installing Cython Dependency
DESCRIPTION: Command to install Cython requirement for building Pandas from source

LANGUAGE: shell
CODE:
pip install cython

----------------------------------------

TITLE: DataFrame infer_objects Type Conversion Example
DESCRIPTION: Example showing how the new infer_objects method converts Python objects to native types.

LANGUAGE: python
CODE:
df = pd.DataFrame({'A': [1, 2, 3],
                      'B': np.array([1, 2, 3], dtype='object'),
                      'C': ['1', '2', '3']})
df.dtypes
df.infer_objects().dtypes

----------------------------------------

TITLE: Pickle Compression Support
DESCRIPTION: Example showing new support for reading/writing compressed pickle files using compression parameter or inferred from file extension.

LANGUAGE: python
CODE:
df = pd.DataFrame({'A': np.random.randn(1000),
                      'B': 'foo',
                      'C': pd.date_range('20130101', periods=1000, freq='s')})

# Using explicit compression
df.to_pickle("data.pkl.compress", compression="gzip")
rt = pd.read_pickle("data.pkl.compress", compression="gzip")

# Infer compression from extension 
df.to_pickle("data.pkl.gz")
rt = pd.read_pickle("data.pkl.gz")

----------------------------------------

TITLE: Bug Fixes in Pandas 2.0.2
DESCRIPTION: Collection of bug fixes addressing issues with ArrowExtensionArray, interchange API, merge operations, date/time handling, and various DataFrame operations with PyArrow integration.

LANGUAGE: python
CODE:
arrays.ArrowExtensionArray # Fixed dict vs list type handling
api.interchange.from_dataframe() # Fixed categorical and slice handling
merge() # Fixed datetime resolution handling
read_csv() # Fixed pyarrow engine date parsing
to_datetime() # Fixed AM/PM format inference
to_timedelta() # Fixed pandas.NA handling
DataFrame.convert_dtypes() # Fixed pyarrow backend behavior
DataFrame.sort_values() # Fixed PyArrow dictionary support
Series.describe() # Fixed timestamp handling
Series.rename() # Fixed Copy-on-Write behavior
pd.array() # Fixed large string/binary support

----------------------------------------

TITLE: Suppressing Output in IPython for Pandas Import
DESCRIPTION: This code snippet suppresses output when importing all contents from the pandas library in an IPython environment. It's used for documentation purposes to avoid cluttering the output.

LANGUAGE: python
CODE:
from pandas import *  # noqa F401, F403

----------------------------------------

TITLE: Renaming Columns in Pandas DataFrame
DESCRIPTION: Uses the rename method to change column names, mapping old names to new station identifiers from OpenAQ.

LANGUAGE: python
CODE:
air_quality_renamed = air_quality.rename(
    columns={
        "station_antwerp": "BETR801",
        "station_paris": "FR04014",
        "station_london": "London Westminster",
    }
)

air_quality_renamed.head()

----------------------------------------

TITLE: Installing Pandas in Development Mode
DESCRIPTION: Command to install Pandas in editable development mode with verbose output

LANGUAGE: shell
CODE:
python -m pip install -ve . --no-build-isolation -Ceditable-verbose=true

----------------------------------------

TITLE: Rolling window operations on grouped data
DESCRIPTION: Demonstrates the new syntax for performing rolling window operations on grouped data

LANGUAGE: python
CODE:
df = pd.DataFrame({"A": [1] * 20 + [2] * 12 + [3] * 8, "B": np.arange(40)})

df.groupby("A").rolling(4).B.mean()

----------------------------------------

TITLE: Method chaining with callable arguments
DESCRIPTION: Demonstrates using callable arguments in various pandas methods to enable method chaining

LANGUAGE: python
CODE:
df = pd.DataFrame({"A": [1, 2, 3], "B": [4, 5, 6], "C": [7, 8, 9]})
df.where(lambda x: x > 4, lambda x: x + 10)

df.loc[lambda x: x.A >= 2, lambda x: x.sum() > 10]

df[lambda x: "A"]

----------------------------------------

TITLE: Building Pandas with setup.py (Deprecated)
DESCRIPTION: Command to build Pandas using the deprecated setup.py method.

LANGUAGE: bash
CODE:
python setup.py develop

----------------------------------------

TITLE: Ranking DataFrame with NA Handling Options in Python
DESCRIPTION: Shows how to use the new na_option parameter in DataFrame.rank() to assign either the largest or smallest rank to missing values.

LANGUAGE: python
CODE:
df = pd.DataFrame(np.random.randn(6, 3), columns=['A', 'B', 'C'])

df.loc[2:4] = np.nan

df.rank()

df.rank(na_option='top')

df.rank(na_option='bottom')

----------------------------------------

TITLE: HTML Collapsible Data Section
DESCRIPTION: HTML markup for creating a collapsible data section that contains information about NO2 air quality measurements from OpenAQ. Uses Bootstrap classes for styling and collapse functionality.

LANGUAGE: html
CODE:
<div data-bs-toggle="collapse" href="#collapsedata" role="button" aria-expanded="false" aria-controls="collapsedata">
    <span class="badge bg-secondary">Air quality data</span>
</div>
<div class="collapse" id="collapsedata">
    <div class="card-body">
        <div class="card-text">
            <a href="https://github.com/pandas-dev/pandas/tree/main/doc/data/air_quality_no2.csv" class="btn btn-dark btn-sm">To raw data</a>
        </div>
    </div>
</div>

----------------------------------------

TITLE: Evaluating Expressions in R and pandas
DESCRIPTION: Demonstrates expression evaluation in R using with() and the equivalent operation in pandas using eval().

LANGUAGE: r
CODE:
df <- data.frame(a=rnorm(10), b=rnorm(10))
with(df, a + b)
df$a + df$b  # same as the previous expression

LANGUAGE: python
CODE:
df = pd.DataFrame({"a": np.random.randn(10), "b": np.random.randn(10)})
df.eval("a + b")
df["a"] + df["b"]  # same as the previous expression

----------------------------------------

TITLE: String Method Enhancements
DESCRIPTION: New string operation methods available through the .str accessor for both Series and Index objects.

LANGUAGE: python
CODE:
idx = pd.Index([" jack", "jill ", " jesse ", "frank"])
idx.str.strip()

# String splitting with expand parameter
s = pd.Series(["a,b", "a,c", "b,c"])
s.str.split(",", expand=True)

----------------------------------------

TITLE: New DataFrame.sort_values method
DESCRIPTION: Example of using the new sort_values method to sort a DataFrame by column values.

LANGUAGE: python
CODE:
df = pd.DataFrame(
    np.random.random([3, 3]),
    columns=['A', 'B', 'C'], 
    index=['first', 'second', 'third']
)
df
df.round(2)
df.round({'A': 0, 'C': 2})

----------------------------------------

TITLE: Setting Up Virtual Environment for Pandas Development on Windows
DESCRIPTION: PowerShell commands to create a virtual environment, activate it, and install development dependencies for Pandas on Windows.

LANGUAGE: powershell
CODE:
python -m venv $env:USERPROFILE\virtualenvs\pandas-dev
~\virtualenvs\pandas-dev\Scripts\Activate.ps1
python -m pip install -r requirements-dev.txt

----------------------------------------

TITLE: Accessing Vectorized String Processing Methods in Pandas
DESCRIPTION: Demonstrates how to access the new vectorized string processing methods in Pandas 0.8.1 using the Series.str attribute. These methods provide NA-friendly string processing functionality.

LANGUAGE: python
CODE:
Series.str

----------------------------------------

TITLE: Installing Development Version of Pandas
DESCRIPTION: Commands to install the latest development version of pandas from the scientific-python-nightly-wheels index

LANGUAGE: shell
CODE:
pip install --pre --extra-index https://pypi.anaconda.org/scientific-python-nightly-wheels/simple pandas

LANGUAGE: shell
CODE:
pip uninstall pandas -y

----------------------------------------

TITLE: Casting Data in R and pandas
DESCRIPTION: Demonstrates data casting in R using acast() and dcast(), and the equivalent operations in pandas using pivot_table() and groupby().

LANGUAGE: r
CODE:
df <- data.frame(
  x = runif(12, 1, 168),
  y = runif(12, 7, 334),
  z = runif(12, 1.7, 20.7),
  month = rep(c(5,6,7),4),
  week = rep(c(1,2), 6)
)

mdf <- melt(df, id=c("month", "week"))
acast(mdf, week ~ month ~ variable, mean)

df <- data.frame(
  Animal = c('Animal1', 'Animal2', 'Animal3', 'Animal2', 'Animal1',
             'Animal2', 'Animal3'),
  FeedType = c('A', 'B', 'A', 'A', 'B', 'B', 'A'),
  Amount = c(10, 7, 4, 2, 5, 6, 2)
)

dcast(df, Animal ~ FeedType, sum, fill=NaN)
# Alternative method using base R
with(df, tapply(Amount, list(Animal, FeedType), sum))

LANGUAGE: python
CODE:
df = pd.DataFrame(
    {
        "x": np.random.uniform(1.0, 168.0, 12),
        "y": np.random.uniform(7.0, 334.0, 12),
        "z": np.random.uniform(1.7, 20.7, 12),
        "month": [5, 6, 7] * 4,
        "week": [1, 2] * 6,
    }
)

mdf = pd.melt(df, id_vars=["month", "week"])
pd.pivot_table(
    mdf,
    values="value",
    index=["variable", "week"],
    columns=["month"],
    aggfunc="mean",
)

df = pd.DataFrame(
    {
        "Animal": [
            "Animal1",
            "Animal2",
            "Animal3",
            "Animal2",
            "Animal1",
            "Animal2",
            "Animal3",
        ],
        "FeedType": ["A", "B", "A", "A", "B", "B", "A"],
        "Amount": [10, 7, 4, 2, 5, 6, 2],
    }
)

df.pivot_table(values="Amount", index="Animal", columns="FeedType", aggfunc="sum")

df.groupby(["Animal", "FeedType"])["Amount"].sum()

----------------------------------------

TITLE: Demonstrating Label-Based Slicing in Python with Pandas
DESCRIPTION: Shows how negative step support for label-based slices has been fixed to include all relevant labels.

LANGUAGE: python
CODE:
s = pd.Series(np.arange(3), ['a', 'b', 'c'])
s.loc['c':'a':-1]

----------------------------------------

TITLE: Demonstrating nested function calls in pandas
DESCRIPTION: Example of confusing nested function calls on a DataFrame that the new pipe method aims to simplify.

LANGUAGE: python
CODE:
# df is a DataFrame
# f, g, and h are functions that take and return DataFrames
f(g(h(df), arg1=1), arg2=2, arg3=3)  # noqa F821

----------------------------------------

TITLE: Running Pandas Debug Docker Container
DESCRIPTION: Docker command to run the pandas debug container with the current directory mounted as a volume.

LANGUAGE: sh
CODE:
docker run --rm -it -w /data -v ${PWD}:/data pandas/pandas-debug

----------------------------------------

TITLE: Handling NA Values in Boolean Comparisons
DESCRIPTION: Illustrates the behavior of NA/NaN values in boolean comparisons with Series objects, showing how NA values are treated as False in most comparisons except for inequality.

LANGUAGE: python
CODE:
In [1]: series = pd.Series(["Steve", np.nan, "Joe"])

In [2]: series == "Steve"
Out[2]:
0     True
1    False
2    False
Length: 3, dtype: bool

In [3]: series != "Steve"
Out[3]:
0    False
1     True
2     True
Length: 3, dtype: bool

----------------------------------------

TITLE: Creating a Pandas DataFrame with Numeric Data
DESCRIPTION: This code snippet represents the structure of a pandas DataFrame with three columns labeled A, B, and C, containing two rows of numeric data. It demonstrates the tabular format used in pandas for data manipulation and analysis.

LANGUAGE: python
CODE:
A   B   C
1   2   3
4   5   6

----------------------------------------

TITLE: Exporting Data to CSV in SAS using PROC EXPORT
DESCRIPTION: This SAS code snippet shows how to export a SAS data set to a CSV file using the PROC EXPORT procedure.

LANGUAGE: sas
CODE:
proc export data=tips outfile='tips2.csv' dbms=csv;
run;

----------------------------------------

TITLE: Integer vs True Division
DESCRIPTION: Demonstrates the change to true division for NDFrame objects, showing examples of integer division using // operator and float division using / operator.

LANGUAGE: python
CODE:
In [3]: arr = np.array([1, 2, 3, 4])

In [4]: arr2 = np.array([5, 3, 2, 1])

In [5]: arr / arr2
Out[5]: array([0, 0, 1, 4])

In [6]: pd.Series(arr) // pd.Series(arr2)
Out[6]:
0    0
1    0
2    1
3    4
dtype: int64

In [7]: pd.Series(arr) / pd.Series(arr2)  # no future import required
Out[7]:
0    0.200000
1    0.666667
2    1.500000
3    4.000000
dtype: float64

----------------------------------------

TITLE: Using Sample Method
DESCRIPTION: Examples of using the new sample() method to randomly sample data from Series and DataFrames with various options.

LANGUAGE: python
CODE:
example_series = pd.Series([0, 1, 2, 3, 4, 5])

# Basic sampling
example_series.sample()

# Sample specific number of rows
example_series.sample(n=3)

# Sample by fraction
example_series.sample(frac=0.5)

# Weighted sampling
example_weights = [0, 0, 0.2, 0.2, 0.2, 0.4]
example_series.sample(n=3, weights=example_weights)

----------------------------------------

TITLE: Validating pandas Docstrings
DESCRIPTION: Shows how to use a utility script to validate and test the docstring of a specific pandas method.

LANGUAGE: python
CODE:
python scripts/validate_docstrings.py pandas.DataFrame.mean

----------------------------------------

TITLE: Series Indexing with Lists and Slices in Python
DESCRIPTION: Shows how Series indexing with lists and slices behaves similarly to .ix[] indexing, except for integer indexes where it shadows ndarray behavior.

LANGUAGE: python
CODE:
s = pd.Series(np.random.randn(6), index=list('acegkm'))
s[['m', 'a', 'c', 'e']]
s['b':'l']
s['c':'k']

s = pd.Series(np.random.randn(6), index=range(0, 12, 2))
s[[4, 0, 2]]
s[1:5]

----------------------------------------

TITLE: Generating Class Documentation Structure with Jinja2 for Pandas
DESCRIPTION: This Jinja2 template creates a structured documentation page for a Pandas class. It includes sections for the class name, attributes, and methods, with conditional rendering and filtering of items.

LANGUAGE: jinja2
CODE:
{{ fullname | escape | underline}}

.. currentmodule:: {{ module }}

.. autoclass:: {{ objname }}

   {% block methods %}

   {% block attributes %}
   {% if attributes %}
   .. rubric:: {{ _('Attributes') }}

   .. autosummary::
   {% for item in attributes %}
      {% if item in members and not item.startswith('_') %}
        ~{{ name }}.{{ item }}
      {% endif %}
   {%- endfor %}
   {% endif %}
   {% endblock %}

   {% if methods %}
   .. rubric:: {{ _('Methods') }}

   .. autosummary::
   {% for item in methods %}
      {% if item in members and (not item.startswith('_') or item in ['__call__']) %}
        ~{{ name }}.{{ item }}
      {% endif %}
   {%- endfor %}
   {% endif %}
   {% endblock %}

----------------------------------------

TITLE: Merging Data in SAS
DESCRIPTION: This SAS code snippet shows how to perform different types of joins (left, inner, right, outer) on two sorted datasets using the DATA step and IN= variables.

LANGUAGE: sas
CODE:
proc sort data=df1;
    by key;
run;

proc sort data=df2;
    by key;
run;

data left_join inner_join right_join outer_join;
    merge df1(in=a) df2(in=b);

    if a and b then output inner_join;
    if a then output left_join;
    if b then output right_join;
    if a or b then output outer_join;
run;

----------------------------------------

TITLE: Using CustomBusinessDay for Custom Calendars
DESCRIPTION: Example showing how to use the new CustomBusinessDay class to create custom business day offsets with holiday calendars.

LANGUAGE: Python
CODE:
from pandas.tseries.offsets import CustomBusinessDay
from datetime import datetime

weekmask_egypt = "Sun Mon Tue Wed Thu"
holidays = ["2012-05-01", datetime(2013, 5, 1), np.datetime64("2014-05-01")]
bday_egypt = CustomBusinessDay(holidays=holidays, weekmask=weekmask_egypt)
dt = datetime(2013, 4, 30)
print(dt + 2 * bday_egypt)
dts = pd.date_range(dt, periods=5, freq=bday_egypt)
print(pd.Series(dts.weekday, dts).map(pd.Series("Mon Tue Wed Thu Fri Sat Sun".split())))

----------------------------------------

TITLE: Converting SparseSeries to COO Matrix
DESCRIPTION: Example showing conversion between SparseSeries and scipy.sparse.coo_matrix formats

LANGUAGE: python
CODE:
s = pd.Series([3.0, np.nan, 1.0, 3.0, np.nan, np.nan])
s.index = pd.MultiIndex.from_tuples([(1, 2, 'a', 0),
                                     (1, 2, 'a', 1), 
                                     (1, 1, 'b', 0),
                                     (1, 1, 'b', 1),
                                     (2, 1, 'b', 0),
                                     (2, 1, 'b', 1)],
                                    names=['A', 'B', 'C', 'D'])

ss = s.to_sparse()
A, rows, columns = ss.to_coo(row_levels=['A', 'B'],
                             column_levels=['C', 'D'],
                             sort_labels=False)

----------------------------------------

TITLE: Building pandas Documentation
DESCRIPTION: Provides commands for building the full pandas documentation or specific sections using the make.py script.

LANGUAGE: python
CODE:
python make.py html

LANGUAGE: python
CODE:
python make.py clean
python make.py html

LANGUAGE: python
CODE:
python make.py clean
python make.py --no-api

LANGUAGE: python
CODE:
python make.py clean
python make.py --single development/contributing.rst

LANGUAGE: python
CODE:
python make.py clean
python make.py --single pandas.DataFrame.join

LANGUAGE: python
CODE:
python make.py clean
python make.py --whatsnew

LANGUAGE: python
CODE:
python make.py html --num-jobs 4

----------------------------------------

TITLE: Integer Indexing with Series in Python
DESCRIPTION: Shows how integer indexing behavior has changed in pandas 0.7.0, raising a KeyError when attempting to access a non-existent index instead of falling back to location-based lookup.

LANGUAGE: python
CODE:
s = pd.Series(np.random.randn(10), index=range(0, 20, 2))
s[0]  # Returns -1.2945235902555294
s[2]  # Returns 0.41373810535784006
s[4]  # Returns 0.2766617129497566
s[1]  # Raises KeyError: 1

----------------------------------------

TITLE: Using read_html to Parse HTML into DataFrame
DESCRIPTION: Example demonstrating how to use pd.read_html() to parse HTML content and convert it into a DataFrame.

LANGUAGE: Python
CODE:
import io
df = pd.DataFrame({"a": range(3), "b": list("abc")})
print(df)
html = df.to_html()
alist = pd.read_html(io.StringIO(html), index_col=0)
print(df == alist[0])

----------------------------------------

TITLE: Reading CSV Data with pandas
DESCRIPTION: Demonstrates how to read a CSV file using pandas' read_csv function, which is equivalent to SPSS's File > Open > Data operation.

LANGUAGE: python
CODE:
url = (
    "https://raw.githubusercontent.com/pandas-dev"
    "/pandas/main/pandas/tests/io/data/csv/tips.csv"
)
tips = pd.read_csv(url)
tips

----------------------------------------

TITLE: HDFStore Multi-table Operations in Python
DESCRIPTION: Shows how to create and select from multiple tables using append_to_multiple and select_as_multiple functions, with the ability to combine results based on a selector table.

LANGUAGE: python
CODE:
df_mt = pd.DataFrame(
    np.random.randn(8, 6),
    index=pd.date_range("1/1/2000", periods=8),
    columns=["A", "B", "C", "D", "E", "F"],
)
df_mt["foo"] = "bar"

# you can also create the tables individually
store.append_to_multiple(
    {"df1_mt": ["A", "B"], "df2_mt": None}, df_mt, selector="df1_mt"
)

# as a multiple
store.select_as_multiple(
    ["df1_mt", "df2_mt"], where=["A>0", "B>0"], selector="df1_mt"
)

----------------------------------------

TITLE: String Method Enhancements
DESCRIPTION: Shows new string accessor methods added for Series objects

LANGUAGE: python
CODE:
s = pd.Series(['abcd', '3456', 'EFGH'])
s.str.isalpha()
s.str.find('ab')

----------------------------------------

TITLE: Exiting Git Bisect and Rebuilding Current Pandas Version
DESCRIPTION: These commands exit the git bisect process and rebuild the current version of pandas after investigating a regression.

LANGUAGE: bash
CODE:
git bisect reset
python -m pip install -ve . --no-build-isolation -Ceditable-verbose=true

----------------------------------------

TITLE: Using NTV-pandas for JSON Conversion
DESCRIPTION: Demonstrates how to use NTV-pandas for JSON conversion with extended data type support.

LANGUAGE: python
CODE:
import ntv_pandas as npd

jsn = df.npd.to_json(table=False)  # save df as a JSON-value (format Table Schema if table is True else format NTV )
df  = npd.read_json(jsn)  # load a JSON-value as a `DataFrame`

df.equals(npd.read_json(df.npd.to_json(df)))  # `True` in any case, whether `table=True` or not

----------------------------------------

TITLE: DataFrame Grouping and Pivoting Example
DESCRIPTION: Example showing pivot_table functionality with Grouper for frequency-based operations on dates

LANGUAGE: python
CODE:
df.pivot_table(values='Quantity',
              index=pd.Grouper(freq='M', key='Date'),
              columns=pd.Grouper(freq='M', key='PayDay'),
              aggfunc="sum")

----------------------------------------

TITLE: Reading Tab-Delimited Data without Headers in pandas
DESCRIPTION: Shows how to read a tab-delimited file without column names using pandas, equivalent to specifying delimiters and variable names in SPSS.

LANGUAGE: python
CODE:
tips = pd.read_csv("tips.csv", sep="\t", header=None)

# alternatively, read_table is an alias to read_csv with tab delimiter
tips = pd.read_table("tips.csv", header=None)

----------------------------------------

TITLE: Demonstrating new column naming in pandas read_csv
DESCRIPTION: Shows how the default column names for files with no header have changed to integers 0 through N-1. Demonstrates how to reproduce the old behavior of X0, X1, etc. using the prefix option.

LANGUAGE: python
CODE:
import io

data = """
a,b,c
1,Yes,2
3,No,4
"""

print(data)

pd.read_csv(io.StringIO(data), header=None)

pd.read_csv(io.StringIO(data), header=None, prefix="X")

----------------------------------------

TITLE: Demonstrating Enhanced concat Functionality in Pandas 0.15.1
DESCRIPTION: Shows how concat now permits a wider variety of iterables of pandas objects to be passed as the first parameter.

LANGUAGE: python
CODE:
from collections import deque

df1 = pd.DataFrame([1, 2, 3])
df2 = pd.DataFrame([4, 5, 6])

pd.concat(deque((df1, df2)))

----------------------------------------

TITLE: Triggering Backport with MeeseeksDev Bot
DESCRIPTION: This comment triggers the MeeseeksDev bot to backport a change to a specific version branch.

LANGUAGE: markdown
CODE:
@meeseeksdev backport version-branch

----------------------------------------

TITLE: Configuring SSH Tunnel for Airflow Dashboard Access in Bash
DESCRIPTION: This command sets up an SSH tunnel to view the Airflow dashboard for pandas benchmarks on the original server. It forwards local port 8080 to the remote server's localhost:8080.

LANGUAGE: bash
CODE:
ssh -L 8080:localhost:8080 pandas@panda.likescandy.com

----------------------------------------

TITLE: Using Dateutil Timezones in Pandas Date Range
DESCRIPTION: Demonstrates how to create a date range using dateutil timezones, which are now supported in the same way as pytz timezones.

LANGUAGE: Python
CODE:
rng = pd.date_range(
    "3/6/2012 00:00", periods=10, freq="D", tz="dateutil/Europe/London"
)
rng.tz

----------------------------------------

TITLE: Filtering Data in pandas
DESCRIPTION: Demonstrates how to filter data in pandas, similar to using an if clause in Stata.

LANGUAGE: python
CODE:
tips[tips["total_bill"] > 10]

----------------------------------------

TITLE: Appending Levels to Existing Index/MultiIndex in Pandas
DESCRIPTION: Shows how to use the set_index method in Series/DataFrame to append levels to an existing Index or MultiIndex in Pandas 0.8.1.

LANGUAGE: python
CODE:
Series.set_index()
DataFrame.set_index()

----------------------------------------

TITLE: Using the New .dt Accessor
DESCRIPTION: Example of using the new .dt accessor for datetime-like Series in pandas 0.15.0

LANGUAGE: Python
CODE:
s = pd.Series(pd.date_range('20130101 09:10:12', periods=4))
s.dt.hour
s.dt.second
s.dt.day

s[s.dt.day == 2]

stz = s.dt.tz_localize('US/Eastern')
stz.dt.tz

----------------------------------------

TITLE: Complete DataFrame Metadata Example
DESCRIPTION: Comprehensive example of pandas DataFrame metadata in Parquet format, showing various column types and their metadata specifications.

LANGUAGE: text
CODE:
{'index_columns': ['__index_level_0__'],
 'column_indexes': [
     {'name': None,
      'field_name': 'None',
      'pandas_type': 'unicode',
      'numpy_type': 'object',
      'metadata': {'encoding': 'UTF-8'}}
 ],
 'columns': [
     {'name': 'c0',
      'field_name': 'c0',
      'pandas_type': 'int8',
      'numpy_type': 'int8',
      'metadata': None},
     {'name': 'c1',
      'field_name': 'c1',
      'pandas_type': 'bytes',
      'numpy_type': 'object',
      'metadata': None},
     {'name': 'c2',
      'field_name': 'c2',
      'pandas_type': 'categorical',
      'numpy_type': 'int16',
      'metadata': {'num_categories': 1000, 'ordered': False}},
     {'name': 'c3',
      'field_name': 'c3',
      'pandas_type': 'datetimetz',
      'numpy_type': 'datetime64[ns]',
      'metadata': {'timezone': 'America/Los_Angeles'}},
     {'name': 'c4',
      'field_name': 'c4',
      'pandas_type': 'object',
      'numpy_type': 'object',
      'metadata': {'encoding': 'pickle'}},
     {'name': None,
      'field_name': '__index_level_0__',
      'pandas_type': 'int64',
      'numpy_type': 'int64',
      'metadata': None}
 ],
 'pandas_version': '1.4.0',
 'creator': {
   'library': 'pyarrow',
   'version': '0.13.0'
 }}

----------------------------------------

TITLE: Rendering Active Institutional Partners with Jinja2
DESCRIPTION: Template code for displaying active institutional partners that support pandas by employing contributors. Uses Jinja2 templating to iterate through sponsor data.

LANGUAGE: jinja2
CODE:
<ul>
    {% for company in sponsors.active if company.kind == "partner" %}
        <li><a href="{{ company.url }}">{{ company.name }}</a>: {{ company.description }}</li>
    {% endfor %}
</ul>

----------------------------------------

TITLE: Using the new pipe method in pandas
DESCRIPTION: Example of using the new pipe method to chain function calls on a DataFrame in a more readable way.

LANGUAGE: python
CODE:
(
    df.pipe(h)  # noqa F821
    .pipe(g, arg1=1)  # noqa F821
    .pipe(f, arg2=2, arg3=3)  # noqa F821
)

----------------------------------------

TITLE: Using inplace Parameter for DataFrame Modification
DESCRIPTION: Demonstrates the use of inplace=True parameter to modify a DataFrame directly. Note that this approach is under discussion for deprecation except for specific methods like replace.

LANGUAGE: python
CODE:
df.replace(5, inplace=True)

----------------------------------------

TITLE: Installing Pandas with PyArrow
DESCRIPTION: New pip installation command to install pandas with PyArrow dependency using the new pip extra feature.

LANGUAGE: bash
CODE:
pip install pandas[pyarrow]

----------------------------------------

TITLE: Demonstrating MonthEnd Offset Behavior in Pandas
DESCRIPTION: Shows the difference in behavior of MonthEnd offset between versions 0.14.0 and 0.14.1, where time preservation is now the default.

LANGUAGE: Python
CODE:
from pandas.tseries import offsets

d = pd.Timestamp('2014-01-01 09:00')

# new behaviour
d + offsets.MonthEnd()
d + offsets.MonthEnd(normalize=True)

----------------------------------------

TITLE: HTML Data Toggle Structure for Titanic Dataset Documentation
DESCRIPTION: HTML structure that creates a collapsible section containing the Titanic dataset documentation with a download button for the raw CSV data.

LANGUAGE: html
CODE:
.. raw:: html

    <div data-bs-toggle="collapse" href="#collapsedata" role="button" aria-expanded="false" aria-controls="collapsedata">
        <span class="badge bg-secondary">Titanic data</span>
    </div>
    <div class="collapse" id="collapsedata">
        <div class="card-body">
            <p class="card-text">

This tutorial uses the Titanic data set, stored as CSV. The data
consists of the following data columns:

-  PassengerId: Id of every passenger.
-  Survived: Indication whether passenger survived. ``0`` for yes and ``1`` for no.
-  Pclass: One out of the 3 ticket classes: Class ``1``, Class ``2`` and Class ``3``.
-  Name: Name of passenger.
-  Sex: Gender of passenger.
-  Age: Age of passenger in years.
-  SibSp: Number of siblings or spouses aboard.
-  Parch: Number of parents or children aboard.
-  Ticket: Ticket number of passenger.
-  Fare: Indicating the fare.
-  Cabin: Cabin number of passenger.
-  Embarked: Port of embarkation.

.. raw:: html

            </p>
            <a href="https://github.com/pandas-dev/pandas/raw/main/doc/data/titanic.csv" class="btn btn-dark btn-sm">To raw data</a>
        </div>
    </div>

----------------------------------------

TITLE: Citing pandas Paper in BibTeX Format
DESCRIPTION: BibTeX citation for the original pandas paper by Wes McKinney. This citation should be used when referencing the foundational work on pandas in scientific publications.

LANGUAGE: bibtex
CODE:
@InProceedings{ mckinney-proc-scipy-2010,
  author    = { {W}es {M}c{K}inney },
  title     = { {D}ata {S}tructures for {S}tatistical {C}omputing in {P}ython },
  booktitle = { {P}roceedings of the 9th {P}ython in {S}cience {C}onference },
  pages     = { 56 - 61 },
  year      = { 2010 },
  editor    = { {S}t\'efan van der {W}alt and {J}arrod {M}illman },
  doi       = { 10.25080/Majora-92bf1922-00a }
}

----------------------------------------

TITLE: Creating a DatetimeIndex with timezones
DESCRIPTION: Example of creating a DataFrame with DatetimeIndex columns including timezone information.

LANGUAGE: python
CODE:
df = pd.DataFrame({
    "A": pd.date_range("20130101", periods=3),
    "B": pd.date_range("20130101", periods=3, tz="US/Eastern"),
    "C": pd.date_range("20130101", periods=3, tz="CET")
})
df
df.dtypes

----------------------------------------

TITLE: Displaying First Rows of DataFrame using head() Method in Python
DESCRIPTION: This snippet demonstrates how to use the head() method to display the first few rows of a DataFrame named 'tips'. The method takes an integer parameter to specify the number of rows to show.

LANGUAGE: python
CODE:
tips.head(5)

----------------------------------------

TITLE: from_dummies Function Example
DESCRIPTION: Example showing how to convert dummy coded DataFrame into categorical DataFrame

LANGUAGE: python
CODE:
import pandas as pd
df = pd.DataFrame({"col1_a": [1, 0, 1], "col1_b": [0, 1, 0],
                   "col2_a": [0, 1, 0], "col2_b": [1, 0, 0],
                   "col2_c": [0, 0, 1]})
pd.from_dummies(df, sep="_")

----------------------------------------

TITLE: Handling Integer Dtype Upcasting in Pandas
DESCRIPTION: This code demonstrates how performing indexing operations on integer type data can result in upcasting. It shows that the dtype of input data is preserved when NaNs are not introduced, but upcasting occurs when NaNs are present.

LANGUAGE: Python
CODE:
dfi = df3.astype('int32')
dfi['D'] = dfi['D'].astype('int64')
dfi
dfi.dtypes
casted = dfi[dfi > 0]
casted
casted.dtypes

df4 = df3.copy()
df4['A'] = df4['A'].astype('float32')
df4.dtypes
casted = df4[df4 > 0]
casted
casted.dtypes

----------------------------------------

TITLE: Importing Pandas and Loading Data
DESCRIPTION: Basic setup code to import pandas and load the titanic and air quality datasets

LANGUAGE: python
CODE:
import pandas as pd

titanic = pd.read_csv("data/titanic.csv")
air_quality = pd.read_csv(
    "data/air_quality_long.csv", index_col="date.utc", parse_dates=True
)

----------------------------------------

TITLE: Implementing PyData Copyright Banner in Python Source Files
DESCRIPTION: Standard copyright and license banner that should be included at the top of any pandas source code file to indicate copyright and BSD license terms.

LANGUAGE: python
CODE:
#-----------------------------------------------------------------------------
# Copyright (c) 2012, PyData Development Team
# All rights reserved.
#
# Distributed under the terms of the BSD Simplified License.
#
# The full license is in the LICENSE file, distributed with this software.
#-----------------------------------------------------------------------------

----------------------------------------

TITLE: Creating PyArrow-backed string array using pandas options
DESCRIPTION: Demonstrates how to create a PyArrow-backed string array using pandas options

LANGUAGE: python
CODE:
with pd.option_context("string_storage", "pyarrow"):
    s = pd.Series(['abc', None, 'def'], dtype="string")
s

----------------------------------------

TITLE: Calculating String Lengths in Pandas Series
DESCRIPTION: Shows two approaches for calculating string lengths in a Pandas Series: using str.len() directly and combining with rstrip() to exclude trailing whitespace. Works with a 'tips' DataFrame containing a 'time' column.

LANGUAGE: python
CODE:
tips["time"].str.len()
tips["time"].str.rstrip().str.len()

----------------------------------------

TITLE: Constructing a DataFrame in pandas
DESCRIPTION: Demonstrates how to create a DataFrame from specified values, similar to Stata's input statement.

LANGUAGE: python
CODE:
df = pd.DataFrame({"x": [1, 3, 5], "y": [2, 4, 6]})
print(df)

----------------------------------------

TITLE: HDFStore Data Column Querying in Python
DESCRIPTION: Demonstrates how to create and query an HDFStore with designated data columns. Shows table operations including appending data and performing queries on specified columns.

LANGUAGE: python
CODE:
store = pd.HDFStore("store.h5")
df = pd.DataFrame(
    np.random.randn(8, 3),
    index=pd.date_range("1/1/2000", periods=8),
    columns=["A", "B", "C"],
)
df["string"] = "foo"
df.loc[df.index[4:6], "string"] = np.nan
df.loc[df.index[7:9], "string"] = "bar"
df["string2"] = "cool"

# on-disk operations
store.append("df", df, data_columns=["B", "C", "string", "string2"])
store.select("df", "B>0 and string=='foo'")

----------------------------------------

TITLE: Importing Pandas and Loading Data
DESCRIPTION: Basic setup code to import pandas and load the Titanic dataset

LANGUAGE: python
CODE:
import pandas as pd
titanic = pd.read_csv("data/titanic.csv")
titanic.head()

----------------------------------------

TITLE: Updating Symlinks for Stable Pandas Documentation
DESCRIPTION: These commands update the symlinks for the stable pandas documentation on the web server.

LANGUAGE: bash
CODE:
cd /var/www/html/pandas-docs/
ln -sfn version/2.1 stable
ln -sfn version/2.0.3 version/2.0

----------------------------------------

TITLE: Time-based Rolling Window in Python
DESCRIPTION: Illustrates a rolling window sum operation using a time-based window on a pandas Series with a DatetimeIndex.

LANGUAGE: python
CODE:
times = ['2020-01-01', '2020-01-03', '2020-01-04', '2020-01-05', '2020-01-29']
s = pd.Series(range(5), index=pd.DatetimeIndex(times))
s
# Window with 2 observations
s.rolling(window=2).sum()
# Window with 2 days worth of observations
s.rolling(window='2D').sum()

----------------------------------------

TITLE: Forward Fill Missing Values in Pandas
DESCRIPTION: Demonstrates forward filling missing values using the previous valid value with the ffill() method

LANGUAGE: python
CODE:
outer_join.ffill()

----------------------------------------

TITLE: Output Management in pandas
DESCRIPTION: Shows how to manage and export results in pandas, which is similar to SPSS's Output Management System (OMS).

LANGUAGE: python
CODE:
# Save summary statistics to CSV
tips.groupby('sex')[['total_bill', 'tip']].mean().to_csv('summary.csv')

# Save multiple results to Excel sheets
with pd.ExcelWriter('results.xlsx') as writer:
    tips.describe().to_excel(writer, sheet_name='Descriptives')
    tips.groupby('sex').mean().to_excel(writer, sheet_name='Means by Gender')

----------------------------------------

TITLE: Creating n-dimensional panels in pandas
DESCRIPTION: Demonstrates the experimental support for Panel4D and creating n-dimensional named panels using factory functions.

LANGUAGE: python
CODE:
p4d = Panel4D(np.random.randn(2, 2, 5, 4),
      labels=['Label1','Label2'],
      items=['Item1', 'Item2'],
      major_axis=date_range('1/1/2000', periods=5),
      minor_axis=['A', 'B', 'C', 'D'])

p4d

----------------------------------------

TITLE: Creating Subplots for Each Column in Pandas DataFrame
DESCRIPTION: Generate area plots for each column in separate subplots using the subplots parameter.

LANGUAGE: python
CODE:
axs = air_quality.plot.area(figsize=(12, 4), subplots=True)
plt.show()

----------------------------------------

TITLE: Uploading Pandas Release Wheels to PyPI
DESCRIPTION: This twine command uploads the pandas release wheels and source distribution to PyPI.

LANGUAGE: bash
CODE:
twine upload pandas/dist/pandas-<version>*.{whl,tar.gz} --skip-existing

----------------------------------------

TITLE: Centered Rolling Window in Python
DESCRIPTION: Shows how to center the labels in a rolling window operation.

LANGUAGE: python
CODE:
s = pd.Series(range(10))
s.rolling(window=5).mean()
s.rolling(window=5, center=True).mean()

----------------------------------------

TITLE: Splitting Names into First and Last Name Columns using Pandas
DESCRIPTION: This code creates a DataFrame with full names, then splits them into separate columns for first and last names. It uses the str.split() method for first names and str.rsplit() for last names, with the expand parameter set to True to create new columns.

LANGUAGE: python
CODE:
firstlast = pd.DataFrame({"String": ["John Smith", "Jane Cook"]})
firstlast["First_Name"] = firstlast["String"].str.split(" ", expand=True)[0]
firstlast["Last_Name"] = firstlast["String"].str.rsplit(" ", expand=True)[1]
firstlast

----------------------------------------

TITLE: Date Operations in SAS
DESCRIPTION: This SAS code snippet shows various date operations and functions available in SAS for working with date/datetime columns.

LANGUAGE: sas
CODE:
data tips;
    set tips;
    format date1 date2 date1_plusmonth mmddyy10.;
    date1 = mdy(1, 15, 2013);
    date2 = mdy(2, 15, 2015);
    date1_year = year(date1);
    date2_month = month(date2);
    * shift date to beginning of next interval;
    date1_next = intnx('MONTH', date1, 1);
    * count intervals between dates;
    months_between = intck('MONTH', date1, date2);
run;

----------------------------------------

TITLE: Parsing Excel Columns by Name in Python
DESCRIPTION: Shows how to reference Excel columns by their names when parsing an Excel file using pandas.

LANGUAGE: python
CODE:
xl = pd.ExcelFile('data/test.xls')

xl.parse('Sheet1', index_col=0, parse_dates=True,
               parse_cols='A:D')

----------------------------------------

TITLE: Importing Pandas and Loading Sample Data
DESCRIPTION: Imports the Pandas library and loads the Titanic dataset from a CSV file.

LANGUAGE: python
CODE:
import pandas as pd

titanic = pd.read_csv("data/titanic.csv")
titanic.head()

----------------------------------------

TITLE: Calendar Embed HTML
DESCRIPTION: HTML iframe element for embedding the pandas community meeting calendar

LANGUAGE: html
CODE:
<iframe src="https://calendar.google.com/calendar/embed?src=pgbn14p6poja8a1cf2dv2jhrmg%40group.calendar.google.com" style="border: 0" width="800" height="600" frameborder="0" scrolling="no"></iframe>

----------------------------------------

TITLE: Custom Rolling Window Indexer in Python
DESCRIPTION: Demonstrates how to create a custom BaseIndexer subclass for defining custom window bounds in rolling operations.

LANGUAGE: python
CODE:
from pandas.api.indexers import BaseIndexer

class CustomIndexer(BaseIndexer):
     def get_window_bounds(self, num_values, min_periods, center, closed, step):
         start = np.empty(num_values, dtype=np.int64)
         end = np.empty(num_values, dtype=np.int64)
         for i in range(num_values):
             if self.use_expanding[i]:
                 start[i] = 0
                 end[i] = i + 1
             else:
                 start[i] = i
                 end[i] = i + self.window_size
         return start, end

indexer = CustomIndexer(window_size=1, use_expanding=use_expanding)

df.rolling(indexer).sum()

----------------------------------------

TITLE: Pytest Test Structure Example
DESCRIPTION: Example showing preferred pytest test structure using fixtures and parameterization.

LANGUAGE: python
CODE:
import pytest
import numpy as np
import pandas as pd

@pytest.mark.parametrize('dtype', ['int8', 'int16', 'int32', 'int64'])
def test_dtypes(dtype):
    assert str(np.dtype(dtype)) == dtype

@pytest.mark.parametrize(
    'dtype', ['float32', pytest.param('int16', marks=pytest.mark.skip),
              pytest.param('int32', marks=pytest.mark.xfail(
                  reason='to show how it works'))])
def test_mark(dtype):
    assert str(np.dtype(dtype)) == 'float32'

@pytest.fixture
def series():
    return pd.Series([1, 2, 3])

@pytest.fixture(params=['int8', 'int16', 'int32', 'int64'])
def dtype(request):
    return request.param

def test_series(series, dtype):
    # GH <issue_number>
    result = series.astype(dtype)
    assert result.dtype == dtype

    expected = pd.Series([1, 2, 3], dtype=dtype)
    tm.assert_series_equal(result, expected)

----------------------------------------

TITLE: Melting Data in R and pandas
DESCRIPTION: Shows how to melt data in R using melt() and the equivalent operations in pandas.

LANGUAGE: r
CODE:
a <- array(c(1:23, NA), c(2,3,4))
data.frame(melt(a))

a <- as.list(c(1:4, NA))
data.frame(melt(a))

cheese <- data.frame(
  first = c('John', 'Mary'),
  last = c('Doe', 'Bo'),
  height = c(5.5, 6.0),
  weight = c(130, 150)
)
melt(cheese, id=c("first", "last"))

LANGUAGE: python
CODE:
a = np.array(list(range(1, 24)) + [np.NAN]).reshape(2, 3, 4)
pd.DataFrame([tuple(list(x) + [val]) for x, val in np.ndenumerate(a)])

a = list(enumerate(list(range(1, 5)) + [np.NAN]))
pd.DataFrame(a)

cheese = pd.DataFrame(
    {
        "first": ["John", "Mary"],
        "last": ["Doe", "Bo"],
        "height": [5.5, 6.0],
        "weight": [130, 150],
    }
)

pd.melt(cheese, id_vars=["first", "last"])
cheese.set_index(["first", "last"]).stack()  # alternative way

----------------------------------------

TITLE: Accessing Series and DataFrame Elements in Python
DESCRIPTION: New methods get_value and set_value were added to Series, DataFrame, and Panel for faster access to scalar elements. set_value can also produce an enlarged object.

LANGUAGE: python
CODE:
# Example usage (not provided in the original text)
df.get_value(index, column)
df.set_value(index, column, value)

----------------------------------------

TITLE: Displaying First N Rows of DataFrame in Pandas
DESCRIPTION: This snippet shows how to use the head() method to display the first 8 rows of a pandas DataFrame named 'titanic'.

LANGUAGE: python
CODE:
titanic.head(8)

----------------------------------------

TITLE: Defining RST Document Structure for Pandas Tutorials
DESCRIPTION: RestructuredText markup defining the tutorial navigation structure with a table of contents tree containing links to 10 different pandas tutorial sections.

LANGUAGE: rst
CODE:
.. _10times1minute:

=========================
Getting started tutorials
=========================

.. toctree::
    :maxdepth: 1

    01_table_oriented
    02_read_write
    03_subset_data
    04_plotting
    05_add_columns
    06_calculate_statistics
    07_reshape_table_layout
    08_combine_dataframes
    09_timeseries
    10_text_data

----------------------------------------

TITLE: Applying styles to the weather DataFrame
DESCRIPTION: Applies the styling functions to a slice of the weather DataFrame.

LANGUAGE: python
CODE:
weather_df.loc["2021-01-04":"2021-01-08"].style.pipe(make_pretty)

----------------------------------------

TITLE: Generating Accessor Callable Documentation in Pandas using Sphinx
DESCRIPTION: This snippet sets up the documentation structure for a Pandas accessor callable object. It includes directives for the module, full name, and autoaccessorcallable. The template uses Jinja2-style variable substitution to dynamically insert the appropriate values.

LANGUAGE: reStructuredText
CODE:
{{ fullname }}
{{ underline }}

.. currentmodule:: {{ module.split('.')[0] }}

.. autoaccessorcallable:: {{ (module.split('.')[1:] + [objname]) | join('.') }}.__call__

----------------------------------------

TITLE: Creating a custom Styler subclass
DESCRIPTION: Shows how to create a custom Styler subclass with a custom HTML template.

LANGUAGE: python
CODE:
class MyStyler(Styler):
    env = Environment(
        loader=ChoiceLoader(
            [
                FileSystemLoader("templates"),  # contains ours
                Styler.loader,  # the default
            ]
        )
    )
    template_html_table = env.get_template("myhtml.tpl")

----------------------------------------

TITLE: DataFrame Operations and CSV Handling (Python)
DESCRIPTION: New DataFrame operations including append with ignore_index, CSV reading with delimiter sniffing and MultiIndex support, and DataFrame renaming functionality.

LANGUAGE: python
CODE:
dataframe.append(other_df, ignore_index=True)
pd.read_csv('file.csv')
dataframe.to_csv('output.csv')
dataframe.rename(columns={'old': 'new'}, copy=False)

----------------------------------------

TITLE: Merging DataFrames in pandas
DESCRIPTION: Demonstrates various types of joins in pandas, equivalent to Stata's merge operation.

LANGUAGE: python
CODE:
df1 = pd.DataFrame({"key": ["A", "B", "C", "D"], "value": np.random.randn(4)})
df2 = pd.DataFrame({"key": ["B", "D", "D", "E"], "value": np.random.randn(4)})

# Left join
print(df1.merge(df2, how="left", on="key"))

# Right join
print(df1.merge(df2, how="right", on="key"))

# Inner join
print(df1.merge(df2, how="inner", on="key"))

# Outer join
print(df1.merge(df2, how="outer", on="key"))

----------------------------------------

TITLE: Concatenating styled DataFrames
DESCRIPTION: Demonstrates how to concatenate a styled DataFrame with summary statistics.

LANGUAGE: python
CODE:
summary_styler = (
    df.agg(["sum", "mean"]).style.format(precision=3).relabel_index(["Sum", "Average"])
)
df.style.format(precision=1).concat(summary_styler)

----------------------------------------

TITLE: Importing pandas and numpy
DESCRIPTION: Imports the pandas and numpy libraries, which are used throughout the examples.

LANGUAGE: python
CODE:
import pandas as pd
import numpy as np

----------------------------------------

TITLE: Applying NumPy ufuncs to SparseArray in Python
DESCRIPTION: This snippet shows how NumPy ufuncs can be applied to SparseArray objects, resulting in another SparseArray. It also demonstrates how the ufunc is applied to the fill_value.

LANGUAGE: python
CODE:
arr = pd.arrays.SparseArray([1., np.nan, np.nan, -2., np.nan])
np.abs(arr)

arr = pd.arrays.SparseArray([1., -1, -1, -2., -1], fill_value=-1)
np.abs(arr)
np.abs(arr).to_dense()

----------------------------------------

TITLE: Creating a Minimal Reproducible Example for Regression Testing in Python
DESCRIPTION: This code snippet demonstrates how to create a minimal reproducible example for regression testing in pandas. It asserts that the sum of a Series with two 1s should equal 2.

LANGUAGE: python
CODE:
import pandas as pd
assert pd.Series([1, 1]).sum() == 2

----------------------------------------

TITLE: Excel File Operations with Pandas
DESCRIPTION: Shows how to write DataFrame to Excel file and read it back using pandas Excel I/O functionality.

LANGUAGE: python
CODE:
tips.to_excel("./tips.xlsx")

tips_df = pd.read_excel("./tips.xlsx", index_col=0)

----------------------------------------

TITLE: Creating and Converting SparseArray in Python
DESCRIPTION: This code creates a SparseArray from a numpy array with NaN values, then demonstrates how to convert it back to a dense numpy array using np.asarray().

LANGUAGE: python
CODE:
arr = np.random.randn(10)
arr[2:5] = np.nan
arr[7:8] = np.nan
sparr = pd.arrays.SparseArray(arr)
sparr

np.asarray(sparr)

----------------------------------------

TITLE: Applying conditional formatting
DESCRIPTION: Demonstrates how to apply conditional formatting to a DataFrame.

LANGUAGE: python
CODE:
def style_negative(v, props=""):
    return props if v < 0 else None


s2 = df2.style.map(style_negative, props="color:red;").map(
    lambda v: "opacity: 20%;" if (v < 0.3) and (v > -0.3) else None
)
s2

----------------------------------------

TITLE: Basic Options Usage with pandas
DESCRIPTION: Demonstrates basic usage of getting and setting pandas options using the options API

LANGUAGE: python
CODE:
import pandas as pd

pd.options.display.max_rows
pd.options.display.max_rows = 999
pd.options.display.max_rows

----------------------------------------

TITLE: Importing Pandas Testing Module
DESCRIPTION: This snippet shows how to import the Pandas testing module. It's typically used at the beginning of a file to access testing functions.

LANGUAGE: Python
CODE:
.. currentmodule:: pandas

----------------------------------------

TITLE: Reading CSV Data in SAS using PROC IMPORT
DESCRIPTION: This SAS code snippet shows how to read CSV data into a SAS data set using the PROC IMPORT procedure.

LANGUAGE: sas
CODE:
proc import datafile='tips.csv' dbms=csv out=tips replace;
    getnames=yes;
run;

----------------------------------------

TITLE: Creating and Using SparseDtype in Python
DESCRIPTION: This snippet shows how to create a SparseDtype, which stores information about the dtype of non-sparse values and the fill value. It demonstrates different ways of constructing SparseDtype.

LANGUAGE: python
CODE:
sparr.dtype

pd.SparseDtype(np.dtype('datetime64[ns]'))

pd.SparseDtype(np.dtype('datetime64[ns]'),
               fill_value=pd.Timestamp('2017-01-01'))

pd.array([1, 0, 0, 2], dtype='Sparse[int]')

----------------------------------------

TITLE: Updating Index Set Operations in Pandas
DESCRIPTION: API changes to the sort parameter behavior for Index.union, Index.difference, Index.symmetric_difference, and Index.intersection methods. The defaults and behavior of sort parameter were modified to maintain consistency and prepare for future enhancements.

LANGUAGE: python
CODE:
Index.union(sort=None)        # Changed default from True to None
Index.difference(sort=None)    # Updated behavior
Index.symmetric_difference()  # Updated behavior
Index.intersection(sort=False) # Changed default from True to False

----------------------------------------

TITLE: Constructing IntegerArray with Pandas Array Function
DESCRIPTION: Demonstrates how to create an IntegerArray using pd.array() with the Int64Dtype. This allows for integer data with possibly missing values.

LANGUAGE: python
CODE:
arr = pd.array([1, 2, None], dtype=pd.Int64Dtype())
arr

----------------------------------------

TITLE: Generating Pandas Class Documentation Template in RST
DESCRIPTION: A reStructuredText template that uses directives to automatically generate documentation for a Pandas class. It sets up the module context and creates class documentation using autoclass directive.

LANGUAGE: rst
CODE:
{{ fullname }}
{{ underline }}

.. currentmodule:: {{ module }}

.. autoclass:: {{ objname }}

----------------------------------------

TITLE: DataFrame Apply with Safe Copy in Python
DESCRIPTION: Shows how to safely modify DataFrame data within an apply function by making a copy first to avoid mutation issues during iteration.

LANGUAGE: python
CODE:
def f(s):
    s = s.copy()
    s.pop("a")
    return s

df = pd.DataFrame({"a": [1, 2, 3], 'b': [4, 5, 6]})
df.apply(f, axis="columns")

----------------------------------------

TITLE: Converting Sparse Series to scipy.sparse.coo_matrix in Python
DESCRIPTION: This code shows how to convert a Series with sparse values and a MultiIndex to a scipy.sparse.coo_matrix using the Series.sparse.to_coo() method.

LANGUAGE: python
CODE:
s = pd.Series([3.0, np.nan, 1.0, 3.0, np.nan, np.nan])
s.index = pd.MultiIndex.from_tuples(
    [
        (1, 2, "a", 0),
        (1, 2, "a", 1),
        (1, 1, "b", 0),
        (1, 1, "b", 1),
        (2, 1, "b", 0),
        (2, 1, "b", 1),
    ],
    names=["A", "B", "C", "D"],
)
ss = s.astype('Sparse')
ss

A, rows, columns = ss.sparse.to_coo(
    row_levels=["A", "B"], column_levels=["C", "D"], sort_labels=True
)

A
A.todense()
rows
columns

----------------------------------------

TITLE: Preserving Timezone Info in GroupBy Operations in Python
DESCRIPTION: This bug fix ensures that timezone information is not dropped in GroupBy.shift(), GroupBy.bfill(), and GroupBy.ffill() operations.

LANGUAGE: Python
CODE:
GroupBy.shift()
GroupBy.bfill()
GroupBy.ffill()

----------------------------------------

TITLE: Python Integration Function Implementation
DESCRIPTION: Pure Python implementation of numerical integration function using for loop.

LANGUAGE: python
CODE:
def f(x):
    return x * (x - 1)

def integrate_f(a, b, N):
    s = 0
    dx = (b - a) / N
    for i in range(N):
        s += f(a + i * dx)
    return s * dx

----------------------------------------

TITLE: Creating Table of Contents for Tool Comparisons in reStructuredText
DESCRIPTION: This snippet creates a table of contents using reStructuredText syntax, listing comparisons between pandas and other data analysis tools. It includes a main heading and a toctree directive with a maxdepth of 2.

LANGUAGE: restructuredtext
CODE:
.. _comparison:

===========================
Comparison with other tools
===========================

.. toctree::
    :maxdepth: 2

    comparison_with_r
    comparison_with_sql
    comparison_with_spreadsheets
    comparison_with_sas
    comparison_with_stata
    comparison_with_spss

----------------------------------------

TITLE: Container Mutation with List Iterator in Python
DESCRIPTION: Example showing incorrect and correct ways to mutate a list while iterating over it. Demonstrates why creating a copy is necessary when modifying containers during iteration.

LANGUAGE: python
CODE:
values = [0, 1, 2, 3, 4, 5]
n_removed = 0
for k, value in enumerate(values.copy()):
    idx = k - n_removed
    if value % 2 == 1:
        del values[idx]
        n_removed += 1
    else:
        values[idx] = value + 1
values

----------------------------------------

TITLE: DataFrame Column Selection and Assignment
DESCRIPTION: Shows how to select and modify columns in a DataFrame using list indexing

LANGUAGE: python
CODE:
df = pd.DataFrame(np.arange(25).reshape(5, 5), index=list("abcde"), columns=list("abcde"))
df.loc[["a", "c", "e"], ["b", "d"]]

----------------------------------------

TITLE: Ensuring Python 3.8 Compatibility in DataFrame Query in Python
DESCRIPTION: This fix ensures compatibility with Python 3.8 when using the DataFrame.query() method.

LANGUAGE: Python
CODE:
DataFrame.query(...)

----------------------------------------

TITLE: DataFrame Operations with Duplicate Column Labels
DESCRIPTION: Demonstrates how indexing behavior changes with duplicate column labels in DataFrames.

LANGUAGE: python
CODE:
df1 = pd.DataFrame([[0, 1, 2], [3, 4, 5]], columns=["A", "A", "B"])
df1["B"]  # returns a series
df1["A"]  # returns a DataFrame

----------------------------------------

TITLE: Index Set Operations
DESCRIPTION: Shows set operations like union, intersection and difference on Index objects

LANGUAGE: python
CODE:
a = pd.Index(['c', 'b', 'a'])
b = pd.Index(['c', 'e', 'd'])
a.difference(b)

----------------------------------------

TITLE: Conditional Assignment in DataFrame
DESCRIPTION: Demonstrates how to conditionally assign values to DataFrame columns based on boolean criteria

LANGUAGE: python
CODE:
df.loc[df.AAA >= 5, "BBB"] = -1
df.loc[df.AAA >= 5, ["BBB", "CCC"]] = 555
df.loc[df.AAA < 5, ["BBB", "CCC"]] = 2000

----------------------------------------

TITLE: Fixing DataFrame Correlation for Kendall Method in Python
DESCRIPTION: Corrected the calculation of Kendall correlation for columns with repeated values in DataFrame.corr.

LANGUAGE: python
CODE:
df.corr(method='kendall')

----------------------------------------

TITLE: Creating Compilation Database Symlink
DESCRIPTION: Command to create a symlink to the compilation database for IDE support.

LANGUAGE: shell
CODE:
ln -s debug/compile_commands.json .

----------------------------------------

TITLE: Creating Series with Duplicate Labels in Python
DESCRIPTION: Example showing creation of a Series with duplicate index labels and demonstrating how reindexing fails with duplicates.

LANGUAGE: python
CODE:
s1 = pd.Series([0, 1, 2], index=["a", "b", "b"])
s1.reindex(["a", "b", "c"])

----------------------------------------

TITLE: Time Series Date Range Operations
DESCRIPTION: Shows how to create and manipulate date ranges in pandas

LANGUAGE: python
CODE:
dates = pd.date_range("2000-01-01", periods=5)
dates.to_period(freq="M").to_timestamp()

----------------------------------------

TITLE: Fixing Complex Number Division in Pandas eval Function
DESCRIPTION: Addresses a bug in the eval function where division of complex numbers discarded the imaginary part. This fix ensures proper handling of complex number arithmetic in Pandas evaluations.

LANGUAGE: python
CODE:
eval()

----------------------------------------

TITLE: Hiding rows and columns in a DataFrame
DESCRIPTION: Demonstrates how to hide specific rows and columns when displaying a DataFrame.

LANGUAGE: python
CODE:
df = pd.DataFrame(np.random.default_rng().standard_normal((5, 5)))
df.style.hide(subset=[0, 2, 4], axis=0).hide(subset=[0, 2, 4], axis=1)

----------------------------------------

TITLE: Indexing with NA Values in Pandas Boolean Arrays
DESCRIPTION: Demonstrates how pandas allows indexing with NA values in a boolean array, treating them as False. Also shows how to keep NA values using fillna(True).

LANGUAGE: python
CODE:
s = pd.Series([1, 2, 3])
mask = pd.array([True, False, pd.NA], dtype="boolean")
s[mask]

LANGUAGE: python
CODE:
s[mask.fillna(True)]

----------------------------------------

TITLE: Comparing DataFrames with DataFrame.compare
DESCRIPTION: Demonstrates how to use DataFrame.compare to summarize differences between two DataFrames.

LANGUAGE: python
CODE:
df = pd.DataFrame({"col1": ["a", "a", "b", "b", "a"],
                   "col2": [1.0, 2.0, 3.0, np.nan, 5.0],
                   "col3": [1.0, 2.0, 3.0, 4.0, 5.0]},
                  columns=["col1", "col2", "col3"])

df2 = df.copy()
df2.loc[0, "col1"] = "c"
df2.loc[2, "col3"] = 4.0

df.compare(df2)

----------------------------------------

TITLE: Using slicers with MultiIndex
DESCRIPTION: Shows how to use slicers to select data from a DataFrame with a MultiIndex on both axes.

LANGUAGE: python
CODE:
idx = pd.IndexSlice
dfmi.loc[idx[:, :, ["C1", "C3"]], idx[:, "foo"]]

----------------------------------------

TITLE: Inconsistent parsing with infer_datetime_format
DESCRIPTION: This example demonstrates that using infer_datetime_format doesn't solve the inconsistent parsing issue.

LANGUAGE: python
CODE:
pd.to_datetime(['12-01-2000 00:00:00', '13-01-2000 00:00:00'], infer_datetime_format=True)

----------------------------------------

TITLE: Random String Generation Performance Test Setup
DESCRIPTION: Creates test data for comparing performance between object dtype and pyarrow string dtype using random string generation.

LANGUAGE: python
CODE:
import string
import random

import pandas as pd


def random_string() -> str:
    return "".join(random.choices(string.printable, k=random.randint(10, 100)))


ser_object = pd.Series([random_string() for _ in range(1_000_000)])
ser_string = ser_object.astype("string[pyarrow]")

----------------------------------------

TITLE: Proposed flexible parsing with 'mixed' format
DESCRIPTION: This snippet shows how users could still use flexible parsing by explicitly specifying a 'mixed' format.

LANGUAGE: python
CODE:
pd.to_datetime(['12-01-2000 00:00:00', '13-01-2000 00:00:00'], format='mixed')

----------------------------------------

TITLE: DuckDB Integration Example
DESCRIPTION: Example of using the proposed DuckDB connector with SQL query and predicate pushdown.

LANGUAGE: python
CODE:
pandas.read_duckdb("SELECT *
                    FROM 'dataset.parquet'
                    WHERE my_col > 0")

----------------------------------------

TITLE: Finding Longest Name in Pandas Dataset
DESCRIPTION: Uses string length and idxmax() to find the index of the longest name, then retrieves the full name.

LANGUAGE: python
CODE:
titanic["Name"].str.len()

titanic["Name"].str.len().idxmax()

titanic.loc[titanic["Name"].str.len().idxmax(), "Name"]

----------------------------------------

TITLE: Parsing ISO8601 dates with explicit format
DESCRIPTION: This example demonstrates parsing ISO8601 formatted dates using the proposed 'ISO8601' format specifier.

LANGUAGE: python
CODE:
pd.to_datetime(['2020-01-01', '2020-01-01 03:00'], format='ISO8601')

----------------------------------------

TITLE: Finding Substring Position in Pandas Series
DESCRIPTION: This snippet demonstrates how to use the str.find method to locate the position of the substring 'ale' within the 'sex' column of the 'tips' dataset. The method returns the index of the first occurrence or -1 if not found.

LANGUAGE: python
CODE:
tips["sex"].str.find("ale")

----------------------------------------

TITLE: Categorical Data Handling with Values and Array Methods
DESCRIPTION: Illustrates the difference between accessing categorical data using .values versus the new .array and .to_numpy() methods.

LANGUAGE: python
CODE:
>>> cat = pd.Categorical(['a', 'b', 'a'], categories=['a', 'b', 'c'])
>>> ser = pd.Series(cat)
>>> ser
0    a
1    b
2    a
dtype: category
Categories (3, object): ['a', 'b', 'c']

>>> ser.values
[a, b, a]
Categories (3, object): ['a', 'b', 'c']

>>> ser.array
[a, b, a]
Categories (3, object): ['a', 'b', 'c']

>>> ser.to_numpy()
array(['a', 'b', 'a'], dtype=object)

----------------------------------------

TITLE: Generating Accessor Documentation with Jinja2 and Sphinx
DESCRIPTION: This template creates a documentation page for a Pandas accessor. It sets up the page title, current module context, and uses the autoaccessor directive to automatically generate API documentation for the specified accessor.

LANGUAGE: jinja2
CODE:
{{ fullname }}
{{ underline }}

.. currentmodule:: {{ module.split('.')[0] }}

.. autoaccessor:: {{ (module.split('.')[1:] + [objname]) | join('.') }}

----------------------------------------

TITLE: Using fillna in pandas Series
DESCRIPTION: Shows that calling fillna on a Series now requires specifying either a fill value or an interpolation method. Demonstrates using a fill value and the new ffill convenience method.

LANGUAGE: python
CODE:
s = pd.Series([np.nan, 1.0, 2.0, np.nan, 4])

s

s.fillna(0)

s.fillna(method="pad")

s = pd.Series([np.nan, 1.0, 2.0, np.nan, 4])
s.ffill()

----------------------------------------

TITLE: Pandas Documentation Structure in RST
DESCRIPTION: ReStructuredText markup defining the structure and content of pandas 1.2.5 release notes, including section headers and references.

LANGUAGE: rst
CODE:
.. _whatsnew_125:

What's new in 1.2.5 (June 22, 2021)
-----------------------------------

These are the changes in pandas 1.2.5. See :ref:`release` for a full changelog
including other versions of pandas.

{{ header }}

.. ---------------------------------------------------------------------------

.. _whatsnew_125.regressions:

Fixed regressions
~~~~~~~~~~~~~~~~~
- Fixed regression in :func:`concat` between two :class:`DataFrame` where one has an :class:`Index` that is all-None and the other is :class:`DatetimeIndex` incorrectly raising (:issue:`40841`)
- Fixed regression in :meth:`DataFrame.sum` and :meth:`DataFrame.prod` when ``min_count`` and ``numeric_only`` are both given (:issue:`41074`)
- Fixed regression in :func:`read_csv` when using ``memory_map=True`` with an non-UTF8 encoding (:issue:`40986`)
- Fixed regression in :meth:`DataFrame.replace` and :meth:`Series.replace` when the values to replace is a NumPy float array (:issue:`40371`)
- Fixed regression in :func:`ExcelFile` when a corrupt file is opened but not closed (:issue:`41778`)
- Fixed regression in :meth:`DataFrame.astype` with ``dtype=str`` failing to convert ``NaN`` in categorical columns (:issue:`41797`)

.. ---------------------------------------------------------------------------

.. _whatsnew_125.contributors:

Contributors
~~~~~~~~~~~~

.. contributors:: v1.2.4..v1.2.5|HEAD

----------------------------------------

TITLE: Demonstrating wide DataFrame printing in pandas
DESCRIPTION: Shows how pandas now splits the string representation of wide DataFrames across multiple rows by default. Demonstrates how to revert to the old summary behavior and how to change the line width.

LANGUAGE: python
CODE:
wide_frame = pd.DataFrame(np.random.randn(5, 16))

wide_frame

pd.set_option("expand_frame_repr", False)

wide_frame

pd.reset_option("expand_frame_repr")